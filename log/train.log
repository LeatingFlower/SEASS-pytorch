2018-08-12 00:04:15,836 - INFO - Load model parameters from ./models/params_0.pkl
2018-08-12 00:04:15,836 - INFO - Start to train...
2018-08-12 00:04:21,561 - INFO - epoch 0, step 10, training loss = 2.973902, validation loss = 3.119609
2018-08-12 00:04:27,040 - INFO - epoch 0, step 20, training loss = 3.177298, validation loss = 3.163477
2018-08-12 00:04:32,561 - INFO - epoch 0, step 30, training loss = 3.133022, validation loss = 3.172213
2018-08-12 00:04:38,115 - INFO - epoch 0, step 40, training loss = 3.662149, validation loss = 3.177007
2018-08-12 00:04:43,887 - INFO - epoch 0, step 50, training loss = 2.919917, validation loss = 3.175977
2018-08-12 00:04:49,768 - INFO - epoch 0, step 60, training loss = 3.154827, validation loss = 3.166769
2018-08-12 00:04:55,687 - INFO - epoch 0, step 70, training loss = 3.529652, validation loss = 3.190843
2018-08-12 00:05:02,332 - INFO - epoch 0, step 80, training loss = 3.244097, validation loss = 3.201614
2018-08-12 00:05:08,433 - INFO - epoch 0, step 90, training loss = 3.592860, validation loss = 3.177524
2018-08-12 00:05:15,543 - INFO - epoch 0, step 100, training loss = 3.203747, validation loss = 3.140749
2018-08-12 00:05:22,066 - INFO - epoch 0, step 110, training loss = 3.445040, validation loss = 3.120680
2018-08-12 00:05:28,361 - INFO - epoch 0, step 120, training loss = 3.467200, validation loss = 3.148256
2018-08-12 00:05:34,581 - INFO - epoch 0, step 130, training loss = 3.361591, validation loss = 3.129580
2018-08-12 00:05:40,693 - INFO - epoch 0, step 140, training loss = 3.382023, validation loss = 3.113275
2018-08-12 00:05:47,105 - INFO - epoch 0, step 150, training loss = 2.789519, validation loss = 3.166701
2018-08-12 00:05:53,413 - INFO - epoch 0, step 160, training loss = 3.183787, validation loss = 3.126277
2018-08-12 00:05:59,230 - INFO - epoch 0, step 170, training loss = 3.003320, validation loss = 3.147836
2018-08-12 00:06:05,102 - INFO - epoch 0, step 180, training loss = 3.115143, validation loss = 3.210845
2018-08-12 00:06:11,472 - INFO - epoch 0, step 190, training loss = 3.123177, validation loss = 3.205968
2018-08-12 00:06:17,759 - INFO - epoch 0, step 200, training loss = 3.000850, validation loss = 3.187019
2018-08-12 00:06:23,799 - INFO - epoch 0, step 210, training loss = 3.306193, validation loss = 3.163838
2018-08-12 00:06:30,526 - INFO - epoch 0, step 220, training loss = 2.259065, validation loss = 3.141357
2018-08-12 00:06:36,919 - INFO - epoch 0, step 230, training loss = 3.122422, validation loss = 3.123221
2018-08-12 00:06:43,418 - INFO - epoch 0, step 240, training loss = 2.854749, validation loss = 3.106763
2018-08-12 00:06:49,977 - INFO - epoch 0, step 250, training loss = 2.900948, validation loss = 3.132792
2018-08-12 00:06:56,406 - INFO - epoch 0, step 260, training loss = 2.979452, validation loss = 3.126578
2018-08-12 00:07:02,798 - INFO - epoch 0, step 270, training loss = 3.181497, validation loss = 3.121948
2018-08-12 00:07:09,029 - INFO - epoch 0, step 280, training loss = 3.127083, validation loss = 3.114677
2018-08-12 00:07:15,237 - INFO - epoch 0, step 290, training loss = 3.240111, validation loss = 3.134065
2018-08-12 00:07:21,519 - INFO - epoch 0, step 300, training loss = 3.013267, validation loss = 3.112122
2018-08-12 00:07:27,904 - INFO - epoch 0, step 310, training loss = 3.778237, validation loss = 3.114140
2018-08-12 00:07:34,315 - INFO - epoch 0, step 320, training loss = 3.000176, validation loss = 3.095025
2018-08-12 00:07:40,279 - INFO - epoch 0, step 330, training loss = 3.166076, validation loss = 3.088754
2018-08-12 00:07:46,407 - INFO - epoch 0, step 340, training loss = 3.515114, validation loss = 3.091763
2018-08-12 00:07:52,963 - INFO - epoch 0, step 350, training loss = 3.021152, validation loss = 3.072205
2018-08-12 00:07:59,046 - INFO - epoch 0, step 360, training loss = 3.006874, validation loss = 3.079030
2018-08-12 00:08:05,296 - INFO - epoch 0, step 370, training loss = 2.976250, validation loss = 3.080736
2018-08-12 00:08:11,539 - INFO - epoch 0, step 380, training loss = 2.866316, validation loss = 3.069301
2018-08-12 00:08:17,933 - INFO - epoch 0, step 390, training loss = 3.441313, validation loss = 3.093491
2018-08-12 00:08:24,707 - INFO - epoch 0, step 400, training loss = 3.648226, validation loss = 3.110989
2018-08-12 00:08:32,464 - INFO - epoch 0, step 410, training loss = 3.066504, validation loss = 3.081275
2018-08-12 00:08:38,941 - INFO - epoch 0, step 420, training loss = 2.965456, validation loss = 3.090030
2018-08-12 00:08:45,556 - INFO - epoch 0, step 430, training loss = 3.000844, validation loss = 3.092109
2018-08-12 00:08:51,883 - INFO - epoch 0, step 440, training loss = 3.344363, validation loss = 3.065707
2018-08-12 00:08:58,425 - INFO - epoch 0, step 450, training loss = 3.402457, validation loss = 3.053982
2018-08-12 00:09:05,000 - INFO - epoch 0, step 460, training loss = 3.008016, validation loss = 3.084111
2018-08-12 00:09:11,947 - INFO - epoch 0, step 470, training loss = 2.761112, validation loss = 3.085921
2018-08-12 00:09:18,705 - INFO - epoch 0, step 480, training loss = 3.584165, validation loss = 3.089089
2018-08-12 00:09:25,586 - INFO - epoch 0, step 490, training loss = 2.579826, validation loss = 3.118118
2018-08-12 00:09:32,097 - INFO - epoch 0, step 500, training loss = 2.945228, validation loss = 3.088410
2018-08-12 00:09:38,424 - INFO - epoch 0, step 510, training loss = 3.814739, validation loss = 3.087644
2018-08-12 00:09:44,677 - INFO - epoch 0, step 520, training loss = 3.094244, validation loss = 3.102534
2018-08-12 00:09:51,021 - INFO - epoch 0, step 530, training loss = 3.375762, validation loss = 3.059690
2018-08-12 00:09:57,247 - INFO - epoch 0, step 540, training loss = 3.275806, validation loss = 3.069252
2018-08-12 00:10:03,598 - INFO - epoch 0, step 550, training loss = 3.266549, validation loss = 3.086158
2018-08-12 00:10:09,938 - INFO - epoch 0, step 560, training loss = 2.899923, validation loss = 3.103723
2018-08-12 00:10:16,294 - INFO - epoch 0, step 570, training loss = 2.918383, validation loss = 3.126694
2018-08-12 00:10:22,687 - INFO - epoch 0, step 580, training loss = 3.254735, validation loss = 3.088943
2018-08-12 00:10:29,118 - INFO - epoch 0, step 590, training loss = 3.243169, validation loss = 3.093763
2018-08-12 00:10:35,456 - INFO - epoch 0, step 600, training loss = 3.391524, validation loss = 3.122657
2018-08-12 00:10:42,470 - INFO - epoch 0, step 610, training loss = 2.543093, validation loss = 3.070568
2018-08-12 00:10:49,016 - INFO - epoch 0, step 620, training loss = 3.016057, validation loss = 3.085925
2018-08-12 00:10:55,491 - INFO - epoch 0, step 630, training loss = 3.304669, validation loss = 3.093524
2018-08-12 00:11:01,948 - INFO - epoch 0, step 640, training loss = 3.448351, validation loss = 3.075458
2018-08-12 00:11:08,324 - INFO - epoch 0, step 650, training loss = 3.414165, validation loss = 3.093391
2018-08-12 00:11:14,362 - INFO - epoch 0, step 660, training loss = 3.448434, validation loss = 3.141352
2018-08-12 00:11:19,949 - INFO - epoch 0, step 670, training loss = 3.351795, validation loss = 3.155501
2018-08-12 00:11:25,987 - INFO - epoch 0, step 680, training loss = 3.089744, validation loss = 3.136101
2018-08-12 00:11:31,785 - INFO - epoch 0, step 690, training loss = 3.379283, validation loss = 3.148414
2018-08-12 00:11:37,278 - INFO - epoch 0, step 700, training loss = 2.953568, validation loss = 3.150368
2018-08-12 00:11:43,319 - INFO - epoch 0, step 710, training loss = 3.060309, validation loss = 3.160625
2018-08-12 00:11:49,568 - INFO - epoch 0, step 720, training loss = 3.128156, validation loss = 3.156556
2018-08-12 00:11:55,503 - INFO - epoch 0, step 730, training loss = 3.226113, validation loss = 3.141343
2018-08-12 00:12:01,217 - INFO - epoch 0, step 740, training loss = 3.546688, validation loss = 3.131435
2018-08-12 00:12:11,854 - INFO - epoch 0, step 750, training loss = 0.943590, validation loss = 3.130723
2018-08-12 00:12:17,704 - INFO - epoch 0, step 760, training loss = 3.379307, validation loss = 3.127634
2018-08-12 00:12:23,706 - INFO - epoch 0, step 770, training loss = 2.997893, validation loss = 3.143986
2018-08-12 00:12:29,902 - INFO - epoch 0, step 780, training loss = 2.924522, validation loss = 3.152774
2018-08-12 00:12:36,156 - INFO - epoch 0, step 790, training loss = 3.350844, validation loss = 3.154114
2018-08-12 00:12:41,798 - INFO - epoch 0, step 800, training loss = 3.263869, validation loss = 3.145907
2018-08-12 00:12:47,645 - INFO - epoch 0, step 810, training loss = 2.898842, validation loss = 3.146832
2018-08-12 00:12:53,192 - INFO - epoch 0, step 820, training loss = 3.157707, validation loss = 3.154920
2018-08-12 00:13:01,189 - INFO - epoch 0, step 830, training loss = 3.139998, validation loss = 3.156849
2018-08-12 00:13:09,196 - INFO - epoch 0, step 840, training loss = 2.735868, validation loss = 3.148126
2018-08-12 00:13:14,760 - INFO - epoch 0, step 850, training loss = 3.208986, validation loss = 3.155115
2018-08-12 00:13:20,497 - INFO - epoch 0, step 860, training loss = 2.704753, validation loss = 3.171195
2018-08-12 00:13:25,933 - INFO - epoch 0, step 870, training loss = 3.559258, validation loss = 3.194067
2018-08-12 00:13:31,144 - INFO - epoch 0, step 880, training loss = 2.785982, validation loss = 3.121145
2018-08-12 00:13:36,506 - INFO - epoch 0, step 890, training loss = 3.000691, validation loss = 3.149670
2018-08-12 00:13:41,518 - INFO - epoch 0, step 900, training loss = 3.430762, validation loss = 3.151095
2018-08-12 00:13:46,872 - INFO - epoch 0, step 910, training loss = 2.577086, validation loss = 3.151421
2018-08-12 00:13:52,363 - INFO - epoch 0, step 920, training loss = 2.779425, validation loss = 3.166035
2018-08-12 00:13:58,429 - INFO - epoch 0, step 930, training loss = 3.557633, validation loss = 3.152502
2018-08-12 00:14:04,787 - INFO - epoch 0, step 940, training loss = 3.117521, validation loss = 3.109246
2018-08-12 00:14:11,464 - INFO - epoch 0, step 950, training loss = 3.241504, validation loss = 3.133202
2018-08-12 00:14:17,873 - INFO - epoch 0, step 960, training loss = 3.472553, validation loss = 3.104355
2018-08-12 00:14:24,804 - INFO - epoch 0, step 970, training loss = 2.971817, validation loss = 3.109817
2018-08-12 00:14:30,817 - INFO - epoch 0, step 980, training loss = 3.508653, validation loss = 3.125976
2018-08-12 00:14:35,992 - INFO - epoch 0, step 990, training loss = 3.245361, validation loss = 3.153017
2018-08-12 00:14:41,260 - INFO - epoch 0, step 1000, training loss = 3.227573, validation loss = 3.176292
2018-08-12 00:14:46,371 - INFO - epoch 0, step 1010, training loss = 3.498749, validation loss = 3.143623
2018-08-12 00:14:51,397 - INFO - epoch 0, step 1020, training loss = 2.895303, validation loss = 3.157152
2018-08-12 00:14:56,683 - INFO - epoch 0, step 1030, training loss = 3.410812, validation loss = 3.170666
2018-08-12 00:15:02,087 - INFO - epoch 0, step 1040, training loss = 3.208420, validation loss = 3.134304
2018-08-12 00:15:07,297 - INFO - epoch 0, step 1050, training loss = 3.309427, validation loss = 3.157615
2018-08-12 00:15:12,497 - INFO - epoch 0, step 1060, training loss = 3.171262, validation loss = 3.159473
2018-08-12 00:15:17,748 - INFO - epoch 0, step 1070, training loss = 2.829209, validation loss = 3.179561
2018-08-12 00:15:23,098 - INFO - epoch 0, step 1080, training loss = 2.792984, validation loss = 3.175987
2018-08-12 00:15:28,328 - INFO - epoch 0, step 1090, training loss = 3.165347, validation loss = 3.169394
2018-08-12 00:15:34,057 - INFO - epoch 0, step 1100, training loss = 3.227205, validation loss = 3.141012
2018-08-12 00:15:39,809 - INFO - epoch 0, step 1110, training loss = 3.115315, validation loss = 3.152264
2018-08-12 00:15:45,492 - INFO - epoch 0, step 1120, training loss = 3.378936, validation loss = 3.172054
2018-08-12 00:15:51,215 - INFO - epoch 0, step 1130, training loss = 3.261591, validation loss = 3.186535
2018-08-12 00:15:57,222 - INFO - epoch 0, step 1140, training loss = 3.233503, validation loss = 3.165680
2018-08-12 00:16:03,669 - INFO - epoch 0, step 1150, training loss = 3.068123, validation loss = 3.221822
2018-08-12 00:16:09,918 - INFO - epoch 0, step 1160, training loss = 3.322322, validation loss = 3.110440
2018-08-12 00:16:16,252 - INFO - epoch 0, step 1170, training loss = 3.482181, validation loss = 3.134080
2018-08-12 00:16:22,387 - INFO - epoch 0, step 1180, training loss = 3.267858, validation loss = 3.154099
2018-08-12 00:16:28,849 - INFO - epoch 0, step 1190, training loss = 3.148401, validation loss = 3.102563
2018-08-12 00:16:35,261 - INFO - epoch 0, step 1200, training loss = 3.219760, validation loss = 3.138201
2018-08-12 00:16:42,556 - INFO - epoch 0, step 1210, training loss = 3.307566, validation loss = 3.109006
2018-08-12 00:16:48,355 - INFO - epoch 0, step 1220, training loss = 3.389158, validation loss = 3.136427
2018-08-12 00:16:54,089 - INFO - epoch 0, step 1230, training loss = 3.018916, validation loss = 3.137301
2018-08-12 00:16:59,773 - INFO - epoch 0, step 1240, training loss = 3.434091, validation loss = 3.214005
2018-08-12 00:17:05,580 - INFO - epoch 0, step 1250, training loss = 3.266053, validation loss = 3.148779
2018-08-12 00:17:11,279 - INFO - epoch 0, step 1260, training loss = 3.096141, validation loss = 3.144375
2018-08-12 00:17:16,704 - INFO - epoch 0, step 1270, training loss = 3.147589, validation loss = 3.170011
2018-08-12 00:17:22,256 - INFO - epoch 0, step 1280, training loss = 3.329909, validation loss = 3.142624
2018-08-12 00:17:27,892 - INFO - epoch 0, step 1290, training loss = 3.172514, validation loss = 3.153305
2018-08-12 00:17:33,675 - INFO - epoch 0, step 1300, training loss = 3.256034, validation loss = 3.151717
2018-08-12 00:17:39,324 - INFO - epoch 0, step 1310, training loss = 2.478290, validation loss = 3.177762
2018-08-12 00:17:44,212 - INFO - epoch 0, step 1320, training loss = 3.220214, validation loss = 3.165853
2018-08-12 00:17:49,872 - INFO - epoch 0, step 1330, training loss = 3.168641, validation loss = 3.185344
2018-08-12 00:17:55,638 - INFO - epoch 0, step 1340, training loss = 3.265442, validation loss = 3.092758
2018-08-12 00:18:01,830 - INFO - epoch 0, step 1350, training loss = 3.293713, validation loss = 3.115960
2018-08-12 00:18:07,744 - INFO - epoch 0, step 1360, training loss = 2.964548, validation loss = 3.087993
2018-08-12 00:18:13,835 - INFO - epoch 0, step 1370, training loss = 3.226069, validation loss = 3.092155
2018-08-12 00:18:19,551 - INFO - epoch 0, step 1380, training loss = 3.220824, validation loss = 3.077269
2018-08-12 00:18:24,560 - INFO - epoch 0, step 1390, training loss = 3.176904, validation loss = 3.088842
2018-08-12 00:18:29,441 - INFO - epoch 0, step 1400, training loss = 3.542844, validation loss = 3.095126
2018-08-12 00:18:34,241 - INFO - epoch 0, step 1410, training loss = 3.642032, validation loss = 3.099455
2018-08-12 00:18:38,664 - INFO - epoch 0, step 1420, training loss = 3.261076, validation loss = 3.098106
2018-08-12 00:18:42,962 - INFO - epoch 0, step 1430, training loss = 2.877326, validation loss = 3.145797
2018-08-12 00:18:47,201 - INFO - epoch 0, step 1440, training loss = 2.844221, validation loss = 3.128144
2018-08-12 00:18:51,690 - INFO - epoch 0, step 1450, training loss = 3.118326, validation loss = 3.127165
2018-08-12 00:18:56,150 - INFO - epoch 0, step 1460, training loss = 2.971519, validation loss = 3.147837
2018-08-12 00:19:00,961 - INFO - epoch 0, step 1470, training loss = 3.397043, validation loss = 3.149310
2018-08-12 00:19:07,677 - INFO - epoch 0, step 1480, training loss = 2.640061, validation loss = 3.098927
2018-08-12 00:19:14,414 - INFO - epoch 0, step 1490, training loss = 3.192155, validation loss = 3.114453
2018-08-12 00:19:20,960 - INFO - epoch 0, step 1500, training loss = 3.014965, validation loss = 3.104654
2018-08-12 00:19:27,692 - INFO - epoch 0, step 1510, training loss = 2.998761, validation loss = 3.101903
2018-08-12 00:19:34,055 - INFO - epoch 0, step 1520, training loss = 3.378443, validation loss = 3.104669
2018-08-12 00:19:40,389 - INFO - epoch 0, step 1530, training loss = 3.102686, validation loss = 3.191789
2018-08-12 00:19:46,912 - INFO - epoch 0, step 1540, training loss = 2.879149, validation loss = 3.111600
2018-08-12 00:19:53,349 - INFO - epoch 0, step 1550, training loss = 2.892691, validation loss = 3.112296
2018-08-12 00:19:59,719 - INFO - epoch 0, step 1560, training loss = 2.907100, validation loss = 3.151551
2018-08-12 00:20:05,994 - INFO - epoch 0, step 1570, training loss = 2.575575, validation loss = 3.100906
2018-08-12 00:20:12,519 - INFO - epoch 0, step 1580, training loss = 3.055359, validation loss = 3.159556
2018-08-12 00:20:18,909 - INFO - epoch 0, step 1590, training loss = 3.067490, validation loss = 3.133112
2018-08-12 00:20:25,342 - INFO - epoch 0, step 1600, training loss = 3.143032, validation loss = 3.091068
2018-08-12 00:20:31,941 - INFO - epoch 0, step 1610, training loss = 2.894658, validation loss = 3.174194
2018-08-12 00:20:38,352 - INFO - epoch 0, step 1620, training loss = 2.990670, validation loss = 3.108028
2018-08-12 00:20:45,001 - INFO - epoch 0, step 1630, training loss = 3.105352, validation loss = 3.097843
2018-08-12 00:20:51,134 - INFO - epoch 0, step 1640, training loss = 3.742814, validation loss = 3.078770
2018-08-12 00:20:57,117 - INFO - epoch 0, step 1650, training loss = 3.081700, validation loss = 3.114095
2018-08-12 00:21:03,590 - INFO - epoch 0, step 1660, training loss = 3.186794, validation loss = 3.119901
2018-08-12 00:21:09,430 - INFO - epoch 0, step 1670, training loss = 2.499100, validation loss = 3.122468
2018-08-12 00:21:15,269 - INFO - epoch 0, step 1680, training loss = 3.487596, validation loss = 3.140567
2018-08-12 00:21:21,587 - INFO - epoch 0, step 1690, training loss = 2.904621, validation loss = 3.179249
2018-08-12 00:21:27,564 - INFO - epoch 0, step 1700, training loss = 3.553726, validation loss = 3.072797
2018-08-12 00:21:33,922 - INFO - epoch 0, step 1710, training loss = 3.102404, validation loss = 3.084776
2018-08-12 00:21:40,187 - INFO - epoch 0, step 1720, training loss = 2.854218, validation loss = 3.058566
2018-08-12 00:21:46,409 - INFO - epoch 0, step 1730, training loss = 3.650896, validation loss = 3.076174
2018-08-12 00:21:52,828 - INFO - epoch 0, step 1740, training loss = 3.326053, validation loss = 3.058540
2018-08-12 00:21:59,075 - INFO - epoch 0, step 1750, training loss = 2.412822, validation loss = 3.071542
2018-08-12 00:22:04,975 - INFO - epoch 0, step 1760, training loss = 3.187763, validation loss = 3.091157
2018-08-12 00:22:10,715 - INFO - epoch 0, step 1770, training loss = 2.580920, validation loss = 3.114232
2018-08-12 00:22:16,399 - INFO - epoch 0, step 1780, training loss = 2.863220, validation loss = 3.115131
2018-08-12 00:22:22,359 - INFO - epoch 0, step 1790, training loss = 2.915708, validation loss = 3.115157
2018-08-12 00:22:28,383 - INFO - epoch 0, step 1800, training loss = 3.234324, validation loss = 3.111438
2018-08-12 00:22:34,316 - INFO - epoch 0, step 1810, training loss = 2.747717, validation loss = 3.114509
2018-08-12 00:22:40,164 - INFO - epoch 0, step 1820, training loss = 2.964787, validation loss = 3.130526
2018-08-12 00:22:46,467 - INFO - epoch 0, step 1830, training loss = 3.146680, validation loss = 3.144259
2018-08-12 00:22:52,304 - INFO - epoch 0, step 1840, training loss = 3.414797, validation loss = 3.122434
2018-08-12 00:22:58,746 - INFO - epoch 0, step 1850, training loss = 2.891173, validation loss = 3.134547
2018-08-12 00:23:04,489 - INFO - epoch 0, step 1860, training loss = 3.309756, validation loss = 3.120279
2018-08-12 00:23:10,372 - INFO - epoch 0, step 1870, training loss = 2.831845, validation loss = 3.119950
2018-08-12 00:23:15,710 - INFO - epoch 0, step 1880, training loss = 3.078547, validation loss = 3.114480
2018-08-12 00:23:21,132 - INFO - epoch 0, step 1890, training loss = 2.548654, validation loss = 3.107657
2018-08-12 00:23:26,013 - INFO - epoch 0, step 1900, training loss = 2.955894, validation loss = 3.156081
2018-08-12 00:23:31,295 - INFO - epoch 0, step 1910, training loss = 3.119280, validation loss = 3.126865
2018-08-12 00:23:36,432 - INFO - epoch 0, step 1920, training loss = 3.096951, validation loss = 3.132588
2018-08-12 00:23:41,807 - INFO - epoch 0, step 1930, training loss = 3.370430, validation loss = 3.142837
2018-08-12 00:23:47,125 - INFO - epoch 0, step 1940, training loss = 3.439775, validation loss = 3.151098
2018-08-12 00:23:53,442 - INFO - epoch 0, step 1950, training loss = 2.944526, validation loss = 3.102860
2018-08-12 00:23:59,950 - INFO - epoch 0, step 1960, training loss = 3.039664, validation loss = 3.129992
2018-08-12 00:24:06,240 - INFO - epoch 0, step 1970, training loss = 2.953016, validation loss = 3.117957
2018-08-12 00:24:12,383 - INFO - epoch 0, step 1980, training loss = 2.938103, validation loss = 3.091079
2018-08-12 00:24:18,514 - INFO - epoch 0, step 1990, training loss = 3.403556, validation loss = 3.101287
2018-08-12 00:24:24,734 - INFO - epoch 0, step 2000, training loss = 3.046399, validation loss = 3.106780
2018-08-12 00:24:30,822 - INFO - epoch 0, step 2010, training loss = 3.881118, validation loss = 3.069977
2018-08-12 00:24:36,052 - INFO - epoch 0, step 2020, training loss = 3.761855, validation loss = 3.074791
2018-08-12 00:24:41,480 - INFO - epoch 0, step 2030, training loss = 3.720309, validation loss = 3.095943
2018-08-12 00:24:46,675 - INFO - epoch 0, step 2040, training loss = 2.789093, validation loss = 3.101691
2018-08-12 00:24:52,494 - INFO - epoch 0, step 2050, training loss = 2.846219, validation loss = 3.150776
2018-08-12 00:24:58,324 - INFO - epoch 0, step 2060, training loss = 3.040439, validation loss = 3.111803
2018-08-12 00:25:03,938 - INFO - epoch 0, step 2070, training loss = 2.983847, validation loss = 3.088440
2018-08-12 00:25:09,573 - INFO - epoch 0, step 2080, training loss = 2.663510, validation loss = 3.126060
2018-08-12 00:25:15,223 - INFO - epoch 0, step 2090, training loss = 2.715443, validation loss = 3.143237
2018-08-12 00:25:20,555 - INFO - epoch 0, step 2100, training loss = 3.135857, validation loss = 3.126530
2018-08-12 00:25:26,204 - INFO - epoch 0, step 2110, training loss = 3.101204, validation loss = 3.131990
2018-08-12 00:25:32,385 - INFO - epoch 0, step 2120, training loss = 3.033558, validation loss = 3.090799
2018-08-12 00:25:38,546 - INFO - epoch 0, step 2130, training loss = 3.092149, validation loss = 3.065521
2018-08-12 00:25:44,362 - INFO - epoch 0, step 2140, training loss = 2.951746, validation loss = 3.074321
2018-08-12 00:25:50,049 - INFO - epoch 0, step 2150, training loss = 3.226610, validation loss = 3.059692
2018-08-12 00:25:55,754 - INFO - epoch 0, step 2160, training loss = 3.034300, validation loss = 3.050896
2018-08-12 00:26:01,766 - INFO - epoch 0, step 2170, training loss = 3.069259, validation loss = 3.084449
2018-08-12 00:26:07,920 - INFO - epoch 0, step 2180, training loss = 2.791718, validation loss = 3.099400
2018-08-12 00:26:13,692 - INFO - epoch 0, step 2190, training loss = 3.193424, validation loss = 3.094776
2018-08-12 00:26:19,188 - INFO - epoch 0, step 2200, training loss = 3.326825, validation loss = 3.092005
2018-08-12 00:26:24,902 - INFO - epoch 0, step 2210, training loss = 3.006917, validation loss = 3.090382
2018-08-12 00:26:30,688 - INFO - epoch 0, step 2220, training loss = 3.153283, validation loss = 3.095224
2018-08-12 00:26:36,227 - INFO - epoch 0, step 2230, training loss = 2.846854, validation loss = 3.083455
2018-08-12 00:26:41,914 - INFO - epoch 0, step 2240, training loss = 3.521821, validation loss = 3.077443
2018-08-12 00:26:47,425 - INFO - epoch 0, step 2250, training loss = 2.667192, validation loss = 3.090530
2018-08-12 00:26:53,342 - INFO - epoch 0, step 2260, training loss = 3.153592, validation loss = 3.081407
2018-08-12 00:26:59,091 - INFO - epoch 0, step 2270, training loss = 2.940396, validation loss = 3.102631
2018-08-12 00:27:04,923 - INFO - epoch 0, step 2280, training loss = 3.163912, validation loss = 3.065387
2018-08-12 00:27:10,466 - INFO - epoch 0, step 2290, training loss = 3.239698, validation loss = 3.072870
2018-08-12 00:27:15,980 - INFO - epoch 0, step 2300, training loss = 3.357981, validation loss = 3.081649
2018-08-12 00:27:21,636 - INFO - epoch 0, step 2310, training loss = 2.562924, validation loss = 3.093582
2018-08-12 00:27:27,455 - INFO - epoch 0, step 2320, training loss = 3.395370, validation loss = 3.094587
2018-08-12 00:27:33,431 - INFO - epoch 0, step 2330, training loss = 3.081642, validation loss = 3.096879
2018-08-12 00:27:40,164 - INFO - epoch 0, step 2340, training loss = 3.016180, validation loss = 3.041142
2018-08-12 00:27:46,721 - INFO - epoch 0, step 2350, training loss = 3.327554, validation loss = 3.105229
2018-08-12 00:27:53,169 - INFO - epoch 0, step 2360, training loss = 3.208245, validation loss = 3.045722
2018-08-12 00:27:59,577 - INFO - epoch 0, step 2370, training loss = 3.365424, validation loss = 3.053687
2018-08-12 00:28:06,072 - INFO - epoch 0, step 2380, training loss = 2.830376, validation loss = 3.075741
2018-08-12 00:28:12,698 - INFO - epoch 0, step 2390, training loss = 3.060834, validation loss = 3.054081
2018-08-12 00:28:18,694 - INFO - epoch 0, step 2400, training loss = 2.952476, validation loss = 3.016715
2018-08-12 00:28:24,661 - INFO - epoch 0, step 2410, training loss = 2.767919, validation loss = 3.006172
2018-08-12 00:28:30,973 - INFO - epoch 0, step 2420, training loss = 2.576905, validation loss = 3.016094
2018-08-12 00:28:37,131 - INFO - epoch 0, step 2430, training loss = 2.962144, validation loss = 2.995378
2018-08-12 00:28:43,345 - INFO - epoch 0, step 2440, training loss = 3.267376, validation loss = 3.000762
2018-08-12 00:28:48,536 - INFO - epoch 0, step 2450, training loss = 3.724663, validation loss = 3.025979
2018-08-12 00:28:53,710 - INFO - epoch 0, step 2460, training loss = 3.077432, validation loss = 3.074450
2018-08-12 00:28:58,817 - INFO - epoch 0, step 2470, training loss = 3.367293, validation loss = 3.084634
2018-08-12 00:29:04,046 - INFO - epoch 0, step 2480, training loss = 2.815467, validation loss = 3.057045
2018-08-12 00:29:09,479 - INFO - epoch 0, step 2490, training loss = 3.266298, validation loss = 3.080676
2018-08-12 00:29:14,842 - INFO - epoch 0, step 2500, training loss = 2.951236, validation loss = 3.081973
2018-08-12 00:29:22,131 - INFO - epoch 0, step 2510, training loss = 3.072964, validation loss = 3.132298
2018-08-12 00:29:28,732 - INFO - epoch 0, step 2520, training loss = 2.741264, validation loss = 3.018604
2018-08-12 00:29:34,864 - INFO - epoch 0, step 2530, training loss = 3.115781, validation loss = 3.033546
2018-08-12 00:29:41,366 - INFO - epoch 0, step 2540, training loss = 2.883316, validation loss = 3.009698
2018-08-12 00:29:47,513 - INFO - epoch 0, step 2550, training loss = 2.966392, validation loss = 3.007649
2018-08-12 00:29:53,634 - INFO - epoch 0, step 2560, training loss = 3.196931, validation loss = 2.995925
2018-08-12 00:29:59,401 - INFO - epoch 0, step 2570, training loss = 2.984354, validation loss = 2.995278
2018-08-12 00:30:05,129 - INFO - epoch 0, step 2580, training loss = 3.022948, validation loss = 2.992563
2018-08-12 00:30:10,965 - INFO - epoch 0, step 2590, training loss = 3.047025, validation loss = 3.007473
2018-08-12 00:30:16,682 - INFO - epoch 0, step 2600, training loss = 3.055489, validation loss = 2.999386
2018-08-12 00:30:22,969 - INFO - epoch 0, step 2610, training loss = 3.049647, validation loss = 3.010557
2018-08-12 00:30:29,291 - INFO - epoch 0, step 2620, training loss = 3.138260, validation loss = 2.977319
2018-08-12 00:30:35,574 - INFO - epoch 0, step 2630, training loss = 3.412360, validation loss = 3.016833
2018-08-12 00:30:41,909 - INFO - epoch 0, step 2640, training loss = 2.766113, validation loss = 2.999722
2018-08-12 00:30:48,102 - INFO - epoch 0, step 2650, training loss = 3.284679, validation loss = 3.000898
2018-08-12 00:30:54,367 - INFO - epoch 0, step 2660, training loss = 2.943628, validation loss = 3.001074
2018-08-12 00:31:00,287 - INFO - epoch 0, step 2670, training loss = 2.733651, validation loss = 3.002075
2018-08-12 00:31:06,356 - INFO - epoch 0, step 2680, training loss = 3.072411, validation loss = 3.039815
2018-08-12 00:31:12,511 - INFO - epoch 0, step 2690, training loss = 3.115217, validation loss = 3.044106
2018-08-12 00:31:18,609 - INFO - epoch 0, step 2700, training loss = 2.685806, validation loss = 3.041780
2018-08-12 00:31:24,606 - INFO - epoch 0, step 2710, training loss = 3.106309, validation loss = 3.040862
2018-08-12 00:31:30,566 - INFO - epoch 0, step 2720, training loss = 2.820574, validation loss = 3.037026
2018-08-12 00:31:36,287 - INFO - epoch 0, step 2730, training loss = 3.029861, validation loss = 3.039517
2018-08-12 00:31:42,324 - INFO - epoch 0, step 2740, training loss = 2.977499, validation loss = 3.041192
2018-08-12 00:31:48,069 - INFO - epoch 0, step 2750, training loss = 3.088490, validation loss = 3.034042
2018-08-12 00:31:54,009 - INFO - epoch 0, step 2760, training loss = 3.107755, validation loss = 3.028568
2018-08-12 00:32:00,019 - INFO - epoch 0, step 2770, training loss = 2.701155, validation loss = 3.018012
2018-08-12 00:32:06,193 - INFO - epoch 0, step 2780, training loss = 3.270574, validation loss = 2.977079
2018-08-12 00:32:12,250 - INFO - epoch 0, step 2790, training loss = 2.874003, validation loss = 2.978306
2018-08-12 00:32:18,396 - INFO - epoch 0, step 2800, training loss = 2.732327, validation loss = 2.976208
2018-08-12 00:32:24,640 - INFO - epoch 0, step 2810, training loss = 2.698498, validation loss = 2.967400
2018-08-12 00:32:31,140 - INFO - epoch 0, step 2820, training loss = 2.994937, validation loss = 3.037883
2018-08-12 00:32:37,604 - INFO - epoch 0, step 2830, training loss = 3.218053, validation loss = 3.008986
2018-08-12 00:32:43,998 - INFO - epoch 0, step 2840, training loss = 3.008116, validation loss = 2.987209
2018-08-12 00:32:50,457 - INFO - epoch 0, step 2850, training loss = 3.423424, validation loss = 3.032058
2018-08-12 00:32:56,809 - INFO - epoch 0, step 2860, training loss = 3.262666, validation loss = 2.982665
2018-08-12 00:33:03,317 - INFO - epoch 0, step 2870, training loss = 3.159983, validation loss = 3.011466
2018-08-12 00:33:10,056 - INFO - epoch 0, step 2880, training loss = 3.312666, validation loss = 3.017892
2018-08-12 00:33:16,625 - INFO - epoch 0, step 2890, training loss = 2.903402, validation loss = 2.997262
2018-08-12 00:33:23,107 - INFO - epoch 0, step 2900, training loss = 2.875244, validation loss = 3.008495
2018-08-12 00:33:29,988 - INFO - epoch 0, step 2910, training loss = 2.182358, validation loss = 3.007430
2018-08-12 00:33:36,658 - INFO - epoch 0, step 2920, training loss = 3.241372, validation loss = 3.025018
2018-08-12 00:33:41,792 - INFO - epoch 0, step 2930, training loss = 3.633472, validation loss = 3.040961
2018-08-12 00:33:47,039 - INFO - epoch 0, step 2940, training loss = 3.462415, validation loss = 3.007746
2018-08-12 00:33:52,055 - INFO - epoch 0, step 2950, training loss = 3.357695, validation loss = 3.053073
2018-08-12 00:33:57,197 - INFO - epoch 0, step 2960, training loss = 3.275966, validation loss = 3.054438
2018-08-12 00:34:02,448 - INFO - epoch 0, step 2970, training loss = 2.559498, validation loss = 3.073889
2018-08-12 00:34:07,503 - INFO - epoch 0, step 2980, training loss = 2.999929, validation loss = 3.095737
2018-08-12 00:34:13,945 - INFO - epoch 0, step 2990, training loss = 2.866207, validation loss = 3.129257
2018-08-12 00:34:20,574 - INFO - epoch 0, step 3000, training loss = 2.920835, validation loss = 3.004631
2018-08-12 00:34:26,916 - INFO - epoch 0, step 3010, training loss = 2.910274, validation loss = 3.056382
2018-08-12 00:34:33,338 - INFO - epoch 0, step 3020, training loss = 3.062524, validation loss = 3.009029
2018-08-12 00:34:39,915 - INFO - epoch 0, step 3030, training loss = 3.472203, validation loss = 3.086520
2018-08-12 00:34:46,428 - INFO - epoch 0, step 3040, training loss = 2.780856, validation loss = 3.003329
2018-08-12 00:34:52,787 - INFO - epoch 0, step 3050, training loss = 2.774779, validation loss = 3.054115
2018-08-12 00:35:00,609 - INFO - epoch 0, step 3060, training loss = 3.072247, validation loss = 2.991683
2018-08-12 00:35:06,873 - INFO - epoch 0, step 3070, training loss = 3.346452, validation loss = 3.053585
2018-08-12 00:35:13,265 - INFO - epoch 0, step 3080, training loss = 2.750292, validation loss = 2.992568
2018-08-12 00:35:19,773 - INFO - epoch 0, step 3090, training loss = 2.735976, validation loss = 3.025562
2018-08-12 00:35:26,356 - INFO - epoch 0, step 3100, training loss = 3.312373, validation loss = 3.014683
2018-08-12 00:35:33,227 - INFO - epoch 0, step 3110, training loss = 2.752772, validation loss = 3.049021
2018-08-12 00:35:39,602 - INFO - epoch 0, step 3120, training loss = 2.898363, validation loss = 3.013228
2018-08-12 00:35:45,997 - INFO - epoch 0, step 3130, training loss = 3.398893, validation loss = 3.020621
2018-08-12 00:35:52,385 - INFO - epoch 0, step 3140, training loss = 3.251338, validation loss = 3.033245
2018-08-12 00:35:58,354 - INFO - epoch 0, step 3150, training loss = 3.203457, validation loss = 3.024335
2018-08-12 00:36:04,457 - INFO - epoch 0, step 3160, training loss = 3.269254, validation loss = 3.055865
2018-08-12 00:36:10,613 - INFO - epoch 0, step 3170, training loss = 3.106880, validation loss = 3.064566
2018-08-12 00:36:16,406 - INFO - epoch 0, step 3180, training loss = 3.069425, validation loss = 3.055946
2018-08-12 00:36:22,133 - INFO - epoch 0, step 3190, training loss = 3.055026, validation loss = 3.041378
2018-08-12 00:36:28,045 - INFO - epoch 0, step 3200, training loss = 3.113149, validation loss = 3.043303
2018-08-12 00:36:34,018 - INFO - epoch 0, step 3210, training loss = 2.920542, validation loss = 3.061685
2018-08-12 00:36:39,867 - INFO - epoch 0, step 3220, training loss = 3.333313, validation loss = 3.074339
2018-08-12 00:36:45,602 - INFO - epoch 0, step 3230, training loss = 3.144394, validation loss = 3.080728
2018-08-12 00:36:51,203 - INFO - epoch 0, step 3240, training loss = 2.918960, validation loss = 3.075410
2018-08-12 00:36:56,993 - INFO - epoch 0, step 3250, training loss = 2.717846, validation loss = 3.079419
2018-08-12 00:37:02,504 - INFO - epoch 0, step 3260, training loss = 2.856180, validation loss = 3.103465
2018-08-12 00:37:07,810 - INFO - epoch 0, step 3270, training loss = 2.977563, validation loss = 3.076366
2018-08-12 00:37:13,153 - INFO - epoch 0, step 3280, training loss = 3.101552, validation loss = 3.081867
2018-08-12 00:37:18,303 - INFO - epoch 0, step 3290, training loss = 3.045033, validation loss = 3.074582
2018-08-12 00:37:23,423 - INFO - epoch 0, step 3300, training loss = 3.252845, validation loss = 3.095678
2018-08-12 00:37:28,756 - INFO - epoch 0, step 3310, training loss = 2.698725, validation loss = 3.074381
2018-08-12 00:37:34,169 - INFO - epoch 0, step 3320, training loss = 2.985924, validation loss = 3.071712
2018-08-12 00:37:39,776 - INFO - epoch 0, step 3330, training loss = 2.963980, validation loss = 3.067833
2018-08-12 00:37:44,314 - INFO - epoch 0, step 3340, training loss = 2.971893, validation loss = 3.079163
2018-08-12 00:37:49,149 - INFO - epoch 0, step 3350, training loss = 2.833291, validation loss = 3.089429
2018-08-12 00:37:53,574 - INFO - epoch 0, step 3360, training loss = 3.108918, validation loss = 3.083644
2018-08-12 00:37:58,053 - INFO - epoch 0, step 3370, training loss = 2.857643, validation loss = 3.038226
2018-08-12 00:38:02,595 - INFO - epoch 0, step 3380, training loss = 3.316675, validation loss = 3.021117
2018-08-12 00:38:06,908 - INFO - epoch 0, step 3390, training loss = 2.792280, validation loss = 3.078033
2018-08-12 00:38:11,098 - INFO - epoch 0, step 3400, training loss = 3.092823, validation loss = 3.017841
2018-08-12 00:38:15,351 - INFO - epoch 0, step 3410, training loss = 2.547525, validation loss = 3.056118
2018-08-12 00:38:19,867 - INFO - epoch 0, step 3420, training loss = 2.677292, validation loss = 3.037920
2018-08-12 00:38:24,864 - INFO - epoch 0, step 3430, training loss = 3.066046, validation loss = 3.065152
2018-08-12 00:38:30,528 - INFO - epoch 0, step 3440, training loss = 2.743831, validation loss = 3.058795
2018-08-12 00:38:35,950 - INFO - epoch 0, step 3450, training loss = 2.565546, validation loss = 3.049861
2018-08-12 00:38:42,104 - INFO - epoch 0, step 3460, training loss = 3.456939, validation loss = 3.008657
2018-08-12 00:38:48,121 - INFO - epoch 0, step 3470, training loss = 3.412434, validation loss = 3.008396
2018-08-12 00:38:54,376 - INFO - epoch 0, step 3480, training loss = 2.762829, validation loss = 2.997981
2018-08-12 00:39:00,925 - INFO - epoch 0, step 3490, training loss = 2.983516, validation loss = 2.985268
2018-08-12 00:39:07,432 - INFO - epoch 0, step 3500, training loss = 3.267615, validation loss = 2.996955
2018-08-12 00:39:14,134 - INFO - epoch 0, step 3510, training loss = 2.679303, validation loss = 2.957007
2018-08-12 00:39:20,586 - INFO - epoch 0, step 3520, training loss = 2.724267, validation loss = 2.999777
2018-08-12 00:39:27,104 - INFO - epoch 0, step 3530, training loss = 3.452644, validation loss = 2.992666
2018-08-12 00:39:33,368 - INFO - epoch 0, step 3540, training loss = 3.033949, validation loss = 3.017748
2018-08-12 00:39:39,907 - INFO - epoch 0, step 3550, training loss = 2.837804, validation loss = 3.002270
2018-08-12 00:39:46,343 - INFO - epoch 0, step 3560, training loss = 3.128246, validation loss = 2.981146
2018-08-12 00:39:53,161 - INFO - epoch 0, step 3570, training loss = 2.958787, validation loss = 2.997053
2018-08-12 00:39:59,470 - INFO - epoch 0, step 3580, training loss = 3.294775, validation loss = 2.991912
2018-08-12 00:40:05,640 - INFO - epoch 0, step 3590, training loss = 2.891330, validation loss = 2.991560
2018-08-12 00:40:12,207 - INFO - epoch 0, step 3600, training loss = 2.780069, validation loss = 3.013335
2018-08-12 00:40:19,452 - INFO - epoch 0, step 3610, training loss = 2.962979, validation loss = 2.977779
2018-08-12 00:40:24,971 - INFO - epoch 0, step 3620, training loss = 2.979870, validation loss = 3.093694
2018-08-12 00:40:30,636 - INFO - epoch 0, step 3630, training loss = 3.039160, validation loss = 3.044969
2018-08-12 00:40:36,379 - INFO - epoch 0, step 3640, training loss = 3.400639, validation loss = 3.063713
2018-08-12 00:40:42,516 - INFO - epoch 0, step 3650, training loss = 2.612960, validation loss = 3.059051
2018-08-12 00:40:48,436 - INFO - epoch 0, step 3660, training loss = 3.102305, validation loss = 3.068505
2018-08-12 00:40:54,178 - INFO - epoch 0, step 3670, training loss = 2.863480, validation loss = 3.046665
2018-08-12 00:41:00,073 - INFO - epoch 0, step 3680, training loss = 3.121171, validation loss = 3.050359
2018-08-12 00:41:05,620 - INFO - epoch 0, step 3690, training loss = 3.057676, validation loss = 3.057974
2018-08-12 00:41:11,518 - INFO - epoch 0, step 3700, training loss = 2.804344, validation loss = 3.059090
2018-08-12 00:41:17,141 - INFO - epoch 0, step 3710, training loss = 3.363042, validation loss = 3.085149
2018-08-12 00:41:22,149 - INFO - epoch 0, step 3720, training loss = 2.855151, validation loss = 3.025310
2018-08-12 00:41:27,254 - INFO - epoch 0, step 3730, training loss = 2.656049, validation loss = 3.140335
2018-08-12 00:41:32,365 - INFO - epoch 0, step 3740, training loss = 3.286428, validation loss = 3.051709
2018-08-12 00:41:37,486 - INFO - epoch 0, step 3750, training loss = 2.690196, validation loss = 3.089471
2018-08-12 00:41:42,786 - INFO - epoch 0, step 3760, training loss = 2.441043, validation loss = 3.063882
2018-08-12 00:41:48,046 - INFO - epoch 0, step 3770, training loss = 3.422238, validation loss = 3.100606
2018-08-12 00:41:53,554 - INFO - epoch 0, step 3780, training loss = 2.685951, validation loss = 3.054787
2018-08-12 00:41:58,928 - INFO - epoch 0, step 3790, training loss = 2.990941, validation loss = 3.020873
2018-08-12 00:42:04,573 - INFO - epoch 0, step 3800, training loss = 3.346037, validation loss = 3.016260
2018-08-12 00:42:10,139 - INFO - epoch 0, step 3810, training loss = 3.188931, validation loss = 3.012782
2018-08-12 00:42:15,948 - INFO - epoch 0, step 3820, training loss = 2.792161, validation loss = 3.028823
2018-08-12 00:42:21,581 - INFO - epoch 0, step 3830, training loss = 3.035026, validation loss = 3.013274
2018-08-12 00:42:27,333 - INFO - epoch 0, step 3840, training loss = 2.859016, validation loss = 3.012415
2018-08-12 00:42:33,059 - INFO - epoch 0, step 3850, training loss = 2.836451, validation loss = 2.999361
2018-08-12 00:42:39,061 - INFO - epoch 0, step 3860, training loss = 2.806608, validation loss = 2.992864
2018-08-12 00:42:44,700 - INFO - epoch 0, step 3870, training loss = 3.230748, validation loss = 3.010606
2018-08-12 00:42:50,478 - INFO - epoch 0, step 3880, training loss = 3.231628, validation loss = 3.020948
2018-08-12 00:42:56,281 - INFO - epoch 0, step 3890, training loss = 2.826933, validation loss = 3.058418
2018-08-12 00:43:02,254 - INFO - epoch 0, step 3900, training loss = 3.498876, validation loss = 3.056303
2018-08-12 00:43:08,458 - INFO - epoch 0, step 3910, training loss = 2.970595, validation loss = 3.058164
2018-08-12 00:43:14,493 - INFO - epoch 0, step 3920, training loss = 3.169261, validation loss = 3.059535
2018-08-12 00:43:20,602 - INFO - epoch 0, step 3930, training loss = 2.988169, validation loss = 3.054146
2018-08-12 00:43:26,733 - INFO - epoch 0, step 3940, training loss = 2.548476, validation loss = 3.082838
2018-08-12 00:43:32,864 - INFO - epoch 0, step 3950, training loss = 3.065692, validation loss = 2.998522
2018-08-12 00:43:39,261 - INFO - epoch 0, step 3960, training loss = 2.831853, validation loss = 3.023238
2018-08-12 00:43:45,114 - INFO - epoch 0, step 3970, training loss = 2.800035, validation loss = 2.999900
2018-08-12 00:43:51,413 - INFO - epoch 0, step 3980, training loss = 2.617273, validation loss = 3.014204
2018-08-12 00:43:57,751 - INFO - epoch 0, step 3990, training loss = 2.893614, validation loss = 2.980895
2018-08-12 00:44:03,968 - INFO - epoch 0, step 4000, training loss = 3.136656, validation loss = 2.954385
2018-08-12 00:44:10,372 - INFO - epoch 0, step 4010, training loss = 2.657712, validation loss = 3.009292
2018-08-12 00:44:16,946 - INFO - epoch 0, step 4020, training loss = 2.968318, validation loss = 2.969599
2018-08-12 00:44:23,459 - INFO - epoch 0, step 4030, training loss = 3.163558, validation loss = 2.952334
2018-08-12 00:44:29,885 - INFO - epoch 0, step 4040, training loss = 2.942293, validation loss = 2.941616
2018-08-12 00:44:36,150 - INFO - epoch 0, step 4050, training loss = 2.975631, validation loss = 2.958768
2018-08-12 00:44:42,805 - INFO - epoch 0, step 4060, training loss = 3.333526, validation loss = 3.041590
2018-08-12 00:44:49,502 - INFO - epoch 0, step 4070, training loss = 2.889692, validation loss = 2.950200
2018-08-12 00:44:56,142 - INFO - epoch 0, step 4080, training loss = 2.943749, validation loss = 3.007942
2018-08-12 00:45:02,771 - INFO - epoch 0, step 4090, training loss = 2.956889, validation loss = 3.017446
2018-08-12 00:45:09,398 - INFO - epoch 0, step 4100, training loss = 3.054958, validation loss = 2.995295
2018-08-12 00:45:15,748 - INFO - epoch 0, step 4110, training loss = 2.920440, validation loss = 3.027809
2018-08-12 00:45:22,029 - INFO - epoch 0, step 4120, training loss = 2.874960, validation loss = 2.980469
2018-08-12 00:45:27,982 - INFO - epoch 0, step 4130, training loss = 2.901560, validation loss = 2.968044
2018-08-12 00:45:33,924 - INFO - epoch 0, step 4140, training loss = 3.071204, validation loss = 3.004086
2018-08-12 00:45:39,507 - INFO - epoch 0, step 4150, training loss = 3.131947, validation loss = 3.044272
2018-08-12 00:45:44,679 - INFO - epoch 0, step 4160, training loss = 3.342714, validation loss = 3.050504
2018-08-12 00:45:50,062 - INFO - epoch 0, step 4170, training loss = 2.732528, validation loss = 3.030304
2018-08-12 00:45:55,216 - INFO - epoch 0, step 4180, training loss = 2.865028, validation loss = 3.055490
2018-08-12 00:46:00,336 - INFO - epoch 0, step 4190, training loss = 3.514487, validation loss = 3.068254
2018-08-12 00:46:05,764 - INFO - epoch 0, step 4200, training loss = 2.868314, validation loss = 3.067200
2018-08-12 00:46:11,452 - INFO - epoch 0, step 4210, training loss = 3.375601, validation loss = 3.033545
2018-08-12 00:46:18,446 - INFO - epoch 0, step 4220, training loss = 2.032077, validation loss = 3.026154
2018-08-12 00:46:24,960 - INFO - epoch 0, step 4230, training loss = 3.007363, validation loss = 3.014787
2018-08-12 00:46:31,230 - INFO - epoch 0, step 4240, training loss = 2.960389, validation loss = 3.045834
2018-08-12 00:46:37,404 - INFO - epoch 0, step 4250, training loss = 2.933072, validation loss = 2.998132
2018-08-12 00:46:43,663 - INFO - epoch 0, step 4260, training loss = 3.069556, validation loss = 3.009784
2018-08-12 00:46:48,562 - INFO - epoch 0, step 4270, training loss = 3.151632, validation loss = 3.061745
2018-08-12 00:46:54,105 - INFO - epoch 0, step 4280, training loss = 3.215371, validation loss = 3.039660
2018-08-12 00:46:59,592 - INFO - epoch 0, step 4290, training loss = 2.784369, validation loss = 3.061738
2018-08-12 00:47:04,974 - INFO - epoch 0, step 4300, training loss = 2.758864, validation loss = 3.069034
2018-08-12 00:47:10,359 - INFO - epoch 0, step 4310, training loss = 2.644547, validation loss = 3.066261
2018-08-12 00:47:15,638 - INFO - epoch 0, step 4320, training loss = 2.692456, validation loss = 3.052002
2018-08-12 00:47:20,835 - INFO - epoch 0, step 4330, training loss = 3.260295, validation loss = 3.059147
2018-08-12 00:47:26,675 - INFO - epoch 0, step 4340, training loss = 3.205334, validation loss = 3.026676
2018-08-12 00:47:32,441 - INFO - epoch 0, step 4350, training loss = 3.025612, validation loss = 3.045440
2018-08-12 00:47:38,532 - INFO - epoch 0, step 4360, training loss = 3.048915, validation loss = 3.081006
2018-08-12 00:47:44,092 - INFO - epoch 0, step 4370, training loss = 2.967855, validation loss = 3.065484
2018-08-12 00:47:51,449 - INFO - epoch 0, step 4380, training loss = 3.341814, validation loss = 3.065773
2018-08-12 00:47:56,736 - INFO - epoch 0, step 4390, training loss = 3.132237, validation loss = 3.026821
2018-08-12 00:48:01,862 - INFO - epoch 0, step 4400, training loss = 2.842591, validation loss = 3.095056
2018-08-12 00:48:07,240 - INFO - epoch 0, step 4410, training loss = 3.086568, validation loss = 3.091208
2018-08-12 00:48:12,437 - INFO - epoch 0, step 4420, training loss = 2.911332, validation loss = 3.067520
2018-08-12 00:48:17,787 - INFO - epoch 0, step 4430, training loss = 3.178212, validation loss = 3.106731
2018-08-12 00:48:23,212 - INFO - epoch 0, step 4440, training loss = 2.916662, validation loss = 3.057321
2018-08-12 00:48:29,354 - INFO - epoch 0, step 4450, training loss = 2.492722, validation loss = 3.067147
2018-08-12 00:48:35,174 - INFO - epoch 0, step 4460, training loss = 3.296946, validation loss = 3.077383
2018-08-12 00:48:40,654 - INFO - epoch 0, step 4470, training loss = 3.383990, validation loss = 3.093676
2018-08-12 00:48:46,305 - INFO - epoch 0, step 4480, training loss = 3.189001, validation loss = 3.109668
2018-08-12 00:48:51,462 - INFO - epoch 0, step 4490, training loss = 3.310136, validation loss = 3.070824
2018-08-12 00:48:56,787 - INFO - epoch 0, step 4500, training loss = 3.087133, validation loss = 3.081628
2018-08-12 00:49:02,015 - INFO - epoch 0, step 4510, training loss = 3.324914, validation loss = 3.083275
2018-08-12 00:49:07,420 - INFO - epoch 0, step 4520, training loss = 2.889353, validation loss = 3.098250
2018-08-12 00:49:12,744 - INFO - epoch 0, step 4530, training loss = 3.142825, validation loss = 3.118455
2018-08-12 00:49:18,043 - INFO - epoch 0, step 4540, training loss = 3.213629, validation loss = 3.078702
2018-08-12 00:49:24,500 - INFO - epoch 0, step 4550, training loss = 2.875143, validation loss = 3.097743
2018-08-12 00:49:31,317 - INFO - epoch 0, step 4560, training loss = 2.885162, validation loss = 3.029791
2018-08-12 00:49:36,863 - INFO - epoch 0, step 4570, training loss = 2.774209, validation loss = 3.102478
2018-08-12 00:49:42,221 - INFO - epoch 0, step 4580, training loss = 3.214223, validation loss = 3.069747
2018-08-12 00:49:47,150 - INFO - epoch 0, step 4590, training loss = 3.063973, validation loss = 3.099837
2018-08-12 00:49:52,427 - INFO - epoch 0, step 4600, training loss = 2.742459, validation loss = 3.088554
2018-08-12 00:49:57,806 - INFO - epoch 0, step 4610, training loss = 2.777685, validation loss = 3.098437
2018-08-12 00:50:03,096 - INFO - epoch 0, step 4620, training loss = 3.316550, validation loss = 3.093087
2018-08-12 00:50:08,495 - INFO - epoch 0, step 4630, training loss = 3.173687, validation loss = 3.090138
2018-08-12 00:50:14,300 - INFO - epoch 0, step 4640, training loss = 2.577888, validation loss = 3.055661
2018-08-12 00:50:19,818 - INFO - epoch 0, step 4650, training loss = 2.698519, validation loss = 3.049569
2018-08-12 00:50:25,177 - INFO - epoch 0, step 4660, training loss = 2.915790, validation loss = 3.068444
2018-08-12 00:50:31,023 - INFO - epoch 0, step 4670, training loss = 3.124892, validation loss = 3.050548
2018-08-12 00:50:36,886 - INFO - epoch 0, step 4680, training loss = 2.659068, validation loss = 3.050668
2018-08-12 00:50:42,972 - INFO - epoch 0, step 4690, training loss = 3.354340, validation loss = 3.046585
2018-08-12 00:50:49,377 - INFO - epoch 0, step 4700, training loss = 2.989360, validation loss = 3.004899
2018-08-12 00:50:55,662 - INFO - epoch 0, step 4710, training loss = 3.065098, validation loss = 2.999490
2018-08-12 00:51:02,151 - INFO - epoch 0, step 4720, training loss = 3.464138, validation loss = 3.012309
2018-08-12 00:51:08,198 - INFO - epoch 0, step 4730, training loss = 3.365873, validation loss = 2.979048
2018-08-12 00:51:14,061 - INFO - epoch 0, step 4740, training loss = 3.637280, validation loss = 2.978196
2018-08-12 00:51:19,450 - INFO - epoch 0, step 4750, training loss = 2.408041, validation loss = 3.023250
2018-08-12 00:51:24,726 - INFO - epoch 0, step 4760, training loss = 3.329942, validation loss = 3.030261
2018-08-12 00:51:29,874 - INFO - epoch 0, step 4770, training loss = 3.392318, validation loss = 3.045247
2018-08-12 00:51:35,189 - INFO - epoch 0, step 4780, training loss = 2.708038, validation loss = 3.074023
2018-08-12 00:51:40,329 - INFO - epoch 0, step 4790, training loss = 2.913437, validation loss = 3.057830
2018-08-12 00:51:45,762 - INFO - epoch 0, step 4800, training loss = 2.920215, validation loss = 3.065032
2018-08-12 00:51:51,376 - INFO - epoch 0, step 4810, training loss = 2.931154, validation loss = 3.047733
2018-08-12 00:51:57,009 - INFO - epoch 0, step 4820, training loss = 2.703784, validation loss = 3.044394
2018-08-12 00:52:02,760 - INFO - epoch 0, step 4830, training loss = 3.681407, validation loss = 3.035763
2018-08-12 00:52:08,448 - INFO - epoch 0, step 4840, training loss = 3.446784, validation loss = 3.043575
2018-08-12 00:52:14,168 - INFO - epoch 0, step 4850, training loss = 3.338527, validation loss = 3.033467
2018-08-12 00:52:20,894 - INFO - epoch 0, step 4860, training loss = 3.058216, validation loss = 3.027358
2018-08-12 00:52:27,557 - INFO - epoch 0, step 4870, training loss = 3.225676, validation loss = 3.006996
2018-08-12 00:52:33,971 - INFO - epoch 0, step 4880, training loss = 3.358060, validation loss = 2.992204
2018-08-12 00:52:41,176 - INFO - epoch 0, step 4890, training loss = 1.998608, validation loss = 3.026591
2018-08-12 00:52:47,925 - INFO - epoch 0, step 4900, training loss = 2.683733, validation loss = 2.980726
2018-08-12 00:52:54,397 - INFO - epoch 0, step 4910, training loss = 3.372488, validation loss = 3.058879
2018-08-12 00:53:00,566 - INFO - epoch 0, step 4920, training loss = 3.470324, validation loss = 2.982615
2018-08-12 00:53:06,716 - INFO - epoch 0, step 4930, training loss = 2.799160, validation loss = 3.010344
2018-08-12 00:53:12,098 - INFO - epoch 0, step 4940, training loss = 3.280370, validation loss = 3.016882
2018-08-12 00:53:17,666 - INFO - epoch 0, step 4950, training loss = 2.913614, validation loss = 3.022975
2018-08-12 00:53:23,132 - INFO - epoch 0, step 4960, training loss = 3.146521, validation loss = 3.025750
2018-08-12 00:53:28,883 - INFO - epoch 0, step 4970, training loss = 3.395997, validation loss = 3.017114
2018-08-12 00:53:34,293 - INFO - epoch 0, step 4980, training loss = 3.684042, validation loss = 3.025969
2018-08-12 00:53:40,140 - INFO - epoch 0, step 4990, training loss = 3.199904, validation loss = 3.018375
2018-08-12 00:53:46,051 - INFO - epoch 0, step 5000, training loss = 3.208054, validation loss = 3.022307
2018-08-12 00:53:51,953 - INFO - epoch 0, step 5010, training loss = 2.827953, validation loss = 3.019715
2018-08-12 00:53:57,401 - INFO - epoch 0, step 5020, training loss = 3.640999, validation loss = 3.035398
2018-08-12 00:54:02,816 - INFO - epoch 0, step 5030, training loss = 3.540507, validation loss = 3.033630
2018-08-12 00:54:08,026 - INFO - epoch 0, step 5040, training loss = 3.746836, validation loss = 3.044228
2018-08-12 00:54:13,382 - INFO - epoch 0, step 5050, training loss = 3.618461, validation loss = 3.034527
2018-08-12 00:54:18,576 - INFO - epoch 0, step 5060, training loss = 3.313316, validation loss = 3.042694
2018-08-12 00:54:23,656 - INFO - epoch 0, step 5070, training loss = 3.298603, validation loss = 3.044517
2018-08-12 00:54:29,104 - INFO - epoch 0, step 5080, training loss = 3.618795, validation loss = 3.022601
2018-08-12 00:54:34,895 - INFO - epoch 0, step 5090, training loss = 3.355162, validation loss = 2.977161
2018-08-12 00:54:40,764 - INFO - epoch 0, step 5100, training loss = 3.412594, validation loss = 2.954072
2018-08-12 00:54:46,617 - INFO - epoch 0, step 5110, training loss = 3.763412, validation loss = 2.967067
2018-08-12 00:54:52,293 - INFO - epoch 0, step 5120, training loss = 3.343794, validation loss = 3.005975
2018-08-12 00:54:57,577 - INFO - epoch 0, step 5130, training loss = 3.677328, validation loss = 2.994885
2018-08-12 00:55:03,053 - INFO - epoch 0, step 5140, training loss = 3.592584, validation loss = 3.032126
2018-08-12 00:55:08,281 - INFO - epoch 0, step 5150, training loss = 3.517650, validation loss = 3.028073
2018-08-12 00:55:13,692 - INFO - epoch 0, step 5160, training loss = 3.226295, validation loss = 3.015620
2018-08-12 00:55:19,568 - INFO - epoch 0, step 5170, training loss = 3.676443, validation loss = 3.015093
2018-08-12 00:55:26,156 - INFO - epoch 0, step 5180, training loss = 2.940187, validation loss = 2.995001
2018-08-12 00:55:32,840 - INFO - epoch 0, step 5190, training loss = 3.617054, validation loss = 3.008832
2018-08-12 00:55:39,200 - INFO - epoch 0, step 5200, training loss = 3.523492, validation loss = 2.989565
2018-08-12 00:55:47,877 - INFO - epoch 0, step 5210, training loss = 3.396160, validation loss = 3.018966
2018-08-12 00:55:54,254 - INFO - epoch 0, step 5220, training loss = 3.059350, validation loss = 2.958632
2018-08-12 00:56:01,024 - INFO - epoch 0, step 5230, training loss = 3.076675, validation loss = 2.971429
2018-08-12 00:56:07,399 - INFO - epoch 0, step 5240, training loss = 3.528977, validation loss = 2.990154
2018-08-12 00:56:14,052 - INFO - epoch 0, step 5250, training loss = 2.868991, validation loss = 2.985759
2018-08-12 00:56:20,007 - INFO - epoch 0, step 5260, training loss = 3.505440, validation loss = 2.978939
2018-08-12 00:56:25,617 - INFO - epoch 0, step 5270, training loss = 2.928854, validation loss = 2.953447
2018-08-12 00:56:31,158 - INFO - epoch 0, step 5280, training loss = 3.305666, validation loss = 2.968480
2018-08-12 00:56:36,904 - INFO - epoch 0, step 5290, training loss = 3.030612, validation loss = 2.944131
2018-08-12 00:56:42,348 - INFO - epoch 0, step 5300, training loss = 3.025362, validation loss = 2.951847
2018-08-12 00:56:47,668 - INFO - epoch 0, step 5310, training loss = 2.981956, validation loss = 2.930172
2018-08-12 00:56:53,077 - INFO - epoch 0, step 5320, training loss = 3.475216, validation loss = 2.955616
2018-08-12 00:56:58,441 - INFO - epoch 0, step 5330, training loss = 2.918068, validation loss = 2.988821
2018-08-12 00:57:03,016 - INFO - epoch 0, step 5340, training loss = 2.923089, validation loss = 3.007850
2018-08-12 00:57:07,388 - INFO - epoch 0, step 5350, training loss = 4.132357, validation loss = 3.019432
2018-08-12 00:57:11,787 - INFO - epoch 0, step 5360, training loss = 3.247274, validation loss = 3.019634
2018-08-12 00:57:16,353 - INFO - epoch 0, step 5370, training loss = 2.748603, validation loss = 3.056012
2018-08-12 00:57:20,725 - INFO - epoch 0, step 5380, training loss = 3.444448, validation loss = 3.006121
2018-08-12 00:57:25,391 - INFO - epoch 0, step 5390, training loss = 3.020865, validation loss = 2.958748
2018-08-12 00:57:29,914 - INFO - epoch 0, step 5400, training loss = 2.676634, validation loss = 2.939788
2018-08-12 00:57:34,510 - INFO - epoch 0, step 5410, training loss = 3.348002, validation loss = 2.938460
2018-08-12 00:57:39,052 - INFO - epoch 0, step 5420, training loss = 3.298158, validation loss = 2.954502
2018-08-12 00:57:45,939 - INFO - epoch 0, step 5430, training loss = 3.239052, validation loss = 3.009815
2018-08-12 00:57:51,997 - INFO - epoch 0, step 5440, training loss = 3.098173, validation loss = 2.988170
2018-08-12 00:57:57,890 - INFO - epoch 0, step 5450, training loss = 2.817451, validation loss = 3.039843
2018-08-12 00:58:03,662 - INFO - epoch 0, step 5460, training loss = 2.778274, validation loss = 2.991448
2018-08-12 00:58:09,089 - INFO - epoch 0, step 5470, training loss = 3.462689, validation loss = 2.991786
2018-08-12 00:58:14,936 - INFO - epoch 0, step 5480, training loss = 2.873285, validation loss = 3.029049
2018-08-12 00:58:20,693 - INFO - epoch 0, step 5490, training loss = 3.392198, validation loss = 3.023774
2018-08-12 00:58:26,311 - INFO - epoch 0, step 5500, training loss = 3.381946, validation loss = 3.015414
2018-08-12 00:58:31,632 - INFO - epoch 0, step 5510, training loss = 3.863564, validation loss = 3.051789
2018-08-12 00:58:37,887 - INFO - epoch 0, step 5520, training loss = 3.160298, validation loss = 3.008874
2018-08-12 00:58:44,030 - INFO - epoch 0, step 5530, training loss = 3.383094, validation loss = 2.975711
2018-08-12 00:58:48,596 - INFO - epoch 0, step 5540, training loss = 3.061781, validation loss = 2.950027
2018-08-12 00:58:53,314 - INFO - epoch 0, step 5550, training loss = 3.313140, validation loss = 2.950032
2018-08-12 00:58:58,004 - INFO - epoch 0, step 5560, training loss = 3.313445, validation loss = 2.940782
2018-08-12 00:59:02,094 - INFO - epoch 0, step 5570, training loss = 2.989579, validation loss = 2.958573
2018-08-12 00:59:06,291 - INFO - epoch 0, step 5580, training loss = 2.767097, validation loss = 2.962185
2018-08-12 00:59:10,708 - INFO - epoch 0, step 5590, training loss = 3.024626, validation loss = 2.971512
2018-08-12 00:59:15,008 - INFO - epoch 0, step 5600, training loss = 3.394006, validation loss = 3.007003
2018-08-12 00:59:19,226 - INFO - epoch 0, step 5610, training loss = 2.752515, validation loss = 2.998618
2018-08-12 00:59:23,952 - INFO - epoch 0, step 5620, training loss = 2.860521, validation loss = 2.994588
2018-08-12 00:59:29,298 - INFO - epoch 0, step 5630, training loss = 3.608457, validation loss = 2.995812
2018-08-12 00:59:34,419 - INFO - epoch 0, step 5640, training loss = 3.462342, validation loss = 2.997571
2018-08-12 00:59:40,012 - INFO - epoch 0, step 5650, training loss = 3.389036, validation loss = 2.994633
2018-08-12 00:59:45,470 - INFO - epoch 0, step 5660, training loss = 3.332023, validation loss = 3.010544
2018-08-12 00:59:50,997 - INFO - epoch 0, step 5670, training loss = 3.204329, validation loss = 3.001675
2018-08-12 00:59:56,947 - INFO - epoch 0, step 5680, training loss = 3.307480, validation loss = 3.012955
2018-08-12 01:00:02,355 - INFO - epoch 0, step 5690, training loss = 2.856816, validation loss = 3.022790
2018-08-12 01:00:07,969 - INFO - epoch 0, step 5700, training loss = 3.535954, validation loss = 3.009269
2018-08-12 01:00:13,398 - INFO - epoch 0, step 5710, training loss = 3.398411, validation loss = 3.008811
2018-08-12 01:00:19,063 - INFO - epoch 0, step 5720, training loss = 2.502812, validation loss = 3.006140
2018-08-12 01:00:24,695 - INFO - epoch 0, step 5730, training loss = 2.397406, validation loss = 3.008011
2018-08-12 01:00:30,978 - INFO - epoch 0, step 5740, training loss = 3.152472, validation loss = 2.987853
2018-08-12 01:00:37,296 - INFO - epoch 0, step 5750, training loss = 3.317161, validation loss = 2.959160
2018-08-12 01:00:43,409 - INFO - epoch 0, step 5760, training loss = 3.352164, validation loss = 2.958473
2018-08-12 01:00:49,352 - INFO - epoch 0, step 5770, training loss = 3.494873, validation loss = 2.965707
2018-08-12 01:00:55,694 - INFO - epoch 0, step 5780, training loss = 2.756639, validation loss = 2.933617
2018-08-12 01:01:02,176 - INFO - epoch 0, step 5790, training loss = 3.300109, validation loss = 2.999197
2018-08-12 01:01:08,514 - INFO - epoch 0, step 5800, training loss = 2.977303, validation loss = 2.937699
2018-08-12 01:01:14,749 - INFO - epoch 0, step 5810, training loss = 2.402277, validation loss = 2.937991
2018-08-12 01:01:21,107 - INFO - epoch 0, step 5820, training loss = 3.187425, validation loss = 2.952996
2018-08-12 01:01:26,890 - INFO - epoch 0, step 5830, training loss = 2.957676, validation loss = 2.962097
2018-08-12 01:01:32,349 - INFO - epoch 0, step 5840, training loss = 3.047705, validation loss = 2.948710
2018-08-12 01:01:38,188 - INFO - epoch 0, step 5850, training loss = 3.248870, validation loss = 2.970936
2018-08-12 01:01:43,545 - INFO - epoch 0, step 5860, training loss = 2.895273, validation loss = 3.022492
2018-08-12 01:01:49,235 - INFO - epoch 0, step 5870, training loss = 3.271964, validation loss = 2.984858
2018-08-12 01:01:54,717 - INFO - epoch 0, step 5880, training loss = 3.313693, validation loss = 3.014598
2018-08-12 01:02:00,396 - INFO - epoch 0, step 5890, training loss = 3.388324, validation loss = 2.963740
2018-08-12 01:02:06,836 - INFO - epoch 0, step 5900, training loss = 3.256399, validation loss = 2.943215
2018-08-12 01:02:13,313 - INFO - epoch 0, step 5910, training loss = 3.082280, validation loss = 2.935857
2018-08-12 01:02:19,497 - INFO - epoch 0, step 5920, training loss = 3.016907, validation loss = 2.947143
2018-08-12 01:02:25,646 - INFO - epoch 0, step 5930, training loss = 3.554350, validation loss = 2.932402
2018-08-12 01:02:31,786 - INFO - epoch 0, step 5940, training loss = 3.462027, validation loss = 2.930472
2018-08-12 01:02:37,850 - INFO - epoch 0, step 5950, training loss = 3.427837, validation loss = 2.941146
2018-08-12 01:02:43,858 - INFO - epoch 0, step 5960, training loss = 3.498072, validation loss = 2.961763
2018-08-12 01:02:49,463 - INFO - epoch 0, step 5970, training loss = 3.562671, validation loss = 2.967700
2018-08-12 01:02:55,337 - INFO - epoch 0, step 5980, training loss = 3.033055, validation loss = 2.963016
2018-08-12 01:03:00,905 - INFO - epoch 0, step 5990, training loss = 2.801458, validation loss = 2.957184
2018-08-12 01:03:06,523 - INFO - epoch 0, step 6000, training loss = 3.070932, validation loss = 2.966517
2018-08-12 01:03:12,134 - INFO - epoch 0, step 6010, training loss = 2.763503, validation loss = 2.981266
2018-08-12 01:03:17,775 - INFO - epoch 0, step 6020, training loss = 2.368716, validation loss = 2.975142
2018-08-12 01:03:23,927 - INFO - epoch 0, step 6030, training loss = 3.652594, validation loss = 3.053778
2018-08-12 01:03:30,379 - INFO - epoch 0, step 6040, training loss = 3.220100, validation loss = 2.927544
2018-08-12 01:03:36,984 - INFO - epoch 0, step 6050, training loss = 3.038674, validation loss = 2.936667
2018-08-12 01:03:43,587 - INFO - epoch 0, step 6060, training loss = 3.108099, validation loss = 2.950568
2018-08-12 01:03:50,055 - INFO - epoch 0, step 6070, training loss = 2.835546, validation loss = 2.938580
2018-08-12 01:03:56,682 - INFO - epoch 0, step 6080, training loss = 2.957138, validation loss = 2.963162
2018-08-12 01:04:03,152 - INFO - epoch 0, step 6090, training loss = 3.462860, validation loss = 2.901919
2018-08-12 01:04:09,757 - INFO - epoch 0, step 6100, training loss = 3.460401, validation loss = 2.992600
2018-08-12 01:04:16,252 - INFO - epoch 0, step 6110, training loss = 2.932269, validation loss = 2.906181
2018-08-12 01:04:22,715 - INFO - epoch 0, step 6120, training loss = 3.460640, validation loss = 2.964789
2018-08-12 01:04:29,137 - INFO - epoch 0, step 6130, training loss = 3.022734, validation loss = 2.930533
2018-08-12 01:04:35,510 - INFO - epoch 0, step 6140, training loss = 3.199935, validation loss = 2.973820
2018-08-12 01:04:41,942 - INFO - epoch 0, step 6150, training loss = 3.257690, validation loss = 2.922446
2018-08-12 01:04:48,110 - INFO - epoch 0, step 6160, training loss = 3.341806, validation loss = 2.937996
2018-08-12 01:04:53,846 - INFO - epoch 0, step 6170, training loss = 3.074628, validation loss = 2.998966
2018-08-12 01:04:59,198 - INFO - epoch 0, step 6180, training loss = 2.903692, validation loss = 2.967795
2018-08-12 01:05:04,832 - INFO - epoch 0, step 6190, training loss = 2.993946, validation loss = 3.009697
2018-08-12 01:05:10,613 - INFO - epoch 0, step 6200, training loss = 3.216205, validation loss = 2.998418
2018-08-12 01:05:17,057 - INFO - epoch 0, step 6210, training loss = 2.943513, validation loss = 2.970313
2018-08-12 01:05:23,535 - INFO - epoch 0, step 6220, training loss = 3.301289, validation loss = 2.963020
2018-08-12 01:05:29,821 - INFO - epoch 0, step 6230, training loss = 2.948998, validation loss = 2.947224
2018-08-12 01:05:36,238 - INFO - epoch 0, step 6240, training loss = 3.419751, validation loss = 2.985169
2018-08-12 01:05:42,456 - INFO - epoch 0, step 6250, training loss = 2.749007, validation loss = 2.960385
2018-08-12 01:05:48,729 - INFO - epoch 0, step 6260, training loss = 3.192896, validation loss = 2.947331
2018-08-12 01:05:54,825 - INFO - epoch 0, step 6270, training loss = 3.368049, validation loss = 2.957793
2018-08-12 01:06:00,868 - INFO - epoch 0, step 6280, training loss = 3.337999, validation loss = 2.951703
2018-08-12 01:06:06,790 - INFO - epoch 0, step 6290, training loss = 3.303913, validation loss = 2.963350
2018-08-12 01:06:12,527 - INFO - epoch 0, step 6300, training loss = 3.040983, validation loss = 2.981869
2018-08-12 01:06:18,827 - INFO - epoch 0, step 6310, training loss = 3.109263, validation loss = 2.983224
2018-08-12 01:06:24,615 - INFO - epoch 0, step 6320, training loss = 2.896086, validation loss = 2.989591
2018-08-12 01:06:30,478 - INFO - epoch 0, step 6330, training loss = 2.726876, validation loss = 3.025926
2018-08-12 01:06:36,015 - INFO - epoch 0, step 6340, training loss = 3.617437, validation loss = 2.999313
2018-08-12 01:06:41,573 - INFO - epoch 0, step 6350, training loss = 3.362519, validation loss = 2.988033
2018-08-12 01:06:46,707 - INFO - epoch 0, step 6360, training loss = 3.037488, validation loss = 3.007699
2018-08-12 01:06:52,015 - INFO - epoch 0, step 6370, training loss = 3.472370, validation loss = 2.992699
2018-08-12 01:06:57,431 - INFO - epoch 0, step 6380, training loss = 3.304532, validation loss = 2.996326
2018-08-12 01:07:02,857 - INFO - epoch 0, step 6390, training loss = 3.594519, validation loss = 3.010781
2018-08-12 01:07:08,348 - INFO - epoch 0, step 6400, training loss = 3.261919, validation loss = 3.002468
2018-08-12 01:07:14,501 - INFO - epoch 0, step 6410, training loss = 2.771249, validation loss = 2.942685
2018-08-12 01:07:20,566 - INFO - epoch 0, step 6420, training loss = 3.015021, validation loss = 2.924705
2018-08-12 01:07:26,542 - INFO - epoch 0, step 6430, training loss = 3.280115, validation loss = 2.944618
2018-08-12 01:07:32,448 - INFO - epoch 0, step 6440, training loss = 2.695140, validation loss = 2.927356
2018-08-12 01:07:38,132 - INFO - epoch 0, step 6450, training loss = 3.293815, validation loss = 2.926036
2018-08-12 01:07:43,497 - INFO - epoch 0, step 6460, training loss = 3.361730, validation loss = 2.942158
2018-08-12 01:07:48,703 - INFO - epoch 0, step 6470, training loss = 3.310016, validation loss = 2.970874
2018-08-12 01:07:53,913 - INFO - epoch 0, step 6480, training loss = 3.365636, validation loss = 2.978528
2018-08-12 01:07:59,032 - INFO - epoch 0, step 6490, training loss = 3.590393, validation loss = 2.971208
2018-08-12 01:08:04,153 - INFO - epoch 0, step 6500, training loss = 3.372442, validation loss = 2.981520
2018-08-12 01:08:09,346 - INFO - epoch 0, step 6510, training loss = 3.467025, validation loss = 2.973075
2018-08-12 01:08:14,415 - INFO - epoch 0, step 6520, training loss = 3.755711, validation loss = 2.973123
2018-08-12 01:08:19,666 - INFO - epoch 0, step 6530, training loss = 3.470351, validation loss = 2.986731
2018-08-12 01:08:25,839 - INFO - epoch 0, step 6540, training loss = 3.233343, validation loss = 3.018697
2018-08-12 01:08:32,609 - INFO - epoch 0, step 6550, training loss = 3.464250, validation loss = 2.940641
2018-08-12 01:08:39,073 - INFO - epoch 0, step 6560, training loss = 3.020847, validation loss = 2.906819
2018-08-12 01:08:45,152 - INFO - epoch 0, step 6570, training loss = 3.134160, validation loss = 2.911839
2018-08-12 01:08:51,258 - INFO - epoch 0, step 6580, training loss = 3.338454, validation loss = 2.898622
2018-08-12 01:08:57,339 - INFO - epoch 0, step 6590, training loss = 2.969444, validation loss = 2.901547
2018-08-12 01:09:03,126 - INFO - epoch 0, step 6600, training loss = 3.246034, validation loss = 2.889525
2018-08-12 01:09:08,170 - INFO - epoch 0, step 6610, training loss = 3.810289, validation loss = 2.924782
2018-08-12 01:09:13,415 - INFO - epoch 0, step 6620, training loss = 3.432058, validation loss = 2.953398
2018-08-12 01:09:18,616 - INFO - epoch 0, step 6630, training loss = 2.987692, validation loss = 2.964748
2018-08-12 01:09:23,938 - INFO - epoch 0, step 6640, training loss = 3.151393, validation loss = 2.965920
2018-08-12 01:09:29,289 - INFO - epoch 0, step 6650, training loss = 3.248110, validation loss = 2.970178
2018-08-12 01:09:34,708 - INFO - epoch 0, step 6660, training loss = 3.582111, validation loss = 2.997928
2018-08-12 01:09:40,016 - INFO - epoch 0, step 6670, training loss = 3.111774, validation loss = 2.975845
2018-08-12 01:09:45,578 - INFO - epoch 0, step 6680, training loss = 3.092528, validation loss = 2.954885
2018-08-12 01:09:51,372 - INFO - epoch 0, step 6690, training loss = 2.872649, validation loss = 2.943456
2018-08-12 01:09:57,194 - INFO - epoch 0, step 6700, training loss = 2.421872, validation loss = 2.953919
2018-08-12 01:10:02,718 - INFO - epoch 0, step 6710, training loss = 2.891932, validation loss = 2.959056
2018-08-12 01:10:08,096 - INFO - epoch 0, step 6720, training loss = 3.161925, validation loss = 2.960364
2018-08-12 01:10:13,682 - INFO - epoch 0, step 6730, training loss = 2.988127, validation loss = 2.967834
2018-08-12 01:10:19,824 - INFO - epoch 0, step 6740, training loss = 3.324968, validation loss = 2.975456
2018-08-12 01:10:26,173 - INFO - epoch 0, step 6750, training loss = 3.405798, validation loss = 2.925067
2018-08-12 01:10:32,713 - INFO - epoch 0, step 6760, training loss = 3.018240, validation loss = 2.944668
2018-08-12 01:10:39,162 - INFO - epoch 0, step 6770, training loss = 3.212574, validation loss = 2.920670
2018-08-12 01:10:45,678 - INFO - epoch 0, step 6780, training loss = 3.071334, validation loss = 2.983249
2018-08-12 01:10:52,198 - INFO - epoch 0, step 6790, training loss = 3.008224, validation loss = 2.922930
2018-08-12 01:10:58,677 - INFO - epoch 0, step 6800, training loss = 3.462270, validation loss = 2.968043
2018-08-12 01:11:04,294 - INFO - epoch 0, step 6810, training loss = 3.599961, validation loss = 3.025907
2018-08-12 01:11:09,466 - INFO - epoch 0, step 6820, training loss = 3.298131, validation loss = 2.959918
2018-08-12 01:11:14,850 - INFO - epoch 0, step 6830, training loss = 3.127313, validation loss = 2.979000
2018-08-12 01:11:20,409 - INFO - epoch 0, step 6840, training loss = 2.818358, validation loss = 2.982943
2018-08-12 01:11:25,906 - INFO - epoch 0, step 6850, training loss = 2.514031, validation loss = 3.020109
2018-08-12 01:11:30,959 - INFO - epoch 0, step 6860, training loss = 3.505894, validation loss = 3.000623
2018-08-12 01:11:37,055 - INFO - epoch 0, step 6870, training loss = 3.314432, validation loss = 2.943026
2018-08-12 01:11:43,262 - INFO - epoch 0, step 6880, training loss = 2.783761, validation loss = 2.915065
2018-08-12 01:11:49,499 - INFO - epoch 0, step 6890, training loss = 2.993067, validation loss = 2.936027
2018-08-12 01:11:55,349 - INFO - epoch 0, step 6900, training loss = 3.131317, validation loss = 2.899003
2018-08-12 01:12:00,749 - INFO - epoch 0, step 6910, training loss = 2.947738, validation loss = 2.923024
2018-08-12 01:12:05,996 - INFO - epoch 0, step 6920, training loss = 2.705958, validation loss = 2.933292
2018-08-12 01:12:11,651 - INFO - epoch 0, step 6930, training loss = 2.481028, validation loss = 2.954413
2018-08-12 01:12:17,203 - INFO - epoch 0, step 6940, training loss = 3.107192, validation loss = 2.936859
2018-08-12 01:12:23,728 - INFO - epoch 0, step 6950, training loss = 2.998112, validation loss = 2.924420
2018-08-12 01:12:30,096 - INFO - epoch 0, step 6960, training loss = 3.093458, validation loss = 2.908913
2018-08-12 01:12:36,552 - INFO - epoch 0, step 6970, training loss = 3.334547, validation loss = 2.921324
2018-08-12 01:12:43,095 - INFO - epoch 0, step 6980, training loss = 3.630247, validation loss = 2.913306
2018-08-12 01:12:50,178 - INFO - epoch 0, step 6990, training loss = 2.597114, validation loss = 2.912101
2018-08-12 01:12:56,598 - INFO - epoch 0, step 7000, training loss = 2.844353, validation loss = 2.933151
2018-08-12 01:13:02,606 - INFO - epoch 0, step 7010, training loss = 3.086617, validation loss = 2.898376
2018-08-12 01:13:09,159 - INFO - epoch 0, step 7020, training loss = 3.221115, validation loss = 2.925843
2018-08-12 01:13:15,542 - INFO - epoch 0, step 7030, training loss = 3.346890, validation loss = 2.955999
2018-08-12 01:13:21,003 - INFO - epoch 0, step 7040, training loss = 3.344658, validation loss = 2.958658
2018-08-12 01:13:26,838 - INFO - epoch 0, step 7050, training loss = 3.601774, validation loss = 2.967536
2018-08-12 01:13:33,153 - INFO - epoch 0, step 7060, training loss = 3.541196, validation loss = 2.965126
2018-08-12 01:13:39,132 - INFO - epoch 0, step 7070, training loss = 3.402524, validation loss = 2.952096
2018-08-12 01:13:44,991 - INFO - epoch 0, step 7080, training loss = 3.291353, validation loss = 2.954627
2018-08-12 01:13:51,112 - INFO - epoch 0, step 7090, training loss = 2.496599, validation loss = 2.955766
2018-08-12 01:13:57,273 - INFO - epoch 0, step 7100, training loss = 3.176029, validation loss = 2.993331
2018-08-12 01:14:03,246 - INFO - epoch 0, step 7110, training loss = 3.283453, validation loss = 2.974061
2018-08-12 01:14:09,633 - INFO - epoch 0, step 7120, training loss = 2.981025, validation loss = 2.901407
2018-08-12 01:14:16,310 - INFO - epoch 0, step 7130, training loss = 3.456025, validation loss = 2.949407
2018-08-12 01:14:22,906 - INFO - epoch 0, step 7140, training loss = 3.221944, validation loss = 2.895400
2018-08-12 01:14:29,465 - INFO - epoch 0, step 7150, training loss = 3.617976, validation loss = 2.944628
2018-08-12 01:14:35,756 - INFO - epoch 0, step 7160, training loss = 2.902527, validation loss = 2.906694
2018-08-12 01:14:42,167 - INFO - epoch 0, step 7170, training loss = 3.336797, validation loss = 2.929790
2018-08-12 01:14:47,864 - INFO - epoch 0, step 7180, training loss = 4.519301, validation loss = 2.907957
2018-08-12 01:14:52,802 - INFO - epoch 0, step 7190, training loss = 3.758433, validation loss = 2.978281
2018-08-12 01:14:57,810 - INFO - epoch 0, step 7200, training loss = 4.358445, validation loss = 3.037456
2018-08-12 01:15:02,944 - INFO - epoch 0, step 7210, training loss = 3.986950, validation loss = 3.016944
2018-08-12 01:15:07,696 - INFO - epoch 0, step 7220, training loss = 3.861115, validation loss = 3.061032
2018-08-12 01:15:12,914 - INFO - epoch 0, step 7230, training loss = 3.982925, validation loss = 3.070902
2018-08-12 01:15:18,104 - INFO - epoch 0, step 7240, training loss = 3.423773, validation loss = 3.056697
2018-08-12 01:15:23,378 - INFO - epoch 0, step 7250, training loss = 3.606419, validation loss = 3.079728
2018-08-12 01:15:28,503 - INFO - epoch 0, step 7260, training loss = 4.158540, validation loss = 3.079774
2018-08-12 01:15:33,980 - INFO - epoch 0, step 7270, training loss = 3.732857, validation loss = 3.011150
2018-08-12 01:15:39,632 - INFO - epoch 0, step 7280, training loss = 3.543097, validation loss = 3.068385
2018-08-12 01:15:45,276 - INFO - epoch 0, step 7290, training loss = 3.868865, validation loss = 3.041822
2018-08-12 01:15:50,939 - INFO - epoch 0, step 7300, training loss = 3.501021, validation loss = 3.025063
2018-08-12 01:15:56,326 - INFO - epoch 0, step 7310, training loss = 3.660675, validation loss = 3.121335
2018-08-12 01:16:05,358 - INFO - epoch 0, step 7320, training loss = 2.953154, validation loss = 3.311783
2018-08-12 01:16:14,215 - INFO - epoch 0, step 7330, training loss = 3.044606, validation loss = 3.148048
2018-08-12 01:16:24,159 - INFO - epoch 0, step 7340, training loss = 3.122918, validation loss = 3.234648
2018-08-12 01:16:30,073 - INFO - epoch 0, step 7350, training loss = 3.510198, validation loss = 3.004371
2018-08-12 01:16:35,238 - INFO - epoch 0, step 7360, training loss = 3.688980, validation loss = 3.073127
2018-08-12 01:16:40,356 - INFO - epoch 0, step 7370, training loss = 3.475147, validation loss = 3.060581
2018-08-12 01:16:45,499 - INFO - epoch 0, step 7380, training loss = 3.560791, validation loss = 3.083646
2018-08-12 01:16:50,488 - INFO - epoch 0, step 7390, training loss = 3.735736, validation loss = 3.085973
2018-08-12 01:16:55,503 - INFO - epoch 0, step 7400, training loss = 3.730707, validation loss = 3.072291
2018-08-12 01:17:00,224 - INFO - epoch 0, step 7410, training loss = 4.336659, validation loss = 3.096593
2018-08-12 01:17:05,263 - INFO - epoch 0, step 7420, training loss = 3.567741, validation loss = 3.105853
2018-08-12 01:17:10,961 - INFO - epoch 0, step 7430, training loss = 3.671552, validation loss = 3.083392
2018-08-12 01:17:21,546 - INFO - epoch 0, step 7440, training loss = 2.734506, validation loss = 3.342444
2018-08-12 01:17:30,437 - INFO - epoch 0, step 7450, training loss = 2.648211, validation loss = 3.152307
2018-08-12 01:17:38,965 - INFO - epoch 0, step 7460, training loss = 2.992662, validation loss = 3.189658
2018-08-12 01:17:47,260 - INFO - epoch 0, step 7470, training loss = 3.216201, validation loss = 3.178240
2018-08-12 01:17:56,470 - INFO - epoch 0, step 7480, training loss = 2.838399, validation loss = 3.234567
2018-08-12 01:18:05,462 - INFO - epoch 0, step 7490, training loss = 2.523479, validation loss = 3.245054
2018-08-12 01:18:13,795 - INFO - epoch 0, step 7500, training loss = 2.901521, validation loss = 3.222595
2018-08-12 01:18:20,817 - INFO - epoch 0, step 7510, training loss = 2.501368, validation loss = 3.267809
2018-08-12 01:18:28,456 - INFO - epoch 0, step 7520, training loss = 2.595358, validation loss = 3.248663
2018-08-12 01:18:35,685 - INFO - epoch 0, step 7530, training loss = 3.076945, validation loss = 3.191951
2018-08-12 01:18:43,821 - INFO - epoch 0, step 7540, training loss = 3.003668, validation loss = 3.300617
2018-08-12 01:18:52,307 - INFO - epoch 0, step 7550, training loss = 3.272316, validation loss = 3.200427
2018-08-12 01:19:03,190 - INFO - epoch 0, step 7560, training loss = 2.248016, validation loss = 3.283353
2018-08-12 01:19:14,124 - INFO - epoch 0, step 7570, training loss = 2.504095, validation loss = 3.210864
2018-08-12 01:19:24,458 - INFO - epoch 0, step 7580, training loss = 2.531647, validation loss = 3.277117
2018-08-12 01:19:34,754 - INFO - epoch 0, step 7590, training loss = 2.756261, validation loss = 3.172876
2018-08-12 01:19:44,964 - INFO - epoch 0, step 7600, training loss = 3.049835, validation loss = 3.223261
2018-08-12 01:19:54,560 - INFO - epoch 0, step 7610, training loss = 3.020364, validation loss = 3.141075
2018-08-12 01:20:03,929 - INFO - epoch 0, step 7620, training loss = 3.529140, validation loss = 3.241106
2018-08-12 01:20:15,297 - INFO - epoch 0, step 7630, training loss = 2.979046, validation loss = 3.191097
2018-08-12 01:20:25,240 - INFO - epoch 0, step 7640, training loss = 2.881858, validation loss = 3.197481
2018-08-12 01:20:35,046 - INFO - epoch 0, step 7650, training loss = 2.876392, validation loss = 3.193834
2018-08-12 01:20:43,945 - INFO - epoch 0, step 7660, training loss = 3.099677, validation loss = 3.172006
2018-08-12 01:20:53,287 - INFO - epoch 0, step 7670, training loss = 2.944923, validation loss = 3.202823
2018-08-12 01:21:02,410 - INFO - epoch 0, step 7680, training loss = 3.083168, validation loss = 3.139430
2018-08-12 01:21:11,786 - INFO - epoch 0, step 7690, training loss = 3.071888, validation loss = 3.249987
2018-08-12 01:21:18,840 - INFO - epoch 0, step 7700, training loss = 4.444676, validation loss = 3.004521
2018-08-12 01:21:23,835 - INFO - epoch 0, step 7710, training loss = 3.276533, validation loss = 3.068837
2018-08-12 01:21:28,766 - INFO - epoch 0, step 7720, training loss = 3.385272, validation loss = 3.082943
2018-08-12 01:21:33,816 - INFO - epoch 0, step 7730, training loss = 4.136828, validation loss = 3.085366
2018-08-12 01:21:39,077 - INFO - epoch 0, step 7740, training loss = 3.276154, validation loss = 3.096987
2018-08-12 01:21:43,936 - INFO - epoch 0, step 7750, training loss = 3.516879, validation loss = 3.124429
2018-08-12 01:21:48,762 - INFO - epoch 0, step 7760, training loss = 3.783279, validation loss = 3.121166
2018-08-12 01:21:53,770 - INFO - epoch 0, step 7770, training loss = 3.597961, validation loss = 3.127059
2018-08-12 01:21:58,817 - INFO - epoch 0, step 7780, training loss = 3.657624, validation loss = 3.120038
2018-08-12 01:22:03,949 - INFO - epoch 0, step 7790, training loss = 3.986321, validation loss = 3.107078
2018-08-12 01:22:10,889 - INFO - epoch 0, step 7800, training loss = 3.429060, validation loss = 3.207456
2018-08-12 01:22:18,997 - INFO - epoch 0, step 7810, training loss = 2.960007, validation loss = 3.210111
2018-08-12 01:22:26,974 - INFO - epoch 0, step 7820, training loss = 2.976169, validation loss = 3.257866
2018-08-12 01:22:34,335 - INFO - epoch 0, step 7830, training loss = 3.894227, validation loss = 3.234286
2018-08-12 01:22:41,974 - INFO - epoch 0, step 7840, training loss = 2.578996, validation loss = 3.252244
2018-08-12 01:22:49,350 - INFO - epoch 0, step 7850, training loss = 3.816770, validation loss = 3.256596
2018-08-12 01:22:57,455 - INFO - epoch 0, step 7860, training loss = 2.715570, validation loss = 3.281658
2018-08-12 01:23:07,232 - INFO - epoch 0, step 7870, training loss = 2.785901, validation loss = 3.296854
2018-08-12 01:23:17,028 - INFO - epoch 0, step 7880, training loss = 2.762135, validation loss = 3.243106
2018-08-12 01:23:26,484 - INFO - epoch 0, step 7890, training loss = 3.114233, validation loss = 3.309780
2018-08-12 01:23:34,974 - INFO - epoch 0, step 7900, training loss = 2.991178, validation loss = 3.180398
2018-08-12 01:23:44,023 - INFO - epoch 0, step 7910, training loss = 3.216980, validation loss = 3.229893
2018-08-12 01:23:53,733 - INFO - epoch 0, step 7920, training loss = 2.899895, validation loss = 3.282645
2018-08-12 01:24:03,204 - INFO - epoch 0, step 7930, training loss = 2.526692, validation loss = 3.227844
2018-08-12 01:24:12,660 - INFO - epoch 0, step 7940, training loss = 3.127137, validation loss = 3.289215
2018-08-12 01:24:22,313 - INFO - epoch 0, step 7950, training loss = 2.650878, validation loss = 3.184128
2018-08-12 01:24:30,873 - INFO - epoch 0, step 7960, training loss = 2.866660, validation loss = 3.242582
2018-08-12 01:24:37,692 - INFO - epoch 0, step 7970, training loss = 3.648830, validation loss = 3.045138
2018-08-12 01:24:44,339 - INFO - epoch 0, step 7980, training loss = 3.079352, validation loss = 3.185837
2018-08-12 01:24:50,807 - INFO - epoch 0, step 7990, training loss = 2.834170, validation loss = 3.066802
2018-08-12 01:24:58,355 - INFO - epoch 0, step 8000, training loss = 3.242835, validation loss = 3.152560
2018-08-12 01:25:04,825 - INFO - epoch 0, step 8010, training loss = 2.901662, validation loss = 3.076062
2018-08-12 01:25:09,464 - INFO - epoch 0, step 8020, training loss = 4.480245, validation loss = 3.803424
2018-08-12 01:25:13,506 - INFO - epoch 0, step 8030, training loss = 4.482201, validation loss = 3.403427
2018-08-12 01:25:17,463 - INFO - epoch 0, step 8040, training loss = 3.325111, validation loss = 3.519307
2018-08-12 01:25:21,505 - INFO - epoch 0, step 8050, training loss = 3.163606, validation loss = 3.451224
2018-08-12 01:25:25,522 - INFO - epoch 0, step 8060, training loss = 3.553036, validation loss = 3.607959
2018-08-12 01:25:29,567 - INFO - epoch 0, step 8070, training loss = 3.547423, validation loss = 3.577403
2018-08-12 01:25:33,605 - INFO - epoch 0, step 8080, training loss = 3.068233, validation loss = 3.664002
2018-08-12 01:25:37,703 - INFO - epoch 0, step 8090, training loss = 3.023639, validation loss = 3.584063
2018-08-12 01:25:43,037 - INFO - epoch 0, step 8100, training loss = 3.775130, validation loss = 3.145321
2018-08-12 01:25:48,764 - INFO - epoch 0, step 8110, training loss = 3.646095, validation loss = 3.125676
2018-08-12 01:25:54,101 - INFO - epoch 0, step 8120, training loss = 3.716610, validation loss = 3.149367
2018-08-12 01:25:59,837 - INFO - epoch 0, step 8130, training loss = 3.669844, validation loss = 3.126423
2018-08-12 01:26:05,588 - INFO - epoch 0, step 8140, training loss = 3.561291, validation loss = 3.146966
2018-08-12 01:26:11,116 - INFO - epoch 0, step 8150, training loss = 3.309021, validation loss = 3.118931
2018-08-12 01:26:16,038 - INFO - epoch 0, step 8160, training loss = 3.660466, validation loss = 3.495553
2018-08-12 01:26:19,919 - INFO - epoch 0, step 8170, training loss = 4.211293, validation loss = 3.385289
2018-08-12 01:26:23,869 - INFO - epoch 0, step 8180, training loss = 3.659521, validation loss = 3.464120
2018-08-12 01:26:27,890 - INFO - epoch 0, step 8190, training loss = 4.079491, validation loss = 3.421774
2018-08-12 01:26:31,917 - INFO - epoch 0, step 8200, training loss = 3.619416, validation loss = 3.512483
2018-08-12 01:26:35,710 - INFO - epoch 0, step 8210, training loss = 4.207466, validation loss = 3.537003
2018-08-12 01:26:44,494 - INFO - epoch 0, step 8220, training loss = 3.984157, validation loss = 3.436444
2018-08-12 01:26:53,025 - INFO - epoch 0, step 8230, training loss = 3.503094, validation loss = 3.323243
2018-08-12 01:27:01,510 - INFO - epoch 0, step 8240, training loss = 3.982604, validation loss = 3.317660
2018-08-12 01:27:10,068 - INFO - epoch 0, step 8250, training loss = 4.012558, validation loss = 3.351120
2018-08-12 01:27:18,494 - INFO - epoch 0, step 8260, training loss = 3.423638, validation loss = 3.342035
2018-08-12 01:27:27,073 - INFO - epoch 0, step 8270, training loss = 3.391884, validation loss = 3.348490
2018-08-12 01:27:35,606 - INFO - epoch 0, step 8280, training loss = 3.766781, validation loss = 3.355547
2018-08-12 01:27:44,444 - INFO - epoch 0, step 8290, training loss = 3.116146, validation loss = 3.422784
2018-08-12 01:27:53,308 - INFO - epoch 0, step 8300, training loss = 4.060472, validation loss = 3.432693
2018-08-12 01:28:01,780 - INFO - epoch 0, step 8310, training loss = 3.819859, validation loss = 3.339192
2018-08-12 01:28:09,857 - INFO - epoch 0, step 8320, training loss = 3.269304, validation loss = 3.357487
2018-08-12 01:28:15,870 - INFO - epoch 0, step 8330, training loss = 3.006924, validation loss = 3.262885
2018-08-12 01:28:21,725 - INFO - epoch 0, step 8340, training loss = 3.071264, validation loss = 3.264539
2018-08-12 01:28:28,200 - INFO - epoch 0, step 8350, training loss = 3.594568, validation loss = 3.138757
2018-08-12 01:28:35,303 - INFO - epoch 0, step 8360, training loss = 3.688788, validation loss = 3.091771
2018-08-12 01:28:42,183 - INFO - epoch 0, step 8370, training loss = 3.503814, validation loss = 3.107596
2018-08-12 01:28:48,600 - INFO - epoch 0, step 8380, training loss = 3.388368, validation loss = 3.093321
2018-08-12 01:28:53,543 - INFO - epoch 0, step 8390, training loss = 3.921594, validation loss = 3.066584
2018-08-12 01:28:58,489 - INFO - epoch 0, step 8400, training loss = 3.733246, validation loss = 3.122151
2018-08-12 01:29:03,634 - INFO - epoch 0, step 8410, training loss = 3.448718, validation loss = 3.137217
2018-08-12 01:29:08,641 - INFO - epoch 0, step 8420, training loss = 3.629813, validation loss = 3.134968
2018-08-12 01:29:13,800 - INFO - epoch 0, step 8430, training loss = 3.661591, validation loss = 3.141213
2018-08-12 01:29:18,981 - INFO - epoch 0, step 8440, training loss = 3.758695, validation loss = 3.146788
2018-08-12 01:29:24,056 - INFO - epoch 0, step 8450, training loss = 3.913135, validation loss = 3.139590
2018-08-12 01:29:29,209 - INFO - epoch 0, step 8460, training loss = 3.883616, validation loss = 3.139984
2018-08-12 01:29:34,370 - INFO - epoch 0, step 8470, training loss = 3.849677, validation loss = 3.139932
2018-08-12 01:29:41,281 - INFO - epoch 0, step 8480, training loss = 3.252776, validation loss = 3.168873
2018-08-12 01:29:48,840 - INFO - epoch 0, step 8490, training loss = 2.963856, validation loss = 3.166592
2018-08-12 01:29:56,121 - INFO - epoch 0, step 8500, training loss = 3.933640, validation loss = 3.235661
2018-08-12 01:30:03,850 - INFO - epoch 0, step 8510, training loss = 3.476524, validation loss = 3.182429
2018-08-12 01:30:12,074 - INFO - epoch 0, step 8520, training loss = 2.729262, validation loss = 3.253275
2018-08-12 01:30:19,853 - INFO - epoch 0, step 8530, training loss = 3.840359, validation loss = 3.229922
2018-08-12 01:30:28,399 - INFO - epoch 0, step 8540, training loss = 3.685688, validation loss = 3.365686
2018-08-12 01:30:36,951 - INFO - epoch 0, step 8550, training loss = 3.183599, validation loss = 3.289838
2018-08-12 01:30:45,671 - INFO - epoch 0, step 8560, training loss = 3.481069, validation loss = 3.330113
2018-08-12 01:30:54,240 - INFO - epoch 0, step 8570, training loss = 3.320970, validation loss = 3.319654
2018-08-12 01:31:02,688 - INFO - epoch 0, step 8580, training loss = 3.002466, validation loss = 3.259243
2018-08-12 01:31:10,806 - INFO - epoch 0, step 8590, training loss = 3.132597, validation loss = 3.312481
2018-08-12 01:31:19,879 - INFO - epoch 0, step 8600, training loss = 2.831684, validation loss = 3.294731
2018-08-12 01:31:28,654 - INFO - epoch 0, step 8610, training loss = 3.337098, validation loss = 3.252837
2018-08-12 01:31:37,062 - INFO - epoch 0, step 8620, training loss = 3.765053, validation loss = 3.341035
2018-08-12 01:31:45,665 - INFO - epoch 0, step 8630, training loss = 3.207957, validation loss = 3.193650
2018-08-12 01:31:54,146 - INFO - epoch 0, step 8640, training loss = 3.608487, validation loss = 3.310100
2018-08-12 01:32:02,456 - INFO - epoch 0, step 8650, training loss = 3.146622, validation loss = 3.277851
2018-08-12 01:32:10,914 - INFO - epoch 0, step 8660, training loss = 3.017721, validation loss = 3.332042
2018-08-12 01:32:19,021 - INFO - epoch 0, step 8670, training loss = 3.390512, validation loss = 3.276137
2018-08-12 01:32:28,130 - INFO - epoch 0, step 8680, training loss = 3.492768, validation loss = 3.306952
2018-08-12 01:32:35,852 - INFO - epoch 0, step 8690, training loss = 2.905208, validation loss = 3.104645
2018-08-12 01:32:42,715 - INFO - epoch 0, step 8700, training loss = 2.602516, validation loss = 3.069845
2018-08-12 01:32:49,175 - INFO - epoch 0, step 8710, training loss = 4.271938, validation loss = 3.080416
2018-08-12 01:32:53,319 - INFO - epoch 0, step 8720, training loss = 4.307673, validation loss = 3.356963
2018-08-12 01:32:57,675 - INFO - epoch 0, step 8730, training loss = 3.198860, validation loss = 3.322690
2018-08-12 01:33:02,007 - INFO - epoch 0, step 8740, training loss = 3.179763, validation loss = 3.378314
2018-08-12 01:33:07,284 - INFO - epoch 0, step 8750, training loss = 4.083404, validation loss = 3.178530
2018-08-12 01:33:13,606 - INFO - epoch 0, step 8760, training loss = 3.226540, validation loss = 3.148834
2018-08-12 01:33:20,303 - INFO - epoch 0, step 8770, training loss = 3.525145, validation loss = 3.081758
2018-08-12 01:33:28,554 - INFO - epoch 0, step 8780, training loss = 3.725026, validation loss = 3.297709
2018-08-12 01:33:37,323 - INFO - epoch 0, step 8790, training loss = 3.742958, validation loss = 3.392689
2018-08-12 01:33:46,237 - INFO - epoch 0, step 8800, training loss = 3.488959, validation loss = 3.347692
2018-08-12 01:33:54,926 - INFO - epoch 0, step 8810, training loss = 3.941686, validation loss = 3.399167
2018-08-12 01:34:03,807 - INFO - epoch 0, step 8820, training loss = 3.238137, validation loss = 3.375170
2018-08-12 01:34:12,242 - INFO - epoch 0, step 8830, training loss = 3.470725, validation loss = 3.382615
2018-08-12 01:34:21,119 - INFO - epoch 0, step 8840, training loss = 3.191309, validation loss = 3.422929
2018-08-12 01:34:30,083 - INFO - epoch 0, step 8850, training loss = 3.475765, validation loss = 3.386015
2018-08-12 01:34:39,103 - INFO - epoch 0, step 8860, training loss = 3.270306, validation loss = 3.411287
2018-08-12 01:34:48,054 - INFO - epoch 0, step 8870, training loss = 3.189866, validation loss = 3.443809
2018-08-12 01:34:56,558 - INFO - epoch 0, step 8880, training loss = 3.286635, validation loss = 3.238795
2018-08-12 01:35:03,140 - INFO - epoch 0, step 8890, training loss = 3.167861, validation loss = 3.091695
2018-08-12 01:35:09,998 - INFO - epoch 0, step 8900, training loss = 3.622709, validation loss = 3.155661
2018-08-12 01:35:16,890 - INFO - epoch 0, step 8910, training loss = 3.586117, validation loss = 3.096783
2018-08-12 01:35:22,169 - INFO - epoch 0, step 8920, training loss = 3.024358, validation loss = 3.077793
2018-08-12 01:35:27,367 - INFO - epoch 0, step 8930, training loss = 3.990106, validation loss = 3.133680
2018-08-12 01:35:32,277 - INFO - epoch 0, step 8940, training loss = 4.113142, validation loss = 3.161940
2018-08-12 01:35:37,282 - INFO - epoch 0, step 8950, training loss = 3.469759, validation loss = 3.155064
2018-08-12 01:35:42,104 - INFO - epoch 0, step 8960, training loss = 4.158289, validation loss = 3.149886
2018-08-12 01:35:46,941 - INFO - epoch 0, step 8970, training loss = 4.219818, validation loss = 3.155297
2018-08-12 01:35:51,940 - INFO - epoch 0, step 8980, training loss = 3.422315, validation loss = 3.154922
2018-08-12 01:35:57,058 - INFO - epoch 0, step 8990, training loss = 3.933515, validation loss = 3.154979
2018-08-12 01:36:01,881 - INFO - epoch 0, step 9000, training loss = 3.875330, validation loss = 3.173409
2018-08-12 01:36:06,955 - INFO - epoch 0, step 9010, training loss = 3.664688, validation loss = 3.170560
2018-08-12 01:36:10,847 - INFO - epoch 0, step 9020, training loss = 3.943239, validation loss = 3.579539
2018-08-12 01:36:14,803 - INFO - epoch 0, step 9030, training loss = 3.651857, validation loss = 3.431107
2018-08-12 01:36:18,931 - INFO - epoch 0, step 9040, training loss = 2.412735, validation loss = 3.462128
2018-08-12 01:36:22,865 - INFO - epoch 0, step 9050, training loss = 3.690046, validation loss = 3.459285
2018-08-12 01:36:31,030 - INFO - epoch 0, step 9060, training loss = 2.450497, validation loss = 3.189725
2018-08-12 01:36:40,013 - INFO - epoch 0, step 9070, training loss = 3.121159, validation loss = 3.246290
2018-08-12 01:36:49,438 - INFO - epoch 0, step 9080, training loss = 2.962022, validation loss = 3.268421
2018-08-12 01:36:58,272 - INFO - epoch 0, step 9090, training loss = 3.489122, validation loss = 3.217906
2018-08-12 01:37:06,881 - INFO - epoch 0, step 9100, training loss = 3.015186, validation loss = 3.318047
2018-08-12 01:37:15,424 - INFO - epoch 0, step 9110, training loss = 3.282820, validation loss = 3.219327
2018-08-12 01:37:24,011 - INFO - epoch 0, step 9120, training loss = 3.130445, validation loss = 3.265898
2018-08-12 01:37:31,979 - INFO - epoch 0, step 9130, training loss = 3.478015, validation loss = 3.273022
2018-08-12 01:37:39,932 - INFO - epoch 0, step 9140, training loss = 3.245514, validation loss = 3.254142
2018-08-12 01:37:47,760 - INFO - epoch 0, step 9150, training loss = 3.655200, validation loss = 3.308994
2018-08-12 01:37:55,753 - INFO - epoch 0, step 9160, training loss = 3.563249, validation loss = 3.272713
2018-08-12 01:38:04,031 - INFO - epoch 0, step 9170, training loss = 2.892688, validation loss = 3.293840
2018-08-12 01:38:11,282 - INFO - epoch 0, step 9180, training loss = 4.218346, validation loss = 3.182532
2018-08-12 01:38:15,039 - INFO - epoch 0, step 9190, training loss = 3.522230, validation loss = 3.131665
2018-08-12 01:38:18,777 - INFO - epoch 0, step 9200, training loss = 3.769758, validation loss = 3.141076
2018-08-12 01:38:22,494 - INFO - epoch 0, step 9210, training loss = 3.371049, validation loss = 3.150020
2018-08-12 01:38:26,053 - INFO - epoch 0, step 9220, training loss = 3.791027, validation loss = 3.157143
2018-08-12 01:38:29,848 - INFO - epoch 0, step 9230, training loss = 2.607735, validation loss = 3.149492
2018-08-12 01:38:33,509 - INFO - epoch 0, step 9240, training loss = 3.650430, validation loss = 3.164234
2018-08-12 01:38:37,504 - INFO - epoch 0, step 9250, training loss = 3.267499, validation loss = 3.159487
2018-08-12 01:38:41,138 - INFO - epoch 0, step 9260, training loss = 4.126673, validation loss = 3.179621
2018-08-12 01:38:45,126 - INFO - epoch 0, step 9270, training loss = 3.566091, validation loss = 3.176963
2018-08-12 01:38:48,822 - INFO - epoch 0, step 9280, training loss = 3.216192, validation loss = 3.201505
2018-08-12 01:38:54,224 - INFO - epoch 0, step 9290, training loss = 3.086576, validation loss = 3.264027
2018-08-12 01:39:00,247 - INFO - epoch 0, step 9300, training loss = 2.947882, validation loss = 3.349391
2018-08-12 01:39:06,670 - INFO - epoch 0, step 9310, training loss = 3.474721, validation loss = 3.266191
2018-08-12 01:39:15,372 - INFO - epoch 0, step 9320, training loss = 2.970208, validation loss = 3.274068
2018-08-12 01:39:24,015 - INFO - epoch 0, step 9330, training loss = 3.247132, validation loss = 3.188604
2018-08-12 01:39:32,881 - INFO - epoch 0, step 9340, training loss = 3.300624, validation loss = 3.167751
2018-08-12 01:39:41,140 - INFO - epoch 0, step 9350, training loss = 3.233608, validation loss = 3.223835
2018-08-12 01:39:49,628 - INFO - epoch 0, step 9360, training loss = 3.038820, validation loss = 3.168766
2018-08-12 01:39:58,586 - INFO - epoch 0, step 9370, training loss = 2.304410, validation loss = 3.224353
2018-08-12 01:40:04,512 - INFO - epoch 0, step 9380, training loss = 3.889643, validation loss = 3.141991
2018-08-12 01:40:09,663 - INFO - epoch 0, step 9390, training loss = 2.988615, validation loss = 3.128549
2018-08-12 01:40:15,440 - INFO - epoch 0, step 9400, training loss = 3.639381, validation loss = 3.126341
2018-08-12 01:40:20,221 - INFO - epoch 0, step 9410, training loss = 3.369470, validation loss = 3.151580
2018-08-12 01:40:25,185 - INFO - epoch 0, step 9420, training loss = 3.316637, validation loss = 3.146785
2018-08-12 01:40:30,173 - INFO - epoch 0, step 9430, training loss = 3.771611, validation loss = 3.143528
2018-08-12 01:40:34,965 - INFO - epoch 0, step 9440, training loss = 3.356580, validation loss = 3.156819
2018-08-12 01:40:39,941 - INFO - epoch 0, step 9450, training loss = 3.453481, validation loss = 3.155166
2018-08-12 01:40:44,910 - INFO - epoch 0, step 9460, training loss = 3.526630, validation loss = 3.167578
2018-08-12 01:40:49,687 - INFO - epoch 0, step 9470, training loss = 3.462476, validation loss = 3.173833
2018-08-12 01:40:54,756 - INFO - epoch 0, step 9480, training loss = 3.412386, validation loss = 3.165220
2018-08-12 01:41:01,606 - INFO - epoch 0, step 9490, training loss = 3.501613, validation loss = 3.137119
2018-08-12 01:41:08,156 - INFO - epoch 0, step 9500, training loss = 3.197408, validation loss = 3.114159
2018-08-12 01:41:14,953 - INFO - epoch 0, step 9510, training loss = 3.671141, validation loss = 3.130363
2018-08-12 01:41:20,265 - INFO - epoch 0, step 9520, training loss = 3.523643, validation loss = 3.081354
2018-08-12 01:41:25,072 - INFO - epoch 0, step 9530, training loss = 3.761581, validation loss = 3.123048
2018-08-12 01:41:29,947 - INFO - epoch 0, step 9540, training loss = 4.021966, validation loss = 3.134434
2018-08-12 01:41:34,767 - INFO - epoch 0, step 9550, training loss = 3.298524, validation loss = 3.149872
2018-08-12 01:41:39,478 - INFO - epoch 0, step 9560, training loss = 3.895762, validation loss = 3.169981
2018-08-12 01:41:44,381 - INFO - epoch 0, step 9570, training loss = 3.631058, validation loss = 3.172561
2018-08-12 01:41:49,322 - INFO - epoch 0, step 9580, training loss = 3.295002, validation loss = 3.174594
2018-08-12 01:41:54,071 - INFO - epoch 0, step 9590, training loss = 3.590562, validation loss = 3.181064
2018-08-12 01:41:59,257 - INFO - epoch 0, step 9600, training loss = 3.245100, validation loss = 3.175046
2018-08-12 01:42:04,095 - INFO - epoch 0, step 9610, training loss = 4.005462, validation loss = 3.165933
2018-08-12 01:42:12,203 - INFO - epoch 0, step 9620, training loss = 3.512106, validation loss = 3.303545
2018-08-12 01:42:20,761 - INFO - epoch 0, step 9630, training loss = 3.487305, validation loss = 3.357295
2018-08-12 01:42:28,945 - INFO - epoch 0, step 9640, training loss = 3.211810, validation loss = 3.200031
2018-08-12 01:42:37,063 - INFO - epoch 0, step 9650, training loss = 3.430274, validation loss = 3.284204
2018-08-12 01:42:45,698 - INFO - epoch 0, step 9660, training loss = 3.281778, validation loss = 3.258902
2018-08-12 01:42:53,770 - INFO - epoch 0, step 9670, training loss = 3.583359, validation loss = 3.259083
2018-08-12 01:43:02,617 - INFO - epoch 0, step 9680, training loss = 2.820438, validation loss = 3.218024
2018-08-12 01:43:12,609 - INFO - epoch 0, step 9690, training loss = 2.645606, validation loss = 3.224280
2018-08-12 01:43:22,057 - INFO - epoch 0, step 9700, training loss = 2.809768, validation loss = 3.178185
2018-08-12 01:43:32,411 - INFO - epoch 0, step 9710, training loss = 2.799888, validation loss = 3.204655
2018-08-12 01:43:41,603 - INFO - epoch 0, step 9720, training loss = 3.225055, validation loss = 3.173874
2018-08-12 01:43:50,449 - INFO - epoch 0, step 9730, training loss = 3.373056, validation loss = 3.111928
2018-08-12 01:44:00,825 - INFO - epoch 0, step 9740, training loss = 3.008732, validation loss = 3.268684
2018-08-12 01:44:10,845 - INFO - epoch 0, step 9750, training loss = 2.638222, validation loss = 3.150395
2018-08-12 01:44:20,628 - INFO - epoch 0, step 9760, training loss = 2.172347, validation loss = 3.215391
2018-08-12 01:44:28,869 - INFO - epoch 0, step 9770, training loss = 3.150825, validation loss = 3.106215
2018-08-12 01:44:35,651 - INFO - epoch 0, step 9780, training loss = 3.488625, validation loss = 3.060937
2018-08-12 01:44:42,135 - INFO - epoch 0, step 9790, training loss = 3.722791, validation loss = 3.091474
2018-08-12 01:44:48,859 - INFO - epoch 0, step 9800, training loss = 3.715522, validation loss = 3.080527
2018-08-12 01:44:55,162 - INFO - epoch 0, step 9810, training loss = 3.678995, validation loss = 3.081257
2018-08-12 01:45:02,090 - INFO - epoch 0, step 9820, training loss = 2.627117, validation loss = 3.120619
2018-08-12 01:45:10,174 - INFO - epoch 0, step 9830, training loss = 3.134830, validation loss = 3.207760
2018-08-12 01:45:19,311 - INFO - epoch 0, step 9840, training loss = 2.785893, validation loss = 3.252451
2018-08-12 01:45:28,172 - INFO - epoch 0, step 9850, training loss = 2.582699, validation loss = 3.209690
2018-08-12 01:45:37,436 - INFO - epoch 0, step 9860, training loss = 2.992271, validation loss = 3.209743
2018-08-12 01:45:47,492 - INFO - epoch 0, step 9870, training loss = 2.822462, validation loss = 3.197155
2018-08-12 01:45:56,199 - INFO - epoch 0, step 9880, training loss = 2.525894, validation loss = 3.208081
2018-08-12 01:46:05,643 - INFO - epoch 0, step 9890, training loss = 2.742761, validation loss = 3.202297
2018-08-12 01:46:14,899 - INFO - epoch 0, step 9900, training loss = 3.095058, validation loss = 3.206270
2018-08-12 01:46:24,036 - INFO - epoch 0, step 9910, training loss = 2.762610, validation loss = 3.263633
2018-08-12 01:46:33,162 - INFO - epoch 0, step 9920, training loss = 2.743465, validation loss = 3.198625
2018-08-12 01:46:42,283 - INFO - epoch 0, step 9930, training loss = 2.630775, validation loss = 3.227994
2018-08-12 01:46:50,957 - INFO - epoch 0, step 9940, training loss = 4.057164, validation loss = 3.191113
2018-08-12 01:46:57,187 - INFO - epoch 0, step 9950, training loss = 3.765652, validation loss = 3.083652
2018-08-12 01:47:02,293 - INFO - epoch 0, step 9960, training loss = 3.958208, validation loss = 3.135196
2018-08-12 01:47:07,377 - INFO - epoch 0, step 9970, training loss = 3.357552, validation loss = 3.167129
2018-08-12 01:47:12,350 - INFO - epoch 0, step 9980, training loss = 3.647592, validation loss = 3.153382
2018-08-12 01:47:17,369 - INFO - epoch 0, step 9990, training loss = 3.716571, validation loss = 3.147265
2018-08-12 01:47:22,411 - INFO - epoch 0, step 10000, training loss = 3.873083, validation loss = 3.138280
2018-08-12 01:47:27,456 - INFO - epoch 0, step 10010, training loss = 3.489231, validation loss = 3.148105
2018-08-12 01:47:32,351 - INFO - epoch 0, step 10020, training loss = 3.664030, validation loss = 3.163909
2018-08-12 01:47:37,266 - INFO - epoch 0, step 10030, training loss = 4.135160, validation loss = 3.119628
2018-08-12 01:47:42,214 - INFO - epoch 0, step 10040, training loss = 3.499415, validation loss = 3.126177
2018-08-12 01:47:47,293 - INFO - epoch 0, step 10050, training loss = 3.745373, validation loss = 3.144929
2018-08-12 01:47:52,271 - INFO - epoch 0, step 10060, training loss = 3.294949, validation loss = 3.149095
2018-08-12 01:47:57,160 - INFO - epoch 0, step 10070, training loss = 3.527925, validation loss = 3.154142
2018-08-12 01:48:02,264 - INFO - epoch 0, step 10080, training loss = 3.560206, validation loss = 3.154948
2018-08-12 01:48:07,096 - INFO - epoch 0, step 10090, training loss = 3.624533, validation loss = 3.190791
2018-08-12 01:48:11,747 - INFO - epoch 0, step 10100, training loss = 2.880400, validation loss = 3.168366
2018-08-12 01:48:16,719 - INFO - epoch 0, step 10110, training loss = 3.381890, validation loss = 3.170383
2018-08-12 01:48:23,606 - INFO - epoch 0, step 10120, training loss = 3.348017, validation loss = 3.180427
2018-08-12 01:48:30,208 - INFO - epoch 0, step 10130, training loss = 3.444880, validation loss = 3.143666
2018-08-12 01:48:37,571 - INFO - epoch 0, step 10140, training loss = 3.042365, validation loss = 3.160946
2018-08-12 01:48:44,503 - INFO - epoch 0, step 10150, training loss = 3.279618, validation loss = 3.142440
2018-08-12 01:48:51,403 - INFO - epoch 0, step 10160, training loss = 2.714772, validation loss = 3.138515
2018-08-12 01:48:58,192 - INFO - epoch 0, step 10170, training loss = 3.197369, validation loss = 3.116233
2018-08-12 01:49:04,922 - INFO - epoch 0, step 10180, training loss = 3.340901, validation loss = 3.153347
2018-08-12 01:49:11,416 - INFO - epoch 0, step 10190, training loss = 2.943803, validation loss = 3.113414
2018-08-12 01:49:18,334 - INFO - epoch 0, step 10200, training loss = 3.033821, validation loss = 3.127235
2018-08-12 01:49:26,030 - INFO - epoch 0, step 10210, training loss = 2.848892, validation loss = 3.135647
2018-08-12 01:49:32,719 - INFO - epoch 0, step 10220, training loss = 3.375562, validation loss = 3.196650
2018-08-12 01:49:39,713 - INFO - epoch 0, step 10230, training loss = 2.711305, validation loss = 3.162874
2018-08-12 01:49:47,130 - INFO - epoch 0, step 10240, training loss = 3.469481, validation loss = 3.239132
2018-08-12 01:49:55,643 - INFO - epoch 0, step 10250, training loss = 3.025811, validation loss = 3.311805
2018-08-12 01:50:03,786 - INFO - epoch 0, step 10260, training loss = 3.393982, validation loss = 3.247131
2018-08-12 01:50:12,104 - INFO - epoch 0, step 10270, training loss = 3.587275, validation loss = 3.283636
2018-08-12 01:50:20,605 - INFO - epoch 0, step 10280, training loss = 3.368656, validation loss = 3.263198
2018-08-12 01:50:28,756 - INFO - epoch 0, step 10290, training loss = 3.398753, validation loss = 3.257921
2018-08-12 01:50:36,983 - INFO - epoch 0, step 10300, training loss = 3.367422, validation loss = 3.239746
2018-08-12 01:50:45,106 - INFO - epoch 0, step 10310, training loss = 3.878839, validation loss = 3.222514
2018-08-12 01:50:50,800 - INFO - epoch 0, step 10320, training loss = 3.688203, validation loss = 3.063336
2018-08-12 01:50:56,419 - INFO - epoch 0, step 10330, training loss = 3.595903, validation loss = 3.094566
2018-08-12 01:51:02,168 - INFO - epoch 0, step 10340, training loss = 3.671597, validation loss = 3.106478
2018-08-12 01:51:07,829 - INFO - epoch 0, step 10350, training loss = 3.128446, validation loss = 3.112754
2018-08-12 01:51:13,550 - INFO - epoch 0, step 10360, training loss = 2.924521, validation loss = 3.105773
2018-08-12 01:51:20,501 - INFO - epoch 0, step 10370, training loss = 2.787142, validation loss = 3.265384
2018-08-12 01:51:27,065 - INFO - epoch 0, step 10380, training loss = 3.221879, validation loss = 3.114585
2018-08-12 01:51:34,202 - INFO - epoch 0, step 10390, training loss = 2.286036, validation loss = 3.157399
2018-08-12 01:51:40,817 - INFO - epoch 0, step 10400, training loss = 3.386863, validation loss = 3.091569
2018-08-12 01:51:45,835 - INFO - epoch 0, step 10410, training loss = 3.653840, validation loss = 3.144961
2018-08-12 01:51:50,828 - INFO - epoch 0, step 10420, training loss = 2.893300, validation loss = 3.133237
2018-08-12 01:51:55,729 - INFO - epoch 0, step 10430, training loss = 3.119507, validation loss = 3.128647
2018-08-12 01:52:00,586 - INFO - epoch 0, step 10440, training loss = 3.852954, validation loss = 3.144736
2018-08-12 01:52:05,599 - INFO - epoch 0, step 10450, training loss = 3.844710, validation loss = 3.157356
2018-08-12 01:52:10,698 - INFO - epoch 0, step 10460, training loss = 3.804609, validation loss = 3.145162
2018-08-12 01:52:15,421 - INFO - epoch 0, step 10470, training loss = 3.468675, validation loss = 3.148548
2018-08-12 01:52:22,725 - INFO - epoch 0, step 10480, training loss = 3.315816, validation loss = 3.112665
2018-08-12 01:52:32,726 - INFO - epoch 0, step 10490, training loss = 3.287946, validation loss = 3.313236
2018-08-12 01:52:42,275 - INFO - epoch 0, step 10500, training loss = 2.951191, validation loss = 3.233145
2018-08-12 01:52:52,731 - INFO - epoch 0, step 10510, training loss = 2.674872, validation loss = 3.203037
2018-08-12 01:53:02,701 - INFO - epoch 0, step 10520, training loss = 2.144195, validation loss = 3.233642
2018-08-12 01:53:11,281 - INFO - epoch 0, step 10530, training loss = 3.210557, validation loss = 3.219238
2018-08-12 01:53:20,204 - INFO - epoch 0, step 10540, training loss = 2.847383, validation loss = 3.243877
2018-08-12 01:53:28,106 - INFO - epoch 0, step 10550, training loss = 3.547486, validation loss = 3.269983
2018-08-12 01:53:36,346 - INFO - epoch 0, step 10560, training loss = 3.179927, validation loss = 3.288624
2018-08-12 01:53:44,569 - INFO - epoch 0, step 10570, training loss = 3.455987, validation loss = 3.239537
2018-08-12 01:53:52,506 - INFO - epoch 0, step 10580, training loss = 3.421134, validation loss = 3.281043
2018-08-12 01:54:00,663 - INFO - epoch 0, step 10590, training loss = 3.051131, validation loss = 3.265491
2018-08-12 01:54:08,938 - INFO - epoch 0, step 10600, training loss = 3.647135, validation loss = 3.267215
2018-08-12 01:54:17,122 - INFO - epoch 0, step 10610, training loss = 3.305175, validation loss = 3.252828
2018-08-12 01:54:25,506 - INFO - epoch 0, step 10620, training loss = 3.230712, validation loss = 3.290872
2018-08-12 01:54:33,326 - INFO - epoch 0, step 10630, training loss = 3.362809, validation loss = 3.211616
2018-08-12 01:54:42,463 - INFO - epoch 0, step 10640, training loss = 3.288613, validation loss = 3.317830
2018-08-12 01:54:50,950 - INFO - epoch 0, step 10650, training loss = 3.624842, validation loss = 3.308235
2018-08-12 01:54:59,043 - INFO - epoch 0, step 10660, training loss = 3.556962, validation loss = 3.354580
2018-08-12 01:55:07,638 - INFO - epoch 0, step 10670, training loss = 3.095055, validation loss = 3.377912
2018-08-12 01:55:16,074 - INFO - epoch 0, step 10680, training loss = 3.284490, validation loss = 3.395537
2018-08-12 01:55:24,590 - INFO - epoch 0, step 10690, training loss = 3.155867, validation loss = 3.412285
2018-08-12 01:55:32,901 - INFO - epoch 0, step 10700, training loss = 3.160455, validation loss = 3.354262
2018-08-12 01:55:40,939 - INFO - epoch 0, step 10710, training loss = 3.786227, validation loss = 3.430702
2018-08-12 01:55:50,074 - INFO - epoch 0, step 10720, training loss = 3.346921, validation loss = 3.380194
2018-08-12 01:55:58,319 - INFO - epoch 0, step 10730, training loss = 2.997392, validation loss = 3.391838
2018-08-12 01:56:07,483 - INFO - epoch 0, step 10740, training loss = 2.854481, validation loss = 3.414783
2018-08-12 01:56:16,324 - INFO - epoch 0, step 10750, training loss = 3.272958, validation loss = 3.421981
2018-08-12 01:56:22,068 - INFO - epoch 0, step 10760, training loss = 3.596713, validation loss = 3.093226
2018-08-12 01:56:26,994 - INFO - epoch 0, step 10770, training loss = 3.866100, validation loss = 3.139194
2018-08-12 01:56:32,198 - INFO - epoch 0, step 10780, training loss = 3.607923, validation loss = 3.154719
2018-08-12 01:56:37,240 - INFO - epoch 0, step 10790, training loss = 4.100854, validation loss = 3.158302
2018-08-12 01:56:42,359 - INFO - epoch 0, step 10800, training loss = 3.700517, validation loss = 3.155416
2018-08-12 01:56:47,406 - INFO - epoch 0, step 10810, training loss = 4.035110, validation loss = 3.156431
2018-08-12 01:56:52,793 - INFO - epoch 0, step 10820, training loss = 3.305881, validation loss = 3.149802
2018-08-12 01:57:00,507 - INFO - epoch 0, step 10830, training loss = 3.187540, validation loss = 3.244706
2018-08-12 01:57:08,315 - INFO - epoch 0, step 10840, training loss = 3.017518, validation loss = 3.179530
2018-08-12 01:57:15,770 - INFO - epoch 0, step 10850, training loss = 3.088537, validation loss = 3.234882
2018-08-12 01:57:23,481 - INFO - epoch 0, step 10860, training loss = 3.066003, validation loss = 3.203996
2018-08-12 01:57:31,286 - INFO - epoch 0, step 10870, training loss = 3.253401, validation loss = 3.213256
2018-08-12 01:57:38,131 - INFO - epoch 0, step 10880, training loss = 3.442338, validation loss = 3.211845
2018-08-12 01:57:45,371 - INFO - epoch 0, step 10890, training loss = 3.049865, validation loss = 3.212879
2018-08-12 01:57:53,235 - INFO - epoch 0, step 10900, training loss = 3.816766, validation loss = 3.235536
2018-08-12 01:58:00,619 - INFO - epoch 0, step 10910, training loss = 2.662717, validation loss = 3.238613
2018-08-12 01:58:08,591 - INFO - epoch 0, step 10920, training loss = 3.758072, validation loss = 3.270358
2018-08-12 01:58:15,286 - INFO - epoch 0, step 10930, training loss = 3.513385, validation loss = 3.203913
2018-08-12 01:58:21,557 - INFO - epoch 0, step 10940, training loss = 2.529088, validation loss = 3.271679
2018-08-12 01:58:24,962 - INFO - epoch 0, step 10950, training loss = 2.950869, validation loss = 3.423732
2018-08-12 01:58:27,900 - INFO - epoch 0, step 10960, training loss = 3.588316, validation loss = 3.358392
2018-08-12 01:58:30,823 - INFO - epoch 0, step 10970, training loss = 3.239911, validation loss = 3.558966
2018-08-12 01:58:33,556 - INFO - epoch 0, step 10980, training loss = 3.949645, validation loss = 3.499937
2018-08-12 01:58:36,362 - INFO - epoch 0, step 10990, training loss = 3.842798, validation loss = 3.605480
2018-08-12 01:58:39,194 - INFO - epoch 0, step 11000, training loss = 3.701720, validation loss = 3.504540
2018-08-12 01:58:42,100 - INFO - epoch 0, step 11010, training loss = 2.602810, validation loss = 3.561705
2018-08-12 01:58:45,186 - INFO - epoch 0, step 11020, training loss = 3.744164, validation loss = 3.533850
2018-08-12 01:58:49,645 - INFO - epoch 0, step 11030, training loss = 3.400558, validation loss = 3.177016
2018-08-12 01:58:55,732 - INFO - epoch 0, step 11040, training loss = 3.063638, validation loss = 3.156938
2018-08-12 01:59:03,056 - INFO - epoch 0, step 11050, training loss = 3.047307, validation loss = 3.148350
2018-08-12 01:59:09,939 - INFO - epoch 0, step 11060, training loss = 3.163907, validation loss = 3.209319
2018-08-12 01:59:17,420 - INFO - epoch 0, step 11070, training loss = 2.404742, validation loss = 3.216849
2018-08-12 01:59:24,692 - INFO - epoch 0, step 11080, training loss = 2.501213, validation loss = 3.153938
2018-08-12 01:59:31,652 - INFO - epoch 0, step 11090, training loss = 2.290666, validation loss = 3.187623
2018-08-12 01:59:38,362 - INFO - epoch 0, step 11100, training loss = 3.402035, validation loss = 3.121893
2018-08-12 01:59:45,694 - INFO - epoch 0, step 11110, training loss = 2.564658, validation loss = 3.159049
2018-08-12 01:59:55,242 - INFO - epoch 0, step 11120, training loss = 3.058765, validation loss = 3.304721
2018-08-12 02:00:05,471 - INFO - epoch 0, step 11130, training loss = 2.947687, validation loss = 3.185722
2018-08-12 02:00:15,528 - INFO - epoch 0, step 11140, training loss = 2.669255, validation loss = 3.238681
2018-08-12 02:00:26,259 - INFO - epoch 0, step 11150, training loss = 2.390669, validation loss = 3.216287
2018-08-12 02:00:36,062 - INFO - epoch 0, step 11160, training loss = 3.043797, validation loss = 3.212804
2018-08-12 02:00:46,044 - INFO - epoch 0, step 11170, training loss = 2.400160, validation loss = 3.253984
2018-08-12 02:00:55,788 - INFO - epoch 0, step 11180, training loss = 3.302797, validation loss = 3.226230
2018-08-12 02:01:05,797 - INFO - epoch 0, step 11190, training loss = 2.936589, validation loss = 3.225859
2018-08-12 02:01:14,752 - INFO - epoch 0, step 11200, training loss = 3.164149, validation loss = 3.213067
2018-08-12 02:01:24,370 - INFO - epoch 0, step 11210, training loss = 2.831256, validation loss = 3.222347
2018-08-12 02:01:34,586 - INFO - epoch 0, step 11220, training loss = 2.651111, validation loss = 3.281034
2018-08-12 02:01:43,916 - INFO - epoch 0, step 11230, training loss = 3.192450, validation loss = 3.238813
2018-08-12 02:01:53,027 - INFO - epoch 0, step 11240, training loss = 3.090664, validation loss = 3.209446
2018-08-12 02:02:02,014 - INFO - epoch 0, step 11250, training loss = 3.549757, validation loss = 3.247532
2018-08-12 02:02:11,689 - INFO - epoch 0, step 11260, training loss = 3.336509, validation loss = 3.273889
2018-08-12 02:02:21,229 - INFO - epoch 0, step 11270, training loss = 3.034387, validation loss = 3.259932
2018-08-12 02:02:30,803 - INFO - epoch 0, step 11280, training loss = 2.580104, validation loss = 3.272953
2018-08-12 02:02:40,754 - INFO - epoch 0, step 11290, training loss = 3.016723, validation loss = 3.271793
2018-08-12 02:02:49,657 - INFO - epoch 0, step 11300, training loss = 2.725346, validation loss = 3.292922
2018-08-12 02:02:57,659 - INFO - epoch 0, step 11310, training loss = 2.941696, validation loss = 3.099451
2018-08-12 02:03:04,329 - INFO - epoch 0, step 11320, training loss = 3.169239, validation loss = 3.116973
2018-08-12 02:03:11,083 - INFO - epoch 0, step 11330, training loss = 3.295991, validation loss = 3.134845
2018-08-12 02:03:17,768 - INFO - epoch 0, step 11340, training loss = 3.682589, validation loss = 3.135739
2018-08-12 02:03:23,189 - INFO - epoch 0, step 11350, training loss = 3.194709, validation loss = 3.114708
2018-08-12 02:03:28,588 - INFO - epoch 0, step 11360, training loss = 3.500468, validation loss = 3.143263
2018-08-12 02:03:34,007 - INFO - epoch 0, step 11370, training loss = 3.546943, validation loss = 3.128780
2018-08-12 02:03:39,729 - INFO - epoch 0, step 11380, training loss = 2.857475, validation loss = 3.131440
2018-08-12 02:03:45,404 - INFO - epoch 0, step 11390, training loss = 2.662641, validation loss = 3.380115
2018-08-12 02:03:51,228 - INFO - epoch 0, step 11400, training loss = 2.762920, validation loss = 3.329825
2018-08-12 02:03:57,172 - INFO - epoch 0, step 11410, training loss = 2.394192, validation loss = 3.135100
2018-08-12 02:04:02,331 - INFO - epoch 0, step 11420, training loss = 3.103898, validation loss = 3.111233
2018-08-12 02:04:07,589 - INFO - epoch 0, step 11430, training loss = 3.368611, validation loss = 3.147041
2018-08-12 02:04:12,775 - INFO - epoch 0, step 11440, training loss = 3.856780, validation loss = 3.142410
2018-08-12 02:04:17,865 - INFO - epoch 0, step 11450, training loss = 3.694707, validation loss = 3.151371
2018-08-12 02:04:22,874 - INFO - epoch 0, step 11460, training loss = 3.392992, validation loss = 3.162576
2018-08-12 02:04:27,868 - INFO - epoch 0, step 11470, training loss = 3.162593, validation loss = 3.161216
2018-08-12 02:04:32,909 - INFO - epoch 0, step 11480, training loss = 3.710546, validation loss = 3.167421
2018-08-12 02:04:38,064 - INFO - epoch 0, step 11490, training loss = 3.460585, validation loss = 3.156318
2018-08-12 02:04:42,927 - INFO - epoch 0, step 11500, training loss = 3.479598, validation loss = 3.167823
2018-08-12 02:04:49,653 - INFO - epoch 0, step 11510, training loss = 3.268240, validation loss = 3.125712
2018-08-12 02:04:56,417 - INFO - epoch 0, step 11520, training loss = 3.596838, validation loss = 3.143101
2018-08-12 02:05:03,583 - INFO - epoch 0, step 11530, training loss = 2.942863, validation loss = 3.210891
2018-08-12 02:05:10,462 - INFO - epoch 0, step 11540, training loss = 3.083280, validation loss = 3.169179
2018-08-12 02:05:16,994 - INFO - epoch 0, step 11550, training loss = 3.225754, validation loss = 3.173011
2018-08-12 02:05:23,338 - INFO - epoch 0, step 11560, training loss = 3.061891, validation loss = 3.170360
2018-08-12 02:05:28,005 - INFO - epoch 0, step 11570, training loss = 4.213463, validation loss = 3.424491
2018-08-12 02:05:31,866 - INFO - epoch 0, step 11580, training loss = 3.165016, validation loss = 3.391793
2018-08-12 02:05:35,538 - INFO - epoch 0, step 11590, training loss = 3.059670, validation loss = 3.511844
2018-08-12 02:05:39,304 - INFO - epoch 0, step 11600, training loss = 3.276813, validation loss = 3.513382
2018-08-12 02:05:43,178 - INFO - epoch 0, step 11610, training loss = 3.367213, validation loss = 3.500939
2018-08-12 02:05:46,961 - INFO - epoch 0, step 11620, training loss = 3.727479, validation loss = 3.504781
2018-08-12 02:05:50,709 - INFO - epoch 0, step 11630, training loss = 3.516863, validation loss = 3.566597
2018-08-12 02:05:54,438 - INFO - epoch 0, step 11640, training loss = 3.939929, validation loss = 3.646079
2018-08-12 02:05:59,574 - INFO - epoch 0, step 11650, training loss = 3.993157, validation loss = 3.250983
2018-08-12 02:06:04,766 - INFO - epoch 0, step 11660, training loss = 3.675690, validation loss = 3.199771
2018-08-12 02:06:09,802 - INFO - epoch 0, step 11670, training loss = 3.617985, validation loss = 3.208720
2018-08-12 02:06:14,786 - INFO - epoch 0, step 11680, training loss = 4.302022, validation loss = 3.196922
2018-08-12 02:06:19,913 - INFO - epoch 0, step 11690, training loss = 3.452623, validation loss = 3.219081
2018-08-12 02:06:24,517 - INFO - epoch 0, step 11700, training loss = 3.763973, validation loss = 3.204999
2018-08-12 02:06:29,734 - INFO - epoch 0, step 11710, training loss = 3.165558, validation loss = 3.234583
2018-08-12 02:06:35,498 - INFO - epoch 0, step 11720, training loss = 3.149188, validation loss = 3.525277
2018-08-12 02:06:41,177 - INFO - epoch 0, step 11730, training loss = 2.525626, validation loss = 3.364964
2018-08-12 02:06:50,277 - INFO - epoch 0, step 11740, training loss = 2.780614, validation loss = 3.227970
2018-08-12 02:06:59,166 - INFO - epoch 0, step 11750, training loss = 2.824067, validation loss = 3.214366
2018-08-12 02:07:07,808 - INFO - epoch 0, step 11760, training loss = 2.849393, validation loss = 3.140076
2018-08-12 02:07:14,558 - INFO - epoch 0, step 11770, training loss = 3.209074, validation loss = 3.174183
2018-08-12 02:07:21,616 - INFO - epoch 0, step 11780, training loss = 3.188030, validation loss = 3.175240
2018-08-12 02:07:28,118 - INFO - epoch 0, step 11790, training loss = 2.868570, validation loss = 3.137949
2018-08-12 02:07:34,971 - INFO - epoch 0, step 11800, training loss = 3.406947, validation loss = 3.190188
2018-08-12 02:07:41,288 - INFO - epoch 0, step 11810, training loss = 2.744649, validation loss = 3.179439
2018-08-12 02:07:48,221 - INFO - epoch 0, step 11820, training loss = 3.257001, validation loss = 3.181515
2018-08-12 02:07:54,912 - INFO - epoch 0, step 11830, training loss = 3.526636, validation loss = 3.157633
2018-08-12 02:08:01,438 - INFO - epoch 0, step 11840, training loss = 3.302384, validation loss = 3.180911
2018-08-12 02:08:08,453 - INFO - epoch 0, step 11850, training loss = 2.791754, validation loss = 3.193380
2018-08-12 02:08:16,596 - INFO - epoch 0, step 11860, training loss = 3.235845, validation loss = 3.251431
2018-08-12 02:08:24,125 - INFO - epoch 0, step 11870, training loss = 3.390281, validation loss = 3.233855
2018-08-12 02:08:31,797 - INFO - epoch 0, step 11880, training loss = 3.365953, validation loss = 3.279097
2018-08-12 02:08:39,806 - INFO - epoch 0, step 11890, training loss = 3.291363, validation loss = 3.250354
2018-08-12 02:08:47,724 - INFO - epoch 0, step 11900, training loss = 3.735036, validation loss = 3.259946
2018-08-12 02:08:56,284 - INFO - epoch 0, step 11910, training loss = 2.414925, validation loss = 3.265793
2018-08-12 02:09:04,399 - INFO - epoch 0, step 11920, training loss = 3.480024, validation loss = 3.297995
2018-08-12 02:09:12,592 - INFO - epoch 0, step 11930, training loss = 3.104303, validation loss = 3.255663
2018-08-12 02:09:20,726 - INFO - epoch 0, step 11940, training loss = 3.222376, validation loss = 3.289645
2018-08-12 02:09:29,479 - INFO - epoch 0, step 11950, training loss = 3.510989, validation loss = 3.240960
2018-08-12 02:09:37,377 - INFO - epoch 0, step 11960, training loss = 3.038238, validation loss = 3.294145
2018-08-12 02:09:45,119 - INFO - epoch 0, step 11970, training loss = 2.976151, validation loss = 3.147130
2018-08-12 02:09:52,976 - INFO - epoch 0, step 11980, training loss = 3.122176, validation loss = 3.205972
2018-08-12 02:10:00,648 - INFO - epoch 0, step 11990, training loss = 2.847436, validation loss = 3.232328
2018-08-12 02:10:08,119 - INFO - epoch 0, step 12000, training loss = 3.105400, validation loss = 3.215371
2018-08-12 02:10:15,878 - INFO - epoch 0, step 12010, training loss = 2.699918, validation loss = 3.319336
2018-08-12 02:10:25,688 - INFO - epoch 0, step 12020, training loss = 2.921614, validation loss = 3.314611
2018-08-12 02:10:35,437 - INFO - epoch 0, step 12030, training loss = 2.468853, validation loss = 3.250364
2018-08-12 02:10:46,074 - INFO - epoch 0, step 12040, training loss = 2.360296, validation loss = 3.235576
2018-08-12 02:10:56,277 - INFO - epoch 0, step 12050, training loss = 2.187543, validation loss = 3.299714
2018-08-12 02:11:05,919 - INFO - epoch 0, step 12060, training loss = 2.646209, validation loss = 3.286078
2018-08-12 02:11:15,774 - INFO - epoch 0, step 12070, training loss = 2.373661, validation loss = 3.278790
2018-08-12 02:11:25,096 - INFO - epoch 0, step 12080, training loss = 2.791599, validation loss = 3.272656
2018-08-12 02:11:34,781 - INFO - epoch 0, step 12090, training loss = 2.579753, validation loss = 3.262275
2018-08-12 02:11:44,623 - INFO - epoch 0, step 12100, training loss = 2.560097, validation loss = 3.255207
2018-08-12 02:11:54,707 - INFO - epoch 0, step 12110, training loss = 2.115997, validation loss = 3.223366
2018-08-12 02:12:04,569 - INFO - epoch 0, step 12120, training loss = 3.989859, validation loss = 3.267668
2018-08-12 02:12:09,467 - INFO - epoch 0, step 12130, training loss = 3.516493, validation loss = 3.139466
2018-08-12 02:12:14,807 - INFO - epoch 0, step 12140, training loss = 3.025315, validation loss = 3.181823
2018-08-12 02:12:19,952 - INFO - epoch 0, step 12150, training loss = 3.630224, validation loss = 3.163903
2018-08-12 02:12:24,871 - INFO - epoch 0, step 12160, training loss = 3.835378, validation loss = 3.199800
2018-08-12 02:12:29,926 - INFO - epoch 0, step 12170, training loss = 3.821560, validation loss = 3.184406
2018-08-12 02:12:34,899 - INFO - epoch 0, step 12180, training loss = 3.561584, validation loss = 3.177320
2018-08-12 02:12:40,026 - INFO - epoch 0, step 12190, training loss = 3.686069, validation loss = 3.197180
2018-08-12 02:12:45,168 - INFO - epoch 0, step 12200, training loss = 3.523400, validation loss = 3.187396
2018-08-12 02:12:50,261 - INFO - epoch 0, step 12210, training loss = 3.910891, validation loss = 3.199345
2018-08-12 02:12:55,225 - INFO - epoch 0, step 12220, training loss = 3.384620, validation loss = 3.207301
2018-08-12 02:12:59,995 - INFO - epoch 0, step 12230, training loss = 4.434765, validation loss = 3.198849
2018-08-12 02:13:04,877 - INFO - epoch 0, step 12240, training loss = 3.483808, validation loss = 3.192723
2018-08-12 02:13:10,461 - INFO - epoch 0, step 12250, training loss = 3.381716, validation loss = 3.188610
2018-08-12 02:13:15,431 - INFO - epoch 0, step 12260, training loss = 3.998998, validation loss = 3.194479
2018-08-12 02:13:20,286 - INFO - epoch 0, step 12270, training loss = 3.328635, validation loss = 3.181660
2018-08-12 02:13:25,416 - INFO - epoch 0, step 12280, training loss = 3.450181, validation loss = 3.184755
2018-08-12 02:13:30,594 - INFO - epoch 0, step 12290, training loss = 2.999786, validation loss = 3.195961
2018-08-12 02:13:35,531 - INFO - epoch 0, step 12300, training loss = 4.126205, validation loss = 3.187010
2018-08-12 02:13:40,393 - INFO - epoch 0, step 12310, training loss = 4.198303, validation loss = 3.202807
2018-08-12 02:13:45,471 - INFO - epoch 0, step 12320, training loss = 3.715427, validation loss = 3.192838
2018-08-12 02:13:51,434 - INFO - epoch 0, step 12330, training loss = 3.259427, validation loss = 3.192020
2018-08-12 02:13:56,313 - INFO - epoch 0, step 12340, training loss = 4.160761, validation loss = 3.179844
2018-08-12 02:14:01,124 - INFO - epoch 0, step 12350, training loss = 4.164184, validation loss = 3.194124
2018-08-12 02:14:06,030 - INFO - epoch 0, step 12360, training loss = 3.653941, validation loss = 3.211836
2018-08-12 02:14:11,136 - INFO - epoch 0, step 12370, training loss = 3.390136, validation loss = 3.214315
2018-08-12 02:14:15,948 - INFO - epoch 0, step 12380, training loss = 3.975597, validation loss = 3.228512
2018-08-12 02:14:21,102 - INFO - epoch 0, step 12390, training loss = 3.656626, validation loss = 3.189637
2018-08-12 02:14:26,330 - INFO - epoch 0, step 12400, training loss = 3.113256, validation loss = 3.195069
2018-08-12 02:14:32,682 - INFO - epoch 0, step 12410, training loss = 3.667008, validation loss = 3.211111
2018-08-12 02:14:37,362 - INFO - epoch 0, step 12420, training loss = 4.085654, validation loss = 3.198411
2018-08-12 02:14:42,848 - INFO - epoch 0, step 12430, training loss = 2.755309, validation loss = 3.208330
2018-08-12 02:14:47,936 - INFO - epoch 0, step 12440, training loss = 3.125147, validation loss = 3.212271
2018-08-12 02:14:54,719 - INFO - epoch 0, step 12450, training loss = 2.998761, validation loss = 3.173665
2018-08-12 02:15:01,385 - INFO - epoch 0, step 12460, training loss = 3.283487, validation loss = 3.180100
2018-08-12 02:15:08,490 - INFO - epoch 0, step 12470, training loss = 2.906400, validation loss = 3.165900
2018-08-12 02:15:16,576 - INFO - epoch 0, step 12480, training loss = 4.060816, validation loss = 3.460721
2018-08-12 02:15:25,718 - INFO - epoch 0, step 12490, training loss = 3.617505, validation loss = 3.522434
2018-08-12 02:15:34,509 - INFO - epoch 0, step 12500, training loss = 3.438627, validation loss = 3.492110
2018-08-12 02:15:43,391 - INFO - epoch 0, step 12510, training loss = 4.132246, validation loss = 3.503199
2018-08-12 02:15:52,761 - INFO - epoch 0, step 12520, training loss = 3.293044, validation loss = 3.478718
2018-08-12 02:16:01,376 - INFO - epoch 0, step 12530, training loss = 2.980344, validation loss = 3.511734
2018-08-12 02:16:10,137 - INFO - epoch 0, step 12540, training loss = 3.731183, validation loss = 3.499092
2018-08-12 02:16:19,026 - INFO - epoch 0, step 12550, training loss = 3.513215, validation loss = 3.500443
2018-08-12 02:16:27,794 - INFO - epoch 0, step 12560, training loss = 3.727464, validation loss = 3.494296
2018-08-12 02:16:36,700 - INFO - epoch 0, step 12570, training loss = 3.394026, validation loss = 3.508084
2018-08-12 02:16:44,915 - INFO - epoch 0, step 12580, training loss = 4.116934, validation loss = 3.461356
2018-08-12 02:16:50,751 - INFO - epoch 0, step 12590, training loss = 3.868126, validation loss = 3.153853
2018-08-12 02:16:56,333 - INFO - epoch 0, step 12600, training loss = 3.625393, validation loss = 3.171721
2018-08-12 02:17:01,831 - INFO - epoch 0, step 12610, training loss = 3.190183, validation loss = 3.140614
2018-08-12 02:17:07,739 - INFO - epoch 0, step 12620, training loss = 3.007279, validation loss = 3.154244
2018-08-12 02:17:13,112 - INFO - epoch 0, step 12630, training loss = 3.547469, validation loss = 3.154751
2018-08-12 02:17:21,137 - INFO - epoch 0, step 12640, training loss = 3.288964, validation loss = 3.187660
2018-08-12 02:17:30,297 - INFO - epoch 0, step 12650, training loss = 3.009999, validation loss = 3.357351
2018-08-12 02:17:39,529 - INFO - epoch 0, step 12660, training loss = 3.008236, validation loss = 3.210159
2018-08-12 02:17:47,347 - INFO - epoch 0, step 12670, training loss = 3.031889, validation loss = 3.249955
2018-08-12 02:17:57,348 - INFO - epoch 0, step 12680, training loss = 3.074586, validation loss = 3.249817
2018-08-12 02:18:05,598 - INFO - epoch 0, step 12690, training loss = 3.154030, validation loss = 3.243968
2018-08-12 02:18:13,915 - INFO - epoch 0, step 12700, training loss = 3.174078, validation loss = 3.251712
2018-08-12 02:18:21,506 - INFO - epoch 0, step 12710, training loss = 2.999957, validation loss = 3.274111
2018-08-12 02:18:28,093 - INFO - epoch 0, step 12720, training loss = 2.857299, validation loss = 3.248443
2018-08-12 02:18:35,533 - INFO - epoch 0, step 12730, training loss = 3.186107, validation loss = 3.202463
2018-08-12 02:18:39,215 - INFO - epoch 0, step 12740, training loss = 2.866856, validation loss = 3.145064
2018-08-12 02:18:43,204 - INFO - epoch 0, step 12750, training loss = 4.081001, validation loss = 3.188415
2018-08-12 02:18:46,964 - INFO - epoch 0, step 12760, training loss = 3.647657, validation loss = 3.185689
2018-08-12 02:18:50,724 - INFO - epoch 0, step 12770, training loss = 3.660593, validation loss = 3.208952
2018-08-12 02:18:54,454 - INFO - epoch 0, step 12780, training loss = 3.381570, validation loss = 3.207564
2018-08-12 02:18:58,508 - INFO - epoch 0, step 12790, training loss = 3.598093, validation loss = 3.205967
2018-08-12 02:19:07,702 - INFO - epoch 0, step 12800, training loss = 2.854908, validation loss = 3.204969
2018-08-12 02:19:17,557 - INFO - epoch 0, step 12810, training loss = 2.995147, validation loss = 3.344149
2018-08-12 02:19:27,002 - INFO - epoch 0, step 12820, training loss = 2.977962, validation loss = 3.195748
2018-08-12 02:19:35,601 - INFO - epoch 0, step 12830, training loss = 2.717238, validation loss = 3.264840
2018-08-12 02:19:45,731 - INFO - epoch 0, step 12840, training loss = 2.333527, validation loss = 3.247815
2018-08-12 02:19:55,835 - INFO - epoch 0, step 12850, training loss = 2.887258, validation loss = 3.270050
2018-08-12 02:20:04,909 - INFO - epoch 0, step 12860, training loss = 2.498159, validation loss = 3.259452
2018-08-12 02:20:14,985 - INFO - epoch 0, step 12870, training loss = 1.952808, validation loss = 3.288012
2018-08-12 02:20:22,778 - INFO - epoch 0, step 12880, training loss = 3.622386, validation loss = 3.164633
2018-08-12 02:20:29,417 - INFO - epoch 0, step 12890, training loss = 2.902141, validation loss = 3.128072
2018-08-12 02:20:36,219 - INFO - epoch 0, step 12900, training loss = 2.948394, validation loss = 3.170361
2018-08-12 02:20:42,082 - INFO - epoch 0, step 12910, training loss = 3.653718, validation loss = 3.106342
2018-08-12 02:20:47,291 - INFO - epoch 0, step 12920, training loss = 3.755270, validation loss = 3.151820
2018-08-12 02:20:52,279 - INFO - epoch 0, step 12930, training loss = 3.350957, validation loss = 3.179583
2018-08-12 02:20:57,181 - INFO - epoch 0, step 12940, training loss = 3.207382, validation loss = 3.166820
2018-08-12 02:21:02,044 - INFO - epoch 0, step 12950, training loss = 3.370537, validation loss = 3.158764
2018-08-12 02:21:06,705 - INFO - epoch 0, step 12960, training loss = 3.448633, validation loss = 3.161072
2018-08-12 02:21:11,842 - INFO - epoch 0, step 12970, training loss = 3.719459, validation loss = 3.163543
2018-08-12 02:21:18,557 - INFO - epoch 0, step 12980, training loss = 3.261031, validation loss = 3.189517
2018-08-12 02:21:27,137 - INFO - epoch 0, step 12990, training loss = 3.129852, validation loss = 3.505145
2018-08-12 02:21:36,043 - INFO - epoch 0, step 13000, training loss = 3.286392, validation loss = 3.376971
2018-08-12 02:21:44,905 - INFO - epoch 0, step 13010, training loss = 2.785600, validation loss = 3.358259
2018-08-12 02:21:53,537 - INFO - epoch 0, step 13020, training loss = 3.465135, validation loss = 3.346083
2018-08-12 02:22:02,168 - INFO - epoch 0, step 13030, training loss = 3.445238, validation loss = 3.394326
2018-08-12 02:22:10,452 - INFO - epoch 0, step 13040, training loss = 3.717955, validation loss = 3.337335
2018-08-12 02:22:18,978 - INFO - epoch 0, step 13050, training loss = 3.092745, validation loss = 3.426793
2018-08-12 02:22:27,023 - INFO - epoch 0, step 13060, training loss = 3.397619, validation loss = 3.311886
2018-08-12 02:22:35,585 - INFO - epoch 0, step 13070, training loss = 3.079758, validation loss = 3.417525
2018-08-12 02:22:44,268 - INFO - epoch 0, step 13080, training loss = 2.868882, validation loss = 3.402953
2018-08-12 02:22:53,657 - INFO - epoch 0, step 13090, training loss = 2.567594, validation loss = 3.335639
2018-08-12 02:23:03,474 - INFO - epoch 0, step 13100, training loss = 3.285970, validation loss = 3.180470
2018-08-12 02:23:12,929 - INFO - epoch 0, step 13110, training loss = 3.284316, validation loss = 3.235434
2018-08-12 02:23:21,941 - INFO - epoch 0, step 13120, training loss = 2.889340, validation loss = 3.185893
2018-08-12 02:23:30,952 - INFO - epoch 0, step 13130, training loss = 2.800771, validation loss = 3.213676
2018-08-12 02:23:40,393 - INFO - epoch 0, step 13140, training loss = 2.917697, validation loss = 3.233647
2018-08-12 02:23:50,054 - INFO - epoch 0, step 13150, training loss = 2.909519, validation loss = 3.190852
2018-08-12 02:23:58,788 - INFO - epoch 0, step 13160, training loss = 3.425408, validation loss = 3.362904
2018-08-12 02:24:07,390 - INFO - epoch 0, step 13170, training loss = 3.106287, validation loss = 3.361149
2018-08-12 02:24:15,637 - INFO - epoch 0, step 13180, training loss = 3.496597, validation loss = 3.389789
2018-08-12 02:24:24,503 - INFO - epoch 0, step 13190, training loss = 3.162040, validation loss = 3.337134
2018-08-12 02:24:33,365 - INFO - epoch 0, step 13200, training loss = 3.180897, validation loss = 3.374411
2018-08-12 02:24:42,415 - INFO - epoch 0, step 13210, training loss = 2.970477, validation loss = 3.392989
2018-08-12 02:24:50,689 - INFO - epoch 0, step 13220, training loss = 3.279178, validation loss = 3.355319
2018-08-12 02:24:59,307 - INFO - epoch 0, step 13230, training loss = 3.420135, validation loss = 3.412085
2018-08-12 02:25:05,794 - INFO - epoch 0, step 13240, training loss = 3.972519, validation loss = 3.200305
2018-08-12 02:25:11,006 - INFO - epoch 0, step 13250, training loss = 3.039697, validation loss = 3.357686
2018-08-12 02:25:16,647 - INFO - epoch 0, step 13260, training loss = 2.960052, validation loss = 3.227486
2018-08-12 02:25:21,936 - INFO - epoch 0, step 13270, training loss = 2.813195, validation loss = 3.357413
2018-08-12 02:25:26,998 - INFO - epoch 0, step 13280, training loss = 3.750333, validation loss = 3.140667
2018-08-12 02:25:31,965 - INFO - epoch 0, step 13290, training loss = 4.095519, validation loss = 3.169889
2018-08-12 02:25:36,915 - INFO - epoch 0, step 13300, training loss = 3.801196, validation loss = 3.187124
2018-08-12 02:25:41,823 - INFO - epoch 0, step 13310, training loss = 4.060471, validation loss = 3.186621
2018-08-12 02:25:46,753 - INFO - epoch 0, step 13320, training loss = 4.082065, validation loss = 3.174664
2018-08-12 02:25:51,822 - INFO - epoch 0, step 13330, training loss = 3.452653, validation loss = 3.188516
2018-08-12 02:25:56,788 - INFO - epoch 0, step 13340, training loss = 3.960182, validation loss = 3.197525
2018-08-12 02:26:01,720 - INFO - epoch 0, step 13350, training loss = 3.513178, validation loss = 3.178708
2018-08-12 02:26:08,310 - INFO - epoch 0, step 13360, training loss = 2.844841, validation loss = 3.176579
2018-08-12 02:26:17,965 - INFO - epoch 0, step 13370, training loss = 2.919743, validation loss = 3.227229
2018-08-12 02:26:28,029 - INFO - epoch 0, step 13380, training loss = 2.948743, validation loss = 3.240582
2018-08-12 02:26:37,199 - INFO - epoch 0, step 13390, training loss = 2.886408, validation loss = 3.196555
2018-08-12 02:26:46,468 - INFO - epoch 0, step 13400, training loss = 2.865162, validation loss = 3.208058
2018-08-12 02:26:55,680 - INFO - epoch 0, step 13410, training loss = 2.885982, validation loss = 3.214885
2018-08-12 02:27:05,298 - INFO - epoch 0, step 13420, training loss = 2.555749, validation loss = 3.195450
2018-08-12 02:27:14,200 - INFO - epoch 0, step 13430, training loss = 3.385972, validation loss = 3.403028
2018-08-12 02:27:22,934 - INFO - epoch 0, step 13440, training loss = 3.495740, validation loss = 3.376832
2018-08-12 02:27:31,651 - INFO - epoch 0, step 13450, training loss = 3.173107, validation loss = 3.384599
2018-08-12 02:27:40,330 - INFO - epoch 0, step 13460, training loss = 3.466825, validation loss = 3.399594
2018-08-12 02:27:49,042 - INFO - epoch 0, step 13470, training loss = 3.457074, validation loss = 3.419278
2018-08-12 02:27:57,719 - INFO - epoch 0, step 13480, training loss = 3.202155, validation loss = 3.379411
2018-08-12 02:28:06,867 - INFO - epoch 0, step 13490, training loss = 2.811518, validation loss = 3.420122
2018-08-12 02:28:15,692 - INFO - epoch 0, step 13500, training loss = 3.601641, validation loss = 3.443520
2018-08-12 02:28:24,349 - INFO - epoch 0, step 13510, training loss = 2.882622, validation loss = 3.428784
2018-08-12 02:28:32,572 - INFO - epoch 0, step 13520, training loss = 3.671389, validation loss = 3.422717
2018-08-12 02:28:40,585 - INFO - epoch 0, step 13530, training loss = 3.698171, validation loss = 3.406625
2018-08-12 02:28:47,552 - INFO - epoch 0, step 13540, training loss = 3.196741, validation loss = 3.135281
2018-08-12 02:28:54,049 - INFO - epoch 0, step 13550, training loss = 2.839541, validation loss = 3.118957
2018-08-12 02:29:00,373 - INFO - epoch 0, step 13560, training loss = 3.077199, validation loss = 3.123759
2018-08-12 02:29:06,288 - INFO - epoch 0, step 13570, training loss = 3.040578, validation loss = 3.267732
2018-08-12 02:29:11,987 - INFO - epoch 0, step 13580, training loss = 2.927544, validation loss = 3.213521
2018-08-12 02:29:20,003 - INFO - epoch 0, step 13590, training loss = 3.483030, validation loss = 3.223811
2018-08-12 02:29:28,499 - INFO - epoch 0, step 13600, training loss = 3.370343, validation loss = 3.199008
2018-08-12 02:29:36,900 - INFO - epoch 0, step 13610, training loss = 3.370950, validation loss = 3.183171
2018-08-12 02:29:45,450 - INFO - epoch 0, step 13620, training loss = 3.011627, validation loss = 3.194004
2018-08-12 02:29:54,513 - INFO - epoch 0, step 13630, training loss = 2.246227, validation loss = 3.186483
2018-08-12 02:30:02,863 - INFO - epoch 0, step 13640, training loss = 3.407157, validation loss = 3.203536
2018-08-12 02:30:10,289 - INFO - epoch 0, step 13650, training loss = 3.074288, validation loss = 3.132306
2018-08-12 02:30:17,478 - INFO - epoch 0, step 13660, training loss = 2.945069, validation loss = 3.080205
2018-08-12 02:30:24,923 - INFO - epoch 0, step 13670, training loss = 2.407147, validation loss = 3.134799
2018-08-12 02:30:31,471 - INFO - epoch 0, step 13680, training loss = 3.151190, validation loss = 3.106639
2018-08-12 02:30:38,477 - INFO - epoch 0, step 13690, training loss = 3.335888, validation loss = 3.132411
2018-08-12 02:30:44,960 - INFO - epoch 0, step 13700, training loss = 3.806547, validation loss = 3.109535
2018-08-12 02:30:49,626 - INFO - epoch 0, step 13710, training loss = 3.778608, validation loss = 3.117114
2018-08-12 02:30:54,745 - INFO - epoch 0, step 13720, training loss = 3.782071, validation loss = 3.148519
2018-08-12 02:30:59,915 - INFO - epoch 0, step 13730, training loss = 3.970552, validation loss = 3.138131
2018-08-12 02:31:04,841 - INFO - epoch 0, step 13740, training loss = 3.534524, validation loss = 3.141404
2018-08-12 02:31:09,726 - INFO - epoch 0, step 13750, training loss = 3.283703, validation loss = 3.150991
2018-08-12 02:31:14,626 - INFO - epoch 0, step 13760, training loss = 3.558899, validation loss = 3.127404
2018-08-12 02:31:19,740 - INFO - epoch 0, step 13770, training loss = 3.138562, validation loss = 3.139421
2018-08-12 02:31:24,890 - INFO - epoch 0, step 13780, training loss = 3.595819, validation loss = 3.147885
2018-08-12 02:31:30,849 - INFO - epoch 0, step 13790, training loss = 3.479789, validation loss = 3.102061
2018-08-12 02:31:37,231 - INFO - epoch 0, step 13800, training loss = 3.396823, validation loss = 3.126104
2018-08-12 02:31:44,202 - INFO - epoch 0, step 13810, training loss = 3.413440, validation loss = 3.127986
2018-08-12 02:31:53,246 - INFO - epoch 0, step 13820, training loss = 2.820728, validation loss = 3.232230
2018-08-12 02:32:02,655 - INFO - epoch 0, step 13830, training loss = 3.034517, validation loss = 3.229893
2018-08-12 02:32:12,488 - INFO - epoch 0, step 13840, training loss = 2.897820, validation loss = 3.226491
2018-08-12 02:32:21,578 - INFO - epoch 0, step 13850, training loss = 2.583965, validation loss = 3.195155
2018-08-12 02:32:31,482 - INFO - epoch 0, step 13860, training loss = 3.061172, validation loss = 3.227022
2018-08-12 02:32:41,327 - INFO - epoch 0, step 13870, training loss = 2.859625, validation loss = 3.199278
2018-08-12 02:32:50,199 - INFO - epoch 0, step 13880, training loss = 3.139002, validation loss = 3.182958
2018-08-12 02:32:59,307 - INFO - epoch 0, step 13890, training loss = 3.064402, validation loss = 3.196990
2018-08-12 02:33:07,604 - INFO - epoch 0, step 13900, training loss = 3.200259, validation loss = 3.232304
2018-08-12 02:33:15,717 - INFO - epoch 0, step 13910, training loss = 3.152526, validation loss = 3.239142
2018-08-12 02:33:24,366 - INFO - epoch 0, step 13920, training loss = 2.712135, validation loss = 3.235137
2018-08-12 02:33:32,663 - INFO - epoch 0, step 13930, training loss = 3.237948, validation loss = 3.201061
2018-08-12 02:33:41,515 - INFO - epoch 0, step 13940, training loss = 2.769804, validation loss = 3.220521
2018-08-12 02:33:49,779 - INFO - epoch 0, step 13950, training loss = 3.358804, validation loss = 3.222090
2018-08-12 02:33:57,937 - INFO - epoch 0, step 13960, training loss = 3.217519, validation loss = 3.279354
2018-08-12 02:34:06,506 - INFO - epoch 0, step 13970, training loss = 2.183154, validation loss = 3.304671
2018-08-12 02:34:15,272 - INFO - epoch 0, step 13980, training loss = 2.330185, validation loss = 3.253693
2018-08-12 02:34:23,797 - INFO - epoch 0, step 13990, training loss = 3.144928, validation loss = 3.322731
2018-08-12 02:34:32,263 - INFO - epoch 0, step 14000, training loss = 3.142182, validation loss = 3.221680
2018-08-12 02:34:41,047 - INFO - epoch 0, step 14010, training loss = 3.029812, validation loss = 3.319387
2018-08-12 02:34:49,733 - INFO - epoch 0, step 14020, training loss = 3.131788, validation loss = 3.305818
2018-08-12 02:34:58,513 - INFO - epoch 0, step 14030, training loss = 3.002392, validation loss = 3.327193
2018-08-12 02:35:08,221 - INFO - epoch 0, step 14040, training loss = 2.505573, validation loss = 3.314542
2018-08-12 02:35:16,765 - INFO - epoch 0, step 14050, training loss = 2.349262, validation loss = 3.336278
2018-08-12 02:35:25,583 - INFO - epoch 0, step 14060, training loss = 3.212417, validation loss = 3.332901
2018-08-12 02:35:33,618 - INFO - epoch 0, step 14070, training loss = 3.021342, validation loss = 3.301135
2018-08-12 02:35:42,364 - INFO - epoch 0, step 14080, training loss = 2.949909, validation loss = 3.352611
2018-08-12 02:35:50,825 - INFO - epoch 0, step 14090, training loss = 3.102146, validation loss = 3.291104
2018-08-12 02:35:58,989 - INFO - epoch 0, step 14100, training loss = 3.317544, validation loss = 3.356988
2018-08-12 02:36:07,572 - INFO - epoch 0, step 14110, training loss = 3.045124, validation loss = 3.297468
2018-08-12 02:36:16,109 - INFO - epoch 0, step 14120, training loss = 3.188817, validation loss = 3.344221
2018-08-12 02:36:24,465 - INFO - epoch 0, step 14130, training loss = 2.895919, validation loss = 3.285841
2018-08-12 02:36:32,899 - INFO - epoch 0, step 14140, training loss = 3.080324, validation loss = 3.352799
2018-08-12 02:36:41,149 - INFO - epoch 0, step 14150, training loss = 2.991465, validation loss = 3.318722
2018-08-12 02:36:49,609 - INFO - epoch 0, step 14160, training loss = 3.576598, validation loss = 3.339440
2018-08-12 02:36:58,202 - INFO - epoch 0, step 14170, training loss = 3.251638, validation loss = 3.349981
2018-08-12 02:37:06,440 - INFO - epoch 0, step 14180, training loss = 3.172819, validation loss = 3.324229
2018-08-12 02:37:12,978 - INFO - epoch 0, step 14190, training loss = 3.252378, validation loss = 3.087754
2018-08-12 02:37:20,038 - INFO - epoch 0, step 14200, training loss = 2.496867, validation loss = 3.130062
2018-08-12 02:37:28,343 - INFO - epoch 0, step 14210, training loss = 3.119303, validation loss = 3.202956
2018-08-12 02:37:37,712 - INFO - epoch 0, step 14220, training loss = 2.633617, validation loss = 3.242759
2018-08-12 02:37:47,479 - INFO - epoch 0, step 14230, training loss = 2.615236, validation loss = 3.177788
2018-08-12 02:37:57,384 - INFO - epoch 0, step 14240, training loss = 2.954097, validation loss = 3.208412
2018-08-12 02:38:07,349 - INFO - epoch 0, step 14250, training loss = 2.698125, validation loss = 3.178171
2018-08-12 02:38:14,354 - INFO - epoch 0, step 14260, training loss = 3.329139, validation loss = 3.074725
2018-08-12 02:38:18,990 - INFO - epoch 0, step 14270, training loss = 4.076316, validation loss = 3.084255
2018-08-12 02:38:23,629 - INFO - epoch 0, step 14280, training loss = 3.314378, validation loss = 3.140984
2018-08-12 02:38:28,364 - INFO - epoch 0, step 14290, training loss = 3.862802, validation loss = 3.137438
2018-08-12 02:38:32,970 - INFO - epoch 0, step 14300, training loss = 3.845603, validation loss = 3.137685
2018-08-12 02:38:37,386 - INFO - epoch 0, step 14310, training loss = 3.419515, validation loss = 3.153953
2018-08-12 02:38:41,882 - INFO - epoch 0, step 14320, training loss = 3.211514, validation loss = 3.148289
2018-08-12 02:38:46,844 - INFO - epoch 0, step 14330, training loss = 3.258385, validation loss = 3.114403
2018-08-12 02:38:51,933 - INFO - epoch 0, step 14340, training loss = 3.134377, validation loss = 3.137789
2018-08-12 02:38:56,926 - INFO - epoch 0, step 14350, training loss = 3.294959, validation loss = 3.144735
2018-08-12 02:39:03,267 - INFO - epoch 0, step 14360, training loss = 3.382406, validation loss = 3.343053
2018-08-12 02:39:09,550 - INFO - epoch 0, step 14370, training loss = 3.272081, validation loss = 3.239611
2018-08-12 02:39:15,985 - INFO - epoch 0, step 14380, training loss = 3.084533, validation loss = 3.294787
2018-08-12 02:39:22,448 - INFO - epoch 0, step 14390, training loss = 3.039243, validation loss = 3.220359
2018-08-12 02:39:30,852 - INFO - epoch 0, step 14400, training loss = 3.348616, validation loss = 3.261756
2018-08-12 02:39:39,895 - INFO - epoch 0, step 14410, training loss = 3.232663, validation loss = 3.233219
2018-08-12 02:39:48,815 - INFO - epoch 0, step 14420, training loss = 3.360072, validation loss = 3.281334
2018-08-12 02:39:58,137 - INFO - epoch 0, step 14430, training loss = 3.692059, validation loss = 3.393936
2018-08-12 02:40:07,026 - INFO - epoch 0, step 14440, training loss = 3.423421, validation loss = 3.401807
2018-08-12 02:40:15,645 - INFO - epoch 0, step 14450, training loss = 3.267875, validation loss = 3.363877
2018-08-12 02:40:24,598 - INFO - epoch 0, step 14460, training loss = 3.195432, validation loss = 3.406287
2018-08-12 02:40:33,436 - INFO - epoch 0, step 14470, training loss = 3.592602, validation loss = 3.378319
2018-08-12 02:40:40,580 - INFO - epoch 0, step 14480, training loss = 3.378210, validation loss = 3.450365
2018-08-12 02:40:47,412 - INFO - epoch 0, step 14490, training loss = 3.546827, validation loss = 3.409677
2018-08-12 02:40:54,280 - INFO - epoch 0, step 14500, training loss = 2.935225, validation loss = 3.407648
2018-08-12 02:41:00,795 - INFO - epoch 0, step 14510, training loss = 3.105341, validation loss = 3.431704
2018-08-12 02:41:07,379 - INFO - epoch 0, step 14520, training loss = 3.465361, validation loss = 3.361378
2018-08-12 02:41:13,391 - INFO - epoch 0, step 14530, training loss = 3.094989, validation loss = 3.199564
2018-08-12 02:41:19,900 - INFO - epoch 0, step 14540, training loss = 2.867115, validation loss = 3.083246
2018-08-12 02:41:26,556 - INFO - epoch 0, step 14550, training loss = 2.785408, validation loss = 3.137188
2018-08-12 02:41:34,441 - INFO - epoch 0, step 14560, training loss = 3.120459, validation loss = 3.172698
2018-08-12 02:41:44,227 - INFO - epoch 0, step 14570, training loss = 2.776932, validation loss = 3.204984
2018-08-12 02:41:53,276 - INFO - epoch 0, step 14580, training loss = 2.870858, validation loss = 3.140440
2018-08-12 02:42:02,889 - INFO - epoch 0, step 14590, training loss = 2.042697, validation loss = 3.191562
2018-08-12 02:42:12,999 - INFO - epoch 0, step 14600, training loss = 2.884332, validation loss = 3.202294
2018-08-12 02:42:22,897 - INFO - epoch 0, step 14610, training loss = 3.423838, validation loss = 3.262614
2018-08-12 02:42:31,849 - INFO - epoch 0, step 14620, training loss = 2.737472, validation loss = 3.265809
2018-08-12 02:42:40,462 - INFO - epoch 0, step 14630, training loss = 3.405652, validation loss = 3.313274
2018-08-12 02:42:49,518 - INFO - epoch 0, step 14640, training loss = 3.150300, validation loss = 3.295114
2018-08-12 02:42:58,081 - INFO - epoch 0, step 14650, training loss = 3.465816, validation loss = 3.273914
2018-08-12 02:43:06,398 - INFO - epoch 0, step 14660, training loss = 3.214494, validation loss = 3.283950
2018-08-12 02:43:14,745 - INFO - epoch 0, step 14670, training loss = 3.464484, validation loss = 3.313083
2018-08-12 02:43:23,741 - INFO - epoch 0, step 14680, training loss = 3.295250, validation loss = 3.240967
2018-08-12 02:43:32,368 - INFO - epoch 0, step 14690, training loss = 3.011393, validation loss = 3.310868
2018-08-12 02:43:41,534 - INFO - epoch 0, step 14700, training loss = 3.212053, validation loss = 3.320882
2018-08-12 02:43:50,104 - INFO - epoch 0, step 14710, training loss = 3.362568, validation loss = 3.232755
2018-08-12 02:43:58,958 - INFO - epoch 0, step 14720, training loss = 2.707651, validation loss = 3.319719
2018-08-12 02:44:07,971 - INFO - epoch 0, step 14730, training loss = 2.893203, validation loss = 3.224086
2018-08-12 02:44:16,426 - INFO - epoch 0, step 14740, training loss = 3.097990, validation loss = 3.265380
2018-08-12 02:44:24,916 - INFO - epoch 0, step 14750, training loss = 3.614677, validation loss = 3.287185
2018-08-12 02:44:33,902 - INFO - epoch 0, step 14760, training loss = 2.960887, validation loss = 3.252541
2018-08-12 02:44:42,741 - INFO - epoch 0, step 14770, training loss = 2.996545, validation loss = 3.288280
2018-08-12 02:44:51,564 - INFO - epoch 0, step 14780, training loss = 3.078026, validation loss = 3.327667
2018-08-12 02:45:00,326 - INFO - epoch 0, step 14790, training loss = 3.157707, validation loss = 3.282463
2018-08-12 02:45:08,607 - INFO - epoch 0, step 14800, training loss = 2.731369, validation loss = 3.278704
2018-08-12 02:45:17,369 - INFO - epoch 0, step 14810, training loss = 3.252262, validation loss = 3.324167
2018-08-12 02:45:26,211 - INFO - epoch 0, step 14820, training loss = 2.938265, validation loss = 3.282016
2018-08-12 02:45:34,639 - INFO - epoch 0, step 14830, training loss = 2.759415, validation loss = 3.333694
2018-08-12 02:45:43,078 - INFO - epoch 0, step 14840, training loss = 3.052740, validation loss = 3.266875
2018-08-12 02:45:51,123 - INFO - epoch 0, step 14850, training loss = 3.799839, validation loss = 3.258745
2018-08-12 02:45:57,906 - INFO - epoch 0, step 14860, training loss = 3.471853, validation loss = 3.057780
2018-08-12 02:46:05,453 - INFO - epoch 0, step 14870, training loss = 2.946824, validation loss = 3.087326
2018-08-12 02:46:12,574 - INFO - epoch 0, step 14880, training loss = 2.917880, validation loss = 3.146207
2018-08-12 02:46:20,696 - INFO - epoch 0, step 14890, training loss = 3.248307, validation loss = 3.237521
2018-08-12 02:46:28,900 - INFO - epoch 0, step 14900, training loss = 3.198184, validation loss = 3.190914
2018-08-12 02:46:37,357 - INFO - epoch 0, step 14910, training loss = 3.369729, validation loss = 3.195775
2018-08-12 02:46:46,604 - INFO - epoch 0, step 14920, training loss = 3.202340, validation loss = 3.231421
2018-08-12 02:46:55,341 - INFO - epoch 0, step 14930, training loss = 3.382056, validation loss = 3.261978
2018-08-12 02:47:04,087 - INFO - epoch 0, step 14940, training loss = 2.654443, validation loss = 3.290835
2018-08-12 02:47:12,743 - INFO - epoch 0, step 14950, training loss = 3.045876, validation loss = 3.328495
2018-08-12 02:47:21,180 - INFO - epoch 0, step 14960, training loss = 3.311089, validation loss = 3.320339
2018-08-12 02:47:29,676 - INFO - epoch 0, step 14970, training loss = 2.977430, validation loss = 3.307133
2018-08-12 02:47:38,289 - INFO - epoch 0, step 14980, training loss = 3.516732, validation loss = 3.349840
2018-08-12 02:47:46,819 - INFO - epoch 0, step 14990, training loss = 2.876117, validation loss = 3.370257
2018-08-12 02:47:55,595 - INFO - epoch 0, step 15000, training loss = 2.790641, validation loss = 3.339919
2018-08-12 02:48:03,993 - INFO - epoch 0, step 15010, training loss = 3.212810, validation loss = 3.387376
2018-08-12 02:48:12,613 - INFO - epoch 0, step 15020, training loss = 3.366292, validation loss = 3.347144
2018-08-12 02:48:20,884 - INFO - epoch 0, step 15030, training loss = 2.995089, validation loss = 3.343238
2018-08-12 02:48:27,743 - INFO - epoch 0, step 15040, training loss = 3.148412, validation loss = 3.059499
2018-08-12 02:48:34,332 - INFO - epoch 0, step 15050, training loss = 3.479689, validation loss = 3.078846
2018-08-12 02:48:39,670 - INFO - epoch 0, step 15060, training loss = 3.920048, validation loss = 3.092110
2018-08-12 02:48:44,488 - INFO - epoch 0, step 15070, training loss = 3.680037, validation loss = 3.102331
2018-08-12 02:48:49,297 - INFO - epoch 0, step 15080, training loss = 3.768234, validation loss = 3.134368
2018-08-12 02:48:54,282 - INFO - epoch 0, step 15090, training loss = 3.628043, validation loss = 3.160520
2018-08-12 02:48:59,198 - INFO - epoch 0, step 15100, training loss = 3.518272, validation loss = 3.127277
2018-08-12 02:49:05,520 - INFO - epoch 0, step 15110, training loss = 3.346424, validation loss = 3.125005
2018-08-12 02:49:14,757 - INFO - epoch 0, step 15120, training loss = 3.496699, validation loss = 3.258339
2018-08-12 02:49:22,685 - INFO - epoch 0, step 15130, training loss = 3.241009, validation loss = 3.134011
2018-08-12 02:49:31,338 - INFO - epoch 0, step 15140, training loss = 2.993012, validation loss = 3.216661
2018-08-12 02:49:39,734 - INFO - epoch 0, step 15150, training loss = 2.961807, validation loss = 3.144281
2018-08-12 02:49:47,828 - INFO - epoch 0, step 15160, training loss = 3.409173, validation loss = 3.177548
2018-08-12 02:49:56,389 - INFO - epoch 0, step 15170, training loss = 3.118106, validation loss = 3.168568
2018-08-12 02:50:05,060 - INFO - epoch 0, step 15180, training loss = 3.002150, validation loss = 3.159731
2018-08-12 02:50:14,234 - INFO - epoch 0, step 15190, training loss = 2.929725, validation loss = 3.164011
2018-08-12 02:50:24,342 - INFO - epoch 0, step 15200, training loss = 2.039824, validation loss = 3.138610
2018-08-12 02:50:33,950 - INFO - epoch 0, step 15210, training loss = 2.499740, validation loss = 3.155670
2018-08-12 02:50:43,376 - INFO - epoch 0, step 15220, training loss = 2.584100, validation loss = 3.125396
2018-08-12 02:50:52,319 - INFO - epoch 0, step 15230, training loss = 2.412558, validation loss = 3.104504
2018-08-12 02:51:01,356 - INFO - epoch 0, step 15240, training loss = 2.406738, validation loss = 3.177821
2018-08-12 02:51:10,070 - INFO - epoch 0, step 15250, training loss = 2.616750, validation loss = 3.141366
2018-08-12 02:51:19,405 - INFO - epoch 0, step 15260, training loss = 3.211216, validation loss = 3.143049
2018-08-12 02:51:27,969 - INFO - epoch 0, step 15270, training loss = 2.731813, validation loss = 3.151860
2018-08-12 02:51:36,897 - INFO - epoch 0, step 15280, training loss = 2.908749, validation loss = 3.111906
2018-08-12 02:51:46,219 - INFO - epoch 0, step 15290, training loss = 2.848821, validation loss = 3.127266
2018-08-12 02:51:54,888 - INFO - epoch 0, step 15300, training loss = 2.871793, validation loss = 3.098572
2018-08-12 02:52:04,710 - INFO - epoch 0, step 15310, training loss = 2.945341, validation loss = 3.106527
2018-08-12 02:52:14,730 - INFO - epoch 0, step 15320, training loss = 2.819333, validation loss = 3.266535
2018-08-12 02:52:23,806 - INFO - epoch 0, step 15330, training loss = 2.397536, validation loss = 3.124095
2018-08-12 02:52:32,967 - INFO - epoch 0, step 15340, training loss = 2.991463, validation loss = 3.181468
2018-08-12 02:52:42,457 - INFO - epoch 0, step 15350, training loss = 2.375680, validation loss = 3.242995
2018-08-12 02:52:51,702 - INFO - epoch 0, step 15360, training loss = 2.987002, validation loss = 3.184208
2018-08-12 02:53:00,863 - INFO - epoch 0, step 15370, training loss = 2.605984, validation loss = 3.222791
2018-08-12 02:53:06,759 - INFO - epoch 0, step 15380, training loss = 3.519074, validation loss = 3.071035
2018-08-12 02:53:11,296 - INFO - epoch 0, step 15390, training loss = 3.484673, validation loss = 3.278477
2018-08-12 02:53:15,693 - INFO - epoch 0, step 15400, training loss = 3.132260, validation loss = 3.343816
2018-08-12 02:53:20,236 - INFO - epoch 0, step 15410, training loss = 3.199599, validation loss = 3.255343
2018-08-12 02:53:24,994 - INFO - epoch 0, step 15420, training loss = 2.928089, validation loss = 3.302105
2018-08-12 02:53:30,723 - INFO - epoch 0, step 15430, training loss = 2.274946, validation loss = 3.295893
2018-08-12 02:53:35,909 - INFO - epoch 0, step 15440, training loss = 3.103717, validation loss = 3.264030
2018-08-12 02:53:45,200 - INFO - epoch 0, step 15450, training loss = 3.159674, validation loss = 3.211163
2018-08-12 02:53:54,100 - INFO - epoch 0, step 15460, training loss = 2.755027, validation loss = 3.065789
2018-08-12 02:54:02,650 - INFO - epoch 0, step 15470, training loss = 2.819953, validation loss = 3.112254
2018-08-12 02:54:12,588 - INFO - epoch 0, step 15480, training loss = 2.886017, validation loss = 3.114474
2018-08-12 02:54:22,195 - INFO - epoch 0, step 15490, training loss = 2.688768, validation loss = 3.108829
2018-08-12 02:54:32,040 - INFO - epoch 0, step 15500, training loss = 2.432705, validation loss = 3.134151
2018-08-12 02:54:41,859 - INFO - epoch 0, step 15510, training loss = 2.803589, validation loss = 3.101527
2018-08-12 02:54:50,940 - INFO - epoch 0, step 15520, training loss = 2.790445, validation loss = 3.173388
2018-08-12 02:55:00,329 - INFO - epoch 0, step 15530, training loss = 3.229503, validation loss = 3.094124
2018-08-12 02:55:05,337 - INFO - epoch 0, step 15540, training loss = 3.129731, validation loss = 3.045398
2018-08-12 02:55:10,465 - INFO - epoch 0, step 15550, training loss = 3.837336, validation loss = 3.096956
2018-08-12 02:55:15,487 - INFO - epoch 0, step 15560, training loss = 4.238676, validation loss = 3.090336
2018-08-12 02:55:20,479 - INFO - epoch 0, step 15570, training loss = 3.634317, validation loss = 3.098124
2018-08-12 02:55:25,487 - INFO - epoch 0, step 15580, training loss = 3.630268, validation loss = 3.117768
2018-08-12 02:55:30,620 - INFO - epoch 0, step 15590, training loss = 3.662110, validation loss = 3.105697
2018-08-12 02:55:36,425 - INFO - epoch 0, step 15600, training loss = 3.356504, validation loss = 3.065325
2018-08-12 02:55:42,568 - INFO - epoch 0, step 15610, training loss = 3.344757, validation loss = 3.051491
2018-08-12 02:55:49,081 - INFO - epoch 0, step 15620, training loss = 3.242924, validation loss = 3.043686
2018-08-12 02:55:55,529 - INFO - epoch 0, step 15630, training loss = 2.959640, validation loss = 3.093262
2018-08-12 02:56:01,339 - INFO - epoch 0, step 15640, training loss = 2.647764, validation loss = 3.156457
2018-08-12 02:56:07,551 - INFO - epoch 0, step 15650, training loss = 3.983360, validation loss = 3.280312
2018-08-12 02:56:11,522 - INFO - epoch 0, step 15660, training loss = 3.272437, validation loss = 3.341565
2018-08-12 02:56:15,393 - INFO - epoch 0, step 15670, training loss = 3.448020, validation loss = 3.427918
2018-08-12 02:56:19,234 - INFO - epoch 0, step 15680, training loss = 3.110739, validation loss = 3.434252
2018-08-12 02:56:23,155 - INFO - epoch 0, step 15690, training loss = 4.037691, validation loss = 3.444561
2018-08-12 02:56:27,273 - INFO - epoch 0, step 15700, training loss = 3.600977, validation loss = 3.441059
2018-08-12 02:56:31,363 - INFO - epoch 0, step 15710, training loss = 3.427182, validation loss = 3.482833
2018-08-12 02:56:35,091 - INFO - epoch 0, step 15720, training loss = 3.048165, validation loss = 3.425214
2018-08-12 02:56:39,926 - INFO - epoch 0, step 15730, training loss = 3.564426, validation loss = 3.116992
2018-08-12 02:56:44,673 - INFO - epoch 0, step 15740, training loss = 4.250402, validation loss = 3.160914
2018-08-12 02:56:49,713 - INFO - epoch 0, step 15750, training loss = 3.369243, validation loss = 3.143611
2018-08-12 02:56:54,606 - INFO - epoch 0, step 15760, training loss = 3.682320, validation loss = 3.122348
2018-08-12 02:56:59,735 - INFO - epoch 0, step 15770, training loss = 3.943815, validation loss = 3.137641
2018-08-12 02:57:04,916 - INFO - epoch 0, step 15780, training loss = 3.750103, validation loss = 3.136047
2018-08-12 02:57:12,631 - INFO - epoch 0, step 15790, training loss = 3.265261, validation loss = 3.112658
2018-08-12 02:57:20,753 - INFO - epoch 0, step 15800, training loss = 3.609263, validation loss = 3.336661
2018-08-12 02:57:29,044 - INFO - epoch 0, step 15810, training loss = 3.333754, validation loss = 3.215635
2018-08-12 02:57:37,505 - INFO - epoch 0, step 15820, training loss = 3.315891, validation loss = 3.225863
2018-08-12 02:57:45,777 - INFO - epoch 0, step 15830, training loss = 3.275873, validation loss = 3.250760
2018-08-12 02:57:54,740 - INFO - epoch 0, step 15840, training loss = 2.828368, validation loss = 3.314669
2018-08-12 02:58:03,367 - INFO - epoch 0, step 15850, training loss = 3.473508, validation loss = 3.199374
2018-08-12 02:58:12,006 - INFO - epoch 0, step 15860, training loss = 3.342481, validation loss = 3.284930
2018-08-12 02:58:20,323 - INFO - epoch 0, step 15870, training loss = 3.256804, validation loss = 3.296916
2018-08-12 02:58:28,998 - INFO - epoch 0, step 15880, training loss = 3.031729, validation loss = 3.265729
2018-08-12 02:58:37,823 - INFO - epoch 0, step 15890, training loss = 3.364229, validation loss = 3.351543
2018-08-12 02:58:42,910 - INFO - epoch 0, step 15900, training loss = 4.158658, validation loss = 3.103448
2018-08-12 02:58:46,810 - INFO - epoch 0, step 15910, training loss = 3.520300, validation loss = 3.264272
2018-08-12 02:58:50,586 - INFO - epoch 0, step 15920, training loss = 3.567577, validation loss = 3.326322
2018-08-12 02:58:54,362 - INFO - epoch 0, step 15930, training loss = 3.863452, validation loss = 3.413687
2018-08-12 02:58:58,029 - INFO - epoch 0, step 15940, training loss = 3.398612, validation loss = 3.424191
2018-08-12 02:59:01,882 - INFO - epoch 0, step 15950, training loss = 3.770856, validation loss = 3.400470
2018-08-12 02:59:05,851 - INFO - epoch 0, step 15960, training loss = 3.499933, validation loss = 3.421523
2018-08-12 02:59:12,482 - INFO - epoch 0, step 15970, training loss = 3.273178, validation loss = 3.243401
2018-08-12 02:59:22,441 - INFO - epoch 0, step 15980, training loss = 2.844063, validation loss = 3.221955
2018-08-12 02:59:31,652 - INFO - epoch 0, step 15990, training loss = 2.955189, validation loss = 3.146347
2018-08-12 02:59:42,430 - INFO - epoch 0, step 16000, training loss = 2.446707, validation loss = 3.138604
2018-08-12 02:59:52,455 - INFO - epoch 0, step 16010, training loss = 2.205981, validation loss = 3.158776
2018-08-12 03:00:01,450 - INFO - epoch 0, step 16020, training loss = 2.978263, validation loss = 3.115614
2018-08-12 03:00:11,104 - INFO - epoch 0, step 16030, training loss = 3.050373, validation loss = 3.178413
2018-08-12 03:00:21,081 - INFO - epoch 0, step 16040, training loss = 2.819643, validation loss = 3.138028
2018-08-12 03:00:30,047 - INFO - epoch 0, step 16050, training loss = 2.207358, validation loss = 3.135300
2018-08-12 03:00:38,643 - INFO - epoch 0, step 16060, training loss = 2.629352, validation loss = 3.165684
2018-08-12 03:00:42,520 - INFO - epoch 0, step 16070, training loss = 3.253552, validation loss = 3.191222
2018-08-12 03:00:46,232 - INFO - epoch 0, step 16080, training loss = 3.713248, validation loss = 3.247765
2018-08-12 03:00:50,037 - INFO - epoch 0, step 16090, training loss = 3.417072, validation loss = 3.366818
2018-08-12 03:00:53,727 - INFO - epoch 0, step 16100, training loss = 3.619008, validation loss = 3.302768
2018-08-12 03:00:57,381 - INFO - epoch 0, step 16110, training loss = 3.138373, validation loss = 3.383006
2018-08-12 03:01:00,231 - INFO - epoch 0, step 16120, training loss = 2.700043, validation loss = 3.394812
2018-08-12 03:01:03,097 - INFO - epoch 0, step 16130, training loss = 3.499843, validation loss = 3.362863
2018-08-12 03:01:07,747 - INFO - epoch 0, step 16140, training loss = 3.599654, validation loss = 3.236454
2018-08-12 03:01:15,013 - INFO - epoch 0, step 16150, training loss = 3.596522, validation loss = 3.178015
2018-08-12 03:01:21,700 - INFO - epoch 0, step 16160, training loss = 3.133173, validation loss = 3.204851
2018-08-12 03:01:28,116 - INFO - epoch 0, step 16170, training loss = 3.267621, validation loss = 3.168968
2018-08-12 03:01:34,828 - INFO - epoch 0, step 16180, training loss = 3.300534, validation loss = 3.175794
2018-08-12 03:01:42,867 - INFO - epoch 0, step 16190, training loss = 3.727398, validation loss = 3.186639
2018-08-12 03:01:51,101 - INFO - epoch 0, step 16200, training loss = 3.545099, validation loss = 3.160673
2018-08-12 03:01:59,232 - INFO - epoch 0, step 16210, training loss = 3.458288, validation loss = 3.155164
2018-08-12 03:02:07,716 - INFO - epoch 0, step 16220, training loss = 3.242060, validation loss = 3.135463
2018-08-12 03:02:16,276 - INFO - epoch 0, step 16230, training loss = 3.370584, validation loss = 3.148041
2018-08-12 03:02:24,787 - INFO - epoch 0, step 16240, training loss = 2.470085, validation loss = 3.129121
2018-08-12 03:02:33,054 - INFO - epoch 0, step 16250, training loss = 3.384516, validation loss = 3.167919
2018-08-12 03:02:41,104 - INFO - epoch 0, step 16260, training loss = 3.136977, validation loss = 3.103198
2018-08-12 03:02:47,973 - INFO - epoch 0, step 16270, training loss = 3.474247, validation loss = 2.997323
2018-08-12 03:02:54,688 - INFO - epoch 0, step 16280, training loss = 2.914403, validation loss = 3.041303
2018-08-12 03:03:01,167 - INFO - epoch 0, step 16290, training loss = 2.951827, validation loss = 3.044134
2018-08-12 03:03:07,009 - INFO - epoch 0, step 16300, training loss = 3.189413, validation loss = 3.033090
2018-08-12 03:03:12,619 - INFO - epoch 0, step 16310, training loss = 2.643052, validation loss = 3.300569
2018-08-12 03:03:17,738 - INFO - epoch 0, step 16320, training loss = 2.985016, validation loss = 3.234452
2018-08-12 03:03:22,955 - INFO - epoch 0, step 16330, training loss = 2.762543, validation loss = 3.278200
2018-08-12 03:03:31,743 - INFO - epoch 0, step 16340, training loss = 3.039903, validation loss = 3.095463
2018-08-12 03:03:41,249 - INFO - epoch 0, step 16350, training loss = 3.356708, validation loss = 3.111367
2018-08-12 03:03:49,882 - INFO - epoch 0, step 16360, training loss = 2.856338, validation loss = 3.085621
2018-08-12 03:03:58,177 - INFO - epoch 0, step 16370, training loss = 3.214843, validation loss = 3.121663
2018-08-12 03:04:06,548 - INFO - epoch 0, step 16380, training loss = 3.267785, validation loss = 3.128076
2018-08-12 03:04:14,595 - INFO - epoch 0, step 16390, training loss = 3.463087, validation loss = 3.171305
2018-08-12 03:04:22,922 - INFO - epoch 0, step 16400, training loss = 3.215745, validation loss = 3.180798
2018-08-12 03:04:31,442 - INFO - epoch 0, step 16410, training loss = 3.596401, validation loss = 3.126884
2018-08-12 03:04:40,092 - INFO - epoch 0, step 16420, training loss = 2.717856, validation loss = 3.190777
2018-08-12 03:04:48,439 - INFO - epoch 0, step 16430, training loss = 3.413961, validation loss = 3.114359
2018-08-12 03:04:57,201 - INFO - epoch 0, step 16440, training loss = 2.924224, validation loss = 3.181133
2018-08-12 03:05:06,569 - INFO - epoch 0, step 16450, training loss = 2.828805, validation loss = 3.062373
2018-08-12 03:05:15,934 - INFO - epoch 0, step 16460, training loss = 2.883029, validation loss = 3.115218
2018-08-12 03:05:25,374 - INFO - epoch 0, step 16470, training loss = 3.123855, validation loss = 3.114828
2018-08-12 03:05:35,290 - INFO - epoch 0, step 16480, training loss = 2.573303, validation loss = 3.088445
2018-08-12 03:05:45,074 - INFO - epoch 0, step 16490, training loss = 3.085494, validation loss = 3.146455
2018-08-12 03:05:53,543 - INFO - epoch 0, step 16500, training loss = 2.757264, validation loss = 3.058376
2018-08-12 03:06:00,520 - INFO - epoch 0, step 16510, training loss = 2.781288, validation loss = 3.039049
2018-08-12 03:06:07,162 - INFO - epoch 0, step 16520, training loss = 2.461368, validation loss = 3.103747
2018-08-12 03:06:14,642 - INFO - epoch 0, step 16530, training loss = 3.032132, validation loss = 3.089605
2018-08-12 03:06:20,236 - INFO - epoch 0, step 16540, training loss = 3.676083, validation loss = 3.050646
2018-08-12 03:06:25,835 - INFO - epoch 0, step 16550, training loss = 3.324465, validation loss = 3.074449
2018-08-12 03:06:31,448 - INFO - epoch 0, step 16560, training loss = 3.356336, validation loss = 3.069079
2018-08-12 03:06:37,126 - INFO - epoch 0, step 16570, training loss = 3.200812, validation loss = 3.080516
2018-08-12 03:06:42,608 - INFO - epoch 0, step 16580, training loss = 3.671222, validation loss = 3.084975
2018-08-12 03:06:50,184 - INFO - epoch 0, step 16590, training loss = 2.666861, validation loss = 3.128161
2018-08-12 03:06:59,658 - INFO - epoch 0, step 16600, training loss = 2.681134, validation loss = 3.197583
2018-08-12 03:07:09,453 - INFO - epoch 0, step 16610, training loss = 3.096472, validation loss = 3.143395
2018-08-12 03:07:18,171 - INFO - epoch 0, step 16620, training loss = 2.486484, validation loss = 3.115132
2018-08-12 03:07:27,125 - INFO - epoch 0, step 16630, training loss = 2.872623, validation loss = 3.200984
2018-08-12 03:07:35,906 - INFO - epoch 0, step 16640, training loss = 2.789204, validation loss = 3.086082
2018-08-12 03:07:44,880 - INFO - epoch 0, step 16650, training loss = 2.658975, validation loss = 3.131582
2018-08-12 03:07:55,109 - INFO - epoch 0, step 16660, training loss = 3.123446, validation loss = 3.185331
2018-08-12 03:08:04,425 - INFO - epoch 0, step 16670, training loss = 2.822485, validation loss = 3.112390
2018-08-12 03:08:13,784 - INFO - epoch 0, step 16680, training loss = 3.491048, validation loss = 3.188617
2018-08-12 03:08:21,904 - INFO - epoch 0, step 16690, training loss = 3.506029, validation loss = 3.083771
2018-08-12 03:08:30,015 - INFO - epoch 0, step 16700, training loss = 2.596622, validation loss = 3.150146
2018-08-12 03:08:38,167 - INFO - epoch 0, step 16710, training loss = 3.348127, validation loss = 3.131222
2018-08-12 03:08:45,616 - INFO - epoch 0, step 16720, training loss = 3.201425, validation loss = 3.141577
2018-08-12 03:08:53,168 - INFO - epoch 0, step 16730, training loss = 2.926519, validation loss = 3.181428
2018-08-12 03:09:01,138 - INFO - epoch 0, step 16740, training loss = 2.833228, validation loss = 3.174080
2018-08-12 03:09:10,099 - INFO - epoch 0, step 16750, training loss = 2.984367, validation loss = 3.292898
2018-08-12 03:09:18,324 - INFO - epoch 0, step 16760, training loss = 3.251820, validation loss = 3.211762
2018-08-12 03:09:27,306 - INFO - epoch 0, step 16770, training loss = 2.701958, validation loss = 3.290767
2018-08-12 03:09:35,807 - INFO - epoch 0, step 16780, training loss = 3.100521, validation loss = 3.261742
2018-08-12 03:09:44,017 - INFO - epoch 0, step 16790, training loss = 3.083154, validation loss = 3.240349
2018-08-12 03:09:53,054 - INFO - epoch 0, step 16800, training loss = 3.229468, validation loss = 3.278530
2018-08-12 03:10:03,530 - INFO - epoch 0, step 16810, training loss = 2.415912, validation loss = 3.259267
2018-08-12 03:10:11,866 - INFO - epoch 0, step 16820, training loss = 3.028351, validation loss = 3.229691
2018-08-12 03:10:20,356 - INFO - epoch 0, step 16830, training loss = 2.863103, validation loss = 3.282149
2018-08-12 03:10:29,249 - INFO - epoch 0, step 16840, training loss = 3.288474, validation loss = 3.275483
2018-08-12 03:10:37,775 - INFO - epoch 0, step 16850, training loss = 3.272183, validation loss = 3.243968
2018-08-12 03:10:46,040 - INFO - epoch 0, step 16860, training loss = 3.156149, validation loss = 3.264019
2018-08-12 03:10:54,102 - INFO - epoch 0, step 16870, training loss = 3.095157, validation loss = 3.264890
2018-08-12 03:11:02,466 - INFO - epoch 0, step 16880, training loss = 3.054581, validation loss = 3.287889
2018-08-12 03:11:11,157 - INFO - epoch 0, step 16890, training loss = 3.168919, validation loss = 3.316615
2018-08-12 03:11:19,541 - INFO - epoch 0, step 16900, training loss = 3.372729, validation loss = 3.260187
2018-08-12 03:11:28,222 - INFO - epoch 0, step 16910, training loss = 2.960639, validation loss = 3.302314
2018-08-12 03:11:36,873 - INFO - epoch 0, step 16920, training loss = 3.115725, validation loss = 3.277589
2018-08-12 03:11:45,653 - INFO - epoch 0, step 16930, training loss = 3.150434, validation loss = 3.261700
2018-08-12 03:11:54,243 - INFO - epoch 0, step 16940, training loss = 3.066620, validation loss = 3.296569
2018-08-12 03:12:02,479 - INFO - epoch 0, step 16950, training loss = 3.519270, validation loss = 3.249627
2018-08-12 03:12:11,032 - INFO - epoch 0, step 16960, training loss = 3.151193, validation loss = 3.322823
2018-08-12 03:12:20,084 - INFO - epoch 0, step 16970, training loss = 3.001179, validation loss = 3.346862
2018-08-12 03:12:28,486 - INFO - epoch 0, step 16980, training loss = 3.329902, validation loss = 3.206643
2018-08-12 03:12:38,505 - INFO - epoch 0, step 16990, training loss = 3.145590, validation loss = 3.189297
2018-08-12 03:12:46,645 - INFO - epoch 0, step 17000, training loss = 2.934850, validation loss = 3.170308
2018-08-12 03:12:54,871 - INFO - epoch 0, step 17010, training loss = 3.298408, validation loss = 3.176277
2018-08-12 03:13:02,824 - INFO - epoch 0, step 17020, training loss = 3.454969, validation loss = 3.207776
2018-08-12 03:13:11,377 - INFO - epoch 0, step 17030, training loss = 3.161524, validation loss = 3.216525
2018-08-12 03:13:19,256 - INFO - epoch 0, step 17040, training loss = 3.080427, validation loss = 3.209605
2018-08-12 03:13:24,452 - INFO - epoch 0, step 17050, training loss = 3.525753, validation loss = 3.026726
2018-08-12 03:13:28,618 - INFO - epoch 0, step 17060, training loss = 2.882946, validation loss = 3.307986
2018-08-12 03:13:32,583 - INFO - epoch 0, step 17070, training loss = 3.643578, validation loss = 3.237710
2018-08-12 03:13:36,462 - INFO - epoch 0, step 17080, training loss = 2.825396, validation loss = 3.324033
2018-08-12 03:13:40,666 - INFO - epoch 0, step 17090, training loss = 3.529270, validation loss = 3.309105
2018-08-12 03:13:44,676 - INFO - epoch 0, step 17100, training loss = 2.656695, validation loss = 3.340177
2018-08-12 03:13:48,757 - INFO - epoch 0, step 17110, training loss = 3.658235, validation loss = 3.319951
2018-08-12 03:13:57,101 - INFO - epoch 0, step 17120, training loss = 3.268015, validation loss = 3.136965
2018-08-12 03:14:05,633 - INFO - epoch 0, step 17130, training loss = 2.889733, validation loss = 3.297724
2018-08-12 03:14:14,489 - INFO - epoch 0, step 17140, training loss = 3.140480, validation loss = 3.177821
2018-08-12 03:14:23,042 - INFO - epoch 0, step 17150, training loss = 3.224097, validation loss = 3.216751
2018-08-12 03:14:31,368 - INFO - epoch 0, step 17160, training loss = 2.965650, validation loss = 3.208285
2018-08-12 03:14:39,941 - INFO - epoch 0, step 17170, training loss = 3.077386, validation loss = 3.228516
2018-08-12 03:14:48,945 - INFO - epoch 0, step 17180, training loss = 3.165515, validation loss = 3.234959
2018-08-12 03:14:57,359 - INFO - epoch 0, step 17190, training loss = 3.421036, validation loss = 3.183516
2018-08-12 03:15:06,121 - INFO - epoch 0, step 17200, training loss = 3.250545, validation loss = 3.267211
2018-08-12 03:15:14,441 - INFO - epoch 0, step 17210, training loss = 2.891015, validation loss = 3.237364
2018-08-12 03:15:22,724 - INFO - epoch 0, step 17220, training loss = 2.869352, validation loss = 3.258585
2018-08-12 03:15:31,315 - INFO - epoch 0, step 17230, training loss = 3.173307, validation loss = 3.208777
2018-08-12 03:15:37,136 - INFO - epoch 0, step 17240, training loss = 3.927055, validation loss = 3.057911
2018-08-12 03:15:42,434 - INFO - epoch 0, step 17250, training loss = 3.485262, validation loss = 3.096410
2018-08-12 03:15:47,301 - INFO - epoch 0, step 17260, training loss = 3.812602, validation loss = 3.104592
2018-08-12 03:15:52,297 - INFO - epoch 0, step 17270, training loss = 3.744522, validation loss = 3.105662
2018-08-12 03:15:57,503 - INFO - epoch 0, step 17280, training loss = 3.702226, validation loss = 3.121566
2018-08-12 03:16:02,500 - INFO - epoch 0, step 17290, training loss = 3.708443, validation loss = 3.107509
2018-08-12 03:16:07,531 - INFO - epoch 0, step 17300, training loss = 3.422474, validation loss = 3.100332
2018-08-12 03:16:12,367 - INFO - epoch 0, step 17310, training loss = 4.044128, validation loss = 3.106305
2018-08-12 03:16:17,283 - INFO - epoch 0, step 17320, training loss = 3.477683, validation loss = 3.120687
2018-08-12 03:16:25,911 - INFO - epoch 0, step 17330, training loss = 3.283924, validation loss = 3.312156
2018-08-12 03:16:34,522 - INFO - epoch 0, step 17340, training loss = 3.443684, validation loss = 3.491253
2018-08-12 03:16:43,643 - INFO - epoch 0, step 17350, training loss = 2.930884, validation loss = 3.366861
2018-08-12 03:16:52,484 - INFO - epoch 0, step 17360, training loss = 3.314365, validation loss = 3.415913
2018-08-12 03:17:01,139 - INFO - epoch 0, step 17370, training loss = 3.478355, validation loss = 3.367482
2018-08-12 03:17:10,146 - INFO - epoch 0, step 17380, training loss = 3.599713, validation loss = 3.373017
2018-08-12 03:17:19,080 - INFO - epoch 0, step 17390, training loss = 3.223598, validation loss = 3.348608
2018-08-12 03:17:28,047 - INFO - epoch 0, step 17400, training loss = 3.730964, validation loss = 3.390633
2018-08-12 03:17:36,559 - INFO - epoch 0, step 17410, training loss = 3.197361, validation loss = 3.318424
2018-08-12 03:17:43,044 - INFO - epoch 0, step 17420, training loss = 3.098530, validation loss = 3.116487
2018-08-12 03:17:52,429 - INFO - epoch 0, step 17430, training loss = 2.705446, validation loss = 3.126083
2018-08-12 03:18:03,621 - INFO - epoch 0, step 17440, training loss = 3.030466, validation loss = 3.154364
2018-08-12 03:18:15,261 - INFO - epoch 0, step 17450, training loss = 2.404562, validation loss = 3.085020
2018-08-12 03:18:24,265 - INFO - epoch 0, step 17460, training loss = 2.663800, validation loss = 3.121101
2018-08-12 03:18:32,869 - INFO - epoch 0, step 17470, training loss = 3.353392, validation loss = 3.111966
2018-08-12 03:18:40,655 - INFO - epoch 0, step 17480, training loss = 3.225836, validation loss = 3.118868
2018-08-12 03:18:49,016 - INFO - epoch 0, step 17490, training loss = 3.653836, validation loss = 3.144437
2018-08-12 03:18:56,348 - INFO - epoch 0, step 17500, training loss = 2.829038, validation loss = 3.132367
2018-08-12 03:19:04,173 - INFO - epoch 0, step 17510, training loss = 3.384253, validation loss = 3.175868
2018-08-12 03:19:12,624 - INFO - epoch 0, step 17520, training loss = 2.722917, validation loss = 3.145129
2018-08-12 03:19:20,246 - INFO - epoch 0, step 17530, training loss = 2.693743, validation loss = 3.155268
2018-08-12 03:19:24,190 - INFO - epoch 0, step 17540, training loss = 4.128788, validation loss = 3.212461
2018-08-12 03:19:27,992 - INFO - epoch 0, step 17550, training loss = 3.439926, validation loss = 3.325313
2018-08-12 03:19:32,150 - INFO - epoch 0, step 17560, training loss = 3.011921, validation loss = 3.426480
2018-08-12 03:19:36,130 - INFO - epoch 0, step 17570, training loss = 3.434719, validation loss = 3.393487
2018-08-12 03:19:40,159 - INFO - epoch 0, step 17580, training loss = 2.961817, validation loss = 3.424761
2018-08-12 03:19:43,888 - INFO - epoch 0, step 17590, training loss = 3.278638, validation loss = 3.415184
2018-08-12 03:19:47,762 - INFO - epoch 0, step 17600, training loss = 3.397187, validation loss = 3.381400
2018-08-12 03:19:51,689 - INFO - epoch 0, step 17610, training loss = 3.263368, validation loss = 3.460062
2018-08-12 03:19:58,057 - INFO - epoch 0, step 17620, training loss = 3.553324, validation loss = 3.090442
2018-08-12 03:20:05,299 - INFO - epoch 0, step 17630, training loss = 3.649058, validation loss = 3.083163
2018-08-12 03:20:12,318 - INFO - epoch 0, step 17640, training loss = 2.803918, validation loss = 3.085426
2018-08-12 03:20:19,024 - INFO - epoch 0, step 17650, training loss = 3.032594, validation loss = 3.065851
2018-08-12 03:20:25,644 - INFO - epoch 0, step 17660, training loss = 3.007402, validation loss = 3.152982
2018-08-12 03:20:33,266 - INFO - epoch 0, step 17670, training loss = 3.385482, validation loss = 3.100742
2018-08-12 03:20:40,812 - INFO - epoch 0, step 17680, training loss = 3.633842, validation loss = 3.157262
2018-08-12 03:20:47,655 - INFO - epoch 0, step 17690, training loss = 3.523472, validation loss = 3.159376
2018-08-12 03:20:54,990 - INFO - epoch 0, step 17700, training loss = 3.768666, validation loss = 3.180127
2018-08-12 03:21:01,352 - INFO - epoch 0, step 17710, training loss = 3.488788, validation loss = 3.143515
2018-08-12 03:21:07,978 - INFO - epoch 0, step 17720, training loss = 3.360108, validation loss = 3.237284
2018-08-12 03:21:14,989 - INFO - epoch 0, step 17730, training loss = 2.977096, validation loss = 3.122159
2018-08-12 03:21:21,420 - INFO - epoch 0, step 17740, training loss = 2.191798, validation loss = 3.081532
2018-08-12 03:21:26,810 - INFO - epoch 0, step 17750, training loss = 3.111217, validation loss = 3.091316
2018-08-12 03:21:32,083 - INFO - epoch 0, step 17760, training loss = 2.221612, validation loss = 3.083823
2018-08-12 03:21:37,205 - INFO - epoch 0, step 17770, training loss = 3.455866, validation loss = 3.095665
2018-08-12 03:21:42,890 - INFO - epoch 0, step 17780, training loss = 3.164450, validation loss = 3.082677
2018-08-12 03:21:48,529 - INFO - epoch 0, step 17790, training loss = 3.049863, validation loss = 3.115042
2018-08-12 03:21:56,551 - INFO - epoch 0, step 17800, training loss = 2.843444, validation loss = 3.204864
2018-08-12 03:22:04,262 - INFO - epoch 0, step 17810, training loss = 2.700310, validation loss = 3.163134
2018-08-12 03:22:13,851 - INFO - epoch 0, step 17820, training loss = 2.344381, validation loss = 3.169445
2018-08-12 03:22:23,347 - INFO - epoch 0, step 17830, training loss = 2.570983, validation loss = 3.145696
2018-08-12 03:22:33,339 - INFO - epoch 0, step 17840, training loss = 2.490840, validation loss = 3.148232
2018-08-12 03:22:40,452 - INFO - epoch 0, step 17850, training loss = 2.596352, validation loss = 3.022936
2018-08-12 03:22:47,131 - INFO - epoch 0, step 17860, training loss = 3.292338, validation loss = 3.055995
2018-08-12 03:22:53,778 - INFO - epoch 0, step 17870, training loss = 3.054579, validation loss = 3.078083
2018-08-12 03:23:00,070 - INFO - epoch 0, step 17880, training loss = 4.102370, validation loss = 3.088618
2018-08-12 03:23:06,016 - INFO - epoch 0, step 17890, training loss = 3.762984, validation loss = 3.142870
2018-08-12 03:23:12,459 - INFO - epoch 0, step 17900, training loss = 3.412658, validation loss = 3.213531
2018-08-12 03:23:18,462 - INFO - epoch 0, step 17910, training loss = 3.589106, validation loss = 3.217215
2018-08-12 03:23:24,612 - INFO - epoch 0, step 17920, training loss = 3.372974, validation loss = 3.220445
2018-08-12 03:23:30,668 - INFO - epoch 0, step 17930, training loss = 3.251809, validation loss = 3.211123
2018-08-12 03:23:36,762 - INFO - epoch 0, step 17940, training loss = 2.959636, validation loss = 3.215265
2018-08-12 03:23:42,709 - INFO - epoch 0, step 17950, training loss = 3.357686, validation loss = 3.260846
2018-08-12 03:23:49,103 - INFO - epoch 0, step 17960, training loss = 3.045899, validation loss = 3.263102
2018-08-12 03:23:54,851 - INFO - epoch 0, step 17970, training loss = 3.396380, validation loss = 3.287278
2018-08-12 03:24:00,859 - INFO - epoch 0, step 17980, training loss = 3.412931, validation loss = 3.264307
2018-08-12 03:24:07,003 - INFO - epoch 0, step 17990, training loss = 3.044437, validation loss = 3.257563
2018-08-12 03:24:13,063 - INFO - epoch 0, step 18000, training loss = 2.979097, validation loss = 3.263672
2018-08-12 03:24:19,041 - INFO - epoch 0, step 18010, training loss = 2.774065, validation loss = 3.287881
2018-08-12 03:24:24,966 - INFO - epoch 0, step 18020, training loss = 3.148551, validation loss = 3.257374
2018-08-12 03:24:30,978 - INFO - epoch 0, step 18030, training loss = 3.255718, validation loss = 3.230834
2018-08-12 03:24:37,483 - INFO - epoch 0, step 18040, training loss = 3.140362, validation loss = 3.259312
2018-08-12 03:24:43,467 - INFO - epoch 0, step 18050, training loss = 3.096222, validation loss = 3.262264
2018-08-12 03:24:49,711 - INFO - epoch 0, step 18060, training loss = 3.405797, validation loss = 3.233229
2018-08-12 03:24:55,943 - INFO - epoch 0, step 18070, training loss = 3.200504, validation loss = 3.273625
2018-08-12 03:25:02,047 - INFO - epoch 0, step 18080, training loss = 3.200221, validation loss = 3.266309
2018-08-12 03:25:07,868 - INFO - epoch 0, step 18090, training loss = 3.339506, validation loss = 3.228433
2018-08-12 03:25:13,885 - INFO - epoch 0, step 18100, training loss = 2.793821, validation loss = 3.276436
2018-08-12 03:25:19,819 - INFO - epoch 0, step 18110, training loss = 3.079690, validation loss = 3.234251
2018-08-12 03:25:25,717 - INFO - epoch 0, step 18120, training loss = 3.016799, validation loss = 3.276347
2018-08-12 03:25:31,765 - INFO - epoch 0, step 18130, training loss = 3.168671, validation loss = 3.200613
2018-08-12 03:25:37,767 - INFO - epoch 0, step 18140, training loss = 2.955195, validation loss = 3.274868
2018-08-12 03:25:43,608 - INFO - epoch 0, step 18150, training loss = 3.030552, validation loss = 3.285864
2018-08-12 03:25:49,567 - INFO - epoch 0, step 18160, training loss = 3.125001, validation loss = 3.269236
2018-08-12 03:25:55,597 - INFO - epoch 0, step 18170, training loss = 2.705111, validation loss = 3.285631
2018-08-12 03:26:01,523 - INFO - epoch 0, step 18180, training loss = 2.927054, validation loss = 3.288356
2018-08-12 03:26:07,456 - INFO - epoch 0, step 18190, training loss = 2.746729, validation loss = 3.251885
2018-08-12 03:26:13,368 - INFO - epoch 0, step 18200, training loss = 3.243918, validation loss = 3.268758
2018-08-12 03:26:19,246 - INFO - epoch 0, step 18210, training loss = 3.274567, validation loss = 3.237658
2018-08-12 03:26:25,281 - INFO - epoch 0, step 18220, training loss = 3.040459, validation loss = 3.256639
2018-08-12 03:26:31,099 - INFO - epoch 0, step 18230, training loss = 2.868251, validation loss = 3.261420
2018-08-12 03:26:37,244 - INFO - epoch 0, step 18240, training loss = 3.149124, validation loss = 3.286314
2018-08-12 03:26:43,177 - INFO - epoch 0, step 18250, training loss = 2.882845, validation loss = 3.261233
2018-08-12 03:26:49,684 - INFO - epoch 0, step 18260, training loss = 3.148154, validation loss = 3.283737
2018-08-12 03:26:55,763 - INFO - epoch 0, step 18270, training loss = 3.016075, validation loss = 3.276715
2018-08-12 03:27:01,735 - INFO - epoch 0, step 18280, training loss = 2.834275, validation loss = 3.252282
2018-08-12 03:27:07,951 - INFO - epoch 0, step 18290, training loss = 2.923640, validation loss = 3.305150
2018-08-12 03:27:13,818 - INFO - epoch 0, step 18300, training loss = 3.033369, validation loss = 3.279676
2018-08-12 03:27:19,985 - INFO - epoch 0, step 18310, training loss = 2.572670, validation loss = 3.230534
2018-08-12 03:27:25,917 - INFO - epoch 0, step 18320, training loss = 3.275131, validation loss = 3.281995
2018-08-12 03:27:31,903 - INFO - epoch 0, step 18330, training loss = 2.897082, validation loss = 3.284295
2018-08-12 03:27:38,002 - INFO - epoch 0, step 18340, training loss = 2.734645, validation loss = 3.282156
2018-08-12 03:27:43,778 - INFO - epoch 0, step 18350, training loss = 2.910244, validation loss = 3.254572
2018-08-12 03:27:49,675 - INFO - epoch 0, step 18360, training loss = 2.561661, validation loss = 3.256577
2018-08-12 03:27:55,806 - INFO - epoch 0, step 18370, training loss = 3.178269, validation loss = 3.287039
2018-08-12 03:28:01,766 - INFO - epoch 0, step 18380, training loss = 3.226277, validation loss = 3.296668
2018-08-12 03:28:07,689 - INFO - epoch 0, step 18390, training loss = 3.464806, validation loss = 3.238881
2018-08-12 03:28:13,673 - INFO - epoch 0, step 18400, training loss = 3.615268, validation loss = 3.151165
2018-08-12 03:28:19,417 - INFO - epoch 0, step 18410, training loss = 3.727278, validation loss = 3.224695
2018-08-12 03:28:25,627 - INFO - epoch 0, step 18420, training loss = 3.192149, validation loss = 3.223294
2018-08-12 03:28:31,500 - INFO - epoch 0, step 18430, training loss = 3.683732, validation loss = 3.151952
2018-08-12 03:28:37,244 - INFO - epoch 0, step 18440, training loss = 3.325896, validation loss = 3.286940
2018-08-12 03:28:43,221 - INFO - epoch 0, step 18450, training loss = 3.961828, validation loss = 3.143460
2018-08-12 03:28:48,870 - INFO - epoch 0, step 18460, training loss = 3.527670, validation loss = 3.257873
2018-08-12 03:28:54,825 - INFO - epoch 0, step 18470, training loss = 3.683501, validation loss = 3.196221
2018-08-12 03:29:01,091 - INFO - epoch 0, step 18480, training loss = 3.648139, validation loss = 3.170131
2018-08-12 03:29:07,161 - INFO - epoch 0, step 18490, training loss = 3.721513, validation loss = 3.147955
2018-08-12 03:29:12,797 - INFO - epoch 0, step 18500, training loss = 3.772442, validation loss = 3.278880
2018-08-12 03:29:18,595 - INFO - epoch 0, step 18510, training loss = 2.828098, validation loss = 3.225328
2018-08-12 03:29:24,755 - INFO - epoch 0, step 18520, training loss = 3.464867, validation loss = 3.178987
2018-08-12 03:29:30,364 - INFO - epoch 0, step 18530, training loss = 3.480699, validation loss = 3.259382
2018-08-12 03:29:36,291 - INFO - epoch 0, step 18540, training loss = 3.323358, validation loss = 3.202217
2018-08-12 03:29:42,301 - INFO - epoch 0, step 18550, training loss = 3.829269, validation loss = 3.219602
2018-08-12 03:29:48,253 - INFO - epoch 0, step 18560, training loss = 3.460833, validation loss = 3.219203
2018-08-12 03:29:53,718 - INFO - epoch 0, step 18570, training loss = 3.205115, validation loss = 3.284684
2018-08-12 03:29:59,335 - INFO - epoch 0, step 18580, training loss = 3.522274, validation loss = 3.214869
2018-08-12 03:30:05,102 - INFO - epoch 0, step 18590, training loss = 3.769932, validation loss = 3.191972
2018-08-12 03:30:10,723 - INFO - epoch 0, step 18600, training loss = 3.611667, validation loss = 3.227389
2018-08-12 03:30:16,603 - INFO - epoch 0, step 18610, training loss = 3.682336, validation loss = 3.278508
2018-08-12 03:30:22,611 - INFO - epoch 0, step 18620, training loss = 3.334466, validation loss = 3.148497
2018-08-12 03:30:28,536 - INFO - epoch 0, step 18630, training loss = 3.729358, validation loss = 3.187365
2018-08-12 03:30:34,500 - INFO - epoch 0, step 18640, training loss = 3.482013, validation loss = 3.250695
2018-08-12 03:30:40,257 - INFO - epoch 0, step 18650, training loss = 3.466434, validation loss = 3.239351
2018-08-12 03:30:45,810 - INFO - epoch 0, step 18660, training loss = 4.088400, validation loss = 3.225610
2018-08-12 03:30:51,388 - INFO - epoch 0, step 18670, training loss = 3.623284, validation loss = 3.256551
2018-08-12 03:30:57,019 - INFO - epoch 0, step 18680, training loss = 3.587990, validation loss = 3.304526
2018-08-12 03:31:02,562 - INFO - epoch 0, step 18690, training loss = 3.544294, validation loss = 3.258085
2018-08-12 03:31:08,542 - INFO - epoch 0, step 18700, training loss = 2.994736, validation loss = 3.227811
2018-08-12 03:31:14,256 - INFO - epoch 0, step 18710, training loss = 3.990582, validation loss = 3.280619
2018-08-12 03:31:20,324 - INFO - epoch 0, step 18720, training loss = 3.596367, validation loss = 3.173800
2018-08-12 03:31:25,996 - INFO - epoch 0, step 18730, training loss = 3.653518, validation loss = 3.243664
2018-08-12 03:31:32,067 - INFO - epoch 0, step 18740, training loss = 3.252353, validation loss = 3.217619
2018-08-12 03:31:37,646 - INFO - epoch 0, step 18750, training loss = 3.692136, validation loss = 3.234051
2018-08-12 03:31:41,643 - INFO - Model saved in dir ./models
