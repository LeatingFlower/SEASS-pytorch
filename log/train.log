2018-12-07 14:52:31,683 - INFO - Start to train...
2018-12-07 14:52:49,013 - INFO - epoch 0, step 50, training loss = 7.664495, validation loss = 7.977621
2018-12-07 14:53:06,707 - INFO - epoch 0, step 100, training loss = 7.338233, validation loss = 7.713603
2018-12-07 14:53:24,388 - INFO - epoch 0, step 150, training loss = 7.178923, validation loss = 7.454870
2018-12-07 14:53:45,227 - INFO - epoch 0, step 200, training loss = 7.034965, validation loss = 7.620396
2018-12-07 14:54:04,715 - INFO - epoch 0, step 250, training loss = 6.792377, validation loss = 7.108237
2018-12-07 14:54:24,440 - INFO - epoch 0, step 300, training loss = 6.720368, validation loss = 7.090317
2018-12-07 14:54:43,219 - INFO - epoch 0, step 350, training loss = 6.757203, validation loss = 7.137617
2018-12-07 14:55:02,317 - INFO - epoch 0, step 400, training loss = 6.498993, validation loss = 7.261187
2018-12-07 14:55:21,810 - INFO - epoch 0, step 450, training loss = 6.836342, validation loss = 7.151051
2018-12-07 14:55:41,748 - INFO - epoch 0, step 500, training loss = 6.864139, validation loss = 7.158141
2018-12-07 14:56:01,540 - INFO - epoch 0, step 550, training loss = 6.785866, validation loss = 6.810561
2018-12-07 14:56:21,169 - INFO - epoch 0, step 600, training loss = 6.252470, validation loss = 6.395290
2018-12-07 14:56:41,368 - INFO - epoch 0, step 650, training loss = 6.559714, validation loss = 6.243381
2018-12-07 14:57:00,916 - INFO - epoch 0, step 700, training loss = 6.317528, validation loss = 6.561929
2018-12-07 14:57:20,695 - INFO - epoch 0, step 750, training loss = 6.651417, validation loss = 6.788345
2018-12-07 14:57:41,122 - INFO - epoch 0, step 800, training loss = 6.458731, validation loss = 5.795192
2018-12-07 14:58:02,190 - INFO - epoch 0, step 850, training loss = 6.383866, validation loss = 6.200055
2018-12-07 14:58:22,416 - INFO - epoch 0, step 900, training loss = 6.592120, validation loss = 6.530108
2018-12-07 14:58:43,606 - INFO - epoch 0, step 950, training loss = 5.213963, validation loss = 6.446240
2018-12-07 14:59:04,052 - INFO - epoch 0, step 1000, training loss = 5.430467, validation loss = 5.967411
2018-12-07 14:59:24,140 - INFO - epoch 0, step 1050, training loss = 5.927611, validation loss = 6.357979
2018-12-07 14:59:43,761 - INFO - epoch 0, step 1100, training loss = 5.481145, validation loss = 6.309216
2018-12-07 15:00:03,675 - INFO - epoch 0, step 1150, training loss = 5.438614, validation loss = 5.931373
2018-12-07 15:00:23,307 - INFO - epoch 0, step 1200, training loss = 6.228191, validation loss = 6.183343
2018-12-07 15:00:43,373 - INFO - epoch 0, step 1250, training loss = 5.743245, validation loss = 5.945527
2018-12-07 15:01:03,049 - INFO - epoch 0, step 1300, training loss = 6.023337, validation loss = 6.202878
2018-12-07 15:01:20,724 - INFO - epoch 0, step 1350, training loss = 6.103774, validation loss = 5.976562
2018-12-07 15:01:38,455 - INFO - epoch 0, step 1400, training loss = 5.403880, validation loss = 5.823431
2018-12-07 15:01:56,974 - INFO - epoch 0, step 1450, training loss = 5.683578, validation loss = 5.811426
2018-12-07 15:02:17,653 - INFO - epoch 0, step 1500, training loss = 4.981986, validation loss = 6.269317
2018-12-07 15:02:36,174 - INFO - epoch 0, step 1550, training loss = 5.899415, validation loss = 6.031398
2018-12-07 15:02:54,423 - INFO - epoch 0, step 1600, training loss = 5.838745, validation loss = 5.562519
2018-12-07 15:03:12,306 - INFO - epoch 0, step 1650, training loss = 5.793548, validation loss = 5.903496
2018-12-07 15:03:32,567 - INFO - epoch 0, step 1700, training loss = 6.028679, validation loss = 6.111624
2018-12-07 15:03:49,278 - INFO - epoch 0, step 1750, training loss = 5.859567, validation loss = 5.904815
2018-12-07 15:04:05,325 - INFO - epoch 0, step 1800, training loss = 5.623209, validation loss = 5.422028
2018-12-07 15:04:22,297 - INFO - epoch 0, step 1850, training loss = 5.460885, validation loss = 5.936949
2018-12-07 15:04:42,746 - INFO - epoch 0, step 1900, training loss = 5.768417, validation loss = 6.138075
2018-12-07 15:05:03,384 - INFO - epoch 0, step 1950, training loss = 5.361120, validation loss = 5.469537
2018-12-07 15:05:19,581 - INFO - epoch 0, step 2000, training loss = 5.555962, validation loss = 5.329990
2018-12-07 15:05:35,542 - INFO - epoch 0, step 2050, training loss = 5.288036, validation loss = 6.013495
2018-12-07 15:05:51,859 - INFO - epoch 0, step 2100, training loss = 5.334854, validation loss = 5.967883
2018-12-07 15:06:08,114 - INFO - epoch 0, step 2150, training loss = 4.520236, validation loss = 5.884369
2018-12-07 15:06:24,815 - INFO - epoch 0, step 2200, training loss = 5.874293, validation loss = 5.212979
2018-12-07 15:06:42,375 - INFO - epoch 0, step 2250, training loss = 5.424227, validation loss = 6.039217
2018-12-07 15:07:00,862 - INFO - epoch 0, step 2300, training loss = 5.006486, validation loss = 5.748574
2018-12-07 15:07:20,340 - INFO - epoch 0, step 2350, training loss = 5.229528, validation loss = 6.082194
2018-12-07 15:07:39,996 - INFO - epoch 0, step 2400, training loss = 5.259015, validation loss = 5.986849
2018-12-07 15:07:58,922 - INFO - epoch 0, step 2450, training loss = 5.275010, validation loss = 5.751407
2018-12-07 15:08:16,474 - INFO - epoch 0, step 2500, training loss = 5.576269, validation loss = 5.543514
2018-12-07 15:08:33,542 - INFO - epoch 0, step 2550, training loss = 4.966695, validation loss = 5.426038
2018-12-07 15:08:51,136 - INFO - epoch 0, step 2600, training loss = 5.114356, validation loss = 5.416833
2018-12-07 15:09:08,774 - INFO - epoch 0, step 2650, training loss = 5.276038, validation loss = 5.722952
2018-12-07 15:09:28,919 - INFO - epoch 0, step 2700, training loss = 5.884425, validation loss = 5.634130
2018-12-07 15:09:49,235 - INFO - epoch 0, step 2750, training loss = 5.068033, validation loss = 4.733503
2018-12-07 15:10:09,502 - INFO - epoch 0, step 2800, training loss = 5.636754, validation loss = 5.494008
2018-12-07 15:10:27,642 - INFO - epoch 0, step 2850, training loss = 5.209940, validation loss = 5.625214
2018-12-07 15:10:45,234 - INFO - epoch 0, step 2900, training loss = 5.296578, validation loss = 5.326085
2018-12-07 15:11:03,736 - INFO - epoch 0, step 2950, training loss = 4.974249, validation loss = 5.031811
2018-12-07 15:11:24,484 - INFO - epoch 0, step 3000, training loss = 4.842076, validation loss = 5.306785
2018-12-07 15:11:45,867 - INFO - epoch 0, step 3050, training loss = 4.711230, validation loss = 5.535809
2018-12-07 15:12:06,194 - INFO - epoch 0, step 3100, training loss = 4.713457, validation loss = 5.453095
2018-12-07 15:12:26,348 - INFO - epoch 0, step 3150, training loss = 4.989549, validation loss = 4.835331
2018-12-07 15:12:46,488 - INFO - epoch 0, step 3200, training loss = 5.300541, validation loss = 5.620994
2018-12-07 15:13:07,529 - INFO - epoch 0, step 3250, training loss = 5.135293, validation loss = 5.068576
2018-12-07 15:13:26,904 - INFO - epoch 0, step 3300, training loss = 5.356370, validation loss = 5.478260
2018-12-07 15:13:45,204 - INFO - epoch 0, step 3350, training loss = 4.777132, validation loss = 5.584901
2018-12-07 15:14:03,796 - INFO - epoch 0, step 3400, training loss = 5.785393, validation loss = 5.521308
2018-12-07 15:14:23,357 - INFO - epoch 0, step 3450, training loss = 5.037166, validation loss = 5.363963
2018-12-07 15:14:42,646 - INFO - epoch 0, step 3500, training loss = 4.728589, validation loss = 5.585662
2018-12-07 15:15:00,738 - INFO - epoch 0, step 3550, training loss = 4.684752, validation loss = 5.096937
2018-12-07 15:15:18,852 - INFO - epoch 0, step 3600, training loss = 5.170720, validation loss = 5.461931
2018-12-07 15:15:37,072 - INFO - epoch 0, step 3650, training loss = 5.327776, validation loss = 5.501434
2018-12-07 15:15:55,933 - INFO - epoch 0, step 3700, training loss = 5.012601, validation loss = 5.708832
2018-12-07 15:16:13,331 - INFO - epoch 0, step 3750, training loss = 5.325085, validation loss = 5.390186
2018-12-07 15:16:29,418 - INFO - epoch 0, step 3800, training loss = 3.840458, validation loss = 5.233781
2018-12-07 15:16:45,920 - INFO - epoch 0, step 3850, training loss = 4.780095, validation loss = 5.590489
2018-12-07 15:17:03,853 - INFO - epoch 0, step 3900, training loss = 4.658995, validation loss = 5.180971
2018-12-07 15:17:23,984 - INFO - epoch 0, step 3950, training loss = 5.157671, validation loss = 5.113369
2018-12-07 15:17:43,495 - INFO - epoch 0, step 4000, training loss = 4.766341, validation loss = 5.862206
2018-12-07 15:18:01,268 - INFO - epoch 0, step 4050, training loss = 4.749028, validation loss = 5.661009
2018-12-07 15:18:18,654 - INFO - epoch 0, step 4100, training loss = 4.494370, validation loss = 5.084916
2018-12-07 15:18:36,504 - INFO - epoch 0, step 4150, training loss = 4.577787, validation loss = 4.912904
2018-12-07 15:18:53,576 - INFO - epoch 0, step 4200, training loss = 4.913217, validation loss = 5.342235
2018-12-07 15:19:11,861 - INFO - epoch 0, step 4250, training loss = 5.049944, validation loss = 5.535639
2018-12-07 15:19:30,511 - INFO - epoch 0, step 4300, training loss = 4.914529, validation loss = 5.131718
2018-12-07 15:19:49,497 - INFO - epoch 0, step 4350, training loss = 5.064716, validation loss = 4.605538
2018-12-07 15:20:08,591 - INFO - epoch 0, step 4400, training loss = 5.615119, validation loss = 4.234926
2018-12-07 15:20:28,555 - INFO - epoch 0, step 4450, training loss = 5.451994, validation loss = 4.268867
2018-12-07 15:20:48,010 - INFO - epoch 0, step 4500, training loss = 4.842620, validation loss = 4.793578
2018-12-07 15:21:07,761 - INFO - epoch 0, step 4550, training loss = 4.386254, validation loss = 4.587588
2018-12-07 15:21:27,157 - INFO - epoch 0, step 4600, training loss = 4.670866, validation loss = 5.034532
2018-12-07 15:21:46,895 - INFO - epoch 0, step 4650, training loss = 4.710755, validation loss = 4.569362
2018-12-07 15:22:10,477 - INFO - epoch 0, step 4700, training loss = 5.282972, validation loss = 4.069123
2018-12-07 15:22:33,554 - INFO - epoch 0, step 4750, training loss = 5.052514, validation loss = 4.871457
2018-12-07 15:22:56,471 - INFO - epoch 0, step 4800, training loss = 4.705954, validation loss = 4.624670
2018-12-07 15:23:18,289 - INFO - epoch 0, step 4850, training loss = 4.793740, validation loss = 4.910625
2018-12-07 15:23:38,864 - INFO - epoch 0, step 4900, training loss = 5.233404, validation loss = 4.746782
2018-12-07 15:23:57,306 - INFO - epoch 0, step 4950, training loss = 4.381358, validation loss = 4.538371
2018-12-07 15:24:16,830 - INFO - epoch 0, step 5000, training loss = 5.075933, validation loss = 4.479425
2018-12-07 15:24:40,929 - INFO - epoch 0, step 5050, training loss = 4.641047, validation loss = 5.079723
2018-12-07 15:25:05,411 - INFO - epoch 0, step 5100, training loss = 4.080544, validation loss = 5.194077
2018-12-07 15:25:27,275 - INFO - epoch 0, step 5150, training loss = 4.997869, validation loss = 5.090138
2018-12-07 15:25:48,055 - INFO - epoch 0, step 5200, training loss = 4.073621, validation loss = 5.029887
2018-12-07 15:26:12,020 - INFO - epoch 0, step 5250, training loss = 5.031986, validation loss = 4.492719
2018-12-07 15:26:35,184 - INFO - epoch 0, step 5300, training loss = 5.082488, validation loss = 4.451362
2018-12-07 15:26:57,273 - INFO - epoch 0, step 5350, training loss = 4.357950, validation loss = 4.734818
2018-12-07 15:27:19,327 - INFO - epoch 0, step 5400, training loss = 4.763224, validation loss = 5.071446
2018-12-07 15:27:41,136 - INFO - epoch 0, step 5450, training loss = 4.572515, validation loss = 4.244009
2018-12-07 15:28:02,780 - INFO - epoch 0, step 5500, training loss = 5.061201, validation loss = 4.305047
2018-12-07 15:28:25,297 - INFO - epoch 0, step 5550, training loss = 4.593499, validation loss = 4.639784
2018-12-07 15:28:49,213 - INFO - epoch 0, step 5600, training loss = 4.690916, validation loss = 4.911322
2018-12-07 15:29:13,635 - INFO - epoch 0, step 5650, training loss = 4.543508, validation loss = 4.958202
2018-12-07 15:29:39,053 - INFO - epoch 0, step 5700, training loss = 4.967612, validation loss = 5.384347
2018-12-07 15:30:04,963 - INFO - epoch 0, step 5750, training loss = 4.799436, validation loss = 5.152770
2018-12-07 15:30:31,310 - INFO - epoch 0, step 5800, training loss = 4.688889, validation loss = 5.068901
2018-12-07 15:30:57,036 - INFO - epoch 0, step 5850, training loss = 4.775115, validation loss = 4.758453
2018-12-07 15:31:18,360 - INFO - epoch 0, step 5900, training loss = 4.625839, validation loss = 4.325217
2018-12-07 15:31:39,183 - INFO - epoch 0, step 5950, training loss = 4.190217, validation loss = 4.022493
2018-12-07 15:32:04,241 - INFO - epoch 0, step 6000, training loss = 4.624498, validation loss = 4.178883
2018-12-07 15:32:30,553 - INFO - epoch 0, step 6050, training loss = 4.478889, validation loss = 5.011118
2018-12-07 15:32:55,988 - INFO - epoch 0, step 6100, training loss = 4.593670, validation loss = 4.621986
2018-12-07 15:33:22,241 - INFO - epoch 0, step 6150, training loss = 4.733274, validation loss = 4.773696
2018-12-07 15:33:47,789 - INFO - epoch 0, step 6200, training loss = 4.853967, validation loss = 4.275969
2018-12-07 15:34:12,039 - INFO - epoch 0, step 6250, training loss = 4.319631, validation loss = 4.626795
2018-12-07 15:34:34,593 - INFO - epoch 0, step 6300, training loss = 5.031547, validation loss = 4.351854
2018-12-07 15:34:54,199 - INFO - epoch 0, step 6350, training loss = 4.566377, validation loss = 4.924810
2018-12-07 15:35:13,977 - INFO - epoch 0, step 6400, training loss = 4.422776, validation loss = 4.440997
2018-12-07 15:35:34,550 - INFO - epoch 0, step 6450, training loss = 4.224432, validation loss = 4.328479
2018-12-07 15:35:55,402 - INFO - epoch 0, step 6500, training loss = 3.848353, validation loss = 3.844447
2018-12-07 15:36:16,307 - INFO - epoch 0, step 6550, training loss = 4.393185, validation loss = 4.006921
2018-12-07 15:36:36,976 - INFO - epoch 0, step 6600, training loss = 4.627120, validation loss = 4.837841
2018-12-07 15:36:58,163 - INFO - epoch 0, step 6650, training loss = 4.688649, validation loss = 4.699274
2018-12-07 15:37:21,292 - INFO - epoch 0, step 6700, training loss = 4.694837, validation loss = 4.838488
2018-12-07 15:37:44,201 - INFO - epoch 0, step 6750, training loss = 4.675233, validation loss = 4.449791
2018-12-07 15:38:06,590 - INFO - epoch 0, step 6800, training loss = 4.664755, validation loss = 4.345106
2018-12-07 15:38:28,642 - INFO - epoch 0, step 6850, training loss = 4.428972, validation loss = 3.951578
2018-12-07 15:38:50,517 - INFO - epoch 0, step 6900, training loss = 3.852571, validation loss = 4.241099
2018-12-07 15:39:14,304 - INFO - epoch 0, step 6950, training loss = 4.693351, validation loss = 4.254345
2018-12-07 15:39:38,938 - INFO - epoch 0, step 7000, training loss = 4.834848, validation loss = 4.576602
2018-12-07 15:40:04,899 - INFO - epoch 0, step 7050, training loss = 4.298553, validation loss = 4.707951
2018-12-07 15:40:29,670 - INFO - epoch 0, step 7100, training loss = 4.464336, validation loss = 3.931086
2018-12-07 15:40:55,334 - INFO - epoch 0, step 7150, training loss = 4.193439, validation loss = 3.781013
2018-12-07 15:41:20,162 - INFO - epoch 0, step 7200, training loss = 4.321520, validation loss = 4.499732
2018-12-07 15:41:44,108 - INFO - epoch 0, step 7250, training loss = 4.393575, validation loss = 4.654101
2018-12-07 15:42:06,553 - INFO - epoch 0, step 7300, training loss = 4.327200, validation loss = 4.880575
2018-12-07 15:42:29,198 - INFO - epoch 0, step 7350, training loss = 4.751296, validation loss = 4.759610
2018-12-07 15:42:51,028 - INFO - epoch 0, step 7400, training loss = 4.344632, validation loss = 4.600910
2018-12-07 15:43:11,701 - INFO - epoch 0, step 7450, training loss = 4.609232, validation loss = 4.744984
2018-12-07 15:43:31,734 - INFO - epoch 0, step 7500, training loss = 3.352731, validation loss = 4.418365
2018-12-07 15:43:52,030 - INFO - epoch 0, step 7550, training loss = 4.136624, validation loss = 4.732941
2018-12-07 15:44:13,771 - INFO - epoch 0, step 7600, training loss = 4.289480, validation loss = 4.254324
2018-12-07 15:44:36,356 - INFO - epoch 0, step 7650, training loss = 3.977731, validation loss = 3.913040
2018-12-07 15:44:58,997 - INFO - epoch 0, step 7700, training loss = 3.979227, validation loss = 4.303905
2018-12-07 15:45:21,276 - INFO - epoch 0, step 7750, training loss = 3.967153, validation loss = 4.661428
2018-12-07 15:45:43,973 - INFO - epoch 0, step 7800, training loss = 4.618219, validation loss = 4.500241
2018-12-07 15:46:07,843 - INFO - epoch 0, step 7850, training loss = 4.738089, validation loss = 4.572945
2018-12-07 15:46:31,561 - INFO - epoch 0, step 7900, training loss = 4.120718, validation loss = 4.080594
2018-12-07 15:46:55,554 - INFO - epoch 0, step 7950, training loss = 3.748790, validation loss = 3.813159
2018-12-07 15:47:20,851 - INFO - epoch 0, step 8000, training loss = 4.452960, validation loss = 4.361856
2018-12-07 15:47:46,251 - INFO - epoch 0, step 8050, training loss = 4.021341, validation loss = 4.367273
2018-12-07 15:48:11,974 - INFO - epoch 0, step 8100, training loss = 4.187933, validation loss = 4.571028
2018-12-07 15:48:38,199 - INFO - epoch 0, step 8150, training loss = 4.860932, validation loss = 4.513457
2018-12-07 15:49:04,563 - INFO - epoch 0, step 8200, training loss = 4.615183, validation loss = 4.215047
2018-12-07 15:49:29,867 - INFO - epoch 0, step 8250, training loss = 4.192792, validation loss = 3.812076
2018-12-07 15:49:52,831 - INFO - epoch 0, step 8300, training loss = 4.309768, validation loss = 3.660847
2018-12-07 15:50:13,397 - INFO - epoch 0, step 8350, training loss = 3.891025, validation loss = 4.458614
2018-12-07 15:50:33,999 - INFO - epoch 0, step 8400, training loss = 4.248614, validation loss = 4.178560
2018-12-07 15:50:58,074 - INFO - epoch 0, step 8450, training loss = 4.507831, validation loss = 4.635612
2018-12-07 15:51:22,853 - INFO - epoch 0, step 8500, training loss = 4.078802, validation loss = 4.797727
2018-12-07 15:51:45,283 - INFO - epoch 0, step 8550, training loss = 4.468777, validation loss = 4.075110
2018-12-07 15:52:06,089 - INFO - epoch 0, step 8600, training loss = 3.307579, validation loss = 3.802683
2018-12-07 15:52:26,593 - INFO - epoch 0, step 8650, training loss = 4.033355, validation loss = 3.656757
2018-12-07 15:52:48,020 - INFO - epoch 0, step 8700, training loss = 4.427837, validation loss = 4.144677
2018-12-07 15:53:10,210 - INFO - epoch 0, step 8750, training loss = 4.875062, validation loss = 4.166058
2018-12-07 15:53:31,415 - INFO - epoch 0, step 8800, training loss = 3.978196, validation loss = 4.985948
2018-12-07 15:53:52,072 - INFO - epoch 0, step 8850, training loss = 4.002071, validation loss = 4.732881
2018-12-07 15:54:13,212 - INFO - epoch 0, step 8900, training loss = 4.665215, validation loss = 3.935267
2018-12-07 15:54:34,551 - INFO - epoch 0, step 8950, training loss = 4.726178, validation loss = 3.969661
2018-12-07 15:54:54,663 - INFO - epoch 0, step 9000, training loss = 4.140356, validation loss = 4.270823
2018-12-07 15:55:15,690 - INFO - epoch 0, step 9050, training loss = 4.560810, validation loss = 4.510645
2018-12-07 15:55:37,674 - INFO - epoch 0, step 9100, training loss = 4.213672, validation loss = 4.574558
2018-12-07 15:56:00,553 - INFO - epoch 0, step 9150, training loss = 3.823581, validation loss = 4.327602
2018-12-07 15:56:20,701 - INFO - epoch 0, step 9200, training loss = 3.072627, validation loss = 4.435616
2018-12-07 15:56:41,384 - INFO - epoch 0, step 9250, training loss = 3.066300, validation loss = 4.867983
2018-12-07 15:57:03,014 - INFO - epoch 0, step 9300, training loss = 4.094568, validation loss = 4.573510
2018-12-07 15:57:24,667 - INFO - epoch 0, step 9350, training loss = 4.323119, validation loss = 4.382271
2018-12-07 15:57:48,787 - INFO - epoch 0, step 9400, training loss = 4.266863, validation loss = 3.920933
2018-12-07 15:58:13,962 - INFO - epoch 0, step 9450, training loss = 4.593936, validation loss = 4.224880
2018-12-07 15:58:36,757 - INFO - epoch 0, step 9500, training loss = 3.086288, validation loss = 4.108108
2018-12-07 15:58:57,364 - INFO - epoch 0, step 9550, training loss = 3.844179, validation loss = 4.287397
2018-12-07 15:59:18,092 - INFO - epoch 0, step 9600, training loss = 3.316794, validation loss = 4.385820
2018-12-07 15:59:40,112 - INFO - epoch 0, step 9650, training loss = 3.094843, validation loss = 4.065237
2018-12-07 16:00:02,205 - INFO - epoch 0, step 9700, training loss = 4.033300, validation loss = 4.671670
2018-12-07 16:00:28,435 - INFO - epoch 0, step 9750, training loss = 4.008511, validation loss = 4.525233
2018-12-07 16:00:54,704 - INFO - epoch 0, step 9800, training loss = 3.922813, validation loss = 3.688884
2018-12-07 16:01:19,331 - INFO - epoch 0, step 9850, training loss = 3.508098, validation loss = 3.953499
2018-12-07 16:01:40,609 - INFO - epoch 0, step 9900, training loss = 3.046682, validation loss = 4.452704
2018-12-07 16:02:02,344 - INFO - epoch 0, step 9950, training loss = 3.749502, validation loss = 3.905662
2018-12-07 16:02:24,319 - INFO - epoch 0, step 10000, training loss = 4.422679, validation loss = 4.188884
2018-12-07 16:02:45,697 - INFO - epoch 0, step 10050, training loss = 4.076751, validation loss = 4.031641
2018-12-07 16:03:06,724 - INFO - epoch 0, step 10100, training loss = 3.954486, validation loss = 3.385059
2018-12-07 16:03:27,324 - INFO - epoch 0, step 10150, training loss = 3.622013, validation loss = 3.943916
2018-12-07 16:03:50,092 - INFO - epoch 0, step 10200, training loss = 4.164071, validation loss = 4.226958
2018-12-07 16:04:12,218 - INFO - epoch 0, step 10250, training loss = 4.180017, validation loss = 4.591766
2018-12-07 16:04:33,269 - INFO - epoch 0, step 10300, training loss = 3.985113, validation loss = 4.902280
2018-12-07 16:04:55,940 - INFO - epoch 0, step 10350, training loss = 4.271910, validation loss = 3.634079
2018-12-07 16:05:21,281 - INFO - epoch 0, step 10400, training loss = 4.751551, validation loss = 3.759561
2018-12-07 16:05:47,925 - INFO - epoch 0, step 10450, training loss = 4.049916, validation loss = 4.068832
2018-12-07 16:06:13,159 - INFO - epoch 0, step 10500, training loss = 4.313288, validation loss = 3.941289
2018-12-07 16:06:37,422 - INFO - epoch 0, step 10550, training loss = 4.499092, validation loss = 4.576488
2018-12-07 16:07:00,243 - INFO - epoch 0, step 10600, training loss = 3.956868, validation loss = 4.305347
2018-12-07 16:07:22,658 - INFO - epoch 0, step 10650, training loss = 4.368726, validation loss = 4.095778
2018-12-07 16:07:45,534 - INFO - epoch 0, step 10700, training loss = 4.800089, validation loss = 3.476659
2018-12-07 16:08:08,682 - INFO - epoch 0, step 10750, training loss = 3.743171, validation loss = 3.764436
2018-12-07 16:08:31,715 - INFO - epoch 0, step 10800, training loss = 4.095200, validation loss = 3.944914
2018-12-07 16:08:54,592 - INFO - epoch 0, step 10850, training loss = 4.136275, validation loss = 4.248902
2018-12-07 16:09:16,752 - INFO - epoch 0, step 10900, training loss = 4.103422, validation loss = 4.333285
2018-12-07 16:09:37,574 - INFO - epoch 0, step 10950, training loss = 3.322102, validation loss = 3.567686
2018-12-07 16:09:58,428 - INFO - epoch 0, step 11000, training loss = 4.186159, validation loss = 4.029663
2018-12-07 16:10:20,215 - INFO - epoch 0, step 11050, training loss = 4.236041, validation loss = 4.354883
2018-12-07 16:10:44,150 - INFO - epoch 0, step 11100, training loss = 4.287590, validation loss = 4.565019
2018-12-07 16:11:06,669 - INFO - epoch 0, step 11150, training loss = 3.375011, validation loss = 4.672675
2018-12-07 16:11:29,326 - INFO - epoch 0, step 11200, training loss = 4.060612, validation loss = 3.382850
2018-12-07 16:11:51,441 - INFO - epoch 0, step 11250, training loss = 3.731865, validation loss = 3.570499
2018-12-07 16:12:12,178 - INFO - epoch 0, step 11300, training loss = 3.867272, validation loss = 4.370065
2018-12-07 16:12:33,737 - INFO - epoch 0, step 11350, training loss = 3.683156, validation loss = 4.253086
2018-12-07 16:12:55,608 - INFO - epoch 0, step 11400, training loss = 4.343119, validation loss = 4.173685
2018-12-07 16:13:17,207 - INFO - epoch 0, step 11450, training loss = 3.933963, validation loss = 3.612988
2018-12-07 16:13:41,700 - INFO - epoch 0, step 11500, training loss = 4.723965, validation loss = 3.739033
2018-12-07 16:14:05,387 - INFO - epoch 0, step 11550, training loss = 3.426070, validation loss = 4.200959
2018-12-07 16:14:30,558 - INFO - epoch 0, step 11600, training loss = 4.200832, validation loss = 4.575836
2018-12-07 16:14:54,777 - INFO - epoch 0, step 11650, training loss = 3.452820, validation loss = 4.422499
2018-12-07 16:15:16,469 - INFO - epoch 0, step 11700, training loss = 3.925671, validation loss = 4.673614
2018-12-07 16:15:37,932 - INFO - epoch 0, step 11750, training loss = 3.622636, validation loss = 4.622846
2018-12-07 16:16:00,823 - INFO - epoch 0, step 11800, training loss = 4.250510, validation loss = 3.879603
2018-12-07 16:16:24,676 - INFO - epoch 0, step 11850, training loss = 3.750286, validation loss = 3.910278
2018-12-07 16:16:48,257 - INFO - epoch 0, step 11900, training loss = 4.303050, validation loss = 3.831869
2018-12-07 16:17:10,665 - INFO - epoch 0, step 11950, training loss = 2.915934, validation loss = 4.513539
2018-12-07 16:17:32,534 - INFO - epoch 0, step 12000, training loss = 3.634019, validation loss = 4.083952
2018-12-07 16:17:54,831 - INFO - epoch 0, step 12050, training loss = 4.205422, validation loss = 3.596780
2018-12-07 16:18:20,313 - INFO - epoch 0, step 12100, training loss = 4.418373, validation loss = 3.913085
2018-12-07 16:18:45,359 - INFO - epoch 0, step 12150, training loss = 4.136806, validation loss = 4.138499
2018-12-07 16:19:10,919 - INFO - epoch 0, step 12200, training loss = 3.784950, validation loss = 4.008339
2018-12-07 16:19:36,119 - INFO - epoch 0, step 12250, training loss = 4.002976, validation loss = 3.930925
2018-12-07 16:20:01,574 - INFO - epoch 0, step 12300, training loss = 4.533642, validation loss = 3.560270
2018-12-07 16:20:24,228 - INFO - epoch 0, step 12350, training loss = 4.345619, validation loss = 3.751496
2018-12-07 16:20:46,153 - INFO - epoch 0, step 12400, training loss = 4.031671, validation loss = 3.943823
2018-12-07 16:21:10,979 - INFO - epoch 0, step 12450, training loss = 3.514765, validation loss = 4.492889
2018-12-07 16:21:35,127 - INFO - epoch 0, step 12500, training loss = 3.793251, validation loss = 3.783171
2018-12-07 16:21:59,249 - INFO - epoch 0, step 12550, training loss = 4.246946, validation loss = 3.408854
2018-12-07 16:22:21,684 - INFO - epoch 0, step 12600, training loss = 3.694869, validation loss = 3.905577
2018-12-07 16:22:44,372 - INFO - epoch 0, step 12650, training loss = 4.046608, validation loss = 4.481815
2018-12-07 16:23:06,221 - INFO - epoch 0, step 12700, training loss = 4.395607, validation loss = 4.407856
2018-12-07 16:23:26,826 - INFO - epoch 0, step 12750, training loss = 4.090507, validation loss = 3.635186
2018-12-07 16:23:48,219 - INFO - epoch 0, step 12800, training loss = 4.543329, validation loss = 3.517940
2018-12-07 16:24:11,843 - INFO - epoch 0, step 12850, training loss = 4.097424, validation loss = 3.712727
2018-12-07 16:24:34,618 - INFO - epoch 0, step 12900, training loss = 3.955544, validation loss = 3.847102
2018-12-07 16:24:55,537 - INFO - epoch 0, step 12950, training loss = 4.317603, validation loss = 4.282531
2018-12-07 16:25:16,144 - INFO - epoch 0, step 13000, training loss = 4.200327, validation loss = 4.751364
2018-12-07 16:25:36,674 - INFO - epoch 0, step 13050, training loss = 4.233856, validation loss = 4.305989
2018-12-07 16:26:01,184 - INFO - epoch 0, step 13100, training loss = 4.062390, validation loss = 4.366576
2018-12-07 16:26:25,147 - INFO - epoch 0, step 13150, training loss = 3.819251, validation loss = 3.923713
2018-12-07 16:26:48,735 - INFO - epoch 0, step 13200, training loss = 3.875651, validation loss = 3.351127
2018-12-07 16:27:08,914 - INFO - epoch 0, step 13250, training loss = 3.581222, validation loss = 3.989025
2018-12-07 16:27:30,143 - INFO - epoch 0, step 13300, training loss = 3.508208, validation loss = 4.136289
2018-12-07 16:27:51,932 - INFO - epoch 0, step 13350, training loss = 3.226652, validation loss = 4.516464
2018-12-07 16:28:13,688 - INFO - epoch 0, step 13400, training loss = 3.720572, validation loss = 3.299958
2018-12-07 16:28:34,808 - INFO - epoch 0, step 13450, training loss = 3.555656, validation loss = 3.738672
2018-12-07 16:28:58,863 - INFO - epoch 0, step 13500, training loss = 4.359644, validation loss = 3.651670
2018-12-07 16:29:24,260 - INFO - epoch 0, step 13550, training loss = 4.211276, validation loss = 4.525959
2018-12-07 16:29:49,643 - INFO - epoch 0, step 13600, training loss = 4.409349, validation loss = 4.021679
2018-12-07 16:30:10,611 - INFO - epoch 0, step 13650, training loss = 3.622754, validation loss = 3.245513
2018-12-07 16:30:31,731 - INFO - epoch 0, step 13700, training loss = 3.057595, validation loss = 3.479616
2018-12-07 16:30:53,806 - INFO - epoch 0, step 13750, training loss = 3.866778, validation loss = 4.155632
2018-12-07 16:31:17,076 - INFO - epoch 0, step 13800, training loss = 3.815763, validation loss = 4.533817
2018-12-07 16:31:37,929 - INFO - epoch 0, step 13850, training loss = 3.642470, validation loss = 4.118984
2018-12-07 16:32:01,097 - INFO - epoch 0, step 13900, training loss = 3.570945, validation loss = 3.452305
2018-12-07 16:32:26,093 - INFO - epoch 0, step 13950, training loss = 4.420289, validation loss = 3.585132
2018-12-07 16:32:51,695 - INFO - epoch 0, step 14000, training loss = 3.251256, validation loss = 3.934123
2018-12-07 16:33:15,894 - INFO - epoch 0, step 14050, training loss = 4.168096, validation loss = 4.680136
2018-12-07 16:33:37,983 - INFO - epoch 0, step 14100, training loss = 4.126183, validation loss = 3.455359
2018-12-07 16:34:01,414 - INFO - epoch 0, step 14150, training loss = 4.158094, validation loss = 3.416347
2018-12-07 16:34:24,273 - INFO - epoch 0, step 14200, training loss = 4.131506, validation loss = 3.754004
2018-12-07 16:34:48,747 - INFO - epoch 0, step 14250, training loss = 3.564543, validation loss = 4.251186
2018-12-07 16:35:14,065 - INFO - epoch 0, step 14300, training loss = 4.149474, validation loss = 3.941601
2018-12-07 16:35:38,953 - INFO - epoch 0, step 14350, training loss = 4.981214, validation loss = 4.231684
2018-12-07 16:35:58,084 - INFO - epoch 0, step 14400, training loss = 4.982511, validation loss = 4.227480
2018-12-07 16:36:17,383 - INFO - epoch 0, step 14450, training loss = 4.442816, validation loss = 3.906571
2018-12-07 16:36:36,885 - INFO - epoch 0, step 14500, training loss = 4.543087, validation loss = 3.521748
2018-12-07 16:36:57,365 - INFO - epoch 0, step 14550, training loss = 4.815970, validation loss = 3.666129
2018-12-07 16:37:18,775 - INFO - epoch 0, step 14600, training loss = 4.368711, validation loss = 4.240253
2018-12-07 16:37:46,354 - INFO - epoch 0, step 14650, training loss = 5.062333, validation loss = 4.121783
2018-12-07 16:38:14,992 - INFO - epoch 0, step 14700, training loss = 3.842250, validation loss = 3.686167
2018-12-07 16:38:34,350 - INFO - epoch 0, step 14750, training loss = 4.034775, validation loss = 3.259179
2018-12-07 16:38:53,758 - INFO - epoch 0, step 14800, training loss = 4.003708, validation loss = 4.329950
2018-12-07 16:39:13,345 - INFO - epoch 0, step 14850, training loss = 3.873330, validation loss = 4.515035
2018-12-07 16:39:46,338 - INFO - epoch 0, step 14900, training loss = 4.423366, validation loss = 4.281797
2018-12-07 16:40:19,291 - INFO - epoch 0, step 14950, training loss = 4.833744, validation loss = 3.883746
2018-12-07 16:40:53,970 - INFO - epoch 0, step 15000, training loss = 4.396097, validation loss = 3.901660
2018-12-07 16:41:27,158 - INFO - epoch 0, step 15050, training loss = 4.707833, validation loss = 4.051904
2018-12-07 16:42:02,492 - INFO - epoch 0, step 15100, training loss = 4.458321, validation loss = 4.705092
2018-12-07 16:42:40,085 - INFO - epoch 0, step 15150, training loss = 4.741508, validation loss = 4.020317
2018-12-07 16:43:16,891 - INFO - epoch 0, step 15200, training loss = 5.077856, validation loss = 3.576444
2018-12-07 16:43:52,247 - INFO - epoch 0, step 15250, training loss = 4.913799, validation loss = 3.910152
2018-12-07 16:44:27,566 - INFO - epoch 0, step 15300, training loss = 3.825176, validation loss = 3.964874
2018-12-07 16:45:00,362 - INFO - epoch 0, step 15350, training loss = 4.536241, validation loss = 4.112589
2018-12-07 16:45:30,103 - INFO - epoch 0, step 15400, training loss = 5.216345, validation loss = 3.416242
2018-12-07 16:45:49,378 - INFO - epoch 0, step 15450, training loss = 4.852025, validation loss = 3.488660
2018-12-07 16:46:08,662 - INFO - epoch 0, step 15500, training loss = 4.538288, validation loss = 3.954429
2018-12-07 16:46:27,886 - INFO - epoch 0, step 15550, training loss = 3.931806, validation loss = 4.507226
2018-12-07 16:46:49,604 - INFO - epoch 0, step 15600, training loss = 4.623187, validation loss = 4.403490
2018-12-07 16:47:18,254 - INFO - epoch 0, step 15650, training loss = 4.309517, validation loss = 4.090920
2018-12-07 16:47:46,481 - INFO - epoch 0, step 15700, training loss = 4.845208, validation loss = 4.376331
2018-12-07 16:48:19,446 - INFO - epoch 0, step 15750, training loss = 4.724692, validation loss = 3.964527
2018-12-07 16:48:52,418 - INFO - epoch 0, step 15800, training loss = 4.985058, validation loss = 4.174709
2018-12-07 16:49:25,763 - INFO - epoch 0, step 15850, training loss = 4.379293, validation loss = 3.553267
2018-12-07 16:49:59,672 - INFO - epoch 0, step 15900, training loss = 4.235045, validation loss = 4.006572
2018-12-07 16:50:27,427 - INFO - epoch 0, step 15950, training loss = 4.113526, validation loss = 4.249166
2018-12-07 16:50:53,450 - INFO - epoch 0, step 16000, training loss = 4.800597, validation loss = 4.110000
2018-12-07 16:51:13,442 - INFO - epoch 0, step 16050, training loss = 5.329719, validation loss = 3.589581
2018-12-07 16:51:28,296 - INFO - epoch 0, step 16100, training loss = 4.140107, validation loss = 4.299481
2018-12-07 16:51:43,456 - INFO - epoch 0, step 16150, training loss = 4.363636, validation loss = 4.987372
2018-12-07 16:52:00,507 - INFO - epoch 0, step 16200, training loss = 5.043797, validation loss = 4.449295
2018-12-07 16:52:21,539 - INFO - epoch 0, step 16250, training loss = 4.521080, validation loss = 3.675203
2018-12-07 16:52:43,912 - INFO - epoch 0, step 16300, training loss = 4.772492, validation loss = 3.611377
2018-12-07 16:53:00,060 - INFO - epoch 0, step 16350, training loss = 4.619609, validation loss = 4.735544
2018-12-07 16:53:14,931 - INFO - epoch 0, step 16400, training loss = 4.344511, validation loss = 4.718817
2018-12-07 16:53:38,911 - INFO - epoch 0, step 16450, training loss = 4.264423, validation loss = 4.406030
2018-12-07 16:54:09,598 - INFO - epoch 0, step 16500, training loss = 5.039365, validation loss = 3.730566
2018-12-07 16:54:40,424 - INFO - epoch 0, step 16550, training loss = 4.684060, validation loss = 3.412044
2018-12-07 16:55:11,484 - INFO - epoch 0, step 16600, training loss = 4.939962, validation loss = 4.167136
2018-12-07 16:55:40,298 - INFO - epoch 0, step 16650, training loss = 5.181490, validation loss = 4.795664
2018-12-07 16:56:03,608 - INFO - epoch 0, step 16700, training loss = 4.446345, validation loss = 4.381808
2018-12-07 16:56:29,779 - INFO - epoch 0, step 16750, training loss = 4.703641, validation loss = 3.577237
2018-12-07 16:56:49,967 - INFO - epoch 0, step 16800, training loss = 4.622161, validation loss = 3.699077
2018-12-07 16:57:09,434 - INFO - epoch 0, step 16850, training loss = 4.398918, validation loss = 4.398983
2018-12-07 16:57:29,346 - INFO - epoch 0, step 16900, training loss = 4.796493, validation loss = 4.341546
2018-12-07 16:57:49,403 - INFO - epoch 0, step 16950, training loss = 4.945539, validation loss = 4.503799
2018-12-07 16:58:19,101 - INFO - epoch 0, step 17000, training loss = 4.562002, validation loss = 4.096059
2018-12-07 16:58:48,282 - INFO - epoch 0, step 17050, training loss = 4.532834, validation loss = 4.502135
2018-12-07 16:59:19,463 - INFO - epoch 0, step 17100, training loss = 4.134884, validation loss = 4.269061
2018-12-07 16:59:50,697 - INFO - epoch 0, step 17150, training loss = 4.140108, validation loss = 4.435413
2018-12-07 17:00:21,191 - INFO - epoch 0, step 17200, training loss = 3.977865, validation loss = 4.425861
2018-12-07 17:00:52,141 - INFO - epoch 0, step 17250, training loss = 4.176318, validation loss = 4.482061
2018-12-07 17:01:22,699 - INFO - epoch 0, step 17300, training loss = 3.512787, validation loss = 3.516445
2018-12-07 17:01:53,335 - INFO - epoch 0, step 17350, training loss = 4.990200, validation loss = 4.010801
2018-12-07 17:02:21,667 - INFO - epoch 0, step 17400, training loss = 4.502888, validation loss = 4.149230
2018-12-07 17:02:41,360 - INFO - epoch 0, step 17450, training loss = 5.788252, validation loss = 4.597192
2018-12-07 17:02:59,624 - INFO - epoch 0, step 17500, training loss = 4.762449, validation loss = 4.219186
2018-12-07 17:03:25,837 - INFO - epoch 0, step 17550, training loss = 5.105916, validation loss = 3.719949
2018-12-07 17:03:58,112 - INFO - epoch 0, step 17600, training loss = 4.606788, validation loss = 4.067414
2018-12-07 17:04:29,675 - INFO - epoch 0, step 17650, training loss = 4.597304, validation loss = 4.138111
2018-12-07 17:05:01,796 - INFO - epoch 0, step 17700, training loss = 4.582165, validation loss = 3.556590
2018-12-07 17:05:34,207 - INFO - epoch 0, step 17750, training loss = 4.470831, validation loss = 4.152614
2018-12-07 17:06:00,560 - INFO - epoch 0, step 17800, training loss = 4.456252, validation loss = 3.755077
2018-12-07 17:06:23,252 - INFO - epoch 0, step 17850, training loss = 3.520967, validation loss = 3.364391
2018-12-07 17:06:43,278 - INFO - epoch 0, step 17900, training loss = 4.281508, validation loss = 4.053741
2018-12-07 17:07:02,705 - INFO - epoch 0, step 17950, training loss = 4.511246, validation loss = 4.121882
2018-12-07 17:07:22,595 - INFO - epoch 0, step 18000, training loss = 3.990947, validation loss = 3.907203
2018-12-07 17:07:39,898 - INFO - epoch 0, step 18050, training loss = 4.021731, validation loss = 4.038922
2018-12-07 17:07:55,285 - INFO - epoch 0, step 18100, training loss = 3.770362, validation loss = 3.613471
2018-12-07 17:08:26,780 - INFO - epoch 0, step 18150, training loss = 4.612644, validation loss = 3.987934
2018-12-07 17:08:58,514 - INFO - epoch 0, step 18200, training loss = 4.536181, validation loss = 4.197450
2018-12-07 17:09:29,747 - INFO - epoch 0, step 18250, training loss = 4.529167, validation loss = 3.473922
2018-12-07 17:10:01,236 - INFO - epoch 0, step 18300, training loss = 4.837333, validation loss = 3.383665
2018-12-07 17:10:33,259 - INFO - epoch 0, step 18350, training loss = 3.837113, validation loss = 3.909725
2018-12-07 17:10:55,451 - INFO - epoch 0, step 18400, training loss = 4.296445, validation loss = 3.854784
2018-12-07 17:11:14,957 - INFO - epoch 0, step 18450, training loss = 4.389949, validation loss = 3.852500
2018-12-07 17:11:35,121 - INFO - epoch 0, step 18500, training loss = 3.819648, validation loss = 3.625873
2018-12-07 17:11:55,248 - INFO - epoch 0, step 18550, training loss = 3.164061, validation loss = 3.976513
2018-12-07 17:12:16,723 - INFO - epoch 0, step 18600, training loss = 5.014405, validation loss = 4.403355
2018-12-07 17:12:45,000 - INFO - epoch 0, step 18650, training loss = 4.683156, validation loss = 3.918610
2018-12-07 17:13:15,863 - INFO - epoch 0, step 18700, training loss = 4.428679, validation loss = 3.930346
2018-12-07 17:13:46,369 - INFO - epoch 0, step 18750, training loss = 4.505104, validation loss = 3.782827
2018-12-07 17:14:06,815 - INFO - epoch 0, step 18800, training loss = 4.478848, validation loss = 3.853051
2018-12-07 17:14:26,298 - INFO - epoch 0, step 18850, training loss = 3.911229, validation loss = 3.512391
2018-12-07 17:14:45,769 - INFO - epoch 0, step 18900, training loss = 3.829978, validation loss = 3.659278
2018-12-07 17:15:05,596 - INFO - epoch 0, step 18950, training loss = 3.376198, validation loss = 3.908932
2018-12-07 17:15:30,480 - INFO - epoch 0, step 19000, training loss = 4.448744, validation loss = 3.839910
2018-12-07 17:15:53,414 - INFO - epoch 0, step 19050, training loss = 3.880359, validation loss = 4.047771
2018-12-07 17:16:12,888 - INFO - epoch 0, step 19100, training loss = 3.704513, validation loss = 3.752864
2018-12-07 17:16:31,967 - INFO - epoch 0, step 19150, training loss = 3.831639, validation loss = 3.517241
2018-12-07 17:16:51,757 - INFO - epoch 0, step 19200, training loss = 4.490265, validation loss = 3.642319
2018-12-07 17:17:17,764 - INFO - epoch 0, step 19250, training loss = 4.833072, validation loss = 3.878182
2018-12-07 17:17:48,584 - INFO - epoch 0, step 19300, training loss = 4.754978, validation loss = 3.454397
2018-12-07 17:18:19,447 - INFO - epoch 0, step 19350, training loss = 4.143852, validation loss = 3.701307
2018-12-07 17:18:54,889 - INFO - epoch 0, step 19400, training loss = 4.042880, validation loss = 3.888822
2018-12-07 17:19:29,057 - INFO - epoch 0, step 19450, training loss = 3.884163, validation loss = 3.882329
2018-12-07 17:20:04,363 - INFO - epoch 0, step 19500, training loss = 4.654178, validation loss = 3.409082
2018-12-07 17:20:36,873 - INFO - epoch 0, step 19550, training loss = 4.008705, validation loss = 3.947566
2018-12-07 17:21:02,482 - INFO - epoch 0, step 19600, training loss = 4.507049, validation loss = 3.888573
2018-12-07 17:21:28,988 - INFO - epoch 0, step 19650, training loss = 4.390613, validation loss = 3.802000
2018-12-07 17:22:03,240 - INFO - epoch 0, step 19700, training loss = 3.797814, validation loss = 3.535900
2018-12-07 17:22:38,714 - INFO - epoch 0, step 19750, training loss = 4.580584, validation loss = 3.851814
2018-12-07 17:23:13,420 - INFO - epoch 0, step 19800, training loss = 4.297040, validation loss = 4.021433
2018-12-07 17:23:48,321 - INFO - epoch 0, step 19850, training loss = 4.114647, validation loss = 4.012267
2018-12-07 17:24:17,862 - INFO - epoch 0, step 19900, training loss = 3.486004, validation loss = 3.400909
2018-12-07 17:24:38,812 - INFO - epoch 0, step 19950, training loss = 4.238167, validation loss = 4.051111
2018-12-07 17:24:59,908 - INFO - epoch 0, step 20000, training loss = 4.184645, validation loss = 4.121116
2018-12-07 17:25:20,739 - INFO - epoch 0, step 20050, training loss = 4.368758, validation loss = 3.614803
2018-12-07 17:25:41,266 - INFO - epoch 0, step 20100, training loss = 3.955733, validation loss = 3.562800
2018-12-07 17:26:01,939 - INFO - epoch 0, step 20150, training loss = 3.343225, validation loss = 3.931978
2018-12-07 17:26:21,977 - INFO - epoch 0, step 20200, training loss = 3.720401, validation loss = 3.656554
2018-12-07 17:26:47,238 - INFO - epoch 0, step 20250, training loss = 4.544405, validation loss = 3.802498
2018-12-07 17:27:14,784 - INFO - epoch 0, step 20300, training loss = 4.879688, validation loss = 3.713087
2018-12-07 17:27:41,875 - INFO - epoch 0, step 20350, training loss = 3.957764, validation loss = 3.698506
2018-12-07 17:28:08,750 - INFO - epoch 0, step 20400, training loss = 4.477836, validation loss = 4.116883
2018-12-07 17:28:36,617 - INFO - epoch 0, step 20450, training loss = 4.915429, validation loss = 4.134934
2018-12-07 17:29:06,250 - INFO - epoch 0, step 20500, training loss = 4.361660, validation loss = 4.282429
2018-12-07 17:29:38,066 - INFO - epoch 0, step 20550, training loss = 4.049553, validation loss = 3.753749
2018-12-07 17:30:09,484 - INFO - epoch 0, step 20600, training loss = 3.979808, validation loss = 4.057518
2018-12-07 17:30:35,483 - INFO - epoch 0, step 20650, training loss = 4.386786, validation loss = 3.662080
2018-12-07 17:30:58,751 - INFO - epoch 0, step 20700, training loss = 3.969154, validation loss = 3.651845
2018-12-07 17:31:24,950 - INFO - epoch 0, step 20750, training loss = 3.763736, validation loss = 3.988598
2018-12-07 17:31:50,958 - INFO - epoch 0, step 20800, training loss = 4.076191, validation loss = 4.036213
2018-12-07 17:32:11,012 - INFO - epoch 0, step 20850, training loss = 3.189576, validation loss = 3.990743
2018-12-07 17:32:30,805 - INFO - epoch 0, step 20900, training loss = 4.171749, validation loss = 3.409944
2018-12-07 17:32:50,850 - INFO - epoch 0, step 20950, training loss = 3.948246, validation loss = 3.958967
2018-12-07 17:33:26,446 - INFO - epoch 0, step 21000, training loss = 4.132104, validation loss = 3.792504
2018-12-07 17:34:01,635 - INFO - epoch 0, step 21050, training loss = 4.163634, validation loss = 3.746028
2018-12-07 17:34:32,628 - INFO - epoch 0, step 21100, training loss = 4.635046, validation loss = 3.484159
2018-12-07 17:35:02,582 - INFO - epoch 0, step 21150, training loss = 4.342349, validation loss = 3.449590
2018-12-07 17:35:31,897 - INFO - epoch 0, step 21200, training loss = 4.586531, validation loss = 3.768300
2018-12-07 17:36:01,557 - INFO - epoch 0, step 21250, training loss = 3.530038, validation loss = 4.151611
2018-12-07 17:36:32,695 - INFO - epoch 0, step 21300, training loss = 4.599883, validation loss = 3.943238
2018-12-07 17:37:02,781 - INFO - epoch 0, step 21350, training loss = 3.863486, validation loss = 3.460526
2018-12-07 17:37:34,195 - INFO - epoch 0, step 21400, training loss = 4.046591, validation loss = 4.433941
2018-12-07 17:38:05,943 - INFO - epoch 0, step 21450, training loss = 3.944260, validation loss = 4.256029
2018-12-07 17:38:38,188 - INFO - epoch 0, step 21500, training loss = 4.227219, validation loss = 3.910536
2018-12-07 17:38:58,913 - INFO - epoch 0, step 21550, training loss = 5.001634, validation loss = 3.806264
2018-12-07 17:39:18,514 - INFO - epoch 0, step 21600, training loss = 4.460011, validation loss = 3.644644
2018-12-07 17:39:40,304 - INFO - epoch 0, step 21650, training loss = 4.707326, validation loss = 4.200662
2018-12-07 17:40:08,664 - INFO - epoch 0, step 21700, training loss = 4.439386, validation loss = 3.718581
2018-12-07 17:40:36,644 - INFO - epoch 0, step 21750, training loss = 4.447452, validation loss = 3.529756
2018-12-07 17:41:06,181 - INFO - epoch 0, step 21800, training loss = 4.158937, validation loss = 3.816891
2018-12-07 17:41:35,044 - INFO - epoch 0, step 21850, training loss = 4.555614, validation loss = 3.987979
2018-12-07 17:41:59,384 - INFO - epoch 0, step 21900, training loss = 3.581738, validation loss = 3.762239
2018-12-07 17:42:14,163 - INFO - epoch 0, step 21950, training loss = 4.291199, validation loss = 4.439886
2018-12-07 17:42:28,903 - INFO - epoch 0, step 22000, training loss = 4.633243, validation loss = 4.379370
2018-12-07 17:42:44,935 - INFO - epoch 0, step 22050, training loss = 5.020360, validation loss = 3.941634
2018-12-07 17:43:11,999 - INFO - epoch 0, step 22100, training loss = 4.830153, validation loss = 4.021369
2018-12-07 17:43:38,184 - INFO - epoch 0, step 22150, training loss = 4.441190, validation loss = 4.256835
2018-12-07 17:44:04,586 - INFO - epoch 0, step 22200, training loss = 4.475105, validation loss = 3.830401
2018-12-07 17:44:36,051 - INFO - epoch 0, step 22250, training loss = 4.454456, validation loss = 4.521287
2018-12-07 17:45:11,787 - INFO - epoch 0, step 22300, training loss = 3.765572, validation loss = 4.309756
2018-12-07 17:45:47,233 - INFO - epoch 0, step 22350, training loss = 4.150998, validation loss = 4.427795
2018-12-07 17:46:20,981 - INFO - epoch 0, step 22400, training loss = 4.279870, validation loss = 4.319870
2018-12-07 17:46:55,824 - INFO - epoch 0, step 22450, training loss = 4.153173, validation loss = 4.651524
2018-12-07 17:47:27,979 - INFO - epoch 0, step 22500, training loss = 4.485623, validation loss = 4.100602
2018-12-07 17:48:02,330 - INFO - epoch 0, step 22550, training loss = 4.223832, validation loss = 4.122579
2018-12-07 17:48:36,713 - INFO - epoch 0, step 22600, training loss = 3.763242, validation loss = 4.037632
2018-12-07 17:49:03,854 - INFO - epoch 0, step 22650, training loss = 4.286139, validation loss = 4.031062
2018-12-07 17:49:27,592 - INFO - epoch 0, step 22700, training loss = 4.183862, validation loss = 3.985555
2018-12-07 17:49:48,732 - INFO - epoch 0, step 22750, training loss = 4.353382, validation loss = 4.181795
2018-12-07 17:50:10,265 - INFO - epoch 0, step 22800, training loss = 4.847694, validation loss = 4.447861
2018-12-07 17:50:31,016 - INFO - epoch 0, step 22850, training loss = 3.415369, validation loss = 3.923649
2018-12-07 17:50:50,953 - INFO - epoch 0, step 22900, training loss = 3.746903, validation loss = 4.166346
2018-12-07 17:51:10,313 - INFO - epoch 0, step 22950, training loss = 3.836068, validation loss = 4.383016
2018-12-07 17:51:29,485 - INFO - epoch 0, step 23000, training loss = 4.003809, validation loss = 4.351534
2018-12-07 17:51:55,897 - INFO - epoch 0, step 23050, training loss = 4.414675, validation loss = 4.020029
2018-12-07 17:52:21,388 - INFO - epoch 0, step 23100, training loss = 4.183646, validation loss = 4.101010
2018-12-07 17:52:41,109 - INFO - epoch 0, step 23150, training loss = 3.286219, validation loss = 4.280099
2018-12-07 17:52:55,605 - INFO - epoch 0, step 23200, training loss = 3.474663, validation loss = 4.459267
2018-12-07 17:53:09,894 - INFO - epoch 0, step 23250, training loss = 4.352970, validation loss = 4.425736
2018-12-07 17:53:26,239 - INFO - epoch 0, step 23300, training loss = 4.024234, validation loss = 4.176437
2018-12-07 17:53:46,183 - INFO - epoch 0, step 23350, training loss = 3.654389, validation loss = 4.344943
2018-12-07 17:54:05,348 - INFO - epoch 0, step 23400, training loss = 3.984791, validation loss = 4.212218
2018-12-07 17:54:26,720 - INFO - epoch 0, step 23450, training loss = 4.531130, validation loss = 4.476081
2018-12-07 17:54:57,272 - INFO - epoch 0, step 23500, training loss = 4.148972, validation loss = 4.394287
2018-12-07 17:55:25,735 - INFO - epoch 0, step 23550, training loss = 4.490590, validation loss = 4.388857
2018-12-07 17:55:51,210 - INFO - epoch 0, step 23600, training loss = 4.187576, validation loss = 4.120571
2018-12-07 17:56:16,567 - INFO - epoch 0, step 23650, training loss = 4.102797, validation loss = 4.298841
2018-12-07 17:56:42,643 - INFO - epoch 0, step 23700, training loss = 4.196685, validation loss = 4.375298
2018-12-07 17:57:11,718 - INFO - epoch 0, step 23750, training loss = 4.104874, validation loss = 4.235319
2018-12-07 17:57:40,756 - INFO - epoch 0, step 23800, training loss = 4.220726, validation loss = 4.495284
2018-12-07 17:58:11,038 - INFO - epoch 0, step 23850, training loss = 4.586819, validation loss = 3.906856
2018-12-07 17:58:41,562 - INFO - epoch 0, step 23900, training loss = 4.596407, validation loss = 4.472671
2018-12-07 17:59:11,318 - INFO - epoch 0, step 23950, training loss = 4.567890, validation loss = 4.200956
2018-12-07 17:59:39,537 - INFO - epoch 0, step 24000, training loss = 4.158551, validation loss = 4.548745
2018-12-07 18:00:12,106 - INFO - epoch 0, step 24050, training loss = 4.244110, validation loss = 4.183073
2018-12-07 18:00:48,564 - INFO - epoch 0, step 24100, training loss = 4.537773, validation loss = 4.520698
2018-12-07 18:01:24,055 - INFO - epoch 0, step 24150, training loss = 4.566365, validation loss = 3.856022
2018-12-07 18:01:57,754 - INFO - epoch 0, step 24200, training loss = 4.379631, validation loss = 4.013743
2018-12-07 18:02:29,259 - INFO - epoch 0, step 24250, training loss = 3.778357, validation loss = 4.194898
2018-12-07 18:02:49,159 - INFO - epoch 0, step 24300, training loss = 4.089143, validation loss = 4.019859
2018-12-07 18:03:08,733 - INFO - epoch 0, step 24350, training loss = 3.339964, validation loss = 4.151348
2018-12-07 18:03:28,648 - INFO - epoch 0, step 24400, training loss = 3.685389, validation loss = 3.834112
2018-12-07 18:03:48,058 - INFO - epoch 0, step 24450, training loss = 4.530241, validation loss = 4.095539
2018-12-07 18:04:07,604 - INFO - epoch 0, step 24500, training loss = 4.053083, validation loss = 4.163013
2018-12-07 18:04:26,877 - INFO - epoch 0, step 24550, training loss = 3.552662, validation loss = 4.347258
2018-12-07 18:04:46,699 - INFO - epoch 0, step 24600, training loss = 5.119298, validation loss = 4.225269
2018-12-07 18:05:07,214 - INFO - epoch 0, step 24650, training loss = 4.127312, validation loss = 4.444808
2018-12-07 18:05:26,660 - INFO - epoch 0, step 24700, training loss = 4.151388, validation loss = 4.328722
2018-12-07 18:05:46,026 - INFO - epoch 0, step 24750, training loss = 4.172587, validation loss = 4.474957
2018-12-07 18:06:05,955 - INFO - epoch 0, step 24800, training loss = 3.252664, validation loss = 3.939704
2018-12-07 18:06:26,057 - INFO - epoch 0, step 24850, training loss = 3.374408, validation loss = 4.695985
2018-12-07 18:06:48,157 - INFO - epoch 0, step 24900, training loss = 4.151476, validation loss = 3.869454
2018-12-07 18:07:14,156 - INFO - epoch 0, step 24950, training loss = 4.617306, validation loss = 4.188896
2018-12-07 18:07:46,071 - INFO - epoch 0, step 25000, training loss = 4.596492, validation loss = 4.349216
2018-12-07 18:08:18,373 - INFO - epoch 0, step 25050, training loss = 4.337484, validation loss = 4.416074
2018-12-07 18:08:50,433 - INFO - epoch 0, step 25100, training loss = 4.210104, validation loss = 4.138058
2018-12-07 18:09:22,527 - INFO - epoch 0, step 25150, training loss = 4.310644, validation loss = 4.696531
2018-12-07 18:09:45,889 - INFO - epoch 0, step 25200, training loss = 4.178459, validation loss = 3.993331
2018-12-07 18:10:07,881 - INFO - epoch 0, step 25250, training loss = 4.487767, validation loss = 3.949870
2018-12-07 18:10:36,519 - INFO - epoch 0, step 25300, training loss = 4.363879, validation loss = 4.045545
2018-12-07 18:11:08,925 - INFO - epoch 0, step 25350, training loss = 4.390630, validation loss = 4.269741
2018-12-07 18:11:42,249 - INFO - epoch 0, step 25400, training loss = 3.712163, validation loss = 4.364017
2018-12-07 18:12:14,433 - INFO - epoch 0, step 25450, training loss = 4.259559, validation loss = 4.183710
2018-12-07 18:12:36,683 - INFO - epoch 0, step 25500, training loss = 3.877827, validation loss = 3.913822
2018-12-07 18:12:55,737 - INFO - epoch 0, step 25550, training loss = 3.876612, validation loss = 4.576467
2018-12-07 18:13:20,693 - INFO - epoch 0, step 25600, training loss = 4.394461, validation loss = 4.541206
2018-12-07 18:13:52,996 - INFO - epoch 0, step 25650, training loss = 4.156077, validation loss = 4.281165
2018-12-07 18:14:27,201 - INFO - epoch 0, step 25700, training loss = 3.779982, validation loss = 4.149437
2018-12-07 18:15:00,278 - INFO - epoch 0, step 25750, training loss = 3.902336, validation loss = 4.552686
2018-12-07 18:15:26,405 - INFO - epoch 0, step 25800, training loss = 4.306760, validation loss = 3.912696
2018-12-07 18:15:47,405 - INFO - epoch 0, step 25850, training loss = 4.297970, validation loss = 4.124494
2018-12-07 18:16:06,464 - INFO - epoch 0, step 25900, training loss = 3.604724, validation loss = 4.165384
2018-12-07 18:16:26,002 - INFO - epoch 0, step 25950, training loss = 4.175633, validation loss = 4.351715
2018-12-07 18:16:57,347 - INFO - epoch 0, step 26000, training loss = 4.075501, validation loss = 3.998274
2018-12-07 18:17:28,612 - INFO - epoch 0, step 26050, training loss = 3.662986, validation loss = 4.231817
2018-12-07 18:17:59,192 - INFO - epoch 0, step 26100, training loss = 3.751788, validation loss = 4.040989
2018-12-07 18:18:29,576 - INFO - epoch 0, step 26150, training loss = 4.233045, validation loss = 4.246313
2018-12-07 18:19:03,988 - INFO - epoch 0, step 26200, training loss = 4.643965, validation loss = 4.254988
2018-12-07 18:19:36,207 - INFO - epoch 0, step 26250, training loss = 4.147583, validation loss = 4.315966
2018-12-07 18:20:09,718 - INFO - epoch 0, step 26300, training loss = 3.798621, validation loss = 4.176829
2018-12-07 18:20:40,758 - INFO - epoch 0, step 26350, training loss = 4.861061, validation loss = 4.669043
2018-12-07 18:21:12,177 - INFO - epoch 0, step 26400, training loss = 4.228188, validation loss = 4.528090
2018-12-07 18:21:43,272 - INFO - epoch 0, step 26450, training loss = 4.314086, validation loss = 4.247952
2018-12-07 18:22:07,364 - INFO - epoch 0, step 26500, training loss = 4.566238, validation loss = 4.147375
2018-12-07 18:22:27,590 - INFO - epoch 0, step 26550, training loss = 4.225677, validation loss = 4.420632
2018-12-07 18:22:46,743 - INFO - epoch 0, step 26600, training loss = 4.392387, validation loss = 4.392402
2018-12-07 18:23:05,928 - INFO - epoch 0, step 26650, training loss = 3.737572, validation loss = 4.201710
2018-12-07 18:23:25,292 - INFO - epoch 0, step 26700, training loss = 3.293333, validation loss = 4.375098
2018-12-07 18:23:55,844 - INFO - epoch 0, step 26750, training loss = 4.549915, validation loss = 4.288407
2018-12-07 18:24:29,637 - INFO - epoch 0, step 26800, training loss = 4.165240, validation loss = 4.243769
2018-12-07 18:25:02,956 - INFO - epoch 0, step 26850, training loss = 3.853544, validation loss = 3.982339
2018-12-07 18:25:34,324 - INFO - epoch 0, step 26900, training loss = 4.053607, validation loss = 4.197886
2018-12-07 18:26:05,334 - INFO - epoch 0, step 26950, training loss = 4.172001, validation loss = 4.447034
2018-12-07 18:26:37,613 - INFO - epoch 0, step 27000, training loss = 4.542323, validation loss = 4.427050
2018-12-07 18:27:08,358 - INFO - epoch 0, step 27050, training loss = 4.307804, validation loss = 4.329786
2018-12-07 18:27:33,953 - INFO - epoch 0, step 27100, training loss = 4.186729, validation loss = 4.060277
2018-12-07 18:27:56,890 - INFO - epoch 0, step 27150, training loss = 4.994241, validation loss = 4.109482
2018-12-07 18:28:25,036 - INFO - epoch 0, step 27200, training loss = 4.016039, validation loss = 3.936114
2018-12-07 18:28:55,639 - INFO - epoch 0, step 27250, training loss = 4.281286, validation loss = 4.584082
2018-12-07 18:29:25,522 - INFO - epoch 0, step 27300, training loss = 4.382999, validation loss = 4.223606
2018-12-07 18:29:51,934 - INFO - epoch 0, step 27350, training loss = 3.827150, validation loss = 4.487528
2018-12-07 18:30:16,906 - INFO - epoch 0, step 27400, training loss = 3.871193, validation loss = 4.228082
2018-12-07 18:30:36,035 - INFO - epoch 0, step 27450, training loss = 4.301788, validation loss = 4.599503
2018-12-07 18:30:55,193 - INFO - epoch 0, step 27500, training loss = 3.613493, validation loss = 3.904786
2018-12-07 18:31:15,008 - INFO - epoch 0, step 27550, training loss = 3.222202, validation loss = 4.054135
2018-12-07 18:31:38,177 - INFO - epoch 0, step 27600, training loss = 4.347918, validation loss = 4.538860
2018-12-07 18:32:08,266 - INFO - epoch 0, step 27650, training loss = 4.375537, validation loss = 3.834731
2018-12-07 18:32:41,960 - INFO - epoch 0, step 27700, training loss = 4.310701, validation loss = 4.382649
2018-12-07 18:33:15,919 - INFO - epoch 0, step 27750, training loss = 4.147709, validation loss = 3.908554
2018-12-07 18:33:47,711 - INFO - epoch 0, step 27800, training loss = 3.866424, validation loss = 4.132116
2018-12-07 18:34:17,970 - INFO - epoch 0, step 27850, training loss = 3.576316, validation loss = 4.267646
2018-12-07 18:34:48,540 - INFO - epoch 0, step 27900, training loss = 3.862205, validation loss = 4.283732
2018-12-07 18:35:18,807 - INFO - epoch 0, step 27950, training loss = 3.644901, validation loss = 4.196288
2018-12-07 18:35:50,078 - INFO - epoch 0, step 28000, training loss = 4.029896, validation loss = 4.140633
2018-12-07 18:36:21,656 - INFO - epoch 0, step 28050, training loss = 3.927377, validation loss = 4.247343
2018-12-07 18:36:53,897 - INFO - epoch 0, step 28100, training loss = 3.560841, validation loss = 4.170935
2018-12-07 18:37:24,787 - INFO - epoch 0, step 28150, training loss = 4.355289, validation loss = 4.399268
2018-12-07 18:37:55,677 - INFO - epoch 0, step 28200, training loss = 4.238884, validation loss = 4.210561
2018-12-07 18:38:26,242 - INFO - epoch 0, step 28250, training loss = 3.562704, validation loss = 4.292239
2018-12-07 18:38:56,957 - INFO - epoch 0, step 28300, training loss = 4.141319, validation loss = 4.054377
2018-12-07 18:39:27,793 - INFO - epoch 0, step 28350, training loss = 4.337685, validation loss = 4.268658
2018-12-07 18:39:54,434 - INFO - epoch 0, step 28400, training loss = 3.926950, validation loss = 4.045956
2018-12-07 18:40:26,334 - INFO - epoch 0, step 28450, training loss = 4.237522, validation loss = 4.584216
2018-12-07 18:41:01,478 - INFO - epoch 0, step 28500, training loss = 4.069448, validation loss = 4.400667
2018-12-07 18:41:23,979 - INFO - epoch 0, step 28550, training loss = 3.826085, validation loss = 4.377930
2018-12-07 18:41:43,284 - INFO - epoch 0, step 28600, training loss = 4.197659, validation loss = 4.276196
2018-12-07 18:42:02,161 - INFO - epoch 0, step 28650, training loss = 4.075642, validation loss = 4.249971
2018-12-07 18:42:27,581 - INFO - epoch 0, step 28700, training loss = 4.441988, validation loss = 3.647062
2018-12-07 18:42:57,708 - INFO - epoch 0, step 28750, training loss = 4.049675, validation loss = 3.842712
2018-12-07 18:43:27,703 - INFO - epoch 0, step 28800, training loss = 3.977661, validation loss = 4.221375
2018-12-07 18:43:58,254 - INFO - epoch 0, step 28850, training loss = 3.889297, validation loss = 4.194224
2018-12-07 18:44:28,522 - INFO - epoch 0, step 28900, training loss = 3.622264, validation loss = 4.032122
2018-12-07 18:44:59,431 - INFO - epoch 0, step 28950, training loss = 3.971041, validation loss = 4.149981
2018-12-07 18:45:31,212 - INFO - epoch 0, step 29000, training loss = 3.738070, validation loss = 3.894079
2018-12-07 18:46:02,009 - INFO - epoch 0, step 29050, training loss = 3.748825, validation loss = 4.316320
2018-12-07 18:46:27,979 - INFO - epoch 0, step 29100, training loss = 4.082403, validation loss = 4.444952
2018-12-07 18:46:59,576 - INFO - epoch 0, step 29150, training loss = 4.083260, validation loss = 4.105278
2018-12-07 18:47:33,772 - INFO - epoch 0, step 29200, training loss = 3.749455, validation loss = 4.171288
2018-12-07 18:48:06,446 - INFO - epoch 0, step 29250, training loss = 4.167667, validation loss = 4.442977
2018-12-07 18:48:38,324 - INFO - epoch 0, step 29300, training loss = 4.220321, validation loss = 4.535142
2018-12-07 18:49:09,175 - INFO - epoch 0, step 29350, training loss = 3.882035, validation loss = 4.517431
2018-12-07 18:49:41,375 - INFO - epoch 0, step 29400, training loss = 4.061805, validation loss = 4.564312
2018-12-07 18:50:12,776 - INFO - epoch 0, step 29450, training loss = 4.475356, validation loss = 4.795537
2018-12-07 18:50:43,693 - INFO - epoch 0, step 29500, training loss = 4.419107, validation loss = 4.274652
2018-12-07 18:51:15,587 - INFO - epoch 0, step 29550, training loss = 4.285727, validation loss = 4.263315
2018-12-07 18:51:47,125 - INFO - epoch 0, step 29600, training loss = 4.034517, validation loss = 3.896274
2018-12-07 18:52:18,726 - INFO - epoch 0, step 29650, training loss = 3.701917, validation loss = 4.104798
2018-12-07 18:52:49,063 - INFO - epoch 0, step 29700, training loss = 3.758744, validation loss = 4.672198
2018-12-07 18:53:14,728 - INFO - epoch 0, step 29750, training loss = 3.928864, validation loss = 4.024683
2018-12-07 18:53:44,198 - INFO - epoch 0, step 29800, training loss = 3.801248, validation loss = 4.291263
2018-12-07 18:54:15,387 - INFO - epoch 0, step 29850, training loss = 3.665286, validation loss = 4.457242
2018-12-07 18:54:46,997 - INFO - epoch 0, step 29900, training loss = 4.074257, validation loss = 4.483791
2018-12-07 18:55:18,296 - INFO - epoch 0, step 29950, training loss = 3.815783, validation loss = 3.731849
2018-12-07 18:55:49,586 - INFO - epoch 0, step 30000, training loss = 3.827579, validation loss = 4.745811
2018-12-07 18:56:20,400 - INFO - epoch 0, step 30050, training loss = 3.552732, validation loss = 4.294698
2018-12-07 18:56:46,433 - INFO - epoch 0, step 30100, training loss = 4.558196, validation loss = 4.155591
2018-12-07 18:57:05,851 - INFO - epoch 0, step 30150, training loss = 3.440371, validation loss = 4.094004
2018-12-07 18:57:24,922 - INFO - epoch 0, step 30200, training loss = 4.306252, validation loss = 4.295390
2018-12-07 18:57:53,019 - INFO - epoch 0, step 30250, training loss = 3.801005, validation loss = 4.473042
2018-12-07 18:58:22,869 - INFO - epoch 0, step 30300, training loss = 3.599613, validation loss = 4.338783
2018-12-07 18:58:52,869 - INFO - epoch 0, step 30350, training loss = 4.283502, validation loss = 4.542550
2018-12-07 18:59:26,693 - INFO - epoch 0, step 30400, training loss = 3.853557, validation loss = 4.574327
2018-12-07 18:59:59,581 - INFO - epoch 0, step 30450, training loss = 4.011764, validation loss = 4.575918
2018-12-07 19:00:31,814 - INFO - epoch 0, step 30500, training loss = 4.088568, validation loss = 3.926541
2018-12-07 19:01:03,732 - INFO - epoch 0, step 30550, training loss = 4.346787, validation loss = 4.418925
2018-12-07 19:01:36,263 - INFO - epoch 0, step 30600, training loss = 4.133705, validation loss = 4.723155
2018-12-07 19:02:10,393 - INFO - epoch 0, step 30650, training loss = 4.263147, validation loss = 4.213650
2018-12-07 19:02:43,616 - INFO - epoch 0, step 30700, training loss = 3.947203, validation loss = 3.949712
2018-12-07 19:03:15,328 - INFO - epoch 0, step 30750, training loss = 5.312584, validation loss = 4.062028
2018-12-07 19:03:31,852 - INFO - epoch 0, step 30800, training loss = 4.168548, validation loss = 4.445099
2018-12-07 19:03:50,156 - INFO - epoch 0, step 30850, training loss = 4.173073, validation loss = 3.954506
2018-12-07 19:04:15,041 - INFO - epoch 0, step 30900, training loss = 3.942503, validation loss = 3.850500
2018-12-07 19:04:46,723 - INFO - epoch 0, step 30950, training loss = 4.167187, validation loss = 4.719587
2018-12-07 19:05:21,647 - INFO - epoch 0, step 31000, training loss = 3.568106, validation loss = 3.835102
2018-12-07 19:05:55,953 - INFO - epoch 0, step 31050, training loss = 4.034445, validation loss = 4.120245
2018-12-07 19:06:18,057 - INFO - epoch 0, step 31100, training loss = 3.712450, validation loss = 4.292539
2018-12-07 19:06:37,693 - INFO - epoch 0, step 31150, training loss = 3.599719, validation loss = 4.265111
2018-12-07 19:06:58,239 - INFO - epoch 0, step 31200, training loss = 3.928002, validation loss = 4.328890
2018-12-07 19:07:23,403 - INFO - epoch 0, step 31250, training loss = 4.831476, validation loss = 4.456847
2018-12-07 19:07:45,913 - INFO - epoch 0, step 31300, training loss = 4.159435, validation loss = 4.027277
2018-12-07 19:08:01,284 - INFO - epoch 0, step 31350, training loss = 3.330984, validation loss = 4.818846
2018-12-07 19:08:17,003 - INFO - epoch 0, step 31400, training loss = 3.773148, validation loss = 4.458263
2018-12-07 19:08:33,036 - INFO - epoch 0, step 31450, training loss = 3.830929, validation loss = 4.561314
2018-12-07 19:08:52,853 - INFO - epoch 0, step 31500, training loss = 3.772134, validation loss = 4.092518
2018-12-07 19:09:12,948 - INFO - epoch 0, step 31550, training loss = 3.843033, validation loss = 4.336386
2018-12-07 19:09:40,320 - INFO - epoch 0, step 31600, training loss = 4.557902, validation loss = 3.896086
2018-12-07 19:10:10,350 - INFO - epoch 0, step 31650, training loss = 3.577006, validation loss = 4.349775
2018-12-07 19:10:40,761 - INFO - epoch 0, step 31700, training loss = 4.424656, validation loss = 3.940796
2018-12-07 19:11:11,110 - INFO - epoch 0, step 31750, training loss = 4.240853, validation loss = 4.586444
2018-12-07 19:11:37,197 - INFO - epoch 0, step 31800, training loss = 3.914173, validation loss = 4.699407
2018-12-07 19:11:51,581 - INFO - epoch 0, step 31850, training loss = 3.743053, validation loss = 4.069224
2018-12-07 19:12:05,722 - INFO - epoch 0, step 31900, training loss = 3.812075, validation loss = 3.573917
2018-12-07 19:12:27,330 - INFO - epoch 0, step 31950, training loss = 3.730911, validation loss = 4.403351
2018-12-07 19:13:02,020 - INFO - epoch 0, step 32000, training loss = 4.212947, validation loss = 3.916366
2018-12-07 19:13:35,367 - INFO - epoch 0, step 32050, training loss = 4.401576, validation loss = 4.446026
2018-12-07 19:14:10,192 - INFO - epoch 0, step 32100, training loss = 3.928929, validation loss = 4.087176
2018-12-07 19:14:32,415 - INFO - epoch 0, step 32150, training loss = 3.476475, validation loss = 4.832316
2018-12-07 19:14:47,363 - INFO - epoch 0, step 32200, training loss = 4.082310, validation loss = 4.632895
2018-12-07 19:15:02,381 - INFO - epoch 0, step 32250, training loss = 3.671825, validation loss = 4.746162
2018-12-07 19:15:27,594 - INFO - epoch 0, step 32300, training loss = 4.425851, validation loss = 4.221922
2018-12-07 19:15:58,346 - INFO - epoch 0, step 32350, training loss = 4.308438, validation loss = 4.699721
2018-12-07 19:16:29,024 - INFO - epoch 0, step 32400, training loss = 4.074026, validation loss = 4.467094
2018-12-07 19:16:59,256 - INFO - epoch 0, step 32450, training loss = 4.014565, validation loss = 4.617779
2018-12-07 19:17:29,560 - INFO - epoch 0, step 32500, training loss = 4.197520, validation loss = 4.352454
2018-12-07 19:17:56,167 - INFO - epoch 0, step 32550, training loss = 3.722359, validation loss = 4.443918
2018-12-07 19:18:19,669 - INFO - epoch 0, step 32600, training loss = 4.268537, validation loss = 4.190721
2018-12-07 19:18:39,313 - INFO - epoch 0, step 32650, training loss = 4.290211, validation loss = 4.537117
2018-12-07 19:19:08,778 - INFO - epoch 0, step 32700, training loss = 3.962181, validation loss = 4.112286
2018-12-07 19:19:39,279 - INFO - epoch 0, step 32750, training loss = 3.533404, validation loss = 4.396426
2018-12-07 19:20:08,509 - INFO - epoch 0, step 32800, training loss = 4.156519, validation loss = 4.313375
2018-12-07 19:20:38,836 - INFO - epoch 0, step 32850, training loss = 3.583647, validation loss = 4.090575
2018-12-07 19:21:09,898 - INFO - epoch 0, step 32900, training loss = 3.887964, validation loss = 4.116445
2018-12-07 19:21:43,398 - INFO - epoch 0, step 32950, training loss = 4.067804, validation loss = 4.192306
2018-12-07 19:22:15,956 - INFO - epoch 0, step 33000, training loss = 4.376690, validation loss = 3.928640
2018-12-07 19:22:41,089 - INFO - epoch 0, step 33050, training loss = 4.073008, validation loss = 4.357934
2018-12-07 19:23:03,398 - INFO - epoch 0, step 33100, training loss = 4.170312, validation loss = 4.121447
2018-12-07 19:23:24,960 - INFO - epoch 0, step 33150, training loss = 4.638489, validation loss = 3.989413
2018-12-07 19:23:52,849 - INFO - epoch 0, step 33200, training loss = 3.890543, validation loss = 4.336553
2018-12-07 19:24:25,656 - INFO - epoch 0, step 33250, training loss = 3.450671, validation loss = 4.335052
2018-12-07 19:24:57,793 - INFO - epoch 0, step 33300, training loss = 4.121542, validation loss = 4.687670
2018-12-07 19:25:31,270 - INFO - epoch 0, step 33350, training loss = 3.670496, validation loss = 4.227109
2018-12-07 19:26:00,083 - INFO - epoch 0, step 33400, training loss = 3.993856, validation loss = 3.965056
2018-12-07 19:26:28,624 - INFO - epoch 0, step 33450, training loss = 4.026371, validation loss = 3.663879
2018-12-07 19:26:57,504 - INFO - epoch 0, step 33500, training loss = 4.466971, validation loss = 3.934846
2018-12-07 19:27:27,749 - INFO - epoch 0, step 33550, training loss = 3.894233, validation loss = 3.996110
2018-12-07 19:27:58,096 - INFO - epoch 0, step 33600, training loss = 3.476920, validation loss = 4.122297
2018-12-07 19:28:29,184 - INFO - epoch 0, step 33650, training loss = 4.201932, validation loss = 3.843019
2018-12-07 19:28:59,423 - INFO - epoch 0, step 33700, training loss = 3.580413, validation loss = 4.240262
2018-12-07 19:29:29,325 - INFO - epoch 0, step 33750, training loss = 4.561080, validation loss = 4.274940
2018-12-07 19:29:59,585 - INFO - epoch 0, step 33800, training loss = 3.482455, validation loss = 4.449678
2018-12-07 19:30:30,379 - INFO - epoch 0, step 33850, training loss = 3.565780, validation loss = 4.228585
2018-12-07 19:31:00,737 - INFO - epoch 0, step 33900, training loss = 4.385663, validation loss = 3.952926
2018-12-07 19:31:31,269 - INFO - epoch 0, step 33950, training loss = 3.698214, validation loss = 4.173072
2018-12-07 19:32:01,542 - INFO - epoch 0, step 34000, training loss = 4.001544, validation loss = 4.246619
2018-12-07 19:32:31,278 - INFO - epoch 0, step 34050, training loss = 3.708662, validation loss = 3.977134
2018-12-07 19:32:56,063 - INFO - epoch 0, step 34100, training loss = 3.257998, validation loss = 4.253416
2018-12-07 19:33:10,149 - INFO - epoch 0, step 34150, training loss = 4.027938, validation loss = 4.024868
2018-12-07 19:33:24,587 - INFO - epoch 0, step 34200, training loss = 3.242079, validation loss = 4.487616
2018-12-07 19:33:47,917 - INFO - epoch 0, step 34250, training loss = 3.889389, validation loss = 3.510608
2018-12-07 19:34:17,408 - INFO - epoch 0, step 34300, training loss = 4.394308, validation loss = 3.780454
2018-12-07 19:34:47,766 - INFO - epoch 0, step 34350, training loss = 3.989152, validation loss = 4.367557
2018-12-07 19:35:17,972 - INFO - epoch 0, step 34400, training loss = 3.719330, validation loss = 3.785949
2018-12-07 19:35:47,269 - INFO - epoch 0, step 34450, training loss = 3.645421, validation loss = 4.156693
2018-12-07 19:36:09,979 - INFO - epoch 0, step 34500, training loss = 3.877976, validation loss = 4.241948
2018-12-07 19:36:29,417 - INFO - epoch 0, step 34550, training loss = 4.244579, validation loss = 4.319437
2018-12-07 19:36:49,163 - INFO - epoch 0, step 34600, training loss = 3.348188, validation loss = 4.609417
2018-12-07 19:37:10,285 - INFO - epoch 0, step 34650, training loss = 4.458910, validation loss = 4.313621
2018-12-07 19:37:40,883 - INFO - epoch 0, step 34700, training loss = 3.712855, validation loss = 4.077232
2018-12-07 19:38:12,249 - INFO - epoch 0, step 34750, training loss = 3.908780, validation loss = 4.293686
2018-12-07 19:38:44,186 - INFO - epoch 0, step 34800, training loss = 4.524632, validation loss = 3.864626
2018-12-07 19:39:11,632 - INFO - epoch 0, step 34850, training loss = 4.220437, validation loss = 4.286506
2018-12-07 19:39:46,931 - INFO - epoch 0, step 34900, training loss = 3.924405, validation loss = 3.948124
2018-12-07 19:40:16,677 - INFO - epoch 0, step 34950, training loss = 3.997848, validation loss = 4.033702
2018-12-07 19:40:45,184 - INFO - epoch 0, step 35000, training loss = 4.208749, validation loss = 4.086882
2018-12-07 19:41:13,030 - INFO - epoch 0, step 35050, training loss = 3.984082, validation loss = 3.464777
2018-12-07 19:41:29,239 - INFO - epoch 0, step 35100, training loss = 3.513608, validation loss = 4.358048
2018-12-07 19:41:42,764 - INFO - epoch 0, step 35150, training loss = 3.782147, validation loss = 4.701205
2018-12-07 19:41:56,136 - INFO - epoch 0, step 35200, training loss = 3.812076, validation loss = 4.040091
2018-12-07 19:42:15,337 - INFO - epoch 0, step 35250, training loss = 4.111599, validation loss = 3.821361
2018-12-07 19:42:40,241 - INFO - epoch 0, step 35300, training loss = 3.781603, validation loss = 4.449731
2018-12-07 19:43:06,344 - INFO - epoch 0, step 35350, training loss = 4.085130, validation loss = 3.712771
2018-12-07 19:43:32,665 - INFO - epoch 0, step 35400, training loss = 4.103298, validation loss = 4.903021
2018-12-07 19:43:58,147 - INFO - epoch 0, step 35450, training loss = 4.039965, validation loss = 3.646049
2018-12-07 19:44:22,753 - INFO - epoch 0, step 35500, training loss = 4.107569, validation loss = 3.506367
2018-12-07 19:44:47,327 - INFO - epoch 0, step 35550, training loss = 4.480713, validation loss = 3.900239
2018-12-07 19:45:15,415 - INFO - epoch 0, step 35600, training loss = 4.095879, validation loss = 3.763984
2018-12-07 19:45:47,473 - INFO - epoch 0, step 35650, training loss = 3.960654, validation loss = 3.917631
2018-12-07 19:46:16,661 - INFO - epoch 0, step 35700, training loss = 3.987292, validation loss = 3.682115
2018-12-07 19:46:40,274 - INFO - epoch 0, step 35750, training loss = 5.262039, validation loss = 3.822430
2018-12-07 19:47:02,433 - INFO - epoch 0, step 35800, training loss = 4.248987, validation loss = 4.450858
2018-12-07 19:47:25,196 - INFO - epoch 0, step 35850, training loss = 4.363841, validation loss = 3.670322
2018-12-07 19:47:47,840 - INFO - epoch 0, step 35900, training loss = 3.837590, validation loss = 3.684077
2018-12-07 19:48:11,060 - INFO - epoch 0, step 35950, training loss = 3.877692, validation loss = 4.124947
2018-12-07 19:48:34,410 - INFO - epoch 0, step 36000, training loss = 3.707126, validation loss = 4.484885
2018-12-07 19:48:57,078 - INFO - epoch 0, step 36050, training loss = 3.988016, validation loss = 4.582523
2018-12-07 19:49:20,203 - INFO - epoch 0, step 36100, training loss = 3.884010, validation loss = 4.316767
2018-12-07 19:49:43,385 - INFO - epoch 0, step 36150, training loss = 3.350314, validation loss = 3.787700
2018-12-07 19:50:06,518 - INFO - epoch 0, step 36200, training loss = 3.470176, validation loss = 4.535697
2018-12-07 19:50:29,234 - INFO - epoch 0, step 36250, training loss = 4.496663, validation loss = 3.996930
2018-12-07 19:50:52,105 - INFO - epoch 0, step 36300, training loss = 3.653069, validation loss = 3.722764
2018-12-07 19:51:15,197 - INFO - epoch 0, step 36350, training loss = 3.371814, validation loss = 3.902778
2018-12-07 19:51:38,199 - INFO - epoch 0, step 36400, training loss = 4.024804, validation loss = 4.240368
2018-12-07 19:52:00,302 - INFO - epoch 0, step 36450, training loss = 3.795496, validation loss = 3.796708
2018-12-07 19:52:23,407 - INFO - epoch 0, step 36500, training loss = 3.609973, validation loss = 4.105036
2018-12-07 19:52:46,987 - INFO - epoch 0, step 36550, training loss = 3.670042, validation loss = 3.696037
2018-12-07 19:53:10,058 - INFO - epoch 0, step 36600, training loss = 3.560930, validation loss = 4.017738
2018-12-07 19:53:33,963 - INFO - epoch 0, step 36650, training loss = 4.216586, validation loss = 4.056085
2018-12-07 19:53:57,534 - INFO - epoch 0, step 36700, training loss = 3.427615, validation loss = 3.849653
2018-12-07 19:54:20,499 - INFO - epoch 0, step 36750, training loss = 3.253719, validation loss = 4.545006
2018-12-07 19:54:42,396 - INFO - epoch 0, step 36800, training loss = 5.898983, validation loss = 4.151332
2018-12-07 19:55:04,270 - INFO - epoch 0, step 36850, training loss = 5.878323, validation loss = 4.267982
2018-12-07 19:55:26,257 - INFO - epoch 0, step 36900, training loss = 5.163734, validation loss = 4.529531
2018-12-07 19:55:47,924 - INFO - epoch 0, step 36950, training loss = 5.414683, validation loss = 4.450042
2018-12-07 19:56:10,366 - INFO - epoch 0, step 37000, training loss = 5.051756, validation loss = 4.222143
2018-12-07 19:56:32,502 - INFO - epoch 0, step 37050, training loss = 5.180046, validation loss = 4.096011
2018-12-07 19:56:54,654 - INFO - epoch 0, step 37100, training loss = 5.299334, validation loss = 4.060820
2018-12-07 19:57:15,911 - INFO - epoch 0, step 37150, training loss = 5.028875, validation loss = 4.099953
2018-12-07 19:57:38,182 - INFO - epoch 0, step 37200, training loss = 5.378232, validation loss = 4.360926
2018-12-07 19:58:00,403 - INFO - epoch 0, step 37250, training loss = 5.013539, validation loss = 4.104287
2018-12-07 19:58:21,928 - INFO - epoch 0, step 37300, training loss = 5.507456, validation loss = 4.123719
2018-12-07 19:58:42,685 - INFO - epoch 0, step 37350, training loss = 5.254726, validation loss = 3.967849
2018-12-07 19:59:04,263 - INFO - epoch 0, step 37400, training loss = 4.777683, validation loss = 4.092962
2018-12-07 19:59:26,760 - INFO - epoch 0, step 37450, training loss = 4.916761, validation loss = 4.037408
2018-12-07 19:59:48,959 - INFO - epoch 0, step 37500, training loss = 5.456880, validation loss = 4.156184
2018-12-07 20:00:11,992 - INFO - epoch 0, step 37550, training loss = 5.180397, validation loss = 4.294105
2018-12-07 20:00:34,444 - INFO - epoch 0, step 37600, training loss = 5.009474, validation loss = 4.345143
2018-12-07 20:00:57,474 - INFO - epoch 0, step 37650, training loss = 5.321732, validation loss = 4.209738
2018-12-07 20:01:21,067 - INFO - epoch 0, step 37700, training loss = 5.490441, validation loss = 4.331137
2018-12-07 20:01:44,772 - INFO - epoch 0, step 37750, training loss = 5.579029, validation loss = 4.199446
2018-12-07 20:02:06,852 - INFO - epoch 0, step 37800, training loss = 5.036036, validation loss = 4.152835
2018-12-07 20:02:30,578 - INFO - epoch 0, step 37850, training loss = 5.040927, validation loss = 4.372590
2018-12-07 20:02:54,665 - INFO - epoch 0, step 37900, training loss = 5.169292, validation loss = 4.026388
2018-12-07 20:03:16,526 - INFO - epoch 0, step 37950, training loss = 4.718420, validation loss = 4.169987
2018-12-07 20:03:38,304 - INFO - epoch 0, step 38000, training loss = 4.711620, validation loss = 4.310346
2018-12-07 20:04:01,340 - INFO - epoch 0, step 38050, training loss = 5.334487, validation loss = 3.845462
2018-12-07 20:04:23,933 - INFO - epoch 0, step 38100, training loss = 5.301612, validation loss = 4.080294
2018-12-07 20:04:45,630 - INFO - epoch 0, step 38150, training loss = 4.435338, validation loss = 4.327884
2018-12-07 20:05:08,523 - INFO - epoch 0, step 38200, training loss = 4.476995, validation loss = 4.622682
2018-12-07 20:05:32,000 - INFO - epoch 0, step 38250, training loss = 4.659621, validation loss = 4.148973
2018-12-07 20:05:58,725 - INFO - epoch 0, step 38300, training loss = 5.402612, validation loss = 4.038466
2018-12-07 20:06:30,199 - INFO - epoch 0, step 38350, training loss = 5.335184, validation loss = 4.003809
2018-12-07 20:07:03,745 - INFO - epoch 0, step 38400, training loss = 5.965701, validation loss = 4.547615
2018-12-07 20:07:27,898 - INFO - epoch 0, step 38450, training loss = 5.579944, validation loss = 4.116502
2018-12-07 20:07:58,032 - INFO - epoch 0, step 38500, training loss = 5.568775, validation loss = 4.598223
2018-12-07 20:08:28,362 - INFO - epoch 0, step 38550, training loss = 5.153493, validation loss = 3.871597
2018-12-07 20:08:51,312 - INFO - epoch 0, step 38600, training loss = 5.014288, validation loss = 4.439121
2018-12-07 20:09:15,305 - INFO - epoch 0, step 38650, training loss = 4.727981, validation loss = 3.921135
2018-12-07 20:09:39,286 - INFO - epoch 0, step 38700, training loss = 5.077186, validation loss = 4.238032
2018-12-07 20:10:08,799 - INFO - epoch 0, step 38750, training loss = 5.227858, validation loss = 4.328573
2018-12-07 20:10:40,989 - INFO - epoch 0, step 38800, training loss = 5.266502, validation loss = 4.105440
2018-12-07 20:11:12,803 - INFO - epoch 0, step 38850, training loss = 5.767207, validation loss = 4.106358
2018-12-07 20:11:44,725 - INFO - epoch 0, step 38900, training loss = 5.236825, validation loss = 4.311215
2018-12-07 20:12:16,417 - INFO - epoch 0, step 38950, training loss = 5.355077, validation loss = 4.379339
2018-12-07 20:12:43,041 - INFO - epoch 0, step 39000, training loss = 5.428662, validation loss = 4.595070
2018-12-07 20:13:13,021 - INFO - epoch 0, step 39050, training loss = 5.014259, validation loss = 4.305986
2018-12-07 20:13:43,799 - INFO - epoch 0, step 39100, training loss = 5.247097, validation loss = 3.853472
2018-12-07 20:14:08,943 - INFO - epoch 0, step 39150, training loss = 4.990237, validation loss = 4.240112
2018-12-07 20:14:34,026 - INFO - epoch 0, step 39200, training loss = 5.132341, validation loss = 4.325064
2018-12-07 20:15:05,389 - INFO - epoch 0, step 39250, training loss = 5.226460, validation loss = 4.528481
2018-12-07 20:15:35,990 - INFO - epoch 0, step 39300, training loss = 5.213600, validation loss = 4.351272
2018-12-07 20:16:02,453 - INFO - epoch 0, step 39350, training loss = 4.797379, validation loss = 4.203211
2018-12-07 20:16:25,889 - INFO - epoch 0, step 39400, training loss = 5.456492, validation loss = 4.026110
2018-12-07 20:16:59,049 - INFO - epoch 0, step 39450, training loss = 5.236313, validation loss = 4.138731
2018-12-07 20:17:26,203 - INFO - epoch 0, step 39500, training loss = 4.805146, validation loss = 4.285356
2018-12-07 20:17:52,768 - INFO - epoch 0, step 39550, training loss = 5.045688, validation loss = 4.390016
2018-12-07 20:18:23,636 - INFO - epoch 0, step 39600, training loss = 5.310474, validation loss = 4.438494
2018-12-07 20:18:55,379 - INFO - epoch 0, step 39650, training loss = 5.034243, validation loss = 4.121138
2018-12-07 20:19:27,583 - INFO - epoch 0, step 39700, training loss = 5.528469, validation loss = 4.693238
2018-12-07 20:19:56,395 - INFO - epoch 0, step 39750, training loss = 4.871334, validation loss = 4.293432
2018-12-07 20:20:18,645 - INFO - epoch 0, step 39800, training loss = 4.792270, validation loss = 3.944503
2018-12-07 20:20:42,376 - INFO - epoch 0, step 39850, training loss = 4.857464, validation loss = 4.432754
2018-12-07 20:21:09,965 - INFO - epoch 0, step 39900, training loss = 4.589889, validation loss = 4.593732
2018-12-07 20:21:41,018 - INFO - epoch 0, step 39950, training loss = 5.162704, validation loss = 4.372183
2018-12-07 20:22:08,274 - INFO - epoch 0, step 40000, training loss = 4.997020, validation loss = 3.780235
2018-12-07 20:22:31,701 - INFO - epoch 0, step 40050, training loss = 5.224593, validation loss = 4.311856
2018-12-07 20:22:55,322 - INFO - epoch 0, step 40100, training loss = 5.296782, validation loss = 4.189211
2018-12-07 20:23:17,234 - INFO - epoch 0, step 40150, training loss = 5.063047, validation loss = 4.094283
2018-12-07 20:23:39,951 - INFO - epoch 0, step 40200, training loss = 4.948110, validation loss = 4.174312
2018-12-07 20:24:02,874 - INFO - epoch 0, step 40250, training loss = 4.491725, validation loss = 3.987242
2018-12-07 20:24:27,138 - INFO - epoch 0, step 40300, training loss = 4.907201, validation loss = 3.977456
2018-12-07 20:24:50,021 - INFO - epoch 0, step 40350, training loss = 5.224482, validation loss = 4.492507
2018-12-07 20:25:12,688 - INFO - epoch 0, step 40400, training loss = 4.885338, validation loss = 4.626177
2018-12-07 20:25:40,832 - INFO - epoch 0, step 40450, training loss = 5.304402, validation loss = 4.141855
2018-12-07 20:26:02,878 - INFO - epoch 0, step 40500, training loss = 4.868061, validation loss = 3.985822
2018-12-07 20:26:25,123 - INFO - epoch 0, step 40550, training loss = 5.073129, validation loss = 3.746607
2018-12-07 20:26:52,064 - INFO - epoch 0, step 40600, training loss = 4.886421, validation loss = 4.402958
2018-12-07 20:27:21,676 - INFO - epoch 0, step 40650, training loss = 5.422569, validation loss = 4.365357
2018-12-07 20:27:51,562 - INFO - epoch 0, step 40700, training loss = 4.208173, validation loss = 4.186639
2018-12-07 20:28:15,705 - INFO - epoch 0, step 40750, training loss = 4.734437, validation loss = 4.110882
2018-12-07 20:28:39,230 - INFO - epoch 0, step 40800, training loss = 4.867046, validation loss = 4.250486
2018-12-07 20:29:03,348 - INFO - epoch 0, step 40850, training loss = 4.910088, validation loss = 4.570593
2018-12-07 20:29:25,652 - INFO - epoch 0, step 40900, training loss = 4.729657, validation loss = 4.436942
2018-12-07 20:29:48,503 - INFO - epoch 0, step 40950, training loss = 4.950114, validation loss = 4.876237
2018-12-07 20:30:12,133 - INFO - epoch 0, step 41000, training loss = 4.971796, validation loss = 4.510451
2018-12-07 20:30:35,822 - INFO - epoch 0, step 41050, training loss = 4.427190, validation loss = 4.084416
2018-12-07 20:30:58,524 - INFO - epoch 0, step 41100, training loss = 5.177856, validation loss = 4.116824
2018-12-07 20:31:20,929 - INFO - epoch 0, step 41150, training loss = 4.615798, validation loss = 4.416995
2018-12-07 20:31:43,543 - INFO - epoch 0, step 41200, training loss = 4.543633, validation loss = 4.035001
2018-12-07 20:32:06,364 - INFO - epoch 0, step 41250, training loss = 4.829684, validation loss = 4.340317
2018-12-07 20:32:28,480 - INFO - epoch 0, step 41300, training loss = 4.680501, validation loss = 4.106654
2018-12-07 20:32:50,678 - INFO - epoch 0, step 41350, training loss = 4.471706, validation loss = 4.120075
2018-12-07 20:33:17,388 - INFO - epoch 0, step 41400, training loss = 4.882957, validation loss = 4.717533
2018-12-07 20:33:48,976 - INFO - epoch 0, step 41450, training loss = 5.319661, validation loss = 4.213531
2018-12-07 20:34:17,539 - INFO - epoch 0, step 41500, training loss = 4.929476, validation loss = 4.882854
2018-12-07 20:34:41,677 - INFO - epoch 0, step 41550, training loss = 5.185885, validation loss = 4.318779
2018-12-07 20:35:11,633 - INFO - epoch 0, step 41600, training loss = 5.653627, validation loss = 4.511334
2018-12-07 20:35:40,313 - INFO - epoch 0, step 41650, training loss = 4.146695, validation loss = 4.213894
2018-12-07 20:36:03,611 - INFO - epoch 0, step 41700, training loss = 4.115591, validation loss = 4.316077
2018-12-07 20:36:30,431 - INFO - epoch 0, step 41750, training loss = 5.251818, validation loss = 4.464721
2018-12-07 20:36:54,388 - INFO - epoch 0, step 41800, training loss = 4.873430, validation loss = 4.487779
2018-12-07 20:37:17,171 - INFO - epoch 0, step 41850, training loss = 4.859208, validation loss = 4.277102
2018-12-07 20:37:40,091 - INFO - epoch 0, step 41900, training loss = 5.444091, validation loss = 4.309130
2018-12-07 20:38:09,985 - INFO - epoch 0, step 41950, training loss = 5.206708, validation loss = 4.265175
2018-12-07 20:38:39,809 - INFO - epoch 0, step 42000, training loss = 4.878447, validation loss = 4.453721
2018-12-07 20:39:03,087 - INFO - epoch 0, step 42050, training loss = 4.899119, validation loss = 4.461520
2018-12-07 20:39:26,694 - INFO - epoch 0, step 42100, training loss = 4.664440, validation loss = 4.144318
2018-12-07 20:39:54,279 - INFO - epoch 0, step 42150, training loss = 5.169806, validation loss = 4.237974
2018-12-07 20:40:23,734 - INFO - epoch 0, step 42200, training loss = 5.350588, validation loss = 4.362645
2018-12-07 20:40:46,972 - INFO - epoch 0, step 42250, training loss = 5.254785, validation loss = 4.513037
2018-12-07 20:41:09,683 - INFO - epoch 0, step 42300, training loss = 4.626359, validation loss = 4.587946
2018-12-07 20:41:32,706 - INFO - epoch 0, step 42350, training loss = 4.443299, validation loss = 4.105789
2018-12-07 20:41:56,749 - INFO - epoch 0, step 42400, training loss = 4.084466, validation loss = 4.495399
2018-12-07 20:42:25,894 - INFO - epoch 0, step 42450, training loss = 5.142103, validation loss = 4.271931
2018-12-07 20:42:56,311 - INFO - epoch 0, step 42500, training loss = 5.148571, validation loss = 4.498309
2018-12-07 20:43:25,825 - INFO - epoch 0, step 42550, training loss = 5.575004, validation loss = 4.245773
2018-12-07 20:43:48,575 - INFO - epoch 0, step 42600, training loss = 5.058245, validation loss = 4.152410
2018-12-07 20:44:11,932 - INFO - epoch 0, step 42650, training loss = 4.925206, validation loss = 4.611447
2018-12-07 20:44:35,926 - INFO - epoch 0, step 42700, training loss = 3.993775, validation loss = 4.545835
2018-12-07 20:45:00,792 - INFO - epoch 0, step 42750, training loss = 4.993904, validation loss = 4.564710
2018-12-07 20:45:33,859 - INFO - epoch 0, step 42800, training loss = 5.311885, validation loss = 4.711879
2018-12-07 20:46:02,434 - INFO - epoch 0, step 42850, training loss = 5.268556, validation loss = 4.294919
2018-12-07 20:46:24,327 - INFO - epoch 0, step 42900, training loss = 5.129578, validation loss = 4.688877
2018-12-07 20:46:46,687 - INFO - epoch 0, step 42950, training loss = 5.151834, validation loss = 4.221485
2018-12-07 20:47:10,653 - INFO - epoch 0, step 43000, training loss = 4.927085, validation loss = 4.644875
2018-12-07 20:47:38,953 - INFO - epoch 0, step 43050, training loss = 4.812393, validation loss = 4.448280
2018-12-07 20:48:07,565 - INFO - epoch 0, step 43100, training loss = 5.066365, validation loss = 3.996781
2018-12-07 20:48:30,989 - INFO - epoch 0, step 43150, training loss = 4.452872, validation loss = 4.015246
2018-12-07 20:48:55,319 - INFO - epoch 0, step 43200, training loss = 4.640387, validation loss = 4.034749
2018-12-07 20:49:18,653 - INFO - epoch 0, step 43250, training loss = 4.916882, validation loss = 4.546266
2018-12-07 20:49:50,591 - INFO - epoch 0, step 43300, training loss = 4.769147, validation loss = 4.670308
2018-12-07 20:50:15,928 - INFO - epoch 0, step 43350, training loss = 4.999632, validation loss = 4.596951
2018-12-07 20:50:40,060 - INFO - epoch 0, step 43400, training loss = 4.388903, validation loss = 4.316483
2018-12-07 20:51:04,426 - INFO - epoch 0, step 43450, training loss = 5.120157, validation loss = 4.026050
2018-12-07 20:51:28,214 - INFO - epoch 0, step 43500, training loss = 4.795851, validation loss = 4.161992
2018-12-07 20:51:55,498 - INFO - epoch 0, step 43550, training loss = 4.974459, validation loss = 4.201876
2018-12-07 20:52:20,006 - INFO - epoch 0, step 43600, training loss = 5.194147, validation loss = 4.299514
2018-12-07 20:52:45,193 - INFO - epoch 0, step 43650, training loss = 5.118779, validation loss = 4.071450
2018-12-07 20:53:12,080 - INFO - epoch 0, step 43700, training loss = 4.916982, validation loss = 4.791582
2018-12-07 20:53:34,752 - INFO - epoch 0, step 43750, training loss = 4.346688, validation loss = 4.608539
2018-12-07 20:54:01,462 - INFO - epoch 0, step 43800, training loss = 4.777586, validation loss = 4.383669
2018-12-07 20:54:26,752 - INFO - epoch 0, step 43850, training loss = 5.262236, validation loss = 4.226663
2018-12-07 20:54:50,303 - INFO - epoch 0, step 43900, training loss = 5.013967, validation loss = 3.829759
2018-12-07 20:55:13,809 - INFO - epoch 0, step 43950, training loss = 4.390262, validation loss = 4.194646
2018-12-07 20:55:38,196 - INFO - epoch 0, step 44000, training loss = 4.682475, validation loss = 4.516640
2018-12-07 20:56:01,275 - INFO - epoch 0, step 44050, training loss = 4.570851, validation loss = 4.203781
2018-12-07 20:56:25,099 - INFO - epoch 0, step 44100, training loss = 4.437750, validation loss = 4.428778
2018-12-07 20:56:49,414 - INFO - epoch 0, step 44150, training loss = 4.569129, validation loss = 4.471489
2018-12-07 20:57:12,657 - INFO - epoch 0, step 44200, training loss = 5.015893, validation loss = 4.174848
2018-12-07 20:57:36,422 - INFO - epoch 0, step 44250, training loss = 4.157514, validation loss = 3.963670
2018-12-07 20:58:00,944 - INFO - epoch 0, step 44300, training loss = 4.555146, validation loss = 4.102754
2018-12-07 20:58:25,179 - INFO - epoch 0, step 44350, training loss = 5.062484, validation loss = 4.732098
2018-12-07 20:58:48,002 - INFO - epoch 0, step 44400, training loss = 5.072243, validation loss = 4.181457
2018-12-07 20:59:10,025 - INFO - epoch 0, step 44450, training loss = 4.864137, validation loss = 4.276728
2018-12-07 20:59:34,683 - INFO - epoch 0, step 44500, training loss = 4.853437, validation loss = 4.053103
2018-12-07 21:00:01,755 - INFO - epoch 0, step 44550, training loss = 4.765322, validation loss = 4.056601
2018-12-07 21:00:25,818 - INFO - epoch 0, step 44600, training loss = 4.574536, validation loss = 4.307967
2018-12-07 21:00:53,391 - INFO - epoch 0, step 44650, training loss = 5.115687, validation loss = 4.535969
2018-12-07 21:01:24,277 - INFO - epoch 0, step 44700, training loss = 4.802349, validation loss = 4.061818
2018-12-07 21:01:49,988 - INFO - epoch 0, step 44750, training loss = 4.707816, validation loss = 4.230573
2018-12-07 21:02:15,524 - INFO - epoch 0, step 44800, training loss = 4.600748, validation loss = 4.409613
2018-12-07 21:02:41,182 - INFO - epoch 0, step 44850, training loss = 5.087335, validation loss = 4.311296
2018-12-07 21:03:03,333 - INFO - epoch 0, step 44900, training loss = 4.675484, validation loss = 4.309191
2018-12-07 21:03:27,060 - INFO - epoch 0, step 44950, training loss = 4.364386, validation loss = 4.236941
2018-12-07 21:03:53,950 - INFO - epoch 0, step 45000, training loss = 4.958008, validation loss = 4.448409
2018-12-07 21:04:22,066 - INFO - epoch 0, step 45050, training loss = 4.878487, validation loss = 4.129875
2018-12-07 21:04:49,293 - INFO - epoch 0, step 45100, training loss = 4.408301, validation loss = 4.032074
2018-12-07 21:05:12,934 - INFO - epoch 0, step 45150, training loss = 4.731279, validation loss = 4.454196
2018-12-07 21:05:41,193 - INFO - epoch 0, step 45200, training loss = 5.092205, validation loss = 4.107022
2018-12-07 21:06:06,322 - INFO - epoch 0, step 45250, training loss = 4.740905, validation loss = 4.471618
2018-12-07 21:06:32,641 - INFO - epoch 0, step 45300, training loss = 4.763735, validation loss = 3.741150
2018-12-07 21:07:02,993 - INFO - epoch 0, step 45350, training loss = 4.717352, validation loss = 4.708302
2018-12-07 21:07:32,882 - INFO - epoch 0, step 45400, training loss = 4.932491, validation loss = 4.249480
2018-12-07 21:08:03,409 - INFO - epoch 0, step 45450, training loss = 4.766318, validation loss = 3.766064
2018-12-07 21:08:27,130 - INFO - epoch 0, step 45500, training loss = 4.913279, validation loss = 4.696093
2018-12-07 21:08:54,363 - INFO - epoch 0, step 45550, training loss = 5.222395, validation loss = 3.945443
2018-12-07 21:09:16,851 - INFO - epoch 0, step 45600, training loss = 4.993999, validation loss = 4.458787
2018-12-07 21:09:38,842 - INFO - epoch 0, step 45650, training loss = 4.833986, validation loss = 4.086122
2018-12-07 21:10:01,977 - INFO - epoch 0, step 45700, training loss = 5.064683, validation loss = 4.383362
2018-12-07 21:10:24,592 - INFO - epoch 0, step 45750, training loss = 4.769708, validation loss = 4.369237
2018-12-07 21:10:46,734 - INFO - epoch 0, step 45800, training loss = 5.014109, validation loss = 4.391877
2018-12-07 21:11:15,936 - INFO - epoch 0, step 45850, training loss = 4.675713, validation loss = 4.381760
2018-12-07 21:11:46,983 - INFO - epoch 0, step 45900, training loss = 5.290064, validation loss = 4.282488
2018-12-07 21:12:19,302 - INFO - epoch 0, step 45950, training loss = 4.667861, validation loss = 4.923969
2018-12-07 21:12:51,045 - INFO - epoch 0, step 46000, training loss = 5.153226, validation loss = 4.211788
2018-12-07 21:13:16,988 - INFO - epoch 0, step 46050, training loss = 4.895849, validation loss = 4.761942
2018-12-07 21:13:40,771 - INFO - epoch 0, step 46100, training loss = 4.628815, validation loss = 3.809432
2018-12-07 21:14:05,090 - INFO - epoch 0, step 46150, training loss = 4.178442, validation loss = 4.474256
2018-12-07 21:14:27,781 - INFO - epoch 0, step 46200, training loss = 4.587328, validation loss = 4.600170
2018-12-07 21:14:51,406 - INFO - epoch 0, step 46250, training loss = 4.777841, validation loss = 4.434161
2018-12-07 21:15:15,928 - INFO - epoch 0, step 46300, training loss = 4.620878, validation loss = 4.246012
2018-12-07 21:15:39,093 - INFO - epoch 0, step 46350, training loss = 4.626166, validation loss = 4.078731
2018-12-07 21:16:01,316 - INFO - epoch 0, step 46400, training loss = 4.790518, validation loss = 4.540392
2018-12-07 21:16:23,061 - INFO - epoch 0, step 46450, training loss = 4.487092, validation loss = 4.796066
2018-12-07 21:16:50,781 - INFO - epoch 0, step 46500, training loss = 4.754482, validation loss = 4.589775
2018-12-07 21:17:17,171 - INFO - epoch 0, step 46550, training loss = 4.698122, validation loss = 4.199993
2018-12-07 21:17:41,518 - INFO - epoch 0, step 46600, training loss = 5.198022, validation loss = 4.211247
2018-12-07 21:18:08,714 - INFO - epoch 0, step 46650, training loss = 4.659770, validation loss = 3.968813
2018-12-07 21:18:27,639 - INFO - epoch 0, step 46700, training loss = 4.902273, validation loss = 4.307250
2018-12-07 21:18:48,010 - INFO - epoch 0, step 46750, training loss = 3.916369, validation loss = 3.990978
2018-12-07 21:19:08,542 - INFO - epoch 0, step 46800, training loss = 4.745571, validation loss = 4.383332
2018-12-07 21:19:27,730 - INFO - epoch 0, step 46850, training loss = 4.957455, validation loss = 4.164789
2018-12-07 21:19:47,119 - INFO - epoch 0, step 46900, training loss = 4.592358, validation loss = 4.600781
2018-12-07 21:20:12,541 - INFO - epoch 0, step 46950, training loss = 4.929285, validation loss = 4.266122
2018-12-07 21:20:40,019 - INFO - epoch 0, step 47000, training loss = 5.240792, validation loss = 4.281991
2018-12-07 21:21:04,751 - INFO - epoch 0, step 47050, training loss = 4.780150, validation loss = 4.095512
2018-12-07 21:21:26,804 - INFO - epoch 0, step 47100, training loss = 4.553602, validation loss = 4.485450
2018-12-07 21:21:48,342 - INFO - epoch 0, step 47150, training loss = 4.637637, validation loss = 4.343374
2018-12-07 21:22:08,637 - INFO - epoch 0, step 47200, training loss = 4.013731, validation loss = 3.979755
2018-12-07 21:22:24,546 - INFO - epoch 0, step 47250, training loss = 3.561860, validation loss = 3.445827
2018-12-07 21:22:43,090 - INFO - epoch 0, step 47300, training loss = 3.673336, validation loss = 3.832194
2018-12-07 21:23:02,195 - INFO - epoch 0, step 47350, training loss = 3.270951, validation loss = 4.008128
2018-12-07 21:23:18,366 - INFO - epoch 0, step 47400, training loss = 3.348268, validation loss = 4.057960
2018-12-07 21:23:35,665 - INFO - epoch 0, step 47450, training loss = 3.484629, validation loss = 4.206123
2018-12-07 21:23:54,220 - INFO - epoch 0, step 47500, training loss = 3.327208, validation loss = 4.242872
2018-12-07 21:24:12,579 - INFO - epoch 0, step 47550, training loss = 3.626253, validation loss = 4.428841
2018-12-07 21:24:30,471 - INFO - epoch 0, step 47600, training loss = 3.322463, validation loss = 4.005468
2018-12-07 21:24:47,308 - INFO - epoch 0, step 47650, training loss = 3.509856, validation loss = 4.013368
2018-12-07 21:25:02,912 - INFO - epoch 0, step 47700, training loss = 3.511082, validation loss = 4.006263
2018-12-07 21:25:19,450 - INFO - epoch 0, step 47750, training loss = 3.604391, validation loss = 4.062524
2018-12-07 21:25:37,145 - INFO - epoch 0, step 47800, training loss = 3.428783, validation loss = 4.049302
2018-12-07 21:25:56,575 - INFO - epoch 0, step 47850, training loss = 2.999256, validation loss = 4.017137
2018-12-07 21:26:18,353 - INFO - epoch 0, step 47900, training loss = 3.509287, validation loss = 4.498967
2018-12-07 21:26:40,148 - INFO - epoch 0, step 47950, training loss = 3.836954, validation loss = 4.068596
2018-12-07 21:27:00,577 - INFO - epoch 0, step 48000, training loss = 3.401592, validation loss = 3.858963
2018-12-07 21:27:17,942 - INFO - epoch 0, step 48050, training loss = 3.238940, validation loss = 4.201877
2018-12-07 21:27:34,370 - INFO - epoch 0, step 48100, training loss = 3.463258, validation loss = 3.889488
2018-12-07 21:27:52,027 - INFO - epoch 0, step 48150, training loss = 3.184399, validation loss = 3.805322
2018-12-07 21:28:12,538 - INFO - epoch 0, step 48200, training loss = 2.825666, validation loss = 3.805574
2018-12-07 21:28:33,344 - INFO - epoch 0, step 48250, training loss = 3.091356, validation loss = 3.876221
2018-12-07 21:28:52,798 - INFO - epoch 0, step 48300, training loss = 2.923032, validation loss = 4.301538
2018-12-07 21:29:14,205 - INFO - epoch 0, step 48350, training loss = 3.328596, validation loss = 4.554699
2018-12-07 21:29:36,095 - INFO - epoch 0, step 48400, training loss = 3.217065, validation loss = 4.695529
2018-12-07 21:29:56,578 - INFO - epoch 0, step 48450, training loss = 3.182402, validation loss = 3.565269
2018-12-07 21:30:14,081 - INFO - epoch 0, step 48500, training loss = 3.392199, validation loss = 3.696645
2018-12-07 21:30:29,767 - INFO - epoch 0, step 48550, training loss = 3.299367, validation loss = 3.642279
2018-12-07 21:30:46,531 - INFO - epoch 0, step 48600, training loss = 2.910128, validation loss = 3.969751
2018-12-07 21:31:04,711 - INFO - epoch 0, step 48650, training loss = 3.122490, validation loss = 4.083313
2018-12-07 21:31:24,814 - INFO - epoch 0, step 48700, training loss = 3.127558, validation loss = 4.482471
2018-12-07 21:31:45,092 - INFO - epoch 0, step 48750, training loss = 2.920723, validation loss = 4.553077
2018-12-07 21:32:05,909 - INFO - epoch 0, step 48800, training loss = 2.690799, validation loss = 4.026470
2018-12-07 21:32:26,917 - INFO - epoch 0, step 48850, training loss = 3.520197, validation loss = 3.832931
2018-12-07 21:32:46,081 - INFO - epoch 0, step 48900, training loss = 3.255511, validation loss = 4.004776
2018-12-07 21:33:04,752 - INFO - epoch 0, step 48950, training loss = 3.074996, validation loss = 4.170706
2018-12-07 21:33:22,323 - INFO - epoch 0, step 49000, training loss = 3.109402, validation loss = 4.127303
2018-12-07 21:33:38,401 - INFO - epoch 0, step 49050, training loss = 2.695272, validation loss = 3.468423
2018-12-07 21:33:57,500 - INFO - epoch 0, step 49100, training loss = 2.975861, validation loss = 3.773517
2018-12-07 21:34:15,732 - INFO - epoch 0, step 49150, training loss = 2.936583, validation loss = 4.322662
2018-12-07 21:34:33,793 - INFO - epoch 0, step 49200, training loss = 3.075892, validation loss = 3.895526
2018-12-07 21:34:54,129 - INFO - epoch 0, step 49250, training loss = 2.884054, validation loss = 3.945413
2018-12-07 21:35:12,806 - INFO - epoch 0, step 49300, training loss = 2.828865, validation loss = 3.952386
2018-12-07 21:35:29,573 - INFO - epoch 0, step 49350, training loss = 3.226040, validation loss = 4.004199
2018-12-07 21:35:46,189 - INFO - epoch 0, step 49400, training loss = 3.139108, validation loss = 4.004939
2018-12-07 21:36:01,355 - INFO - epoch 0, step 49450, training loss = 3.423147, validation loss = 4.347270
2018-12-07 21:36:18,388 - INFO - epoch 0, step 49500, training loss = 2.948686, validation loss = 4.760556
2018-12-07 21:36:33,840 - INFO - epoch 0, step 49550, training loss = 3.240658, validation loss = 3.984264
2018-12-07 21:36:50,846 - INFO - epoch 0, step 49600, training loss = 2.627935, validation loss = 3.584309
2018-12-07 21:37:10,099 - INFO - epoch 0, step 49650, training loss = 2.723081, validation loss = 3.975841
2018-12-07 21:37:31,968 - INFO - epoch 0, step 49700, training loss = 3.292789, validation loss = 4.369956
2018-12-07 21:37:53,664 - INFO - epoch 0, step 49750, training loss = 3.013321, validation loss = 4.311392
2018-12-07 21:38:13,759 - INFO - epoch 0, step 49800, training loss = 3.478362, validation loss = 4.279414
2018-12-07 21:38:30,041 - INFO - epoch 0, step 49850, training loss = 2.891876, validation loss = 4.267478
2018-12-07 21:38:47,976 - INFO - epoch 0, step 49900, training loss = 3.125176, validation loss = 3.893738
2018-12-07 21:39:07,280 - INFO - epoch 0, step 49950, training loss = 2.597415, validation loss = 3.781790
2018-12-07 21:39:27,764 - INFO - epoch 0, step 50000, training loss = 2.964330, validation loss = 3.429787
2018-12-07 21:39:48,283 - INFO - epoch 0, step 50050, training loss = 2.722544, validation loss = 4.237988
2018-12-07 21:40:07,814 - INFO - epoch 0, step 50100, training loss = 3.214160, validation loss = 3.808238
2018-12-07 21:40:25,041 - INFO - epoch 0, step 50150, training loss = 2.369344, validation loss = 3.904836
2018-12-07 21:40:45,781 - INFO - epoch 0, step 50200, training loss = 2.909727, validation loss = 4.408770
2018-12-07 21:41:06,435 - INFO - epoch 0, step 50250, training loss = 3.522876, validation loss = 4.037561
2018-12-07 21:41:27,663 - INFO - epoch 0, step 50300, training loss = 3.159471, validation loss = 3.691002
2018-12-07 21:41:48,881 - INFO - epoch 0, step 50350, training loss = 2.942179, validation loss = 4.233829
2018-12-07 21:42:09,879 - INFO - epoch 0, step 50400, training loss = 2.910103, validation loss = 4.058101
2018-12-07 21:42:28,194 - INFO - epoch 0, step 50450, training loss = 2.956109, validation loss = 4.393493
2018-12-07 21:42:45,034 - INFO - epoch 0, step 50500, training loss = 3.396070, validation loss = 4.307744
2018-12-07 21:43:00,741 - INFO - epoch 0, step 50550, training loss = 3.287333, validation loss = 4.465259
2018-12-07 21:43:20,977 - INFO - epoch 0, step 50600, training loss = 3.081065, validation loss = 3.969921
2018-12-07 21:43:41,493 - INFO - epoch 0, step 50650, training loss = 2.862693, validation loss = 3.778098
2018-12-07 21:44:02,085 - INFO - epoch 0, step 50700, training loss = 3.077033, validation loss = 4.431840
2018-12-07 21:44:19,742 - INFO - epoch 0, step 50750, training loss = 2.702801, validation loss = 4.913741
2018-12-07 21:44:36,553 - INFO - epoch 0, step 50800, training loss = 3.188719, validation loss = 4.385325
2018-12-07 21:44:53,778 - INFO - epoch 0, step 50850, training loss = 2.447397, validation loss = 3.855597
2018-12-07 21:45:12,135 - INFO - epoch 0, step 50900, training loss = 2.652085, validation loss = 4.207848
2018-12-07 21:45:29,612 - INFO - epoch 0, step 50950, training loss = 2.861837, validation loss = 4.413032
2018-12-07 21:45:46,491 - INFO - epoch 0, step 51000, training loss = 3.336015, validation loss = 4.066544
2018-12-07 21:46:03,574 - INFO - epoch 0, step 51050, training loss = 2.968583, validation loss = 4.571053
2018-12-07 21:46:23,227 - INFO - epoch 0, step 51100, training loss = 3.013892, validation loss = 4.715258
2018-12-07 21:46:42,579 - INFO - epoch 0, step 51150, training loss = 2.858373, validation loss = 4.417048
2018-12-07 21:47:01,115 - INFO - epoch 0, step 51200, training loss = 2.792805, validation loss = 3.911710
2018-12-07 21:47:18,724 - INFO - epoch 0, step 51250, training loss = 2.750861, validation loss = 4.286254
2018-12-07 21:47:35,458 - INFO - epoch 0, step 51300, training loss = 3.071217, validation loss = 4.177570
2018-12-07 21:47:50,787 - INFO - epoch 0, step 51350, training loss = 2.982654, validation loss = 4.512043
2018-12-07 21:48:06,357 - INFO - epoch 0, step 51400, training loss = 3.114523, validation loss = 4.247132
2018-12-07 21:48:24,772 - INFO - epoch 0, step 51450, training loss = 2.693973, validation loss = 4.338078
2018-12-07 21:48:45,102 - INFO - epoch 0, step 51500, training loss = 2.753938, validation loss = 4.561741
2018-12-07 21:49:05,108 - INFO - epoch 0, step 51550, training loss = 2.625639, validation loss = 4.127263
2018-12-07 21:49:24,148 - INFO - epoch 0, step 51600, training loss = 3.024002, validation loss = 3.184733
2018-12-07 21:49:43,375 - INFO - epoch 0, step 51650, training loss = 2.824738, validation loss = 3.917788
2018-12-07 21:50:01,989 - INFO - epoch 0, step 51700, training loss = 2.647834, validation loss = 4.170483
2018-12-07 21:50:22,564 - INFO - epoch 0, step 51750, training loss = 2.823442, validation loss = 4.283642
2018-12-07 21:50:43,900 - INFO - epoch 0, step 51800, training loss = 2.886132, validation loss = 4.270342
2018-12-07 21:51:04,557 - INFO - epoch 0, step 51850, training loss = 3.139875, validation loss = 4.112399
2018-12-07 21:51:20,023 - INFO - epoch 0, step 51900, training loss = 2.713171, validation loss = 4.610570
2018-12-07 21:51:36,070 - INFO - epoch 0, step 51950, training loss = 2.656666, validation loss = 3.971794
2018-12-07 21:51:53,062 - INFO - epoch 0, step 52000, training loss = 3.018175, validation loss = 4.199569
2018-12-07 21:52:13,077 - INFO - epoch 0, step 52050, training loss = 3.188737, validation loss = 4.653466
2018-12-07 21:52:33,763 - INFO - epoch 0, step 52100, training loss = 3.034418, validation loss = 4.292006
2018-12-07 21:52:53,748 - INFO - epoch 0, step 52150, training loss = 2.522918, validation loss = 4.242004
2018-12-07 21:53:09,857 - INFO - epoch 0, step 52200, training loss = 3.014587, validation loss = 4.351629
2018-12-07 21:53:25,644 - INFO - epoch 0, step 52250, training loss = 3.369936, validation loss = 4.527651
2018-12-07 21:53:42,240 - INFO - epoch 0, step 52300, training loss = 2.831364, validation loss = 3.713871
2018-12-07 21:54:03,920 - INFO - epoch 0, step 52350, training loss = 2.765739, validation loss = 4.109266
2018-12-07 21:54:22,727 - INFO - epoch 0, step 52400, training loss = 3.099796, validation loss = 3.283354
2018-12-07 21:54:38,503 - INFO - epoch 0, step 52450, training loss = 3.271818, validation loss = 3.857212
2018-12-07 21:54:54,442 - INFO - epoch 0, step 52500, training loss = 3.026736, validation loss = 3.988474
2018-12-07 21:55:13,170 - INFO - epoch 0, step 52550, training loss = 2.896491, validation loss = 4.065349
2018-12-07 21:55:32,740 - INFO - epoch 0, step 52600, training loss = 3.081375, validation loss = 4.251891
2018-12-07 21:55:49,622 - INFO - epoch 0, step 52650, training loss = 2.843581, validation loss = 4.081742
2018-12-07 21:56:09,303 - INFO - epoch 0, step 52700, training loss = 2.787048, validation loss = 3.747337
2018-12-07 21:56:30,016 - INFO - epoch 0, step 52750, training loss = 2.562464, validation loss = 3.545418
2018-12-07 21:56:50,968 - INFO - epoch 0, step 52800, training loss = 2.956666, validation loss = 3.961352
2018-12-07 21:57:12,765 - INFO - epoch 0, step 52850, training loss = 2.789218, validation loss = 4.015491
2018-12-07 21:57:30,550 - INFO - epoch 0, step 52900, training loss = 2.817635, validation loss = 4.021684
2018-12-07 21:57:46,255 - INFO - epoch 0, step 52950, training loss = 2.853922, validation loss = 4.489390
2018-12-07 21:58:01,983 - INFO - epoch 0, step 53000, training loss = 2.952516, validation loss = 4.434490
2018-12-07 21:58:19,106 - INFO - epoch 0, step 53050, training loss = 2.641017, validation loss = 4.078029
2018-12-07 21:58:37,168 - INFO - epoch 0, step 53100, training loss = 2.631689, validation loss = 4.035594
2018-12-07 21:58:56,309 - INFO - epoch 0, step 53150, training loss = 2.781104, validation loss = 4.052645
2018-12-07 21:59:12,545 - INFO - epoch 0, step 53200, training loss = 2.714522, validation loss = 3.884985
2018-12-07 21:59:29,213 - INFO - epoch 0, step 53250, training loss = 3.090035, validation loss = 4.237741
2018-12-07 21:59:48,224 - INFO - epoch 0, step 53300, training loss = 2.680779, validation loss = 4.452642
2018-12-07 22:00:08,587 - INFO - epoch 0, step 53350, training loss = 2.760400, validation loss = 3.687641
2018-12-07 22:00:29,857 - INFO - epoch 0, step 53400, training loss = 2.753849, validation loss = 4.157622
2018-12-07 22:00:51,879 - INFO - epoch 0, step 53450, training loss = 3.298024, validation loss = 4.300379
2018-12-07 22:01:11,857 - INFO - epoch 0, step 53500, training loss = 2.934829, validation loss = 4.389829
2018-12-07 22:01:29,183 - INFO - epoch 0, step 53550, training loss = 3.147831, validation loss = 4.324585
2018-12-07 22:01:45,226 - INFO - epoch 0, step 53600, training loss = 3.012722, validation loss = 4.002670
2018-12-07 22:02:03,583 - INFO - epoch 0, step 53650, training loss = 3.154962, validation loss = 3.719692
2018-12-07 22:02:22,619 - INFO - epoch 0, step 53700, training loss = 2.995236, validation loss = 4.068006
2018-12-07 22:02:42,909 - INFO - epoch 0, step 53750, training loss = 2.644398, validation loss = 4.248966
2018-12-07 22:03:01,671 - INFO - epoch 0, step 53800, training loss = 2.830786, validation loss = 4.531375
2018-12-07 22:03:18,190 - INFO - epoch 0, step 53850, training loss = 3.061411, validation loss = 4.252264
2018-12-07 22:03:33,625 - INFO - epoch 0, step 53900, training loss = 3.083972, validation loss = 4.499669
2018-12-07 22:03:49,549 - INFO - epoch 0, step 53950, training loss = 2.229633, validation loss = 4.354839
2018-12-07 22:04:07,393 - INFO - epoch 0, step 54000, training loss = 2.575679, validation loss = 4.245646
2018-12-07 22:04:29,810 - INFO - epoch 0, step 54050, training loss = 2.890100, validation loss = 3.657687
2018-12-07 22:04:47,922 - INFO - epoch 0, step 54100, training loss = 2.894694, validation loss = 4.265340
2018-12-07 22:05:03,466 - INFO - epoch 0, step 54150, training loss = 2.812218, validation loss = 4.371641
2018-12-07 22:05:19,586 - INFO - epoch 0, step 54200, training loss = 2.780105, validation loss = 4.430524
2018-12-07 22:05:38,006 - INFO - epoch 0, step 54250, training loss = 3.038155, validation loss = 4.378242
2018-12-07 22:05:58,349 - INFO - epoch 0, step 54300, training loss = 2.574125, validation loss = 4.410796
2018-12-07 22:06:15,107 - INFO - epoch 0, step 54350, training loss = 2.816647, validation loss = 3.967207
2018-12-07 22:06:31,625 - INFO - epoch 0, step 54400, training loss = 3.292720, validation loss = 3.962823
2018-12-07 22:06:48,641 - INFO - epoch 0, step 54450, training loss = 3.053995, validation loss = 4.364642
2018-12-07 22:07:10,283 - INFO - epoch 0, step 54500, training loss = 2.241186, validation loss = 4.310387
2018-12-07 22:07:29,129 - INFO - epoch 0, step 54550, training loss = 2.859358, validation loss = 3.915465
2018-12-07 22:07:46,986 - INFO - epoch 0, step 54600, training loss = 2.641938, validation loss = 4.192554
2018-12-07 22:08:06,020 - INFO - epoch 0, step 54650, training loss = 3.016329, validation loss = 4.685304
2018-12-07 22:08:26,067 - INFO - epoch 0, step 54700, training loss = 3.169578, validation loss = 4.266911
2018-12-07 22:08:45,796 - INFO - epoch 0, step 54750, training loss = 2.653144, validation loss = 4.411093
2018-12-07 22:09:01,813 - INFO - epoch 0, step 54800, training loss = 2.685431, validation loss = 4.404503
2018-12-07 22:09:21,282 - INFO - epoch 0, step 54850, training loss = 2.986956, validation loss = 4.333663
2018-12-07 22:09:43,661 - INFO - epoch 0, step 54900, training loss = 2.445709, validation loss = 3.994448
2018-12-07 22:10:04,928 - INFO - epoch 0, step 54950, training loss = 2.415007, validation loss = 4.009291
2018-12-07 22:10:25,475 - INFO - epoch 0, step 55000, training loss = 2.493282, validation loss = 4.226055
2018-12-07 22:10:46,308 - INFO - epoch 0, step 55050, training loss = 2.739748, validation loss = 4.156518
2018-12-07 22:11:06,318 - INFO - epoch 0, step 55100, training loss = 2.653556, validation loss = 4.239563
2018-12-07 22:11:25,832 - INFO - epoch 0, step 55150, training loss = 2.938499, validation loss = 4.401542
2018-12-07 22:11:43,566 - INFO - epoch 0, step 55200, training loss = 2.755558, validation loss = 4.586545
2018-12-07 22:12:03,988 - INFO - epoch 0, step 55250, training loss = 2.729890, validation loss = 4.162650
2018-12-07 22:12:25,627 - INFO - epoch 0, step 55300, training loss = 2.977947, validation loss = 4.200023
2018-12-07 22:12:47,850 - INFO - epoch 0, step 55350, training loss = 2.702692, validation loss = 4.128672
2018-12-07 22:13:06,918 - INFO - epoch 0, step 55400, training loss = 3.161426, validation loss = 4.567069
2018-12-07 22:13:22,728 - INFO - epoch 0, step 55450, training loss = 2.762709, validation loss = 4.640089
2018-12-07 22:13:41,752 - INFO - epoch 0, step 55500, training loss = 2.778692, validation loss = 4.359077
2018-12-07 22:14:00,655 - INFO - epoch 0, step 55550, training loss = 3.077311, validation loss = 4.463201
2018-12-07 22:14:18,005 - INFO - epoch 0, step 55600, training loss = 3.116342, validation loss = 3.970117
2018-12-07 22:14:39,937 - INFO - epoch 0, step 55650, training loss = 2.684648, validation loss = 3.704074
2018-12-07 22:15:00,907 - INFO - epoch 0, step 55700, training loss = 2.685365, validation loss = 3.936157
2018-12-07 22:15:21,363 - INFO - epoch 0, step 55750, training loss = 2.881083, validation loss = 4.251979
2018-12-07 22:15:39,485 - INFO - epoch 0, step 55800, training loss = 2.659893, validation loss = 4.024918
2018-12-07 22:15:58,764 - INFO - epoch 0, step 55850, training loss = 2.818905, validation loss = 4.014000
2018-12-07 22:16:20,622 - INFO - epoch 0, step 55900, training loss = 2.440380, validation loss = 4.102736
2018-12-07 22:16:40,996 - INFO - epoch 0, step 55950, training loss = 2.631492, validation loss = 3.694912
2018-12-07 22:17:01,314 - INFO - epoch 0, step 56000, training loss = 2.784005, validation loss = 4.334194
2018-12-07 22:17:20,722 - INFO - epoch 0, step 56050, training loss = 2.814888, validation loss = 4.467798
2018-12-07 22:17:38,983 - INFO - epoch 0, step 56100, training loss = 2.700204, validation loss = 4.368413
2018-12-07 22:18:00,511 - INFO - epoch 0, step 56150, training loss = 3.392314, validation loss = 4.068963
2018-12-07 22:18:21,040 - INFO - epoch 0, step 56200, training loss = 2.938523, validation loss = 4.460495
2018-12-07 22:18:36,733 - INFO - epoch 0, step 56250, training loss = 2.845748, validation loss = 4.793862
2018-12-07 22:18:52,585 - INFO - epoch 0, step 56300, training loss = 2.664149, validation loss = 4.596195
2018-12-07 22:19:09,776 - INFO - epoch 0, step 56350, training loss = 2.700316, validation loss = 4.421425
2018-12-07 22:19:30,366 - INFO - epoch 0, step 56400, training loss = 3.325092, validation loss = 4.597991
2018-12-07 22:19:51,340 - INFO - epoch 0, step 56450, training loss = 3.037634, validation loss = 4.708461
2018-12-07 22:20:13,507 - INFO - epoch 0, step 56500, training loss = 2.614317, validation loss = 3.962081
2018-12-07 22:20:34,799 - INFO - epoch 0, step 56550, training loss = 3.265337, validation loss = 4.317527
2018-12-07 22:20:52,322 - INFO - epoch 0, step 56600, training loss = 2.812221, validation loss = 4.336304
2018-12-07 22:21:10,124 - INFO - epoch 0, step 56650, training loss = 3.147528, validation loss = 4.446214
2018-12-07 22:21:27,101 - INFO - epoch 0, step 56700, training loss = 3.166411, validation loss = 4.461802
2018-12-07 22:21:48,171 - INFO - epoch 0, step 56750, training loss = 2.841330, validation loss = 4.631344
2018-12-07 22:22:07,055 - INFO - epoch 0, step 56800, training loss = 2.702559, validation loss = 4.314891
2018-12-07 22:22:25,450 - INFO - epoch 0, step 56850, training loss = 2.905587, validation loss = 4.810637
2018-12-07 22:22:41,913 - INFO - epoch 0, step 56900, training loss = 2.637010, validation loss = 4.142595
2018-12-07 22:22:58,948 - INFO - epoch 0, step 56950, training loss = 2.859522, validation loss = 4.176056
2018-12-07 22:23:17,151 - INFO - epoch 0, step 57000, training loss = 2.497801, validation loss = 4.433606
2018-12-07 22:23:38,698 - INFO - epoch 0, step 57050, training loss = 2.289173, validation loss = 4.316350
2018-12-07 22:23:58,820 - INFO - epoch 0, step 57100, training loss = 2.805844, validation loss = 4.240183
2018-12-07 22:24:18,244 - INFO - epoch 0, step 57150, training loss = 2.668063, validation loss = 4.449477
2018-12-07 22:24:39,457 - INFO - epoch 0, step 57200, training loss = 2.675174, validation loss = 4.520398
2018-12-07 22:25:00,925 - INFO - epoch 0, step 57250, training loss = 2.462852, validation loss = 4.414172
2018-12-07 22:25:21,087 - INFO - epoch 0, step 57300, training loss = 2.674848, validation loss = 4.026600
2018-12-07 22:25:39,114 - INFO - epoch 0, step 57350, training loss = 2.369871, validation loss = 4.067191
2018-12-07 22:25:55,957 - INFO - epoch 0, step 57400, training loss = 2.644839, validation loss = 4.313705
2018-12-07 22:26:12,035 - INFO - epoch 0, step 57450, training loss = 2.566132, validation loss = 4.142779
2018-12-07 22:26:28,164 - INFO - epoch 0, step 57500, training loss = 2.544600, validation loss = 4.585298
2018-12-07 22:26:44,501 - INFO - epoch 0, step 57550, training loss = 2.847100, validation loss = 4.645672
2018-12-07 22:27:00,752 - INFO - epoch 0, step 57600, training loss = 2.636308, validation loss = 4.145437
2018-12-07 22:27:16,765 - INFO - epoch 0, step 57650, training loss = 2.824049, validation loss = 3.928388
2018-12-07 22:27:37,729 - INFO - epoch 0, step 57700, training loss = 3.289154, validation loss = 4.073525
2018-12-07 22:27:57,249 - INFO - epoch 0, step 57750, training loss = 3.063048, validation loss = 4.088646
2018-12-07 22:28:16,344 - INFO - epoch 0, step 57800, training loss = 2.641347, validation loss = 4.043781
2018-12-07 22:28:36,042 - INFO - epoch 0, step 57850, training loss = 3.088956, validation loss = 4.107016
2018-12-07 22:28:57,191 - INFO - epoch 0, step 57900, training loss = 2.747625, validation loss = 4.329337
2018-12-07 22:29:18,050 - INFO - epoch 0, step 57950, training loss = 2.445027, validation loss = 4.021458
2018-12-07 22:29:38,903 - INFO - epoch 0, step 58000, training loss = 2.615716, validation loss = 3.835746
2018-12-07 22:29:59,773 - INFO - epoch 0, step 58050, training loss = 2.405137, validation loss = 4.338900
2018-12-07 22:30:19,355 - INFO - epoch 0, step 58100, training loss = 2.572056, validation loss = 4.227827
2018-12-07 22:30:36,740 - INFO - epoch 0, step 58150, training loss = 2.796206, validation loss = 4.878799
2018-12-07 22:30:52,339 - INFO - epoch 0, step 58200, training loss = 2.978230, validation loss = 4.537296
2018-12-07 22:31:11,784 - INFO - epoch 0, step 58250, training loss = 2.577730, validation loss = 4.108758
2018-12-07 22:31:32,532 - INFO - epoch 0, step 58300, training loss = 2.135929, validation loss = 4.068188
2018-12-07 22:31:53,218 - INFO - epoch 0, step 58350, training loss = 2.727953, validation loss = 4.081610
2018-12-07 22:32:13,759 - INFO - epoch 0, step 58400, training loss = 2.988724, validation loss = 4.183150
2018-12-07 22:32:31,943 - INFO - epoch 0, step 58450, training loss = 2.519243, validation loss = 4.697233
2018-12-07 22:32:50,520 - INFO - epoch 0, step 58500, training loss = 2.979128, validation loss = 4.553329
2018-12-07 22:33:08,981 - INFO - epoch 0, step 58550, training loss = 2.747270, validation loss = 4.300526
2018-12-07 22:33:29,451 - INFO - epoch 0, step 58600, training loss = 2.655476, validation loss = 4.631512
2018-12-07 22:33:47,483 - INFO - epoch 0, step 58650, training loss = 2.902584, validation loss = 4.709630
2018-12-07 22:34:03,993 - INFO - epoch 0, step 58700, training loss = 2.946494, validation loss = 4.991151
2018-12-07 22:34:24,392 - INFO - epoch 0, step 58750, training loss = 2.211909, validation loss = 4.386301
2018-12-07 22:34:45,792 - INFO - epoch 0, step 58800, training loss = 2.433667, validation loss = 4.120022
2018-12-07 22:35:05,791 - INFO - epoch 0, step 58850, training loss = 2.439930, validation loss = 4.541497
2018-12-07 22:35:26,715 - INFO - epoch 0, step 58900, training loss = 2.737601, validation loss = 4.248189
2018-12-07 22:35:45,831 - INFO - epoch 0, step 58950, training loss = 2.608727, validation loss = 4.471323
2018-12-07 22:36:02,582 - INFO - epoch 0, step 59000, training loss = 2.851754, validation loss = 4.257501
2018-12-07 22:36:22,388 - INFO - epoch 0, step 59050, training loss = 2.822846, validation loss = 3.746719
2018-12-07 22:36:41,389 - INFO - epoch 0, step 59100, training loss = 2.521362, validation loss = 4.214322
2018-12-07 22:36:59,129 - INFO - epoch 0, step 59150, training loss = 2.210160, validation loss = 4.446453
2018-12-07 22:37:17,680 - INFO - epoch 0, step 59200, training loss = 2.275471, validation loss = 4.376555
2018-12-07 22:37:38,426 - INFO - epoch 0, step 59250, training loss = 2.050502, validation loss = 4.027792
2018-12-07 22:37:59,755 - INFO - epoch 0, step 59300, training loss = 2.515169, validation loss = 4.519373
2018-12-07 22:38:21,743 - INFO - epoch 0, step 59350, training loss = 2.486275, validation loss = 4.604458
2018-12-07 22:38:38,840 - INFO - epoch 0, step 59400, training loss = 2.772770, validation loss = 4.043406
2018-12-07 22:38:50,177 - INFO - Model saved in dir ./models
2018-12-07 22:39:08,037 - INFO - epoch 1, step 50, training loss = 3.921253, validation loss = 3.908920
2018-12-07 22:39:26,146 - INFO - epoch 1, step 100, training loss = 3.142260, validation loss = 4.296052
2018-12-07 22:39:44,638 - INFO - epoch 1, step 150, training loss = 3.649482, validation loss = 4.169747
2018-12-07 22:40:05,010 - INFO - epoch 1, step 200, training loss = 3.336653, validation loss = 4.271980
2018-12-07 22:40:25,248 - INFO - epoch 1, step 250, training loss = 3.244614, validation loss = 4.680944
2018-12-07 22:40:45,419 - INFO - epoch 1, step 300, training loss = 3.373770, validation loss = 4.168115
2018-12-07 22:41:04,491 - INFO - epoch 1, step 350, training loss = 3.444741, validation loss = 3.922863
2018-12-07 22:41:23,824 - INFO - epoch 1, step 400, training loss = 3.088576, validation loss = 3.996068
2018-12-07 22:41:43,629 - INFO - epoch 1, step 450, training loss = 3.803139, validation loss = 4.362226
2018-12-07 22:42:03,975 - INFO - epoch 1, step 500, training loss = 3.799661, validation loss = 4.257466
2018-12-07 22:42:24,048 - INFO - epoch 1, step 550, training loss = 3.506939, validation loss = 4.359333
2018-12-07 22:42:43,812 - INFO - epoch 1, step 600, training loss = 3.216722, validation loss = 4.352418
2018-12-07 22:43:03,881 - INFO - epoch 1, step 650, training loss = 3.450241, validation loss = 4.236650
2018-12-07 22:43:23,626 - INFO - epoch 1, step 700, training loss = 3.287150, validation loss = 4.188117
2018-12-07 22:43:43,692 - INFO - epoch 1, step 750, training loss = 3.640402, validation loss = 4.300044
2018-12-07 22:44:04,655 - INFO - epoch 1, step 800, training loss = 3.774122, validation loss = 3.812547
2018-12-07 22:44:26,324 - INFO - epoch 1, step 850, training loss = 3.406622, validation loss = 4.147879
2018-12-07 22:44:47,162 - INFO - epoch 1, step 900, training loss = 4.026632, validation loss = 4.206915
2018-12-07 22:45:09,100 - INFO - epoch 1, step 950, training loss = 2.876357, validation loss = 4.341064
2018-12-07 22:45:30,319 - INFO - epoch 1, step 1000, training loss = 3.430715, validation loss = 4.686312
2018-12-07 22:45:51,025 - INFO - epoch 1, step 1050, training loss = 3.196028, validation loss = 4.021562
2018-12-07 22:46:11,346 - INFO - epoch 1, step 1100, training loss = 3.122352, validation loss = 4.284966
2018-12-07 22:46:31,950 - INFO - epoch 1, step 1150, training loss = 3.276825, validation loss = 4.137555
2018-12-07 22:46:52,275 - INFO - epoch 1, step 1200, training loss = 3.681323, validation loss = 4.178754
2018-12-07 22:47:12,821 - INFO - epoch 1, step 1250, training loss = 3.103884, validation loss = 4.220027
2018-12-07 22:47:33,053 - INFO - epoch 1, step 1300, training loss = 3.722136, validation loss = 4.195327
2018-12-07 22:47:51,303 - INFO - epoch 1, step 1350, training loss = 3.582168, validation loss = 4.214052
2018-12-07 22:48:09,606 - INFO - epoch 1, step 1400, training loss = 3.041996, validation loss = 4.670636
2018-12-07 22:48:28,660 - INFO - epoch 1, step 1450, training loss = 3.248908, validation loss = 4.237551
2018-12-07 22:48:49,912 - INFO - epoch 1, step 1500, training loss = 2.895082, validation loss = 3.953986
2018-12-07 22:49:09,140 - INFO - epoch 1, step 1550, training loss = 3.496138, validation loss = 4.086561
2018-12-07 22:49:28,022 - INFO - epoch 1, step 1600, training loss = 3.617064, validation loss = 4.503563
2018-12-07 22:49:46,542 - INFO - epoch 1, step 1650, training loss = 3.493163, validation loss = 4.045514
2018-12-07 22:50:07,521 - INFO - epoch 1, step 1700, training loss = 3.539780, validation loss = 4.517809
2018-12-07 22:50:24,882 - INFO - epoch 1, step 1750, training loss = 3.352023, validation loss = 4.106695
2018-12-07 22:50:41,853 - INFO - epoch 1, step 1800, training loss = 3.395692, validation loss = 4.229073
2018-12-07 22:50:59,347 - INFO - epoch 1, step 1850, training loss = 3.252847, validation loss = 4.340318
2018-12-07 22:51:20,476 - INFO - epoch 1, step 1900, training loss = 3.423493, validation loss = 4.189097
2018-12-07 22:51:41,847 - INFO - epoch 1, step 1950, training loss = 3.582273, validation loss = 3.608073
2018-12-07 22:51:58,810 - INFO - epoch 1, step 2000, training loss = 3.372478, validation loss = 3.946371
2018-12-07 22:52:15,495 - INFO - epoch 1, step 2050, training loss = 3.124138, validation loss = 4.520917
2018-12-07 22:52:32,588 - INFO - epoch 1, step 2100, training loss = 3.422799, validation loss = 4.405015
2018-12-07 22:52:49,468 - INFO - epoch 1, step 2150, training loss = 2.477588, validation loss = 3.487886
2018-12-07 22:53:06,698 - INFO - epoch 1, step 2200, training loss = 3.538445, validation loss = 4.560832
2018-12-07 22:53:24,961 - INFO - epoch 1, step 2250, training loss = 3.080630, validation loss = 4.308674
2018-12-07 22:53:44,116 - INFO - epoch 1, step 2300, training loss = 3.142014, validation loss = 4.522725
2018-12-07 22:54:04,420 - INFO - epoch 1, step 2350, training loss = 3.177732, validation loss = 4.187907
2018-12-07 22:54:24,731 - INFO - epoch 1, step 2400, training loss = 3.158272, validation loss = 4.487461
2018-12-07 22:54:44,146 - INFO - epoch 1, step 2450, training loss = 3.023026, validation loss = 4.203141
2018-12-07 22:55:02,405 - INFO - epoch 1, step 2500, training loss = 3.576845, validation loss = 3.759707
2018-12-07 22:55:20,028 - INFO - epoch 1, step 2550, training loss = 2.955076, validation loss = 3.683595
2018-12-07 22:55:38,014 - INFO - epoch 1, step 2600, training loss = 3.057740, validation loss = 3.986229
2018-12-07 22:55:56,336 - INFO - epoch 1, step 2650, training loss = 3.045224, validation loss = 4.234002
2018-12-07 22:56:17,278 - INFO - epoch 1, step 2700, training loss = 3.799855, validation loss = 3.777126
2018-12-07 22:56:38,145 - INFO - epoch 1, step 2750, training loss = 3.122314, validation loss = 4.292660
2018-12-07 22:56:59,039 - INFO - epoch 1, step 2800, training loss = 3.583769, validation loss = 4.256695
2018-12-07 22:57:17,753 - INFO - epoch 1, step 2850, training loss = 3.346415, validation loss = 4.355767
2018-12-07 22:57:35,907 - INFO - epoch 1, step 2900, training loss = 3.168870, validation loss = 4.606214
2018-12-07 22:57:54,856 - INFO - epoch 1, step 2950, training loss = 3.158845, validation loss = 4.009232
2018-12-07 22:58:16,573 - INFO - epoch 1, step 3000, training loss = 3.134622, validation loss = 4.167454
2018-12-07 22:58:37,729 - INFO - epoch 1, step 3050, training loss = 3.322839, validation loss = 4.386731
2018-12-07 22:58:58,557 - INFO - epoch 1, step 3100, training loss = 3.259006, validation loss = 3.826571
2018-12-07 22:59:19,340 - INFO - epoch 1, step 3150, training loss = 3.205997, validation loss = 4.112770
2018-12-07 22:59:39,968 - INFO - epoch 1, step 3200, training loss = 3.503789, validation loss = 4.101546
2018-12-07 23:00:01,411 - INFO - epoch 1, step 3250, training loss = 3.458061, validation loss = 4.333369
2018-12-07 23:00:21,138 - INFO - epoch 1, step 3300, training loss = 3.473131, validation loss = 4.254022
2018-12-07 23:00:39,992 - INFO - epoch 1, step 3350, training loss = 3.069042, validation loss = 4.798971
2018-12-07 23:00:59,112 - INFO - epoch 1, step 3400, training loss = 3.679159, validation loss = 4.404173
2018-12-07 23:01:19,054 - INFO - epoch 1, step 3450, training loss = 3.256012, validation loss = 4.269132
2018-12-07 23:01:38,987 - INFO - epoch 1, step 3500, training loss = 3.153219, validation loss = 4.480072
2018-12-07 23:01:57,611 - INFO - epoch 1, step 3550, training loss = 3.156860, validation loss = 4.504765
2018-12-07 23:02:16,199 - INFO - epoch 1, step 3600, training loss = 3.410365, validation loss = 4.252231
2018-12-07 23:02:34,970 - INFO - epoch 1, step 3650, training loss = 3.741020, validation loss = 4.264453
2018-12-07 23:02:54,146 - INFO - epoch 1, step 3700, training loss = 3.183885, validation loss = 4.127572
2018-12-07 23:03:12,078 - INFO - epoch 1, step 3750, training loss = 3.362409, validation loss = 4.080662
2018-12-07 23:03:28,727 - INFO - epoch 1, step 3800, training loss = 2.341897, validation loss = 4.437850
2018-12-07 23:03:45,610 - INFO - epoch 1, step 3850, training loss = 2.963088, validation loss = 4.597968
2018-12-07 23:04:06,161 - INFO - epoch 1, step 3900, training loss = 3.023765, validation loss = 4.075755
2018-12-07 23:04:31,796 - INFO - epoch 1, step 3950, training loss = 3.311030, validation loss = 4.043303
2018-12-07 23:04:54,408 - INFO - epoch 1, step 4000, training loss = 3.162461, validation loss = 4.505292
2018-12-07 23:05:12,535 - INFO - epoch 1, step 4050, training loss = 3.051918, validation loss = 4.561535
2018-12-07 23:05:30,133 - INFO - epoch 1, step 4100, training loss = 3.102092, validation loss = 4.077513
2018-12-07 23:05:48,290 - INFO - epoch 1, step 4150, training loss = 3.261385, validation loss = 3.768826
2018-12-07 23:06:06,019 - INFO - epoch 1, step 4200, training loss = 3.296597, validation loss = 4.252759
2018-12-07 23:06:24,686 - INFO - epoch 1, step 4250, training loss = 3.446946, validation loss = 4.155109
2018-12-07 23:06:43,338 - INFO - epoch 1, step 4300, training loss = 3.461714, validation loss = 4.301890
2018-12-07 23:07:01,804 - INFO - epoch 1, step 4350, training loss = 3.500745, validation loss = 4.355856
2018-12-07 23:07:19,979 - INFO - epoch 1, step 4400, training loss = 3.975578, validation loss = 4.152075
2018-12-07 23:07:38,579 - INFO - epoch 1, step 4450, training loss = 3.705639, validation loss = 4.234176
2018-12-07 23:07:56,588 - INFO - epoch 1, step 4500, training loss = 3.163159, validation loss = 4.343139
2018-12-07 23:08:14,782 - INFO - epoch 1, step 4550, training loss = 2.942869, validation loss = 4.373382
2018-12-07 23:08:32,564 - INFO - epoch 1, step 4600, training loss = 3.119339, validation loss = 4.577433
2018-12-07 23:08:50,639 - INFO - epoch 1, step 4650, training loss = 3.220969, validation loss = 4.101411
2018-12-07 23:09:11,873 - INFO - epoch 1, step 4700, training loss = 3.560265, validation loss = 4.402829
2018-12-07 23:09:32,730 - INFO - epoch 1, step 4750, training loss = 3.447985, validation loss = 4.162826
2018-12-07 23:09:53,061 - INFO - epoch 1, step 4800, training loss = 3.039638, validation loss = 4.141346
2018-12-07 23:10:12,382 - INFO - epoch 1, step 4850, training loss = 3.085853, validation loss = 4.420908
2018-12-07 23:10:30,892 - INFO - epoch 1, step 4900, training loss = 3.609736, validation loss = 4.448992
2018-12-07 23:10:47,499 - INFO - epoch 1, step 4950, training loss = 3.075876, validation loss = 3.918489
2018-12-07 23:11:04,742 - INFO - epoch 1, step 5000, training loss = 3.469336, validation loss = 4.361940
2018-12-07 23:11:25,846 - INFO - epoch 1, step 5050, training loss = 2.955588, validation loss = 4.386930
2018-12-07 23:11:46,828 - INFO - epoch 1, step 5100, training loss = 2.806326, validation loss = 4.768251
2018-12-07 23:12:05,955 - INFO - epoch 1, step 5150, training loss = 3.232146, validation loss = 4.284932
2018-12-07 23:12:24,062 - INFO - epoch 1, step 5200, training loss = 2.721211, validation loss = 4.234874
2018-12-07 23:12:44,444 - INFO - epoch 1, step 5250, training loss = 3.452466, validation loss = 4.222727
2018-12-07 23:13:04,952 - INFO - epoch 1, step 5300, training loss = 3.595601, validation loss = 3.964410
2018-12-07 23:13:24,068 - INFO - epoch 1, step 5350, training loss = 2.963256, validation loss = 3.970593
2018-12-07 23:13:43,281 - INFO - epoch 1, step 5400, training loss = 3.272233, validation loss = 4.027928
2018-12-07 23:14:02,146 - INFO - epoch 1, step 5450, training loss = 3.136187, validation loss = 3.915521
2018-12-07 23:14:20,635 - INFO - epoch 1, step 5500, training loss = 3.536145, validation loss = 4.367035
2018-12-07 23:14:39,437 - INFO - epoch 1, step 5550, training loss = 3.268580, validation loss = 4.147141
2018-12-07 23:14:58,998 - INFO - epoch 1, step 5600, training loss = 3.265638, validation loss = 4.586486
2018-12-07 23:15:19,468 - INFO - epoch 1, step 5650, training loss = 3.309576, validation loss = 3.977345
2018-12-07 23:15:40,496 - INFO - epoch 1, step 5700, training loss = 3.596178, validation loss = 4.178903
2018-12-07 23:16:01,332 - INFO - epoch 1, step 5750, training loss = 3.332054, validation loss = 4.297068
2018-12-07 23:16:22,662 - INFO - epoch 1, step 5800, training loss = 3.129926, validation loss = 4.078332
2018-12-07 23:16:43,443 - INFO - epoch 1, step 5850, training loss = 3.213502, validation loss = 3.852422
2018-12-07 23:17:00,124 - INFO - epoch 1, step 5900, training loss = 3.078545, validation loss = 3.996491
2018-12-07 23:17:16,737 - INFO - epoch 1, step 5950, training loss = 2.789199, validation loss = 3.869136
2018-12-07 23:17:37,113 - INFO - epoch 1, step 6000, training loss = 3.243550, validation loss = 4.030666
2018-12-07 23:17:58,200 - INFO - epoch 1, step 6050, training loss = 3.104347, validation loss = 4.316449
2018-12-07 23:18:19,033 - INFO - epoch 1, step 6100, training loss = 3.110637, validation loss = 4.748004
2018-12-07 23:18:40,594 - INFO - epoch 1, step 6150, training loss = 3.332416, validation loss = 4.191475
2018-12-07 23:19:01,582 - INFO - epoch 1, step 6200, training loss = 3.514386, validation loss = 4.525176
2018-12-07 23:19:22,521 - INFO - epoch 1, step 6250, training loss = 3.121387, validation loss = 4.250392
2018-12-07 23:19:42,187 - INFO - epoch 1, step 6300, training loss = 3.580533, validation loss = 4.870325
2018-12-07 23:20:00,832 - INFO - epoch 1, step 6350, training loss = 3.194479, validation loss = 4.541376
2018-12-07 23:20:19,393 - INFO - epoch 1, step 6400, training loss = 3.184969, validation loss = 3.859099
2018-12-07 23:20:38,107 - INFO - epoch 1, step 6450, training loss = 2.906973, validation loss = 4.056377
2018-12-07 23:20:56,407 - INFO - epoch 1, step 6500, training loss = 2.717684, validation loss = 4.437078
2018-12-07 23:21:14,474 - INFO - epoch 1, step 6550, training loss = 3.195579, validation loss = 4.192714
2018-12-07 23:21:32,145 - INFO - epoch 1, step 6600, training loss = 3.267362, validation loss = 4.695126
2018-12-07 23:21:50,775 - INFO - epoch 1, step 6650, training loss = 3.414817, validation loss = 4.053975
2018-12-07 23:22:10,079 - INFO - epoch 1, step 6700, training loss = 3.466606, validation loss = 4.446443
2018-12-07 23:22:28,932 - INFO - epoch 1, step 6750, training loss = 3.174573, validation loss = 4.221386
2018-12-07 23:22:47,035 - INFO - epoch 1, step 6800, training loss = 3.161714, validation loss = 4.309204
2018-12-07 23:23:05,103 - INFO - epoch 1, step 6850, training loss = 2.994886, validation loss = 4.348791
2018-12-07 23:23:22,865 - INFO - epoch 1, step 6900, training loss = 2.689988, validation loss = 4.121287
2018-12-07 23:23:42,174 - INFO - epoch 1, step 6950, training loss = 3.210369, validation loss = 4.364553
2018-12-07 23:24:02,684 - INFO - epoch 1, step 7000, training loss = 3.451615, validation loss = 4.570085
2018-12-07 23:24:24,174 - INFO - epoch 1, step 7050, training loss = 3.227615, validation loss = 3.944108
2018-12-07 23:24:44,640 - INFO - epoch 1, step 7100, training loss = 3.139564, validation loss = 3.926053
2018-12-07 23:25:05,641 - INFO - epoch 1, step 7150, training loss = 2.980539, validation loss = 4.052830
2018-12-07 23:25:25,847 - INFO - epoch 1, step 7200, training loss = 3.191683, validation loss = 4.508596
2018-12-07 23:25:45,353 - INFO - epoch 1, step 7250, training loss = 3.117659, validation loss = 3.968517
2018-12-07 23:26:03,524 - INFO - epoch 1, step 7300, training loss = 2.972837, validation loss = 4.203750
2018-12-07 23:26:21,979 - INFO - epoch 1, step 7350, training loss = 3.389476, validation loss = 4.184419
2018-12-07 23:26:39,897 - INFO - epoch 1, step 7400, training loss = 3.129360, validation loss = 4.051643
2018-12-07 23:26:56,752 - INFO - epoch 1, step 7450, training loss = 3.336750, validation loss = 4.559342
2018-12-07 23:27:13,075 - INFO - epoch 1, step 7500, training loss = 2.272625, validation loss = 4.486686
2018-12-07 23:27:29,600 - INFO - epoch 1, step 7550, training loss = 2.811874, validation loss = 4.353352
2018-12-07 23:27:47,435 - INFO - epoch 1, step 7600, training loss = 2.938154, validation loss = 4.236023
2018-12-07 23:28:05,678 - INFO - epoch 1, step 7650, training loss = 2.874218, validation loss = 4.644581
2018-12-07 23:28:23,865 - INFO - epoch 1, step 7700, training loss = 2.835924, validation loss = 4.708979
2018-12-07 23:28:42,114 - INFO - epoch 1, step 7750, training loss = 2.837132, validation loss = 3.971317
2018-12-07 23:29:00,614 - INFO - epoch 1, step 7800, training loss = 3.395255, validation loss = 4.201906
2018-12-07 23:29:19,901 - INFO - epoch 1, step 7850, training loss = 3.439785, validation loss = 4.145079
2018-12-07 23:29:39,191 - INFO - epoch 1, step 7900, training loss = 2.949207, validation loss = 4.256523
2018-12-07 23:29:58,804 - INFO - epoch 1, step 7950, training loss = 2.784809, validation loss = 4.077466
2018-12-07 23:30:19,255 - INFO - epoch 1, step 8000, training loss = 3.171569, validation loss = 4.034945
2018-12-07 23:30:40,299 - INFO - epoch 1, step 8050, training loss = 3.005987, validation loss = 3.969959
2018-12-07 23:31:01,316 - INFO - epoch 1, step 8100, training loss = 3.044436, validation loss = 4.160038
2018-12-07 23:31:22,636 - INFO - epoch 1, step 8150, training loss = 3.693722, validation loss = 4.532116
2018-12-07 23:31:43,957 - INFO - epoch 1, step 8200, training loss = 3.208233, validation loss = 4.271127
2018-12-07 23:32:04,382 - INFO - epoch 1, step 8250, training loss = 2.950273, validation loss = 3.913717
2018-12-07 23:32:23,074 - INFO - epoch 1, step 8300, training loss = 3.059146, validation loss = 3.875540
2018-12-07 23:32:39,900 - INFO - epoch 1, step 8350, training loss = 2.959992, validation loss = 4.220509
2018-12-07 23:32:56,615 - INFO - epoch 1, step 8400, training loss = 2.962700, validation loss = 4.356503
2018-12-07 23:33:16,369 - INFO - epoch 1, step 8450, training loss = 3.105686, validation loss = 4.378331
2018-12-07 23:33:36,516 - INFO - epoch 1, step 8500, training loss = 2.756219, validation loss = 3.986341
2018-12-07 23:33:54,769 - INFO - epoch 1, step 8550, training loss = 3.215840, validation loss = 4.241654
2018-12-07 23:34:12,006 - INFO - epoch 1, step 8600, training loss = 2.486245, validation loss = 4.352407
2018-12-07 23:34:29,171 - INFO - epoch 1, step 8650, training loss = 2.828936, validation loss = 4.271441
2018-12-07 23:34:47,526 - INFO - epoch 1, step 8700, training loss = 3.339998, validation loss = 4.063082
2018-12-07 23:35:06,016 - INFO - epoch 1, step 8750, training loss = 3.612684, validation loss = 3.995236
2018-12-07 23:35:23,787 - INFO - epoch 1, step 8800, training loss = 2.823666, validation loss = 4.194929
2018-12-07 23:35:40,972 - INFO - epoch 1, step 8850, training loss = 2.893188, validation loss = 4.370965
2018-12-07 23:35:58,941 - INFO - epoch 1, step 8900, training loss = 3.457784, validation loss = 4.911364
2018-12-07 23:36:16,933 - INFO - epoch 1, step 8950, training loss = 3.556400, validation loss = 4.210655
2018-12-07 23:36:33,989 - INFO - epoch 1, step 9000, training loss = 3.130629, validation loss = 4.393410
2018-12-07 23:36:51,117 - INFO - epoch 1, step 9050, training loss = 3.481095, validation loss = 4.445001
2018-12-07 23:37:09,339 - INFO - epoch 1, step 9100, training loss = 3.107097, validation loss = 4.401766
2018-12-07 23:37:28,320 - INFO - epoch 1, step 9150, training loss = 2.813321, validation loss = 4.912824
2018-12-07 23:37:44,835 - INFO - epoch 1, step 9200, training loss = 2.393019, validation loss = 4.163352
2018-12-07 23:38:01,724 - INFO - epoch 1, step 9250, training loss = 2.245583, validation loss = 4.338540
2018-12-07 23:38:19,366 - INFO - epoch 1, step 9300, training loss = 2.913559, validation loss = 4.475884
2018-12-07 23:38:37,368 - INFO - epoch 1, step 9350, training loss = 3.188977, validation loss = 4.407802
2018-12-07 23:38:57,299 - INFO - epoch 1, step 9400, training loss = 3.227760, validation loss = 4.392738
2018-12-07 23:39:17,997 - INFO - epoch 1, step 9450, training loss = 3.373358, validation loss = 3.653400
2018-12-07 23:39:36,801 - INFO - epoch 1, step 9500, training loss = 2.252452, validation loss = 3.551459
2018-12-07 23:39:53,638 - INFO - epoch 1, step 9550, training loss = 2.835549, validation loss = 4.067764
2018-12-07 23:40:10,584 - INFO - epoch 1, step 9600, training loss = 2.539305, validation loss = 4.323711
2018-12-07 23:40:28,638 - INFO - epoch 1, step 9650, training loss = 2.172849, validation loss = 4.345355
2018-12-07 23:40:46,876 - INFO - epoch 1, step 9700, training loss = 3.017143, validation loss = 4.512387
2018-12-07 23:41:08,838 - INFO - epoch 1, step 9750, training loss = 3.019194, validation loss = 4.241327
2018-12-07 23:41:30,728 - INFO - epoch 1, step 9800, training loss = 2.999476, validation loss = 3.521256
2018-12-07 23:41:51,175 - INFO - epoch 1, step 9850, training loss = 2.602704, validation loss = 3.648956
2018-12-07 23:42:09,114 - INFO - epoch 1, step 9900, training loss = 2.260265, validation loss = 3.662505
2018-12-07 23:42:27,514 - INFO - epoch 1, step 9950, training loss = 2.805778, validation loss = 3.937736
2018-12-07 23:42:45,561 - INFO - epoch 1, step 10000, training loss = 3.115748, validation loss = 4.014723
2018-12-07 23:43:03,272 - INFO - epoch 1, step 10050, training loss = 2.885194, validation loss = 4.406801
2018-12-07 23:43:20,381 - INFO - epoch 1, step 10100, training loss = 3.109159, validation loss = 4.429428
2018-12-07 23:43:37,257 - INFO - epoch 1, step 10150, training loss = 2.766979, validation loss = 4.127813
2018-12-07 23:43:55,944 - INFO - epoch 1, step 10200, training loss = 3.196225, validation loss = 3.821244
2018-12-07 23:44:14,073 - INFO - epoch 1, step 10250, training loss = 3.228822, validation loss = 3.713398
2018-12-07 23:44:31,333 - INFO - epoch 1, step 10300, training loss = 2.969961, validation loss = 4.539689
2018-12-07 23:44:49,982 - INFO - epoch 1, step 10350, training loss = 3.210818, validation loss = 4.677979
2018-12-07 23:45:10,889 - INFO - epoch 1, step 10400, training loss = 3.750587, validation loss = 4.835492
2018-12-07 23:45:33,010 - INFO - epoch 1, step 10450, training loss = 2.990235, validation loss = 4.779328
2018-12-07 23:45:53,413 - INFO - epoch 1, step 10500, training loss = 3.367982, validation loss = 4.170513
2018-12-07 23:46:13,428 - INFO - epoch 1, step 10550, training loss = 3.278123, validation loss = 4.285386
2018-12-07 23:46:32,383 - INFO - epoch 1, step 10600, training loss = 2.828557, validation loss = 3.923762
2018-12-07 23:46:51,100 - INFO - epoch 1, step 10650, training loss = 3.355092, validation loss = 4.207879
2018-12-07 23:47:09,601 - INFO - epoch 1, step 10700, training loss = 3.643408, validation loss = 4.511220
2018-12-07 23:47:28,520 - INFO - epoch 1, step 10750, training loss = 2.957367, validation loss = 4.384058
2018-12-07 23:47:47,519 - INFO - epoch 1, step 10800, training loss = 3.193997, validation loss = 4.654529
2018-12-07 23:48:06,230 - INFO - epoch 1, step 10850, training loss = 3.020714, validation loss = 4.378508
2018-12-07 23:48:24,351 - INFO - epoch 1, step 10900, training loss = 3.175771, validation loss = 4.644603
2018-12-07 23:48:41,110 - INFO - epoch 1, step 10950, training loss = 2.564933, validation loss = 4.689515
2018-12-07 23:48:57,956 - INFO - epoch 1, step 11000, training loss = 3.199365, validation loss = 3.852126
2018-12-07 23:49:15,859 - INFO - epoch 1, step 11050, training loss = 3.097761, validation loss = 4.329908
2018-12-07 23:49:35,290 - INFO - epoch 1, step 11100, training loss = 3.188602, validation loss = 4.017903
2018-12-07 23:49:53,696 - INFO - epoch 1, step 11150, training loss = 2.469304, validation loss = 3.877675
2018-12-07 23:50:12,115 - INFO - epoch 1, step 11200, training loss = 3.131228, validation loss = 4.171814
2018-12-07 23:50:30,232 - INFO - epoch 1, step 11250, training loss = 2.786377, validation loss = 4.358355
2018-12-07 23:50:47,273 - INFO - epoch 1, step 11300, training loss = 2.895331, validation loss = 4.094535
2018-12-07 23:51:05,270 - INFO - epoch 1, step 11350, training loss = 2.829096, validation loss = 4.446857
2018-12-07 23:51:23,313 - INFO - epoch 1, step 11400, training loss = 3.355107, validation loss = 4.598077
2018-12-07 23:51:41,304 - INFO - epoch 1, step 11450, training loss = 3.085622, validation loss = 4.464673
2018-12-07 23:52:01,234 - INFO - epoch 1, step 11500, training loss = 3.718440, validation loss = 4.072909
2018-12-07 23:52:20,711 - INFO - epoch 1, step 11550, training loss = 2.503643, validation loss = 3.896574
2018-12-07 23:52:41,501 - INFO - epoch 1, step 11600, training loss = 3.227751, validation loss = 4.067212
2018-12-07 23:53:01,904 - INFO - epoch 1, step 11650, training loss = 2.560518, validation loss = 4.194022
2018-12-07 23:53:19,898 - INFO - epoch 1, step 11700, training loss = 2.950399, validation loss = 4.496549
2018-12-07 23:53:37,946 - INFO - epoch 1, step 11750, training loss = 2.646585, validation loss = 4.464752
2018-12-07 23:53:57,130 - INFO - epoch 1, step 11800, training loss = 3.273704, validation loss = 4.619625
2018-12-07 23:54:17,327 - INFO - epoch 1, step 11850, training loss = 2.878770, validation loss = 4.273846
2018-12-07 23:54:37,231 - INFO - epoch 1, step 11900, training loss = 3.085027, validation loss = 4.024092
2018-12-07 23:54:55,885 - INFO - epoch 1, step 11950, training loss = 2.256113, validation loss = 4.170418
2018-12-07 23:55:13,933 - INFO - epoch 1, step 12000, training loss = 2.816870, validation loss = 4.173856
2018-12-07 23:55:32,291 - INFO - epoch 1, step 12050, training loss = 3.276094, validation loss = 4.502915
2018-12-07 23:55:53,404 - INFO - epoch 1, step 12100, training loss = 3.459314, validation loss = 4.227370
2018-12-07 23:56:14,230 - INFO - epoch 1, step 12150, training loss = 3.172917, validation loss = 4.661752
2018-12-07 23:56:35,264 - INFO - epoch 1, step 12200, training loss = 2.818955, validation loss = 4.878721
2018-12-07 23:56:56,402 - INFO - epoch 1, step 12250, training loss = 3.066403, validation loss = 3.265529
2018-12-07 23:57:17,119 - INFO - epoch 1, step 12300, training loss = 3.648513, validation loss = 3.884767
2018-12-07 23:57:35,799 - INFO - epoch 1, step 12350, training loss = 3.482288, validation loss = 3.752312
2018-12-07 23:57:53,891 - INFO - epoch 1, step 12400, training loss = 3.079364, validation loss = 4.224552
2018-12-07 23:58:14,301 - INFO - epoch 1, step 12450, training loss = 2.823420, validation loss = 3.802721
2018-12-07 23:58:34,301 - INFO - epoch 1, step 12500, training loss = 2.732822, validation loss = 4.160833
2018-12-07 23:58:54,160 - INFO - epoch 1, step 12550, training loss = 3.052595, validation loss = 4.248634
2018-12-07 23:59:12,744 - INFO - epoch 1, step 12600, training loss = 2.834412, validation loss = 4.297831
2018-12-07 23:59:31,450 - INFO - epoch 1, step 12650, training loss = 3.101261, validation loss = 4.146924
2018-12-07 23:59:49,325 - INFO - epoch 1, step 12700, training loss = 3.524181, validation loss = 4.024434
2018-12-08 00:00:06,168 - INFO - epoch 1, step 12750, training loss = 3.285786, validation loss = 3.943494
2018-12-08 00:00:23,694 - INFO - epoch 1, step 12800, training loss = 3.475812, validation loss = 4.188251
2018-12-08 00:00:43,347 - INFO - epoch 1, step 12850, training loss = 3.093707, validation loss = 4.230402
2018-12-08 00:01:02,264 - INFO - epoch 1, step 12900, training loss = 3.131161, validation loss = 4.058221
2018-12-08 00:01:19,311 - INFO - epoch 1, step 12950, training loss = 3.448557, validation loss = 4.174037
2018-12-08 00:01:35,986 - INFO - epoch 1, step 13000, training loss = 3.412626, validation loss = 4.009279
2018-12-08 00:01:52,749 - INFO - epoch 1, step 13050, training loss = 3.170901, validation loss = 4.275750
2018-12-08 00:02:12,982 - INFO - epoch 1, step 13100, training loss = 3.173400, validation loss = 3.768389
2018-12-08 00:02:33,118 - INFO - epoch 1, step 13150, training loss = 2.913651, validation loss = 4.640987
2018-12-08 00:02:52,488 - INFO - epoch 1, step 13200, training loss = 3.075107, validation loss = 4.148809
2018-12-08 00:03:09,260 - INFO - epoch 1, step 13250, training loss = 2.897074, validation loss = 3.811402
2018-12-08 00:03:26,601 - INFO - epoch 1, step 13300, training loss = 2.808074, validation loss = 4.473575
2018-12-08 00:03:44,082 - INFO - epoch 1, step 13350, training loss = 2.552180, validation loss = 4.459236
2018-12-08 00:04:02,248 - INFO - epoch 1, step 13400, training loss = 2.752161, validation loss = 3.882800
2018-12-08 00:04:19,910 - INFO - epoch 1, step 13450, training loss = 2.818197, validation loss = 4.035542
2018-12-08 00:04:39,980 - INFO - epoch 1, step 13500, training loss = 3.386533, validation loss = 3.890958
2018-12-08 00:05:01,063 - INFO - epoch 1, step 13550, training loss = 3.314685, validation loss = 4.200281
2018-12-08 00:05:22,385 - INFO - epoch 1, step 13600, training loss = 3.429338, validation loss = 4.359810
2018-12-08 00:05:39,795 - INFO - epoch 1, step 13650, training loss = 2.764507, validation loss = 4.803912
2018-12-08 00:05:58,051 - INFO - epoch 1, step 13700, training loss = 2.373917, validation loss = 3.721165
2018-12-08 00:06:17,724 - INFO - epoch 1, step 13750, training loss = 2.972836, validation loss = 4.108034
2018-12-08 00:06:38,387 - INFO - epoch 1, step 13800, training loss = 2.933710, validation loss = 4.200793
2018-12-08 00:06:56,713 - INFO - epoch 1, step 13850, training loss = 2.766703, validation loss = 4.259516
2018-12-08 00:07:16,553 - INFO - epoch 1, step 13900, training loss = 2.705564, validation loss = 4.330699
2018-12-08 00:07:37,503 - INFO - epoch 1, step 13950, training loss = 3.555927, validation loss = 4.085607
2018-12-08 00:07:58,892 - INFO - epoch 1, step 14000, training loss = 2.533465, validation loss = 4.301557
2018-12-08 00:08:18,855 - INFO - epoch 1, step 14050, training loss = 3.335206, validation loss = 4.507895
2018-12-08 00:08:36,812 - INFO - epoch 1, step 14100, training loss = 3.375240, validation loss = 4.044163
2018-12-08 00:08:55,943 - INFO - epoch 1, step 14150, training loss = 3.466035, validation loss = 3.954667
2018-12-08 00:09:14,780 - INFO - epoch 1, step 14200, training loss = 3.235715, validation loss = 4.070748
2018-12-08 00:09:35,051 - INFO - epoch 1, step 14250, training loss = 2.827210, validation loss = 4.286079
2018-12-08 00:09:56,117 - INFO - epoch 1, step 14300, training loss = 3.256868, validation loss = 4.024151
2018-12-08 00:10:16,539 - INFO - epoch 1, step 14350, training loss = 3.667082, validation loss = 4.482072
2018-12-08 00:10:32,172 - INFO - epoch 1, step 14400, training loss = 3.836826, validation loss = 4.245942
2018-12-08 00:10:47,915 - INFO - epoch 1, step 14450, training loss = 3.303735, validation loss = 4.883898
2018-12-08 00:11:04,198 - INFO - epoch 1, step 14500, training loss = 3.418420, validation loss = 4.516718
2018-12-08 00:11:21,499 - INFO - epoch 1, step 14550, training loss = 3.901921, validation loss = 3.849682
2018-12-08 00:11:39,524 - INFO - epoch 1, step 14600, training loss = 3.446581, validation loss = 3.911802
2018-12-08 00:12:03,656 - INFO - epoch 1, step 14650, training loss = 4.026273, validation loss = 4.165946
2018-12-08 00:12:28,975 - INFO - epoch 1, step 14700, training loss = 2.978108, validation loss = 3.757407
2018-12-08 00:12:45,443 - INFO - epoch 1, step 14750, training loss = 3.150635, validation loss = 4.189741
2018-12-08 00:13:01,282 - INFO - epoch 1, step 14800, training loss = 2.980512, validation loss = 4.498411
2018-12-08 00:13:17,303 - INFO - epoch 1, step 14850, training loss = 3.043808, validation loss = 3.727377
2018-12-08 00:13:45,762 - INFO - epoch 1, step 14900, training loss = 3.556478, validation loss = 3.635215
2018-12-08 00:14:13,389 - INFO - epoch 1, step 14950, training loss = 3.858296, validation loss = 3.613436
2018-12-08 00:14:42,610 - INFO - epoch 1, step 15000, training loss = 3.661308, validation loss = 4.002932
2018-12-08 00:15:10,360 - INFO - epoch 1, step 15050, training loss = 3.978842, validation loss = 3.911189
2018-12-08 00:15:39,894 - INFO - epoch 1, step 15100, training loss = 3.608095, validation loss = 4.127337
2018-12-08 00:16:11,718 - INFO - epoch 1, step 15150, training loss = 3.810921, validation loss = 3.958847
2018-12-08 00:16:42,856 - INFO - epoch 1, step 15200, training loss = 4.108144, validation loss = 3.454614
2018-12-08 00:17:12,580 - INFO - epoch 1, step 15250, training loss = 3.958731, validation loss = 4.018203
2018-12-08 00:17:42,512 - INFO - epoch 1, step 15300, training loss = 3.012049, validation loss = 3.798084
2018-12-08 00:18:09,912 - INFO - epoch 1, step 15350, training loss = 3.540221, validation loss = 3.989722
2018-12-08 00:18:34,989 - INFO - epoch 1, step 15400, training loss = 4.081690, validation loss = 3.813219
2018-12-08 00:18:50,984 - INFO - epoch 1, step 15450, training loss = 3.845305, validation loss = 4.221466
2018-12-08 00:19:06,911 - INFO - epoch 1, step 15500, training loss = 3.605620, validation loss = 3.822383
2018-12-08 00:19:22,558 - INFO - epoch 1, step 15550, training loss = 3.049781, validation loss = 3.464771
2018-12-08 00:19:40,703 - INFO - epoch 1, step 15600, training loss = 3.813363, validation loss = 3.528145
2018-12-08 00:20:04,852 - INFO - epoch 1, step 15650, training loss = 3.473218, validation loss = 3.827092
2018-12-08 00:20:28,213 - INFO - epoch 1, step 15700, training loss = 3.891344, validation loss = 3.612350
2018-12-08 00:20:55,925 - INFO - epoch 1, step 15750, training loss = 3.849397, validation loss = 3.828813
2018-12-08 00:21:23,425 - INFO - epoch 1, step 15800, training loss = 4.111505, validation loss = 4.211430
2018-12-08 00:21:51,046 - INFO - epoch 1, step 15850, training loss = 3.643603, validation loss = 3.517509
2018-12-08 00:22:19,539 - INFO - epoch 1, step 15900, training loss = 3.343704, validation loss = 3.354861
2018-12-08 00:22:42,633 - INFO - epoch 1, step 15950, training loss = 3.351166, validation loss = 3.373017
2018-12-08 00:23:04,242 - INFO - epoch 1, step 16000, training loss = 3.899920, validation loss = 3.599824
2018-12-08 00:23:20,364 - INFO - epoch 1, step 16050, training loss = 3.803247, validation loss = 4.483495
2018-12-08 00:23:32,508 - INFO - epoch 1, step 16100, training loss = 3.227293, validation loss = 4.656083
2018-12-08 00:23:44,513 - INFO - epoch 1, step 16150, training loss = 3.456572, validation loss = 4.693143
2018-12-08 00:23:58,512 - INFO - epoch 1, step 16200, training loss = 4.142293, validation loss = 3.545224
2018-12-08 00:24:16,222 - INFO - epoch 1, step 16250, training loss = 3.718791, validation loss = 3.483899
2018-12-08 00:24:34,633 - INFO - epoch 1, step 16300, training loss = 3.817929, validation loss = 3.462532
2018-12-08 00:24:48,047 - INFO - epoch 1, step 16350, training loss = 3.523638, validation loss = 4.386480
2018-12-08 00:25:00,152 - INFO - epoch 1, step 16400, training loss = 3.378201, validation loss = 4.497463
2018-12-08 00:25:20,406 - INFO - epoch 1, step 16450, training loss = 3.468596, validation loss = 4.270152
2018-12-08 00:25:46,005 - INFO - epoch 1, step 16500, training loss = 4.025528, validation loss = 4.297390
2018-12-08 00:26:11,454 - INFO - epoch 1, step 16550, training loss = 3.953975, validation loss = 3.979078
2018-12-08 00:26:37,385 - INFO - epoch 1, step 16600, training loss = 4.082711, validation loss = 3.231214
2018-12-08 00:27:01,251 - INFO - epoch 1, step 16650, training loss = 4.159934, validation loss = 3.506814
2018-12-08 00:27:20,335 - INFO - epoch 1, step 16700, training loss = 3.545244, validation loss = 3.772640
2018-12-08 00:27:42,001 - INFO - epoch 1, step 16750, training loss = 3.807919, validation loss = 3.616669
2018-12-08 00:27:58,615 - INFO - epoch 1, step 16800, training loss = 3.727399, validation loss = 4.344586
2018-12-08 00:28:14,647 - INFO - epoch 1, step 16850, training loss = 3.496265, validation loss = 4.791128
2018-12-08 00:28:31,054 - INFO - epoch 1, step 16900, training loss = 3.888834, validation loss = 4.612437
2018-12-08 00:28:47,474 - INFO - epoch 1, step 16950, training loss = 4.108751, validation loss = 4.056912
2018-12-08 00:29:11,697 - INFO - epoch 1, step 17000, training loss = 3.827371, validation loss = 3.526118
2018-12-08 00:29:35,494 - INFO - epoch 1, step 17050, training loss = 3.774854, validation loss = 3.515047
2018-12-08 00:30:00,812 - INFO - epoch 1, step 17100, training loss = 3.359279, validation loss = 4.103313
2018-12-08 00:30:26,763 - INFO - epoch 1, step 17150, training loss = 3.209981, validation loss = 3.785662
2018-12-08 00:30:52,097 - INFO - epoch 1, step 17200, training loss = 3.136190, validation loss = 4.352770
2018-12-08 00:31:17,851 - INFO - epoch 1, step 17250, training loss = 3.415992, validation loss = 4.560434
2018-12-08 00:31:43,292 - INFO - epoch 1, step 17300, training loss = 2.750785, validation loss = 3.796788
2018-12-08 00:32:09,113 - INFO - epoch 1, step 17350, training loss = 4.101071, validation loss = 3.614172
2018-12-08 00:32:32,219 - INFO - epoch 1, step 17400, training loss = 3.616720, validation loss = 4.184621
2018-12-08 00:32:47,789 - INFO - epoch 1, step 17450, training loss = 4.536272, validation loss = 4.054442
2018-12-08 00:33:02,357 - INFO - epoch 1, step 17500, training loss = 3.996697, validation loss = 4.116764
2018-12-08 00:33:23,650 - INFO - epoch 1, step 17550, training loss = 4.374763, validation loss = 3.521646
2018-12-08 00:33:50,369 - INFO - epoch 1, step 17600, training loss = 3.810093, validation loss = 3.701130
2018-12-08 00:34:16,524 - INFO - epoch 1, step 17650, training loss = 3.870894, validation loss = 3.667237
2018-12-08 00:34:43,009 - INFO - epoch 1, step 17700, training loss = 3.590590, validation loss = 3.811117
2018-12-08 00:35:10,216 - INFO - epoch 1, step 17750, training loss = 3.713433, validation loss = 3.926867
2018-12-08 00:35:31,976 - INFO - epoch 1, step 17800, training loss = 3.829765, validation loss = 4.060634
2018-12-08 00:35:50,537 - INFO - epoch 1, step 17850, training loss = 2.860728, validation loss = 4.243103
2018-12-08 00:36:06,270 - INFO - epoch 1, step 17900, training loss = 3.534682, validation loss = 4.096064
2018-12-08 00:36:21,731 - INFO - epoch 1, step 17950, training loss = 3.823854, validation loss = 4.042403
2018-12-08 00:36:37,590 - INFO - epoch 1, step 18000, training loss = 3.245305, validation loss = 4.206031
2018-12-08 00:36:51,183 - INFO - epoch 1, step 18050, training loss = 3.244500, validation loss = 4.509709
2018-12-08 00:37:03,238 - INFO - epoch 1, step 18100, training loss = 2.960111, validation loss = 4.644513
2018-12-08 00:37:29,158 - INFO - epoch 1, step 18150, training loss = 3.712037, validation loss = 3.810577
2018-12-08 00:37:55,209 - INFO - epoch 1, step 18200, training loss = 3.677835, validation loss = 4.230328
2018-12-08 00:38:20,594 - INFO - epoch 1, step 18250, training loss = 3.714401, validation loss = 3.997746
2018-12-08 00:38:46,134 - INFO - epoch 1, step 18300, training loss = 4.168363, validation loss = 3.597071
2018-12-08 00:39:12,435 - INFO - epoch 1, step 18350, training loss = 3.218201, validation loss = 3.862454
2018-12-08 00:39:30,009 - INFO - epoch 1, step 18400, training loss = 3.597026, validation loss = 3.974027
2018-12-08 00:39:45,355 - INFO - epoch 1, step 18450, training loss = 3.589793, validation loss = 4.304494
2018-12-08 00:40:01,603 - INFO - epoch 1, step 18500, training loss = 3.187471, validation loss = 4.178010
2018-12-08 00:40:17,595 - INFO - epoch 1, step 18550, training loss = 2.616664, validation loss = 4.914670
2018-12-08 00:40:34,923 - INFO - epoch 1, step 18600, training loss = 3.953355, validation loss = 4.532563
2018-12-08 00:40:58,337 - INFO - epoch 1, step 18650, training loss = 3.892388, validation loss = 3.785890
2018-12-08 00:41:23,859 - INFO - epoch 1, step 18700, training loss = 3.600465, validation loss = 3.869991
2018-12-08 00:41:48,863 - INFO - epoch 1, step 18750, training loss = 3.640803, validation loss = 3.615208
2018-12-08 00:42:05,238 - INFO - epoch 1, step 18800, training loss = 3.609834, validation loss = 3.939820
2018-12-08 00:42:20,596 - INFO - epoch 1, step 18850, training loss = 3.144935, validation loss = 4.276145
2018-12-08 00:42:36,223 - INFO - epoch 1, step 18900, training loss = 3.081367, validation loss = 4.532525
2018-12-08 00:42:51,991 - INFO - epoch 1, step 18950, training loss = 2.683187, validation loss = 4.120603
2018-12-08 00:43:12,257 - INFO - epoch 1, step 19000, training loss = 3.616919, validation loss = 3.570330
2018-12-08 00:43:30,626 - INFO - epoch 1, step 19050, training loss = 3.172428, validation loss = 3.382618
2018-12-08 00:43:46,125 - INFO - epoch 1, step 19100, training loss = 2.960067, validation loss = 3.870591
2018-12-08 00:44:01,381 - INFO - epoch 1, step 19150, training loss = 3.171772, validation loss = 3.682584
2018-12-08 00:44:17,080 - INFO - epoch 1, step 19200, training loss = 3.739800, validation loss = 4.171990
2018-12-08 00:44:38,117 - INFO - epoch 1, step 19250, training loss = 4.049912, validation loss = 3.646394
2018-12-08 00:45:03,419 - INFO - epoch 1, step 19300, training loss = 3.960450, validation loss = 3.135751
2018-12-08 00:45:28,723 - INFO - epoch 1, step 19350, training loss = 3.436985, validation loss = 3.353433
2018-12-08 00:45:57,709 - INFO - epoch 1, step 19400, training loss = 3.404222, validation loss = 3.744200
2018-12-08 00:46:25,839 - INFO - epoch 1, step 19450, training loss = 3.175001, validation loss = 3.596156
2018-12-08 00:46:54,599 - INFO - epoch 1, step 19500, training loss = 3.960773, validation loss = 3.471503
2018-12-08 00:47:20,856 - INFO - epoch 1, step 19550, training loss = 3.209963, validation loss = 3.324905
2018-12-08 00:47:41,607 - INFO - epoch 1, step 19600, training loss = 3.713893, validation loss = 3.511728
2018-12-08 00:48:02,617 - INFO - epoch 1, step 19650, training loss = 3.623852, validation loss = 3.647482
2018-12-08 00:48:29,590 - INFO - epoch 1, step 19700, training loss = 3.028319, validation loss = 3.719641
2018-12-08 00:48:57,800 - INFO - epoch 1, step 19750, training loss = 3.835342, validation loss = 3.962398
2018-12-08 00:49:25,135 - INFO - epoch 1, step 19800, training loss = 3.752709, validation loss = 3.231382
2018-12-08 00:49:52,616 - INFO - epoch 1, step 19850, training loss = 3.309847, validation loss = 3.208554
2018-12-08 00:50:15,868 - INFO - epoch 1, step 19900, training loss = 2.794315, validation loss = 3.832159
2018-12-08 00:50:31,878 - INFO - epoch 1, step 19950, training loss = 3.340911, validation loss = 3.989112
2018-12-08 00:50:48,078 - INFO - epoch 1, step 20000, training loss = 3.436033, validation loss = 4.289143
2018-12-08 00:51:03,810 - INFO - epoch 1, step 20050, training loss = 3.701013, validation loss = 3.714197
2018-12-08 00:51:19,743 - INFO - epoch 1, step 20100, training loss = 3.186417, validation loss = 3.957792
2018-12-08 00:51:35,696 - INFO - epoch 1, step 20150, training loss = 2.719492, validation loss = 4.338857
2018-12-08 00:51:51,181 - INFO - epoch 1, step 20200, training loss = 3.034909, validation loss = 3.507525
2018-12-08 00:52:10,886 - INFO - epoch 1, step 20250, training loss = 3.844568, validation loss = 3.764664
2018-12-08 00:52:32,846 - INFO - epoch 1, step 20300, training loss = 4.207644, validation loss = 3.784605
2018-12-08 00:52:54,096 - INFO - epoch 1, step 20350, training loss = 3.189443, validation loss = 3.656358
2018-12-08 00:53:15,200 - INFO - epoch 1, step 20400, training loss = 3.747581, validation loss = 3.391026
2018-12-08 00:53:37,062 - INFO - epoch 1, step 20450, training loss = 4.092622, validation loss = 4.128521
2018-12-08 00:54:00,645 - INFO - epoch 1, step 20500, training loss = 3.546303, validation loss = 3.834694
2018-12-08 00:54:25,717 - INFO - epoch 1, step 20550, training loss = 3.313875, validation loss = 3.218592
2018-12-08 00:54:50,668 - INFO - epoch 1, step 20600, training loss = 3.335559, validation loss = 3.174459
2018-12-08 00:55:11,255 - INFO - epoch 1, step 20650, training loss = 3.535625, validation loss = 3.651317
2018-12-08 00:55:29,472 - INFO - epoch 1, step 20700, training loss = 3.397858, validation loss = 4.317722
2018-12-08 00:55:50,104 - INFO - epoch 1, step 20750, training loss = 3.118741, validation loss = 4.069144
2018-12-08 00:56:11,081 - INFO - epoch 1, step 20800, training loss = 3.523875, validation loss = 2.932669
2018-12-08 00:56:26,799 - INFO - epoch 1, step 20850, training loss = 2.570205, validation loss = 3.864927
2018-12-08 00:56:42,577 - INFO - epoch 1, step 20900, training loss = 3.492405, validation loss = 4.102777
2018-12-08 00:56:58,356 - INFO - epoch 1, step 20950, training loss = 3.463660, validation loss = 4.184585
2018-12-08 00:57:27,347 - INFO - epoch 1, step 21000, training loss = 3.397982, validation loss = 4.130498
2018-12-08 00:57:56,780 - INFO - epoch 1, step 21050, training loss = 3.470530, validation loss = 3.031883
2018-12-08 00:58:22,225 - INFO - epoch 1, step 21100, training loss = 3.962863, validation loss = 3.383948
2018-12-08 00:58:47,123 - INFO - epoch 1, step 21150, training loss = 3.618043, validation loss = 3.525813
2018-12-08 00:59:12,043 - INFO - epoch 1, step 21200, training loss = 3.860953, validation loss = 3.621053
2018-12-08 00:59:37,131 - INFO - epoch 1, step 21250, training loss = 2.812658, validation loss = 4.284030
2018-12-08 01:00:02,889 - INFO - epoch 1, step 21300, training loss = 3.864028, validation loss = 3.515579
2018-12-08 01:00:28,391 - INFO - epoch 1, step 21350, training loss = 3.179766, validation loss = 3.391803
2018-12-08 01:00:54,398 - INFO - epoch 1, step 21400, training loss = 3.407180, validation loss = 3.386305
2018-12-08 01:01:20,654 - INFO - epoch 1, step 21450, training loss = 3.376586, validation loss = 3.855023
2018-12-08 01:01:47,386 - INFO - epoch 1, step 21500, training loss = 3.624214, validation loss = 3.745570
2018-12-08 01:02:04,290 - INFO - epoch 1, step 21550, training loss = 4.213919, validation loss = 3.792143
2018-12-08 01:02:20,487 - INFO - epoch 1, step 21600, training loss = 3.695737, validation loss = 3.889389
2018-12-08 01:02:38,224 - INFO - epoch 1, step 21650, training loss = 4.021358, validation loss = 3.826605
2018-12-08 01:03:01,919 - INFO - epoch 1, step 21700, training loss = 3.768263, validation loss = 3.757823
2018-12-08 01:03:25,231 - INFO - epoch 1, step 21750, training loss = 3.758024, validation loss = 3.876638
2018-12-08 01:03:49,696 - INFO - epoch 1, step 21800, training loss = 3.514187, validation loss = 3.677872
2018-12-08 01:04:14,031 - INFO - epoch 1, step 21850, training loss = 3.817608, validation loss = 3.493877
2018-12-08 01:04:34,116 - INFO - epoch 1, step 21900, training loss = 2.588511, validation loss = 4.731648
2018-12-08 01:04:46,065 - INFO - epoch 1, step 21950, training loss = 3.327824, validation loss = 4.821801
2018-12-08 01:04:57,723 - INFO - epoch 1, step 22000, training loss = 3.897918, validation loss = 4.404682
2018-12-08 01:05:10,927 - INFO - epoch 1, step 22050, training loss = 4.106197, validation loss = 3.828778
2018-12-08 01:05:33,112 - INFO - epoch 1, step 22100, training loss = 4.033638, validation loss = 3.667595
2018-12-08 01:05:55,083 - INFO - epoch 1, step 22150, training loss = 3.616433, validation loss = 3.740396
2018-12-08 01:06:16,699 - INFO - epoch 1, step 22200, training loss = 3.833333, validation loss = 3.898388
2018-12-08 01:06:42,856 - INFO - epoch 1, step 22250, training loss = 3.638853, validation loss = 3.834381
2018-12-08 01:07:12,341 - INFO - epoch 1, step 22300, training loss = 3.217375, validation loss = 3.646151
2018-12-08 01:07:41,969 - INFO - epoch 1, step 22350, training loss = 3.516221, validation loss = 3.261915
2018-12-08 01:08:09,992 - INFO - epoch 1, step 22400, training loss = 3.689170, validation loss = 3.523253
2018-12-08 01:08:38,775 - INFO - epoch 1, step 22450, training loss = 3.514797, validation loss = 3.829811
2018-12-08 01:09:05,474 - INFO - epoch 1, step 22500, training loss = 3.853545, validation loss = 4.284917
2018-12-08 01:09:33,889 - INFO - epoch 1, step 22550, training loss = 3.591428, validation loss = 3.374022
2018-12-08 01:10:02,519 - INFO - epoch 1, step 22600, training loss = 3.220877, validation loss = 3.228662
2018-12-08 01:10:24,761 - INFO - epoch 1, step 22650, training loss = 3.670255, validation loss = 3.705303
2018-12-08 01:10:44,034 - INFO - epoch 1, step 22700, training loss = 3.548227, validation loss = 4.038297
2018-12-08 01:11:01,428 - INFO - epoch 1, step 22750, training loss = 3.723223, validation loss = 4.305548
2018-12-08 01:11:18,834 - INFO - epoch 1, step 22800, training loss = 3.995966, validation loss = 3.943843
2018-12-08 01:11:35,900 - INFO - epoch 1, step 22850, training loss = 2.785014, validation loss = 3.675231
2018-12-08 01:11:52,218 - INFO - epoch 1, step 22900, training loss = 3.050142, validation loss = 3.976989
2018-12-08 01:12:08,020 - INFO - epoch 1, step 22950, training loss = 3.258644, validation loss = 4.523678
2018-12-08 01:12:24,000 - INFO - epoch 1, step 23000, training loss = 3.347344, validation loss = 4.315964
2018-12-08 01:12:45,807 - INFO - epoch 1, step 23050, training loss = 3.610954, validation loss = 3.470584
2018-12-08 01:13:06,879 - INFO - epoch 1, step 23100, training loss = 3.621844, validation loss = 3.556478
2018-12-08 01:13:23,083 - INFO - epoch 1, step 23150, training loss = 2.636970, validation loss = 4.442881
2018-12-08 01:13:34,519 - INFO - epoch 1, step 23200, training loss = 2.858188, validation loss = 3.810997
2018-12-08 01:13:46,033 - INFO - epoch 1, step 23250, training loss = 3.441618, validation loss = 4.982932
2018-12-08 01:13:59,232 - INFO - epoch 1, step 23300, training loss = 3.281266, validation loss = 3.862125
2018-12-08 01:14:15,186 - INFO - epoch 1, step 23350, training loss = 2.997541, validation loss = 3.677350
2018-12-08 01:14:30,476 - INFO - epoch 1, step 23400, training loss = 3.187303, validation loss = 4.023407
2018-12-08 01:14:47,675 - INFO - epoch 1, step 23450, training loss = 3.799864, validation loss = 4.344218
2018-12-08 01:15:13,037 - INFO - epoch 1, step 23500, training loss = 3.559213, validation loss = 4.201458
2018-12-08 01:15:36,223 - INFO - epoch 1, step 23550, training loss = 3.866124, validation loss = 3.303989
2018-12-08 01:15:57,278 - INFO - epoch 1, step 23600, training loss = 3.687244, validation loss = 3.616755
2018-12-08 01:16:17,999 - INFO - epoch 1, step 23650, training loss = 3.399615, validation loss = 3.886824
2018-12-08 01:16:39,360 - INFO - epoch 1, step 23700, training loss = 3.613296, validation loss = 3.922723
2018-12-08 01:17:03,137 - INFO - epoch 1, step 23750, training loss = 3.552660, validation loss = 4.404100
2018-12-08 01:17:27,200 - INFO - epoch 1, step 23800, training loss = 3.570418, validation loss = 3.435243
2018-12-08 01:17:52,271 - INFO - epoch 1, step 23850, training loss = 4.088332, validation loss = 3.440222
2018-12-08 01:18:17,583 - INFO - epoch 1, step 23900, training loss = 3.998726, validation loss = 3.174813
2018-12-08 01:18:42,173 - INFO - epoch 1, step 23950, training loss = 3.918488, validation loss = 3.921535
2018-12-08 01:19:05,543 - INFO - epoch 1, step 24000, training loss = 3.582395, validation loss = 3.895975
2018-12-08 01:19:32,528 - INFO - epoch 1, step 24050, training loss = 3.643656, validation loss = 4.174476
2018-12-08 01:20:03,137 - INFO - epoch 1, step 24100, training loss = 3.886399, validation loss = 3.350211
2018-12-08 01:20:32,855 - INFO - epoch 1, step 24150, training loss = 3.928737, validation loss = 3.503575
2018-12-08 01:21:01,319 - INFO - epoch 1, step 24200, training loss = 3.828203, validation loss = 3.559444
2018-12-08 01:21:27,677 - INFO - epoch 1, step 24250, training loss = 3.194986, validation loss = 3.771461
2018-12-08 01:21:43,950 - INFO - epoch 1, step 24300, training loss = 3.316272, validation loss = 4.569879
2018-12-08 01:21:59,950 - INFO - epoch 1, step 24350, training loss = 2.726470, validation loss = 3.767895
2018-12-08 01:22:16,086 - INFO - epoch 1, step 24400, training loss = 3.135373, validation loss = 3.844398
2018-12-08 01:22:31,999 - INFO - epoch 1, step 24450, training loss = 3.831030, validation loss = 3.683870
2018-12-08 01:22:48,027 - INFO - epoch 1, step 24500, training loss = 3.572116, validation loss = 3.967510
2018-12-08 01:23:03,674 - INFO - epoch 1, step 24550, training loss = 2.986044, validation loss = 4.185424
2018-12-08 01:23:19,751 - INFO - epoch 1, step 24600, training loss = 4.536016, validation loss = 3.728861
2018-12-08 01:23:36,538 - INFO - epoch 1, step 24650, training loss = 3.470115, validation loss = 3.538784
2018-12-08 01:23:51,893 - INFO - epoch 1, step 24700, training loss = 3.463989, validation loss = 4.322305
2018-12-08 01:24:07,538 - INFO - epoch 1, step 24750, training loss = 3.514698, validation loss = 3.886359
2018-12-08 01:24:23,614 - INFO - epoch 1, step 24800, training loss = 2.636837, validation loss = 4.079728
2018-12-08 01:24:40,377 - INFO - epoch 1, step 24850, training loss = 2.857831, validation loss = 4.327014
2018-12-08 01:24:58,553 - INFO - epoch 1, step 24900, training loss = 3.474512, validation loss = 4.721671
2018-12-08 01:25:20,276 - INFO - epoch 1, step 24950, training loss = 4.006923, validation loss = 4.547488
2018-12-08 01:25:47,143 - INFO - epoch 1, step 25000, training loss = 4.017214, validation loss = 4.485204
2018-12-08 01:26:14,225 - INFO - epoch 1, step 25050, training loss = 3.750070, validation loss = 4.539712
2018-12-08 01:26:41,036 - INFO - epoch 1, step 25100, training loss = 3.640103, validation loss = 4.392324
2018-12-08 01:27:07,838 - INFO - epoch 1, step 25150, training loss = 3.770249, validation loss = 4.734834
2018-12-08 01:27:26,808 - INFO - epoch 1, step 25200, training loss = 3.444018, validation loss = 4.405573
2018-12-08 01:27:44,788 - INFO - epoch 1, step 25250, training loss = 3.828799, validation loss = 4.310077
2018-12-08 01:28:08,458 - INFO - epoch 1, step 25300, training loss = 3.750732, validation loss = 4.359344
2018-12-08 01:28:35,757 - INFO - epoch 1, step 25350, training loss = 3.908221, validation loss = 4.134587
2018-12-08 01:29:03,408 - INFO - epoch 1, step 25400, training loss = 3.226540, validation loss = 4.478852
2018-12-08 01:29:30,185 - INFO - epoch 1, step 25450, training loss = 3.743943, validation loss = 4.109065
2018-12-08 01:29:48,459 - INFO - epoch 1, step 25500, training loss = 3.217085, validation loss = 4.370435
2018-12-08 01:30:04,287 - INFO - epoch 1, step 25550, training loss = 3.344482, validation loss = 4.124029
2018-12-08 01:30:24,898 - INFO - epoch 1, step 25600, training loss = 3.841825, validation loss = 4.490256
2018-12-08 01:30:52,154 - INFO - epoch 1, step 25650, training loss = 3.584763, validation loss = 5.090990
2018-12-08 01:31:21,166 - INFO - epoch 1, step 25700, training loss = 3.283543, validation loss = 4.761781
2018-12-08 01:31:48,974 - INFO - epoch 1, step 25750, training loss = 3.264651, validation loss = 4.585195
2018-12-08 01:32:10,283 - INFO - epoch 1, step 25800, training loss = 3.697550, validation loss = 4.810528
2018-12-08 01:32:27,605 - INFO - epoch 1, step 25850, training loss = 3.662982, validation loss = 4.654170
2018-12-08 01:32:43,216 - INFO - epoch 1, step 25900, training loss = 3.086153, validation loss = 4.358784
2018-12-08 01:32:59,139 - INFO - epoch 1, step 25950, training loss = 3.599194, validation loss = 4.254470
2018-12-08 01:33:25,341 - INFO - epoch 1, step 26000, training loss = 3.466818, validation loss = 4.371726
2018-12-08 01:33:51,462 - INFO - epoch 1, step 26050, training loss = 3.101451, validation loss = 4.314049
2018-12-08 01:34:17,052 - INFO - epoch 1, step 26100, training loss = 3.132105, validation loss = 4.490558
2018-12-08 01:34:42,180 - INFO - epoch 1, step 26150, training loss = 3.778527, validation loss = 4.528059
2018-12-08 01:35:10,604 - INFO - epoch 1, step 26200, training loss = 4.049320, validation loss = 4.425073
2018-12-08 01:35:37,504 - INFO - epoch 1, step 26250, training loss = 3.530710, validation loss = 4.698942
2018-12-08 01:36:05,537 - INFO - epoch 1, step 26300, training loss = 3.231162, validation loss = 3.960032
2018-12-08 01:36:31,435 - INFO - epoch 1, step 26350, training loss = 4.193981, validation loss = 4.892277
2018-12-08 01:36:57,505 - INFO - epoch 1, step 26400, training loss = 3.685974, validation loss = 4.500391
2018-12-08 01:37:23,337 - INFO - epoch 1, step 26450, training loss = 3.677906, validation loss = 4.625325
2018-12-08 01:37:42,730 - INFO - epoch 1, step 26500, training loss = 3.769727, validation loss = 4.356440
2018-12-08 01:37:59,257 - INFO - epoch 1, step 26550, training loss = 3.606187, validation loss = 4.494279
2018-12-08 01:38:14,580 - INFO - epoch 1, step 26600, training loss = 3.729935, validation loss = 4.701751
2018-12-08 01:38:30,193 - INFO - epoch 1, step 26650, training loss = 3.116799, validation loss = 4.329612
2018-12-08 01:38:45,610 - INFO - epoch 1, step 26700, training loss = 2.825655, validation loss = 4.370788
2018-12-08 01:39:10,828 - INFO - epoch 1, step 26750, training loss = 3.998578, validation loss = 4.715601
2018-12-08 01:39:38,998 - INFO - epoch 1, step 26800, training loss = 3.557981, validation loss = 4.698202
2018-12-08 01:40:06,661 - INFO - epoch 1, step 26850, training loss = 3.263799, validation loss = 4.014007
2018-12-08 01:40:32,755 - INFO - epoch 1, step 26900, training loss = 3.506327, validation loss = 4.349579
2018-12-08 01:40:58,538 - INFO - epoch 1, step 26950, training loss = 3.663667, validation loss = 4.236208
2018-12-08 01:41:25,115 - INFO - epoch 1, step 27000, training loss = 3.901670, validation loss = 4.534412
2018-12-08 01:41:50,664 - INFO - epoch 1, step 27050, training loss = 3.750919, validation loss = 4.318163
2018-12-08 01:42:11,896 - INFO - epoch 1, step 27100, training loss = 3.546187, validation loss = 4.143235
2018-12-08 01:42:30,474 - INFO - epoch 1, step 27150, training loss = 4.404799, validation loss = 4.487347
2018-12-08 01:42:53,875 - INFO - epoch 1, step 27200, training loss = 3.435970, validation loss = 4.399756
2018-12-08 01:43:19,465 - INFO - epoch 1, step 27250, training loss = 3.652922, validation loss = 4.560102
2018-12-08 01:43:44,375 - INFO - epoch 1, step 27300, training loss = 3.884486, validation loss = 5.110267
2018-12-08 01:44:06,142 - INFO - epoch 1, step 27350, training loss = 3.148962, validation loss = 4.563026
2018-12-08 01:44:26,748 - INFO - epoch 1, step 27400, training loss = 3.370535, validation loss = 4.610064
2018-12-08 01:44:42,246 - INFO - epoch 1, step 27450, training loss = 3.649896, validation loss = 4.541008
2018-12-08 01:44:58,027 - INFO - epoch 1, step 27500, training loss = 3.137259, validation loss = 4.325021
2018-12-08 01:45:13,915 - INFO - epoch 1, step 27550, training loss = 2.672924, validation loss = 4.856843
2018-12-08 01:45:32,724 - INFO - epoch 1, step 27600, training loss = 3.718153, validation loss = 4.848584
2018-12-08 01:45:57,588 - INFO - epoch 1, step 27650, training loss = 3.746760, validation loss = 4.504189
2018-12-08 01:46:25,970 - INFO - epoch 1, step 27700, training loss = 3.779971, validation loss = 4.469154
2018-12-08 01:46:54,503 - INFO - epoch 1, step 27750, training loss = 3.632715, validation loss = 4.476847
2018-12-08 01:47:20,351 - INFO - epoch 1, step 27800, training loss = 3.297965, validation loss = 4.736822
2018-12-08 01:47:45,635 - INFO - epoch 1, step 27850, training loss = 3.058060, validation loss = 4.990115
2018-12-08 01:48:11,174 - INFO - epoch 1, step 27900, training loss = 3.314615, validation loss = 4.258196
2018-12-08 01:48:36,449 - INFO - epoch 1, step 27950, training loss = 3.032430, validation loss = 4.553997
2018-12-08 01:49:02,276 - INFO - epoch 1, step 28000, training loss = 3.429187, validation loss = 4.650330
2018-12-08 01:49:28,534 - INFO - epoch 1, step 28050, training loss = 3.303876, validation loss = 4.585317
2018-12-08 01:49:55,652 - INFO - epoch 1, step 28100, training loss = 3.047842, validation loss = 5.068224
2018-12-08 01:50:21,331 - INFO - epoch 1, step 28150, training loss = 3.715034, validation loss = 5.586959
2018-12-08 01:50:46,822 - INFO - epoch 1, step 28200, training loss = 3.537694, validation loss = 5.853695
2018-12-08 01:51:12,042 - INFO - epoch 1, step 28250, training loss = 3.021637, validation loss = 5.333655
2018-12-08 01:51:37,599 - INFO - epoch 1, step 28300, training loss = 3.586587, validation loss = 5.659884
2018-12-08 01:52:03,107 - INFO - epoch 1, step 28350, training loss = 3.821322, validation loss = 5.602870
2018-12-08 01:52:25,272 - INFO - epoch 1, step 28400, training loss = 3.295154, validation loss = 5.373511
2018-12-08 01:52:51,589 - INFO - epoch 1, step 28450, training loss = 3.673845, validation loss = 5.671631
2018-12-08 01:53:20,779 - INFO - epoch 1, step 28500, training loss = 3.457829, validation loss = 5.196558
2018-12-08 01:53:39,148 - INFO - epoch 1, step 28550, training loss = 3.303368, validation loss = 5.559880
2018-12-08 01:53:54,767 - INFO - epoch 1, step 28600, training loss = 3.661484, validation loss = 5.635111
2018-12-08 01:54:10,174 - INFO - epoch 1, step 28650, training loss = 3.541559, validation loss = 5.258093
2018-12-08 01:54:31,225 - INFO - epoch 1, step 28700, training loss = 3.869076, validation loss = 5.017170
2018-12-08 01:54:56,287 - INFO - epoch 1, step 28750, training loss = 3.458030, validation loss = 5.336903
2018-12-08 01:55:21,297 - INFO - epoch 1, step 28800, training loss = 3.434819, validation loss = 5.140943
2018-12-08 01:55:46,738 - INFO - epoch 1, step 28850, training loss = 3.390921, validation loss = 5.274016
2018-12-08 01:56:11,929 - INFO - epoch 1, step 28900, training loss = 3.166033, validation loss = 5.561802
2018-12-08 01:56:37,585 - INFO - epoch 1, step 28950, training loss = 3.451470, validation loss = 5.417657
2018-12-08 01:57:03,955 - INFO - epoch 1, step 29000, training loss = 3.244041, validation loss = 5.749576
2018-12-08 01:57:29,413 - INFO - epoch 1, step 29050, training loss = 3.219562, validation loss = 4.967479
2018-12-08 01:57:50,926 - INFO - epoch 1, step 29100, training loss = 3.608590, validation loss = 4.631197
2018-12-08 01:58:17,455 - INFO - epoch 1, step 29150, training loss = 3.563661, validation loss = 4.599700
2018-12-08 01:58:45,877 - INFO - epoch 1, step 29200, training loss = 3.225561, validation loss = 5.048004
2018-12-08 01:59:13,226 - INFO - epoch 1, step 29250, training loss = 3.655413, validation loss = 5.659011
2018-12-08 01:59:39,692 - INFO - epoch 1, step 29300, training loss = 3.725306, validation loss = 5.122666
2018-12-08 02:00:05,432 - INFO - epoch 1, step 29350, training loss = 3.341757, validation loss = 4.632312
2018-12-08 02:00:32,113 - INFO - epoch 1, step 29400, training loss = 3.486607, validation loss = 5.379364
2018-12-08 02:00:58,423 - INFO - epoch 1, step 29450, training loss = 3.876391, validation loss = 5.785662
2018-12-08 02:01:24,021 - INFO - epoch 1, step 29500, training loss = 3.859505, validation loss = 5.307911
2018-12-08 02:01:50,592 - INFO - epoch 1, step 29550, training loss = 3.736305, validation loss = 5.262901
2018-12-08 02:02:16,799 - INFO - epoch 1, step 29600, training loss = 3.400309, validation loss = 5.831707
2018-12-08 02:02:42,958 - INFO - epoch 1, step 29650, training loss = 3.138242, validation loss = 5.422927
2018-12-08 02:03:07,953 - INFO - epoch 1, step 29700, training loss = 3.279445, validation loss = 5.627762
2018-12-08 02:03:28,990 - INFO - epoch 1, step 29750, training loss = 3.268785, validation loss = 5.254072
2018-12-08 02:03:53,473 - INFO - epoch 1, step 29800, training loss = 3.282286, validation loss = 5.529072
2018-12-08 02:04:19,605 - INFO - epoch 1, step 29850, training loss = 3.200713, validation loss = 5.390077
2018-12-08 02:04:46,023 - INFO - epoch 1, step 29900, training loss = 3.549565, validation loss = 5.240744
2018-12-08 02:05:11,933 - INFO - epoch 1, step 29950, training loss = 3.333158, validation loss = 5.155097
2018-12-08 02:05:37,843 - INFO - epoch 1, step 30000, training loss = 3.343944, validation loss = 5.532020
2018-12-08 02:06:03,484 - INFO - epoch 1, step 30050, training loss = 3.049538, validation loss = 5.147381
2018-12-08 02:06:24,945 - INFO - epoch 1, step 30100, training loss = 4.037621, validation loss = 4.862132
2018-12-08 02:06:40,845 - INFO - epoch 1, step 30150, training loss = 2.882068, validation loss = 5.201648
2018-12-08 02:06:56,502 - INFO - epoch 1, step 30200, training loss = 3.679484, validation loss = 5.287331
2018-12-08 02:07:19,775 - INFO - epoch 1, step 30250, training loss = 3.341585, validation loss = 4.910907
2018-12-08 02:07:44,907 - INFO - epoch 1, step 30300, training loss = 3.209627, validation loss = 5.179596
2018-12-08 02:08:09,952 - INFO - epoch 1, step 30350, training loss = 3.754493, validation loss = 4.835110
2018-12-08 02:08:38,149 - INFO - epoch 1, step 30400, training loss = 3.313306, validation loss = 5.134810
2018-12-08 02:09:05,845 - INFO - epoch 1, step 30450, training loss = 3.461623, validation loss = 5.124002
2018-12-08 02:09:32,838 - INFO - epoch 1, step 30500, training loss = 3.529278, validation loss = 4.969768
2018-12-08 02:09:59,673 - INFO - epoch 1, step 30550, training loss = 3.841460, validation loss = 5.176350
2018-12-08 02:10:26,758 - INFO - epoch 1, step 30600, training loss = 3.665182, validation loss = 4.607037
2018-12-08 02:10:55,203 - INFO - epoch 1, step 30650, training loss = 3.750201, validation loss = 4.750246
2018-12-08 02:11:23,393 - INFO - epoch 1, step 30700, training loss = 3.509476, validation loss = 5.456088
2018-12-08 02:11:49,631 - INFO - epoch 1, step 30750, training loss = 4.579841, validation loss = 5.160453
2018-12-08 02:12:03,096 - INFO - epoch 1, step 30800, training loss = 3.609615, validation loss = 4.742881
2018-12-08 02:12:17,764 - INFO - epoch 1, step 30850, training loss = 3.629312, validation loss = 4.675323
2018-12-08 02:12:38,353 - INFO - epoch 1, step 30900, training loss = 3.421221, validation loss = 4.819083
2018-12-08 02:13:04,570 - INFO - epoch 1, step 30950, training loss = 3.581940, validation loss = 5.307136
2018-12-08 02:13:33,770 - INFO - epoch 1, step 31000, training loss = 3.156506, validation loss = 5.296418
2018-12-08 02:14:02,324 - INFO - epoch 1, step 31050, training loss = 3.526555, validation loss = 5.460831
2018-12-08 02:14:20,320 - INFO - epoch 1, step 31100, training loss = 3.194441, validation loss = 5.607995
2018-12-08 02:14:35,938 - INFO - epoch 1, step 31150, training loss = 3.049413, validation loss = 5.500588
2018-12-08 02:14:52,395 - INFO - epoch 1, step 31200, training loss = 3.393008, validation loss = 5.473190
2018-12-08 02:15:12,788 - INFO - epoch 1, step 31250, training loss = 4.256435, validation loss = 4.985108
2018-12-08 02:15:30,930 - INFO - epoch 1, step 31300, training loss = 3.662133, validation loss = 4.964008
2018-12-08 02:15:42,783 - INFO - epoch 1, step 31350, training loss = 2.754441, validation loss = 5.207393
2018-12-08 02:15:54,733 - INFO - epoch 1, step 31400, training loss = 3.257795, validation loss = 5.495667
2018-12-08 02:16:07,014 - INFO - epoch 1, step 31450, training loss = 3.502717, validation loss = 5.459774
2018-12-08 02:16:22,569 - INFO - epoch 1, step 31500, training loss = 3.145734, validation loss = 5.675990
2018-12-08 02:16:38,423 - INFO - epoch 1, step 31550, training loss = 3.453517, validation loss = 5.373813
2018-12-08 02:17:00,574 - INFO - epoch 1, step 31600, training loss = 4.168373, validation loss = 5.501731
2018-12-08 02:17:25,773 - INFO - epoch 1, step 31650, training loss = 3.104833, validation loss = 5.936660
2018-12-08 02:17:51,799 - INFO - epoch 1, step 31700, training loss = 3.945687, validation loss = 4.709283
2018-12-08 02:18:17,121 - INFO - epoch 1, step 31750, training loss = 3.781651, validation loss = 5.405378
2018-12-08 02:18:39,002 - INFO - epoch 1, step 31800, training loss = 3.316152, validation loss = 5.026089
2018-12-08 02:18:50,351 - INFO - epoch 1, step 31850, training loss = 3.226498, validation loss = 5.521620
2018-12-08 02:19:01,774 - INFO - epoch 1, step 31900, training loss = 3.271425, validation loss = 5.596133
2018-12-08 02:19:19,584 - INFO - epoch 1, step 31950, training loss = 3.267469, validation loss = 5.464956
2018-12-08 02:19:48,464 - INFO - epoch 1, step 32000, training loss = 3.667771, validation loss = 5.356781
2018-12-08 02:20:15,784 - INFO - epoch 1, step 32050, training loss = 3.952588, validation loss = 5.160654
2018-12-08 02:20:44,429 - INFO - epoch 1, step 32100, training loss = 3.451166, validation loss = 5.331274
2018-12-08 02:21:02,360 - INFO - epoch 1, step 32150, training loss = 2.935307, validation loss = 4.856862
2018-12-08 02:21:14,265 - INFO - epoch 1, step 32200, training loss = 3.434717, validation loss = 5.006327
2018-12-08 02:21:26,309 - INFO - epoch 1, step 32250, training loss = 3.194621, validation loss = 5.222553
2018-12-08 02:21:46,858 - INFO - epoch 1, step 32300, training loss = 3.999807, validation loss = 5.171091
2018-12-08 02:22:12,245 - INFO - epoch 1, step 32350, training loss = 3.849291, validation loss = 5.260264
2018-12-08 02:22:37,866 - INFO - epoch 1, step 32400, training loss = 3.568234, validation loss = 4.993170
2018-12-08 02:23:03,287 - INFO - epoch 1, step 32450, training loss = 3.546460, validation loss = 5.556446
2018-12-08 02:23:28,756 - INFO - epoch 1, step 32500, training loss = 3.691556, validation loss = 5.284936
2018-12-08 02:23:51,134 - INFO - epoch 1, step 32550, training loss = 3.266283, validation loss = 5.213240
2018-12-08 02:24:10,598 - INFO - epoch 1, step 32600, training loss = 3.669380, validation loss = 5.331692
2018-12-08 02:24:26,464 - INFO - epoch 1, step 32650, training loss = 3.649848, validation loss = 5.167845
2018-12-08 02:24:51,247 - INFO - epoch 1, step 32700, training loss = 3.491279, validation loss = 5.187128
2018-12-08 02:25:16,080 - INFO - epoch 1, step 32750, training loss = 3.047479, validation loss = 5.517045
2018-12-08 02:25:40,426 - INFO - epoch 1, step 32800, training loss = 3.694992, validation loss = 4.840500
2018-12-08 02:26:05,403 - INFO - epoch 1, step 32850, training loss = 3.152023, validation loss = 5.234348
2018-12-08 02:26:30,850 - INFO - epoch 1, step 32900, training loss = 3.460303, validation loss = 4.996276
2018-12-08 02:26:58,643 - INFO - epoch 1, step 32950, training loss = 3.611719, validation loss = 5.129936
2018-12-08 02:27:25,676 - INFO - epoch 1, step 33000, training loss = 3.794739, validation loss = 4.928859
2018-12-08 02:27:46,769 - INFO - epoch 1, step 33050, training loss = 3.538492, validation loss = 4.864204
2018-12-08 02:28:05,410 - INFO - epoch 1, step 33100, training loss = 3.676461, validation loss = 5.263349
2018-12-08 02:28:23,494 - INFO - epoch 1, step 33150, training loss = 4.135522, validation loss = 5.042962
2018-12-08 02:28:46,949 - INFO - epoch 1, step 33200, training loss = 3.351693, validation loss = 5.520134
2018-12-08 02:29:13,761 - INFO - epoch 1, step 33250, training loss = 3.034065, validation loss = 5.651919
2018-12-08 02:29:40,260 - INFO - epoch 1, step 33300, training loss = 3.736679, validation loss = 5.122380
2018-12-08 02:30:08,604 - INFO - epoch 1, step 33350, training loss = 3.211352, validation loss = 5.665024
2018-12-08 02:30:32,912 - INFO - epoch 1, step 33400, training loss = 3.426724, validation loss = 5.372420
2018-12-08 02:30:56,082 - INFO - epoch 1, step 33450, training loss = 3.462488, validation loss = 5.617612
2018-12-08 02:31:20,183 - INFO - epoch 1, step 33500, training loss = 4.055752, validation loss = 5.193375
2018-12-08 02:31:45,129 - INFO - epoch 1, step 33550, training loss = 3.439741, validation loss = 4.756603
2018-12-08 02:32:10,622 - INFO - epoch 1, step 33600, training loss = 2.986873, validation loss = 4.959025
2018-12-08 02:32:37,200 - INFO - epoch 1, step 33650, training loss = 3.723855, validation loss = 5.235968
2018-12-08 02:33:02,660 - INFO - epoch 1, step 33700, training loss = 3.061789, validation loss = 5.304029
2018-12-08 02:33:27,520 - INFO - epoch 1, step 33750, training loss = 4.029099, validation loss = 4.902912
2018-12-08 02:33:52,893 - INFO - epoch 1, step 33800, training loss = 3.003429, validation loss = 5.246409
2018-12-08 02:34:18,430 - INFO - epoch 1, step 33850, training loss = 3.191104, validation loss = 5.418398
2018-12-08 02:34:43,377 - INFO - epoch 1, step 33900, training loss = 3.874983, validation loss = 5.505488
2018-12-08 02:35:09,281 - INFO - epoch 1, step 33950, training loss = 3.273801, validation loss = 5.790937
2018-12-08 02:35:34,822 - INFO - epoch 1, step 34000, training loss = 3.544674, validation loss = 5.581750
2018-12-08 02:35:59,506 - INFO - epoch 1, step 34050, training loss = 3.183063, validation loss = 5.292201
2018-12-08 02:36:20,572 - INFO - epoch 1, step 34100, training loss = 2.808089, validation loss = 5.068674
2018-12-08 02:36:32,178 - INFO - epoch 1, step 34150, training loss = 3.459994, validation loss = 5.381144
2018-12-08 02:36:44,102 - INFO - epoch 1, step 34200, training loss = 2.816387, validation loss = 5.510828
2018-12-08 02:37:03,669 - INFO - epoch 1, step 34250, training loss = 3.407562, validation loss = 5.805767
2018-12-08 02:37:28,767 - INFO - epoch 1, step 34300, training loss = 3.878963, validation loss = 5.236352
2018-12-08 02:37:54,163 - INFO - epoch 1, step 34350, training loss = 3.484742, validation loss = 5.743708
2018-12-08 02:38:20,166 - INFO - epoch 1, step 34400, training loss = 3.173643, validation loss = 5.187360
2018-12-08 02:38:45,358 - INFO - epoch 1, step 34450, training loss = 3.186832, validation loss = 5.170585
2018-12-08 02:39:04,505 - INFO - epoch 1, step 34500, training loss = 3.355456, validation loss = 5.303957
2018-12-08 02:39:20,237 - INFO - epoch 1, step 34550, training loss = 3.793059, validation loss = 5.535874
2018-12-08 02:39:36,378 - INFO - epoch 1, step 34600, training loss = 2.961915, validation loss = 5.351059
2018-12-08 02:39:54,227 - INFO - epoch 1, step 34650, training loss = 4.052162, validation loss = 5.440651
2018-12-08 02:40:20,293 - INFO - epoch 1, step 34700, training loss = 3.253615, validation loss = 5.424515
2018-12-08 02:40:46,969 - INFO - epoch 1, step 34750, training loss = 3.346584, validation loss = 5.966846
2018-12-08 02:41:14,406 - INFO - epoch 1, step 34800, training loss = 4.022978, validation loss = 5.447706
2018-12-08 02:41:37,978 - INFO - epoch 1, step 34850, training loss = 3.770719, validation loss = 4.902017
2018-12-08 02:42:07,763 - INFO - epoch 1, step 34900, training loss = 3.414562, validation loss = 5.392625
2018-12-08 02:42:32,872 - INFO - epoch 1, step 34950, training loss = 3.575729, validation loss = 5.307145
2018-12-08 02:42:56,552 - INFO - epoch 1, step 35000, training loss = 3.817679, validation loss = 5.378233
2018-12-08 02:43:19,751 - INFO - epoch 1, step 35050, training loss = 3.585654, validation loss = 5.315317
2018-12-08 02:43:33,489 - INFO - epoch 1, step 35100, training loss = 2.943650, validation loss = 5.349337
2018-12-08 02:43:45,009 - INFO - epoch 1, step 35150, training loss = 3.339408, validation loss = 5.300121
2018-12-08 02:43:55,967 - INFO - epoch 1, step 35200, training loss = 3.410577, validation loss = 5.273072
2018-12-08 02:44:12,304 - INFO - epoch 1, step 35250, training loss = 3.683067, validation loss = 5.263127
2018-12-08 02:44:33,261 - INFO - epoch 1, step 35300, training loss = 3.329766, validation loss = 4.955879
2018-12-08 02:44:55,171 - INFO - epoch 1, step 35350, training loss = 3.634584, validation loss = 5.249423
2018-12-08 02:45:17,550 - INFO - epoch 1, step 35400, training loss = 3.572482, validation loss = 5.433763
2018-12-08 02:45:39,084 - INFO - epoch 1, step 35450, training loss = 3.627590, validation loss = 5.196263
2018-12-08 02:46:00,401 - INFO - epoch 1, step 35500, training loss = 3.728421, validation loss = 4.951803
2018-12-08 02:46:21,345 - INFO - epoch 1, step 35550, training loss = 4.110531, validation loss = 4.884727
2018-12-08 02:46:45,625 - INFO - epoch 1, step 35600, training loss = 3.602638, validation loss = 5.363121
2018-12-08 02:47:13,031 - INFO - epoch 1, step 35650, training loss = 3.499635, validation loss = 4.949955
2018-12-08 02:47:38,071 - INFO - epoch 1, step 35700, training loss = 3.548526, validation loss = 4.684772
2018-12-08 02:47:58,222 - INFO - epoch 1, step 35750, training loss = 4.386693, validation loss = 4.913819
2018-12-08 02:48:16,822 - INFO - epoch 1, step 35800, training loss = 3.597855, validation loss = 4.926888
2018-12-08 02:48:35,245 - INFO - epoch 1, step 35850, training loss = 3.665530, validation loss = 4.928589
2018-12-08 02:48:53,371 - INFO - epoch 1, step 35900, training loss = 3.274343, validation loss = 5.533130
2018-12-08 02:49:11,813 - INFO - epoch 1, step 35950, training loss = 3.239201, validation loss = 5.296585
2018-12-08 02:49:30,701 - INFO - epoch 1, step 36000, training loss = 3.167767, validation loss = 5.196251
2018-12-08 02:49:48,725 - INFO - epoch 1, step 36050, training loss = 3.452448, validation loss = 5.190403
2018-12-08 02:50:07,271 - INFO - epoch 1, step 36100, training loss = 3.399837, validation loss = 5.385378
2018-12-08 02:50:25,935 - INFO - epoch 1, step 36150, training loss = 2.876675, validation loss = 5.279661
2018-12-08 02:50:44,039 - INFO - epoch 1, step 36200, training loss = 2.897056, validation loss = 5.720176
2018-12-08 02:51:02,167 - INFO - epoch 1, step 36250, training loss = 3.800376, validation loss = 5.556223
2018-12-08 02:51:20,281 - INFO - epoch 1, step 36300, training loss = 3.244455, validation loss = 5.350939
2018-12-08 02:51:38,689 - INFO - epoch 1, step 36350, training loss = 2.947350, validation loss = 5.520434
2018-12-08 02:51:56,809 - INFO - epoch 1, step 36400, training loss = 3.521889, validation loss = 5.055894
2018-12-08 02:52:14,507 - INFO - epoch 1, step 36450, training loss = 3.239692, validation loss = 4.836885
2018-12-08 02:52:32,924 - INFO - epoch 1, step 36500, training loss = 3.176590, validation loss = 5.515247
2018-12-08 02:52:51,730 - INFO - epoch 1, step 36550, training loss = 3.160011, validation loss = 5.557108
2018-12-08 02:53:10,398 - INFO - epoch 1, step 36600, training loss = 3.100208, validation loss = 5.141799
2018-12-08 02:53:28,888 - INFO - epoch 1, step 36650, training loss = 3.827274, validation loss = 5.777656
2018-12-08 02:53:47,208 - INFO - epoch 1, step 36700, training loss = 3.017493, validation loss = 5.284496
2018-12-08 02:54:05,614 - INFO - epoch 1, step 36750, training loss = 2.797882, validation loss = 5.312961
2018-12-08 02:54:23,212 - INFO - epoch 1, step 36800, training loss = 5.291756, validation loss = 5.192845
2018-12-08 02:54:40,631 - INFO - epoch 1, step 36850, training loss = 5.336328, validation loss = 5.386778
2018-12-08 02:54:57,969 - INFO - epoch 1, step 36900, training loss = 4.729246, validation loss = 5.572037
2018-12-08 02:55:15,054 - INFO - epoch 1, step 36950, training loss = 4.960567, validation loss = 5.513743
2018-12-08 02:55:33,172 - INFO - epoch 1, step 37000, training loss = 4.537702, validation loss = 5.192855
2018-12-08 02:55:50,683 - INFO - epoch 1, step 37050, training loss = 4.583862, validation loss = 5.209460
2018-12-08 02:56:08,309 - INFO - epoch 1, step 37100, training loss = 4.755372, validation loss = 4.424938
2018-12-08 02:56:25,173 - INFO - epoch 1, step 37150, training loss = 4.594671, validation loss = 5.119564
2018-12-08 02:56:42,308 - INFO - epoch 1, step 37200, training loss = 4.907112, validation loss = 4.915023
2018-12-08 02:56:59,990 - INFO - epoch 1, step 37250, training loss = 4.545659, validation loss = 4.859516
2018-12-08 02:57:17,039 - INFO - epoch 1, step 37300, training loss = 5.058647, validation loss = 4.394409
2018-12-08 02:57:33,539 - INFO - epoch 1, step 37350, training loss = 4.795466, validation loss = 5.346304
2018-12-08 02:57:50,513 - INFO - epoch 1, step 37400, training loss = 4.362683, validation loss = 4.966391
2018-12-08 02:58:07,645 - INFO - epoch 1, step 37450, training loss = 4.396448, validation loss = 4.734283
2018-12-08 02:58:24,728 - INFO - epoch 1, step 37500, training loss = 5.062133, validation loss = 5.121594
2018-12-08 02:58:41,974 - INFO - epoch 1, step 37550, training loss = 4.773002, validation loss = 5.240904
2018-12-08 02:58:59,465 - INFO - epoch 1, step 37600, training loss = 4.572822, validation loss = 4.944696
2018-12-08 02:59:16,933 - INFO - epoch 1, step 37650, training loss = 4.940259, validation loss = 4.829229
2018-12-08 02:59:35,011 - INFO - epoch 1, step 37700, training loss = 5.216825, validation loss = 4.822255
2018-12-08 02:59:52,834 - INFO - epoch 1, step 37750, training loss = 5.094129, validation loss = 5.070661
2018-12-08 03:00:09,667 - INFO - epoch 1, step 37800, training loss = 4.685564, validation loss = 4.799802
2018-12-08 03:00:27,954 - INFO - epoch 1, step 37850, training loss = 4.542022, validation loss = 5.023822
2018-12-08 03:00:46,383 - INFO - epoch 1, step 37900, training loss = 4.852089, validation loss = 5.353086
2018-12-08 03:01:03,168 - INFO - epoch 1, step 37950, training loss = 4.307066, validation loss = 5.118853
2018-12-08 03:01:19,756 - INFO - epoch 1, step 38000, training loss = 4.352942, validation loss = 5.433503
2018-12-08 03:01:37,516 - INFO - epoch 1, step 38050, training loss = 5.003107, validation loss = 5.034230
2018-12-08 03:01:54,608 - INFO - epoch 1, step 38100, training loss = 5.020842, validation loss = 4.263691
2018-12-08 03:02:11,152 - INFO - epoch 1, step 38150, training loss = 4.039624, validation loss = 4.889988
2018-12-08 03:02:28,630 - INFO - epoch 1, step 38200, training loss = 4.122030, validation loss = 5.211882
2018-12-08 03:02:46,914 - INFO - epoch 1, step 38250, training loss = 4.313717, validation loss = 4.531251
2018-12-08 03:03:07,887 - INFO - epoch 1, step 38300, training loss = 4.936973, validation loss = 5.065911
2018-12-08 03:03:32,698 - INFO - epoch 1, step 38350, training loss = 4.979338, validation loss = 4.573576
2018-12-08 03:03:59,310 - INFO - epoch 1, step 38400, training loss = 5.485678, validation loss = 4.980411
2018-12-08 03:04:18,089 - INFO - epoch 1, step 38450, training loss = 5.096268, validation loss = 4.587386
2018-12-08 03:04:41,855 - INFO - epoch 1, step 38500, training loss = 5.272735, validation loss = 4.414759
2018-12-08 03:05:05,937 - INFO - epoch 1, step 38550, training loss = 4.701546, validation loss = 4.626720
2018-12-08 03:05:24,171 - INFO - epoch 1, step 38600, training loss = 4.409726, validation loss = 4.682897
2018-12-08 03:05:43,682 - INFO - epoch 1, step 38650, training loss = 4.246654, validation loss = 4.602380
2018-12-08 03:06:03,192 - INFO - epoch 1, step 38700, training loss = 4.632421, validation loss = 4.868000
2018-12-08 03:06:27,426 - INFO - epoch 1, step 38750, training loss = 4.918612, validation loss = 4.774956
2018-12-08 03:06:53,742 - INFO - epoch 1, step 38800, training loss = 4.943461, validation loss = 4.645792
2018-12-08 03:07:19,817 - INFO - epoch 1, step 38850, training loss = 5.413867, validation loss = 4.752799
2018-12-08 03:07:46,026 - INFO - epoch 1, step 38900, training loss = 4.859700, validation loss = 5.365014
2018-12-08 03:08:12,359 - INFO - epoch 1, step 38950, training loss = 4.937484, validation loss = 5.049882
2018-12-08 03:08:34,442 - INFO - epoch 1, step 39000, training loss = 4.983449, validation loss = 4.740696
2018-12-08 03:08:59,569 - INFO - epoch 1, step 39050, training loss = 4.700052, validation loss = 4.328543
2018-12-08 03:09:24,961 - INFO - epoch 1, step 39100, training loss = 4.791636, validation loss = 4.958987
2018-12-08 03:09:45,509 - INFO - epoch 1, step 39150, training loss = 4.587703, validation loss = 4.334550
2018-12-08 03:10:05,776 - INFO - epoch 1, step 39200, training loss = 4.668382, validation loss = 3.726700
2018-12-08 03:10:31,462 - INFO - epoch 1, step 39250, training loss = 4.829386, validation loss = 4.698408
2018-12-08 03:10:57,183 - INFO - epoch 1, step 39300, training loss = 4.925799, validation loss = 4.915941
2018-12-08 03:11:18,919 - INFO - epoch 1, step 39350, training loss = 4.403843, validation loss = 4.404634
2018-12-08 03:11:37,941 - INFO - epoch 1, step 39400, training loss = 5.113872, validation loss = 4.471595
2018-12-08 03:12:04,958 - INFO - epoch 1, step 39450, training loss = 4.821592, validation loss = 4.544901
2018-12-08 03:12:27,057 - INFO - epoch 1, step 39500, training loss = 4.352125, validation loss = 4.162477
2018-12-08 03:12:48,632 - INFO - epoch 1, step 39550, training loss = 4.625038, validation loss = 4.589320
2018-12-08 03:13:14,141 - INFO - epoch 1, step 39600, training loss = 4.953868, validation loss = 4.678692
2018-12-08 03:13:40,291 - INFO - epoch 1, step 39650, training loss = 4.717394, validation loss = 4.949575
2018-12-08 03:14:07,042 - INFO - epoch 1, step 39700, training loss = 5.094916, validation loss = 4.955283
2018-12-08 03:14:30,590 - INFO - epoch 1, step 39750, training loss = 4.481862, validation loss = 4.861510
2018-12-08 03:14:49,538 - INFO - epoch 1, step 39800, training loss = 4.313331, validation loss = 4.566057
2018-12-08 03:15:09,285 - INFO - epoch 1, step 39850, training loss = 4.430444, validation loss = 4.775112
2018-12-08 03:15:32,239 - INFO - epoch 1, step 39900, training loss = 4.192473, validation loss = 4.419978
2018-12-08 03:15:58,139 - INFO - epoch 1, step 39950, training loss = 4.858428, validation loss = 4.574433
2018-12-08 03:16:20,636 - INFO - epoch 1, step 40000, training loss = 4.622200, validation loss = 4.781682
2018-12-08 03:16:39,602 - INFO - epoch 1, step 40050, training loss = 4.805579, validation loss = 4.356502
2018-12-08 03:16:59,481 - INFO - epoch 1, step 40100, training loss = 4.961771, validation loss = 4.363426
2018-12-08 03:17:17,696 - INFO - epoch 1, step 40150, training loss = 4.703082, validation loss = 4.203351
2018-12-08 03:17:36,609 - INFO - epoch 1, step 40200, training loss = 4.553717, validation loss = 4.158439
2018-12-08 03:17:55,832 - INFO - epoch 1, step 40250, training loss = 4.019270, validation loss = 4.064557
2018-12-08 03:18:15,977 - INFO - epoch 1, step 40300, training loss = 4.479647, validation loss = 4.656876
2018-12-08 03:18:35,149 - INFO - epoch 1, step 40350, training loss = 4.799934, validation loss = 4.596933
2018-12-08 03:18:53,874 - INFO - epoch 1, step 40400, training loss = 4.501049, validation loss = 4.136659
2018-12-08 03:19:17,188 - INFO - epoch 1, step 40450, training loss = 4.890444, validation loss = 4.304149
2018-12-08 03:19:35,565 - INFO - epoch 1, step 40500, training loss = 4.442190, validation loss = 4.436275
2018-12-08 03:19:53,908 - INFO - epoch 1, step 40550, training loss = 4.728818, validation loss = 4.234026
2018-12-08 03:20:16,953 - INFO - epoch 1, step 40600, training loss = 4.548112, validation loss = 4.578382
2018-12-08 03:20:42,135 - INFO - epoch 1, step 40650, training loss = 4.973581, validation loss = 4.853068
2018-12-08 03:21:07,146 - INFO - epoch 1, step 40700, training loss = 3.760581, validation loss = 4.690319
2018-12-08 03:21:27,476 - INFO - epoch 1, step 40750, training loss = 4.301651, validation loss = 5.075439
2018-12-08 03:21:47,026 - INFO - epoch 1, step 40800, training loss = 4.448051, validation loss = 5.482694
2018-12-08 03:22:07,229 - INFO - epoch 1, step 40850, training loss = 4.585338, validation loss = 4.634463
2018-12-08 03:22:25,965 - INFO - epoch 1, step 40900, training loss = 4.359232, validation loss = 4.700511
2018-12-08 03:22:44,910 - INFO - epoch 1, step 40950, training loss = 4.636397, validation loss = 4.887267
2018-12-08 03:23:04,668 - INFO - epoch 1, step 41000, training loss = 4.686923, validation loss = 4.810778
2018-12-08 03:23:24,887 - INFO - epoch 1, step 41050, training loss = 4.014148, validation loss = 4.393071
2018-12-08 03:23:44,542 - INFO - epoch 1, step 41100, training loss = 4.852564, validation loss = 4.478154
2018-12-08 03:24:03,779 - INFO - epoch 1, step 41150, training loss = 4.221500, validation loss = 4.901555
2018-12-08 03:24:22,990 - INFO - epoch 1, step 41200, training loss = 4.178559, validation loss = 4.524626
2018-12-08 03:24:42,400 - INFO - epoch 1, step 41250, training loss = 4.515925, validation loss = 4.393952
2018-12-08 03:25:01,171 - INFO - epoch 1, step 41300, training loss = 4.423322, validation loss = 4.386141
2018-12-08 03:25:19,921 - INFO - epoch 1, step 41350, training loss = 4.224784, validation loss = 5.180865
2018-12-08 03:25:42,516 - INFO - epoch 1, step 41400, training loss = 4.617832, validation loss = 4.905427
2018-12-08 03:26:09,356 - INFO - epoch 1, step 41450, training loss = 4.970059, validation loss = 5.244684
2018-12-08 03:26:33,622 - INFO - epoch 1, step 41500, training loss = 4.556194, validation loss = 4.497594
2018-12-08 03:26:53,518 - INFO - epoch 1, step 41550, training loss = 4.866049, validation loss = 4.549675
2018-12-08 03:27:19,297 - INFO - epoch 1, step 41600, training loss = 5.269842, validation loss = 4.804663
2018-12-08 03:27:43,761 - INFO - epoch 1, step 41650, training loss = 3.751549, validation loss = 4.558906
2018-12-08 03:28:03,438 - INFO - epoch 1, step 41700, training loss = 3.766470, validation loss = 4.877251
2018-12-08 03:28:26,030 - INFO - epoch 1, step 41750, training loss = 4.871011, validation loss = 4.690732
2018-12-08 03:28:46,574 - INFO - epoch 1, step 41800, training loss = 4.538015, validation loss = 4.304897
2018-12-08 03:29:05,992 - INFO - epoch 1, step 41850, training loss = 4.419569, validation loss = 4.882849
2018-12-08 03:29:25,330 - INFO - epoch 1, step 41900, training loss = 5.044275, validation loss = 4.599526
2018-12-08 03:29:50,962 - INFO - epoch 1, step 41950, training loss = 4.956273, validation loss = 4.102957
2018-12-08 03:30:15,996 - INFO - epoch 1, step 42000, training loss = 4.532120, validation loss = 4.668079
2018-12-08 03:30:35,194 - INFO - epoch 1, step 42050, training loss = 4.440428, validation loss = 3.878099
2018-12-08 03:30:55,249 - INFO - epoch 1, step 42100, training loss = 4.344485, validation loss = 3.916153
2018-12-08 03:31:18,240 - INFO - epoch 1, step 42150, training loss = 4.886448, validation loss = 4.336498
2018-12-08 03:31:43,274 - INFO - epoch 1, step 42200, training loss = 5.036298, validation loss = 4.752243
2018-12-08 03:32:03,055 - INFO - epoch 1, step 42250, training loss = 4.819493, validation loss = 3.624804
2018-12-08 03:32:21,942 - INFO - epoch 1, step 42300, training loss = 4.281748, validation loss = 3.927294
2018-12-08 03:32:40,975 - INFO - epoch 1, step 42350, training loss = 4.070307, validation loss = 4.059432
2018-12-08 03:33:00,849 - INFO - epoch 1, step 42400, training loss = 3.574784, validation loss = 4.193547
2018-12-08 03:33:25,600 - INFO - epoch 1, step 42450, training loss = 4.820821, validation loss = 4.342427
2018-12-08 03:33:51,100 - INFO - epoch 1, step 42500, training loss = 4.819088, validation loss = 3.567172
2018-12-08 03:34:15,511 - INFO - epoch 1, step 42550, training loss = 5.225412, validation loss = 3.983027
2018-12-08 03:34:34,281 - INFO - epoch 1, step 42600, training loss = 4.631475, validation loss = 4.131490
2018-12-08 03:34:53,311 - INFO - epoch 1, step 42650, training loss = 4.514872, validation loss = 4.561779
2018-12-08 03:35:13,606 - INFO - epoch 1, step 42700, training loss = 3.613516, validation loss = 3.190070
2018-12-08 03:35:34,191 - INFO - epoch 1, step 42750, training loss = 4.623516, validation loss = 3.976505
2018-12-08 03:36:02,330 - INFO - epoch 1, step 42800, training loss = 4.963608, validation loss = 4.429560
2018-12-08 03:36:26,157 - INFO - epoch 1, step 42850, training loss = 4.855085, validation loss = 4.830323
2018-12-08 03:36:44,221 - INFO - epoch 1, step 42900, training loss = 4.919577, validation loss = 5.403893
2018-12-08 03:37:02,678 - INFO - epoch 1, step 42950, training loss = 4.777777, validation loss = 4.151910
2018-12-08 03:37:22,464 - INFO - epoch 1, step 43000, training loss = 4.536763, validation loss = 4.416373
2018-12-08 03:37:46,038 - INFO - epoch 1, step 43050, training loss = 4.484717, validation loss = 3.652549
2018-12-08 03:38:10,051 - INFO - epoch 1, step 43100, training loss = 4.650269, validation loss = 4.229226
2018-12-08 03:38:29,528 - INFO - epoch 1, step 43150, training loss = 4.185293, validation loss = 4.442334
2018-12-08 03:38:49,597 - INFO - epoch 1, step 43200, training loss = 4.302215, validation loss = 4.087478
2018-12-08 03:39:08,854 - INFO - epoch 1, step 43250, training loss = 4.611001, validation loss = 4.099331
2018-12-08 03:39:35,459 - INFO - epoch 1, step 43300, training loss = 4.418667, validation loss = 3.956522
2018-12-08 03:39:56,541 - INFO - epoch 1, step 43350, training loss = 4.653138, validation loss = 4.461918
2018-12-08 03:40:16,490 - INFO - epoch 1, step 43400, training loss = 4.007375, validation loss = 4.368817
2018-12-08 03:40:36,847 - INFO - epoch 1, step 43450, training loss = 4.731993, validation loss = 3.522965
2018-12-08 03:40:56,681 - INFO - epoch 1, step 43500, training loss = 4.420214, validation loss = 4.082131
2018-12-08 03:41:19,372 - INFO - epoch 1, step 43550, training loss = 4.582040, validation loss = 4.080507
2018-12-08 03:41:39,923 - INFO - epoch 1, step 43600, training loss = 4.730411, validation loss = 4.078655
2018-12-08 03:42:00,933 - INFO - epoch 1, step 43650, training loss = 4.758546, validation loss = 4.171855
2018-12-08 03:42:23,263 - INFO - epoch 1, step 43700, training loss = 4.533373, validation loss = 3.957677
2018-12-08 03:42:42,482 - INFO - epoch 1, step 43750, training loss = 4.002490, validation loss = 3.915854
2018-12-08 03:43:05,124 - INFO - epoch 1, step 43800, training loss = 4.506981, validation loss = 4.170169
2018-12-08 03:43:26,357 - INFO - epoch 1, step 43850, training loss = 4.975536, validation loss = 4.154133
2018-12-08 03:43:45,709 - INFO - epoch 1, step 43900, training loss = 4.605925, validation loss = 3.725749
2018-12-08 03:44:05,420 - INFO - epoch 1, step 43950, training loss = 4.036901, validation loss = 3.961505
2018-12-08 03:44:25,878 - INFO - epoch 1, step 44000, training loss = 4.281240, validation loss = 4.219158
2018-12-08 03:44:45,267 - INFO - epoch 1, step 44050, training loss = 4.140816, validation loss = 4.424030
2018-12-08 03:45:05,400 - INFO - epoch 1, step 44100, training loss = 4.025959, validation loss = 4.675462
2018-12-08 03:45:25,781 - INFO - epoch 1, step 44150, training loss = 4.211021, validation loss = 4.700503
2018-12-08 03:45:45,085 - INFO - epoch 1, step 44200, training loss = 4.636229, validation loss = 4.188591
2018-12-08 03:46:04,775 - INFO - epoch 1, step 44250, training loss = 3.834066, validation loss = 4.299130
2018-12-08 03:46:25,076 - INFO - epoch 1, step 44300, training loss = 4.254732, validation loss = 4.202806
2018-12-08 03:46:44,949 - INFO - epoch 1, step 44350, training loss = 4.677846, validation loss = 4.691524
2018-12-08 03:47:03,876 - INFO - epoch 1, step 44400, training loss = 4.771792, validation loss = 3.627070
2018-12-08 03:47:22,254 - INFO - epoch 1, step 44450, training loss = 4.485358, validation loss = 4.241477
2018-12-08 03:47:42,747 - INFO - epoch 1, step 44500, training loss = 4.479846, validation loss = 3.988072
2018-12-08 03:48:05,339 - INFO - epoch 1, step 44550, training loss = 4.473373, validation loss = 4.234486
2018-12-08 03:48:25,731 - INFO - epoch 1, step 44600, training loss = 4.200977, validation loss = 3.780225
2018-12-08 03:48:49,125 - INFO - epoch 1, step 44650, training loss = 4.761369, validation loss = 4.016237
2018-12-08 03:49:14,882 - INFO - epoch 1, step 44700, training loss = 4.493396, validation loss = 3.867159
2018-12-08 03:49:36,282 - INFO - epoch 1, step 44750, training loss = 4.408955, validation loss = 4.614008
2018-12-08 03:49:57,713 - INFO - epoch 1, step 44800, training loss = 4.247351, validation loss = 4.132826
2018-12-08 03:50:18,999 - INFO - epoch 1, step 44850, training loss = 4.772383, validation loss = 3.825980
2018-12-08 03:50:37,028 - INFO - epoch 1, step 44900, training loss = 4.375212, validation loss = 4.257806
2018-12-08 03:50:56,586 - INFO - epoch 1, step 44950, training loss = 4.022422, validation loss = 4.204793
2018-12-08 03:51:19,106 - INFO - epoch 1, step 45000, training loss = 4.580256, validation loss = 3.495610
2018-12-08 03:51:42,556 - INFO - epoch 1, step 45050, training loss = 4.575927, validation loss = 4.257491
2018-12-08 03:52:05,343 - INFO - epoch 1, step 45100, training loss = 3.967305, validation loss = 4.119195
2018-12-08 03:52:24,932 - INFO - epoch 1, step 45150, training loss = 4.368625, validation loss = 4.377698
2018-12-08 03:52:48,603 - INFO - epoch 1, step 45200, training loss = 4.769329, validation loss = 4.890593
2018-12-08 03:53:09,576 - INFO - epoch 1, step 45250, training loss = 4.434384, validation loss = 4.612671
2018-12-08 03:53:31,338 - INFO - epoch 1, step 45300, training loss = 4.424361, validation loss = 4.220964
2018-12-08 03:53:56,802 - INFO - epoch 1, step 45350, training loss = 4.434156, validation loss = 3.889748
2018-12-08 03:54:21,886 - INFO - epoch 1, step 45400, training loss = 4.618947, validation loss = 4.204189
2018-12-08 03:54:47,178 - INFO - epoch 1, step 45450, training loss = 4.418618, validation loss = 3.879428
2018-12-08 03:55:06,618 - INFO - epoch 1, step 45500, training loss = 4.570233, validation loss = 4.191056
2018-12-08 03:55:29,906 - INFO - epoch 1, step 45550, training loss = 4.897121, validation loss = 3.545450
2018-12-08 03:55:48,517 - INFO - epoch 1, step 45600, training loss = 4.726288, validation loss = 4.429450
2018-12-08 03:56:07,169 - INFO - epoch 1, step 45650, training loss = 4.509114, validation loss = 3.864250
2018-12-08 03:56:25,956 - INFO - epoch 1, step 45700, training loss = 4.682843, validation loss = 4.290588
2018-12-08 03:56:44,483 - INFO - epoch 1, step 45750, training loss = 4.439029, validation loss = 4.374335
2018-12-08 03:57:02,961 - INFO - epoch 1, step 45800, training loss = 4.739864, validation loss = 4.344101
2018-12-08 03:57:27,367 - INFO - epoch 1, step 45850, training loss = 4.350049, validation loss = 4.037912
2018-12-08 03:57:53,359 - INFO - epoch 1, step 45900, training loss = 4.926554, validation loss = 4.073515
2018-12-08 03:58:20,337 - INFO - epoch 1, step 45950, training loss = 4.341638, validation loss = 4.093856
2018-12-08 03:58:46,924 - INFO - epoch 1, step 46000, training loss = 4.921225, validation loss = 4.364390
2018-12-08 03:59:08,251 - INFO - epoch 1, step 46050, training loss = 4.589293, validation loss = 4.635227
2018-12-08 03:59:28,148 - INFO - epoch 1, step 46100, training loss = 4.281487, validation loss = 3.725255
2018-12-08 03:59:48,481 - INFO - epoch 1, step 46150, training loss = 3.824192, validation loss = 4.333950
2018-12-08 04:00:07,523 - INFO - epoch 1, step 46200, training loss = 4.297211, validation loss = 4.049884
2018-12-08 04:00:27,157 - INFO - epoch 1, step 46250, training loss = 4.395283, validation loss = 4.649243
2018-12-08 04:00:47,686 - INFO - epoch 1, step 46300, training loss = 4.277177, validation loss = 4.832985
2018-12-08 04:01:06,896 - INFO - epoch 1, step 46350, training loss = 4.370288, validation loss = 4.352131
2018-12-08 04:01:25,527 - INFO - epoch 1, step 46400, training loss = 4.515182, validation loss = 3.900289
2018-12-08 04:01:43,816 - INFO - epoch 1, step 46450, training loss = 4.190710, validation loss = 3.958872
2018-12-08 04:02:07,114 - INFO - epoch 1, step 46500, training loss = 4.376521, validation loss = 3.901465
2018-12-08 04:02:29,159 - INFO - epoch 1, step 46550, training loss = 4.333258, validation loss = 4.620501
2018-12-08 04:02:49,777 - INFO - epoch 1, step 46600, training loss = 4.906056, validation loss = 3.432906
2018-12-08 04:03:16,380 - INFO - epoch 1, step 46650, training loss = 4.385619, validation loss = 3.928016
2018-12-08 04:03:34,856 - INFO - epoch 1, step 46700, training loss = 4.583153, validation loss = 4.143397
2018-12-08 04:03:54,788 - INFO - epoch 1, step 46750, training loss = 3.633723, validation loss = 3.910759
2018-12-08 04:04:14,808 - INFO - epoch 1, step 46800, training loss = 4.425819, validation loss = 3.640847
2018-12-08 04:04:33,736 - INFO - epoch 1, step 46850, training loss = 4.668488, validation loss = 3.873216
2018-12-08 04:04:52,400 - INFO - epoch 1, step 46900, training loss = 4.238328, validation loss = 4.407183
2018-12-08 04:05:17,277 - INFO - epoch 1, step 46950, training loss = 4.679785, validation loss = 3.804540
2018-12-08 04:05:44,415 - INFO - epoch 1, step 47000, training loss = 5.032193, validation loss = 4.248074
2018-12-08 04:06:08,934 - INFO - epoch 1, step 47050, training loss = 4.465775, validation loss = 4.451292
2018-12-08 04:06:30,372 - INFO - epoch 1, step 47100, training loss = 4.207713, validation loss = 4.539351
2018-12-08 04:06:51,491 - INFO - epoch 1, step 47150, training loss = 4.273066, validation loss = 4.079125
2018-12-08 04:07:11,414 - INFO - epoch 1, step 47200, training loss = 3.389549, validation loss = 4.013532
2018-12-08 04:07:26,907 - INFO - epoch 1, step 47250, training loss = 2.827344, validation loss = 4.048054
2018-12-08 04:07:45,209 - INFO - epoch 1, step 47300, training loss = 3.091181, validation loss = 5.084745
2018-12-08 04:08:04,135 - INFO - epoch 1, step 47350, training loss = 2.756230, validation loss = 4.271110
2018-12-08 04:08:19,804 - INFO - epoch 1, step 47400, training loss = 2.783582, validation loss = 4.470017
2018-12-08 04:08:36,736 - INFO - epoch 1, step 47450, training loss = 2.868710, validation loss = 4.782225
2018-12-08 04:08:55,280 - INFO - epoch 1, step 47500, training loss = 2.682806, validation loss = 5.134450
2018-12-08 04:09:13,183 - INFO - epoch 1, step 47550, training loss = 3.091866, validation loss = 4.963531
2018-12-08 04:09:30,566 - INFO - epoch 1, step 47600, training loss = 2.882843, validation loss = 4.410583
2018-12-08 04:09:46,984 - INFO - epoch 1, step 47650, training loss = 2.920349, validation loss = 4.450552
2018-12-08 04:10:02,174 - INFO - epoch 1, step 47700, training loss = 2.980696, validation loss = 4.888263
2018-12-08 04:10:18,501 - INFO - epoch 1, step 47750, training loss = 2.992705, validation loss = 4.265599
2018-12-08 04:10:35,840 - INFO - epoch 1, step 47800, training loss = 2.985397, validation loss = 4.445541
2018-12-08 04:10:54,763 - INFO - epoch 1, step 47850, training loss = 2.550137, validation loss = 4.328413
2018-12-08 04:11:16,077 - INFO - epoch 1, step 47900, training loss = 3.025551, validation loss = 4.461280
2018-12-08 04:11:37,839 - INFO - epoch 1, step 47950, training loss = 3.159356, validation loss = 4.486840
2018-12-08 04:11:57,870 - INFO - epoch 1, step 48000, training loss = 2.882849, validation loss = 4.267744
2018-12-08 04:12:14,854 - INFO - epoch 1, step 48050, training loss = 2.738877, validation loss = 4.181967
2018-12-08 04:12:30,820 - INFO - epoch 1, step 48100, training loss = 2.847640, validation loss = 4.775786
2018-12-08 04:12:47,836 - INFO - epoch 1, step 48150, training loss = 2.736331, validation loss = 4.401045
2018-12-08 04:13:07,974 - INFO - epoch 1, step 48200, training loss = 2.387586, validation loss = 4.432304
2018-12-08 04:13:28,338 - INFO - epoch 1, step 48250, training loss = 2.654924, validation loss = 4.429949
2018-12-08 04:13:47,303 - INFO - epoch 1, step 48300, training loss = 2.500490, validation loss = 4.490309
2018-12-08 04:14:08,233 - INFO - epoch 1, step 48350, training loss = 2.918494, validation loss = 4.151353
2018-12-08 04:14:29,605 - INFO - epoch 1, step 48400, training loss = 2.839757, validation loss = 4.687944
2018-12-08 04:14:49,799 - INFO - epoch 1, step 48450, training loss = 2.747455, validation loss = 4.437075
2018-12-08 04:15:06,944 - INFO - epoch 1, step 48500, training loss = 2.916020, validation loss = 4.918012
2018-12-08 04:15:22,383 - INFO - epoch 1, step 48550, training loss = 2.836688, validation loss = 5.218909
2018-12-08 04:15:38,596 - INFO - epoch 1, step 48600, training loss = 2.497823, validation loss = 4.778709
2018-12-08 04:15:56,456 - INFO - epoch 1, step 48650, training loss = 2.774598, validation loss = 4.419986
2018-12-08 04:16:16,174 - INFO - epoch 1, step 48700, training loss = 2.661482, validation loss = 4.455287
2018-12-08 04:16:36,026 - INFO - epoch 1, step 48750, training loss = 2.476384, validation loss = 4.422986
2018-12-08 04:16:56,361 - INFO - epoch 1, step 48800, training loss = 2.238939, validation loss = 4.751815
2018-12-08 04:17:16,965 - INFO - epoch 1, step 48850, training loss = 3.092762, validation loss = 3.647051
2018-12-08 04:17:35,812 - INFO - epoch 1, step 48900, training loss = 2.780792, validation loss = 4.131185
2018-12-08 04:17:54,135 - INFO - epoch 1, step 48950, training loss = 2.659734, validation loss = 4.185254
2018-12-08 04:18:11,374 - INFO - epoch 1, step 49000, training loss = 2.643983, validation loss = 4.926695
2018-12-08 04:18:27,372 - INFO - epoch 1, step 49050, training loss = 2.387504, validation loss = 4.629167
2018-12-08 04:18:46,159 - INFO - epoch 1, step 49100, training loss = 2.479564, validation loss = 4.186421
2018-12-08 04:19:03,987 - INFO - epoch 1, step 49150, training loss = 2.542211, validation loss = 4.398066
2018-12-08 04:19:21,410 - INFO - epoch 1, step 49200, training loss = 2.654085, validation loss = 4.490136
2018-12-08 04:19:41,542 - INFO - epoch 1, step 49250, training loss = 2.455925, validation loss = 4.885731
2018-12-08 04:19:59,877 - INFO - epoch 1, step 49300, training loss = 2.506453, validation loss = 3.980785
2018-12-08 04:20:16,386 - INFO - epoch 1, step 49350, training loss = 2.821889, validation loss = 4.153760
2018-12-08 04:20:32,711 - INFO - epoch 1, step 49400, training loss = 2.710969, validation loss = 4.467199
2018-12-08 04:20:47,601 - INFO - epoch 1, step 49450, training loss = 2.972517, validation loss = 4.950564
2018-12-08 04:21:04,345 - INFO - epoch 1, step 49500, training loss = 2.558041, validation loss = 4.604260
2018-12-08 04:21:19,609 - INFO - epoch 1, step 49550, training loss = 2.843273, validation loss = 4.295114
2018-12-08 04:21:36,134 - INFO - epoch 1, step 49600, training loss = 2.231454, validation loss = 4.890897
2018-12-08 04:21:54,960 - INFO - epoch 1, step 49650, training loss = 2.352324, validation loss = 4.935876
2018-12-08 04:22:16,346 - INFO - epoch 1, step 49700, training loss = 2.913889, validation loss = 4.958002
2018-12-08 04:22:37,460 - INFO - epoch 1, step 49750, training loss = 2.664171, validation loss = 5.156391
2018-12-08 04:22:57,231 - INFO - epoch 1, step 49800, training loss = 3.058727, validation loss = 4.403693
2018-12-08 04:23:13,123 - INFO - epoch 1, step 49850, training loss = 2.471824, validation loss = 4.438305
2018-12-08 04:23:30,708 - INFO - epoch 1, step 49900, training loss = 2.796522, validation loss = 4.810509
2018-12-08 04:23:49,718 - INFO - epoch 1, step 49950, training loss = 2.260991, validation loss = 4.115847
2018-12-08 04:24:09,703 - INFO - epoch 1, step 50000, training loss = 2.550157, validation loss = 4.088390
2018-12-08 04:24:29,854 - INFO - epoch 1, step 50050, training loss = 2.360710, validation loss = 4.208564
2018-12-08 04:24:49,026 - INFO - epoch 1, step 50100, training loss = 2.799814, validation loss = 4.591711
2018-12-08 04:25:05,868 - INFO - epoch 1, step 50150, training loss = 2.038167, validation loss = 3.601322
2018-12-08 04:25:26,196 - INFO - epoch 1, step 50200, training loss = 2.524879, validation loss = 4.410796
2018-12-08 04:25:46,592 - INFO - epoch 1, step 50250, training loss = 3.100214, validation loss = 4.211386
2018-12-08 04:26:07,390 - INFO - epoch 1, step 50300, training loss = 2.687619, validation loss = 4.355053
2018-12-08 04:26:28,052 - INFO - epoch 1, step 50350, training loss = 2.623096, validation loss = 4.265625
2018-12-08 04:26:48,683 - INFO - epoch 1, step 50400, training loss = 2.559055, validation loss = 3.844603
2018-12-08 04:27:06,806 - INFO - epoch 1, step 50450, training loss = 2.559274, validation loss = 4.120585
2018-12-08 04:27:23,337 - INFO - epoch 1, step 50500, training loss = 2.986745, validation loss = 4.339850
2018-12-08 04:27:38,766 - INFO - epoch 1, step 50550, training loss = 2.931501, validation loss = 4.785532
2018-12-08 04:27:58,667 - INFO - epoch 1, step 50600, training loss = 2.630324, validation loss = 4.454379
2018-12-08 04:28:18,772 - INFO - epoch 1, step 50650, training loss = 2.488413, validation loss = 4.566598
2018-12-08 04:28:38,870 - INFO - epoch 1, step 50700, training loss = 2.729671, validation loss = 4.635732
2018-12-08 04:28:55,956 - INFO - epoch 1, step 50750, training loss = 2.380002, validation loss = 5.493667
2018-12-08 04:29:12,230 - INFO - epoch 1, step 50800, training loss = 2.743134, validation loss = 4.998480
2018-12-08 04:29:28,928 - INFO - epoch 1, step 50850, training loss = 2.124342, validation loss = 4.927509
2018-12-08 04:29:46,812 - INFO - epoch 1, step 50900, training loss = 2.336789, validation loss = 4.155158
2018-12-08 04:30:03,787 - INFO - epoch 1, step 50950, training loss = 2.570124, validation loss = 4.724852
2018-12-08 04:30:20,340 - INFO - epoch 1, step 51000, training loss = 2.937593, validation loss = 4.659380
2018-12-08 04:30:36,892 - INFO - epoch 1, step 51050, training loss = 2.645291, validation loss = 4.541203
2018-12-08 04:30:56,105 - INFO - epoch 1, step 51100, training loss = 2.673714, validation loss = 4.231478
2018-12-08 04:31:14,890 - INFO - epoch 1, step 51150, training loss = 2.560470, validation loss = 4.776289
2018-12-08 04:31:32,891 - INFO - epoch 1, step 51200, training loss = 2.367673, validation loss = 4.345978
2018-12-08 04:31:49,977 - INFO - epoch 1, step 51250, training loss = 2.404892, validation loss = 3.916584
2018-12-08 04:32:06,254 - INFO - epoch 1, step 51300, training loss = 2.702333, validation loss = 4.095767
2018-12-08 04:32:21,206 - INFO - epoch 1, step 51350, training loss = 2.649543, validation loss = 4.689042
2018-12-08 04:32:36,473 - INFO - epoch 1, step 51400, training loss = 2.750030, validation loss = 5.645980
2018-12-08 04:32:54,386 - INFO - epoch 1, step 51450, training loss = 2.348905, validation loss = 5.180519
2018-12-08 04:33:14,372 - INFO - epoch 1, step 51500, training loss = 2.451582, validation loss = 5.052659
2018-12-08 04:33:33,901 - INFO - epoch 1, step 51550, training loss = 2.287072, validation loss = 5.546738
2018-12-08 04:33:52,566 - INFO - epoch 1, step 51600, training loss = 2.638174, validation loss = 5.192306
2018-12-08 04:34:11,367 - INFO - epoch 1, step 51650, training loss = 2.465716, validation loss = 5.311746
2018-12-08 04:34:29,483 - INFO - epoch 1, step 51700, training loss = 2.367363, validation loss = 5.184056
2018-12-08 04:34:49,677 - INFO - epoch 1, step 51750, training loss = 2.467580, validation loss = 4.838428
2018-12-08 04:35:10,645 - INFO - epoch 1, step 51800, training loss = 2.419929, validation loss = 4.947535
2018-12-08 04:35:31,078 - INFO - epoch 1, step 51850, training loss = 2.771205, validation loss = 5.898566
2018-12-08 04:35:46,390 - INFO - epoch 1, step 51900, training loss = 2.367605, validation loss = 4.821228
2018-12-08 04:36:01,944 - INFO - epoch 1, step 51950, training loss = 2.304734, validation loss = 5.796534
2018-12-08 04:36:18,634 - INFO - epoch 1, step 52000, training loss = 2.725753, validation loss = 5.136543
2018-12-08 04:36:38,107 - INFO - epoch 1, step 52050, training loss = 2.721163, validation loss = 5.154348
2018-12-08 04:36:58,259 - INFO - epoch 1, step 52100, training loss = 2.712477, validation loss = 5.179789
2018-12-08 04:37:17,775 - INFO - epoch 1, step 52150, training loss = 2.220552, validation loss = 5.458360
2018-12-08 04:37:33,440 - INFO - epoch 1, step 52200, training loss = 2.697169, validation loss = 5.477527
2018-12-08 04:37:48,998 - INFO - epoch 1, step 52250, training loss = 2.986850, validation loss = 5.713215
2018-12-08 04:38:05,199 - INFO - epoch 1, step 52300, training loss = 2.492934, validation loss = 5.323330
2018-12-08 04:38:26,350 - INFO - epoch 1, step 52350, training loss = 2.481024, validation loss = 5.264950
2018-12-08 04:38:44,686 - INFO - epoch 1, step 52400, training loss = 2.728516, validation loss = 5.259862
2018-12-08 04:39:00,146 - INFO - epoch 1, step 52450, training loss = 2.922051, validation loss = 5.442407
2018-12-08 04:39:16,028 - INFO - epoch 1, step 52500, training loss = 2.681640, validation loss = 5.054959
2018-12-08 04:39:34,137 - INFO - epoch 1, step 52550, training loss = 2.610755, validation loss = 5.159901
2018-12-08 04:39:53,198 - INFO - epoch 1, step 52600, training loss = 2.792176, validation loss = 5.435717
2018-12-08 04:40:09,679 - INFO - epoch 1, step 52650, training loss = 2.532164, validation loss = 4.922774
2018-12-08 04:40:28,732 - INFO - epoch 1, step 52700, training loss = 2.484801, validation loss = 5.529857
2018-12-08 04:40:49,047 - INFO - epoch 1, step 52750, training loss = 2.300176, validation loss = 5.817817
2018-12-08 04:41:09,504 - INFO - epoch 1, step 52800, training loss = 2.605791, validation loss = 5.392944
2018-12-08 04:41:30,731 - INFO - epoch 1, step 52850, training loss = 2.477183, validation loss = 4.950247
2018-12-08 04:41:48,305 - INFO - epoch 1, step 52900, training loss = 2.518730, validation loss = 5.279192
2018-12-08 04:42:03,501 - INFO - epoch 1, step 52950, training loss = 2.575326, validation loss = 5.624411
2018-12-08 04:42:19,009 - INFO - epoch 1, step 53000, training loss = 2.626210, validation loss = 5.392303
2018-12-08 04:42:35,784 - INFO - epoch 1, step 53050, training loss = 2.333656, validation loss = 5.452317
2018-12-08 04:42:53,577 - INFO - epoch 1, step 53100, training loss = 2.293250, validation loss = 5.626791
2018-12-08 04:43:12,060 - INFO - epoch 1, step 53150, training loss = 2.464071, validation loss = 5.364573
2018-12-08 04:43:27,837 - INFO - epoch 1, step 53200, training loss = 2.408501, validation loss = 4.704716
2018-12-08 04:43:44,214 - INFO - epoch 1, step 53250, training loss = 2.817688, validation loss = 5.255248
2018-12-08 04:44:02,876 - INFO - epoch 1, step 53300, training loss = 2.397303, validation loss = 5.262101
2018-12-08 04:44:22,860 - INFO - epoch 1, step 53350, training loss = 2.420934, validation loss = 4.728238
2018-12-08 04:44:43,708 - INFO - epoch 1, step 53400, training loss = 2.452403, validation loss = 4.986439
2018-12-08 04:45:05,114 - INFO - epoch 1, step 53450, training loss = 2.911427, validation loss = 4.996798
2018-12-08 04:45:24,694 - INFO - epoch 1, step 53500, training loss = 2.517226, validation loss = 4.427676
2018-12-08 04:45:41,439 - INFO - epoch 1, step 53550, training loss = 2.763287, validation loss = 4.811497
2018-12-08 04:45:57,258 - INFO - epoch 1, step 53600, training loss = 2.636335, validation loss = 5.455554
2018-12-08 04:46:15,212 - INFO - epoch 1, step 53650, training loss = 2.807007, validation loss = 5.046568
2018-12-08 04:46:33,881 - INFO - epoch 1, step 53700, training loss = 2.679732, validation loss = 5.467641
2018-12-08 04:46:53,704 - INFO - epoch 1, step 53750, training loss = 2.312080, validation loss = 5.084435
2018-12-08 04:47:12,187 - INFO - epoch 1, step 53800, training loss = 2.450063, validation loss = 5.362062
2018-12-08 04:47:28,259 - INFO - epoch 1, step 53850, training loss = 2.659147, validation loss = 5.534110
2018-12-08 04:47:43,347 - INFO - epoch 1, step 53900, training loss = 2.699128, validation loss = 4.834242
2018-12-08 04:47:58,943 - INFO - epoch 1, step 53950, training loss = 1.962045, validation loss = 5.168504
2018-12-08 04:48:16,212 - INFO - epoch 1, step 54000, training loss = 2.246991, validation loss = 4.869066
2018-12-08 04:48:38,044 - INFO - epoch 1, step 54050, training loss = 2.604088, validation loss = 5.316878
2018-12-08 04:48:55,808 - INFO - epoch 1, step 54100, training loss = 2.548855, validation loss = 4.854713
2018-12-08 04:49:10,942 - INFO - epoch 1, step 54150, training loss = 2.544701, validation loss = 5.248188
2018-12-08 04:49:26,652 - INFO - epoch 1, step 54200, training loss = 2.523902, validation loss = 4.680607
2018-12-08 04:49:44,450 - INFO - epoch 1, step 54250, training loss = 2.710953, validation loss = 5.026764
2018-12-08 04:50:04,252 - INFO - epoch 1, step 54300, training loss = 2.279984, validation loss = 5.675893
2018-12-08 04:50:20,627 - INFO - epoch 1, step 54350, training loss = 2.466324, validation loss = 5.317253
2018-12-08 04:50:36,512 - INFO - epoch 1, step 54400, training loss = 2.951385, validation loss = 5.640777
2018-12-08 04:50:53,113 - INFO - epoch 1, step 54450, training loss = 2.717346, validation loss = 5.260918
2018-12-08 04:51:14,261 - INFO - epoch 1, step 54500, training loss = 1.976633, validation loss = 4.670342
2018-12-08 04:51:32,613 - INFO - epoch 1, step 54550, training loss = 2.582395, validation loss = 4.714373
2018-12-08 04:51:49,932 - INFO - epoch 1, step 54600, training loss = 2.404273, validation loss = 5.195590
2018-12-08 04:52:08,489 - INFO - epoch 1, step 54650, training loss = 2.693087, validation loss = 5.334370
2018-12-08 04:52:27,915 - INFO - epoch 1, step 54700, training loss = 2.826070, validation loss = 4.853414
2018-12-08 04:52:47,023 - INFO - epoch 1, step 54750, training loss = 2.403606, validation loss = 4.888803
2018-12-08 04:53:02,620 - INFO - epoch 1, step 54800, training loss = 2.387085, validation loss = 5.343540
2018-12-08 04:53:21,836 - INFO - epoch 1, step 54850, training loss = 2.669538, validation loss = 5.235451
2018-12-08 04:53:43,518 - INFO - epoch 1, step 54900, training loss = 2.124304, validation loss = 5.162664
2018-12-08 04:54:04,001 - INFO - epoch 1, step 54950, training loss = 2.204242, validation loss = 5.718839
2018-12-08 04:54:24,082 - INFO - epoch 1, step 55000, training loss = 2.228945, validation loss = 5.265035
2018-12-08 04:54:44,333 - INFO - epoch 1, step 55050, training loss = 2.427924, validation loss = 5.190311
2018-12-08 04:55:03,960 - INFO - epoch 1, step 55100, training loss = 2.347950, validation loss = 4.620004
2018-12-08 04:55:23,223 - INFO - epoch 1, step 55150, training loss = 2.610518, validation loss = 5.216727
2018-12-08 04:55:40,426 - INFO - epoch 1, step 55200, training loss = 2.414625, validation loss = 4.934965
2018-12-08 04:56:00,292 - INFO - epoch 1, step 55250, training loss = 2.428220, validation loss = 5.185274
2018-12-08 04:56:21,609 - INFO - epoch 1, step 55300, training loss = 2.616477, validation loss = 4.721955
2018-12-08 04:56:43,126 - INFO - epoch 1, step 55350, training loss = 2.389040, validation loss = 5.337466
2018-12-08 04:57:01,637 - INFO - epoch 1, step 55400, training loss = 2.780311, validation loss = 5.508686
2018-12-08 04:57:16,985 - INFO - epoch 1, step 55450, training loss = 2.436133, validation loss = 4.946222
2018-12-08 04:57:35,598 - INFO - epoch 1, step 55500, training loss = 2.493593, validation loss = 5.104758
2018-12-08 04:57:53,767 - INFO - epoch 1, step 55550, training loss = 2.806905, validation loss = 4.932281
2018-12-08 04:58:10,588 - INFO - epoch 1, step 55600, training loss = 2.740406, validation loss = 5.374199
2018-12-08 04:58:31,807 - INFO - epoch 1, step 55650, training loss = 2.379585, validation loss = 4.578770
2018-12-08 04:58:52,386 - INFO - epoch 1, step 55700, training loss = 2.385746, validation loss = 4.609433
2018-12-08 04:59:12,399 - INFO - epoch 1, step 55750, training loss = 2.609848, validation loss = 4.568672
2018-12-08 04:59:30,179 - INFO - epoch 1, step 55800, training loss = 2.376683, validation loss = 5.070224
2018-12-08 04:59:48,790 - INFO - epoch 1, step 55850, training loss = 2.597664, validation loss = 5.081637
2018-12-08 05:00:09,840 - INFO - epoch 1, step 55900, training loss = 2.165027, validation loss = 5.187474
2018-12-08 05:00:29,562 - INFO - epoch 1, step 55950, training loss = 2.306994, validation loss = 5.290826
2018-12-08 05:00:49,054 - INFO - epoch 1, step 56000, training loss = 2.456116, validation loss = 5.210696
2018-12-08 05:01:07,721 - INFO - epoch 1, step 56050, training loss = 2.506868, validation loss = 5.269122
2018-12-08 05:01:25,235 - INFO - epoch 1, step 56100, training loss = 2.405638, validation loss = 5.079525
2018-12-08 05:01:46,127 - INFO - epoch 1, step 56150, training loss = 3.170501, validation loss = 5.249097
2018-12-08 05:02:05,924 - INFO - epoch 1, step 56200, training loss = 2.654226, validation loss = 4.790533
2018-12-08 05:02:21,039 - INFO - epoch 1, step 56250, training loss = 2.540428, validation loss = 5.444646
2018-12-08 05:02:36,403 - INFO - epoch 1, step 56300, training loss = 2.395663, validation loss = 5.319799
2018-12-08 05:02:53,096 - INFO - epoch 1, step 56350, training loss = 2.449036, validation loss = 4.798073
2018-12-08 05:03:13,049 - INFO - epoch 1, step 56400, training loss = 2.947128, validation loss = 2.561434
2018-12-08 05:03:33,130 - INFO - epoch 1, step 56450, training loss = 2.728402, validation loss = 2.269739
2018-12-08 05:03:54,397 - INFO - epoch 1, step 56500, training loss = 2.362510, validation loss = 2.732415
2018-12-08 05:04:14,981 - INFO - epoch 1, step 56550, training loss = 2.949344, validation loss = 2.536277
2018-12-08 05:04:31,761 - INFO - epoch 1, step 56600, training loss = 2.506113, validation loss = 2.790159
2018-12-08 05:04:48,845 - INFO - epoch 1, step 56650, training loss = 2.782916, validation loss = 2.894003
2018-12-08 05:05:05,371 - INFO - epoch 1, step 56700, training loss = 2.786205, validation loss = 2.330597
2018-12-08 05:05:25,672 - INFO - epoch 1, step 56750, training loss = 2.567254, validation loss = 2.611679
2018-12-08 05:05:44,100 - INFO - epoch 1, step 56800, training loss = 2.431149, validation loss = 2.310014
2018-12-08 05:06:01,821 - INFO - epoch 1, step 56850, training loss = 2.579437, validation loss = 2.755174
2018-12-08 05:06:17,741 - INFO - epoch 1, step 56900, training loss = 2.334584, validation loss = 2.559491
2018-12-08 05:06:33,929 - INFO - epoch 1, step 56950, training loss = 2.546205, validation loss = 2.521935
2018-12-08 05:06:51,587 - INFO - epoch 1, step 57000, training loss = 2.274383, validation loss = 2.914443
2018-12-08 05:07:12,625 - INFO - epoch 1, step 57050, training loss = 2.009853, validation loss = 2.448815
2018-12-08 05:07:32,297 - INFO - epoch 1, step 57100, training loss = 2.543091, validation loss = 2.643734
2018-12-08 05:07:51,055 - INFO - epoch 1, step 57150, training loss = 2.396891, validation loss = 2.645204
2018-12-08 05:08:11,339 - INFO - epoch 1, step 57200, training loss = 2.410595, validation loss = 2.123134
2018-12-08 05:08:32,025 - INFO - epoch 1, step 57250, training loss = 2.257072, validation loss = 2.763210
2018-12-08 05:08:51,731 - INFO - epoch 1, step 57300, training loss = 2.360966, validation loss = 2.699230
2018-12-08 05:09:09,244 - INFO - epoch 1, step 57350, training loss = 2.148828, validation loss = 2.834240
2018-12-08 05:09:25,436 - INFO - epoch 1, step 57400, training loss = 2.387858, validation loss = 2.537403
2018-12-08 05:09:41,253 - INFO - epoch 1, step 57450, training loss = 2.352009, validation loss = 2.649284
2018-12-08 05:09:56,650 - INFO - epoch 1, step 57500, training loss = 2.246301, validation loss = 2.777348
2018-12-08 05:10:12,373 - INFO - epoch 1, step 57550, training loss = 2.558516, validation loss = 2.333911
2018-12-08 05:10:27,953 - INFO - epoch 1, step 57600, training loss = 2.337426, validation loss = 2.398315
2018-12-08 05:10:43,445 - INFO - epoch 1, step 57650, training loss = 2.541547, validation loss = 2.757545
2018-12-08 05:11:03,677 - INFO - epoch 1, step 57700, training loss = 3.026372, validation loss = 2.936292
2018-12-08 05:11:22,416 - INFO - epoch 1, step 57750, training loss = 2.778267, validation loss = 2.487972
2018-12-08 05:11:40,745 - INFO - epoch 1, step 57800, training loss = 2.327053, validation loss = 2.939678
2018-12-08 05:11:59,815 - INFO - epoch 1, step 57850, training loss = 2.797384, validation loss = 2.566219
2018-12-08 05:12:20,212 - INFO - epoch 1, step 57900, training loss = 2.445461, validation loss = 2.638322
2018-12-08 05:12:40,529 - INFO - epoch 1, step 57950, training loss = 2.172734, validation loss = 2.746670
2018-12-08 05:13:00,782 - INFO - epoch 1, step 58000, training loss = 2.347064, validation loss = 2.659425
2018-12-08 05:13:20,913 - INFO - epoch 1, step 58050, training loss = 2.144115, validation loss = 2.920109
2018-12-08 05:13:39,841 - INFO - epoch 1, step 58100, training loss = 2.200758, validation loss = 2.813950
2018-12-08 05:13:56,679 - INFO - epoch 1, step 58150, training loss = 2.529735, validation loss = 2.848792
2018-12-08 05:14:11,801 - INFO - epoch 1, step 58200, training loss = 2.700065, validation loss = 2.662614
2018-12-08 05:14:30,657 - INFO - epoch 1, step 58250, training loss = 2.346559, validation loss = 2.856380
2018-12-08 05:14:50,698 - INFO - epoch 1, step 58300, training loss = 1.967892, validation loss = 2.659944
2018-12-08 05:15:10,985 - INFO - epoch 1, step 58350, training loss = 2.493922, validation loss = 2.528134
2018-12-08 05:15:30,837 - INFO - epoch 1, step 58400, training loss = 2.780916, validation loss = 2.578785
2018-12-08 05:15:48,602 - INFO - epoch 1, step 58450, training loss = 2.283054, validation loss = 2.629347
2018-12-08 05:16:06,509 - INFO - epoch 1, step 58500, training loss = 2.769252, validation loss = 2.972225
2018-12-08 05:16:24,413 - INFO - epoch 1, step 58550, training loss = 2.399318, validation loss = 2.526939
2018-12-08 05:16:44,303 - INFO - epoch 1, step 58600, training loss = 2.422409, validation loss = 2.710719
2018-12-08 05:17:01,758 - INFO - epoch 1, step 58650, training loss = 2.635519, validation loss = 2.506060
2018-12-08 05:17:17,692 - INFO - epoch 1, step 58700, training loss = 2.729570, validation loss = 2.673880
2018-12-08 05:17:37,704 - INFO - epoch 1, step 58750, training loss = 1.928330, validation loss = 2.872374
2018-12-08 05:17:58,511 - INFO - epoch 1, step 58800, training loss = 2.180131, validation loss = 2.761455
2018-12-08 05:18:17,823 - INFO - epoch 1, step 58850, training loss = 2.226320, validation loss = 2.653957
2018-12-08 05:18:38,025 - INFO - epoch 1, step 58900, training loss = 2.486780, validation loss = 2.738397
2018-12-08 05:18:56,646 - INFO - epoch 1, step 58950, training loss = 2.386299, validation loss = 2.566922
2018-12-08 05:19:12,684 - INFO - epoch 1, step 59000, training loss = 2.541103, validation loss = 2.759463
2018-12-08 05:19:31,888 - INFO - epoch 1, step 59050, training loss = 2.568592, validation loss = 2.572764
2018-12-08 05:19:50,231 - INFO - epoch 1, step 59100, training loss = 2.284056, validation loss = 2.414098
2018-12-08 05:20:07,630 - INFO - epoch 1, step 59150, training loss = 1.995618, validation loss = 2.473379
2018-12-08 05:20:25,632 - INFO - epoch 1, step 59200, training loss = 2.034364, validation loss = 2.723832
2018-12-08 05:20:45,615 - INFO - epoch 1, step 59250, training loss = 1.827772, validation loss = 2.375609
2018-12-08 05:21:06,458 - INFO - epoch 1, step 59300, training loss = 2.244112, validation loss = 2.468805
2018-12-08 05:21:27,937 - INFO - epoch 1, step 59350, training loss = 2.232062, validation loss = 2.562577
2018-12-08 05:21:44,894 - INFO - epoch 1, step 59400, training loss = 2.501579, validation loss = 2.924366
2018-12-08 05:21:57,005 - INFO - Model saved in dir ./models
2018-12-08 05:22:14,536 - INFO - epoch 2, step 50, training loss = 3.454353, validation loss = 2.439299
2018-12-08 05:22:32,383 - INFO - epoch 2, step 100, training loss = 2.676147, validation loss = 2.566964
2018-12-08 05:22:50,253 - INFO - epoch 2, step 150, training loss = 3.248758, validation loss = 2.744731
2018-12-08 05:23:10,000 - INFO - epoch 2, step 200, training loss = 2.912381, validation loss = 2.779274
2018-12-08 05:23:29,579 - INFO - epoch 2, step 250, training loss = 2.852319, validation loss = 2.594281
2018-12-08 05:23:49,275 - INFO - epoch 2, step 300, training loss = 3.062302, validation loss = 2.441685
2018-12-08 05:24:07,839 - INFO - epoch 2, step 350, training loss = 3.128187, validation loss = 2.772144
2018-12-08 05:24:26,645 - INFO - epoch 2, step 400, training loss = 2.762010, validation loss = 2.450899
2018-12-08 05:24:45,738 - INFO - epoch 2, step 450, training loss = 3.362664, validation loss = 2.461271
2018-12-08 05:25:05,410 - INFO - epoch 2, step 500, training loss = 3.422226, validation loss = 2.928785
2018-12-08 05:25:24,702 - INFO - epoch 2, step 550, training loss = 3.120962, validation loss = 2.566714
2018-12-08 05:25:43,823 - INFO - epoch 2, step 600, training loss = 2.845575, validation loss = 2.491548
2018-12-08 05:26:03,362 - INFO - epoch 2, step 650, training loss = 3.060575, validation loss = 2.597847
2018-12-08 05:26:22,702 - INFO - epoch 2, step 700, training loss = 2.953745, validation loss = 2.478600
2018-12-08 05:26:42,231 - INFO - epoch 2, step 750, training loss = 3.235439, validation loss = 2.586855
2018-12-08 05:27:02,541 - INFO - epoch 2, step 800, training loss = 3.439979, validation loss = 2.481238
2018-12-08 05:27:23,452 - INFO - epoch 2, step 850, training loss = 3.102496, validation loss = 2.399568
2018-12-08 05:27:43,820 - INFO - epoch 2, step 900, training loss = 3.662569, validation loss = 2.767842
2018-12-08 05:28:04,785 - INFO - epoch 2, step 950, training loss = 2.620821, validation loss = 2.645782
2018-12-08 05:28:25,329 - INFO - epoch 2, step 1000, training loss = 3.177055, validation loss = 2.755681
2018-12-08 05:28:45,172 - INFO - epoch 2, step 1050, training loss = 2.867704, validation loss = 2.236890
2018-12-08 05:29:04,742 - INFO - epoch 2, step 1100, training loss = 2.842264, validation loss = 2.605642
2018-12-08 05:29:24,503 - INFO - epoch 2, step 1150, training loss = 2.953159, validation loss = 2.277445
2018-12-08 05:29:44,242 - INFO - epoch 2, step 1200, training loss = 3.268804, validation loss = 2.545861
2018-12-08 05:30:04,306 - INFO - epoch 2, step 1250, training loss = 2.798346, validation loss = 2.634905
2018-12-08 05:30:24,081 - INFO - epoch 2, step 1300, training loss = 3.433168, validation loss = 2.466773
2018-12-08 05:30:41,730 - INFO - epoch 2, step 1350, training loss = 3.241000, validation loss = 2.755853
2018-12-08 05:30:59,411 - INFO - epoch 2, step 1400, training loss = 2.741021, validation loss = 2.571292
2018-12-08 05:31:17,787 - INFO - epoch 2, step 1450, training loss = 2.921510, validation loss = 2.883788
2018-12-08 05:31:38,350 - INFO - epoch 2, step 1500, training loss = 2.596758, validation loss = 2.777224
2018-12-08 05:31:57,080 - INFO - epoch 2, step 1550, training loss = 3.196755, validation loss = 2.687003
2018-12-08 05:32:15,298 - INFO - epoch 2, step 1600, training loss = 3.274385, validation loss = 2.447236
2018-12-08 05:32:33,341 - INFO - epoch 2, step 1650, training loss = 3.162307, validation loss = 2.823876
2018-12-08 05:32:53,640 - INFO - epoch 2, step 1700, training loss = 3.150841, validation loss = 2.768564
2018-12-08 05:33:10,494 - INFO - epoch 2, step 1750, training loss = 3.088453, validation loss = 2.554070
2018-12-08 05:33:26,662 - INFO - epoch 2, step 1800, training loss = 3.037477, validation loss = 2.564784
2018-12-08 05:33:43,492 - INFO - epoch 2, step 1850, training loss = 2.990533, validation loss = 2.619991
2018-12-08 05:34:03,978 - INFO - epoch 2, step 1900, training loss = 3.118787, validation loss = 2.802112
2018-12-08 05:34:25,101 - INFO - epoch 2, step 1950, training loss = 3.271166, validation loss = 2.802961
2018-12-08 05:34:41,433 - INFO - epoch 2, step 2000, training loss = 3.019627, validation loss = 2.687045
2018-12-08 05:34:57,307 - INFO - epoch 2, step 2050, training loss = 2.792258, validation loss = 2.568142
2018-12-08 05:35:13,915 - INFO - epoch 2, step 2100, training loss = 3.111651, validation loss = 2.898184
2018-12-08 05:35:30,329 - INFO - epoch 2, step 2150, training loss = 2.216851, validation loss = 2.781076
2018-12-08 05:35:47,041 - INFO - epoch 2, step 2200, training loss = 3.223528, validation loss = 2.817333
2018-12-08 05:36:04,591 - INFO - epoch 2, step 2250, training loss = 2.794241, validation loss = 2.457848
2018-12-08 05:36:23,256 - INFO - epoch 2, step 2300, training loss = 2.815785, validation loss = 2.460923
2018-12-08 05:36:42,933 - INFO - epoch 2, step 2350, training loss = 2.911598, validation loss = 2.987347
2018-12-08 05:37:02,311 - INFO - epoch 2, step 2400, training loss = 2.841683, validation loss = 2.715282
2018-12-08 05:37:21,381 - INFO - epoch 2, step 2450, training loss = 2.731786, validation loss = 2.884522
2018-12-08 05:37:39,027 - INFO - epoch 2, step 2500, training loss = 3.227320, validation loss = 2.713394
2018-12-08 05:37:56,102 - INFO - epoch 2, step 2550, training loss = 2.715697, validation loss = 2.472042
2018-12-08 05:38:13,661 - INFO - epoch 2, step 2600, training loss = 2.677029, validation loss = 2.549828
2018-12-08 05:38:31,212 - INFO - epoch 2, step 2650, training loss = 2.797088, validation loss = 2.935967
2018-12-08 05:38:51,510 - INFO - epoch 2, step 2700, training loss = 3.398333, validation loss = 2.378796
2018-12-08 05:39:12,202 - INFO - epoch 2, step 2750, training loss = 2.824528, validation loss = 2.757932
2018-12-08 05:39:32,268 - INFO - epoch 2, step 2800, training loss = 3.297794, validation loss = 2.879636
2018-12-08 05:39:50,356 - INFO - epoch 2, step 2850, training loss = 3.063483, validation loss = 2.746384
2018-12-08 05:40:08,033 - INFO - epoch 2, step 2900, training loss = 2.864535, validation loss = 2.347807
2018-12-08 05:40:26,451 - INFO - epoch 2, step 2950, training loss = 2.889409, validation loss = 2.311608
2018-12-08 05:40:47,181 - INFO - epoch 2, step 3000, training loss = 2.842371, validation loss = 2.949144
2018-12-08 05:41:07,532 - INFO - epoch 2, step 3050, training loss = 3.073851, validation loss = 2.396470
2018-12-08 05:41:27,881 - INFO - epoch 2, step 3100, training loss = 2.983992, validation loss = 2.403957
2018-12-08 05:41:47,980 - INFO - epoch 2, step 3150, training loss = 2.806351, validation loss = 2.741229
2018-12-08 05:42:07,896 - INFO - epoch 2, step 3200, training loss = 3.254736, validation loss = 2.417089
2018-12-08 05:42:28,712 - INFO - epoch 2, step 3250, training loss = 3.174752, validation loss = 2.548169
2018-12-08 05:42:47,400 - INFO - epoch 2, step 3300, training loss = 3.141754, validation loss = 2.696644
2018-12-08 05:43:05,555 - INFO - epoch 2, step 3350, training loss = 2.768321, validation loss = 2.572542
2018-12-08 05:43:24,204 - INFO - epoch 2, step 3400, training loss = 3.362182, validation loss = 2.857453
2018-12-08 05:43:43,465 - INFO - epoch 2, step 3450, training loss = 2.931650, validation loss = 2.478159
2018-12-08 05:44:02,421 - INFO - epoch 2, step 3500, training loss = 2.836913, validation loss = 2.417638
2018-12-08 05:44:20,432 - INFO - epoch 2, step 3550, training loss = 2.906629, validation loss = 2.835078
2018-12-08 05:44:38,388 - INFO - epoch 2, step 3600, training loss = 3.101070, validation loss = 2.815943
2018-12-08 05:44:56,366 - INFO - epoch 2, step 3650, training loss = 3.408060, validation loss = 2.650843
2018-12-08 05:45:14,979 - INFO - epoch 2, step 3700, training loss = 2.850159, validation loss = 2.801119
2018-12-08 05:45:32,230 - INFO - epoch 2, step 3750, training loss = 3.025819, validation loss = 2.596669
2018-12-08 05:45:48,300 - INFO - epoch 2, step 3800, training loss = 2.095249, validation loss = 2.828602
2018-12-08 05:46:04,610 - INFO - epoch 2, step 3850, training loss = 2.794263, validation loss = 2.404453
2018-12-08 05:46:22,478 - INFO - epoch 2, step 3900, training loss = 2.807470, validation loss = 2.326305
2018-12-08 05:46:42,177 - INFO - epoch 2, step 3950, training loss = 3.035608, validation loss = 2.619293
2018-12-08 05:47:01,494 - INFO - epoch 2, step 4000, training loss = 2.848468, validation loss = 2.498948
2018-12-08 05:47:19,053 - INFO - epoch 2, step 4050, training loss = 2.774384, validation loss = 2.992978
2018-12-08 05:47:36,278 - INFO - epoch 2, step 4100, training loss = 2.832534, validation loss = 2.869602
2018-12-08 05:47:53,776 - INFO - epoch 2, step 4150, training loss = 2.990388, validation loss = 2.387131
2018-12-08 05:48:10,777 - INFO - epoch 2, step 4200, training loss = 3.035063, validation loss = 2.527061
2018-12-08 05:48:28,869 - INFO - epoch 2, step 4250, training loss = 3.221028, validation loss = 2.549814
2018-12-08 05:48:46,808 - INFO - epoch 2, step 4300, training loss = 3.240311, validation loss = 2.613497
2018-12-08 05:49:04,968 - INFO - epoch 2, step 4350, training loss = 3.208595, validation loss = 2.922218
2018-12-08 05:49:22,618 - INFO - epoch 2, step 4400, training loss = 3.613263, validation loss = 2.403523
2018-12-08 05:49:40,632 - INFO - epoch 2, step 4450, training loss = 3.354005, validation loss = 2.354155
2018-12-08 05:49:58,300 - INFO - epoch 2, step 4500, training loss = 2.895187, validation loss = 2.701464
2018-12-08 05:50:16,203 - INFO - epoch 2, step 4550, training loss = 2.667542, validation loss = 2.563576
2018-12-08 05:50:33,361 - INFO - epoch 2, step 4600, training loss = 2.822536, validation loss = 2.754436
2018-12-08 05:50:50,822 - INFO - epoch 2, step 4650, training loss = 2.973755, validation loss = 2.374127
2018-12-08 05:51:11,518 - INFO - epoch 2, step 4700, training loss = 3.334057, validation loss = 2.905856
2018-12-08 05:51:31,782 - INFO - epoch 2, step 4750, training loss = 3.086450, validation loss = 2.642639
2018-12-08 05:51:51,688 - INFO - epoch 2, step 4800, training loss = 2.700589, validation loss = 2.939069
2018-12-08 05:52:10,415 - INFO - epoch 2, step 4850, training loss = 2.749996, validation loss = 2.759632
2018-12-08 05:52:28,437 - INFO - epoch 2, step 4900, training loss = 3.338718, validation loss = 2.917075
2018-12-08 05:52:44,585 - INFO - epoch 2, step 4950, training loss = 2.837524, validation loss = 2.880655
2018-12-08 05:53:01,458 - INFO - epoch 2, step 5000, training loss = 3.158665, validation loss = 2.477175
2018-12-08 05:53:21,941 - INFO - epoch 2, step 5050, training loss = 2.686702, validation loss = 2.971232
2018-12-08 05:53:42,222 - INFO - epoch 2, step 5100, training loss = 2.520314, validation loss = 2.751842
2018-12-08 05:54:00,690 - INFO - epoch 2, step 5150, training loss = 3.015812, validation loss = 2.605735
2018-12-08 05:54:18,413 - INFO - epoch 2, step 5200, training loss = 2.455934, validation loss = 2.663275
2018-12-08 05:54:38,232 - INFO - epoch 2, step 5250, training loss = 3.191424, validation loss = 2.464507
2018-12-08 05:54:58,108 - INFO - epoch 2, step 5300, training loss = 3.236546, validation loss = 2.564178
2018-12-08 05:55:16,568 - INFO - epoch 2, step 5350, training loss = 2.798563, validation loss = 2.576237
2018-12-08 05:55:35,256 - INFO - epoch 2, step 5400, training loss = 2.962990, validation loss = 2.784441
2018-12-08 05:55:53,613 - INFO - epoch 2, step 5450, training loss = 2.992342, validation loss = 3.020386
2018-12-08 05:56:11,622 - INFO - epoch 2, step 5500, training loss = 3.241562, validation loss = 2.664035
2018-12-08 05:56:29,806 - INFO - epoch 2, step 5550, training loss = 2.975479, validation loss = 3.025104
2018-12-08 05:56:48,856 - INFO - epoch 2, step 5600, training loss = 2.953751, validation loss = 2.686980
2018-12-08 05:57:08,652 - INFO - epoch 2, step 5650, training loss = 3.130944, validation loss = 2.865199
2018-12-08 05:57:29,062 - INFO - epoch 2, step 5700, training loss = 3.285408, validation loss = 2.712730
2018-12-08 05:57:49,386 - INFO - epoch 2, step 5750, training loss = 3.069909, validation loss = 2.491891
2018-12-08 05:58:10,128 - INFO - epoch 2, step 5800, training loss = 2.938368, validation loss = 2.650361
2018-12-08 05:58:30,301 - INFO - epoch 2, step 5850, training loss = 2.944799, validation loss = 2.382821
2018-12-08 05:58:46,475 - INFO - epoch 2, step 5900, training loss = 2.748259, validation loss = 2.739854
2018-12-08 05:59:02,416 - INFO - epoch 2, step 5950, training loss = 2.491401, validation loss = 2.612851
2018-12-08 05:59:22,158 - INFO - epoch 2, step 6000, training loss = 3.014964, validation loss = 2.567158
2018-12-08 05:59:42,637 - INFO - epoch 2, step 6050, training loss = 2.866733, validation loss = 2.718828
2018-12-08 06:00:02,890 - INFO - epoch 2, step 6100, training loss = 2.844040, validation loss = 2.809896
2018-12-08 06:00:23,733 - INFO - epoch 2, step 6150, training loss = 3.069009, validation loss = 2.547705
2018-12-08 06:00:44,212 - INFO - epoch 2, step 6200, training loss = 3.203568, validation loss = 3.176186
2018-12-08 06:01:04,496 - INFO - epoch 2, step 6250, training loss = 2.851832, validation loss = 2.729181
2018-12-08 06:01:23,297 - INFO - epoch 2, step 6300, training loss = 3.247686, validation loss = 2.777334
2018-12-08 06:01:41,526 - INFO - epoch 2, step 6350, training loss = 2.878130, validation loss = 3.025188
2018-12-08 06:01:59,389 - INFO - epoch 2, step 6400, training loss = 3.006829, validation loss = 2.863087
2018-12-08 06:02:17,612 - INFO - epoch 2, step 6450, training loss = 2.708056, validation loss = 2.852484
2018-12-08 06:02:35,318 - INFO - epoch 2, step 6500, training loss = 2.459404, validation loss = 2.581167
2018-12-08 06:02:52,836 - INFO - epoch 2, step 6550, training loss = 2.945804, validation loss = 2.547591
2018-12-08 06:03:10,230 - INFO - epoch 2, step 6600, training loss = 2.935065, validation loss = 2.362026
2018-12-08 06:03:28,295 - INFO - epoch 2, step 6650, training loss = 3.152861, validation loss = 2.796167
2018-12-08 06:03:47,119 - INFO - epoch 2, step 6700, training loss = 3.301832, validation loss = 2.662614
2018-12-08 06:04:05,264 - INFO - epoch 2, step 6750, training loss = 2.933750, validation loss = 2.604135
2018-12-08 06:04:22,834 - INFO - epoch 2, step 6800, training loss = 2.846419, validation loss = 2.529922
2018-12-08 06:04:40,245 - INFO - epoch 2, step 6850, training loss = 2.773942, validation loss = 2.626448
2018-12-08 06:04:57,452 - INFO - epoch 2, step 6900, training loss = 2.471500, validation loss = 2.953781
2018-12-08 06:05:16,267 - INFO - epoch 2, step 6950, training loss = 2.971822, validation loss = 2.719111
2018-12-08 06:05:35,959 - INFO - epoch 2, step 7000, training loss = 3.165732, validation loss = 3.007537
2018-12-08 06:05:56,845 - INFO - epoch 2, step 7050, training loss = 2.992325, validation loss = 2.793930
2018-12-08 06:06:16,671 - INFO - epoch 2, step 7100, training loss = 2.848322, validation loss = 2.756400
2018-12-08 06:06:37,232 - INFO - epoch 2, step 7150, training loss = 2.746129, validation loss = 2.676857
2018-12-08 06:06:56,967 - INFO - epoch 2, step 7200, training loss = 2.971596, validation loss = 3.102811
2018-12-08 06:07:15,920 - INFO - epoch 2, step 7250, training loss = 2.899360, validation loss = 2.414422
2018-12-08 06:07:33,597 - INFO - epoch 2, step 7300, training loss = 2.743522, validation loss = 2.733624
2018-12-08 06:07:51,747 - INFO - epoch 2, step 7350, training loss = 3.081613, validation loss = 2.733691
2018-12-08 06:08:09,074 - INFO - epoch 2, step 7400, training loss = 2.809080, validation loss = 2.992671
2018-12-08 06:08:25,221 - INFO - epoch 2, step 7450, training loss = 3.051580, validation loss = 2.654877
2018-12-08 06:08:40,941 - INFO - epoch 2, step 7500, training loss = 2.096619, validation loss = 2.532423
2018-12-08 06:08:57,201 - INFO - epoch 2, step 7550, training loss = 2.588392, validation loss = 2.705758
2018-12-08 06:09:14,496 - INFO - epoch 2, step 7600, training loss = 2.691770, validation loss = 2.525140
2018-12-08 06:09:32,425 - INFO - epoch 2, step 7650, training loss = 2.667928, validation loss = 2.655023
2018-12-08 06:09:49,952 - INFO - epoch 2, step 7700, training loss = 2.629672, validation loss = 2.532904
2018-12-08 06:10:07,747 - INFO - epoch 2, step 7750, training loss = 2.601584, validation loss = 2.713475
2018-12-08 06:10:25,648 - INFO - epoch 2, step 7800, training loss = 3.101990, validation loss = 2.445576
2018-12-08 06:10:44,507 - INFO - epoch 2, step 7850, training loss = 3.098511, validation loss = 2.611691
2018-12-08 06:11:03,175 - INFO - epoch 2, step 7900, training loss = 2.713717, validation loss = 2.354489
2018-12-08 06:11:22,148 - INFO - epoch 2, step 7950, training loss = 2.602039, validation loss = 2.815979
2018-12-08 06:11:41,870 - INFO - epoch 2, step 8000, training loss = 2.990909, validation loss = 2.924242
2018-12-08 06:12:02,171 - INFO - epoch 2, step 8050, training loss = 2.813074, validation loss = 2.810006
2018-12-08 06:12:22,363 - INFO - epoch 2, step 8100, training loss = 2.797049, validation loss = 2.858789
2018-12-08 06:12:43,130 - INFO - epoch 2, step 8150, training loss = 3.454353, validation loss = 2.917857
2018-12-08 06:13:03,551 - INFO - epoch 2, step 8200, training loss = 2.906626, validation loss = 3.027827
2018-12-08 06:13:23,427 - INFO - epoch 2, step 8250, training loss = 2.683499, validation loss = 2.745514
2018-12-08 06:13:41,553 - INFO - epoch 2, step 8300, training loss = 2.777798, validation loss = 2.801118
2018-12-08 06:13:57,724 - INFO - epoch 2, step 8350, training loss = 2.757714, validation loss = 2.946131
2018-12-08 06:14:13,893 - INFO - epoch 2, step 8400, training loss = 2.732690, validation loss = 2.842709
2018-12-08 06:14:33,089 - INFO - epoch 2, step 8450, training loss = 2.852701, validation loss = 2.971767
2018-12-08 06:14:52,527 - INFO - epoch 2, step 8500, training loss = 2.486410, validation loss = 2.826161
2018-12-08 06:15:09,999 - INFO - epoch 2, step 8550, training loss = 2.896385, validation loss = 2.691724
2018-12-08 06:15:26,752 - INFO - epoch 2, step 8600, training loss = 2.253050, validation loss = 2.757873
2018-12-08 06:15:43,354 - INFO - epoch 2, step 8650, training loss = 2.617079, validation loss = 3.070911
2018-12-08 06:16:00,846 - INFO - epoch 2, step 8700, training loss = 3.110295, validation loss = 2.511247
2018-12-08 06:16:18,843 - INFO - epoch 2, step 8750, training loss = 3.273696, validation loss = 2.591718
2018-12-08 06:16:36,075 - INFO - epoch 2, step 8800, training loss = 2.627492, validation loss = 3.325685
2018-12-08 06:16:52,703 - INFO - epoch 2, step 8850, training loss = 2.632629, validation loss = 2.813168
2018-12-08 06:17:10,124 - INFO - epoch 2, step 8900, training loss = 3.145051, validation loss = 2.725869
2018-12-08 06:17:27,720 - INFO - epoch 2, step 8950, training loss = 3.265534, validation loss = 3.266404
2018-12-08 06:17:44,220 - INFO - epoch 2, step 9000, training loss = 2.864999, validation loss = 2.730917
2018-12-08 06:18:00,770 - INFO - epoch 2, step 9050, training loss = 3.183314, validation loss = 2.729752
2018-12-08 06:18:18,599 - INFO - epoch 2, step 9100, training loss = 2.887698, validation loss = 3.116340
2018-12-08 06:18:37,165 - INFO - epoch 2, step 9150, training loss = 2.622789, validation loss = 3.328423
2018-12-08 06:18:53,111 - INFO - epoch 2, step 9200, training loss = 2.192641, validation loss = 2.759650
2018-12-08 06:19:09,506 - INFO - epoch 2, step 9250, training loss = 2.087831, validation loss = 2.638068
2018-12-08 06:19:26,840 - INFO - epoch 2, step 9300, training loss = 2.668495, validation loss = 2.774102
2018-12-08 06:19:44,268 - INFO - epoch 2, step 9350, training loss = 2.976649, validation loss = 2.617840
2018-12-08 06:20:03,594 - INFO - epoch 2, step 9400, training loss = 3.010119, validation loss = 3.058816
2018-12-08 06:20:23,522 - INFO - epoch 2, step 9450, training loss = 3.146698, validation loss = 2.822967
2018-12-08 06:20:41,714 - INFO - epoch 2, step 9500, training loss = 2.087905, validation loss = 2.739409
2018-12-08 06:20:57,938 - INFO - epoch 2, step 9550, training loss = 2.592530, validation loss = 3.021742
2018-12-08 06:21:14,203 - INFO - epoch 2, step 9600, training loss = 2.403224, validation loss = 2.976871
2018-12-08 06:21:31,635 - INFO - epoch 2, step 9650, training loss = 2.017297, validation loss = 2.945321
2018-12-08 06:21:49,368 - INFO - epoch 2, step 9700, training loss = 2.837343, validation loss = 2.934263
2018-12-08 06:22:10,617 - INFO - epoch 2, step 9750, training loss = 2.749807, validation loss = 2.780161
2018-12-08 06:22:32,122 - INFO - epoch 2, step 9800, training loss = 2.809774, validation loss = 3.173260
2018-12-08 06:22:51,961 - INFO - epoch 2, step 9850, training loss = 2.411354, validation loss = 2.943339
2018-12-08 06:23:09,119 - INFO - epoch 2, step 9900, training loss = 2.078205, validation loss = 3.009823
2018-12-08 06:23:26,383 - INFO - epoch 2, step 9950, training loss = 2.655233, validation loss = 2.860893
2018-12-08 06:23:43,924 - INFO - epoch 2, step 10000, training loss = 2.813439, validation loss = 3.332519
2018-12-08 06:24:00,968 - INFO - epoch 2, step 10050, training loss = 2.554049, validation loss = 3.147408
2018-12-08 06:24:17,732 - INFO - epoch 2, step 10100, training loss = 2.854744, validation loss = 3.108567
2018-12-08 06:24:34,179 - INFO - epoch 2, step 10150, training loss = 2.560617, validation loss = 3.103661
2018-12-08 06:24:52,369 - INFO - epoch 2, step 10200, training loss = 2.964655, validation loss = 2.994233
2018-12-08 06:25:09,876 - INFO - epoch 2, step 10250, training loss = 2.978684, validation loss = 2.862879
2018-12-08 06:25:26,497 - INFO - epoch 2, step 10300, training loss = 2.681661, validation loss = 2.821280
2018-12-08 06:25:44,537 - INFO - epoch 2, step 10350, training loss = 3.007067, validation loss = 2.877720
2018-12-08 06:26:04,851 - INFO - epoch 2, step 10400, training loss = 3.508827, validation loss = 2.993845
2018-12-08 06:26:26,284 - INFO - epoch 2, step 10450, training loss = 2.739410, validation loss = 3.046271
2018-12-08 06:26:46,274 - INFO - epoch 2, step 10500, training loss = 3.196528, validation loss = 2.901640
2018-12-08 06:27:05,960 - INFO - epoch 2, step 10550, training loss = 2.953745, validation loss = 2.787366
2018-12-08 06:27:24,518 - INFO - epoch 2, step 10600, training loss = 2.616796, validation loss = 2.762615
2018-12-08 06:27:42,528 - INFO - epoch 2, step 10650, training loss = 3.127196, validation loss = 3.022295
2018-12-08 06:28:00,624 - INFO - epoch 2, step 10700, training loss = 3.434916, validation loss = 2.856366
2018-12-08 06:28:18,938 - INFO - epoch 2, step 10750, training loss = 2.722824, validation loss = 3.205329
2018-12-08 06:28:37,305 - INFO - epoch 2, step 10800, training loss = 2.906041, validation loss = 3.011392
2018-12-08 06:28:55,576 - INFO - epoch 2, step 10850, training loss = 2.733917, validation loss = 3.155366
2018-12-08 06:29:13,105 - INFO - epoch 2, step 10900, training loss = 2.971912, validation loss = 2.940288
2018-12-08 06:29:29,430 - INFO - epoch 2, step 10950, training loss = 2.363780, validation loss = 2.857360
2018-12-08 06:29:45,786 - INFO - epoch 2, step 11000, training loss = 2.954395, validation loss = 2.869505
2018-12-08 06:30:02,948 - INFO - epoch 2, step 11050, training loss = 2.909630, validation loss = 3.110197
2018-12-08 06:30:22,047 - INFO - epoch 2, step 11100, training loss = 2.988301, validation loss = 2.871750
2018-12-08 06:30:39,910 - INFO - epoch 2, step 11150, training loss = 2.243377, validation loss = 2.948818
2018-12-08 06:30:57,615 - INFO - epoch 2, step 11200, training loss = 2.858713, validation loss = 3.070984
2018-12-08 06:31:15,114 - INFO - epoch 2, step 11250, training loss = 2.553999, validation loss = 2.777786
2018-12-08 06:31:31,721 - INFO - epoch 2, step 11300, training loss = 2.701438, validation loss = 3.137878
2018-12-08 06:31:48,982 - INFO - epoch 2, step 11350, training loss = 2.645269, validation loss = 3.398420
2018-12-08 06:32:06,355 - INFO - epoch 2, step 11400, training loss = 3.117258, validation loss = 3.020838
2018-12-08 06:32:23,684 - INFO - epoch 2, step 11450, training loss = 2.844576, validation loss = 2.691208
2018-12-08 06:32:42,867 - INFO - epoch 2, step 11500, training loss = 3.428451, validation loss = 3.314233
2018-12-08 06:33:01,704 - INFO - epoch 2, step 11550, training loss = 2.327738, validation loss = 3.151864
2018-12-08 06:33:21,848 - INFO - epoch 2, step 11600, training loss = 3.048511, validation loss = 3.272318
2018-12-08 06:33:41,328 - INFO - epoch 2, step 11650, training loss = 2.347098, validation loss = 2.902559
2018-12-08 06:33:58,731 - INFO - epoch 2, step 11700, training loss = 2.627526, validation loss = 3.206563
2018-12-08 06:34:16,054 - INFO - epoch 2, step 11750, training loss = 2.427681, validation loss = 3.410065
2018-12-08 06:34:34,547 - INFO - epoch 2, step 11800, training loss = 3.087795, validation loss = 3.202834
2018-12-08 06:34:53,727 - INFO - epoch 2, step 11850, training loss = 2.648499, validation loss = 2.652769
2018-12-08 06:35:12,747 - INFO - epoch 2, step 11900, training loss = 2.784437, validation loss = 2.545459
2018-12-08 06:35:30,762 - INFO - epoch 2, step 11950, training loss = 2.083109, validation loss = 2.910280
2018-12-08 06:35:48,237 - INFO - epoch 2, step 12000, training loss = 2.613455, validation loss = 2.482812
2018-12-08 06:36:05,962 - INFO - epoch 2, step 12050, training loss = 3.057715, validation loss = 3.042537
2018-12-08 06:36:26,587 - INFO - epoch 2, step 12100, training loss = 3.187348, validation loss = 2.960872
2018-12-08 06:36:46,636 - INFO - epoch 2, step 12150, training loss = 3.024702, validation loss = 2.427360
2018-12-08 06:37:07,072 - INFO - epoch 2, step 12200, training loss = 2.567617, validation loss = 2.420944
2018-12-08 06:37:27,470 - INFO - epoch 2, step 12250, training loss = 2.835711, validation loss = 2.887974
2018-12-08 06:37:47,669 - INFO - epoch 2, step 12300, training loss = 3.370624, validation loss = 2.455094
2018-12-08 06:38:05,669 - INFO - epoch 2, step 12350, training loss = 3.168952, validation loss = 3.113875
2018-12-08 06:38:23,003 - INFO - epoch 2, step 12400, training loss = 2.809628, validation loss = 3.356773
2018-12-08 06:38:42,837 - INFO - epoch 2, step 12450, training loss = 2.645085, validation loss = 2.966166
2018-12-08 06:39:02,085 - INFO - epoch 2, step 12500, training loss = 2.522673, validation loss = 2.612526
2018-12-08 06:39:21,441 - INFO - epoch 2, step 12550, training loss = 2.810153, validation loss = 3.019038
2018-12-08 06:39:39,413 - INFO - epoch 2, step 12600, training loss = 2.667730, validation loss = 2.575295
2018-12-08 06:39:57,463 - INFO - epoch 2, step 12650, training loss = 2.833811, validation loss = 2.570836
2018-12-08 06:40:14,920 - INFO - epoch 2, step 12700, training loss = 3.231832, validation loss = 2.911740
2018-12-08 06:40:31,401 - INFO - epoch 2, step 12750, training loss = 3.038799, validation loss = 2.707797
2018-12-08 06:40:48,523 - INFO - epoch 2, step 12800, training loss = 3.182326, validation loss = 2.790876
2018-12-08 06:41:07,793 - INFO - epoch 2, step 12850, training loss = 2.865405, validation loss = 2.675717
2018-12-08 06:41:26,319 - INFO - epoch 2, step 12900, training loss = 2.924289, validation loss = 2.514013
2018-12-08 06:41:42,939 - INFO - epoch 2, step 12950, training loss = 3.172143, validation loss = 2.750237
2018-12-08 06:41:59,314 - INFO - epoch 2, step 13000, training loss = 3.191322, validation loss = 2.725318
2018-12-08 06:42:15,745 - INFO - epoch 2, step 13050, training loss = 2.844276, validation loss = 2.882312
2018-12-08 06:42:35,893 - INFO - epoch 2, step 13100, training loss = 2.942389, validation loss = 2.716884
2018-12-08 06:42:55,571 - INFO - epoch 2, step 13150, training loss = 2.677783, validation loss = 2.760513
2018-12-08 06:43:14,653 - INFO - epoch 2, step 13200, training loss = 2.847318, validation loss = 2.860159
2018-12-08 06:43:31,091 - INFO - epoch 2, step 13250, training loss = 2.713887, validation loss = 3.097017
2018-12-08 06:43:48,082 - INFO - epoch 2, step 13300, training loss = 2.685967, validation loss = 3.075112
2018-12-08 06:44:05,296 - INFO - epoch 2, step 13350, training loss = 2.405766, validation loss = 3.106626
2018-12-08 06:44:22,703 - INFO - epoch 2, step 13400, training loss = 2.552835, validation loss = 3.218076
2018-12-08 06:44:39,837 - INFO - epoch 2, step 13450, training loss = 2.645258, validation loss = 3.038055
2018-12-08 06:44:59,214 - INFO - epoch 2, step 13500, training loss = 3.205128, validation loss = 2.792104
2018-12-08 06:45:19,518 - INFO - epoch 2, step 13550, training loss = 3.129374, validation loss = 2.635720
2018-12-08 06:45:40,313 - INFO - epoch 2, step 13600, training loss = 3.212045, validation loss = 2.945969
2018-12-08 06:45:57,088 - INFO - epoch 2, step 13650, training loss = 2.544732, validation loss = 2.761652
2018-12-08 06:46:13,729 - INFO - epoch 2, step 13700, training loss = 2.239587, validation loss = 2.808917
2018-12-08 06:46:31,427 - INFO - epoch 2, step 13750, training loss = 2.720996, validation loss = 2.903940
2018-12-08 06:46:50,163 - INFO - epoch 2, step 13800, training loss = 2.697397, validation loss = 2.797196
2018-12-08 06:47:07,169 - INFO - epoch 2, step 13850, training loss = 2.591631, validation loss = 2.589566
2018-12-08 06:47:25,499 - INFO - epoch 2, step 13900, training loss = 2.461073, validation loss = 3.151779
2018-12-08 06:47:45,806 - INFO - epoch 2, step 13950, training loss = 3.301634, validation loss = 2.701854
2018-12-08 06:48:06,561 - INFO - epoch 2, step 14000, training loss = 2.338020, validation loss = 2.615914
2018-12-08 06:48:25,774 - INFO - epoch 2, step 14050, training loss = 3.136881, validation loss = 2.754430
2018-12-08 06:48:43,131 - INFO - epoch 2, step 14100, training loss = 3.119965, validation loss = 2.906092
2018-12-08 06:49:01,665 - INFO - epoch 2, step 14150, training loss = 3.250128, validation loss = 2.864619
2018-12-08 06:49:19,580 - INFO - epoch 2, step 14200, training loss = 2.977577, validation loss = 2.950057
2018-12-08 06:49:39,171 - INFO - epoch 2, step 14250, training loss = 2.617696, validation loss = 3.170956
2018-12-08 06:49:59,499 - INFO - epoch 2, step 14300, training loss = 3.017133, validation loss = 2.735453
2018-12-08 06:50:19,891 - INFO - epoch 2, step 14350, training loss = 3.287490, validation loss = 2.329078
2018-12-08 06:50:34,960 - INFO - epoch 2, step 14400, training loss = 3.409693, validation loss = 2.897371
2018-12-08 06:50:50,132 - INFO - epoch 2, step 14450, training loss = 3.026783, validation loss = 3.191322
2018-12-08 06:51:05,713 - INFO - epoch 2, step 14500, training loss = 3.112393, validation loss = 2.681963
2018-12-08 06:51:22,259 - INFO - epoch 2, step 14550, training loss = 3.624566, validation loss = 3.142144
2018-12-08 06:51:39,694 - INFO - epoch 2, step 14600, training loss = 3.199643, validation loss = 3.374602
2018-12-08 06:52:02,040 - INFO - epoch 2, step 14650, training loss = 3.689860, validation loss = 2.674058
2018-12-08 06:52:25,282 - INFO - epoch 2, step 14700, training loss = 2.751961, validation loss = 2.785998
2018-12-08 06:52:41,004 - INFO - epoch 2, step 14750, training loss = 2.834121, validation loss = 2.975401
2018-12-08 06:52:56,242 - INFO - epoch 2, step 14800, training loss = 2.683291, validation loss = 3.019024
2018-12-08 06:53:11,810 - INFO - epoch 2, step 14850, training loss = 2.827747, validation loss = 3.205607
2018-12-08 06:53:38,715 - INFO - epoch 2, step 14900, training loss = 3.276902, validation loss = 2.992774
2018-12-08 06:54:05,310 - INFO - epoch 2, step 14950, training loss = 3.605886, validation loss = 2.926942
2018-12-08 06:54:33,356 - INFO - epoch 2, step 15000, training loss = 3.414057, validation loss = 2.739356
2018-12-08 06:55:00,180 - INFO - epoch 2, step 15050, training loss = 3.684814, validation loss = 3.021808
2018-12-08 06:55:28,985 - INFO - epoch 2, step 15100, training loss = 3.390987, validation loss = 3.090541
2018-12-08 06:55:59,756 - INFO - epoch 2, step 15150, training loss = 3.622644, validation loss = 2.706678
2018-12-08 06:56:29,700 - INFO - epoch 2, step 15200, training loss = 3.833938, validation loss = 3.841008
2018-12-08 06:56:58,190 - INFO - epoch 2, step 15250, training loss = 3.639918, validation loss = 3.161652
2018-12-08 06:57:26,884 - INFO - epoch 2, step 15300, training loss = 2.833476, validation loss = 2.948519
2018-12-08 06:57:53,513 - INFO - epoch 2, step 15350, training loss = 3.294552, validation loss = 2.463919
2018-12-08 06:58:17,943 - INFO - epoch 2, step 15400, training loss = 3.676580, validation loss = 2.905035
2018-12-08 06:58:33,383 - INFO - epoch 2, step 15450, training loss = 3.528741, validation loss = 2.774216
2018-12-08 06:58:48,625 - INFO - epoch 2, step 15500, training loss = 3.338395, validation loss = 2.917691
2018-12-08 06:59:03,820 - INFO - epoch 2, step 15550, training loss = 2.854904, validation loss = 3.019929
2018-12-08 06:59:21,212 - INFO - epoch 2, step 15600, training loss = 3.683268, validation loss = 2.672420
2018-12-08 06:59:44,342 - INFO - epoch 2, step 15650, training loss = 3.241653, validation loss = 2.923712
2018-12-08 07:00:07,208 - INFO - epoch 2, step 15700, training loss = 3.623032, validation loss = 3.084605
2018-12-08 07:00:34,186 - INFO - epoch 2, step 15750, training loss = 3.595596, validation loss = 2.725915
2018-12-08 07:01:00,855 - INFO - epoch 2, step 15800, training loss = 3.809304, validation loss = 3.259052
2018-12-08 07:01:27,491 - INFO - epoch 2, step 15850, training loss = 3.471238, validation loss = 2.895945
2018-12-08 07:01:55,352 - INFO - epoch 2, step 15900, training loss = 3.080247, validation loss = 2.964401
2018-12-08 07:02:17,913 - INFO - epoch 2, step 15950, training loss = 3.195681, validation loss = 2.967186
2018-12-08 07:02:38,872 - INFO - epoch 2, step 16000, training loss = 3.639002, validation loss = 2.782967
2018-12-08 07:02:54,426 - INFO - epoch 2, step 16050, training loss = 3.531799, validation loss = 3.125856
2018-12-08 07:03:05,766 - INFO - epoch 2, step 16100, training loss = 3.031732, validation loss = 3.338210
2018-12-08 07:03:17,169 - INFO - epoch 2, step 16150, training loss = 3.142958, validation loss = 3.478241
2018-12-08 07:03:30,614 - INFO - epoch 2, step 16200, training loss = 3.840726, validation loss = 3.116426
2018-12-08 07:03:47,856 - INFO - epoch 2, step 16250, training loss = 3.537766, validation loss = 3.162177
2018-12-08 07:04:05,628 - INFO - epoch 2, step 16300, training loss = 3.577488, validation loss = 3.066495
2018-12-08 07:04:18,295 - INFO - epoch 2, step 16350, training loss = 3.334941, validation loss = 3.117916
2018-12-08 07:04:29,644 - INFO - epoch 2, step 16400, training loss = 3.108097, validation loss = 3.073086
2018-12-08 07:04:49,149 - INFO - epoch 2, step 16450, training loss = 3.223649, validation loss = 2.721005
2018-12-08 07:05:14,035 - INFO - epoch 2, step 16500, training loss = 3.723476, validation loss = 3.241726
2018-12-08 07:05:39,146 - INFO - epoch 2, step 16550, training loss = 3.762697, validation loss = 3.253187
2018-12-08 07:06:04,634 - INFO - epoch 2, step 16600, training loss = 3.882915, validation loss = 2.995641
2018-12-08 07:06:27,867 - INFO - epoch 2, step 16650, training loss = 3.841430, validation loss = 3.017691
2018-12-08 07:06:46,122 - INFO - epoch 2, step 16700, training loss = 3.282535, validation loss = 3.144507
2018-12-08 07:07:07,121 - INFO - epoch 2, step 16750, training loss = 3.537539, validation loss = 2.828120
2018-12-08 07:07:23,165 - INFO - epoch 2, step 16800, training loss = 3.428291, validation loss = 3.267471
2018-12-08 07:07:38,632 - INFO - epoch 2, step 16850, training loss = 3.196859, validation loss = 2.761164
2018-12-08 07:07:54,314 - INFO - epoch 2, step 16900, training loss = 3.565862, validation loss = 3.062460
2018-12-08 07:08:09,969 - INFO - epoch 2, step 16950, training loss = 3.900926, validation loss = 2.680055
2018-12-08 07:08:33,300 - INFO - epoch 2, step 17000, training loss = 3.624975, validation loss = 2.569982
2018-12-08 07:08:56,392 - INFO - epoch 2, step 17050, training loss = 3.580755, validation loss = 3.316901
2018-12-08 07:09:20,582 - INFO - epoch 2, step 17100, training loss = 3.157115, validation loss = 2.824299
2018-12-08 07:09:45,619 - INFO - epoch 2, step 17150, training loss = 2.946427, validation loss = 2.756588
2018-12-08 07:10:10,141 - INFO - epoch 2, step 17200, training loss = 2.836958, validation loss = 2.901166
2018-12-08 07:10:35,193 - INFO - epoch 2, step 17250, training loss = 3.157275, validation loss = 3.080336
2018-12-08 07:10:59,844 - INFO - epoch 2, step 17300, training loss = 2.561784, validation loss = 2.842140
2018-12-08 07:11:24,568 - INFO - epoch 2, step 17350, training loss = 3.854520, validation loss = 2.854549
2018-12-08 07:11:47,045 - INFO - epoch 2, step 17400, training loss = 3.379244, validation loss = 2.948273
2018-12-08 07:12:02,069 - INFO - epoch 2, step 17450, training loss = 4.186888, validation loss = 2.820245
2018-12-08 07:12:16,108 - INFO - epoch 2, step 17500, training loss = 3.705876, validation loss = 3.003763
2018-12-08 07:12:36,643 - INFO - epoch 2, step 17550, training loss = 4.152415, validation loss = 2.452866
2018-12-08 07:13:02,244 - INFO - epoch 2, step 17600, training loss = 3.588417, validation loss = 2.859861
2018-12-08 07:13:27,604 - INFO - epoch 2, step 17650, training loss = 3.652376, validation loss = 2.840940
2018-12-08 07:13:53,282 - INFO - epoch 2, step 17700, training loss = 3.362274, validation loss = 3.190687
2018-12-08 07:14:19,525 - INFO - epoch 2, step 17750, training loss = 3.540107, validation loss = 3.000269
2018-12-08 07:14:40,455 - INFO - epoch 2, step 17800, training loss = 3.611442, validation loss = 2.743096
2018-12-08 07:14:58,166 - INFO - epoch 2, step 17850, training loss = 2.667709, validation loss = 3.241668
2018-12-08 07:15:13,400 - INFO - epoch 2, step 17900, training loss = 3.330060, validation loss = 2.614542
2018-12-08 07:15:28,206 - INFO - epoch 2, step 17950, training loss = 3.589476, validation loss = 2.841975
2018-12-08 07:15:43,472 - INFO - epoch 2, step 18000, training loss = 2.979818, validation loss = 3.185227
2018-12-08 07:15:56,521 - INFO - epoch 2, step 18050, training loss = 2.963473, validation loss = 3.071320
2018-12-08 07:16:07,898 - INFO - epoch 2, step 18100, training loss = 2.827553, validation loss = 3.437298
2018-12-08 07:16:33,255 - INFO - epoch 2, step 18150, training loss = 3.448946, validation loss = 3.146655
2018-12-08 07:16:58,484 - INFO - epoch 2, step 18200, training loss = 3.431976, validation loss = 2.802889
2018-12-08 07:17:23,145 - INFO - epoch 2, step 18250, training loss = 3.487248, validation loss = 3.130293
2018-12-08 07:17:47,875 - INFO - epoch 2, step 18300, training loss = 3.864459, validation loss = 2.938294
2018-12-08 07:18:13,416 - INFO - epoch 2, step 18350, training loss = 3.045878, validation loss = 2.681949
2018-12-08 07:18:30,446 - INFO - epoch 2, step 18400, training loss = 3.364140, validation loss = 2.764756
2018-12-08 07:18:45,335 - INFO - epoch 2, step 18450, training loss = 3.395403, validation loss = 3.217633
2018-12-08 07:19:01,134 - INFO - epoch 2, step 18500, training loss = 2.928614, validation loss = 2.707824
2018-12-08 07:19:16,586 - INFO - epoch 2, step 18550, training loss = 2.424514, validation loss = 3.146895
2018-12-08 07:19:33,271 - INFO - epoch 2, step 18600, training loss = 3.693189, validation loss = 2.889013
2018-12-08 07:19:55,835 - INFO - epoch 2, step 18650, training loss = 3.608120, validation loss = 2.980800
2018-12-08 07:20:20,648 - INFO - epoch 2, step 18700, training loss = 3.368982, validation loss = 2.599185
2018-12-08 07:20:44,792 - INFO - epoch 2, step 18750, training loss = 3.412615, validation loss = 2.905034
2018-12-08 07:21:00,430 - INFO - epoch 2, step 18800, training loss = 3.322102, validation loss = 2.992754
2018-12-08 07:21:15,390 - INFO - epoch 2, step 18850, training loss = 2.744543, validation loss = 3.001485
2018-12-08 07:21:30,470 - INFO - epoch 2, step 18900, training loss = 2.949662, validation loss = 2.459507
2018-12-08 07:21:45,744 - INFO - epoch 2, step 18950, training loss = 2.490836, validation loss = 3.035284
2018-12-08 07:22:05,545 - INFO - epoch 2, step 19000, training loss = 3.344222, validation loss = 3.064077
2018-12-08 07:22:23,313 - INFO - epoch 2, step 19050, training loss = 2.968048, validation loss = 2.817317
2018-12-08 07:22:38,358 - INFO - epoch 2, step 19100, training loss = 2.736807, validation loss = 2.887353
2018-12-08 07:22:53,112 - INFO - epoch 2, step 19150, training loss = 2.959855, validation loss = 2.898675
2018-12-08 07:23:08,254 - INFO - epoch 2, step 19200, training loss = 3.489705, validation loss = 3.065615
2018-12-08 07:23:28,740 - INFO - epoch 2, step 19250, training loss = 3.755981, validation loss = 2.993973
2018-12-08 07:23:53,316 - INFO - epoch 2, step 19300, training loss = 3.687284, validation loss = 2.854464
2018-12-08 07:24:17,896 - INFO - epoch 2, step 19350, training loss = 3.197087, validation loss = 2.813366
2018-12-08 07:24:45,953 - INFO - epoch 2, step 19400, training loss = 3.163546, validation loss = 2.827062
2018-12-08 07:25:13,455 - INFO - epoch 2, step 19450, training loss = 2.871691, validation loss = 2.958601
2018-12-08 07:25:41,534 - INFO - epoch 2, step 19500, training loss = 3.735000, validation loss = 3.115849
2018-12-08 07:26:07,170 - INFO - epoch 2, step 19550, training loss = 3.018710, validation loss = 3.194647
2018-12-08 07:26:27,437 - INFO - epoch 2, step 19600, training loss = 3.469409, validation loss = 2.978656
2018-12-08 07:26:47,745 - INFO - epoch 2, step 19650, training loss = 3.462978, validation loss = 3.112400
2018-12-08 07:27:13,844 - INFO - epoch 2, step 19700, training loss = 2.869806, validation loss = 3.027682
2018-12-08 07:27:41,124 - INFO - epoch 2, step 19750, training loss = 3.566507, validation loss = 3.037091
2018-12-08 07:28:07,673 - INFO - epoch 2, step 19800, training loss = 3.547011, validation loss = 2.965912
2018-12-08 07:28:34,760 - INFO - epoch 2, step 19850, training loss = 3.035546, validation loss = 2.847415
2018-12-08 07:28:57,390 - INFO - epoch 2, step 19900, training loss = 2.565019, validation loss = 3.045857
2018-12-08 07:29:12,844 - INFO - epoch 2, step 19950, training loss = 3.078266, validation loss = 2.766207
2018-12-08 07:29:28,546 - INFO - epoch 2, step 20000, training loss = 3.169132, validation loss = 2.798488
2018-12-08 07:29:43,930 - INFO - epoch 2, step 20050, training loss = 3.436737, validation loss = 2.931423
2018-12-08 07:29:59,250 - INFO - epoch 2, step 20100, training loss = 2.911503, validation loss = 3.034587
2018-12-08 07:30:14,718 - INFO - epoch 2, step 20150, training loss = 2.488857, validation loss = 2.845285
2018-12-08 07:30:29,577 - INFO - epoch 2, step 20200, training loss = 2.795726, validation loss = 3.004328
2018-12-08 07:30:48,652 - INFO - epoch 2, step 20250, training loss = 3.607734, validation loss = 3.621798
2018-12-08 07:31:10,087 - INFO - epoch 2, step 20300, training loss = 3.911463, validation loss = 2.851940
2018-12-08 07:31:30,581 - INFO - epoch 2, step 20350, training loss = 3.020667, validation loss = 3.264362
2018-12-08 07:31:50,670 - INFO - epoch 2, step 20400, training loss = 3.556691, validation loss = 3.078436
2018-12-08 07:32:11,841 - INFO - epoch 2, step 20450, training loss = 3.760667, validation loss = 3.594451
2018-12-08 07:32:34,967 - INFO - epoch 2, step 20500, training loss = 3.311193, validation loss = 2.799374
2018-12-08 07:32:59,406 - INFO - epoch 2, step 20550, training loss = 3.138077, validation loss = 3.100863
2018-12-08 07:33:23,625 - INFO - epoch 2, step 20600, training loss = 3.090373, validation loss = 3.549594
2018-12-08 07:33:43,693 - INFO - epoch 2, step 20650, training loss = 3.293302, validation loss = 2.980788
2018-12-08 07:34:01,570 - INFO - epoch 2, step 20700, training loss = 3.149488, validation loss = 2.899958
2018-12-08 07:34:21,416 - INFO - epoch 2, step 20750, training loss = 2.945486, validation loss = 3.069721
2018-12-08 07:34:41,403 - INFO - epoch 2, step 20800, training loss = 3.309218, validation loss = 2.999530
2018-12-08 07:34:56,645 - INFO - epoch 2, step 20850, training loss = 2.381475, validation loss = 3.609183
2018-12-08 07:35:11,940 - INFO - epoch 2, step 20900, training loss = 3.253195, validation loss = 3.110748
2018-12-08 07:35:27,270 - INFO - epoch 2, step 20950, training loss = 3.214428, validation loss = 3.336289
2018-12-08 07:35:55,360 - INFO - epoch 2, step 21000, training loss = 3.121603, validation loss = 2.931752
2018-12-08 07:36:23,809 - INFO - epoch 2, step 21050, training loss = 3.170724, validation loss = 2.963247
2018-12-08 07:36:48,426 - INFO - epoch 2, step 21100, training loss = 3.715391, validation loss = 3.487567
2018-12-08 07:37:12,588 - INFO - epoch 2, step 21150, training loss = 3.415167, validation loss = 2.995572
2018-12-08 07:37:36,854 - INFO - epoch 2, step 21200, training loss = 3.582699, validation loss = 3.370629
2018-12-08 07:38:01,060 - INFO - epoch 2, step 21250, training loss = 2.611572, validation loss = 3.457874
2018-12-08 07:38:26,333 - INFO - epoch 2, step 21300, training loss = 3.645090, validation loss = 3.329644
2018-12-08 07:38:50,969 - INFO - epoch 2, step 21350, training loss = 2.949238, validation loss = 3.553440
2018-12-08 07:39:16,146 - INFO - epoch 2, step 21400, training loss = 3.183743, validation loss = 3.407013
2018-12-08 07:39:41,683 - INFO - epoch 2, step 21450, training loss = 3.165672, validation loss = 3.389596
2018-12-08 07:40:07,671 - INFO - epoch 2, step 21500, training loss = 3.464953, validation loss = 3.791098
2018-12-08 07:40:23,948 - INFO - epoch 2, step 21550, training loss = 3.882729, validation loss = 2.989308
2018-12-08 07:40:39,372 - INFO - epoch 2, step 21600, training loss = 3.407692, validation loss = 3.614359
2018-12-08 07:40:56,506 - INFO - epoch 2, step 21650, training loss = 3.799994, validation loss = 3.504132
2018-12-08 07:41:19,433 - INFO - epoch 2, step 21700, training loss = 3.577618, validation loss = 3.311572
2018-12-08 07:41:42,096 - INFO - epoch 2, step 21750, training loss = 3.491498, validation loss = 3.408002
2018-12-08 07:42:05,686 - INFO - epoch 2, step 21800, training loss = 3.294893, validation loss = 3.262855
2018-12-08 07:42:29,171 - INFO - epoch 2, step 21850, training loss = 3.601914, validation loss = 3.232360
2018-12-08 07:42:48,750 - INFO - epoch 2, step 21900, training loss = 2.294124, validation loss = 3.208433
2018-12-08 07:43:00,000 - INFO - epoch 2, step 21950, training loss = 3.024604, validation loss = 3.071048
2018-12-08 07:43:11,014 - INFO - epoch 2, step 22000, training loss = 3.579738, validation loss = 3.285180
2018-12-08 07:43:23,505 - INFO - epoch 2, step 22050, training loss = 3.841687, validation loss = 3.399303
2018-12-08 07:43:45,331 - INFO - epoch 2, step 22100, training loss = 3.795981, validation loss = 3.509966
2018-12-08 07:44:06,526 - INFO - epoch 2, step 22150, training loss = 3.388215, validation loss = 3.207599
2018-12-08 07:44:27,296 - INFO - epoch 2, step 22200, training loss = 3.558077, validation loss = 3.544734
2018-12-08 07:44:52,459 - INFO - epoch 2, step 22250, training loss = 3.396505, validation loss = 3.088151
2018-12-08 07:45:20,898 - INFO - epoch 2, step 22300, training loss = 3.089500, validation loss = 3.552305
2018-12-08 07:45:49,483 - INFO - epoch 2, step 22350, training loss = 3.272534, validation loss = 2.935642
2018-12-08 07:46:16,640 - INFO - epoch 2, step 22400, training loss = 3.492637, validation loss = 3.151609
2018-12-08 07:46:44,577 - INFO - epoch 2, step 22450, training loss = 3.312071, validation loss = 3.235663
2018-12-08 07:47:10,447 - INFO - epoch 2, step 22500, training loss = 3.663384, validation loss = 3.572710
2018-12-08 07:47:37,684 - INFO - epoch 2, step 22550, training loss = 3.390162, validation loss = 3.458866
2018-12-08 07:48:05,439 - INFO - epoch 2, step 22600, training loss = 3.063875, validation loss = 3.576074
2018-12-08 07:48:26,867 - INFO - epoch 2, step 22650, training loss = 3.404263, validation loss = 3.586601
2018-12-08 07:48:45,806 - INFO - epoch 2, step 22700, training loss = 3.335144, validation loss = 3.136909
2018-12-08 07:49:02,655 - INFO - epoch 2, step 22750, training loss = 3.504513, validation loss = 3.517811
2018-12-08 07:49:19,462 - INFO - epoch 2, step 22800, training loss = 3.697872, validation loss = 3.100806
2018-12-08 07:49:36,152 - INFO - epoch 2, step 22850, training loss = 2.537060, validation loss = 3.032799
2018-12-08 07:49:51,847 - INFO - epoch 2, step 22900, training loss = 2.778584, validation loss = 3.058057
2018-12-08 07:50:07,103 - INFO - epoch 2, step 22950, training loss = 3.014329, validation loss = 3.338054
2018-12-08 07:50:22,625 - INFO - epoch 2, step 23000, training loss = 3.112347, validation loss = 3.332245
2018-12-08 07:50:43,873 - INFO - epoch 2, step 23050, training loss = 3.380141, validation loss = 3.161030
2018-12-08 07:51:04,437 - INFO - epoch 2, step 23100, training loss = 3.427487, validation loss = 2.874330
2018-12-08 07:51:19,913 - INFO - epoch 2, step 23150, training loss = 2.407446, validation loss = 3.254664
2018-12-08 07:51:30,824 - INFO - epoch 2, step 23200, training loss = 2.642909, validation loss = 3.049475
2018-12-08 07:51:41,911 - INFO - epoch 2, step 23250, training loss = 3.151558, validation loss = 3.002431
2018-12-08 07:51:54,689 - INFO - epoch 2, step 23300, training loss = 3.066352, validation loss = 2.897448
2018-12-08 07:52:10,321 - INFO - epoch 2, step 23350, training loss = 2.746054, validation loss = 2.703243
2018-12-08 07:52:25,245 - INFO - epoch 2, step 23400, training loss = 2.923178, validation loss = 2.950342
2018-12-08 07:52:41,843 - INFO - epoch 2, step 23450, training loss = 3.569569, validation loss = 3.494821
2018-12-08 07:53:06,584 - INFO - epoch 2, step 23500, training loss = 3.307347, validation loss = 3.215501
2018-12-08 07:53:29,108 - INFO - epoch 2, step 23550, training loss = 3.692952, validation loss = 3.063325
2018-12-08 07:53:49,497 - INFO - epoch 2, step 23600, training loss = 3.470585, validation loss = 3.137974
2018-12-08 07:54:09,589 - INFO - epoch 2, step 23650, training loss = 3.213442, validation loss = 2.718757
2018-12-08 07:54:30,182 - INFO - epoch 2, step 23700, training loss = 3.388176, validation loss = 3.196070
2018-12-08 07:54:53,290 - INFO - epoch 2, step 23750, training loss = 3.359202, validation loss = 2.895298
2018-12-08 07:55:16,714 - INFO - epoch 2, step 23800, training loss = 3.354447, validation loss = 3.142765
2018-12-08 07:55:40,976 - INFO - epoch 2, step 23850, training loss = 3.874802, validation loss = 3.145092
2018-12-08 07:56:05,421 - INFO - epoch 2, step 23900, training loss = 3.772930, validation loss = 3.522463
2018-12-08 07:56:29,070 - INFO - epoch 2, step 23950, training loss = 3.686822, validation loss = 2.854793
2018-12-08 07:56:51,374 - INFO - epoch 2, step 24000, training loss = 3.375226, validation loss = 3.017014
2018-12-08 07:57:17,442 - INFO - epoch 2, step 24050, training loss = 3.389934, validation loss = 2.695498
2018-12-08 07:57:46,907 - INFO - epoch 2, step 24100, training loss = 3.663766, validation loss = 3.333381
2018-12-08 07:58:15,549 - INFO - epoch 2, step 24150, training loss = 3.666441, validation loss = 2.967008
2018-12-08 07:58:43,280 - INFO - epoch 2, step 24200, training loss = 3.616714, validation loss = 3.151727
2018-12-08 07:59:08,728 - INFO - epoch 2, step 24250, training loss = 3.029606, validation loss = 2.913622
2018-12-08 07:59:24,404 - INFO - epoch 2, step 24300, training loss = 2.991603, validation loss = 2.881733
2018-12-08 07:59:39,787 - INFO - epoch 2, step 24350, training loss = 2.514270, validation loss = 2.891815
2018-12-08 07:59:55,531 - INFO - epoch 2, step 24400, training loss = 2.924289, validation loss = 2.920184
2018-12-08 08:00:10,963 - INFO - epoch 2, step 24450, training loss = 3.580915, validation loss = 3.399590
2018-12-08 08:00:26,400 - INFO - epoch 2, step 24500, training loss = 3.299746, validation loss = 2.820297
2018-12-08 08:00:41,738 - INFO - epoch 2, step 24550, training loss = 2.792749, validation loss = 3.457890
2018-12-08 08:00:57,322 - INFO - epoch 2, step 24600, training loss = 4.243829, validation loss = 3.071163
2018-12-08 08:01:13,311 - INFO - epoch 2, step 24650, training loss = 3.271954, validation loss = 3.214166
2018-12-08 08:01:28,453 - INFO - epoch 2, step 24700, training loss = 3.254469, validation loss = 3.124383
2018-12-08 08:01:43,669 - INFO - epoch 2, step 24750, training loss = 3.193891, validation loss = 3.139315
2018-12-08 08:01:59,109 - INFO - epoch 2, step 24800, training loss = 2.432620, validation loss = 2.886683
2018-12-08 08:02:15,087 - INFO - epoch 2, step 24850, training loss = 2.598739, validation loss = 2.747723
2018-12-08 08:02:32,727 - INFO - epoch 2, step 24900, training loss = 3.259919, validation loss = 3.129105
2018-12-08 08:02:53,874 - INFO - epoch 2, step 24950, training loss = 3.829858, validation loss = 3.100227
2018-12-08 08:03:19,973 - INFO - epoch 2, step 25000, training loss = 3.749136, validation loss = 3.030887
2018-12-08 08:03:46,215 - INFO - epoch 2, step 25050, training loss = 3.561733, validation loss = 3.506967
2018-12-08 08:04:12,020 - INFO - epoch 2, step 25100, training loss = 3.437282, validation loss = 2.913716
2018-12-08 08:04:38,031 - INFO - epoch 2, step 25150, training loss = 3.590338, validation loss = 3.079934
2018-12-08 08:04:56,626 - INFO - epoch 2, step 25200, training loss = 3.231818, validation loss = 2.913961
2018-12-08 08:05:13,928 - INFO - epoch 2, step 25250, training loss = 3.561292, validation loss = 3.194748
2018-12-08 08:05:36,863 - INFO - epoch 2, step 25300, training loss = 3.488558, validation loss = 3.413850
2018-12-08 08:06:03,275 - INFO - epoch 2, step 25350, training loss = 3.737334, validation loss = 3.284905
2018-12-08 08:06:30,298 - INFO - epoch 2, step 25400, training loss = 3.036625, validation loss = 3.197592
2018-12-08 08:06:55,920 - INFO - epoch 2, step 25450, training loss = 3.494814, validation loss = 2.870052
2018-12-08 08:07:13,336 - INFO - epoch 2, step 25500, training loss = 2.954785, validation loss = 3.142855
2018-12-08 08:07:28,715 - INFO - epoch 2, step 25550, training loss = 3.234683, validation loss = 3.142784
2018-12-08 08:07:48,860 - INFO - epoch 2, step 25600, training loss = 3.599772, validation loss = 3.057509
2018-12-08 08:08:15,253 - INFO - epoch 2, step 25650, training loss = 3.372656, validation loss = 3.230134
2018-12-08 08:08:43,467 - INFO - epoch 2, step 25700, training loss = 3.117218, validation loss = 3.264172
2018-12-08 08:09:11,148 - INFO - epoch 2, step 25750, training loss = 3.026831, validation loss = 2.997084
2018-12-08 08:09:32,107 - INFO - epoch 2, step 25800, training loss = 3.458385, validation loss = 3.125390
2018-12-08 08:09:48,655 - INFO - epoch 2, step 25850, training loss = 3.385637, validation loss = 3.065020
2018-12-08 08:10:03,770 - INFO - epoch 2, step 25900, training loss = 2.853222, validation loss = 3.043336
2018-12-08 08:10:18,943 - INFO - epoch 2, step 25950, training loss = 3.442621, validation loss = 3.306049
2018-12-08 08:10:44,510 - INFO - epoch 2, step 26000, training loss = 3.210425, validation loss = 3.363331
2018-12-08 08:11:09,975 - INFO - epoch 2, step 26050, training loss = 2.933383, validation loss = 3.280014
2018-12-08 08:11:34,669 - INFO - epoch 2, step 26100, training loss = 2.884569, validation loss = 2.977104
2018-12-08 08:11:59,214 - INFO - epoch 2, step 26150, training loss = 3.551883, validation loss = 3.238523
2018-12-08 08:12:27,047 - INFO - epoch 2, step 26200, training loss = 3.811405, validation loss = 3.287501
2018-12-08 08:12:53,250 - INFO - epoch 2, step 26250, training loss = 3.347736, validation loss = 3.018750
2018-12-08 08:13:20,573 - INFO - epoch 2, step 26300, training loss = 3.035936, validation loss = 3.006759
2018-12-08 08:13:45,637 - INFO - epoch 2, step 26350, training loss = 3.931201, validation loss = 3.182515
2018-12-08 08:14:11,164 - INFO - epoch 2, step 26400, training loss = 3.471905, validation loss = 3.696722
2018-12-08 08:14:36,252 - INFO - epoch 2, step 26450, training loss = 3.417758, validation loss = 3.385255
2018-12-08 08:14:55,514 - INFO - epoch 2, step 26500, training loss = 3.463055, validation loss = 3.209242
2018-12-08 08:15:11,595 - INFO - epoch 2, step 26550, training loss = 3.394263, validation loss = 3.304394
2018-12-08 08:15:26,545 - INFO - epoch 2, step 26600, training loss = 3.412298, validation loss = 3.145101
2018-12-08 08:15:41,765 - INFO - epoch 2, step 26650, training loss = 2.815400, validation loss = 2.762233
2018-12-08 08:15:56,947 - INFO - epoch 2, step 26700, training loss = 2.622191, validation loss = 2.864595
2018-12-08 08:16:22,109 - INFO - epoch 2, step 26750, training loss = 3.755975, validation loss = 3.044711
2018-12-08 08:16:49,570 - INFO - epoch 2, step 26800, training loss = 3.331161, validation loss = 2.910509
2018-12-08 08:17:16,742 - INFO - epoch 2, step 26850, training loss = 3.124900, validation loss = 3.023951
2018-12-08 08:17:42,153 - INFO - epoch 2, step 26900, training loss = 3.291630, validation loss = 3.238167
2018-12-08 08:18:07,268 - INFO - epoch 2, step 26950, training loss = 3.424987, validation loss = 3.245553
2018-12-08 08:18:33,336 - INFO - epoch 2, step 27000, training loss = 3.730171, validation loss = 3.439086
2018-12-08 08:18:58,236 - INFO - epoch 2, step 27050, training loss = 3.497262, validation loss = 3.218921
2018-12-08 08:19:18,929 - INFO - epoch 2, step 27100, training loss = 3.339293, validation loss = 2.873634
2018-12-08 08:19:37,218 - INFO - epoch 2, step 27150, training loss = 4.170814, validation loss = 3.227590
2018-12-08 08:20:00,099 - INFO - epoch 2, step 27200, training loss = 3.179106, validation loss = 3.296660
2018-12-08 08:20:24,991 - INFO - epoch 2, step 27250, training loss = 3.465886, validation loss = 2.984954
2018-12-08 08:20:49,507 - INFO - epoch 2, step 27300, training loss = 3.657844, validation loss = 3.261845
2018-12-08 08:21:11,125 - INFO - epoch 2, step 27350, training loss = 2.969128, validation loss = 2.846593
2018-12-08 08:21:31,672 - INFO - epoch 2, step 27400, training loss = 3.219090, validation loss = 2.973919
2018-12-08 08:21:46,879 - INFO - epoch 2, step 27450, training loss = 3.377770, validation loss = 3.018358
2018-12-08 08:22:02,270 - INFO - epoch 2, step 27500, training loss = 2.960267, validation loss = 2.837157
2018-12-08 08:22:17,941 - INFO - epoch 2, step 27550, training loss = 2.517220, validation loss = 2.884586
2018-12-08 08:22:36,556 - INFO - epoch 2, step 27600, training loss = 3.537378, validation loss = 2.712440
2018-12-08 08:23:00,988 - INFO - epoch 2, step 27650, training loss = 3.508586, validation loss = 2.815923
2018-12-08 08:23:28,683 - INFO - epoch 2, step 27700, training loss = 3.588975, validation loss = 2.835491
2018-12-08 08:23:56,820 - INFO - epoch 2, step 27750, training loss = 3.478707, validation loss = 2.914565
2018-12-08 08:24:22,077 - INFO - epoch 2, step 27800, training loss = 3.122932, validation loss = 3.040604
2018-12-08 08:24:46,985 - INFO - epoch 2, step 27850, training loss = 2.894795, validation loss = 3.024774
2018-12-08 08:25:11,859 - INFO - epoch 2, step 27900, training loss = 3.163287, validation loss = 3.297219
2018-12-08 08:25:36,502 - INFO - epoch 2, step 27950, training loss = 2.771134, validation loss = 3.208319
2018-12-08 08:26:01,784 - INFO - epoch 2, step 28000, training loss = 3.244303, validation loss = 3.125336
2018-12-08 08:26:27,261 - INFO - epoch 2, step 28050, training loss = 3.102335, validation loss = 3.012357
2018-12-08 08:26:53,805 - INFO - epoch 2, step 28100, training loss = 2.850677, validation loss = 3.594393
2018-12-08 08:27:18,871 - INFO - epoch 2, step 28150, training loss = 3.526267, validation loss = 3.125817
2018-12-08 08:27:43,589 - INFO - epoch 2, step 28200, training loss = 3.313110, validation loss = 3.148125
2018-12-08 08:28:08,093 - INFO - epoch 2, step 28250, training loss = 2.769804, validation loss = 3.068599
2018-12-08 08:28:32,973 - INFO - epoch 2, step 28300, training loss = 3.339445, validation loss = 2.790019
2018-12-08 08:28:58,169 - INFO - epoch 2, step 28350, training loss = 3.635033, validation loss = 3.152265
2018-12-08 08:29:19,767 - INFO - epoch 2, step 28400, training loss = 3.128720, validation loss = 2.730911
2018-12-08 08:29:45,730 - INFO - epoch 2, step 28450, training loss = 3.491717, validation loss = 2.898784
2018-12-08 08:30:14,521 - INFO - epoch 2, step 28500, training loss = 3.260406, validation loss = 2.884036
2018-12-08 08:30:32,443 - INFO - epoch 2, step 28550, training loss = 3.095169, validation loss = 3.052218
2018-12-08 08:30:47,780 - INFO - epoch 2, step 28600, training loss = 3.415002, validation loss = 3.043326
2018-12-08 08:31:02,758 - INFO - epoch 2, step 28650, training loss = 3.292151, validation loss = 2.979291
2018-12-08 08:31:23,404 - INFO - epoch 2, step 28700, training loss = 3.663271, validation loss = 2.733883
2018-12-08 08:31:47,942 - INFO - epoch 2, step 28750, training loss = 3.237239, validation loss = 2.995108
2018-12-08 08:32:12,438 - INFO - epoch 2, step 28800, training loss = 3.226903, validation loss = 2.949110
2018-12-08 08:32:37,263 - INFO - epoch 2, step 28850, training loss = 3.188930, validation loss = 3.011633
2018-12-08 08:33:01,877 - INFO - epoch 2, step 28900, training loss = 2.935793, validation loss = 3.032658
2018-12-08 08:33:26,776 - INFO - epoch 2, step 28950, training loss = 3.260591, validation loss = 3.210792
2018-12-08 08:33:52,655 - INFO - epoch 2, step 29000, training loss = 3.051456, validation loss = 2.734038
2018-12-08 08:34:17,830 - INFO - epoch 2, step 29050, training loss = 3.018113, validation loss = 3.028194
2018-12-08 08:34:38,907 - INFO - epoch 2, step 29100, training loss = 3.476894, validation loss = 3.353741
2018-12-08 08:35:04,493 - INFO - epoch 2, step 29150, training loss = 3.355248, validation loss = 3.123366
2018-12-08 08:35:32,243 - INFO - epoch 2, step 29200, training loss = 3.027980, validation loss = 2.838961
2018-12-08 08:35:58,855 - INFO - epoch 2, step 29250, training loss = 3.446213, validation loss = 2.872074
2018-12-08 08:36:24,644 - INFO - epoch 2, step 29300, training loss = 3.462029, validation loss = 2.852464
2018-12-08 08:36:49,908 - INFO - epoch 2, step 29350, training loss = 3.144673, validation loss = 3.131382
2018-12-08 08:37:15,927 - INFO - epoch 2, step 29400, training loss = 3.233373, validation loss = 3.246220
2018-12-08 08:37:41,752 - INFO - epoch 2, step 29450, training loss = 3.643765, validation loss = 3.098092
2018-12-08 08:38:06,877 - INFO - epoch 2, step 29500, training loss = 3.579661, validation loss = 3.025111
2018-12-08 08:38:32,822 - INFO - epoch 2, step 29550, training loss = 3.540140, validation loss = 3.586179
2018-12-08 08:38:58,470 - INFO - epoch 2, step 29600, training loss = 3.218686, validation loss = 3.212870
2018-12-08 08:39:24,247 - INFO - epoch 2, step 29650, training loss = 2.958300, validation loss = 3.209634
2018-12-08 08:39:48,594 - INFO - epoch 2, step 29700, training loss = 3.102612, validation loss = 3.366951
2018-12-08 08:40:09,186 - INFO - epoch 2, step 29750, training loss = 3.120252, validation loss = 3.461704
2018-12-08 08:40:33,092 - INFO - epoch 2, step 29800, training loss = 3.080218, validation loss = 3.347913
2018-12-08 08:40:58,572 - INFO - epoch 2, step 29850, training loss = 2.981350, validation loss = 3.320016
2018-12-08 08:41:24,850 - INFO - epoch 2, step 29900, training loss = 3.271005, validation loss = 3.364817
2018-12-08 08:41:50,362 - INFO - epoch 2, step 29950, training loss = 3.162229, validation loss = 3.054735
2018-12-08 08:42:16,096 - INFO - epoch 2, step 30000, training loss = 3.143505, validation loss = 3.260788
2018-12-08 08:42:40,992 - INFO - epoch 2, step 30050, training loss = 2.844621, validation loss = 3.260061
2018-12-08 08:43:02,157 - INFO - epoch 2, step 30100, training loss = 3.810056, validation loss = 3.539300
2018-12-08 08:43:17,846 - INFO - epoch 2, step 30150, training loss = 2.657328, validation loss = 2.994382
2018-12-08 08:43:33,183 - INFO - epoch 2, step 30200, training loss = 3.386998, validation loss = 3.151696
2018-12-08 08:43:56,023 - INFO - epoch 2, step 30250, training loss = 3.171801, validation loss = 3.479538
2018-12-08 08:44:20,533 - INFO - epoch 2, step 30300, training loss = 3.016231, validation loss = 3.995080
2018-12-08 08:44:45,068 - INFO - epoch 2, step 30350, training loss = 3.575456, validation loss = 3.338821
2018-12-08 08:45:12,786 - INFO - epoch 2, step 30400, training loss = 3.096168, validation loss = 3.506140
2018-12-08 08:45:40,127 - INFO - epoch 2, step 30450, training loss = 3.273680, validation loss = 3.367186
2018-12-08 08:46:06,290 - INFO - epoch 2, step 30500, training loss = 3.325979, validation loss = 3.367568
2018-12-08 08:46:32,424 - INFO - epoch 2, step 30550, training loss = 3.633650, validation loss = 3.583034
2018-12-08 08:46:58,911 - INFO - epoch 2, step 30600, training loss = 3.527451, validation loss = 3.300220
2018-12-08 08:47:26,811 - INFO - epoch 2, step 30650, training loss = 3.534608, validation loss = 3.199676
2018-12-08 08:47:54,288 - INFO - epoch 2, step 30700, training loss = 3.326156, validation loss = 3.550803
2018-12-08 08:48:20,063 - INFO - epoch 2, step 30750, training loss = 4.392751, validation loss = 3.343681
2018-12-08 08:48:33,084 - INFO - epoch 2, step 30800, training loss = 3.394637, validation loss = 3.135596
2018-12-08 08:48:47,337 - INFO - epoch 2, step 30850, training loss = 3.388290, validation loss = 3.511506
2018-12-08 08:49:07,501 - INFO - epoch 2, step 30900, training loss = 3.252019, validation loss = 3.150491
2018-12-08 08:49:32,974 - INFO - epoch 2, step 30950, training loss = 3.406833, validation loss = 3.078940
2018-12-08 08:50:01,365 - INFO - epoch 2, step 31000, training loss = 3.000999, validation loss = 3.251468
2018-12-08 08:50:29,451 - INFO - epoch 2, step 31050, training loss = 3.365364, validation loss = 3.373887
2018-12-08 08:50:47,086 - INFO - epoch 2, step 31100, training loss = 2.972180, validation loss = 3.412370
2018-12-08 08:51:02,488 - INFO - epoch 2, step 31150, training loss = 2.838917, validation loss = 3.124416
2018-12-08 08:51:18,865 - INFO - epoch 2, step 31200, training loss = 3.248009, validation loss = 3.379770
2018-12-08 08:51:38,863 - INFO - epoch 2, step 31250, training loss = 3.967016, validation loss = 3.395530
2018-12-08 08:51:56,420 - INFO - epoch 2, step 31300, training loss = 3.358321, validation loss = 3.091622
2018-12-08 08:52:07,766 - INFO - epoch 2, step 31350, training loss = 2.509917, validation loss = 3.177883
2018-12-08 08:52:19,276 - INFO - epoch 2, step 31400, training loss = 2.983411, validation loss = 3.821559
2018-12-08 08:52:31,117 - INFO - epoch 2, step 31450, training loss = 3.256489, validation loss = 3.692867
2018-12-08 08:52:46,269 - INFO - epoch 2, step 31500, training loss = 2.921430, validation loss = 3.278943
2018-12-08 08:53:01,798 - INFO - epoch 2, step 31550, training loss = 3.288932, validation loss = 3.017929
2018-12-08 08:53:23,501 - INFO - epoch 2, step 31600, training loss = 3.937196, validation loss = 3.599304
2018-12-08 08:53:48,166 - INFO - epoch 2, step 31650, training loss = 2.944344, validation loss = 3.388802
2018-12-08 08:54:13,721 - INFO - epoch 2, step 31700, training loss = 3.732112, validation loss = 3.413128
2018-12-08 08:54:38,373 - INFO - epoch 2, step 31750, training loss = 3.617749, validation loss = 3.368182
2018-12-08 08:54:59,793 - INFO - epoch 2, step 31800, training loss = 3.101850, validation loss = 3.196887
2018-12-08 08:55:10,920 - INFO - epoch 2, step 31850, training loss = 2.970054, validation loss = 3.293544
2018-12-08 08:55:22,082 - INFO - epoch 2, step 31900, training loss = 3.025834, validation loss = 3.392323
2018-12-08 08:55:39,612 - INFO - epoch 2, step 31950, training loss = 3.092452, validation loss = 3.231279
2018-12-08 08:56:08,378 - INFO - epoch 2, step 32000, training loss = 3.412591, validation loss = 2.980608
2018-12-08 08:56:35,568 - INFO - epoch 2, step 32050, training loss = 3.756896, validation loss = 3.327826
2018-12-08 08:57:03,982 - INFO - epoch 2, step 32100, training loss = 3.205440, validation loss = 2.737170
2018-12-08 08:57:21,418 - INFO - epoch 2, step 32150, training loss = 2.727411, validation loss = 3.329966
2018-12-08 08:57:32,832 - INFO - epoch 2, step 32200, training loss = 3.142769, validation loss = 3.431817
2018-12-08 08:57:44,109 - INFO - epoch 2, step 32250, training loss = 2.946799, validation loss = 3.151545
2018-12-08 08:58:04,267 - INFO - epoch 2, step 32300, training loss = 3.826497, validation loss = 3.035697
2018-12-08 08:58:29,073 - INFO - epoch 2, step 32350, training loss = 3.595021, validation loss = 3.185963
2018-12-08 08:58:53,775 - INFO - epoch 2, step 32400, training loss = 3.421580, validation loss = 3.528588
2018-12-08 08:59:18,370 - INFO - epoch 2, step 32450, training loss = 3.413621, validation loss = 3.119844
2018-12-08 08:59:43,168 - INFO - epoch 2, step 32500, training loss = 3.499971, validation loss = 2.705378
2018-12-08 09:00:05,047 - INFO - epoch 2, step 32550, training loss = 3.099156, validation loss = 3.408418
2018-12-08 09:00:24,045 - INFO - epoch 2, step 32600, training loss = 3.445707, validation loss = 3.109383
2018-12-08 09:00:39,681 - INFO - epoch 2, step 32650, training loss = 3.396673, validation loss = 3.036196
2018-12-08 09:01:04,181 - INFO - epoch 2, step 32700, training loss = 3.291695, validation loss = 3.893719
2018-12-08 09:01:28,848 - INFO - epoch 2, step 32750, training loss = 2.871574, validation loss = 3.337463
2018-12-08 09:01:53,230 - INFO - epoch 2, step 32800, training loss = 3.499234, validation loss = 3.310389
2018-12-08 09:02:18,542 - INFO - epoch 2, step 32850, training loss = 2.964044, validation loss = 3.445911
2018-12-08 09:02:44,026 - INFO - epoch 2, step 32900, training loss = 3.332982, validation loss = 3.016054
2018-12-08 09:03:11,604 - INFO - epoch 2, step 32950, training loss = 3.387639, validation loss = 3.562872
2018-12-08 09:03:38,345 - INFO - epoch 2, step 33000, training loss = 3.539961, validation loss = 3.337338
2018-12-08 09:03:59,221 - INFO - epoch 2, step 33050, training loss = 3.261211, validation loss = 3.473293
2018-12-08 09:04:17,903 - INFO - epoch 2, step 33100, training loss = 3.500977, validation loss = 3.179094
2018-12-08 09:04:35,705 - INFO - epoch 2, step 33150, training loss = 3.942432, validation loss = 3.142947
2018-12-08 09:04:58,895 - INFO - epoch 2, step 33200, training loss = 3.137985, validation loss = 3.353232
2018-12-08 09:05:25,732 - INFO - epoch 2, step 33250, training loss = 2.908422, validation loss = 3.274333
2018-12-08 09:05:52,148 - INFO - epoch 2, step 33300, training loss = 3.591804, validation loss = 3.217797
2018-12-08 09:06:19,960 - INFO - epoch 2, step 33350, training loss = 3.059519, validation loss = 3.437072
2018-12-08 09:06:44,086 - INFO - epoch 2, step 33400, training loss = 3.278084, validation loss = 3.473639
2018-12-08 09:07:06,981 - INFO - epoch 2, step 33450, training loss = 3.282791, validation loss = 3.111381
2018-12-08 09:07:31,156 - INFO - epoch 2, step 33500, training loss = 3.912720, validation loss = 3.281171
2018-12-08 09:07:56,047 - INFO - epoch 2, step 33550, training loss = 3.295955, validation loss = 3.775242
2018-12-08 09:08:20,899 - INFO - epoch 2, step 33600, training loss = 2.772472, validation loss = 3.833065
2018-12-08 09:08:47,164 - INFO - epoch 2, step 33650, training loss = 3.555345, validation loss = 3.552244
2018-12-08 09:09:12,186 - INFO - epoch 2, step 33700, training loss = 2.887381, validation loss = 3.196571
2018-12-08 09:09:36,930 - INFO - epoch 2, step 33750, training loss = 3.761928, validation loss = 3.074601
2018-12-08 09:10:01,876 - INFO - epoch 2, step 33800, training loss = 2.882666, validation loss = 3.115890
2018-12-08 09:10:27,372 - INFO - epoch 2, step 33850, training loss = 2.931424, validation loss = 3.240000
2018-12-08 09:10:52,120 - INFO - epoch 2, step 33900, training loss = 3.642775, validation loss = 2.908888
2018-12-08 09:11:17,549 - INFO - epoch 2, step 33950, training loss = 3.104812, validation loss = 3.384178
2018-12-08 09:11:43,168 - INFO - epoch 2, step 34000, training loss = 3.402795, validation loss = 3.111197
2018-12-08 09:12:07,540 - INFO - epoch 2, step 34050, training loss = 3.032611, validation loss = 2.709491
2018-12-08 09:12:28,284 - INFO - epoch 2, step 34100, training loss = 2.625983, validation loss = 3.435829
2018-12-08 09:12:39,798 - INFO - epoch 2, step 34150, training loss = 3.229443, validation loss = 2.967381
2018-12-08 09:12:51,421 - INFO - epoch 2, step 34200, training loss = 2.589778, validation loss = 3.381670
2018-12-08 09:13:10,928 - INFO - epoch 2, step 34250, training loss = 3.264864, validation loss = 3.136661
2018-12-08 09:13:35,784 - INFO - epoch 2, step 34300, training loss = 3.659213, validation loss = 3.071394
2018-12-08 09:14:01,065 - INFO - epoch 2, step 34350, training loss = 3.316016, validation loss = 3.036300
2018-12-08 09:14:26,284 - INFO - epoch 2, step 34400, training loss = 2.959208, validation loss = 3.490640
2018-12-08 09:14:50,787 - INFO - epoch 2, step 34450, training loss = 3.004883, validation loss = 3.654893
2018-12-08 09:15:09,438 - INFO - epoch 2, step 34500, training loss = 3.192872, validation loss = 3.482325
2018-12-08 09:15:24,723 - INFO - epoch 2, step 34550, training loss = 3.604107, validation loss = 3.363153
2018-12-08 09:15:40,235 - INFO - epoch 2, step 34600, training loss = 2.799199, validation loss = 3.164204
2018-12-08 09:15:57,423 - INFO - epoch 2, step 34650, training loss = 3.948387, validation loss = 3.339591
2018-12-08 09:16:23,076 - INFO - epoch 2, step 34700, training loss = 3.109242, validation loss = 3.282921
2018-12-08 09:16:49,248 - INFO - epoch 2, step 34750, training loss = 3.139286, validation loss = 3.809645
2018-12-08 09:17:16,010 - INFO - epoch 2, step 34800, training loss = 3.789137, validation loss = 3.173120
2018-12-08 09:17:38,931 - INFO - epoch 2, step 34850, training loss = 3.572060, validation loss = 3.062521
2018-12-08 09:18:08,544 - INFO - epoch 2, step 34900, training loss = 3.251643, validation loss = 3.476990
2018-12-08 09:18:33,797 - INFO - epoch 2, step 34950, training loss = 3.367742, validation loss = 3.214945
2018-12-08 09:18:57,538 - INFO - epoch 2, step 35000, training loss = 3.655967, validation loss = 3.407575
2018-12-08 09:19:21,025 - INFO - epoch 2, step 35050, training loss = 3.359142, validation loss = 3.783351
2018-12-08 09:19:34,773 - INFO - epoch 2, step 35100, training loss = 2.814011, validation loss = 3.586642
2018-12-08 09:19:46,360 - INFO - epoch 2, step 35150, training loss = 3.122059, validation loss = 3.938115
2018-12-08 09:19:57,411 - INFO - epoch 2, step 35200, training loss = 3.137938, validation loss = 3.515533
2018-12-08 09:20:13,610 - INFO - epoch 2, step 35250, training loss = 3.470572, validation loss = 2.942141
2018-12-08 09:20:34,363 - INFO - epoch 2, step 35300, training loss = 3.165880, validation loss = 2.901938
2018-12-08 09:20:56,205 - INFO - epoch 2, step 35350, training loss = 3.479984, validation loss = 2.761182
2018-12-08 09:21:18,514 - INFO - epoch 2, step 35400, training loss = 3.388149, validation loss = 3.340291
2018-12-08 09:21:40,111 - INFO - epoch 2, step 35450, training loss = 3.422439, validation loss = 3.294090
2018-12-08 09:22:01,482 - INFO - epoch 2, step 35500, training loss = 3.501930, validation loss = 3.098437
2018-12-08 09:22:22,396 - INFO - epoch 2, step 35550, training loss = 3.892229, validation loss = 3.074976
2018-12-08 09:22:46,531 - INFO - epoch 2, step 35600, training loss = 3.437443, validation loss = 3.114182
2018-12-08 09:23:13,860 - INFO - epoch 2, step 35650, training loss = 3.299267, validation loss = 3.125556
2018-12-08 09:23:38,906 - INFO - epoch 2, step 35700, training loss = 3.324421, validation loss = 3.305892
2018-12-08 09:23:59,137 - INFO - epoch 2, step 35750, training loss = 4.086427, validation loss = 2.757973
2018-12-08 09:24:17,722 - INFO - epoch 2, step 35800, training loss = 3.321556, validation loss = 3.059628
2018-12-08 09:24:36,025 - INFO - epoch 2, step 35850, training loss = 3.445734, validation loss = 3.013517
2018-12-08 09:24:54,167 - INFO - epoch 2, step 35900, training loss = 3.127691, validation loss = 3.102021
2018-12-08 09:25:12,678 - INFO - epoch 2, step 35950, training loss = 3.001234, validation loss = 3.567096
2018-12-08 09:25:31,406 - INFO - epoch 2, step 36000, training loss = 3.032303, validation loss = 3.441675
2018-12-08 09:25:49,396 - INFO - epoch 2, step 36050, training loss = 3.269739, validation loss = 3.481567
2018-12-08 09:26:08,097 - INFO - epoch 2, step 36100, training loss = 3.190130, validation loss = 3.202196
2018-12-08 09:26:26,703 - INFO - epoch 2, step 36150, training loss = 2.778616, validation loss = 3.218339
2018-12-08 09:26:44,860 - INFO - epoch 2, step 36200, training loss = 2.704762, validation loss = 2.839822
2018-12-08 09:27:02,953 - INFO - epoch 2, step 36250, training loss = 3.500493, validation loss = 3.143206
2018-12-08 09:27:21,371 - INFO - epoch 2, step 36300, training loss = 3.067932, validation loss = 3.037378
2018-12-08 09:27:39,857 - INFO - epoch 2, step 36350, training loss = 2.723599, validation loss = 3.161298
2018-12-08 09:27:57,950 - INFO - epoch 2, step 36400, training loss = 3.326961, validation loss = 3.580340
2018-12-08 09:28:15,696 - INFO - epoch 2, step 36450, training loss = 3.039765, validation loss = 2.719033
2018-12-08 09:28:34,152 - INFO - epoch 2, step 36500, training loss = 2.981793, validation loss = 2.778872
2018-12-08 09:28:52,812 - INFO - epoch 2, step 36550, training loss = 2.949135, validation loss = 3.502034
2018-12-08 09:29:11,548 - INFO - epoch 2, step 36600, training loss = 2.897189, validation loss = 3.453701
2018-12-08 09:29:30,019 - INFO - epoch 2, step 36650, training loss = 3.700942, validation loss = 3.504853
2018-12-08 09:29:48,167 - INFO - epoch 2, step 36700, training loss = 2.905188, validation loss = 3.486895
2018-12-08 09:30:06,515 - INFO - epoch 2, step 36750, training loss = 2.650179, validation loss = 3.223550
2018-12-08 09:30:24,089 - INFO - epoch 2, step 36800, training loss = 5.009429, validation loss = 3.502466
2018-12-08 09:30:41,504 - INFO - epoch 2, step 36850, training loss = 5.085382, validation loss = 3.119562
2018-12-08 09:30:58,778 - INFO - epoch 2, step 36900, training loss = 4.531319, validation loss = 3.503038
2018-12-08 09:31:15,896 - INFO - epoch 2, step 36950, training loss = 4.728179, validation loss = 3.168156
2018-12-08 09:31:33,670 - INFO - epoch 2, step 37000, training loss = 4.313764, validation loss = 3.119913
2018-12-08 09:31:51,222 - INFO - epoch 2, step 37050, training loss = 4.406063, validation loss = 3.286320
2018-12-08 09:32:08,724 - INFO - epoch 2, step 37100, training loss = 4.543366, validation loss = 3.704967
2018-12-08 09:32:25,730 - INFO - epoch 2, step 37150, training loss = 4.395376, validation loss = 3.158887
2018-12-08 09:32:42,792 - INFO - epoch 2, step 37200, training loss = 4.719023, validation loss = 3.387821
2018-12-08 09:33:00,332 - INFO - epoch 2, step 37250, training loss = 4.375899, validation loss = 3.182388
2018-12-08 09:33:17,532 - INFO - epoch 2, step 37300, training loss = 4.838316, validation loss = 2.969693
2018-12-08 09:33:33,995 - INFO - epoch 2, step 37350, training loss = 4.592106, validation loss = 3.494937
2018-12-08 09:33:50,984 - INFO - epoch 2, step 37400, training loss = 4.261490, validation loss = 3.319281
2018-12-08 09:34:08,278 - INFO - epoch 2, step 37450, training loss = 4.246214, validation loss = 3.406991
2018-12-08 09:34:25,576 - INFO - epoch 2, step 37500, training loss = 4.852374, validation loss = 3.397209
2018-12-08 09:34:42,846 - INFO - epoch 2, step 37550, training loss = 4.606462, validation loss = 3.109434
2018-12-08 09:35:00,271 - INFO - epoch 2, step 37600, training loss = 4.316063, validation loss = 3.157315
2018-12-08 09:35:17,762 - INFO - epoch 2, step 37650, training loss = 4.816252, validation loss = 3.104654
2018-12-08 09:35:35,842 - INFO - epoch 2, step 37700, training loss = 5.001424, validation loss = 3.474028
2018-12-08 09:35:53,686 - INFO - epoch 2, step 37750, training loss = 4.974454, validation loss = 3.239937
2018-12-08 09:36:10,605 - INFO - epoch 2, step 37800, training loss = 4.457939, validation loss = 3.444712
2018-12-08 09:36:28,762 - INFO - epoch 2, step 37850, training loss = 4.384897, validation loss = 3.410065
2018-12-08 09:36:47,134 - INFO - epoch 2, step 37900, training loss = 4.726314, validation loss = 3.052745
2018-12-08 09:37:03,919 - INFO - epoch 2, step 37950, training loss = 4.122596, validation loss = 2.804715
2018-12-08 09:37:20,539 - INFO - epoch 2, step 38000, training loss = 4.207045, validation loss = 2.864347
2018-12-08 09:37:38,510 - INFO - epoch 2, step 38050, training loss = 4.847306, validation loss = 3.246126
2018-12-08 09:37:55,581 - INFO - epoch 2, step 38100, training loss = 4.791761, validation loss = 3.166418
2018-12-08 09:38:12,191 - INFO - epoch 2, step 38150, training loss = 3.921368, validation loss = 3.496364
2018-12-08 09:38:29,411 - INFO - epoch 2, step 38200, training loss = 3.997311, validation loss = 3.498361
2018-12-08 09:38:47,510 - INFO - epoch 2, step 38250, training loss = 4.206254, validation loss = 3.219644
2018-12-08 09:39:08,439 - INFO - epoch 2, step 38300, training loss = 4.759900, validation loss = 2.977045
2018-12-08 09:39:33,362 - INFO - epoch 2, step 38350, training loss = 4.829425, validation loss = 3.541460
2018-12-08 09:40:00,145 - INFO - epoch 2, step 38400, training loss = 5.242052, validation loss = 3.328310
2018-12-08 09:40:18,996 - INFO - epoch 2, step 38450, training loss = 4.826821, validation loss = 3.595457
2018-12-08 09:40:42,720 - INFO - epoch 2, step 38500, training loss = 5.035698, validation loss = 3.001326
2018-12-08 09:41:06,951 - INFO - epoch 2, step 38550, training loss = 4.490026, validation loss = 3.255054
2018-12-08 09:41:25,400 - INFO - epoch 2, step 38600, training loss = 4.099123, validation loss = 3.641648
2018-12-08 09:41:45,025 - INFO - epoch 2, step 38650, training loss = 3.992433, validation loss = 3.411129
2018-12-08 09:42:04,500 - INFO - epoch 2, step 38700, training loss = 4.435346, validation loss = 3.171174
2018-12-08 09:42:28,735 - INFO - epoch 2, step 38750, training loss = 4.738848, validation loss = 2.903357
2018-12-08 09:42:55,187 - INFO - epoch 2, step 38800, training loss = 4.724379, validation loss = 3.385010
2018-12-08 09:43:21,236 - INFO - epoch 2, step 38850, training loss = 5.221475, validation loss = 3.440988
2018-12-08 09:43:47,200 - INFO - epoch 2, step 38900, training loss = 4.698879, validation loss = 3.048850
2018-12-08 09:44:13,106 - INFO - epoch 2, step 38950, training loss = 4.750930, validation loss = 3.211299
2018-12-08 09:44:35,332 - INFO - epoch 2, step 39000, training loss = 4.791613, validation loss = 3.018623
2018-12-08 09:45:00,694 - INFO - epoch 2, step 39050, training loss = 4.541353, validation loss = 3.521707
2018-12-08 09:45:25,975 - INFO - epoch 2, step 39100, training loss = 4.604102, validation loss = 3.565917
2018-12-08 09:45:46,577 - INFO - epoch 2, step 39150, training loss = 4.423608, validation loss = 2.985851
2018-12-08 09:46:06,822 - INFO - epoch 2, step 39200, training loss = 4.429884, validation loss = 3.242604
2018-12-08 09:46:32,647 - INFO - epoch 2, step 39250, training loss = 4.679758, validation loss = 3.375868
2018-12-08 09:46:58,095 - INFO - epoch 2, step 39300, training loss = 4.727666, validation loss = 3.034555
2018-12-08 09:47:19,782 - INFO - epoch 2, step 39350, training loss = 4.196204, validation loss = 3.232588
2018-12-08 09:47:38,746 - INFO - epoch 2, step 39400, training loss = 4.896701, validation loss = 3.399619
2018-12-08 09:48:05,607 - INFO - epoch 2, step 39450, training loss = 4.617450, validation loss = 2.755851
2018-12-08 09:48:27,615 - INFO - epoch 2, step 39500, training loss = 4.191451, validation loss = 3.058572
2018-12-08 09:48:49,246 - INFO - epoch 2, step 39550, training loss = 4.448474, validation loss = 3.375084
2018-12-08 09:49:15,040 - INFO - epoch 2, step 39600, training loss = 4.839910, validation loss = 3.366476
2018-12-08 09:49:40,773 - INFO - epoch 2, step 39650, training loss = 4.537656, validation loss = 3.650024
2018-12-08 09:50:07,491 - INFO - epoch 2, step 39700, training loss = 4.866563, validation loss = 3.238482
2018-12-08 09:50:30,940 - INFO - epoch 2, step 39750, training loss = 4.351413, validation loss = 3.031746
2018-12-08 09:50:50,026 - INFO - epoch 2, step 39800, training loss = 4.088102, validation loss = 3.179068
2018-12-08 09:51:09,976 - INFO - epoch 2, step 39850, training loss = 4.229713, validation loss = 3.125525
2018-12-08 09:51:33,174 - INFO - epoch 2, step 39900, training loss = 4.031447, validation loss = 3.511346
2018-12-08 09:51:59,026 - INFO - epoch 2, step 39950, training loss = 4.660254, validation loss = 3.225905
2018-12-08 09:52:21,623 - INFO - epoch 2, step 40000, training loss = 4.487007, validation loss = 3.381447
2018-12-08 09:52:41,027 - INFO - epoch 2, step 40050, training loss = 4.560055, validation loss = 2.896745
2018-12-08 09:53:00,827 - INFO - epoch 2, step 40100, training loss = 4.751036, validation loss = 3.039222
2018-12-08 09:53:19,084 - INFO - epoch 2, step 40150, training loss = 4.511577, validation loss = 3.209107
2018-12-08 09:53:37,851 - INFO - epoch 2, step 40200, training loss = 4.394507, validation loss = 3.430138
2018-12-08 09:53:56,825 - INFO - epoch 2, step 40250, training loss = 3.813979, validation loss = 3.304942
2018-12-08 09:54:16,952 - INFO - epoch 2, step 40300, training loss = 4.283094, validation loss = 2.861359
2018-12-08 09:54:36,014 - INFO - epoch 2, step 40350, training loss = 4.578428, validation loss = 3.216510
2018-12-08 09:54:54,838 - INFO - epoch 2, step 40400, training loss = 4.319061, validation loss = 3.468506
2018-12-08 09:55:18,351 - INFO - epoch 2, step 40450, training loss = 4.774865, validation loss = 3.769342
2018-12-08 09:55:36,711 - INFO - epoch 2, step 40500, training loss = 4.168818, validation loss = 3.859861
2018-12-08 09:55:55,060 - INFO - epoch 2, step 40550, training loss = 4.572656, validation loss = 2.823439
2018-12-08 09:56:18,007 - INFO - epoch 2, step 40600, training loss = 4.375759, validation loss = 2.954858
2018-12-08 09:56:43,151 - INFO - epoch 2, step 40650, training loss = 4.709685, validation loss = 3.685289
2018-12-08 09:57:08,696 - INFO - epoch 2, step 40700, training loss = 3.608406, validation loss = 3.393061
2018-12-08 09:57:29,214 - INFO - epoch 2, step 40750, training loss = 4.099508, validation loss = 3.272485
2018-12-08 09:57:49,025 - INFO - epoch 2, step 40800, training loss = 4.274937, validation loss = 3.246876
2018-12-08 09:58:09,227 - INFO - epoch 2, step 40850, training loss = 4.414473, validation loss = 3.236270
2018-12-08 09:58:28,012 - INFO - epoch 2, step 40900, training loss = 4.154896, validation loss = 3.592188
2018-12-08 09:58:46,847 - INFO - epoch 2, step 40950, training loss = 4.450356, validation loss = 3.784424
2018-12-08 09:59:06,305 - INFO - epoch 2, step 41000, training loss = 4.550859, validation loss = 3.731127
2018-12-08 09:59:26,306 - INFO - epoch 2, step 41050, training loss = 3.809800, validation loss = 3.598956
2018-12-08 09:59:45,655 - INFO - epoch 2, step 41100, training loss = 4.754268, validation loss = 3.703220
2018-12-08 10:00:04,739 - INFO - epoch 2, step 41150, training loss = 4.057373, validation loss = 3.519108
2018-12-08 10:00:23,811 - INFO - epoch 2, step 41200, training loss = 4.032088, validation loss = 3.319779
2018-12-08 10:00:43,424 - INFO - epoch 2, step 41250, training loss = 4.340563, validation loss = 3.357465
2018-12-08 10:01:02,277 - INFO - epoch 2, step 41300, training loss = 4.278913, validation loss = 3.535328
2018-12-08 10:01:21,054 - INFO - epoch 2, step 41350, training loss = 4.044155, validation loss = 3.302116
2018-12-08 10:01:43,532 - INFO - epoch 2, step 41400, training loss = 4.462760, validation loss = 3.258864
2018-12-08 10:02:10,008 - INFO - epoch 2, step 41450, training loss = 4.787627, validation loss = 3.354417
2018-12-08 10:02:34,505 - INFO - epoch 2, step 41500, training loss = 4.342624, validation loss = 3.443124
2018-12-08 10:02:54,470 - INFO - epoch 2, step 41550, training loss = 4.668659, validation loss = 3.293839
2018-12-08 10:03:20,180 - INFO - epoch 2, step 41600, training loss = 5.102134, validation loss = 3.353061
2018-12-08 10:03:44,548 - INFO - epoch 2, step 41650, training loss = 3.570086, validation loss = 3.175776
2018-12-08 10:04:04,249 - INFO - epoch 2, step 41700, training loss = 3.670542, validation loss = 3.062135
2018-12-08 10:04:26,937 - INFO - epoch 2, step 41750, training loss = 4.677458, validation loss = 3.302358
2018-12-08 10:04:47,659 - INFO - epoch 2, step 41800, training loss = 4.370774, validation loss = 3.779356
2018-12-08 10:05:07,110 - INFO - epoch 2, step 41850, training loss = 4.236014, validation loss = 3.170029
2018-12-08 10:05:26,505 - INFO - epoch 2, step 41900, training loss = 4.885141, validation loss = 3.160329
2018-12-08 10:05:52,059 - INFO - epoch 2, step 41950, training loss = 4.777194, validation loss = 3.316330
2018-12-08 10:06:17,571 - INFO - epoch 2, step 42000, training loss = 4.353868, validation loss = 3.677236
2018-12-08 10:06:36,455 - INFO - epoch 2, step 42050, training loss = 4.213648, validation loss = 3.648029
2018-12-08 10:06:56,447 - INFO - epoch 2, step 42100, training loss = 4.173587, validation loss = 3.246399
2018-12-08 10:07:19,497 - INFO - epoch 2, step 42150, training loss = 4.747836, validation loss = 3.051610
2018-12-08 10:07:44,251 - INFO - epoch 2, step 42200, training loss = 4.887017, validation loss = 3.157315
2018-12-08 10:08:03,832 - INFO - epoch 2, step 42250, training loss = 4.625664, validation loss = 3.182388
2018-12-08 10:08:22,869 - INFO - epoch 2, step 42300, training loss = 4.145398, validation loss = 3.669829
2018-12-08 10:08:42,144 - INFO - epoch 2, step 42350, training loss = 3.838676, validation loss = 3.896161
2018-12-08 10:09:02,076 - INFO - epoch 2, step 42400, training loss = 3.363126, validation loss = 3.559312
2018-12-08 10:09:26,795 - INFO - epoch 2, step 42450, training loss = 4.641814, validation loss = 3.803987
2018-12-08 10:09:52,370 - INFO - epoch 2, step 42500, training loss = 4.671587, validation loss = 3.318639
2018-12-08 10:10:16,816 - INFO - epoch 2, step 42550, training loss = 5.056288, validation loss = 3.070662
2018-12-08 10:10:35,598 - INFO - epoch 2, step 42600, training loss = 4.466230, validation loss = 3.530254
2018-12-08 10:10:54,715 - INFO - epoch 2, step 42650, training loss = 4.361415, validation loss = 3.434773
2018-12-08 10:11:14,698 - INFO - epoch 2, step 42700, training loss = 3.416425, validation loss = 3.617111
2018-12-08 10:11:35,113 - INFO - epoch 2, step 42750, training loss = 4.488773, validation loss = 2.881854
2018-12-08 10:12:03,176 - INFO - epoch 2, step 42800, training loss = 4.717518, validation loss = 3.275656
2018-12-08 10:12:27,077 - INFO - epoch 2, step 42850, training loss = 4.716533, validation loss = 3.338897
2018-12-08 10:12:45,153 - INFO - epoch 2, step 42900, training loss = 4.735590, validation loss = 3.823050
2018-12-08 10:13:03,721 - INFO - epoch 2, step 42950, training loss = 4.589334, validation loss = 3.298413
2018-12-08 10:13:23,681 - INFO - epoch 2, step 43000, training loss = 4.355422, validation loss = 2.875153
2018-12-08 10:13:47,207 - INFO - epoch 2, step 43050, training loss = 4.336684, validation loss = 3.127228
2018-12-08 10:14:11,590 - INFO - epoch 2, step 43100, training loss = 4.470115, validation loss = 3.609794
2018-12-08 10:14:31,234 - INFO - epoch 2, step 43150, training loss = 4.035611, validation loss = 3.940905
2018-12-08 10:14:51,293 - INFO - epoch 2, step 43200, training loss = 4.155881, validation loss = 3.332918
2018-12-08 10:15:10,532 - INFO - epoch 2, step 43250, training loss = 4.474941, validation loss = 3.133345
2018-12-08 10:15:37,202 - INFO - epoch 2, step 43300, training loss = 4.290828, validation loss = 3.297749
2018-12-08 10:15:58,232 - INFO - epoch 2, step 43350, training loss = 4.424904, validation loss = 3.203902
2018-12-08 10:16:18,301 - INFO - epoch 2, step 43400, training loss = 3.868252, validation loss = 3.771829
2018-12-08 10:16:38,624 - INFO - epoch 2, step 43450, training loss = 4.497954, validation loss = 3.126287
2018-12-08 10:16:58,261 - INFO - epoch 2, step 43500, training loss = 4.187050, validation loss = 3.050729
2018-12-08 10:17:21,200 - INFO - epoch 2, step 43550, training loss = 4.447948, validation loss = 3.331813
2018-12-08 10:17:41,854 - INFO - epoch 2, step 43600, training loss = 4.563271, validation loss = 3.628997
2018-12-08 10:18:02,731 - INFO - epoch 2, step 43650, training loss = 4.570051, validation loss = 3.300525
2018-12-08 10:18:25,199 - INFO - epoch 2, step 43700, training loss = 4.341253, validation loss = 3.664299
2018-12-08 10:18:44,579 - INFO - epoch 2, step 43750, training loss = 3.892156, validation loss = 3.781667
2018-12-08 10:19:07,197 - INFO - epoch 2, step 43800, training loss = 4.377823, validation loss = 3.406553
2018-12-08 10:19:28,410 - INFO - epoch 2, step 43850, training loss = 4.720582, validation loss = 3.030739
2018-12-08 10:19:47,833 - INFO - epoch 2, step 43900, training loss = 4.400529, validation loss = 3.152769
2018-12-08 10:20:07,777 - INFO - epoch 2, step 43950, training loss = 3.825241, validation loss = 3.489294
2018-12-08 10:20:28,225 - INFO - epoch 2, step 44000, training loss = 4.100732, validation loss = 3.421658
2018-12-08 10:20:47,726 - INFO - epoch 2, step 44050, training loss = 3.912487, validation loss = 3.115730
2018-12-08 10:21:07,932 - INFO - epoch 2, step 44100, training loss = 3.866450, validation loss = 2.726300
2018-12-08 10:21:28,591 - INFO - epoch 2, step 44150, training loss = 4.052777, validation loss = 3.467196
2018-12-08 10:21:48,258 - INFO - epoch 2, step 44200, training loss = 4.413640, validation loss = 3.482482
2018-12-08 10:22:07,739 - INFO - epoch 2, step 44250, training loss = 3.639581, validation loss = 3.527946
2018-12-08 10:22:28,199 - INFO - epoch 2, step 44300, training loss = 4.055022, validation loss = 3.355772
2018-12-08 10:22:48,370 - INFO - epoch 2, step 44350, training loss = 4.503380, validation loss = 3.491249
2018-12-08 10:23:07,364 - INFO - epoch 2, step 44400, training loss = 4.564059, validation loss = 3.316145
2018-12-08 10:23:25,925 - INFO - epoch 2, step 44450, training loss = 4.323394, validation loss = 3.717664
2018-12-08 10:23:46,428 - INFO - epoch 2, step 44500, training loss = 4.332860, validation loss = 3.436800
2018-12-08 10:24:09,065 - INFO - epoch 2, step 44550, training loss = 4.273984, validation loss = 3.052858
2018-12-08 10:24:29,253 - INFO - epoch 2, step 44600, training loss = 4.086990, validation loss = 3.304493
2018-12-08 10:24:52,680 - INFO - epoch 2, step 44650, training loss = 4.595223, validation loss = 3.353831
2018-12-08 10:25:18,712 - INFO - epoch 2, step 44700, training loss = 4.333575, validation loss = 3.509730
2018-12-08 10:25:40,348 - INFO - epoch 2, step 44750, training loss = 4.225776, validation loss = 3.101051
2018-12-08 10:26:02,162 - INFO - epoch 2, step 44800, training loss = 4.080253, validation loss = 2.813180
2018-12-08 10:26:23,353 - INFO - epoch 2, step 44850, training loss = 4.605859, validation loss = 3.439304
2018-12-08 10:26:41,833 - INFO - epoch 2, step 44900, training loss = 4.228493, validation loss = 3.793995
2018-12-08 10:27:01,483 - INFO - epoch 2, step 44950, training loss = 3.924928, validation loss = 3.582201
2018-12-08 10:27:23,748 - INFO - epoch 2, step 45000, training loss = 4.417784, validation loss = 3.395154
2018-12-08 10:27:47,028 - INFO - epoch 2, step 45050, training loss = 4.374361, validation loss = 3.790903
2018-12-08 10:28:09,650 - INFO - epoch 2, step 45100, training loss = 3.783408, validation loss = 3.318697
2018-12-08 10:28:29,097 - INFO - epoch 2, step 45150, training loss = 4.216268, validation loss = 3.646693
2018-12-08 10:28:53,186 - INFO - epoch 2, step 45200, training loss = 4.615371, validation loss = 3.340464
2018-12-08 10:29:14,230 - INFO - epoch 2, step 45250, training loss = 4.286433, validation loss = 3.559453
2018-12-08 10:29:36,108 - INFO - epoch 2, step 45300, training loss = 4.269228, validation loss = 3.707091
2018-12-08 10:30:01,941 - INFO - epoch 2, step 45350, training loss = 4.304305, validation loss = 3.725427
2018-12-08 10:30:27,793 - INFO - epoch 2, step 45400, training loss = 4.468017, validation loss = 3.131964
2018-12-08 10:30:53,437 - INFO - epoch 2, step 45450, training loss = 4.289108, validation loss = 3.352193
2018-12-08 10:31:13,088 - INFO - epoch 2, step 45500, training loss = 4.343233, validation loss = 3.717710
2018-12-08 10:31:36,177 - INFO - epoch 2, step 45550, training loss = 4.733171, validation loss = 3.567481
2018-12-08 10:31:54,838 - INFO - epoch 2, step 45600, training loss = 4.558285, validation loss = 3.193353
2018-12-08 10:32:13,146 - INFO - epoch 2, step 45650, training loss = 4.377346, validation loss = 3.192113
2018-12-08 10:32:31,992 - INFO - epoch 2, step 45700, training loss = 4.512519, validation loss = 3.662246
2018-12-08 10:32:50,703 - INFO - epoch 2, step 45750, training loss = 4.264347, validation loss = 3.716506
2018-12-08 10:33:09,269 - INFO - epoch 2, step 45800, training loss = 4.595926, validation loss = 3.627405
2018-12-08 10:33:33,981 - INFO - epoch 2, step 45850, training loss = 4.251070, validation loss = 3.321604
2018-12-08 10:34:00,267 - INFO - epoch 2, step 45900, training loss = 4.760264, validation loss = 2.957023
2018-12-08 10:34:27,630 - INFO - epoch 2, step 45950, training loss = 4.223567, validation loss = 3.452560
2018-12-08 10:34:54,479 - INFO - epoch 2, step 46000, training loss = 4.827822, validation loss = 3.782968
2018-12-08 10:35:15,768 - INFO - epoch 2, step 46050, training loss = 4.454466, validation loss = 3.718068
2018-12-08 10:35:35,766 - INFO - epoch 2, step 46100, training loss = 4.183523, validation loss = 3.349541
2018-12-08 10:35:55,994 - INFO - epoch 2, step 46150, training loss = 3.642101, validation loss = 3.226810
2018-12-08 10:36:15,059 - INFO - epoch 2, step 46200, training loss = 4.140710, validation loss = 3.881443
2018-12-08 10:36:34,650 - INFO - epoch 2, step 46250, training loss = 4.242601, validation loss = 3.787289
2018-12-08 10:36:55,130 - INFO - epoch 2, step 46300, training loss = 4.103329, validation loss = 3.914898
2018-12-08 10:37:14,648 - INFO - epoch 2, step 46350, training loss = 4.284288, validation loss = 3.416369
2018-12-08 10:37:34,215 - INFO - epoch 2, step 46400, training loss = 4.389043, validation loss = 4.040403
2018-12-08 10:37:54,722 - INFO - epoch 2, step 46450, training loss = 4.066428, validation loss = 3.697345
2018-12-08 10:38:19,607 - INFO - epoch 2, step 46500, training loss = 4.231158, validation loss = 3.920733
2018-12-08 10:38:42,569 - INFO - epoch 2, step 46550, training loss = 4.186261, validation loss = 3.811571
2018-12-08 10:39:03,380 - INFO - epoch 2, step 46600, training loss = 4.824173, validation loss = 3.947204
2018-12-08 10:39:30,045 - INFO - epoch 2, step 46650, training loss = 4.222885, validation loss = 3.045143
2018-12-08 10:39:48,659 - INFO - epoch 2, step 46700, training loss = 4.402818, validation loss = 3.460104
2018-12-08 10:40:08,946 - INFO - epoch 2, step 46750, training loss = 3.410227, validation loss = 3.485740
2018-12-08 10:40:29,113 - INFO - epoch 2, step 46800, training loss = 4.295258, validation loss = 3.741549
2018-12-08 10:40:47,933 - INFO - epoch 2, step 46850, training loss = 4.533415, validation loss = 3.708140
2018-12-08 10:41:06,964 - INFO - epoch 2, step 46900, training loss = 4.084313, validation loss = 3.263337
2018-12-08 10:41:31,910 - INFO - epoch 2, step 46950, training loss = 4.527324, validation loss = 3.522851
2018-12-08 10:41:59,081 - INFO - epoch 2, step 47000, training loss = 4.873123, validation loss = 3.573560
2018-12-08 10:42:23,617 - INFO - epoch 2, step 47050, training loss = 4.294033, validation loss = 3.035025
2018-12-08 10:42:45,383 - INFO - epoch 2, step 47100, training loss = 4.029289, validation loss = 3.438239
2018-12-08 10:43:06,631 - INFO - epoch 2, step 47150, training loss = 4.102144, validation loss = 3.092581
2018-12-08 10:43:26,493 - INFO - epoch 2, step 47200, training loss = 3.163957, validation loss = 2.937961
2018-12-08 10:43:41,995 - INFO - epoch 2, step 47250, training loss = 2.566766, validation loss = 3.400522
2018-12-08 10:44:00,172 - INFO - epoch 2, step 47300, training loss = 2.818966, validation loss = 3.260257
2018-12-08 10:44:18,893 - INFO - epoch 2, step 47350, training loss = 2.573621, validation loss = 3.109375
2018-12-08 10:44:34,699 - INFO - epoch 2, step 47400, training loss = 2.590236, validation loss = 3.056744
2018-12-08 10:44:51,814 - INFO - epoch 2, step 47450, training loss = 2.642168, validation loss = 2.917359
2018-12-08 10:45:10,073 - INFO - epoch 2, step 47500, training loss = 2.500506, validation loss = 3.070383
2018-12-08 10:45:27,839 - INFO - epoch 2, step 47550, training loss = 2.857637, validation loss = 3.274939
2018-12-08 10:45:45,266 - INFO - epoch 2, step 47600, training loss = 2.699430, validation loss = 2.869736
2018-12-08 10:46:01,844 - INFO - epoch 2, step 47650, training loss = 2.706894, validation loss = 2.937482
2018-12-08 10:46:17,235 - INFO - epoch 2, step 47700, training loss = 2.806348, validation loss = 3.246618
2018-12-08 10:46:33,640 - INFO - epoch 2, step 47750, training loss = 2.739395, validation loss = 3.147889
2018-12-08 10:46:51,287 - INFO - epoch 2, step 47800, training loss = 2.753906, validation loss = 3.067878
2018-12-08 10:47:10,433 - INFO - epoch 2, step 47850, training loss = 2.400830, validation loss = 2.838181
2018-12-08 10:47:31,948 - INFO - epoch 2, step 47900, training loss = 2.863472, validation loss = 3.071096
2018-12-08 10:47:53,541 - INFO - epoch 2, step 47950, training loss = 2.942525, validation loss = 3.386952
2018-12-08 10:48:13,756 - INFO - epoch 2, step 48000, training loss = 2.670678, validation loss = 3.243106
2018-12-08 10:48:30,777 - INFO - epoch 2, step 48050, training loss = 2.570663, validation loss = 3.227676
2018-12-08 10:48:47,184 - INFO - epoch 2, step 48100, training loss = 2.656352, validation loss = 3.129873
2018-12-08 10:49:04,669 - INFO - epoch 2, step 48150, training loss = 2.542502, validation loss = 3.223691
2018-12-08 10:49:25,096 - INFO - epoch 2, step 48200, training loss = 2.225643, validation loss = 2.807888
2018-12-08 10:49:45,352 - INFO - epoch 2, step 48250, training loss = 2.512771, validation loss = 3.020078
2018-12-08 10:50:04,453 - INFO - epoch 2, step 48300, training loss = 2.364595, validation loss = 3.258677
2018-12-08 10:50:25,663 - INFO - epoch 2, step 48350, training loss = 2.807701, validation loss = 3.053406
2018-12-08 10:50:47,219 - INFO - epoch 2, step 48400, training loss = 2.678004, validation loss = 3.103546
2018-12-08 10:51:07,750 - INFO - epoch 2, step 48450, training loss = 2.602354, validation loss = 3.001678
2018-12-08 10:51:25,122 - INFO - epoch 2, step 48500, training loss = 2.772720, validation loss = 2.919070
2018-12-08 10:51:40,809 - INFO - epoch 2, step 48550, training loss = 2.678775, validation loss = 2.838368
2018-12-08 10:51:57,181 - INFO - epoch 2, step 48600, training loss = 2.361916, validation loss = 3.121486
2018-12-08 10:52:15,251 - INFO - epoch 2, step 48650, training loss = 2.574250, validation loss = 2.848421
2018-12-08 10:52:35,107 - INFO - epoch 2, step 48700, training loss = 2.556595, validation loss = 2.884289
2018-12-08 10:52:55,153 - INFO - epoch 2, step 48750, training loss = 2.347927, validation loss = 2.984328
2018-12-08 10:53:16,019 - INFO - epoch 2, step 48800, training loss = 2.106788, validation loss = 3.168030
2018-12-08 10:53:36,775 - INFO - epoch 2, step 48850, training loss = 2.872678, validation loss = 2.733974
2018-12-08 10:53:55,914 - INFO - epoch 2, step 48900, training loss = 2.612735, validation loss = 3.130563
2018-12-08 10:54:14,298 - INFO - epoch 2, step 48950, training loss = 2.520327, validation loss = 3.123610
2018-12-08 10:54:31,621 - INFO - epoch 2, step 49000, training loss = 2.438734, validation loss = 2.952981
2018-12-08 10:54:47,603 - INFO - epoch 2, step 49050, training loss = 2.247385, validation loss = 2.919552
2018-12-08 10:55:06,507 - INFO - epoch 2, step 49100, training loss = 2.382161, validation loss = 3.154986
2018-12-08 10:55:24,442 - INFO - epoch 2, step 49150, training loss = 2.410764, validation loss = 3.252359
2018-12-08 10:55:42,174 - INFO - epoch 2, step 49200, training loss = 2.508083, validation loss = 3.293583
2018-12-08 10:56:02,202 - INFO - epoch 2, step 49250, training loss = 2.268919, validation loss = 2.836007
2018-12-08 10:56:20,658 - INFO - epoch 2, step 49300, training loss = 2.394951, validation loss = 3.302798
2018-12-08 10:56:37,168 - INFO - epoch 2, step 49350, training loss = 2.644205, validation loss = 3.342512
2018-12-08 10:56:53,500 - INFO - epoch 2, step 49400, training loss = 2.568809, validation loss = 2.869414
2018-12-08 10:57:08,576 - INFO - epoch 2, step 49450, training loss = 2.840965, validation loss = 3.029747
2018-12-08 10:57:25,464 - INFO - epoch 2, step 49500, training loss = 2.359257, validation loss = 3.158643
2018-12-08 10:57:40,873 - INFO - epoch 2, step 49550, training loss = 2.640640, validation loss = 2.920371
2018-12-08 10:57:57,476 - INFO - epoch 2, step 49600, training loss = 2.104503, validation loss = 2.980733
2018-12-08 10:58:16,740 - INFO - epoch 2, step 49650, training loss = 2.252300, validation loss = 3.021791
2018-12-08 10:58:38,604 - INFO - epoch 2, step 49700, training loss = 2.749229, validation loss = 3.185481
2018-12-08 10:59:00,127 - INFO - epoch 2, step 49750, training loss = 2.549429, validation loss = 3.315779
2018-12-08 10:59:20,077 - INFO - epoch 2, step 49800, training loss = 2.854716, validation loss = 3.335438
2018-12-08 10:59:36,285 - INFO - epoch 2, step 49850, training loss = 2.350615, validation loss = 3.564875
2018-12-08 10:59:54,170 - INFO - epoch 2, step 49900, training loss = 2.638764, validation loss = 3.075142
2018-12-08 11:00:13,519 - INFO - epoch 2, step 49950, training loss = 2.094585, validation loss = 3.235083
2018-12-08 11:00:34,013 - INFO - epoch 2, step 50000, training loss = 2.431958, validation loss = 2.844956
2018-12-08 11:00:54,681 - INFO - epoch 2, step 50050, training loss = 2.196591, validation loss = 3.165340
2018-12-08 11:01:14,245 - INFO - epoch 2, step 50100, training loss = 2.631430, validation loss = 3.265677
2018-12-08 11:01:31,167 - INFO - epoch 2, step 50150, training loss = 1.926951, validation loss = 3.297088
2018-12-08 11:01:52,037 - INFO - epoch 2, step 50200, training loss = 2.390501, validation loss = 3.227703
2018-12-08 11:02:12,669 - INFO - epoch 2, step 50250, training loss = 2.924013, validation loss = 2.812162
2018-12-08 11:02:33,869 - INFO - epoch 2, step 50300, training loss = 2.487305, validation loss = 3.164644
2018-12-08 11:02:55,189 - INFO - epoch 2, step 50350, training loss = 2.456974, validation loss = 3.042605
2018-12-08 11:03:16,419 - INFO - epoch 2, step 50400, training loss = 2.413762, validation loss = 3.100377
2018-12-08 11:03:34,750 - INFO - epoch 2, step 50450, training loss = 2.417263, validation loss = 2.784812
2018-12-08 11:03:51,584 - INFO - epoch 2, step 50500, training loss = 2.799858, validation loss = 2.950227
2018-12-08 11:04:07,216 - INFO - epoch 2, step 50550, training loss = 2.786102, validation loss = 3.058002
2018-12-08 11:04:27,511 - INFO - epoch 2, step 50600, training loss = 2.465289, validation loss = 3.257982
2018-12-08 11:04:48,156 - INFO - epoch 2, step 50650, training loss = 2.342876, validation loss = 3.110858
2018-12-08 11:05:08,732 - INFO - epoch 2, step 50700, training loss = 2.529437, validation loss = 2.904614
2018-12-08 11:05:26,274 - INFO - epoch 2, step 50750, training loss = 2.244644, validation loss = 3.387552
2018-12-08 11:05:42,859 - INFO - epoch 2, step 50800, training loss = 2.576437, validation loss = 3.460143
2018-12-08 11:06:00,062 - INFO - epoch 2, step 50850, training loss = 1.991962, validation loss = 3.132078
2018-12-08 11:06:18,329 - INFO - epoch 2, step 50900, training loss = 2.192104, validation loss = 3.144746
2018-12-08 11:06:35,679 - INFO - epoch 2, step 50950, training loss = 2.443641, validation loss = 2.971268
2018-12-08 11:06:52,512 - INFO - epoch 2, step 51000, training loss = 2.783258, validation loss = 3.455851
2018-12-08 11:07:09,589 - INFO - epoch 2, step 51050, training loss = 2.511662, validation loss = 3.115914
2018-12-08 11:07:29,072 - INFO - epoch 2, step 51100, training loss = 2.474262, validation loss = 2.825769
2018-12-08 11:07:48,398 - INFO - epoch 2, step 51150, training loss = 2.425301, validation loss = 3.030885
2018-12-08 11:08:06,770 - INFO - epoch 2, step 51200, training loss = 2.211823, validation loss = 3.179543
2018-12-08 11:08:24,217 - INFO - epoch 2, step 51250, training loss = 2.257292, validation loss = 2.761505
2018-12-08 11:08:41,027 - INFO - epoch 2, step 51300, training loss = 2.490368, validation loss = 3.334560
2018-12-08 11:08:56,366 - INFO - epoch 2, step 51350, training loss = 2.494411, validation loss = 3.222487
2018-12-08 11:09:11,979 - INFO - epoch 2, step 51400, training loss = 2.540152, validation loss = 3.089895
2018-12-08 11:09:30,276 - INFO - epoch 2, step 51450, training loss = 2.178454, validation loss = 3.312469
2018-12-08 11:09:50,467 - INFO - epoch 2, step 51500, training loss = 2.344907, validation loss = 3.437177
2018-12-08 11:10:10,389 - INFO - epoch 2, step 51550, training loss = 2.168780, validation loss = 2.953373
2018-12-08 11:10:29,374 - INFO - epoch 2, step 51600, training loss = 2.470600, validation loss = 3.596324
2018-12-08 11:10:48,626 - INFO - epoch 2, step 51650, training loss = 2.300276, validation loss = 3.342034
2018-12-08 11:11:07,128 - INFO - epoch 2, step 51700, training loss = 2.230418, validation loss = 3.422773
2018-12-08 11:11:27,691 - INFO - epoch 2, step 51750, training loss = 2.324149, validation loss = 3.516369
2018-12-08 11:11:49,091 - INFO - epoch 2, step 51800, training loss = 2.280863, validation loss = 3.886978
2018-12-08 11:12:09,893 - INFO - epoch 2, step 51850, training loss = 2.577037, validation loss = 3.403091
2018-12-08 11:12:25,352 - INFO - epoch 2, step 51900, training loss = 2.226411, validation loss = 3.379107
2018-12-08 11:12:41,346 - INFO - epoch 2, step 51950, training loss = 2.169118, validation loss = 3.366153
2018-12-08 11:12:58,424 - INFO - epoch 2, step 52000, training loss = 2.580727, validation loss = 3.439265
2018-12-08 11:13:18,362 - INFO - epoch 2, step 52050, training loss = 2.538973, validation loss = 3.301014
2018-12-08 11:13:39,055 - INFO - epoch 2, step 52100, training loss = 2.559370, validation loss = 3.423305
2018-12-08 11:13:58,948 - INFO - epoch 2, step 52150, training loss = 2.069474, validation loss = 3.340748
2018-12-08 11:14:14,925 - INFO - epoch 2, step 52200, training loss = 2.523772, validation loss = 3.153391
2018-12-08 11:14:30,755 - INFO - epoch 2, step 52250, training loss = 2.819148, validation loss = 3.548790
2018-12-08 11:14:47,223 - INFO - epoch 2, step 52300, training loss = 2.321681, validation loss = 3.662902
2018-12-08 11:15:08,808 - INFO - epoch 2, step 52350, training loss = 2.334484, validation loss = 3.632545
2018-12-08 11:15:27,537 - INFO - epoch 2, step 52400, training loss = 2.597385, validation loss = 3.438901
2018-12-08 11:15:43,409 - INFO - epoch 2, step 52450, training loss = 2.768151, validation loss = 3.309318
2018-12-08 11:15:59,456 - INFO - epoch 2, step 52500, training loss = 2.506234, validation loss = 3.380172
2018-12-08 11:16:18,144 - INFO - epoch 2, step 52550, training loss = 2.461885, validation loss = 3.384470
2018-12-08 11:16:37,655 - INFO - epoch 2, step 52600, training loss = 2.625587, validation loss = 3.165112
2018-12-08 11:16:54,434 - INFO - epoch 2, step 52650, training loss = 2.419246, validation loss = 3.358613
2018-12-08 11:17:14,004 - INFO - epoch 2, step 52700, training loss = 2.350242, validation loss = 3.387250
2018-12-08 11:17:34,778 - INFO - epoch 2, step 52750, training loss = 2.226525, validation loss = 3.284236
2018-12-08 11:17:55,693 - INFO - epoch 2, step 52800, training loss = 2.384239, validation loss = 3.375965
2018-12-08 11:18:17,532 - INFO - epoch 2, step 52850, training loss = 2.350334, validation loss = 3.519958
2018-12-08 11:18:35,484 - INFO - epoch 2, step 52900, training loss = 2.413138, validation loss = 3.654059
2018-12-08 11:18:51,016 - INFO - epoch 2, step 52950, training loss = 2.436078, validation loss = 3.590944
2018-12-08 11:19:06,609 - INFO - epoch 2, step 53000, training loss = 2.471795, validation loss = 3.523858
2018-12-08 11:19:23,662 - INFO - epoch 2, step 53050, training loss = 2.195886, validation loss = 3.685559
2018-12-08 11:19:41,678 - INFO - epoch 2, step 53100, training loss = 2.148245, validation loss = 3.544624
2018-12-08 11:20:00,435 - INFO - epoch 2, step 53150, training loss = 2.331788, validation loss = 3.419607
2018-12-08 11:20:18,431 - INFO - epoch 2, step 53200, training loss = 2.298309, validation loss = 3.060348
2018-12-08 11:20:39,304 - INFO - epoch 2, step 53250, training loss = 2.677837, validation loss = 3.671039
2018-12-08 11:21:02,858 - INFO - epoch 2, step 53300, training loss = 2.304812, validation loss = 3.425931
2018-12-08 11:21:23,493 - INFO - epoch 2, step 53350, training loss = 2.246833, validation loss = 3.804298
2018-12-08 11:21:44,685 - INFO - epoch 2, step 53400, training loss = 2.345653, validation loss = 3.465779
2018-12-08 11:22:06,699 - INFO - epoch 2, step 53450, training loss = 2.734054, validation loss = 3.901905
2018-12-08 11:22:26,596 - INFO - epoch 2, step 53500, training loss = 2.334431, validation loss = 2.929979
2018-12-08 11:22:43,871 - INFO - epoch 2, step 53550, training loss = 2.673170, validation loss = 3.087516
2018-12-08 11:22:59,776 - INFO - epoch 2, step 53600, training loss = 2.490495, validation loss = 3.325666
2018-12-08 11:23:18,056 - INFO - epoch 2, step 53650, training loss = 2.588338, validation loss = 3.246409
2018-12-08 11:23:37,104 - INFO - epoch 2, step 53700, training loss = 2.481648, validation loss = 3.458776
2018-12-08 11:23:57,497 - INFO - epoch 2, step 53750, training loss = 2.180300, validation loss = 2.876463
2018-12-08 11:24:16,434 - INFO - epoch 2, step 53800, training loss = 2.310802, validation loss = 3.154832
2018-12-08 11:24:33,042 - INFO - epoch 2, step 53850, training loss = 2.503906, validation loss = 3.188325
2018-12-08 11:24:48,371 - INFO - epoch 2, step 53900, training loss = 2.491480, validation loss = 3.448521
2018-12-08 11:25:04,427 - INFO - epoch 2, step 53950, training loss = 1.883429, validation loss = 3.436100
2018-12-08 11:25:22,127 - INFO - epoch 2, step 54000, training loss = 2.094059, validation loss = 3.531386
2018-12-08 11:25:44,618 - INFO - epoch 2, step 54050, training loss = 2.478591, validation loss = 3.556611
2018-12-08 11:26:02,894 - INFO - epoch 2, step 54100, training loss = 2.403244, validation loss = 3.547312
2018-12-08 11:26:18,390 - INFO - epoch 2, step 54150, training loss = 2.437774, validation loss = 3.052514
2018-12-08 11:26:34,526 - INFO - epoch 2, step 54200, training loss = 2.391600, validation loss = 3.813799
2018-12-08 11:26:52,806 - INFO - epoch 2, step 54250, training loss = 2.521534, validation loss = 3.052695
2018-12-08 11:27:13,182 - INFO - epoch 2, step 54300, training loss = 2.149789, validation loss = 3.351363
2018-12-08 11:27:29,968 - INFO - epoch 2, step 54350, training loss = 2.320225, validation loss = 3.460174
2018-12-08 11:27:46,515 - INFO - epoch 2, step 54400, training loss = 2.787697, validation loss = 3.655441
2018-12-08 11:28:03,492 - INFO - epoch 2, step 54450, training loss = 2.569602, validation loss = 3.523349
2018-12-08 11:28:24,975 - INFO - epoch 2, step 54500, training loss = 1.882892, validation loss = 3.625669
2018-12-08 11:28:43,660 - INFO - epoch 2, step 54550, training loss = 2.445499, validation loss = 3.347964
2018-12-08 11:29:01,466 - INFO - epoch 2, step 54600, training loss = 2.287372, validation loss = 3.145953
2018-12-08 11:29:20,510 - INFO - epoch 2, step 54650, training loss = 2.540209, validation loss = 3.199904
2018-12-08 11:29:40,489 - INFO - epoch 2, step 54700, training loss = 2.687624, validation loss = 3.683638
2018-12-08 11:30:00,118 - INFO - epoch 2, step 54750, training loss = 2.304284, validation loss = 3.673940
2018-12-08 11:30:16,160 - INFO - epoch 2, step 54800, training loss = 2.239197, validation loss = 3.528603
2018-12-08 11:30:35,769 - INFO - epoch 2, step 54850, training loss = 2.518582, validation loss = 3.171513
2018-12-08 11:30:58,058 - INFO - epoch 2, step 54900, training loss = 2.049237, validation loss = 3.568488
2018-12-08 11:31:19,075 - INFO - epoch 2, step 54950, training loss = 2.106591, validation loss = 3.681183
2018-12-08 11:31:39,518 - INFO - epoch 2, step 55000, training loss = 2.106500, validation loss = 3.423862
2018-12-08 11:32:00,222 - INFO - epoch 2, step 55050, training loss = 2.290236, validation loss = 3.276116
2018-12-08 11:32:20,284 - INFO - epoch 2, step 55100, training loss = 2.233090, validation loss = 3.826405
2018-12-08 11:32:39,725 - INFO - epoch 2, step 55150, training loss = 2.467211, validation loss = 3.238492
2018-12-08 11:32:57,277 - INFO - epoch 2, step 55200, training loss = 2.277714, validation loss = 3.375278
2018-12-08 11:33:17,719 - INFO - epoch 2, step 55250, training loss = 2.322668, validation loss = 3.430083
2018-12-08 11:33:39,383 - INFO - epoch 2, step 55300, training loss = 2.452095, validation loss = 3.655849
2018-12-08 11:34:01,592 - INFO - epoch 2, step 55350, training loss = 2.291714, validation loss = 3.198283
2018-12-08 11:34:20,757 - INFO - epoch 2, step 55400, training loss = 2.602998, validation loss = 3.264952
2018-12-08 11:34:36,717 - INFO - epoch 2, step 55450, training loss = 2.292500, validation loss = 3.010947
2018-12-08 11:34:55,978 - INFO - epoch 2, step 55500, training loss = 2.373695, validation loss = 3.433560
2018-12-08 11:35:14,780 - INFO - epoch 2, step 55550, training loss = 2.675050, validation loss = 3.430516
2018-12-08 11:35:31,880 - INFO - epoch 2, step 55600, training loss = 2.553141, validation loss = 3.556817
2018-12-08 11:35:53,672 - INFO - epoch 2, step 55650, training loss = 2.240010, validation loss = 3.495216
2018-12-08 11:36:14,551 - INFO - epoch 2, step 55700, training loss = 2.249557, validation loss = 3.460389
2018-12-08 11:36:34,856 - INFO - epoch 2, step 55750, training loss = 2.440446, validation loss = 3.552336
2018-12-08 11:36:52,987 - INFO - epoch 2, step 55800, training loss = 2.277235, validation loss = 3.176251
2018-12-08 11:37:12,083 - INFO - epoch 2, step 55850, training loss = 2.502541, validation loss = 3.375484
2018-12-08 11:37:33,579 - INFO - epoch 2, step 55900, training loss = 2.058903, validation loss = 3.564248
2018-12-08 11:37:53,967 - INFO - epoch 2, step 55950, training loss = 2.248950, validation loss = 3.555467
2018-12-08 11:38:14,030 - INFO - epoch 2, step 56000, training loss = 2.301769, validation loss = 3.414934
2018-12-08 11:38:33,109 - INFO - epoch 2, step 56050, training loss = 2.400302, validation loss = 3.566232
2018-12-08 11:38:51,118 - INFO - epoch 2, step 56100, training loss = 2.279392, validation loss = 3.341935
2018-12-08 11:39:12,390 - INFO - epoch 2, step 56150, training loss = 3.049012, validation loss = 3.323604
2018-12-08 11:39:32,760 - INFO - epoch 2, step 56200, training loss = 2.495464, validation loss = 3.134699
2018-12-08 11:39:49,071 - INFO - epoch 2, step 56250, training loss = 2.392290, validation loss = 3.398471
2018-12-08 11:40:09,273 - INFO - epoch 2, step 56300, training loss = 2.220428, validation loss = 3.395725
2018-12-08 11:40:30,878 - INFO - epoch 2, step 56350, training loss = 2.344063, validation loss = 3.410175
2018-12-08 11:40:56,657 - INFO - epoch 2, step 56400, training loss = 2.834210, validation loss = 3.271096
2018-12-08 11:41:22,228 - INFO - epoch 2, step 56450, training loss = 2.567224, validation loss = 3.347980
2018-12-08 11:41:44,150 - INFO - epoch 2, step 56500, training loss = 2.205811, validation loss = 3.425727
2018-12-08 11:42:05,326 - INFO - epoch 2, step 56550, training loss = 2.791966, validation loss = 3.063323
2018-12-08 11:42:22,714 - INFO - epoch 2, step 56600, training loss = 2.366416, validation loss = 3.705587
2018-12-08 11:42:40,094 - INFO - epoch 2, step 56650, training loss = 2.575145, validation loss = 3.575656
2018-12-08 11:42:56,930 - INFO - epoch 2, step 56700, training loss = 2.638401, validation loss = 3.919906
2018-12-08 11:43:17,749 - INFO - epoch 2, step 56750, training loss = 2.451353, validation loss = 3.705866
2018-12-08 11:43:36,542 - INFO - epoch 2, step 56800, training loss = 2.329767, validation loss = 3.894449
2018-12-08 11:43:54,805 - INFO - epoch 2, step 56850, training loss = 2.413841, validation loss = 3.104213
2018-12-08 11:44:11,265 - INFO - epoch 2, step 56900, training loss = 2.193147, validation loss = 3.409591
2018-12-08 11:44:28,236 - INFO - epoch 2, step 56950, training loss = 2.343253, validation loss = 3.829168
2018-12-08 11:44:46,292 - INFO - epoch 2, step 57000, training loss = 2.164685, validation loss = 2.912331
2018-12-08 11:45:07,687 - INFO - epoch 2, step 57050, training loss = 1.915976, validation loss = 3.510578
2018-12-08 11:45:27,753 - INFO - epoch 2, step 57100, training loss = 2.404321, validation loss = 3.291996
2018-12-08 11:45:47,068 - INFO - epoch 2, step 57150, training loss = 2.247915, validation loss = 3.360748
2018-12-08 11:46:08,059 - INFO - epoch 2, step 57200, training loss = 2.307671, validation loss = 3.429387
2018-12-08 11:46:29,269 - INFO - epoch 2, step 57250, training loss = 2.127006, validation loss = 3.331457
2018-12-08 11:46:49,303 - INFO - epoch 2, step 57300, training loss = 2.221239, validation loss = 3.205090
2018-12-08 11:47:07,245 - INFO - epoch 2, step 57350, training loss = 2.043745, validation loss = 3.172419
2018-12-08 11:47:24,002 - INFO - epoch 2, step 57400, training loss = 2.283843, validation loss = 3.436972
2018-12-08 11:47:39,923 - INFO - epoch 2, step 57450, training loss = 2.232535, validation loss = 3.259542
2018-12-08 11:47:55,717 - INFO - epoch 2, step 57500, training loss = 2.091047, validation loss = 3.553947
2018-12-08 11:48:11,919 - INFO - epoch 2, step 57550, training loss = 2.409155, validation loss = 3.219071
2018-12-08 11:48:28,104 - INFO - epoch 2, step 57600, training loss = 2.190067, validation loss = 3.555435
2018-12-08 11:48:43,889 - INFO - epoch 2, step 57650, training loss = 2.374030, validation loss = 3.184351
2018-12-08 11:49:04,535 - INFO - epoch 2, step 57700, training loss = 2.893776, validation loss = 3.528413
2018-12-08 11:49:23,792 - INFO - epoch 2, step 57750, training loss = 2.639964, validation loss = 3.374316
2018-12-08 11:49:42,655 - INFO - epoch 2, step 57800, training loss = 2.204283, validation loss = 3.903000
2018-12-08 11:50:02,156 - INFO - epoch 2, step 57850, training loss = 2.658245, validation loss = 3.861818
2018-12-08 11:50:23,217 - INFO - epoch 2, step 57900, training loss = 2.322575, validation loss = 3.642838
2018-12-08 11:50:43,995 - INFO - epoch 2, step 57950, training loss = 2.059656, validation loss = 3.547561
2018-12-08 11:51:04,773 - INFO - epoch 2, step 58000, training loss = 2.252723, validation loss = 3.617320
2018-12-08 11:51:25,608 - INFO - epoch 2, step 58050, training loss = 2.062960, validation loss = 3.072908
2018-12-08 11:51:45,025 - INFO - epoch 2, step 58100, training loss = 2.050547, validation loss = 2.868392
2018-12-08 11:52:02,216 - INFO - epoch 2, step 58150, training loss = 2.374697, validation loss = 3.220424
2018-12-08 11:52:17,593 - INFO - epoch 2, step 58200, training loss = 2.581428, validation loss = 3.320603
2018-12-08 11:52:37,017 - INFO - epoch 2, step 58250, training loss = 2.221007, validation loss = 3.185896
2018-12-08 11:52:57,571 - INFO - epoch 2, step 58300, training loss = 1.862039, validation loss = 3.285878
2018-12-08 11:53:18,246 - INFO - epoch 2, step 58350, training loss = 2.357546, validation loss = 3.142526
2018-12-08 11:53:38,630 - INFO - epoch 2, step 58400, training loss = 2.630685, validation loss = 3.440557
2018-12-08 11:53:56,674 - INFO - epoch 2, step 58450, training loss = 2.176506, validation loss = 3.844479
2018-12-08 11:54:14,988 - INFO - epoch 2, step 58500, training loss = 2.611351, validation loss = 3.471328
2018-12-08 11:54:33,374 - INFO - epoch 2, step 58550, training loss = 2.241898, validation loss = 3.445216
2018-12-08 11:54:53,851 - INFO - epoch 2, step 58600, training loss = 2.319762, validation loss = 3.508483
2018-12-08 11:55:11,792 - INFO - epoch 2, step 58650, training loss = 2.545691, validation loss = 3.774390
2018-12-08 11:55:28,084 - INFO - epoch 2, step 58700, training loss = 2.600368, validation loss = 3.664520
2018-12-08 11:55:48,534 - INFO - epoch 2, step 58750, training loss = 1.807990, validation loss = 3.716537
2018-12-08 11:56:09,857 - INFO - epoch 2, step 58800, training loss = 2.073982, validation loss = 3.945855
2018-12-08 11:56:29,793 - INFO - epoch 2, step 58850, training loss = 2.132983, validation loss = 3.542309
2018-12-08 11:56:50,485 - INFO - epoch 2, step 58900, training loss = 2.376359, validation loss = 3.520993
2018-12-08 11:57:09,581 - INFO - epoch 2, step 58950, training loss = 2.281837, validation loss = 3.267363
2018-12-08 11:57:26,112 - INFO - epoch 2, step 59000, training loss = 2.418069, validation loss = 3.157455
2018-12-08 11:57:45,759 - INFO - epoch 2, step 59050, training loss = 2.433115, validation loss = 3.845775
2018-12-08 11:58:04,620 - INFO - epoch 2, step 59100, training loss = 2.145277, validation loss = 3.333786
2018-12-08 11:58:22,232 - INFO - epoch 2, step 59150, training loss = 1.873681, validation loss = 3.413919
2018-12-08 11:58:40,643 - INFO - epoch 2, step 59200, training loss = 1.951954, validation loss = 3.639475
2018-12-08 11:59:01,365 - INFO - epoch 2, step 59250, training loss = 1.738023, validation loss = 3.774762
2018-12-08 11:59:22,695 - INFO - epoch 2, step 59300, training loss = 2.128745, validation loss = 2.935717
2018-12-08 11:59:44,605 - INFO - epoch 2, step 59350, training loss = 2.114809, validation loss = 3.907710
2018-12-08 12:00:01,700 - INFO - epoch 2, step 59400, training loss = 2.358074, validation loss = 3.542103
2018-12-08 12:00:13,724 - INFO - Model saved in dir ./models
2018-12-08 12:00:31,699 - INFO - epoch 3, step 50, training loss = 3.239406, validation loss = 3.566341
2018-12-08 12:00:49,824 - INFO - epoch 3, step 100, training loss = 2.569161, validation loss = 3.288274
2018-12-08 12:01:08,318 - INFO - epoch 3, step 150, training loss = 3.038334, validation loss = 3.192198
2018-12-08 12:01:28,687 - INFO - epoch 3, step 200, training loss = 2.745682, validation loss = 3.431690
2018-12-08 12:01:48,815 - INFO - epoch 3, step 250, training loss = 2.694298, validation loss = 3.419465
2018-12-08 12:02:08,753 - INFO - epoch 3, step 300, training loss = 2.900184, validation loss = 3.660855
2018-12-08 12:02:27,869 - INFO - epoch 3, step 350, training loss = 2.968677, validation loss = 3.802240
2018-12-08 12:02:47,111 - INFO - epoch 3, step 400, training loss = 2.620629, validation loss = 3.577090
2018-12-08 12:03:06,855 - INFO - epoch 3, step 450, training loss = 3.095543, validation loss = 3.101871
2018-12-08 12:03:27,341 - INFO - epoch 3, step 500, training loss = 3.186370, validation loss = 3.451320
2018-12-08 12:03:47,323 - INFO - epoch 3, step 550, training loss = 2.946861, validation loss = 3.959240
2018-12-08 12:04:07,033 - INFO - epoch 3, step 600, training loss = 2.723629, validation loss = 3.154764
2018-12-08 12:04:27,087 - INFO - epoch 3, step 650, training loss = 2.896959, validation loss = 2.951353
2018-12-08 12:04:46,742 - INFO - epoch 3, step 700, training loss = 2.777690, validation loss = 3.075166
2018-12-08 12:05:06,644 - INFO - epoch 3, step 750, training loss = 3.052131, validation loss = 3.281401
2018-12-08 12:05:27,644 - INFO - epoch 3, step 800, training loss = 3.303024, validation loss = 2.962605
2018-12-08 12:05:49,084 - INFO - epoch 3, step 850, training loss = 2.950436, validation loss = 2.845464
2018-12-08 12:06:09,964 - INFO - epoch 3, step 900, training loss = 3.431794, validation loss = 3.928861
2018-12-08 12:06:31,694 - INFO - epoch 3, step 950, training loss = 2.495249, validation loss = 2.917830
2018-12-08 12:06:52,803 - INFO - epoch 3, step 1000, training loss = 3.095906, validation loss = 3.222494
2018-12-08 12:07:13,289 - INFO - epoch 3, step 1050, training loss = 2.766080, validation loss = 3.319911
2018-12-08 12:07:33,463 - INFO - epoch 3, step 1100, training loss = 2.718667, validation loss = 3.459680
2018-12-08 12:07:53,903 - INFO - epoch 3, step 1150, training loss = 2.760190, validation loss = 3.791242
2018-12-08 12:08:14,025 - INFO - epoch 3, step 1200, training loss = 3.103606, validation loss = 4.198310
2018-12-08 12:08:34,605 - INFO - epoch 3, step 1250, training loss = 2.634069, validation loss = 3.564120
2018-12-08 12:08:54,762 - INFO - epoch 3, step 1300, training loss = 3.246140, validation loss = 4.286781
2018-12-08 12:09:12,802 - INFO - epoch 3, step 1350, training loss = 3.038270, validation loss = 3.882998
2018-12-08 12:09:31,080 - INFO - epoch 3, step 1400, training loss = 2.567586, validation loss = 4.209864
2018-12-08 12:09:50,051 - INFO - epoch 3, step 1450, training loss = 2.737440, validation loss = 3.481821
2018-12-08 12:10:11,164 - INFO - epoch 3, step 1500, training loss = 2.472689, validation loss = 3.754557
2018-12-08 12:10:30,418 - INFO - epoch 3, step 1550, training loss = 3.006376, validation loss = 3.449359
2018-12-08 12:10:49,177 - INFO - epoch 3, step 1600, training loss = 3.069493, validation loss = 3.620936
2018-12-08 12:11:07,518 - INFO - epoch 3, step 1650, training loss = 3.008374, validation loss = 3.375234
2018-12-08 12:11:28,386 - INFO - epoch 3, step 1700, training loss = 2.970666, validation loss = 4.031097
2018-12-08 12:11:45,770 - INFO - epoch 3, step 1750, training loss = 2.937706, validation loss = 4.158577
2018-12-08 12:12:02,512 - INFO - epoch 3, step 1800, training loss = 2.859041, validation loss = 3.484833
2018-12-08 12:12:19,731 - INFO - epoch 3, step 1850, training loss = 2.851894, validation loss = 2.934185
2018-12-08 12:12:40,817 - INFO - epoch 3, step 1900, training loss = 2.988704, validation loss = 3.798656
2018-12-08 12:13:02,213 - INFO - epoch 3, step 1950, training loss = 3.152761, validation loss = 3.425623
2018-12-08 12:13:18,902 - INFO - epoch 3, step 2000, training loss = 2.821028, validation loss = 4.110306
2018-12-08 12:13:35,341 - INFO - epoch 3, step 2050, training loss = 2.609324, validation loss = 3.617749
2018-12-08 12:13:52,255 - INFO - epoch 3, step 2100, training loss = 2.998140, validation loss = 4.306214
2018-12-08 12:14:08,980 - INFO - epoch 3, step 2150, training loss = 2.083831, validation loss = 3.796026
2018-12-08 12:14:26,161 - INFO - epoch 3, step 2200, training loss = 3.059178, validation loss = 4.068150
2018-12-08 12:14:44,074 - INFO - epoch 3, step 2250, training loss = 2.669908, validation loss = 3.788307
2018-12-08 12:15:03,259 - INFO - epoch 3, step 2300, training loss = 2.629602, validation loss = 4.239381
2018-12-08 12:15:23,470 - INFO - epoch 3, step 2350, training loss = 2.784081, validation loss = 3.912692
2018-12-08 12:15:43,523 - INFO - epoch 3, step 2400, training loss = 2.753860, validation loss = 4.296023
2018-12-08 12:16:02,697 - INFO - epoch 3, step 2450, training loss = 2.610128, validation loss = 3.930464
2018-12-08 12:16:20,741 - INFO - epoch 3, step 2500, training loss = 3.074633, validation loss = 3.973308
2018-12-08 12:16:38,239 - INFO - epoch 3, step 2550, training loss = 2.577002, validation loss = 3.820680
2018-12-08 12:16:56,201 - INFO - epoch 3, step 2600, training loss = 2.561338, validation loss = 4.152743
2018-12-08 12:17:14,389 - INFO - epoch 3, step 2650, training loss = 2.630382, validation loss = 3.776254
2018-12-08 12:17:35,302 - INFO - epoch 3, step 2700, training loss = 3.258955, validation loss = 3.950114
2018-12-08 12:17:56,248 - INFO - epoch 3, step 2750, training loss = 2.667183, validation loss = 4.068682
2018-12-08 12:18:16,981 - INFO - epoch 3, step 2800, training loss = 3.139263, validation loss = 3.544917
2018-12-08 12:18:35,537 - INFO - epoch 3, step 2850, training loss = 2.951836, validation loss = 3.815112
2018-12-08 12:18:53,551 - INFO - epoch 3, step 2900, training loss = 2.712738, validation loss = 3.853095
2018-12-08 12:19:12,550 - INFO - epoch 3, step 2950, training loss = 2.740608, validation loss = 3.344279
2018-12-08 12:19:34,249 - INFO - epoch 3, step 3000, training loss = 2.694976, validation loss = 3.967734
2018-12-08 12:19:55,166 - INFO - epoch 3, step 3050, training loss = 2.927347, validation loss = 3.978772
2018-12-08 12:20:16,186 - INFO - epoch 3, step 3100, training loss = 2.864059, validation loss = 3.667200
2018-12-08 12:20:36,751 - INFO - epoch 3, step 3150, training loss = 2.641129, validation loss = 3.985084
2018-12-08 12:20:57,311 - INFO - epoch 3, step 3200, training loss = 3.106812, validation loss = 4.036813
2018-12-08 12:21:18,622 - INFO - epoch 3, step 3250, training loss = 3.111618, validation loss = 4.632580
2018-12-08 12:21:37,875 - INFO - epoch 3, step 3300, training loss = 3.032057, validation loss = 4.020595
2018-12-08 12:21:56,492 - INFO - epoch 3, step 3350, training loss = 2.662725, validation loss = 3.683096
2018-12-08 12:22:15,569 - INFO - epoch 3, step 3400, training loss = 3.172673, validation loss = 3.434166
2018-12-08 12:22:35,471 - INFO - epoch 3, step 3450, training loss = 2.771825, validation loss = 3.600287
2018-12-08 12:22:54,961 - INFO - epoch 3, step 3500, training loss = 2.709394, validation loss = 3.724397
2018-12-08 12:23:13,444 - INFO - epoch 3, step 3550, training loss = 2.781752, validation loss = 3.765563
2018-12-08 12:23:31,811 - INFO - epoch 3, step 3600, training loss = 2.951977, validation loss = 3.511826
2018-12-08 12:23:50,459 - INFO - epoch 3, step 3650, training loss = 3.226717, validation loss = 3.725388
2018-12-08 12:24:09,534 - INFO - epoch 3, step 3700, training loss = 2.678668, validation loss = 3.910319
2018-12-08 12:24:27,292 - INFO - epoch 3, step 3750, training loss = 2.891385, validation loss = 3.947978
2018-12-08 12:24:43,747 - INFO - epoch 3, step 3800, training loss = 1.958285, validation loss = 3.706766
2018-12-08 12:25:00,587 - INFO - epoch 3, step 3850, training loss = 2.699949, validation loss = 3.441050
2018-12-08 12:25:18,946 - INFO - epoch 3, step 3900, training loss = 2.687111, validation loss = 3.523170
2018-12-08 12:25:39,378 - INFO - epoch 3, step 3950, training loss = 2.874443, validation loss = 3.693043
2018-12-08 12:25:59,182 - INFO - epoch 3, step 4000, training loss = 2.746098, validation loss = 3.552253
2018-12-08 12:26:17,175 - INFO - epoch 3, step 4050, training loss = 2.623469, validation loss = 3.756823
2018-12-08 12:26:34,744 - INFO - epoch 3, step 4100, training loss = 2.671102, validation loss = 3.509083
2018-12-08 12:26:52,716 - INFO - epoch 3, step 4150, training loss = 2.881103, validation loss = 3.867090
2018-12-08 12:27:10,369 - INFO - epoch 3, step 4200, training loss = 2.838916, validation loss = 3.024462
2018-12-08 12:27:28,929 - INFO - epoch 3, step 4250, training loss = 3.039358, validation loss = 3.405144
2018-12-08 12:27:47,451 - INFO - epoch 3, step 4300, training loss = 3.122987, validation loss = 3.985243
2018-12-08 12:28:05,990 - INFO - epoch 3, step 4350, training loss = 3.034874, validation loss = 3.461435
2018-12-08 12:28:24,094 - INFO - epoch 3, step 4400, training loss = 3.442307, validation loss = 3.728923
2018-12-08 12:28:42,555 - INFO - epoch 3, step 4450, training loss = 3.153689, validation loss = 3.737860
2018-12-08 12:29:00,481 - INFO - epoch 3, step 4500, training loss = 2.729759, validation loss = 4.073418
2018-12-08 12:29:18,502 - INFO - epoch 3, step 4550, training loss = 2.544307, validation loss = 4.016497
2018-12-08 12:29:36,200 - INFO - epoch 3, step 4600, training loss = 2.728250, validation loss = 3.934267
2018-12-08 12:29:54,201 - INFO - epoch 3, step 4650, training loss = 2.874558, validation loss = 3.504716
2018-12-08 12:30:15,518 - INFO - epoch 3, step 4700, training loss = 3.247311, validation loss = 3.594011
2018-12-08 12:30:36,243 - INFO - epoch 3, step 4750, training loss = 2.971746, validation loss = 3.261987
2018-12-08 12:30:56,627 - INFO - epoch 3, step 4800, training loss = 2.577770, validation loss = 3.792262
2018-12-08 12:31:15,833 - INFO - epoch 3, step 4850, training loss = 2.637879, validation loss = 3.550236
2018-12-08 12:31:34,287 - INFO - epoch 3, step 4900, training loss = 3.142031, validation loss = 3.644499
2018-12-08 12:31:50,765 - INFO - epoch 3, step 4950, training loss = 2.736238, validation loss = 3.790578
2018-12-08 12:32:08,102 - INFO - epoch 3, step 5000, training loss = 3.015107, validation loss = 3.029137
2018-12-08 12:32:29,319 - INFO - epoch 3, step 5050, training loss = 2.580134, validation loss = 3.416881
2018-12-08 12:32:50,142 - INFO - epoch 3, step 5100, training loss = 2.359759, validation loss = 3.970881
2018-12-08 12:33:09,088 - INFO - epoch 3, step 5150, training loss = 2.918605, validation loss = 3.465239
2018-12-08 12:33:27,259 - INFO - epoch 3, step 5200, training loss = 2.340219, validation loss = 3.514421
2018-12-08 12:33:47,751 - INFO - epoch 3, step 5250, training loss = 3.044897, validation loss = 4.511619
2018-12-08 12:34:08,126 - INFO - epoch 3, step 5300, training loss = 3.064958, validation loss = 3.345017
2018-12-08 12:34:27,091 - INFO - epoch 3, step 5350, training loss = 2.629704, validation loss = 4.603161
2018-12-08 12:34:46,095 - INFO - epoch 3, step 5400, training loss = 2.833611, validation loss = 3.528285
2018-12-08 12:35:04,778 - INFO - epoch 3, step 5450, training loss = 2.868879, validation loss = 3.159768
2018-12-08 12:35:23,057 - INFO - epoch 3, step 5500, training loss = 3.044105, validation loss = 3.757250
2018-12-08 12:35:41,578 - INFO - epoch 3, step 5550, training loss = 2.788266, validation loss = 3.439325
2018-12-08 12:36:00,829 - INFO - epoch 3, step 5600, training loss = 2.800711, validation loss = 3.531750
2018-12-08 12:36:21,332 - INFO - epoch 3, step 5650, training loss = 3.031938, validation loss = 3.412893
2018-12-08 12:36:42,112 - INFO - epoch 3, step 5700, training loss = 3.157937, validation loss = 3.573536
2018-12-08 12:37:03,123 - INFO - epoch 3, step 5750, training loss = 2.951025, validation loss = 4.149636
2018-12-08 12:37:24,245 - INFO - epoch 3, step 5800, training loss = 2.814077, validation loss = 3.439609
2018-12-08 12:37:44,826 - INFO - epoch 3, step 5850, training loss = 2.786790, validation loss = 3.372112
2018-12-08 12:38:01,396 - INFO - epoch 3, step 5900, training loss = 2.570889, validation loss = 3.830095
2018-12-08 12:38:17,751 - INFO - epoch 3, step 5950, training loss = 2.397012, validation loss = 4.138793
2018-12-08 12:38:37,954 - INFO - epoch 3, step 6000, training loss = 2.901604, validation loss = 4.132401
2018-12-08 12:38:58,820 - INFO - epoch 3, step 6050, training loss = 2.719265, validation loss = 3.800185
2018-12-08 12:39:19,512 - INFO - epoch 3, step 6100, training loss = 2.726782, validation loss = 3.264731
2018-12-08 12:39:41,037 - INFO - epoch 3, step 6150, training loss = 2.928921, validation loss = 3.949290
2018-12-08 12:40:01,807 - INFO - epoch 3, step 6200, training loss = 3.015173, validation loss = 3.435651
2018-12-08 12:40:22,429 - INFO - epoch 3, step 6250, training loss = 2.718565, validation loss = 3.211639
2018-12-08 12:40:41,933 - INFO - epoch 3, step 6300, training loss = 3.090220, validation loss = 3.307284
2018-12-08 12:41:00,631 - INFO - epoch 3, step 6350, training loss = 2.754771, validation loss = 3.748957
2018-12-08 12:41:18,981 - INFO - epoch 3, step 6400, training loss = 2.882875, validation loss = 3.248567
2018-12-08 12:41:37,479 - INFO - epoch 3, step 6450, training loss = 2.596285, validation loss = 3.616696
2018-12-08 12:41:55,592 - INFO - epoch 3, step 6500, training loss = 2.293770, validation loss = 3.303379
2018-12-08 12:42:13,604 - INFO - epoch 3, step 6550, training loss = 2.847015, validation loss = 3.547964
2018-12-08 12:42:31,243 - INFO - epoch 3, step 6600, training loss = 2.789151, validation loss = 3.581243
2018-12-08 12:42:49,769 - INFO - epoch 3, step 6650, training loss = 3.050940, validation loss = 3.320298
2018-12-08 12:43:08,767 - INFO - epoch 3, step 6700, training loss = 3.187708, validation loss = 3.941047
2018-12-08 12:43:27,376 - INFO - epoch 3, step 6750, training loss = 2.827336, validation loss = 3.808915
2018-12-08 12:43:45,264 - INFO - epoch 3, step 6800, training loss = 2.731098, validation loss = 3.830678
2018-12-08 12:44:03,168 - INFO - epoch 3, step 6850, training loss = 2.661561, validation loss = 4.239017
2018-12-08 12:44:20,679 - INFO - epoch 3, step 6900, training loss = 2.370965, validation loss = 4.274890
2018-12-08 12:44:39,958 - INFO - epoch 3, step 6950, training loss = 2.823785, validation loss = 3.842321
2018-12-08 12:45:00,118 - INFO - epoch 3, step 7000, training loss = 3.054194, validation loss = 3.846780
2018-12-08 12:45:21,476 - INFO - epoch 3, step 7050, training loss = 2.906601, validation loss = 3.584548
2018-12-08 12:45:41,792 - INFO - epoch 3, step 7100, training loss = 2.682318, validation loss = 3.742844
2018-12-08 12:46:02,686 - INFO - epoch 3, step 7150, training loss = 2.595260, validation loss = 3.892607
2018-12-08 12:46:22,716 - INFO - epoch 3, step 7200, training loss = 2.851547, validation loss = 3.638760
2018-12-08 12:46:42,074 - INFO - epoch 3, step 7250, training loss = 2.807263, validation loss = 3.722420
2018-12-08 12:47:00,159 - INFO - epoch 3, step 7300, training loss = 2.634351, validation loss = 3.529226
2018-12-08 12:47:18,655 - INFO - epoch 3, step 7350, training loss = 2.936707, validation loss = 3.628531
2018-12-08 12:47:36,444 - INFO - epoch 3, step 7400, training loss = 2.652137, validation loss = 3.680889
2018-12-08 12:47:53,108 - INFO - epoch 3, step 7450, training loss = 2.914534, validation loss = 3.777585
2018-12-08 12:48:09,413 - INFO - epoch 3, step 7500, training loss = 2.013560, validation loss = 3.861461
2018-12-08 12:48:25,968 - INFO - epoch 3, step 7550, training loss = 2.459614, validation loss = 4.080552
2018-12-08 12:48:43,744 - INFO - epoch 3, step 7600, training loss = 2.590645, validation loss = 3.934514
2018-12-08 12:49:01,854 - INFO - epoch 3, step 7650, training loss = 2.548006, validation loss = 4.024913
2018-12-08 12:49:19,876 - INFO - epoch 3, step 7700, training loss = 2.507074, validation loss = 4.180121
2018-12-08 12:49:37,886 - INFO - epoch 3, step 7750, training loss = 2.541944, validation loss = 3.755760
2018-12-08 12:49:56,357 - INFO - epoch 3, step 7800, training loss = 3.005501, validation loss = 3.840979
2018-12-08 12:50:15,580 - INFO - epoch 3, step 7850, training loss = 2.927641, validation loss = 3.698223
2018-12-08 12:50:34,683 - INFO - epoch 3, step 7900, training loss = 2.556466, validation loss = 3.800762
2018-12-08 12:50:54,322 - INFO - epoch 3, step 7950, training loss = 2.498516, validation loss = 4.171823
2018-12-08 12:51:14,424 - INFO - epoch 3, step 8000, training loss = 2.857975, validation loss = 3.538618
2018-12-08 12:51:35,159 - INFO - epoch 3, step 8050, training loss = 2.696175, validation loss = 3.922506
2018-12-08 12:51:55,735 - INFO - epoch 3, step 8100, training loss = 2.669055, validation loss = 3.911229
2018-12-08 12:52:16,814 - INFO - epoch 3, step 8150, training loss = 3.308372, validation loss = 4.389639
2018-12-08 12:52:37,875 - INFO - epoch 3, step 8200, training loss = 2.816067, validation loss = 4.070825
2018-12-08 12:52:58,261 - INFO - epoch 3, step 8250, training loss = 2.563034, validation loss = 3.603036
2018-12-08 12:53:16,744 - INFO - epoch 3, step 8300, training loss = 2.598095, validation loss = 3.497791
2018-12-08 12:53:33,334 - INFO - epoch 3, step 8350, training loss = 2.605629, validation loss = 3.999743
2018-12-08 12:53:49,844 - INFO - epoch 3, step 8400, training loss = 2.593663, validation loss = 3.796684
2018-12-08 12:54:09,340 - INFO - epoch 3, step 8450, training loss = 2.748847, validation loss = 4.426322
2018-12-08 12:54:29,303 - INFO - epoch 3, step 8500, training loss = 2.395432, validation loss = 3.376722
2018-12-08 12:54:47,274 - INFO - epoch 3, step 8550, training loss = 2.705400, validation loss = 4.231654
2018-12-08 12:55:04,432 - INFO - epoch 3, step 8600, training loss = 2.196739, validation loss = 3.730151
2018-12-08 12:55:21,358 - INFO - epoch 3, step 8650, training loss = 2.470108, validation loss = 4.045351
2018-12-08 12:55:39,449 - INFO - epoch 3, step 8700, training loss = 3.018128, validation loss = 4.210688
2018-12-08 12:55:57,890 - INFO - epoch 3, step 8750, training loss = 3.120982, validation loss = 3.844074
2018-12-08 12:56:15,484 - INFO - epoch 3, step 8800, training loss = 2.522505, validation loss = 3.819327
2018-12-08 12:56:32,577 - INFO - epoch 3, step 8850, training loss = 2.505478, validation loss = 3.846815
2018-12-08 12:56:50,559 - INFO - epoch 3, step 8900, training loss = 3.016294, validation loss = 3.964544
2018-12-08 12:57:08,499 - INFO - epoch 3, step 8950, training loss = 3.120229, validation loss = 4.232515
2018-12-08 12:57:25,360 - INFO - epoch 3, step 9000, training loss = 2.717829, validation loss = 4.274601
2018-12-08 12:57:42,259 - INFO - epoch 3, step 9050, training loss = 2.994105, validation loss = 3.513946
2018-12-08 12:58:00,316 - INFO - epoch 3, step 9100, training loss = 2.776104, validation loss = 3.960701
2018-12-08 12:58:19,321 - INFO - epoch 3, step 9150, training loss = 2.520233, validation loss = 4.137538
2018-12-08 12:58:35,662 - INFO - epoch 3, step 9200, training loss = 2.076927, validation loss = 4.331063
2018-12-08 12:58:52,264 - INFO - epoch 3, step 9250, training loss = 2.001072, validation loss = 4.216636
2018-12-08 12:59:09,768 - INFO - epoch 3, step 9300, training loss = 2.515830, validation loss = 3.931334
2018-12-08 12:59:27,737 - INFO - epoch 3, step 9350, training loss = 2.837469, validation loss = 3.701794
2018-12-08 12:59:47,602 - INFO - epoch 3, step 9400, training loss = 2.870806, validation loss = 3.749290
2018-12-08 13:00:07,999 - INFO - epoch 3, step 9450, training loss = 3.032021, validation loss = 3.978701
2018-12-08 13:00:26,672 - INFO - epoch 3, step 9500, training loss = 1.959557, validation loss = 3.981784
2018-12-08 13:00:43,325 - INFO - epoch 3, step 9550, training loss = 2.423952, validation loss = 4.089529
2018-12-08 13:01:00,114 - INFO - epoch 3, step 9600, training loss = 2.299743, validation loss = 3.819667
2018-12-08 13:01:17,943 - INFO - epoch 3, step 9650, training loss = 1.908432, validation loss = 4.292200
2018-12-08 13:01:35,942 - INFO - epoch 3, step 9700, training loss = 2.739168, validation loss = 4.013216
2018-12-08 13:01:57,447 - INFO - epoch 3, step 9750, training loss = 2.654128, validation loss = 3.574982
2018-12-08 13:02:19,270 - INFO - epoch 3, step 9800, training loss = 2.642596, validation loss = 3.909118
2018-12-08 13:02:39,750 - INFO - epoch 3, step 9850, training loss = 2.351744, validation loss = 4.273244
2018-12-08 13:02:57,344 - INFO - epoch 3, step 9900, training loss = 1.981309, validation loss = 3.910756
2018-12-08 13:03:15,319 - INFO - epoch 3, step 9950, training loss = 2.536715, validation loss = 3.540732
2018-12-08 13:03:33,217 - INFO - epoch 3, step 10000, training loss = 2.688281, validation loss = 3.950639
2018-12-08 13:03:50,879 - INFO - epoch 3, step 10050, training loss = 2.484251, validation loss = 3.776950
2018-12-08 13:04:07,679 - INFO - epoch 3, step 10100, training loss = 2.745787, validation loss = 3.847872
2018-12-08 13:04:24,262 - INFO - epoch 3, step 10150, training loss = 2.426873, validation loss = 3.921220
2018-12-08 13:04:42,951 - INFO - epoch 3, step 10200, training loss = 2.769793, validation loss = 3.581341
2018-12-08 13:05:01,005 - INFO - epoch 3, step 10250, training loss = 2.834815, validation loss = 3.412129
2018-12-08 13:05:18,232 - INFO - epoch 3, step 10300, training loss = 2.533461, validation loss = 3.968414
2018-12-08 13:05:36,953 - INFO - epoch 3, step 10350, training loss = 2.904950, validation loss = 4.536438
2018-12-08 13:05:57,754 - INFO - epoch 3, step 10400, training loss = 3.365270, validation loss = 3.687396
2018-12-08 13:06:19,927 - INFO - epoch 3, step 10450, training loss = 2.589905, validation loss = 3.449627
2018-12-08 13:06:40,593 - INFO - epoch 3, step 10500, training loss = 3.031930, validation loss = 3.474438
2018-12-08 13:07:00,499 - INFO - epoch 3, step 10550, training loss = 2.796753, validation loss = 4.172465
2018-12-08 13:07:19,522 - INFO - epoch 3, step 10600, training loss = 2.504353, validation loss = 4.045959
2018-12-08 13:07:38,081 - INFO - epoch 3, step 10650, training loss = 2.931374, validation loss = 3.853176
2018-12-08 13:07:56,751 - INFO - epoch 3, step 10700, training loss = 3.302187, validation loss = 3.584862
2018-12-08 13:08:15,755 - INFO - epoch 3, step 10750, training loss = 2.564943, validation loss = 3.766517
2018-12-08 13:08:34,650 - INFO - epoch 3, step 10800, training loss = 2.769986, validation loss = 4.129054
2018-12-08 13:08:53,403 - INFO - epoch 3, step 10850, training loss = 2.579348, validation loss = 3.996538
2018-12-08 13:09:11,474 - INFO - epoch 3, step 10900, training loss = 2.835800, validation loss = 4.631303
2018-12-08 13:09:28,344 - INFO - epoch 3, step 10950, training loss = 2.250822, validation loss = 4.336169
2018-12-08 13:09:45,214 - INFO - epoch 3, step 11000, training loss = 2.797292, validation loss = 3.803453
2018-12-08 13:10:02,741 - INFO - epoch 3, step 11050, training loss = 2.773493, validation loss = 3.558136
2018-12-08 13:10:22,378 - INFO - epoch 3, step 11100, training loss = 2.870250, validation loss = 4.137027
2018-12-08 13:10:40,794 - INFO - epoch 3, step 11150, training loss = 2.127357, validation loss = 3.640071
2018-12-08 13:10:59,169 - INFO - epoch 3, step 11200, training loss = 2.767881, validation loss = 4.309982
2018-12-08 13:11:17,068 - INFO - epoch 3, step 11250, training loss = 2.456669, validation loss = 3.932940
2018-12-08 13:11:34,111 - INFO - epoch 3, step 11300, training loss = 2.584074, validation loss = 3.901071
2018-12-08 13:11:51,850 - INFO - epoch 3, step 11350, training loss = 2.518461, validation loss = 4.436497
2018-12-08 13:12:09,673 - INFO - epoch 3, step 11400, training loss = 2.944897, validation loss = 4.040140
2018-12-08 13:12:27,567 - INFO - epoch 3, step 11450, training loss = 2.713670, validation loss = 4.393009
2018-12-08 13:12:47,395 - INFO - epoch 3, step 11500, training loss = 3.312578, validation loss = 3.976271
2018-12-08 13:13:06,720 - INFO - epoch 3, step 11550, training loss = 2.214245, validation loss = 3.984345
2018-12-08 13:13:27,408 - INFO - epoch 3, step 11600, training loss = 2.901639, validation loss = 3.743941
2018-12-08 13:13:47,439 - INFO - epoch 3, step 11650, training loss = 2.249697, validation loss = 4.039318
2018-12-08 13:14:05,177 - INFO - epoch 3, step 11700, training loss = 2.519477, validation loss = 4.197011
2018-12-08 13:14:22,795 - INFO - epoch 3, step 11750, training loss = 2.300140, validation loss = 4.241595
2018-12-08 13:14:41,776 - INFO - epoch 3, step 11800, training loss = 2.911981, validation loss = 3.931043
2018-12-08 13:15:01,386 - INFO - epoch 3, step 11850, training loss = 2.538871, validation loss = 3.979852
2018-12-08 13:15:20,992 - INFO - epoch 3, step 11900, training loss = 2.652251, validation loss = 3.839583
2018-12-08 13:15:39,281 - INFO - epoch 3, step 11950, training loss = 2.010025, validation loss = 4.302617
2018-12-08 13:15:57,122 - INFO - epoch 3, step 12000, training loss = 2.534988, validation loss = 4.239991
2018-12-08 13:16:15,511 - INFO - epoch 3, step 12050, training loss = 2.936621, validation loss = 3.655200
2018-12-08 13:16:36,473 - INFO - epoch 3, step 12100, training loss = 3.054527, validation loss = 3.795832
2018-12-08 13:16:57,169 - INFO - epoch 3, step 12150, training loss = 2.938646, validation loss = 3.972801
2018-12-08 13:17:17,995 - INFO - epoch 3, step 12200, training loss = 2.438008, validation loss = 4.134518
2018-12-08 13:17:38,897 - INFO - epoch 3, step 12250, training loss = 2.723611, validation loss = 4.069235
2018-12-08 13:17:59,591 - INFO - epoch 3, step 12300, training loss = 3.273316, validation loss = 3.722389
2018-12-08 13:18:17,923 - INFO - epoch 3, step 12350, training loss = 3.064991, validation loss = 4.098570
2018-12-08 13:18:35,828 - INFO - epoch 3, step 12400, training loss = 2.644110, validation loss = 3.773325
2018-12-08 13:18:56,367 - INFO - epoch 3, step 12450, training loss = 2.588243, validation loss = 4.129570
2018-12-08 13:19:16,151 - INFO - epoch 3, step 12500, training loss = 2.430368, validation loss = 3.785149
2018-12-08 13:19:35,860 - INFO - epoch 3, step 12550, training loss = 2.630782, validation loss = 3.717730
2018-12-08 13:19:54,379 - INFO - epoch 3, step 12600, training loss = 2.589717, validation loss = 3.948400
2018-12-08 13:20:12,716 - INFO - epoch 3, step 12650, training loss = 2.646815, validation loss = 4.007571
2018-12-08 13:20:30,402 - INFO - epoch 3, step 12700, training loss = 3.090384, validation loss = 4.369714
2018-12-08 13:20:47,226 - INFO - epoch 3, step 12750, training loss = 2.865986, validation loss = 4.642306
2018-12-08 13:21:04,587 - INFO - epoch 3, step 12800, training loss = 3.048128, validation loss = 3.997516
2018-12-08 13:21:23,970 - INFO - epoch 3, step 12850, training loss = 2.747255, validation loss = 4.318323
2018-12-08 13:21:42,543 - INFO - epoch 3, step 12900, training loss = 2.838380, validation loss = 3.731841
2018-12-08 13:21:59,305 - INFO - epoch 3, step 12950, training loss = 3.007422, validation loss = 4.020784
2018-12-08 13:22:15,904 - INFO - epoch 3, step 13000, training loss = 3.074406, validation loss = 4.284094
2018-12-08 13:22:32,443 - INFO - epoch 3, step 13050, training loss = 2.639709, validation loss = 3.681319
2018-12-08 13:22:52,679 - INFO - epoch 3, step 13100, training loss = 2.851960, validation loss = 3.538899
2018-12-08 13:23:12,413 - INFO - epoch 3, step 13150, training loss = 2.581930, validation loss = 3.620643
2018-12-08 13:23:31,619 - INFO - epoch 3, step 13200, training loss = 2.687556, validation loss = 4.095268
2018-12-08 13:23:48,237 - INFO - epoch 3, step 13250, training loss = 2.570963, validation loss = 4.396305
2018-12-08 13:24:05,422 - INFO - epoch 3, step 13300, training loss = 2.574451, validation loss = 4.394907
2018-12-08 13:24:22,957 - INFO - epoch 3, step 13350, training loss = 2.322742, validation loss = 3.869659
2018-12-08 13:24:40,974 - INFO - epoch 3, step 13400, training loss = 2.443279, validation loss = 3.533123
2018-12-08 13:24:58,454 - INFO - epoch 3, step 13450, training loss = 2.551477, validation loss = 3.694812
2018-12-08 13:25:18,420 - INFO - epoch 3, step 13500, training loss = 3.108720, validation loss = 3.837135
2018-12-08 13:25:39,390 - INFO - epoch 3, step 13550, training loss = 3.017386, validation loss = 3.945885
2018-12-08 13:26:00,247 - INFO - epoch 3, step 13600, training loss = 3.103642, validation loss = 3.554137
2018-12-08 13:26:17,305 - INFO - epoch 3, step 13650, training loss = 2.452936, validation loss = 4.546512
2018-12-08 13:26:34,667 - INFO - epoch 3, step 13700, training loss = 2.153394, validation loss = 4.335855
2018-12-08 13:26:52,810 - INFO - epoch 3, step 13750, training loss = 2.570640, validation loss = 3.879771
2018-12-08 13:27:11,865 - INFO - epoch 3, step 13800, training loss = 2.544286, validation loss = 3.636266
2018-12-08 13:27:29,181 - INFO - epoch 3, step 13850, training loss = 2.475320, validation loss = 3.185583
2018-12-08 13:27:48,022 - INFO - epoch 3, step 13900, training loss = 2.379813, validation loss = 3.723366
2018-12-08 13:28:08,848 - INFO - epoch 3, step 13950, training loss = 3.200380, validation loss = 3.816459
2018-12-08 13:28:29,982 - INFO - epoch 3, step 14000, training loss = 2.282873, validation loss = 3.515813
2018-12-08 13:28:49,700 - INFO - epoch 3, step 14050, training loss = 2.995258, validation loss = 3.903655
2018-12-08 13:29:07,607 - INFO - epoch 3, step 14100, training loss = 2.986648, validation loss = 4.210961
2018-12-08 13:29:26,654 - INFO - epoch 3, step 14150, training loss = 3.163639, validation loss = 3.554159
2018-12-08 13:29:45,112 - INFO - epoch 3, step 14200, training loss = 2.840034, validation loss = 3.260558
2018-12-08 13:30:05,160 - INFO - epoch 3, step 14250, training loss = 2.506075, validation loss = 3.644017
2018-12-08 13:30:25,996 - INFO - epoch 3, step 14300, training loss = 2.925223, validation loss = 4.395852
2018-12-08 13:30:46,443 - INFO - epoch 3, step 14350, training loss = 3.176463, validation loss = 3.512096
2018-12-08 13:31:02,026 - INFO - epoch 3, step 14400, training loss = 3.231877, validation loss = 3.747091
2018-12-08 13:31:17,574 - INFO - epoch 3, step 14450, training loss = 2.801026, validation loss = 3.695518
2018-12-08 13:31:33,629 - INFO - epoch 3, step 14500, training loss = 2.946048, validation loss = 3.606370
2018-12-08 13:31:50,660 - INFO - epoch 3, step 14550, training loss = 3.454923, validation loss = 3.759666
2018-12-08 13:32:08,502 - INFO - epoch 3, step 14600, training loss = 3.064538, validation loss = 3.919315
2018-12-08 13:32:31,688 - INFO - epoch 3, step 14650, training loss = 3.532840, validation loss = 3.279569
2018-12-08 13:32:55,456 - INFO - epoch 3, step 14700, training loss = 2.652616, validation loss = 3.445619
2018-12-08 13:33:11,595 - INFO - epoch 3, step 14750, training loss = 2.669492, validation loss = 3.686897
2018-12-08 13:33:27,103 - INFO - epoch 3, step 14800, training loss = 2.534838, validation loss = 3.637512
2018-12-08 13:33:42,754 - INFO - epoch 3, step 14850, training loss = 2.707090, validation loss = 3.660214
2018-12-08 13:34:10,082 - INFO - epoch 3, step 14900, training loss = 3.167936, validation loss = 3.770287
2018-12-08 13:34:37,563 - INFO - epoch 3, step 14950, training loss = 3.454159, validation loss = 3.979746
2018-12-08 13:35:06,348 - INFO - epoch 3, step 15000, training loss = 3.329356, validation loss = 3.407459
2018-12-08 13:35:33,631 - INFO - epoch 3, step 15050, training loss = 3.518687, validation loss = 3.421417
2018-12-08 13:36:02,748 - INFO - epoch 3, step 15100, training loss = 3.270241, validation loss = 3.802259
2018-12-08 13:36:34,305 - INFO - epoch 3, step 15150, training loss = 3.461214, validation loss = 3.430587
2018-12-08 13:37:05,061 - INFO - epoch 3, step 15200, training loss = 3.634542, validation loss = 3.950254
2018-12-08 13:37:34,184 - INFO - epoch 3, step 15250, training loss = 3.466095, validation loss = 2.915595
2018-12-08 13:38:03,602 - INFO - epoch 3, step 15300, training loss = 2.713252, validation loss = 3.967354
2018-12-08 13:38:30,529 - INFO - epoch 3, step 15350, training loss = 3.176288, validation loss = 3.500468
2018-12-08 13:38:54,952 - INFO - epoch 3, step 15400, training loss = 3.486767, validation loss = 3.112584
2018-12-08 13:39:10,505 - INFO - epoch 3, step 15450, training loss = 3.329617, validation loss = 4.279038
2018-12-08 13:39:26,310 - INFO - epoch 3, step 15500, training loss = 3.135626, validation loss = 3.467529
2018-12-08 13:39:41,777 - INFO - epoch 3, step 15550, training loss = 2.730772, validation loss = 3.899334
2018-12-08 13:39:59,520 - INFO - epoch 3, step 15600, training loss = 3.531084, validation loss = 3.623619
2018-12-08 13:40:23,307 - INFO - epoch 3, step 15650, training loss = 3.075907, validation loss = 3.383575
2018-12-08 13:40:46,348 - INFO - epoch 3, step 15700, training loss = 3.448677, validation loss = 3.691076
2018-12-08 13:41:14,063 - INFO - epoch 3, step 15750, training loss = 3.395516, validation loss = 3.630017
2018-12-08 13:41:41,246 - INFO - epoch 3, step 15800, training loss = 3.653334, validation loss = 3.735346
2018-12-08 13:42:08,193 - INFO - epoch 3, step 15850, training loss = 3.364087, validation loss = 3.615072
2018-12-08 13:42:35,928 - INFO - epoch 3, step 15900, training loss = 2.968674, validation loss = 4.014982
2018-12-08 13:42:58,604 - INFO - epoch 3, step 15950, training loss = 3.069482, validation loss = 3.349270
2018-12-08 13:43:20,083 - INFO - epoch 3, step 16000, training loss = 3.487215, validation loss = 3.843458
2018-12-08 13:43:36,130 - INFO - epoch 3, step 16050, training loss = 3.330871, validation loss = 3.131737
2018-12-08 13:43:48,083 - INFO - epoch 3, step 16100, training loss = 2.917431, validation loss = 3.911267
2018-12-08 13:43:59,802 - INFO - epoch 3, step 16150, training loss = 2.924744, validation loss = 4.065797
2018-12-08 13:44:13,543 - INFO - epoch 3, step 16200, training loss = 3.741838, validation loss = 3.738293
2018-12-08 13:44:31,094 - INFO - epoch 3, step 16250, training loss = 3.387087, validation loss = 3.439090
2018-12-08 13:44:49,070 - INFO - epoch 3, step 16300, training loss = 3.413744, validation loss = 3.290467
2018-12-08 13:45:02,306 - INFO - epoch 3, step 16350, training loss = 3.093405, validation loss = 4.172497
2018-12-08 13:45:14,281 - INFO - epoch 3, step 16400, training loss = 2.955164, validation loss = 4.510833
2018-12-08 13:45:34,263 - INFO - epoch 3, step 16450, training loss = 3.056732, validation loss = 4.200743
2018-12-08 13:45:59,627 - INFO - epoch 3, step 16500, training loss = 3.546912, validation loss = 3.366742
2018-12-08 13:46:24,982 - INFO - epoch 3, step 16550, training loss = 3.598367, validation loss = 3.189392
2018-12-08 13:46:50,133 - INFO - epoch 3, step 16600, training loss = 3.761941, validation loss = 3.137455
2018-12-08 13:47:13,365 - INFO - epoch 3, step 16650, training loss = 3.638585, validation loss = 3.384823
2018-12-08 13:47:32,029 - INFO - epoch 3, step 16700, training loss = 3.157401, validation loss = 3.041065
2018-12-08 13:47:53,210 - INFO - epoch 3, step 16750, training loss = 3.407767, validation loss = 3.612450
2018-12-08 13:48:09,418 - INFO - epoch 3, step 16800, training loss = 3.276054, validation loss = 3.561942
2018-12-08 13:48:25,083 - INFO - epoch 3, step 16850, training loss = 3.054451, validation loss = 4.046806
2018-12-08 13:48:40,940 - INFO - epoch 3, step 16900, training loss = 3.386643, validation loss = 3.378335
2018-12-08 13:48:57,162 - INFO - epoch 3, step 16950, training loss = 3.715470, validation loss = 3.340305
2018-12-08 13:49:20,837 - INFO - epoch 3, step 17000, training loss = 3.493696, validation loss = 3.123358
2018-12-08 13:49:44,281 - INFO - epoch 3, step 17050, training loss = 3.456900, validation loss = 3.785276
2018-12-08 13:50:09,409 - INFO - epoch 3, step 17100, training loss = 3.055430, validation loss = 3.857784
2018-12-08 13:50:35,274 - INFO - epoch 3, step 17150, training loss = 2.786507, validation loss = 3.610202
2018-12-08 13:50:59,996 - INFO - epoch 3, step 17200, training loss = 2.671896, validation loss = 2.962283
2018-12-08 13:51:25,186 - INFO - epoch 3, step 17250, training loss = 3.037879, validation loss = 3.207865
2018-12-08 13:51:50,196 - INFO - epoch 3, step 17300, training loss = 2.403196, validation loss = 3.565351
2018-12-08 13:52:15,416 - INFO - epoch 3, step 17350, training loss = 3.714140, validation loss = 3.468377
2018-12-08 13:52:38,098 - INFO - epoch 3, step 17400, training loss = 3.214705, validation loss = 3.499737
2018-12-08 13:52:53,598 - INFO - epoch 3, step 17450, training loss = 3.879208, validation loss = 3.741555
2018-12-08 13:53:07,909 - INFO - epoch 3, step 17500, training loss = 3.527109, validation loss = 3.853758
2018-12-08 13:53:28,795 - INFO - epoch 3, step 17550, training loss = 3.939398, validation loss = 3.385407
2018-12-08 13:53:54,992 - INFO - epoch 3, step 17600, training loss = 3.402024, validation loss = 3.378089
2018-12-08 13:54:20,466 - INFO - epoch 3, step 17650, training loss = 3.524302, validation loss = 3.456213
2018-12-08 13:54:46,422 - INFO - epoch 3, step 17700, training loss = 3.239554, validation loss = 3.389671
2018-12-08 13:55:12,868 - INFO - epoch 3, step 17750, training loss = 3.383621, validation loss = 3.558035
2018-12-08 13:55:34,355 - INFO - epoch 3, step 17800, training loss = 3.520145, validation loss = 3.449394
2018-12-08 13:55:52,677 - INFO - epoch 3, step 17850, training loss = 2.523543, validation loss = 3.883221
2018-12-08 13:56:08,485 - INFO - epoch 3, step 17900, training loss = 3.114803, validation loss = 3.482471
2018-12-08 13:56:23,645 - INFO - epoch 3, step 17950, training loss = 3.437492, validation loss = 3.103162
2018-12-08 13:56:39,309 - INFO - epoch 3, step 18000, training loss = 2.846008, validation loss = 3.200123
2018-12-08 13:56:52,662 - INFO - epoch 3, step 18050, training loss = 2.786047, validation loss = 3.315635
2018-12-08 13:57:04,758 - INFO - epoch 3, step 18100, training loss = 2.644521, validation loss = 3.079632
2018-12-08 13:57:30,368 - INFO - epoch 3, step 18150, training loss = 3.273435, validation loss = 3.170105
2018-12-08 13:57:55,965 - INFO - epoch 3, step 18200, training loss = 3.293410, validation loss = 3.368119
2018-12-08 13:58:21,006 - INFO - epoch 3, step 18250, training loss = 3.317518, validation loss = 3.716796
2018-12-08 13:58:46,052 - INFO - epoch 3, step 18300, training loss = 3.666390, validation loss = 4.135283
2018-12-08 13:59:11,677 - INFO - epoch 3, step 18350, training loss = 2.916237, validation loss = 4.074327
2018-12-08 13:59:29,069 - INFO - epoch 3, step 18400, training loss = 3.247751, validation loss = 2.954740
2018-12-08 13:59:44,358 - INFO - epoch 3, step 18450, training loss = 3.200345, validation loss = 2.871242
2018-12-08 14:00:00,525 - INFO - epoch 3, step 18500, training loss = 2.783972, validation loss = 2.901542
2018-12-08 14:00:16,236 - INFO - epoch 3, step 18550, training loss = 2.308731, validation loss = 3.293393
2018-12-08 14:00:33,284 - INFO - epoch 3, step 18600, training loss = 3.556216, validation loss = 3.458979
2018-12-08 14:00:56,578 - INFO - epoch 3, step 18650, training loss = 3.482014, validation loss = 3.889876
2018-12-08 14:01:21,808 - INFO - epoch 3, step 18700, training loss = 3.256297, validation loss = 4.070030
2018-12-08 14:01:46,170 - INFO - epoch 3, step 18750, training loss = 3.293152, validation loss = 3.421297
2018-12-08 14:02:02,176 - INFO - epoch 3, step 18800, training loss = 3.199902, validation loss = 3.099060
2018-12-08 14:02:17,324 - INFO - epoch 3, step 18850, training loss = 2.617553, validation loss = 3.177238
2018-12-08 14:02:32,740 - INFO - epoch 3, step 18900, training loss = 2.816004, validation loss = 3.360043
2018-12-08 14:02:48,300 - INFO - epoch 3, step 18950, training loss = 2.384195, validation loss = 3.118803
2018-12-08 14:03:08,292 - INFO - epoch 3, step 19000, training loss = 3.250133, validation loss = 2.665145
2018-12-08 14:03:26,590 - INFO - epoch 3, step 19050, training loss = 2.867365, validation loss = 2.976019
2018-12-08 14:03:41,845 - INFO - epoch 3, step 19100, training loss = 2.588109, validation loss = 3.473035
2018-12-08 14:03:56,980 - INFO - epoch 3, step 19150, training loss = 2.827486, validation loss = 2.834066
2018-12-08 14:04:12,201 - INFO - epoch 3, step 19200, training loss = 3.325503, validation loss = 2.878853
2018-12-08 14:04:32,786 - INFO - epoch 3, step 19250, training loss = 3.621384, validation loss = 3.211819
2018-12-08 14:04:57,869 - INFO - epoch 3, step 19300, training loss = 3.572677, validation loss = 3.276176
2018-12-08 14:05:22,947 - INFO - epoch 3, step 19350, training loss = 3.109655, validation loss = 3.218362
2018-12-08 14:05:51,390 - INFO - epoch 3, step 19400, training loss = 3.047330, validation loss = 3.487886
2018-12-08 14:06:18,902 - INFO - epoch 3, step 19450, training loss = 2.782249, validation loss = 4.171741
2018-12-08 14:06:47,192 - INFO - epoch 3, step 19500, training loss = 3.619194, validation loss = 3.343293
2018-12-08 14:07:13,037 - INFO - epoch 3, step 19550, training loss = 2.873655, validation loss = 2.899346
2018-12-08 14:07:33,703 - INFO - epoch 3, step 19600, training loss = 3.353271, validation loss = 3.400048
2018-12-08 14:07:54,184 - INFO - epoch 3, step 19650, training loss = 3.355945, validation loss = 3.632758
2018-12-08 14:08:20,384 - INFO - epoch 3, step 19700, training loss = 2.767763, validation loss = 3.473940
2018-12-08 14:08:48,013 - INFO - epoch 3, step 19750, training loss = 3.458646, validation loss = 3.778181
2018-12-08 14:09:14,849 - INFO - epoch 3, step 19800, training loss = 3.366895, validation loss = 3.755496
2018-12-08 14:09:41,510 - INFO - epoch 3, step 19850, training loss = 2.877066, validation loss = 3.411474
2018-12-08 14:10:04,304 - INFO - epoch 3, step 19900, training loss = 2.460686, validation loss = 2.822977
2018-12-08 14:10:20,098 - INFO - epoch 3, step 19950, training loss = 2.927399, validation loss = 2.755068
2018-12-08 14:10:35,999 - INFO - epoch 3, step 20000, training loss = 3.000561, validation loss = 3.334267
2018-12-08 14:10:51,456 - INFO - epoch 3, step 20050, training loss = 3.295416, validation loss = 3.137724
2018-12-08 14:11:07,093 - INFO - epoch 3, step 20100, training loss = 2.773602, validation loss = 3.168759
2018-12-08 14:11:22,675 - INFO - epoch 3, step 20150, training loss = 2.364493, validation loss = 3.375839
2018-12-08 14:11:37,855 - INFO - epoch 3, step 20200, training loss = 2.621071, validation loss = 3.131828
2018-12-08 14:11:57,330 - INFO - epoch 3, step 20250, training loss = 3.483844, validation loss = 2.829217
2018-12-08 14:12:18,814 - INFO - epoch 3, step 20300, training loss = 3.767159, validation loss = 3.438326
2018-12-08 14:12:39,524 - INFO - epoch 3, step 20350, training loss = 2.910540, validation loss = 3.350730
2018-12-08 14:12:59,870 - INFO - epoch 3, step 20400, training loss = 3.413673, validation loss = 3.702821
2018-12-08 14:13:21,458 - INFO - epoch 3, step 20450, training loss = 3.566601, validation loss = 3.773839
2018-12-08 14:13:44,798 - INFO - epoch 3, step 20500, training loss = 3.183251, validation loss = 3.886307
2018-12-08 14:14:09,345 - INFO - epoch 3, step 20550, training loss = 3.027428, validation loss = 3.373357
2018-12-08 14:14:34,043 - INFO - epoch 3, step 20600, training loss = 2.991265, validation loss = 3.208398
2018-12-08 14:14:54,235 - INFO - epoch 3, step 20650, training loss = 3.098068, validation loss = 3.564948
2018-12-08 14:15:12,246 - INFO - epoch 3, step 20700, training loss = 3.008027, validation loss = 4.083858
2018-12-08 14:15:32,352 - INFO - epoch 3, step 20750, training loss = 2.799143, validation loss = 3.411148
2018-12-08 14:15:52,594 - INFO - epoch 3, step 20800, training loss = 3.190023, validation loss = 2.896675
2018-12-08 14:16:08,214 - INFO - epoch 3, step 20850, training loss = 2.276458, validation loss = 3.354753
2018-12-08 14:16:23,642 - INFO - epoch 3, step 20900, training loss = 3.159845, validation loss = 3.404284
2018-12-08 14:16:38,992 - INFO - epoch 3, step 20950, training loss = 3.075048, validation loss = 3.178186
2018-12-08 14:17:06,980 - INFO - epoch 3, step 21000, training loss = 3.002483, validation loss = 4.004846
2018-12-08 14:17:35,756 - INFO - epoch 3, step 21050, training loss = 3.124330, validation loss = 3.937631
2018-12-08 14:18:00,576 - INFO - epoch 3, step 21100, training loss = 3.566196, validation loss = 3.545697
2018-12-08 14:18:24,955 - INFO - epoch 3, step 21150, training loss = 3.316385, validation loss = 3.103742
2018-12-08 14:18:49,390 - INFO - epoch 3, step 21200, training loss = 3.452548, validation loss = 3.304010
2018-12-08 14:19:13,866 - INFO - epoch 3, step 21250, training loss = 2.511865, validation loss = 3.396155
2018-12-08 14:19:38,907 - INFO - epoch 3, step 21300, training loss = 3.468091, validation loss = 3.850060
2018-12-08 14:20:03,963 - INFO - epoch 3, step 21350, training loss = 2.797403, validation loss = 3.623334
2018-12-08 14:20:29,287 - INFO - epoch 3, step 21400, training loss = 3.034586, validation loss = 3.708570
2018-12-08 14:20:54,889 - INFO - epoch 3, step 21450, training loss = 3.024552, validation loss = 4.021800
2018-12-08 14:21:20,878 - INFO - epoch 3, step 21500, training loss = 3.311558, validation loss = 3.422001
2018-12-08 14:21:37,525 - INFO - epoch 3, step 21550, training loss = 3.687244, validation loss = 2.364521
2018-12-08 14:21:53,471 - INFO - epoch 3, step 21600, training loss = 3.263505, validation loss = 3.015167
2018-12-08 14:22:10,912 - INFO - epoch 3, step 21650, training loss = 3.653979, validation loss = 3.066918
2018-12-08 14:22:33,981 - INFO - epoch 3, step 21700, training loss = 3.493732, validation loss = 3.618135
2018-12-08 14:22:56,977 - INFO - epoch 3, step 21750, training loss = 3.380319, validation loss = 3.801756
2018-12-08 14:23:20,886 - INFO - epoch 3, step 21800, training loss = 3.235653, validation loss = 3.611794
2018-12-08 14:23:44,746 - INFO - epoch 3, step 21850, training loss = 3.425678, validation loss = 3.982679
2018-12-08 14:24:04,752 - INFO - epoch 3, step 21900, training loss = 2.151493, validation loss = 3.253098
2018-12-08 14:24:16,510 - INFO - epoch 3, step 21950, training loss = 2.830663, validation loss = 3.544518
2018-12-08 14:24:27,997 - INFO - epoch 3, step 22000, training loss = 3.326901, validation loss = 4.073765
2018-12-08 14:24:41,018 - INFO - epoch 3, step 22050, training loss = 3.667806, validation loss = 3.589362
2018-12-08 14:25:02,842 - INFO - epoch 3, step 22100, training loss = 3.684635, validation loss = 3.455938
2018-12-08 14:25:24,578 - INFO - epoch 3, step 22150, training loss = 3.225118, validation loss = 3.860250
2018-12-08 14:25:45,996 - INFO - epoch 3, step 22200, training loss = 3.379288, validation loss = 3.893813
2018-12-08 14:26:11,724 - INFO - epoch 3, step 22250, training loss = 3.174306, validation loss = 3.048304
2018-12-08 14:26:41,162 - INFO - epoch 3, step 22300, training loss = 2.956611, validation loss = 3.472702
2018-12-08 14:27:10,107 - INFO - epoch 3, step 22350, training loss = 3.116841, validation loss = 2.639484
2018-12-08 14:27:37,710 - INFO - epoch 3, step 22400, training loss = 3.380590, validation loss = 3.229166
2018-12-08 14:28:05,870 - INFO - epoch 3, step 22450, training loss = 3.199181, validation loss = 3.351128
2018-12-08 14:28:31,867 - INFO - epoch 3, step 22500, training loss = 3.581463, validation loss = 3.600116
2018-12-08 14:28:59,999 - INFO - epoch 3, step 22550, training loss = 3.237121, validation loss = 3.684924
2018-12-08 14:29:27,941 - INFO - epoch 3, step 22600, training loss = 2.984060, validation loss = 3.392810
2018-12-08 14:29:49,963 - INFO - epoch 3, step 22650, training loss = 3.272302, validation loss = 2.993693
2018-12-08 14:30:09,132 - INFO - epoch 3, step 22700, training loss = 3.207138, validation loss = 2.822799
2018-12-08 14:30:26,370 - INFO - epoch 3, step 22750, training loss = 3.355960, validation loss = 3.232838
2018-12-08 14:30:43,747 - INFO - epoch 3, step 22800, training loss = 3.565051, validation loss = 3.375307
2018-12-08 14:31:00,569 - INFO - epoch 3, step 22850, training loss = 2.477159, validation loss = 3.247560
2018-12-08 14:31:16,452 - INFO - epoch 3, step 22900, training loss = 2.616855, validation loss = 3.573863
2018-12-08 14:31:32,088 - INFO - epoch 3, step 22950, training loss = 2.886544, validation loss = 3.491240
2018-12-08 14:31:47,891 - INFO - epoch 3, step 23000, training loss = 2.927809, validation loss = 3.518501
2018-12-08 14:32:09,254 - INFO - epoch 3, step 23050, training loss = 3.214644, validation loss = 3.317386
2018-12-08 14:32:30,086 - INFO - epoch 3, step 23100, training loss = 3.325847, validation loss = 3.475666
2018-12-08 14:32:46,352 - INFO - epoch 3, step 23150, training loss = 2.265841, validation loss = 3.547427
2018-12-08 14:32:57,833 - INFO - epoch 3, step 23200, training loss = 2.520952, validation loss = 4.095113
2018-12-08 14:33:09,741 - INFO - epoch 3, step 23250, training loss = 2.928457, validation loss = 4.362638
2018-12-08 14:33:22,958 - INFO - epoch 3, step 23300, training loss = 2.942256, validation loss = 3.249601
2018-12-08 14:33:38,888 - INFO - epoch 3, step 23350, training loss = 2.556439, validation loss = 3.649723
2018-12-08 14:33:54,279 - INFO - epoch 3, step 23400, training loss = 2.756181, validation loss = 3.787845
2018-12-08 14:34:11,193 - INFO - epoch 3, step 23450, training loss = 3.397740, validation loss = 4.251184
2018-12-08 14:34:35,906 - INFO - epoch 3, step 23500, training loss = 3.193805, validation loss = 3.550959
2018-12-08 14:34:58,619 - INFO - epoch 3, step 23550, training loss = 3.559370, validation loss = 3.097723
2018-12-08 14:35:19,316 - INFO - epoch 3, step 23600, training loss = 3.324894, validation loss = 3.030101
2018-12-08 14:35:40,103 - INFO - epoch 3, step 23650, training loss = 3.102500, validation loss = 3.326237
2018-12-08 14:36:01,332 - INFO - epoch 3, step 23700, training loss = 3.271234, validation loss = 3.531876
2018-12-08 14:36:25,082 - INFO - epoch 3, step 23750, training loss = 3.269914, validation loss = 3.659019
2018-12-08 14:36:48,912 - INFO - epoch 3, step 23800, training loss = 3.223567, validation loss = 3.484713
2018-12-08 14:37:13,905 - INFO - epoch 3, step 23850, training loss = 3.731522, validation loss = 3.521421
2018-12-08 14:37:38,870 - INFO - epoch 3, step 23900, training loss = 3.686663, validation loss = 3.359563
2018-12-08 14:38:03,131 - INFO - epoch 3, step 23950, training loss = 3.475124, validation loss = 3.550536
2018-12-08 14:38:25,973 - INFO - epoch 3, step 24000, training loss = 3.264404, validation loss = 3.058501
2018-12-08 14:38:52,786 - INFO - epoch 3, step 24050, training loss = 3.231617, validation loss = 3.351295
2018-12-08 14:39:22,365 - INFO - epoch 3, step 24100, training loss = 3.471433, validation loss = 3.462057
2018-12-08 14:39:51,216 - INFO - epoch 3, step 24150, training loss = 3.523052, validation loss = 3.700255
2018-12-08 14:40:18,931 - INFO - epoch 3, step 24200, training loss = 3.496945, validation loss = 3.539065
2018-12-08 14:40:44,461 - INFO - epoch 3, step 24250, training loss = 2.914708, validation loss = 3.684251
2018-12-08 14:41:00,541 - INFO - epoch 3, step 24300, training loss = 2.894904, validation loss = 3.256048
2018-12-08 14:41:16,138 - INFO - epoch 3, step 24350, training loss = 2.426834, validation loss = 3.260696
2018-12-08 14:41:32,159 - INFO - epoch 3, step 24400, training loss = 2.711785, validation loss = 3.535715
2018-12-08 14:41:47,868 - INFO - epoch 3, step 24450, training loss = 3.417408, validation loss = 3.849473
2018-12-08 14:42:03,497 - INFO - epoch 3, step 24500, training loss = 3.175746, validation loss = 3.444764
2018-12-08 14:42:18,979 - INFO - epoch 3, step 24550, training loss = 2.624170, validation loss = 3.736299
2018-12-08 14:42:34,941 - INFO - epoch 3, step 24600, training loss = 4.004626, validation loss = 4.092958
2018-12-08 14:42:51,489 - INFO - epoch 3, step 24650, training loss = 3.171590, validation loss = 3.974141
2018-12-08 14:43:06,744 - INFO - epoch 3, step 24700, training loss = 3.092519, validation loss = 3.831896
2018-12-08 14:43:22,200 - INFO - epoch 3, step 24750, training loss = 3.008191, validation loss = 3.720224
2018-12-08 14:43:37,991 - INFO - epoch 3, step 24800, training loss = 2.311898, validation loss = 3.873948
2018-12-08 14:43:54,255 - INFO - epoch 3, step 24850, training loss = 2.438972, validation loss = 3.577224
2018-12-08 14:44:12,269 - INFO - epoch 3, step 24900, training loss = 3.142946, validation loss = 3.373071
2018-12-08 14:44:33,745 - INFO - epoch 3, step 24950, training loss = 3.775006, validation loss = 3.378906
2018-12-08 14:45:00,319 - INFO - epoch 3, step 25000, training loss = 3.624570, validation loss = 3.476968
2018-12-08 14:45:26,837 - INFO - epoch 3, step 25050, training loss = 3.448367, validation loss = 3.531032
2018-12-08 14:45:53,048 - INFO - epoch 3, step 25100, training loss = 3.324162, validation loss = 3.568874
2018-12-08 14:46:19,272 - INFO - epoch 3, step 25150, training loss = 3.478060, validation loss = 3.687267
2018-12-08 14:46:37,990 - INFO - epoch 3, step 25200, training loss = 3.151861, validation loss = 3.460615
2018-12-08 14:46:55,782 - INFO - epoch 3, step 25250, training loss = 3.465121, validation loss = 3.572776
2018-12-08 14:47:19,192 - INFO - epoch 3, step 25300, training loss = 3.372613, validation loss = 3.573335
2018-12-08 14:47:46,024 - INFO - epoch 3, step 25350, training loss = 3.632206, validation loss = 3.545898
2018-12-08 14:48:13,125 - INFO - epoch 3, step 25400, training loss = 2.917362, validation loss = 3.746410
2018-12-08 14:48:39,603 - INFO - epoch 3, step 25450, training loss = 3.383479, validation loss = 3.699856
2018-12-08 14:48:57,601 - INFO - epoch 3, step 25500, training loss = 2.841678, validation loss = 3.774532
2018-12-08 14:49:13,235 - INFO - epoch 3, step 25550, training loss = 3.139075, validation loss = 3.473432
2018-12-08 14:49:33,485 - INFO - epoch 3, step 25600, training loss = 3.450603, validation loss = 2.987154
2018-12-08 14:49:59,997 - INFO - epoch 3, step 25650, training loss = 3.260932, validation loss = 3.234703
2018-12-08 14:50:28,114 - INFO - epoch 3, step 25700, training loss = 3.020128, validation loss = 3.555275
2018-12-08 14:50:55,228 - INFO - epoch 3, step 25750, training loss = 2.924436, validation loss = 3.163255
2018-12-08 14:51:16,165 - INFO - epoch 3, step 25800, training loss = 3.325296, validation loss = 3.204789
2018-12-08 14:51:33,303 - INFO - epoch 3, step 25850, training loss = 3.301252, validation loss = 3.589038
2018-12-08 14:51:48,630 - INFO - epoch 3, step 25900, training loss = 2.682633, validation loss = 3.298097
2018-12-08 14:52:04,373 - INFO - epoch 3, step 25950, training loss = 3.326299, validation loss = 3.716758
2018-12-08 14:52:29,980 - INFO - epoch 3, step 26000, training loss = 3.112765, validation loss = 3.741124
2018-12-08 14:52:55,888 - INFO - epoch 3, step 26050, training loss = 2.803999, validation loss = 3.474041
2018-12-08 14:53:20,677 - INFO - epoch 3, step 26100, training loss = 2.779513, validation loss = 3.392812
2018-12-08 14:53:45,288 - INFO - epoch 3, step 26150, training loss = 3.389625, validation loss = 3.719855
2018-12-08 14:54:13,184 - INFO - epoch 3, step 26200, training loss = 3.711275, validation loss = 3.736046
2018-12-08 14:54:40,063 - INFO - epoch 3, step 26250, training loss = 3.214711, validation loss = 3.695843
2018-12-08 14:55:07,838 - INFO - epoch 3, step 26300, training loss = 2.932020, validation loss = 3.521279
2018-12-08 14:55:33,652 - INFO - epoch 3, step 26350, training loss = 3.762479, validation loss = 3.780235
2018-12-08 14:55:59,193 - INFO - epoch 3, step 26400, training loss = 3.311865, validation loss = 3.982121
2018-12-08 14:56:24,936 - INFO - epoch 3, step 26450, training loss = 3.279499, validation loss = 3.267893
2018-12-08 14:56:44,247 - INFO - epoch 3, step 26500, training loss = 3.269657, validation loss = 3.735376
2018-12-08 14:57:00,925 - INFO - epoch 3, step 26550, training loss = 3.274248, validation loss = 3.643068
2018-12-08 14:57:16,557 - INFO - epoch 3, step 26600, training loss = 3.256545, validation loss = 3.719880
2018-12-08 14:57:32,424 - INFO - epoch 3, step 26650, training loss = 2.711040, validation loss = 3.889107
2018-12-08 14:57:48,016 - INFO - epoch 3, step 26700, training loss = 2.446696, validation loss = 3.990368
2018-12-08 14:58:13,016 - INFO - epoch 3, step 26750, training loss = 3.647669, validation loss = 3.614577
2018-12-08 14:58:40,802 - INFO - epoch 3, step 26800, training loss = 3.219533, validation loss = 3.885162
2018-12-08 14:59:08,200 - INFO - epoch 3, step 26850, training loss = 3.002878, validation loss = 3.150305
2018-12-08 14:59:33,913 - INFO - epoch 3, step 26900, training loss = 3.185708, validation loss = 3.379292
2018-12-08 14:59:59,654 - INFO - epoch 3, step 26950, training loss = 3.306780, validation loss = 3.720201
2018-12-08 15:00:25,977 - INFO - epoch 3, step 27000, training loss = 3.619283, validation loss = 3.686250
2018-12-08 15:00:51,508 - INFO - epoch 3, step 27050, training loss = 3.368799, validation loss = 3.397811
2018-12-08 15:01:12,591 - INFO - epoch 3, step 27100, training loss = 3.174043, validation loss = 3.692203
2018-12-08 15:01:31,313 - INFO - epoch 3, step 27150, training loss = 4.031183, validation loss = 4.000292
2018-12-08 15:01:54,426 - INFO - epoch 3, step 27200, training loss = 3.071545, validation loss = 3.830760
2018-12-08 15:02:19,992 - INFO - epoch 3, step 27250, training loss = 3.341250, validation loss = 3.165492
2018-12-08 15:02:44,679 - INFO - epoch 3, step 27300, training loss = 3.518040, validation loss = 3.351675
2018-12-08 15:03:06,418 - INFO - epoch 3, step 27350, training loss = 2.860962, validation loss = 3.494728
2018-12-08 15:03:27,284 - INFO - epoch 3, step 27400, training loss = 3.105144, validation loss = 3.221257
2018-12-08 15:03:42,877 - INFO - epoch 3, step 27450, training loss = 3.199375, validation loss = 3.903825
2018-12-08 15:03:58,697 - INFO - epoch 3, step 27500, training loss = 2.855290, validation loss = 4.044967
2018-12-08 15:04:14,620 - INFO - epoch 3, step 27550, training loss = 2.416939, validation loss = 3.285792
2018-12-08 15:04:33,452 - INFO - epoch 3, step 27600, training loss = 3.429516, validation loss = 3.182619
2018-12-08 15:04:58,342 - INFO - epoch 3, step 27650, training loss = 3.353909, validation loss = 3.430203
2018-12-08 15:05:26,235 - INFO - epoch 3, step 27700, training loss = 3.442417, validation loss = 3.365340
2018-12-08 15:05:54,384 - INFO - epoch 3, step 27750, training loss = 3.367976, validation loss = 3.314192
2018-12-08 15:06:20,070 - INFO - epoch 3, step 27800, training loss = 3.005910, validation loss = 3.334039
2018-12-08 15:06:44,926 - INFO - epoch 3, step 27850, training loss = 2.779240, validation loss = 3.628398
2018-12-08 15:07:10,324 - INFO - epoch 3, step 27900, training loss = 2.991801, validation loss = 3.265561
2018-12-08 15:07:35,160 - INFO - epoch 3, step 27950, training loss = 2.674031, validation loss = 3.058980
2018-12-08 15:08:00,491 - INFO - epoch 3, step 28000, training loss = 3.148437, validation loss = 3.539692
2018-12-08 15:08:26,576 - INFO - epoch 3, step 28050, training loss = 2.920911, validation loss = 3.378064
2018-12-08 15:08:53,118 - INFO - epoch 3, step 28100, training loss = 2.715794, validation loss = 4.007588
2018-12-08 15:09:18,654 - INFO - epoch 3, step 28150, training loss = 3.351715, validation loss = 3.600687
2018-12-08 15:09:43,846 - INFO - epoch 3, step 28200, training loss = 3.162621, validation loss = 3.490179
2018-12-08 15:10:08,697 - INFO - epoch 3, step 28250, training loss = 2.677411, validation loss = 3.231666
2018-12-08 15:10:33,706 - INFO - epoch 3, step 28300, training loss = 3.203313, validation loss = 3.294310
2018-12-08 15:10:59,076 - INFO - epoch 3, step 28350, training loss = 3.515711, validation loss = 3.447907
2018-12-08 15:11:20,995 - INFO - epoch 3, step 28400, training loss = 3.003929, validation loss = 3.843322
2018-12-08 15:11:47,742 - INFO - epoch 3, step 28450, training loss = 3.333125, validation loss = 3.788135
2018-12-08 15:12:16,360 - INFO - epoch 3, step 28500, training loss = 3.198451, validation loss = 3.484081
2018-12-08 15:12:34,643 - INFO - epoch 3, step 28550, training loss = 2.901479, validation loss = 3.765399
2018-12-08 15:12:50,378 - INFO - epoch 3, step 28600, training loss = 3.291393, validation loss = 3.831262
2018-12-08 15:13:05,679 - INFO - epoch 3, step 28650, training loss = 3.167687, validation loss = 4.057075
2018-12-08 15:13:26,634 - INFO - epoch 3, step 28700, training loss = 3.543622, validation loss = 3.577025
2018-12-08 15:13:51,727 - INFO - epoch 3, step 28750, training loss = 3.103176, validation loss = 3.263171
2018-12-08 15:14:16,541 - INFO - epoch 3, step 28800, training loss = 3.083659, validation loss = 3.736103
2018-12-08 15:14:41,698 - INFO - epoch 3, step 28850, training loss = 3.052588, validation loss = 3.496811
2018-12-08 15:15:06,619 - INFO - epoch 3, step 28900, training loss = 2.808085, validation loss = 3.551051
2018-12-08 15:15:31,838 - INFO - epoch 3, step 28950, training loss = 3.168449, validation loss = 3.280665
2018-12-08 15:15:57,880 - INFO - epoch 3, step 29000, training loss = 2.898362, validation loss = 2.892204
2018-12-08 15:16:23,178 - INFO - epoch 3, step 29050, training loss = 2.939056, validation loss = 3.506314
2018-12-08 15:16:44,534 - INFO - epoch 3, step 29100, training loss = 3.355496, validation loss = 3.532161
2018-12-08 15:17:10,689 - INFO - epoch 3, step 29150, training loss = 3.239342, validation loss = 3.418999
2018-12-08 15:17:38,809 - INFO - epoch 3, step 29200, training loss = 2.902971, validation loss = 3.144473
2018-12-08 15:18:05,903 - INFO - epoch 3, step 29250, training loss = 3.316259, validation loss = 3.625215
2018-12-08 15:18:31,833 - INFO - epoch 3, step 29300, training loss = 3.328278, validation loss = 3.781970
2018-12-08 15:18:57,350 - INFO - epoch 3, step 29350, training loss = 3.026728, validation loss = 3.245146
2018-12-08 15:19:23,403 - INFO - epoch 3, step 29400, training loss = 3.084786, validation loss = 3.177550
2018-12-08 15:19:49,345 - INFO - epoch 3, step 29450, training loss = 3.515061, validation loss = 3.479522
2018-12-08 15:20:14,716 - INFO - epoch 3, step 29500, training loss = 3.420052, validation loss = 3.308978
2018-12-08 15:20:40,911 - INFO - epoch 3, step 29550, training loss = 3.393313, validation loss = 3.564119
2018-12-08 15:21:07,162 - INFO - epoch 3, step 29600, training loss = 3.069045, validation loss = 3.996379
2018-12-08 15:21:32,899 - INFO - epoch 3, step 29650, training loss = 2.846022, validation loss = 3.515729
2018-12-08 15:21:57,619 - INFO - epoch 3, step 29700, training loss = 2.953469, validation loss = 3.301994
2018-12-08 15:22:18,509 - INFO - epoch 3, step 29750, training loss = 3.027818, validation loss = 3.357010
2018-12-08 15:22:42,832 - INFO - epoch 3, step 29800, training loss = 2.976294, validation loss = 3.633456
2018-12-08 15:23:09,131 - INFO - epoch 3, step 29850, training loss = 2.821026, validation loss = 3.574625
2018-12-08 15:23:35,418 - INFO - epoch 3, step 29900, training loss = 3.150506, validation loss = 3.752355
2018-12-08 15:24:00,995 - INFO - epoch 3, step 29950, training loss = 2.996970, validation loss = 3.747378
2018-12-08 15:24:26,657 - INFO - epoch 3, step 30000, training loss = 2.995439, validation loss = 3.642063
2018-12-08 15:24:51,862 - INFO - epoch 3, step 30050, training loss = 2.762656, validation loss = 3.671304
2018-12-08 15:25:13,330 - INFO - epoch 3, step 30100, training loss = 3.679374, validation loss = 3.564219
2018-12-08 15:25:29,534 - INFO - epoch 3, step 30150, training loss = 2.558654, validation loss = 3.463596
2018-12-08 15:25:45,292 - INFO - epoch 3, step 30200, training loss = 3.201482, validation loss = 3.636149
2018-12-08 15:26:08,685 - INFO - epoch 3, step 30250, training loss = 3.073592, validation loss = 3.651682
2018-12-08 15:26:33,736 - INFO - epoch 3, step 30300, training loss = 2.872901, validation loss = 3.586748
2018-12-08 15:26:58,754 - INFO - epoch 3, step 30350, training loss = 3.434268, validation loss = 3.802310
2018-12-08 15:27:26,559 - INFO - epoch 3, step 30400, training loss = 3.021070, validation loss = 3.373335
2018-12-08 15:27:54,143 - INFO - epoch 3, step 30450, training loss = 3.158801, validation loss = 3.537747
2018-12-08 15:28:20,920 - INFO - epoch 3, step 30500, training loss = 3.243350, validation loss = 3.314795
2018-12-08 15:28:47,603 - INFO - epoch 3, step 30550, training loss = 3.524893, validation loss = 3.343932
2018-12-08 15:29:14,882 - INFO - epoch 3, step 30600, training loss = 3.409102, validation loss = 3.474919
2018-12-08 15:29:42,796 - INFO - epoch 3, step 30650, training loss = 3.398892, validation loss = 3.576399
2018-12-08 15:30:10,430 - INFO - epoch 3, step 30700, training loss = 3.229057, validation loss = 3.557040
2018-12-08 15:30:36,309 - INFO - epoch 3, step 30750, training loss = 4.204617, validation loss = 3.882272
2018-12-08 15:30:49,825 - INFO - epoch 3, step 30800, training loss = 3.226310, validation loss = 3.845209
2018-12-08 15:31:04,665 - INFO - epoch 3, step 30850, training loss = 3.262521, validation loss = 3.706704
2018-12-08 15:31:25,152 - INFO - epoch 3, step 30900, training loss = 3.133305, validation loss = 3.486722
2018-12-08 15:31:50,768 - INFO - epoch 3, step 30950, training loss = 3.287194, validation loss = 3.815305
2018-12-08 15:32:19,732 - INFO - epoch 3, step 31000, training loss = 2.917993, validation loss = 3.378773
2018-12-08 15:32:48,121 - INFO - epoch 3, step 31050, training loss = 3.242557, validation loss = 3.637336
2018-12-08 15:33:06,029 - INFO - epoch 3, step 31100, training loss = 2.838476, validation loss = 3.559668
2018-12-08 15:33:21,847 - INFO - epoch 3, step 31150, training loss = 2.667377, validation loss = 3.594128
2018-12-08 15:33:38,547 - INFO - epoch 3, step 31200, training loss = 3.098102, validation loss = 3.565338
2018-12-08 15:33:58,777 - INFO - epoch 3, step 31250, training loss = 3.790933, validation loss = 3.305256
2018-12-08 15:34:16,724 - INFO - epoch 3, step 31300, training loss = 3.173161, validation loss = 3.115663
2018-12-08 15:34:28,800 - INFO - epoch 3, step 31350, training loss = 2.336040, validation loss = 3.588811
2018-12-08 15:34:41,014 - INFO - epoch 3, step 31400, training loss = 2.856641, validation loss = 4.267863
2018-12-08 15:34:53,367 - INFO - epoch 3, step 31450, training loss = 3.160414, validation loss = 3.951567
2018-12-08 15:35:09,297 - INFO - epoch 3, step 31500, training loss = 2.756326, validation loss = 3.032420
2018-12-08 15:35:25,114 - INFO - epoch 3, step 31550, training loss = 3.151337, validation loss = 3.965589
2018-12-08 15:35:47,096 - INFO - epoch 3, step 31600, training loss = 3.798525, validation loss = 3.640562
2018-12-08 15:36:12,167 - INFO - epoch 3, step 31650, training loss = 2.826949, validation loss = 3.829868
2018-12-08 15:36:38,085 - INFO - epoch 3, step 31700, training loss = 3.562912, validation loss = 3.678626
2018-12-08 15:37:03,309 - INFO - epoch 3, step 31750, training loss = 3.513024, validation loss = 3.777965
2018-12-08 15:37:24,966 - INFO - epoch 3, step 31800, training loss = 2.982699, validation loss = 3.698309
2018-12-08 15:37:36,219 - INFO - epoch 3, step 31850, training loss = 2.844950, validation loss = 3.437558
2018-12-08 15:37:47,424 - INFO - epoch 3, step 31900, training loss = 2.879516, validation loss = 3.555286
2018-12-08 15:38:05,182 - INFO - epoch 3, step 31950, training loss = 2.968775, validation loss = 3.403035
2018-12-08 15:38:34,127 - INFO - epoch 3, step 32000, training loss = 3.278140, validation loss = 3.568472
2018-12-08 15:39:01,250 - INFO - epoch 3, step 32050, training loss = 3.633412, validation loss = 3.163715
2018-12-08 15:39:30,185 - INFO - epoch 3, step 32100, training loss = 3.111630, validation loss = 3.577695
2018-12-08 15:39:47,864 - INFO - epoch 3, step 32150, training loss = 2.561814, validation loss = 3.853191
2018-12-08 15:39:59,415 - INFO - epoch 3, step 32200, training loss = 2.928114, validation loss = 3.904771
2018-12-08 15:40:11,203 - INFO - epoch 3, step 32250, training loss = 2.857826, validation loss = 4.321604
2018-12-08 15:40:31,297 - INFO - epoch 3, step 32300, training loss = 3.697736, validation loss = 3.691774
2018-12-08 15:40:56,454 - INFO - epoch 3, step 32350, training loss = 3.419626, validation loss = 3.900767
2018-12-08 15:41:21,677 - INFO - epoch 3, step 32400, training loss = 3.280512, validation loss = 3.892374
2018-12-08 15:41:46,402 - INFO - epoch 3, step 32450, training loss = 3.302713, validation loss = 3.340066
2018-12-08 15:42:11,178 - INFO - epoch 3, step 32500, training loss = 3.387646, validation loss = 3.593517
2018-12-08 15:42:33,176 - INFO - epoch 3, step 32550, training loss = 2.978353, validation loss = 3.616491
2018-12-08 15:42:52,610 - INFO - epoch 3, step 32600, training loss = 3.269585, validation loss = 3.936178
2018-12-08 15:43:08,442 - INFO - epoch 3, step 32650, training loss = 3.190901, validation loss = 3.961986
2018-12-08 15:43:33,270 - INFO - epoch 3, step 32700, training loss = 3.201380, validation loss = 4.136479
2018-12-08 15:43:58,386 - INFO - epoch 3, step 32750, training loss = 2.750403, validation loss = 3.892589
2018-12-08 15:44:22,668 - INFO - epoch 3, step 32800, training loss = 3.350388, validation loss = 3.643424
2018-12-08 15:44:48,233 - INFO - epoch 3, step 32850, training loss = 2.873624, validation loss = 3.883590
2018-12-08 15:45:13,963 - INFO - epoch 3, step 32900, training loss = 3.226516, validation loss = 3.839657
2018-12-08 15:45:41,615 - INFO - epoch 3, step 32950, training loss = 3.275567, validation loss = 3.481970
2018-12-08 15:46:08,858 - INFO - epoch 3, step 33000, training loss = 3.422034, validation loss = 3.738422
2018-12-08 15:46:29,856 - INFO - epoch 3, step 33050, training loss = 3.129619, validation loss = 3.511521
2018-12-08 15:46:48,413 - INFO - epoch 3, step 33100, training loss = 3.313161, validation loss = 3.498618
2018-12-08 15:47:06,261 - INFO - epoch 3, step 33150, training loss = 3.783104, validation loss = 3.942860
2018-12-08 15:47:29,934 - INFO - epoch 3, step 33200, training loss = 3.057882, validation loss = 3.734696
2018-12-08 15:47:57,105 - INFO - epoch 3, step 33250, training loss = 2.853682, validation loss = 3.582466
2018-12-08 15:48:23,598 - INFO - epoch 3, step 33300, training loss = 3.445854, validation loss = 3.470724
2018-12-08 15:48:51,859 - INFO - epoch 3, step 33350, training loss = 2.968863, validation loss = 3.789367
2018-12-08 15:49:16,264 - INFO - epoch 3, step 33400, training loss = 3.154390, validation loss = 3.525798
2018-12-08 15:49:39,718 - INFO - epoch 3, step 33450, training loss = 3.144985, validation loss = 3.432618
2018-12-08 15:50:04,262 - INFO - epoch 3, step 33500, training loss = 3.772526, validation loss = 3.156058
2018-12-08 15:50:29,456 - INFO - epoch 3, step 33550, training loss = 3.145027, validation loss = 3.553050
2018-12-08 15:50:54,909 - INFO - epoch 3, step 33600, training loss = 2.616334, validation loss = 3.495239
2018-12-08 15:51:21,248 - INFO - epoch 3, step 33650, training loss = 3.386618, validation loss = 3.566398
2018-12-08 15:51:46,697 - INFO - epoch 3, step 33700, training loss = 2.817433, validation loss = 3.712164
2018-12-08 15:52:11,539 - INFO - epoch 3, step 33750, training loss = 3.631632, validation loss = 3.609924
2018-12-08 15:52:37,024 - INFO - epoch 3, step 33800, training loss = 2.791830, validation loss = 3.794229
2018-12-08 15:53:02,575 - INFO - epoch 3, step 33850, training loss = 2.830452, validation loss = 3.836538
2018-12-08 15:53:27,583 - INFO - epoch 3, step 33900, training loss = 3.512640, validation loss = 3.867200
2018-12-08 15:53:53,184 - INFO - epoch 3, step 33950, training loss = 2.989023, validation loss = 4.076233
2018-12-08 15:54:18,732 - INFO - epoch 3, step 34000, training loss = 3.294235, validation loss = 3.570336
2018-12-08 15:54:43,458 - INFO - epoch 3, step 34050, training loss = 2.932621, validation loss = 3.903904
2018-12-08 15:55:04,512 - INFO - epoch 3, step 34100, training loss = 2.443555, validation loss = 3.661551
2018-12-08 15:55:16,387 - INFO - epoch 3, step 34150, training loss = 3.077675, validation loss = 4.000813
2018-12-08 15:55:28,499 - INFO - epoch 3, step 34200, training loss = 2.467506, validation loss = 4.351251
2018-12-08 15:55:48,005 - INFO - epoch 3, step 34250, training loss = 3.149953, validation loss = 3.975972
2018-12-08 15:56:12,897 - INFO - epoch 3, step 34300, training loss = 3.529378, validation loss = 3.458330
2018-12-08 15:56:38,311 - INFO - epoch 3, step 34350, training loss = 3.143988, validation loss = 3.729599
2018-12-08 15:57:03,648 - INFO - epoch 3, step 34400, training loss = 2.809064, validation loss = 3.792767
2018-12-08 15:57:28,473 - INFO - epoch 3, step 34450, training loss = 2.896403, validation loss = 4.138181
2018-12-08 15:57:47,127 - INFO - epoch 3, step 34500, training loss = 3.062130, validation loss = 3.727123
2018-12-08 15:58:02,523 - INFO - epoch 3, step 34550, training loss = 3.426349, validation loss = 3.744789
2018-12-08 15:58:18,252 - INFO - epoch 3, step 34600, training loss = 2.651767, validation loss = 3.745562
2018-12-08 15:58:35,733 - INFO - epoch 3, step 34650, training loss = 3.824399, validation loss = 3.662347
2018-12-08 15:59:01,680 - INFO - epoch 3, step 34700, training loss = 2.958938, validation loss = 3.443196
2018-12-08 15:59:28,387 - INFO - epoch 3, step 34750, training loss = 2.985309, validation loss = 3.667755
2018-12-08 15:59:55,716 - INFO - epoch 3, step 34800, training loss = 3.656763, validation loss = 3.543790
2018-12-08 16:00:19,384 - INFO - epoch 3, step 34850, training loss = 3.433356, validation loss = 3.877701
2018-12-08 16:00:49,387 - INFO - epoch 3, step 34900, training loss = 3.150288, validation loss = 3.309718
2018-12-08 16:01:15,011 - INFO - epoch 3, step 34950, training loss = 3.225983, validation loss = 3.694895
2018-12-08 16:01:38,884 - INFO - epoch 3, step 35000, training loss = 3.561637, validation loss = 3.524695
2018-12-08 16:02:02,999 - INFO - epoch 3, step 35050, training loss = 3.253728, validation loss = 3.502160
2018-12-08 16:02:17,117 - INFO - epoch 3, step 35100, training loss = 2.725000, validation loss = 4.172978
2018-12-08 16:02:28,896 - INFO - epoch 3, step 35150, training loss = 2.932161, validation loss = 3.838751
2018-12-08 16:02:40,302 - INFO - epoch 3, step 35200, training loss = 2.968327, validation loss = 3.686248
2018-12-08 16:02:56,988 - INFO - epoch 3, step 35250, training loss = 3.356601, validation loss = 3.548955
2018-12-08 16:03:18,189 - INFO - epoch 3, step 35300, training loss = 3.008608, validation loss = 3.305355
2018-12-08 16:03:40,407 - INFO - epoch 3, step 35350, training loss = 3.347855, validation loss = 3.564207
2018-12-08 16:04:03,161 - INFO - epoch 3, step 35400, training loss = 3.271369, validation loss = 3.593586
2018-12-08 16:04:25,336 - INFO - epoch 3, step 35450, training loss = 3.308899, validation loss = 4.024788
2018-12-08 16:04:46,877 - INFO - epoch 3, step 35500, training loss = 3.422543, validation loss = 3.609403
2018-12-08 16:05:08,199 - INFO - epoch 3, step 35550, training loss = 3.702869, validation loss = 3.875386
2018-12-08 16:05:32,463 - INFO - epoch 3, step 35600, training loss = 3.363200, validation loss = 3.695475
2018-12-08 16:06:00,136 - INFO - epoch 3, step 35650, training loss = 3.234046, validation loss = 3.915455
2018-12-08 16:06:25,501 - INFO - epoch 3, step 35700, training loss = 3.201565, validation loss = 3.676244
2018-12-08 16:06:45,906 - INFO - epoch 3, step 35750, training loss = 3.840322, validation loss = 3.317538
2018-12-08 16:07:04,851 - INFO - epoch 3, step 35800, training loss = 3.093891, validation loss = 3.707923
2018-12-08 16:07:23,675 - INFO - epoch 3, step 35850, training loss = 3.212604, validation loss = 3.795577
2018-12-08 16:07:42,014 - INFO - epoch 3, step 35900, training loss = 2.977015, validation loss = 3.641896
2018-12-08 16:08:00,811 - INFO - epoch 3, step 35950, training loss = 2.798324, validation loss = 4.079634
2018-12-08 16:08:19,790 - INFO - epoch 3, step 36000, training loss = 2.892821, validation loss = 3.692376
2018-12-08 16:08:38,231 - INFO - epoch 3, step 36050, training loss = 3.161889, validation loss = 4.074250
2018-12-08 16:08:57,127 - INFO - epoch 3, step 36100, training loss = 3.110044, validation loss = 3.799039
2018-12-08 16:09:16,230 - INFO - epoch 3, step 36150, training loss = 2.586251, validation loss = 3.829634
2018-12-08 16:09:34,613 - INFO - epoch 3, step 36200, training loss = 2.585288, validation loss = 3.583458
2018-12-08 16:09:52,737 - INFO - epoch 3, step 36250, training loss = 3.295088, validation loss = 3.730693
2018-12-08 16:10:11,284 - INFO - epoch 3, step 36300, training loss = 2.955919, validation loss = 3.925403
2018-12-08 16:10:29,997 - INFO - epoch 3, step 36350, training loss = 2.606732, validation loss = 4.095692
2018-12-08 16:10:48,307 - INFO - epoch 3, step 36400, training loss = 3.162592, validation loss = 3.442643
2018-12-08 16:11:06,315 - INFO - epoch 3, step 36450, training loss = 2.857672, validation loss = 3.584389
2018-12-08 16:11:24,954 - INFO - epoch 3, step 36500, training loss = 2.875838, validation loss = 3.509786
2018-12-08 16:11:43,978 - INFO - epoch 3, step 36550, training loss = 2.855639, validation loss = 3.994519
2018-12-08 16:12:02,915 - INFO - epoch 3, step 36600, training loss = 2.771285, validation loss = 3.559136
2018-12-08 16:12:21,772 - INFO - epoch 3, step 36650, training loss = 3.588153, validation loss = 3.690380
2018-12-08 16:12:40,672 - INFO - epoch 3, step 36700, training loss = 2.769866, validation loss = 3.735886
2018-12-08 16:12:59,373 - INFO - epoch 3, step 36750, training loss = 2.577982, validation loss = 3.672476
2018-12-08 16:13:17,125 - INFO - epoch 3, step 36800, training loss = 4.828182, validation loss = 3.690732
2018-12-08 16:13:34,907 - INFO - epoch 3, step 36850, training loss = 4.850713, validation loss = 3.922371
2018-12-08 16:13:52,483 - INFO - epoch 3, step 36900, training loss = 4.399601, validation loss = 3.885002
2018-12-08 16:14:10,104 - INFO - epoch 3, step 36950, training loss = 4.559090, validation loss = 3.622582
2018-12-08 16:14:28,092 - INFO - epoch 3, step 37000, training loss = 4.151633, validation loss = 4.201091
2018-12-08 16:14:45,972 - INFO - epoch 3, step 37050, training loss = 4.247288, validation loss = 4.160002
2018-12-08 16:15:03,734 - INFO - epoch 3, step 37100, training loss = 4.386117, validation loss = 3.548498
2018-12-08 16:15:20,803 - INFO - epoch 3, step 37150, training loss = 4.222310, validation loss = 3.841732
2018-12-08 16:15:38,128 - INFO - epoch 3, step 37200, training loss = 4.542765, validation loss = 3.736899
2018-12-08 16:15:55,878 - INFO - epoch 3, step 37250, training loss = 4.176356, validation loss = 3.817238
2018-12-08 16:16:13,455 - INFO - epoch 3, step 37300, training loss = 4.678510, validation loss = 3.800671
2018-12-08 16:16:30,215 - INFO - epoch 3, step 37350, training loss = 4.441592, validation loss = 3.653889
2018-12-08 16:16:47,535 - INFO - epoch 3, step 37400, training loss = 4.131881, validation loss = 3.829943
2018-12-08 16:17:05,119 - INFO - epoch 3, step 37450, training loss = 4.136580, validation loss = 3.780796
2018-12-08 16:17:22,490 - INFO - epoch 3, step 37500, training loss = 4.777786, validation loss = 3.956066
2018-12-08 16:17:40,008 - INFO - epoch 3, step 37550, training loss = 4.507733, validation loss = 3.813850
2018-12-08 16:17:57,727 - INFO - epoch 3, step 37600, training loss = 4.193783, validation loss = 3.554974
2018-12-08 16:18:15,436 - INFO - epoch 3, step 37650, training loss = 4.670546, validation loss = 3.537998
2018-12-08 16:18:33,598 - INFO - epoch 3, step 37700, training loss = 4.833887, validation loss = 3.654109
2018-12-08 16:18:51,840 - INFO - epoch 3, step 37750, training loss = 4.864204, validation loss = 3.922974
2018-12-08 16:19:09,110 - INFO - epoch 3, step 37800, training loss = 4.352315, validation loss = 4.072000
2018-12-08 16:19:27,537 - INFO - epoch 3, step 37850, training loss = 4.273745, validation loss = 3.632960
2018-12-08 16:19:46,287 - INFO - epoch 3, step 37900, training loss = 4.550800, validation loss = 3.684483
2018-12-08 16:20:03,388 - INFO - epoch 3, step 37950, training loss = 4.005634, validation loss = 3.667448
2018-12-08 16:20:20,428 - INFO - epoch 3, step 38000, training loss = 4.055559, validation loss = 3.417472
2018-12-08 16:20:38,387 - INFO - epoch 3, step 38050, training loss = 4.783244, validation loss = 3.713886
2018-12-08 16:20:55,819 - INFO - epoch 3, step 38100, training loss = 4.671795, validation loss = 3.648053
2018-12-08 16:21:12,837 - INFO - epoch 3, step 38150, training loss = 3.799200, validation loss = 3.738254
2018-12-08 16:21:30,751 - INFO - epoch 3, step 38200, training loss = 3.909844, validation loss = 3.812556
2018-12-08 16:21:49,427 - INFO - epoch 3, step 38250, training loss = 4.063031, validation loss = 4.317137
2018-12-08 16:22:11,269 - INFO - epoch 3, step 38300, training loss = 4.571712, validation loss = 3.693838
2018-12-08 16:22:36,931 - INFO - epoch 3, step 38350, training loss = 4.672336, validation loss = 4.012223
2018-12-08 16:23:04,413 - INFO - epoch 3, step 38400, training loss = 5.047888, validation loss = 4.043323
2018-12-08 16:23:23,686 - INFO - epoch 3, step 38450, training loss = 4.717114, validation loss = 3.701554
2018-12-08 16:23:48,316 - INFO - epoch 3, step 38500, training loss = 4.921744, validation loss = 4.228016
2018-12-08 16:24:13,222 - INFO - epoch 3, step 38550, training loss = 4.383403, validation loss = 3.792718
2018-12-08 16:24:32,169 - INFO - epoch 3, step 38600, training loss = 3.892525, validation loss = 3.897491
2018-12-08 16:24:52,190 - INFO - epoch 3, step 38650, training loss = 3.806305, validation loss = 3.996434
2018-12-08 16:25:12,283 - INFO - epoch 3, step 38700, training loss = 4.297593, validation loss = 3.917893
2018-12-08 16:25:37,561 - INFO - epoch 3, step 38750, training loss = 4.579519, validation loss = 3.884946
2018-12-08 16:26:04,759 - INFO - epoch 3, step 38800, training loss = 4.596945, validation loss = 3.308141
2018-12-08 16:26:31,718 - INFO - epoch 3, step 38850, training loss = 5.072371, validation loss = 3.093184
2018-12-08 16:26:58,530 - INFO - epoch 3, step 38900, training loss = 4.576636, validation loss = 3.677989
2018-12-08 16:27:25,381 - INFO - epoch 3, step 38950, training loss = 4.602454, validation loss = 4.007325
2018-12-08 16:27:48,164 - INFO - epoch 3, step 39000, training loss = 4.607986, validation loss = 3.940351
2018-12-08 16:28:14,003 - INFO - epoch 3, step 39050, training loss = 4.401364, validation loss = 3.905007
2018-12-08 16:28:40,162 - INFO - epoch 3, step 39100, training loss = 4.435783, validation loss = 3.723954
2018-12-08 16:29:01,254 - INFO - epoch 3, step 39150, training loss = 4.298849, validation loss = 2.975993
2018-12-08 16:29:21,961 - INFO - epoch 3, step 39200, training loss = 4.288603, validation loss = 3.289647
2018-12-08 16:29:48,398 - INFO - epoch 3, step 39250, training loss = 4.543356, validation loss = 3.218456
2018-12-08 16:30:14,470 - INFO - epoch 3, step 39300, training loss = 4.609757, validation loss = 3.420650
2018-12-08 16:30:36,674 - INFO - epoch 3, step 39350, training loss = 4.061068, validation loss = 3.506443
2018-12-08 16:30:56,223 - INFO - epoch 3, step 39400, training loss = 4.811311, validation loss = 3.685486
2018-12-08 16:31:23,819 - INFO - epoch 3, step 39450, training loss = 4.455239, validation loss = 3.774540
2018-12-08 16:31:46,440 - INFO - epoch 3, step 39500, training loss = 4.106718, validation loss = 3.480341
2018-12-08 16:32:08,489 - INFO - epoch 3, step 39550, training loss = 4.361771, validation loss = 3.371583
2018-12-08 16:32:34,703 - INFO - epoch 3, step 39600, training loss = 4.711603, validation loss = 3.376464
2018-12-08 16:33:01,050 - INFO - epoch 3, step 39650, training loss = 4.415443, validation loss = 3.975797
2018-12-08 16:33:28,453 - INFO - epoch 3, step 39700, training loss = 4.750477, validation loss = 4.242591
2018-12-08 16:33:52,665 - INFO - epoch 3, step 39750, training loss = 4.273494, validation loss = 4.269932
2018-12-08 16:34:12,072 - INFO - epoch 3, step 39800, training loss = 3.930174, validation loss = 4.184559
2018-12-08 16:34:32,494 - INFO - epoch 3, step 39850, training loss = 4.062881, validation loss = 3.573483
2018-12-08 16:34:56,076 - INFO - epoch 3, step 39900, training loss = 3.903018, validation loss = 3.835860
2018-12-08 16:35:22,493 - INFO - epoch 3, step 39950, training loss = 4.493997, validation loss = 3.674712
2018-12-08 16:35:45,652 - INFO - epoch 3, step 40000, training loss = 4.339798, validation loss = 3.800984
2018-12-08 16:36:05,368 - INFO - epoch 3, step 40050, training loss = 4.370984, validation loss = 4.007885
2018-12-08 16:36:25,729 - INFO - epoch 3, step 40100, training loss = 4.572617, validation loss = 3.754714
2018-12-08 16:36:44,480 - INFO - epoch 3, step 40150, training loss = 4.379969, validation loss = 3.964953
2018-12-08 16:37:03,906 - INFO - epoch 3, step 40200, training loss = 4.228528, validation loss = 3.761735
2018-12-08 16:37:23,448 - INFO - epoch 3, step 40250, training loss = 3.695338, validation loss = 4.111010
2018-12-08 16:37:44,203 - INFO - epoch 3, step 40300, training loss = 4.131649, validation loss = 4.023539
2018-12-08 16:38:03,621 - INFO - epoch 3, step 40350, training loss = 4.439814, validation loss = 3.476521
2018-12-08 16:38:22,953 - INFO - epoch 3, step 40400, training loss = 4.174610, validation loss = 3.948167
2018-12-08 16:38:47,009 - INFO - epoch 3, step 40450, training loss = 4.685181, validation loss = 3.588284
2018-12-08 16:39:05,720 - INFO - epoch 3, step 40500, training loss = 4.091604, validation loss = 3.561829
2018-12-08 16:39:24,722 - INFO - epoch 3, step 40550, training loss = 4.480970, validation loss = 3.721502
2018-12-08 16:39:48,096 - INFO - epoch 3, step 40600, training loss = 4.239753, validation loss = 3.945838
2018-12-08 16:40:13,821 - INFO - epoch 3, step 40650, training loss = 4.545581, validation loss = 3.720161
2018-12-08 16:40:39,827 - INFO - epoch 3, step 40700, training loss = 3.467265, validation loss = 3.953341
2018-12-08 16:41:00,752 - INFO - epoch 3, step 40750, training loss = 4.014286, validation loss = 4.023305
2018-12-08 16:41:20,829 - INFO - epoch 3, step 40800, training loss = 4.144494, validation loss = 3.848083
2018-12-08 16:41:41,473 - INFO - epoch 3, step 40850, training loss = 4.230136, validation loss = 3.605508
2018-12-08 16:42:00,633 - INFO - epoch 3, step 40900, training loss = 4.063157, validation loss = 3.606122
2018-12-08 16:42:19,867 - INFO - epoch 3, step 40950, training loss = 4.329162, validation loss = 4.014910
2018-12-08 16:42:39,962 - INFO - epoch 3, step 41000, training loss = 4.410995, validation loss = 3.911613
2018-12-08 16:43:00,685 - INFO - epoch 3, step 41050, training loss = 3.632694, validation loss = 4.011605
2018-12-08 16:43:20,635 - INFO - epoch 3, step 41100, training loss = 4.623438, validation loss = 3.868317
2018-12-08 16:43:40,181 - INFO - epoch 3, step 41150, training loss = 3.951048, validation loss = 3.938156
2018-12-08 16:43:59,866 - INFO - epoch 3, step 41200, training loss = 3.846064, validation loss = 3.877757
2018-12-08 16:44:19,930 - INFO - epoch 3, step 41250, training loss = 4.224705, validation loss = 3.775565
2018-12-08 16:44:39,237 - INFO - epoch 3, step 41300, training loss = 4.191011, validation loss = 3.846584
2018-12-08 16:44:58,511 - INFO - epoch 3, step 41350, training loss = 3.953599, validation loss = 3.804879
2018-12-08 16:45:21,768 - INFO - epoch 3, step 41400, training loss = 4.355994, validation loss = 4.089850
2018-12-08 16:45:49,192 - INFO - epoch 3, step 41450, training loss = 4.651493, validation loss = 3.855577
2018-12-08 16:46:14,177 - INFO - epoch 3, step 41500, training loss = 4.259727, validation loss = 3.998122
2018-12-08 16:46:34,674 - INFO - epoch 3, step 41550, training loss = 4.523464, validation loss = 4.244084
2018-12-08 16:47:00,764 - INFO - epoch 3, step 41600, training loss = 4.986344, validation loss = 3.090909
2018-12-08 16:47:25,929 - INFO - epoch 3, step 41650, training loss = 3.444344, validation loss = 3.573277
2018-12-08 16:47:46,263 - INFO - epoch 3, step 41700, training loss = 3.552670, validation loss = 3.344187
2018-12-08 16:48:09,556 - INFO - epoch 3, step 41750, training loss = 4.584286, validation loss = 3.902970
2018-12-08 16:48:30,724 - INFO - epoch 3, step 41800, training loss = 4.273659, validation loss = 3.621051
2018-12-08 16:48:50,571 - INFO - epoch 3, step 41850, training loss = 4.144363, validation loss = 3.738339
2018-12-08 16:49:10,560 - INFO - epoch 3, step 41900, training loss = 4.782002, validation loss = 3.818028
2018-12-08 16:49:37,030 - INFO - epoch 3, step 41950, training loss = 4.617729, validation loss = 3.904628
2018-12-08 16:50:02,926 - INFO - epoch 3, step 42000, training loss = 4.233946, validation loss = 3.840694
2018-12-08 16:50:22,429 - INFO - epoch 3, step 42050, training loss = 4.024096, validation loss = 3.557267
2018-12-08 16:50:42,848 - INFO - epoch 3, step 42100, training loss = 4.028290, validation loss = 3.631993
2018-12-08 16:51:06,478 - INFO - epoch 3, step 42150, training loss = 4.572655, validation loss = 3.795438
2018-12-08 16:51:31,916 - INFO - epoch 3, step 42200, training loss = 4.785348, validation loss = 3.989566
2018-12-08 16:51:51,996 - INFO - epoch 3, step 42250, training loss = 4.461150, validation loss = 3.629521
2018-12-08 16:52:11,375 - INFO - epoch 3, step 42300, training loss = 4.000726, validation loss = 3.690838
2018-12-08 16:52:30,816 - INFO - epoch 3, step 42350, training loss = 3.697738, validation loss = 3.725629
2018-12-08 16:52:51,156 - INFO - epoch 3, step 42400, training loss = 3.220601, validation loss = 3.845073
2018-12-08 16:53:16,239 - INFO - epoch 3, step 42450, training loss = 4.460449, validation loss = 3.386156
2018-12-08 16:53:42,745 - INFO - epoch 3, step 42500, training loss = 4.576962, validation loss = 3.901254
2018-12-08 16:54:07,633 - INFO - epoch 3, step 42550, training loss = 4.875248, validation loss = 4.015513
2018-12-08 16:54:26,856 - INFO - epoch 3, step 42600, training loss = 4.341021, validation loss = 3.421886
2018-12-08 16:54:46,623 - INFO - epoch 3, step 42650, training loss = 4.183064, validation loss = 3.986038
2018-12-08 16:55:07,179 - INFO - epoch 3, step 42700, training loss = 3.317885, validation loss = 3.882858
2018-12-08 16:55:28,007 - INFO - epoch 3, step 42750, training loss = 4.376502, validation loss = 3.511389
2018-12-08 16:55:56,811 - INFO - epoch 3, step 42800, training loss = 4.564055, validation loss = 3.733820
2018-12-08 16:56:21,410 - INFO - epoch 3, step 42850, training loss = 4.591425, validation loss = 3.579917
2018-12-08 16:56:39,940 - INFO - epoch 3, step 42900, training loss = 4.616381, validation loss = 3.806127
2018-12-08 16:56:59,056 - INFO - epoch 3, step 42950, training loss = 4.470008, validation loss = 3.964689
2018-12-08 16:57:19,375 - INFO - epoch 3, step 43000, training loss = 4.179951, validation loss = 4.301254
2018-12-08 16:57:43,740 - INFO - epoch 3, step 43050, training loss = 4.226836, validation loss = 3.320717
2018-12-08 16:58:08,619 - INFO - epoch 3, step 43100, training loss = 4.333446, validation loss = 3.826949
2018-12-08 16:58:28,661 - INFO - epoch 3, step 43150, training loss = 3.932812, validation loss = 3.828464
2018-12-08 16:58:49,129 - INFO - epoch 3, step 43200, training loss = 4.058970, validation loss = 3.806736
2018-12-08 16:59:08,977 - INFO - epoch 3, step 43250, training loss = 4.353687, validation loss = 4.147146
2018-12-08 16:59:36,320 - INFO - epoch 3, step 43300, training loss = 4.221572, validation loss = 3.656185
2018-12-08 16:59:57,807 - INFO - epoch 3, step 43350, training loss = 4.260202, validation loss = 3.775037
2018-12-08 17:00:18,514 - INFO - epoch 3, step 43400, training loss = 3.746583, validation loss = 4.020515
2018-12-08 17:00:39,538 - INFO - epoch 3, step 43450, training loss = 4.323321, validation loss = 3.599096
2018-12-08 17:00:59,738 - INFO - epoch 3, step 43500, training loss = 3.963367, validation loss = 3.553209
2018-12-08 17:01:23,285 - INFO - epoch 3, step 43550, training loss = 4.341980, validation loss = 3.818972
2018-12-08 17:01:44,440 - INFO - epoch 3, step 43600, training loss = 4.391241, validation loss = 4.047143
2018-12-08 17:02:05,942 - INFO - epoch 3, step 43650, training loss = 4.471714, validation loss = 3.780051
2018-12-08 17:02:28,899 - INFO - epoch 3, step 43700, training loss = 4.228360, validation loss = 4.240375
2018-12-08 17:02:48,574 - INFO - epoch 3, step 43750, training loss = 3.815321, validation loss = 3.506074
2018-12-08 17:03:11,794 - INFO - epoch 3, step 43800, training loss = 4.257552, validation loss = 4.150797
2018-12-08 17:03:33,450 - INFO - epoch 3, step 43850, training loss = 4.554374, validation loss = 3.960586
2018-12-08 17:03:53,365 - INFO - epoch 3, step 43900, training loss = 4.357991, validation loss = 3.487321
2018-12-08 17:04:13,470 - INFO - epoch 3, step 43950, training loss = 3.700238, validation loss = 3.685779
2018-12-08 17:04:34,344 - INFO - epoch 3, step 44000, training loss = 3.993137, validation loss = 3.963474
2018-12-08 17:04:54,031 - INFO - epoch 3, step 44050, training loss = 3.726892, validation loss = 3.523932
2018-12-08 17:05:14,434 - INFO - epoch 3, step 44100, training loss = 3.717407, validation loss = 3.858429
2018-12-08 17:05:35,255 - INFO - epoch 3, step 44150, training loss = 3.920145, validation loss = 4.045310
2018-12-08 17:05:55,055 - INFO - epoch 3, step 44200, training loss = 4.227784, validation loss = 3.342609
2018-12-08 17:06:14,985 - INFO - epoch 3, step 44250, training loss = 3.509449, validation loss = 3.492591
2018-12-08 17:06:35,875 - INFO - epoch 3, step 44300, training loss = 3.988698, validation loss = 3.720730
2018-12-08 17:06:56,357 - INFO - epoch 3, step 44350, training loss = 4.406388, validation loss = 3.935043
2018-12-08 17:07:15,742 - INFO - epoch 3, step 44400, training loss = 4.449416, validation loss = 3.911548
2018-12-08 17:07:34,626 - INFO - epoch 3, step 44450, training loss = 4.200662, validation loss = 4.035052
2018-12-08 17:07:55,625 - INFO - epoch 3, step 44500, training loss = 4.250046, validation loss = 3.943620
2018-12-08 17:08:18,742 - INFO - epoch 3, step 44550, training loss = 4.179376, validation loss = 3.326139
2018-12-08 17:08:39,502 - INFO - epoch 3, step 44600, training loss = 3.975304, validation loss = 3.868274
2018-12-08 17:09:03,162 - INFO - epoch 3, step 44650, training loss = 4.452608, validation loss = 3.794455
2018-12-08 17:09:29,725 - INFO - epoch 3, step 44700, training loss = 4.212965, validation loss = 4.052765
2018-12-08 17:09:52,014 - INFO - epoch 3, step 44750, training loss = 4.107860, validation loss = 3.820534
2018-12-08 17:10:13,968 - INFO - epoch 3, step 44800, training loss = 4.013388, validation loss = 3.941439
2018-12-08 17:10:35,545 - INFO - epoch 3, step 44850, training loss = 4.470010, validation loss = 3.598890
2018-12-08 17:10:54,281 - INFO - epoch 3, step 44900, training loss = 4.134900, validation loss = 3.250821
2018-12-08 17:11:14,441 - INFO - epoch 3, step 44950, training loss = 3.851378, validation loss = 3.485450
2018-12-08 17:11:37,508 - INFO - epoch 3, step 45000, training loss = 4.321622, validation loss = 3.799597
2018-12-08 17:12:01,743 - INFO - epoch 3, step 45050, training loss = 4.263314, validation loss = 3.606323
2018-12-08 17:12:25,099 - INFO - epoch 3, step 45100, training loss = 3.643529, validation loss = 3.713601
2018-12-08 17:12:45,106 - INFO - epoch 3, step 45150, training loss = 4.081138, validation loss = 4.166015
2018-12-08 17:13:09,560 - INFO - epoch 3, step 45200, training loss = 4.522516, validation loss = 3.442391
2018-12-08 17:13:30,909 - INFO - epoch 3, step 45250, training loss = 4.164059, validation loss = 3.343311
2018-12-08 17:13:53,201 - INFO - epoch 3, step 45300, training loss = 4.132645, validation loss = 3.428754
2018-12-08 17:14:19,479 - INFO - epoch 3, step 45350, training loss = 4.189069, validation loss = 3.638304
2018-12-08 17:14:45,349 - INFO - epoch 3, step 45400, training loss = 4.352485, validation loss = 3.801254
2018-12-08 17:15:11,492 - INFO - epoch 3, step 45450, training loss = 4.184499, validation loss = 3.954941
2018-12-08 17:15:31,573 - INFO - epoch 3, step 45500, training loss = 4.213416, validation loss = 3.739342
2018-12-08 17:15:55,139 - INFO - epoch 3, step 45550, training loss = 4.572443, validation loss = 3.328402
2018-12-08 17:16:14,221 - INFO - epoch 3, step 45600, training loss = 4.442327, validation loss = 3.278576
2018-12-08 17:16:33,210 - INFO - epoch 3, step 45650, training loss = 4.280024, validation loss = 3.330328
2018-12-08 17:16:52,467 - INFO - epoch 3, step 45700, training loss = 4.397812, validation loss = 3.713617
2018-12-08 17:17:11,443 - INFO - epoch 3, step 45750, training loss = 4.141419, validation loss = 3.812333
2018-12-08 17:17:30,309 - INFO - epoch 3, step 45800, training loss = 4.497304, validation loss = 4.162776
2018-12-08 17:17:55,412 - INFO - epoch 3, step 45850, training loss = 4.183616, validation loss = 4.132436
2018-12-08 17:18:22,319 - INFO - epoch 3, step 45900, training loss = 4.660312, validation loss = 3.764142
2018-12-08 17:18:49,907 - INFO - epoch 3, step 45950, training loss = 4.075521, validation loss = 3.246496
2018-12-08 17:19:17,359 - INFO - epoch 3, step 46000, training loss = 4.679203, validation loss = 3.447849
2018-12-08 17:19:39,176 - INFO - epoch 3, step 46050, training loss = 4.332158, validation loss = 3.758270
2018-12-08 17:19:59,239 - INFO - epoch 3, step 46100, training loss = 4.048953, validation loss = 3.689123
2018-12-08 17:20:19,839 - INFO - epoch 3, step 46150, training loss = 3.503372, validation loss = 4.050428
2018-12-08 17:20:39,126 - INFO - epoch 3, step 46200, training loss = 4.028334, validation loss = 4.356455
2018-12-08 17:20:59,257 - INFO - epoch 3, step 46250, training loss = 4.082775, validation loss = 4.112158
2018-12-08 17:21:20,287 - INFO - epoch 3, step 46300, training loss = 3.966726, validation loss = 3.743621
2018-12-08 17:21:39,894 - INFO - epoch 3, step 46350, training loss = 4.191755, validation loss = 3.510506
2018-12-08 17:21:58,845 - INFO - epoch 3, step 46400, training loss = 4.245381, validation loss = 3.463177
2018-12-08 17:22:17,415 - INFO - epoch 3, step 46450, training loss = 3.968230, validation loss = 4.060427
2018-12-08 17:22:40,806 - INFO - epoch 3, step 46500, training loss = 4.180948, validation loss = 3.685823
2018-12-08 17:23:03,343 - INFO - epoch 3, step 46550, training loss = 4.094998, validation loss = 4.179353
2018-12-08 17:23:24,525 - INFO - epoch 3, step 46600, training loss = 4.751300, validation loss = 4.468119
2018-12-08 17:23:51,212 - INFO - epoch 3, step 46650, training loss = 4.091212, validation loss = 3.858177
2018-12-08 17:24:10,159 - INFO - epoch 3, step 46700, training loss = 4.275024, validation loss = 3.774721
2018-12-08 17:24:30,672 - INFO - epoch 3, step 46750, training loss = 3.300968, validation loss = 4.001876
2018-12-08 17:24:51,055 - INFO - epoch 3, step 46800, training loss = 4.153086, validation loss = 3.901723
2018-12-08 17:25:10,395 - INFO - epoch 3, step 46850, training loss = 4.420541, validation loss = 4.079095
2018-12-08 17:25:29,693 - INFO - epoch 3, step 46900, training loss = 3.929804, validation loss = 3.613261
2018-12-08 17:25:55,026 - INFO - epoch 3, step 46950, training loss = 4.434638, validation loss = 3.668174
2018-12-08 17:26:22,702 - INFO - epoch 3, step 47000, training loss = 4.764093, validation loss = 3.727675
2018-12-08 17:26:47,763 - INFO - epoch 3, step 47050, training loss = 4.209395, validation loss = 3.907902
2018-12-08 17:27:10,014 - INFO - epoch 3, step 47100, training loss = 3.912037, validation loss = 3.847671
2018-12-08 17:27:31,702 - INFO - epoch 3, step 47150, training loss = 4.029249, validation loss = 3.860399
2018-12-08 17:27:52,048 - INFO - epoch 3, step 47200, training loss = 3.035645, validation loss = 3.829708
2018-12-08 17:28:07,840 - INFO - epoch 3, step 47250, training loss = 2.448311, validation loss = 3.875941
2018-12-08 17:28:26,373 - INFO - epoch 3, step 47300, training loss = 2.671793, validation loss = 3.687365
2018-12-08 17:28:45,617 - INFO - epoch 3, step 47350, training loss = 2.485463, validation loss = 3.799832
2018-12-08 17:29:01,667 - INFO - epoch 3, step 47400, training loss = 2.510398, validation loss = 3.926778
2018-12-08 17:29:18,910 - INFO - epoch 3, step 47450, training loss = 2.458607, validation loss = 3.941482
2018-12-08 17:29:37,653 - INFO - epoch 3, step 47500, training loss = 2.345441, validation loss = 3.631825
2018-12-08 17:29:56,169 - INFO - epoch 3, step 47550, training loss = 2.736856, validation loss = 4.108535
2018-12-08 17:30:13,913 - INFO - epoch 3, step 47600, training loss = 2.633207, validation loss = 3.992900
2018-12-08 17:30:30,855 - INFO - epoch 3, step 47650, training loss = 2.616058, validation loss = 3.583910
2018-12-08 17:30:46,570 - INFO - epoch 3, step 47700, training loss = 2.665013, validation loss = 3.998220
2018-12-08 17:31:03,010 - INFO - epoch 3, step 47750, training loss = 2.559883, validation loss = 3.930948
2018-12-08 17:31:20,683 - INFO - epoch 3, step 47800, training loss = 2.621217, validation loss = 4.001390
2018-12-08 17:31:40,144 - INFO - epoch 3, step 47850, training loss = 2.311524, validation loss = 3.787214
2018-12-08 17:32:02,131 - INFO - epoch 3, step 47900, training loss = 2.751968, validation loss = 4.477607
2018-12-08 17:32:24,205 - INFO - epoch 3, step 47950, training loss = 2.813874, validation loss = 3.942004
2018-12-08 17:32:44,775 - INFO - epoch 3, step 48000, training loss = 2.580386, validation loss = 3.709919
2018-12-08 17:33:02,148 - INFO - epoch 3, step 48050, training loss = 2.437638, validation loss = 3.980541
2018-12-08 17:33:18,625 - INFO - epoch 3, step 48100, training loss = 2.547021, validation loss = 3.687526
2018-12-08 17:33:36,298 - INFO - epoch 3, step 48150, training loss = 2.418888, validation loss = 3.641721
2018-12-08 17:33:56,916 - INFO - epoch 3, step 48200, training loss = 2.127096, validation loss = 3.975060
2018-12-08 17:34:17,783 - INFO - epoch 3, step 48250, training loss = 2.426816, validation loss = 4.198595
2018-12-08 17:34:37,454 - INFO - epoch 3, step 48300, training loss = 2.303558, validation loss = 3.837559
2018-12-08 17:34:59,069 - INFO - epoch 3, step 48350, training loss = 2.667444, validation loss = 3.350068
2018-12-08 17:35:21,272 - INFO - epoch 3, step 48400, training loss = 2.550462, validation loss = 3.159349
2018-12-08 17:35:41,751 - INFO - epoch 3, step 48450, training loss = 2.477983, validation loss = 3.458848
2018-12-08 17:35:59,309 - INFO - epoch 3, step 48500, training loss = 2.640216, validation loss = 3.421145
2018-12-08 17:36:14,998 - INFO - epoch 3, step 48550, training loss = 2.554120, validation loss = 3.833241
2018-12-08 17:36:31,767 - INFO - epoch 3, step 48600, training loss = 2.276615, validation loss = 3.780257
2018-12-08 17:36:49,914 - INFO - epoch 3, step 48650, training loss = 2.445669, validation loss = 3.213248
2018-12-08 17:37:10,234 - INFO - epoch 3, step 48700, training loss = 2.469598, validation loss = 3.408906
2018-12-08 17:37:30,446 - INFO - epoch 3, step 48750, training loss = 2.216448, validation loss = 3.629449
2018-12-08 17:37:51,414 - INFO - epoch 3, step 48800, training loss = 2.074416, validation loss = 3.464002
2018-12-08 17:38:12,468 - INFO - epoch 3, step 48850, training loss = 2.744500, validation loss = 3.533941
2018-12-08 17:38:31,766 - INFO - epoch 3, step 48900, training loss = 2.489904, validation loss = 3.418029
2018-12-08 17:38:50,392 - INFO - epoch 3, step 48950, training loss = 2.429466, validation loss = 3.449521
2018-12-08 17:39:07,952 - INFO - epoch 3, step 49000, training loss = 2.316503, validation loss = 3.653548
2018-12-08 17:39:24,114 - INFO - epoch 3, step 49050, training loss = 2.171005, validation loss = 3.721963
2018-12-08 17:39:43,266 - INFO - epoch 3, step 49100, training loss = 2.304902, validation loss = 3.992102
2018-12-08 17:40:01,689 - INFO - epoch 3, step 49150, training loss = 2.316009, validation loss = 3.338012
2018-12-08 17:40:19,718 - INFO - epoch 3, step 49200, training loss = 2.379117, validation loss = 3.393790
2018-12-08 17:40:39,993 - INFO - epoch 3, step 49250, training loss = 2.141716, validation loss = 3.647357
2018-12-08 17:40:58,595 - INFO - epoch 3, step 49300, training loss = 2.279721, validation loss = 3.772480
2018-12-08 17:41:15,530 - INFO - epoch 3, step 49350, training loss = 2.508971, validation loss = 4.028512
2018-12-08 17:41:32,224 - INFO - epoch 3, step 49400, training loss = 2.445261, validation loss = 3.457154
2018-12-08 17:41:47,560 - INFO - epoch 3, step 49450, training loss = 2.724962, validation loss = 3.941226
2018-12-08 17:42:04,547 - INFO - epoch 3, step 49500, training loss = 2.279719, validation loss = 4.112706
2018-12-08 17:42:19,915 - INFO - epoch 3, step 49550, training loss = 2.529956, validation loss = 3.321839
2018-12-08 17:42:36,784 - INFO - epoch 3, step 49600, training loss = 2.014536, validation loss = 3.750046
2018-12-08 17:42:56,260 - INFO - epoch 3, step 49650, training loss = 2.174575, validation loss = 3.727646
2018-12-08 17:43:18,331 - INFO - epoch 3, step 49700, training loss = 2.651196, validation loss = 3.639785
2018-12-08 17:43:39,856 - INFO - epoch 3, step 49750, training loss = 2.457453, validation loss = 3.407849
2018-12-08 17:44:00,170 - INFO - epoch 3, step 49800, training loss = 2.722461, validation loss = 4.064921
2018-12-08 17:44:16,394 - INFO - epoch 3, step 49850, training loss = 2.258294, validation loss = 3.984513
2018-12-08 17:44:34,117 - INFO - epoch 3, step 49900, training loss = 2.559617, validation loss = 3.377848
2018-12-08 17:44:53,481 - INFO - epoch 3, step 49950, training loss = 1.974027, validation loss = 3.158848
2018-12-08 17:45:13,994 - INFO - epoch 3, step 50000, training loss = 2.359022, validation loss = 3.458107
2018-12-08 17:45:34,924 - INFO - epoch 3, step 50050, training loss = 2.108910, validation loss = 4.101500
2018-12-08 17:45:54,684 - INFO - epoch 3, step 50100, training loss = 2.483564, validation loss = 4.181578
2018-12-08 17:46:11,787 - INFO - epoch 3, step 50150, training loss = 1.854113, validation loss = 2.958840
2018-12-08 17:46:32,566 - INFO - epoch 3, step 50200, training loss = 2.290710, validation loss = 3.502959
2018-12-08 17:46:53,294 - INFO - epoch 3, step 50250, training loss = 2.802421, validation loss = 3.694969
2018-12-08 17:47:14,535 - INFO - epoch 3, step 50300, training loss = 2.329044, validation loss = 3.943241
2018-12-08 17:47:35,991 - INFO - epoch 3, step 50350, training loss = 2.356255, validation loss = 3.920897
2018-12-08 17:47:57,128 - INFO - epoch 3, step 50400, training loss = 2.296934, validation loss = 3.076084
2018-12-08 17:48:15,609 - INFO - epoch 3, step 50450, training loss = 2.302823, validation loss = 3.486041
2018-12-08 17:48:32,485 - INFO - epoch 3, step 50500, training loss = 2.674245, validation loss = 3.747034
2018-12-08 17:48:48,326 - INFO - epoch 3, step 50550, training loss = 2.661136, validation loss = 3.837229
2018-12-08 17:49:08,739 - INFO - epoch 3, step 50600, training loss = 2.370757, validation loss = 4.169169
2018-12-08 17:49:29,174 - INFO - epoch 3, step 50650, training loss = 2.265490, validation loss = 3.438015
2018-12-08 17:49:49,757 - INFO - epoch 3, step 50700, training loss = 2.403334, validation loss = 3.379175
2018-12-08 17:50:07,503 - INFO - epoch 3, step 50750, training loss = 2.131547, validation loss = 3.361994
2018-12-08 17:50:24,274 - INFO - epoch 3, step 50800, training loss = 2.430702, validation loss = 3.921701
2018-12-08 17:50:41,568 - INFO - epoch 3, step 50850, training loss = 1.872404, validation loss = 3.649948
2018-12-08 17:51:00,038 - INFO - epoch 3, step 50900, training loss = 2.097375, validation loss = 3.604495
2018-12-08 17:51:17,552 - INFO - epoch 3, step 50950, training loss = 2.355850, validation loss = 3.815261
2018-12-08 17:51:34,370 - INFO - epoch 3, step 51000, training loss = 2.653431, validation loss = 3.756236
2018-12-08 17:51:51,482 - INFO - epoch 3, step 51050, training loss = 2.456282, validation loss = 3.761263
2018-12-08 17:52:11,220 - INFO - epoch 3, step 51100, training loss = 2.352301, validation loss = 3.739582
2018-12-08 17:52:30,539 - INFO - epoch 3, step 51150, training loss = 2.363015, validation loss = 3.740956
2018-12-08 17:52:49,098 - INFO - epoch 3, step 51200, training loss = 2.097533, validation loss = 3.560778
2018-12-08 17:53:06,445 - INFO - epoch 3, step 51250, training loss = 2.149553, validation loss = 4.056150
2018-12-08 17:53:23,154 - INFO - epoch 3, step 51300, training loss = 2.369582, validation loss = 4.146597
2018-12-08 17:53:38,436 - INFO - epoch 3, step 51350, training loss = 2.412032, validation loss = 3.754045
2018-12-08 17:53:53,874 - INFO - epoch 3, step 51400, training loss = 2.435443, validation loss = 3.423037
2018-12-08 17:54:12,084 - INFO - epoch 3, step 51450, training loss = 2.100072, validation loss = 3.518665
2018-12-08 17:54:32,248 - INFO - epoch 3, step 51500, training loss = 2.265095, validation loss = 3.520145
2018-12-08 17:54:52,354 - INFO - epoch 3, step 51550, training loss = 2.034207, validation loss = 3.858325
2018-12-08 17:55:11,368 - INFO - epoch 3, step 51600, training loss = 2.380485, validation loss = 3.770471
2018-12-08 17:55:30,539 - INFO - epoch 3, step 51650, training loss = 2.222142, validation loss = 3.731595
2018-12-08 17:55:49,152 - INFO - epoch 3, step 51700, training loss = 2.136010, validation loss = 3.356393
2018-12-08 17:56:09,789 - INFO - epoch 3, step 51750, training loss = 2.243342, validation loss = 3.549432
2018-12-08 17:56:31,333 - INFO - epoch 3, step 51800, training loss = 2.218308, validation loss = 3.733994
2018-12-08 17:56:52,147 - INFO - epoch 3, step 51850, training loss = 2.464276, validation loss = 4.206113
2018-12-08 17:57:07,627 - INFO - epoch 3, step 51900, training loss = 2.149673, validation loss = 3.595642
2018-12-08 17:57:23,747 - INFO - epoch 3, step 51950, training loss = 2.098769, validation loss = 3.379978
2018-12-08 17:57:40,835 - INFO - epoch 3, step 52000, training loss = 2.536177, validation loss = 3.680181
2018-12-08 17:58:00,970 - INFO - epoch 3, step 52050, training loss = 2.420324, validation loss = 3.893628
2018-12-08 17:58:21,698 - INFO - epoch 3, step 52100, training loss = 2.428356, validation loss = 4.296232
2018-12-08 17:58:41,586 - INFO - epoch 3, step 52150, training loss = 1.964474, validation loss = 3.567912
2018-12-08 17:58:57,704 - INFO - epoch 3, step 52200, training loss = 2.409151, validation loss = 3.493933
2018-12-08 17:59:13,668 - INFO - epoch 3, step 52250, training loss = 2.711298, validation loss = 3.876797
2018-12-08 17:59:30,169 - INFO - epoch 3, step 52300, training loss = 2.246542, validation loss = 4.174733
2018-12-08 17:59:51,856 - INFO - epoch 3, step 52350, training loss = 2.231123, validation loss = 3.943959
2018-12-08 18:00:10,544 - INFO - epoch 3, step 52400, training loss = 2.543321, validation loss = 3.482216
2018-12-08 18:00:26,378 - INFO - epoch 3, step 52450, training loss = 2.579331, validation loss = 3.519659
2018-12-08 18:00:42,505 - INFO - epoch 3, step 52500, training loss = 2.395505, validation loss = 3.955598
2018-12-08 18:01:01,131 - INFO - epoch 3, step 52550, training loss = 2.334653, validation loss = 3.200574
2018-12-08 18:01:20,603 - INFO - epoch 3, step 52600, training loss = 2.498013, validation loss = 4.403775
2018-12-08 18:01:37,447 - INFO - epoch 3, step 52650, training loss = 2.329751, validation loss = 3.739368
2018-12-08 18:01:56,948 - INFO - epoch 3, step 52700, training loss = 2.269385, validation loss = 3.209192
2018-12-08 18:02:17,808 - INFO - epoch 3, step 52750, training loss = 2.145952, validation loss = 3.661238
2018-12-08 18:02:38,610 - INFO - epoch 3, step 52800, training loss = 2.339581, validation loss = 3.874443
2018-12-08 18:03:00,465 - INFO - epoch 3, step 52850, training loss = 2.220625, validation loss = 4.110091
2018-12-08 18:03:18,459 - INFO - epoch 3, step 52900, training loss = 2.287101, validation loss = 3.427211
2018-12-08 18:03:33,977 - INFO - epoch 3, step 52950, training loss = 2.302864, validation loss = 3.614604
2018-12-08 18:03:49,762 - INFO - epoch 3, step 53000, training loss = 2.349138, validation loss = 3.926095
2018-12-08 18:04:06,911 - INFO - epoch 3, step 53050, training loss = 2.125382, validation loss = 3.827426
2018-12-08 18:04:25,051 - INFO - epoch 3, step 53100, training loss = 2.059115, validation loss = 4.395549
2018-12-08 18:04:43,978 - INFO - epoch 3, step 53150, training loss = 2.225412, validation loss = 3.355479
2018-12-08 18:05:00,264 - INFO - epoch 3, step 53200, training loss = 2.186796, validation loss = 3.585417
2018-12-08 18:05:16,757 - INFO - epoch 3, step 53250, training loss = 2.575213, validation loss = 3.266521
2018-12-08 18:05:36,018 - INFO - epoch 3, step 53300, training loss = 2.240114, validation loss = 3.810680
2018-12-08 18:05:56,203 - INFO - epoch 3, step 53350, training loss = 2.163932, validation loss = 3.852474
2018-12-08 18:06:17,465 - INFO - epoch 3, step 53400, training loss = 2.231362, validation loss = 4.070947
2018-12-08 18:06:39,349 - INFO - epoch 3, step 53450, training loss = 2.648835, validation loss = 3.286505
2018-12-08 18:06:59,366 - INFO - epoch 3, step 53500, training loss = 2.254709, validation loss = 3.634678
2018-12-08 18:07:16,660 - INFO - epoch 3, step 53550, training loss = 2.556734, validation loss = 3.628853
2018-12-08 18:07:32,536 - INFO - epoch 3, step 53600, training loss = 2.387268, validation loss = 3.874443
2018-12-08 18:07:50,901 - INFO - epoch 3, step 53650, training loss = 2.445034, validation loss = 4.342025
2018-12-08 18:08:09,911 - INFO - epoch 3, step 53700, training loss = 2.401588, validation loss = 3.696935
2018-12-08 18:08:30,382 - INFO - epoch 3, step 53750, training loss = 2.106578, validation loss = 3.513862
2018-12-08 18:08:49,139 - INFO - epoch 3, step 53800, training loss = 2.216181, validation loss = 3.527364
2018-12-08 18:09:05,733 - INFO - epoch 3, step 53850, training loss = 2.410476, validation loss = 3.686184
2018-12-08 18:09:21,173 - INFO - epoch 3, step 53900, training loss = 2.349773, validation loss = 4.058102
2018-12-08 18:09:37,282 - INFO - epoch 3, step 53950, training loss = 1.794545, validation loss = 3.500864
2018-12-08 18:09:55,079 - INFO - epoch 3, step 54000, training loss = 1.985588, validation loss = 3.332680
2018-12-08 18:10:17,566 - INFO - epoch 3, step 54050, training loss = 2.386352, validation loss = 3.943325
2018-12-08 18:10:35,636 - INFO - epoch 3, step 54100, training loss = 2.266773, validation loss = 3.815704
2018-12-08 18:10:51,245 - INFO - epoch 3, step 54150, training loss = 2.370215, validation loss = 4.004800
2018-12-08 18:11:07,214 - INFO - epoch 3, step 54200, training loss = 2.287438, validation loss = 3.623192
2018-12-08 18:11:25,322 - INFO - epoch 3, step 54250, training loss = 2.416845, validation loss = 3.682855
2018-12-08 18:11:45,658 - INFO - epoch 3, step 54300, training loss = 2.068607, validation loss = 3.445767
2018-12-08 18:12:02,285 - INFO - epoch 3, step 54350, training loss = 2.188910, validation loss = 3.285180
2018-12-08 18:12:18,592 - INFO - epoch 3, step 54400, training loss = 2.716644, validation loss = 3.318007
2018-12-08 18:12:35,539 - INFO - epoch 3, step 54450, training loss = 2.452507, validation loss = 3.339586
2018-12-08 18:12:57,016 - INFO - epoch 3, step 54500, training loss = 1.854330, validation loss = 3.766083
2018-12-08 18:13:15,611 - INFO - epoch 3, step 54550, training loss = 2.376023, validation loss = 3.565835
2018-12-08 18:13:33,384 - INFO - epoch 3, step 54600, training loss = 2.237265, validation loss = 3.343526
2018-12-08 18:13:52,416 - INFO - epoch 3, step 54650, training loss = 2.451929, validation loss = 3.445582
2018-12-08 18:14:12,361 - INFO - epoch 3, step 54700, training loss = 2.598869, validation loss = 3.422292
2018-12-08 18:14:31,936 - INFO - epoch 3, step 54750, training loss = 2.218434, validation loss = 3.826124
2018-12-08 18:14:47,873 - INFO - epoch 3, step 54800, training loss = 2.184033, validation loss = 3.343844
2018-12-08 18:15:07,638 - INFO - epoch 3, step 54850, training loss = 2.425682, validation loss = 3.421843
2018-12-08 18:15:29,890 - INFO - epoch 3, step 54900, training loss = 1.988448, validation loss = 3.132890
2018-12-08 18:15:50,912 - INFO - epoch 3, step 54950, training loss = 2.042168, validation loss = 3.604105
2018-12-08 18:16:11,260 - INFO - epoch 3, step 55000, training loss = 2.013981, validation loss = 4.120276
2018-12-08 18:16:32,148 - INFO - epoch 3, step 55050, training loss = 2.244329, validation loss = 3.921651
2018-12-08 18:16:52,077 - INFO - epoch 3, step 55100, training loss = 2.150694, validation loss = 3.837049
2018-12-08 18:17:11,473 - INFO - epoch 3, step 55150, training loss = 2.364583, validation loss = 4.147836
2018-12-08 18:17:29,008 - INFO - epoch 3, step 55200, training loss = 2.186991, validation loss = 3.543386
2018-12-08 18:17:49,330 - INFO - epoch 3, step 55250, training loss = 2.241002, validation loss = 3.345757
2018-12-08 18:18:10,816 - INFO - epoch 3, step 55300, training loss = 2.355760, validation loss = 3.235084
2018-12-08 18:18:33,048 - INFO - epoch 3, step 55350, training loss = 2.210920, validation loss = 3.324702
2018-12-08 18:18:52,030 - INFO - epoch 3, step 55400, training loss = 2.504858, validation loss = 3.307679
2018-12-08 18:19:07,612 - INFO - epoch 3, step 55450, training loss = 2.208484, validation loss = 3.511904
2018-12-08 18:19:26,622 - INFO - epoch 3, step 55500, training loss = 2.290149, validation loss = 3.386427
2018-12-08 18:19:45,254 - INFO - epoch 3, step 55550, training loss = 2.569304, validation loss = 3.498957
2018-12-08 18:20:02,301 - INFO - epoch 3, step 55600, training loss = 2.451436, validation loss = 3.789511
2018-12-08 18:20:23,855 - INFO - epoch 3, step 55650, training loss = 2.132474, validation loss = 3.083142
2018-12-08 18:20:44,697 - INFO - epoch 3, step 55700, training loss = 2.166474, validation loss = 3.834396
2018-12-08 18:21:05,017 - INFO - epoch 3, step 55750, training loss = 2.307111, validation loss = 3.474150
2018-12-08 18:21:23,083 - INFO - epoch 3, step 55800, training loss = 2.189226, validation loss = 3.518955
2018-12-08 18:21:42,289 - INFO - epoch 3, step 55850, training loss = 2.418349, validation loss = 3.237625
2018-12-08 18:22:03,776 - INFO - epoch 3, step 55900, training loss = 2.002336, validation loss = 3.518418
2018-12-08 18:22:23,896 - INFO - epoch 3, step 55950, training loss = 2.196049, validation loss = 3.623644
2018-12-08 18:22:43,806 - INFO - epoch 3, step 56000, training loss = 2.209308, validation loss = 3.447484
2018-12-08 18:23:02,938 - INFO - epoch 3, step 56050, training loss = 2.305356, validation loss = 3.472867
2018-12-08 18:23:20,835 - INFO - epoch 3, step 56100, training loss = 2.232155, validation loss = 3.440567
2018-12-08 18:23:42,279 - INFO - epoch 3, step 56150, training loss = 2.948110, validation loss = 3.575546
2018-12-08 18:24:02,724 - INFO - epoch 3, step 56200, training loss = 2.398475, validation loss = 3.104658
2018-12-08 18:24:18,316 - INFO - epoch 3, step 56250, training loss = 2.294428, validation loss = 3.575439
2018-12-08 18:24:33,889 - INFO - epoch 3, step 56300, training loss = 2.168487, validation loss = 3.350354
2018-12-08 18:24:50,776 - INFO - epoch 3, step 56350, training loss = 2.283312, validation loss = 3.624655
2018-12-08 18:25:11,256 - INFO - epoch 3, step 56400, training loss = 2.679728, validation loss = 3.255876
2018-12-08 18:25:32,072 - INFO - epoch 3, step 56450, training loss = 2.481880, validation loss = 3.310456
2018-12-08 18:25:53,842 - INFO - epoch 3, step 56500, training loss = 2.140451, validation loss = 3.354038
2018-12-08 18:26:15,098 - INFO - epoch 3, step 56550, training loss = 2.663734, validation loss = 3.255717
2018-12-08 18:26:32,468 - INFO - epoch 3, step 56600, training loss = 2.289126, validation loss = 3.747686
2018-12-08 18:26:49,825 - INFO - epoch 3, step 56650, training loss = 2.431893, validation loss = 3.879546
2018-12-08 18:27:06,696 - INFO - epoch 3, step 56700, training loss = 2.587300, validation loss = 3.686752
2018-12-08 18:27:27,564 - INFO - epoch 3, step 56750, training loss = 2.378092, validation loss = 3.484139
2018-12-08 18:27:46,514 - INFO - epoch 3, step 56800, training loss = 2.237394, validation loss = 3.510066
2018-12-08 18:28:04,795 - INFO - epoch 3, step 56850, training loss = 2.305857, validation loss = 3.265015
2018-12-08 18:28:21,063 - INFO - epoch 3, step 56900, training loss = 2.055107, validation loss = 4.028146
2018-12-08 18:28:38,014 - INFO - epoch 3, step 56950, training loss = 2.264755, validation loss = 4.014720
2018-12-08 18:28:56,129 - INFO - epoch 3, step 57000, training loss = 2.083112, validation loss = 3.508247
2018-12-08 18:29:17,497 - INFO - epoch 3, step 57050, training loss = 1.821234, validation loss = 3.795245
2018-12-08 18:29:37,538 - INFO - epoch 3, step 57100, training loss = 2.334379, validation loss = 3.698360
2018-12-08 18:29:56,759 - INFO - epoch 3, step 57150, training loss = 2.171284, validation loss = 3.860248
2018-12-08 18:30:17,668 - INFO - epoch 3, step 57200, training loss = 2.180474, validation loss = 4.238101
2018-12-08 18:30:38,896 - INFO - epoch 3, step 57250, training loss = 2.048629, validation loss = 3.647557
2018-12-08 18:30:58,928 - INFO - epoch 3, step 57300, training loss = 2.130733, validation loss = 3.800614
2018-12-08 18:31:16,779 - INFO - epoch 3, step 57350, training loss = 1.959057, validation loss = 3.875283
2018-12-08 18:31:33,609 - INFO - epoch 3, step 57400, training loss = 2.201986, validation loss = 3.851748
2018-12-08 18:31:49,469 - INFO - epoch 3, step 57450, training loss = 2.150640, validation loss = 4.126603
2018-12-08 18:32:05,286 - INFO - epoch 3, step 57500, training loss = 2.019915, validation loss = 4.911272
2018-12-08 18:32:21,456 - INFO - epoch 3, step 57550, training loss = 2.314076, validation loss = 5.323348
2018-12-08 18:32:37,587 - INFO - epoch 3, step 57600, training loss = 2.137053, validation loss = 5.114061
2018-12-08 18:32:53,489 - INFO - epoch 3, step 57650, training loss = 2.259105, validation loss = 5.238489
2018-12-08 18:33:14,151 - INFO - epoch 3, step 57700, training loss = 2.770824, validation loss = 5.236280
2018-12-08 18:33:33,430 - INFO - epoch 3, step 57750, training loss = 2.538297, validation loss = 5.262088
2018-12-08 18:33:52,372 - INFO - epoch 3, step 57800, training loss = 2.093634, validation loss = 5.545051
2018-12-08 18:34:11,718 - INFO - epoch 3, step 57850, training loss = 2.536667, validation loss = 5.061087
2018-12-08 18:34:32,607 - INFO - epoch 3, step 57900, training loss = 2.267953, validation loss = 5.484327
2018-12-08 18:34:53,269 - INFO - epoch 3, step 57950, training loss = 1.997186, validation loss = 5.631749
2018-12-08 18:35:13,925 - INFO - epoch 3, step 58000, training loss = 2.186535, validation loss = 5.056734
2018-12-08 18:35:34,593 - INFO - epoch 3, step 58050, training loss = 2.067019, validation loss = 5.073906
2018-12-08 18:35:53,929 - INFO - epoch 3, step 58100, training loss = 1.958226, validation loss = 5.124929
2018-12-08 18:36:11,113 - INFO - epoch 3, step 58150, training loss = 2.294387, validation loss = 4.956506
2018-12-08 18:36:26,319 - INFO - epoch 3, step 58200, training loss = 2.481911, validation loss = 5.041250
2018-12-08 18:36:45,574 - INFO - epoch 3, step 58250, training loss = 2.148712, validation loss = 5.423088
2018-12-08 18:37:06,134 - INFO - epoch 3, step 58300, training loss = 1.769086, validation loss = 5.212579
2018-12-08 18:37:26,835 - INFO - epoch 3, step 58350, training loss = 2.258799, validation loss = 5.356300
2018-12-08 18:37:47,079 - INFO - epoch 3, step 58400, training loss = 2.532204, validation loss = 4.703897
2018-12-08 18:38:05,227 - INFO - epoch 3, step 58450, training loss = 2.079489, validation loss = 4.465419
2018-12-08 18:38:23,788 - INFO - epoch 3, step 58500, training loss = 2.534963, validation loss = 4.541334
2018-12-08 18:38:42,142 - INFO - epoch 3, step 58550, training loss = 2.103277, validation loss = 5.016202
2018-12-08 18:39:02,628 - INFO - epoch 3, step 58600, training loss = 2.249559, validation loss = 5.500988
2018-12-08 18:39:20,403 - INFO - epoch 3, step 58650, training loss = 2.474966, validation loss = 4.746469
2018-12-08 18:39:36,571 - INFO - epoch 3, step 58700, training loss = 2.499902, validation loss = 4.352323
2018-12-08 18:39:56,891 - INFO - epoch 3, step 58750, training loss = 1.727746, validation loss = 5.222357
2018-12-08 18:40:18,056 - INFO - epoch 3, step 58800, training loss = 2.080707, validation loss = 5.499777
2018-12-08 18:40:37,880 - INFO - epoch 3, step 58850, training loss = 2.056816, validation loss = 5.123586
2018-12-08 18:40:58,631 - INFO - epoch 3, step 58900, training loss = 2.326516, validation loss = 4.866737
2018-12-08 18:41:17,500 - INFO - epoch 3, step 58950, training loss = 2.204051, validation loss = 5.519035
2018-12-08 18:41:33,989 - INFO - epoch 3, step 59000, training loss = 2.314902, validation loss = 4.870356
2018-12-08 18:41:53,783 - INFO - epoch 3, step 59050, training loss = 2.357387, validation loss = 5.420352
2018-12-08 18:42:12,697 - INFO - epoch 3, step 59100, training loss = 2.062647, validation loss = 4.818178
2018-12-08 18:42:30,259 - INFO - epoch 3, step 59150, training loss = 1.788623, validation loss = 5.241133
2018-12-08 18:42:48,886 - INFO - epoch 3, step 59200, training loss = 1.881757, validation loss = 5.166772
2018-12-08 18:43:09,431 - INFO - epoch 3, step 59250, training loss = 1.680276, validation loss = 4.762377
2018-12-08 18:43:30,643 - INFO - epoch 3, step 59300, training loss = 2.050771, validation loss = 4.998644
2018-12-08 18:43:52,460 - INFO - epoch 3, step 59350, training loss = 2.037286, validation loss = 5.413413
2018-12-08 18:44:09,501 - INFO - epoch 3, step 59400, training loss = 2.292333, validation loss = 4.859435
2018-12-08 18:44:21,339 - INFO - Model saved in dir ./models
2018-12-08 18:44:39,075 - INFO - epoch 4, step 50, training loss = 3.091027, validation loss = 4.632193
2018-12-08 18:44:57,341 - INFO - epoch 4, step 100, training loss = 2.454113, validation loss = 5.056696
2018-12-08 18:45:15,619 - INFO - epoch 4, step 150, training loss = 2.884891, validation loss = 4.992747
2018-12-08 18:45:35,848 - INFO - epoch 4, step 200, training loss = 2.578487, validation loss = 4.623595
2018-12-08 18:45:55,939 - INFO - epoch 4, step 250, training loss = 2.563015, validation loss = 5.054179
2018-12-08 18:46:16,036 - INFO - epoch 4, step 300, training loss = 2.798210, validation loss = 4.692170
2018-12-08 18:46:34,933 - INFO - epoch 4, step 350, training loss = 2.851006, validation loss = 4.921199
2018-12-08 18:46:54,146 - INFO - epoch 4, step 400, training loss = 2.526554, validation loss = 4.949211
2018-12-08 18:47:13,685 - INFO - epoch 4, step 450, training loss = 2.967116, validation loss = 4.886434
2018-12-08 18:47:34,048 - INFO - epoch 4, step 500, training loss = 3.059144, validation loss = 4.935702
2018-12-08 18:47:53,822 - INFO - epoch 4, step 550, training loss = 2.842999, validation loss = 4.381730
2018-12-08 18:48:13,452 - INFO - epoch 4, step 600, training loss = 2.658304, validation loss = 4.575629
2018-12-08 18:48:33,384 - INFO - epoch 4, step 650, training loss = 2.783289, validation loss = 5.353797
2018-12-08 18:48:52,994 - INFO - epoch 4, step 700, training loss = 2.679929, validation loss = 5.116970
2018-12-08 18:49:12,897 - INFO - epoch 4, step 750, training loss = 2.910256, validation loss = 4.724343
2018-12-08 18:49:33,700 - INFO - epoch 4, step 800, training loss = 3.177544, validation loss = 4.602614
2018-12-08 18:49:55,146 - INFO - epoch 4, step 850, training loss = 2.831488, validation loss = 4.568429
2018-12-08 18:50:15,841 - INFO - epoch 4, step 900, training loss = 3.298331, validation loss = 5.082363
2018-12-08 18:50:37,435 - INFO - epoch 4, step 950, training loss = 2.437499, validation loss = 4.982752
2018-12-08 18:50:58,554 - INFO - epoch 4, step 1000, training loss = 2.993414, validation loss = 5.159513
2018-12-08 18:51:18,865 - INFO - epoch 4, step 1050, training loss = 2.650601, validation loss = 5.402084
2018-12-08 18:51:38,965 - INFO - epoch 4, step 1100, training loss = 2.626036, validation loss = 5.187585
2018-12-08 18:51:59,362 - INFO - epoch 4, step 1150, training loss = 2.612529, validation loss = 5.292382
2018-12-08 18:52:19,422 - INFO - epoch 4, step 1200, training loss = 2.936136, validation loss = 4.873693
2018-12-08 18:52:40,027 - INFO - epoch 4, step 1250, training loss = 2.537000, validation loss = 4.752029
2018-12-08 18:53:00,051 - INFO - epoch 4, step 1300, training loss = 3.086305, validation loss = 4.785538
2018-12-08 18:53:18,232 - INFO - epoch 4, step 1350, training loss = 2.887086, validation loss = 5.065942
2018-12-08 18:53:36,325 - INFO - epoch 4, step 1400, training loss = 2.487964, validation loss = 5.188777
2018-12-08 18:53:55,243 - INFO - epoch 4, step 1450, training loss = 2.659625, validation loss = 5.447732
2018-12-08 18:54:16,032 - INFO - epoch 4, step 1500, training loss = 2.337205, validation loss = 4.759133
2018-12-08 18:54:35,066 - INFO - epoch 4, step 1550, training loss = 2.847348, validation loss = 5.024454
2018-12-08 18:54:53,775 - INFO - epoch 4, step 1600, training loss = 2.944918, validation loss = 5.238531
2018-12-08 18:55:12,111 - INFO - epoch 4, step 1650, training loss = 2.928584, validation loss = 4.552253
2018-12-08 18:55:32,689 - INFO - epoch 4, step 1700, training loss = 2.788445, validation loss = 4.762628
2018-12-08 18:55:49,937 - INFO - epoch 4, step 1750, training loss = 2.837852, validation loss = 4.890749
2018-12-08 18:56:06,561 - INFO - epoch 4, step 1800, training loss = 2.732637, validation loss = 5.373738
2018-12-08 18:56:23,618 - INFO - epoch 4, step 1850, training loss = 2.725409, validation loss = 5.245249
2018-12-08 18:56:44,652 - INFO - epoch 4, step 1900, training loss = 2.907391, validation loss = 5.188537
2018-12-08 18:57:06,072 - INFO - epoch 4, step 1950, training loss = 3.104908, validation loss = 5.111178
2018-12-08 18:57:22,630 - INFO - epoch 4, step 2000, training loss = 2.704472, validation loss = 5.078847
2018-12-08 18:57:38,899 - INFO - epoch 4, step 2050, training loss = 2.491529, validation loss = 4.948252
2018-12-08 18:57:55,788 - INFO - epoch 4, step 2100, training loss = 2.859306, validation loss = 4.630241
2018-12-08 18:58:12,455 - INFO - epoch 4, step 2150, training loss = 1.994801, validation loss = 4.711282
2018-12-08 18:58:29,579 - INFO - epoch 4, step 2200, training loss = 2.922515, validation loss = 4.969079
2018-12-08 18:58:47,506 - INFO - epoch 4, step 2250, training loss = 2.611353, validation loss = 4.638160
2018-12-08 18:59:06,362 - INFO - epoch 4, step 2300, training loss = 2.569669, validation loss = 4.967842
2018-12-08 18:59:26,295 - INFO - epoch 4, step 2350, training loss = 2.717564, validation loss = 4.614862
2018-12-08 18:59:46,324 - INFO - epoch 4, step 2400, training loss = 2.656228, validation loss = 5.305222
2018-12-08 19:00:05,528 - INFO - epoch 4, step 2450, training loss = 2.539643, validation loss = 5.031833
2018-12-08 19:00:23,499 - INFO - epoch 4, step 2500, training loss = 2.947322, validation loss = 5.189446
2018-12-08 19:00:40,934 - INFO - epoch 4, step 2550, training loss = 2.506145, validation loss = 5.162273
2018-12-08 19:00:58,809 - INFO - epoch 4, step 2600, training loss = 2.457545, validation loss = 4.913481
2018-12-08 19:01:16,975 - INFO - epoch 4, step 2650, training loss = 2.534169, validation loss = 5.004679
2018-12-08 19:01:37,762 - INFO - epoch 4, step 2700, training loss = 3.108815, validation loss = 5.151173
2018-12-08 19:01:58,547 - INFO - epoch 4, step 2750, training loss = 2.601210, validation loss = 4.853370
2018-12-08 19:02:19,276 - INFO - epoch 4, step 2800, training loss = 3.018187, validation loss = 4.631275
2018-12-08 19:02:37,764 - INFO - epoch 4, step 2850, training loss = 2.841897, validation loss = 4.913024
2018-12-08 19:02:55,676 - INFO - epoch 4, step 2900, training loss = 2.575417, validation loss = 4.769216
2018-12-08 19:03:14,537 - INFO - epoch 4, step 2950, training loss = 2.675307, validation loss = 4.673378
2018-12-08 19:03:35,923 - INFO - epoch 4, step 3000, training loss = 2.581223, validation loss = 4.998039
2018-12-08 19:03:56,713 - INFO - epoch 4, step 3050, training loss = 2.859276, validation loss = 4.797532
2018-12-08 19:04:17,584 - INFO - epoch 4, step 3100, training loss = 2.762079, validation loss = 5.068253
2018-12-08 19:04:38,312 - INFO - epoch 4, step 3150, training loss = 2.574214, validation loss = 5.399983
2018-12-08 19:04:58,998 - INFO - epoch 4, step 3200, training loss = 2.964588, validation loss = 5.328656
2018-12-08 19:05:20,132 - INFO - epoch 4, step 3250, training loss = 3.042158, validation loss = 5.002285
2018-12-08 19:05:39,525 - INFO - epoch 4, step 3300, training loss = 2.949555, validation loss = 5.285601
2018-12-08 19:05:58,211 - INFO - epoch 4, step 3350, training loss = 2.565721, validation loss = 5.144482
2018-12-08 19:06:17,307 - INFO - epoch 4, step 3400, training loss = 3.056193, validation loss = 5.285506
2018-12-08 19:06:37,033 - INFO - epoch 4, step 3450, training loss = 2.638389, validation loss = 4.834616
2018-12-08 19:06:56,613 - INFO - epoch 4, step 3500, training loss = 2.611782, validation loss = 4.619670
2018-12-08 19:07:15,173 - INFO - epoch 4, step 3550, training loss = 2.691002, validation loss = 4.395406
2018-12-08 19:07:33,589 - INFO - epoch 4, step 3600, training loss = 2.837924, validation loss = 4.995039
2018-12-08 19:07:52,283 - INFO - epoch 4, step 3650, training loss = 3.059908, validation loss = 4.717924
2018-12-08 19:08:11,320 - INFO - epoch 4, step 3700, training loss = 2.592135, validation loss = 4.644006
2018-12-08 19:08:29,091 - INFO - epoch 4, step 3750, training loss = 2.741062, validation loss = 4.767644
2018-12-08 19:08:45,498 - INFO - epoch 4, step 3800, training loss = 1.876603, validation loss = 5.132120
2018-12-08 19:09:02,207 - INFO - epoch 4, step 3850, training loss = 2.647271, validation loss = 5.146762
2018-12-08 19:09:20,388 - INFO - epoch 4, step 3900, training loss = 2.582004, validation loss = 5.549849
2018-12-08 19:09:40,755 - INFO - epoch 4, step 3950, training loss = 2.804114, validation loss = 5.239233
2018-12-08 19:10:00,445 - INFO - epoch 4, step 4000, training loss = 2.633287, validation loss = 5.061384
2018-12-08 19:10:18,431 - INFO - epoch 4, step 4050, training loss = 2.559801, validation loss = 4.703165
2018-12-08 19:10:35,750 - INFO - epoch 4, step 4100, training loss = 2.558932, validation loss = 5.231476
2018-12-08 19:10:53,837 - INFO - epoch 4, step 4150, training loss = 2.814710, validation loss = 5.045588
2018-12-08 19:11:11,412 - INFO - epoch 4, step 4200, training loss = 2.738941, validation loss = 5.306037
2018-12-08 19:11:30,013 - INFO - epoch 4, step 4250, training loss = 2.980584, validation loss = 5.039979
2018-12-08 19:11:48,507 - INFO - epoch 4, step 4300, training loss = 2.962324, validation loss = 5.418910
2018-12-08 19:12:06,882 - INFO - epoch 4, step 4350, training loss = 2.927670, validation loss = 4.926936
2018-12-08 19:12:25,072 - INFO - epoch 4, step 4400, training loss = 3.348491, validation loss = 4.734204
2018-12-08 19:12:43,710 - INFO - epoch 4, step 4450, training loss = 3.081525, validation loss = 5.267600
2018-12-08 19:13:01,607 - INFO - epoch 4, step 4500, training loss = 2.633163, validation loss = 5.328881
2018-12-08 19:13:19,470 - INFO - epoch 4, step 4550, training loss = 2.439671, validation loss = 5.278301
2018-12-08 19:13:37,046 - INFO - epoch 4, step 4600, training loss = 2.629496, validation loss = 5.117752
2018-12-08 19:13:54,913 - INFO - epoch 4, step 4650, training loss = 2.747464, validation loss = 5.137969
2018-12-08 19:14:16,095 - INFO - epoch 4, step 4700, training loss = 3.083759, validation loss = 5.304033
2018-12-08 19:14:36,823 - INFO - epoch 4, step 4750, training loss = 2.867790, validation loss = 4.860972
2018-12-08 19:14:56,937 - INFO - epoch 4, step 4800, training loss = 2.497884, validation loss = 4.855340
2018-12-08 19:15:16,066 - INFO - epoch 4, step 4850, training loss = 2.548398, validation loss = 4.952025
2018-12-08 19:15:34,440 - INFO - epoch 4, step 4900, training loss = 3.010078, validation loss = 5.359534
2018-12-08 19:15:50,715 - INFO - epoch 4, step 4950, training loss = 2.633761, validation loss = 4.940073
2018-12-08 19:16:07,884 - INFO - epoch 4, step 5000, training loss = 2.879769, validation loss = 4.900956
2018-12-08 19:16:28,865 - INFO - epoch 4, step 5050, training loss = 2.456785, validation loss = 5.138786
2018-12-08 19:16:49,750 - INFO - epoch 4, step 5100, training loss = 2.290510, validation loss = 4.697049
2018-12-08 19:17:08,607 - INFO - epoch 4, step 5150, training loss = 2.830554, validation loss = 5.129964
2018-12-08 19:17:26,466 - INFO - epoch 4, step 5200, training loss = 2.244447, validation loss = 5.139685
2018-12-08 19:17:46,445 - INFO - epoch 4, step 5250, training loss = 2.946211, validation loss = 4.705975
2018-12-08 19:18:06,972 - INFO - epoch 4, step 5300, training loss = 2.955496, validation loss = 5.218235
2018-12-08 19:18:25,750 - INFO - epoch 4, step 5350, training loss = 2.551079, validation loss = 5.466220
2018-12-08 19:18:44,758 - INFO - epoch 4, step 5400, training loss = 2.732445, validation loss = 5.138890
2018-12-08 19:19:03,275 - INFO - epoch 4, step 5450, training loss = 2.753504, validation loss = 4.647500
2018-12-08 19:19:21,740 - INFO - epoch 4, step 5500, training loss = 2.902641, validation loss = 4.880048
2018-12-08 19:19:40,290 - INFO - epoch 4, step 5550, training loss = 2.693150, validation loss = 5.123526
2018-12-08 19:19:59,700 - INFO - epoch 4, step 5600, training loss = 2.723767, validation loss = 4.637846
2018-12-08 19:20:19,873 - INFO - epoch 4, step 5650, training loss = 2.912019, validation loss = 4.658983
2018-12-08 19:20:40,748 - INFO - epoch 4, step 5700, training loss = 3.046204, validation loss = 4.629658
2018-12-08 19:21:01,419 - INFO - epoch 4, step 5750, training loss = 2.887256, validation loss = 4.731840
2018-12-08 19:21:22,823 - INFO - epoch 4, step 5800, training loss = 2.733838, validation loss = 4.818200
2018-12-08 19:21:43,629 - INFO - epoch 4, step 5850, training loss = 2.659019, validation loss = 5.115842
2018-12-08 19:22:00,121 - INFO - epoch 4, step 5900, training loss = 2.451087, validation loss = 5.199442
2018-12-08 19:22:16,504 - INFO - epoch 4, step 5950, training loss = 2.299241, validation loss = 4.959999
2018-12-08 19:22:36,717 - INFO - epoch 4, step 6000, training loss = 2.751460, validation loss = 5.043140
2018-12-08 19:22:57,757 - INFO - epoch 4, step 6050, training loss = 2.626698, validation loss = 5.256494
2018-12-08 19:23:18,389 - INFO - epoch 4, step 6100, training loss = 2.629685, validation loss = 5.100019
2018-12-08 19:23:39,941 - INFO - epoch 4, step 6150, training loss = 2.836533, validation loss = 5.372058
2018-12-08 19:24:00,681 - INFO - epoch 4, step 6200, training loss = 2.924282, validation loss = 5.177546
2018-12-08 19:24:21,336 - INFO - epoch 4, step 6250, training loss = 2.593406, validation loss = 5.052443
2018-12-08 19:24:40,872 - INFO - epoch 4, step 6300, training loss = 2.982640, validation loss = 5.377834
2018-12-08 19:24:59,386 - INFO - epoch 4, step 6350, training loss = 2.727774, validation loss = 4.505905
2018-12-08 19:25:17,703 - INFO - epoch 4, step 6400, training loss = 2.817525, validation loss = 4.610356
2018-12-08 19:25:36,162 - INFO - epoch 4, step 6450, training loss = 2.496566, validation loss = 5.096245
2018-12-08 19:25:54,179 - INFO - epoch 4, step 6500, training loss = 2.218543, validation loss = 5.223294
2018-12-08 19:26:12,145 - INFO - epoch 4, step 6550, training loss = 2.757159, validation loss = 4.966819
2018-12-08 19:26:29,706 - INFO - epoch 4, step 6600, training loss = 2.719434, validation loss = 5.264348
2018-12-08 19:26:48,047 - INFO - epoch 4, step 6650, training loss = 2.934249, validation loss = 4.971011
2018-12-08 19:27:07,049 - INFO - epoch 4, step 6700, training loss = 3.053554, validation loss = 5.056726
2018-12-08 19:27:25,747 - INFO - epoch 4, step 6750, training loss = 2.745593, validation loss = 5.244821
2018-12-08 19:27:43,732 - INFO - epoch 4, step 6800, training loss = 2.647733, validation loss = 5.501776
2018-12-08 19:28:01,636 - INFO - epoch 4, step 6850, training loss = 2.546879, validation loss = 5.614527
2018-12-08 19:28:19,100 - INFO - epoch 4, step 6900, training loss = 2.261445, validation loss = 5.512637
2018-12-08 19:28:38,415 - INFO - epoch 4, step 6950, training loss = 2.739659, validation loss = 5.265921
2018-12-08 19:28:58,644 - INFO - epoch 4, step 7000, training loss = 2.932918, validation loss = 5.156018
2018-12-08 19:29:20,018 - INFO - epoch 4, step 7050, training loss = 2.829185, validation loss = 4.580985
2018-12-08 19:29:40,211 - INFO - epoch 4, step 7100, training loss = 2.537413, validation loss = 4.973859
2018-12-08 19:30:00,945 - INFO - epoch 4, step 7150, training loss = 2.490327, validation loss = 5.088242
2018-12-08 19:30:21,010 - INFO - epoch 4, step 7200, training loss = 2.772422, validation loss = 4.758414
2018-12-08 19:30:40,419 - INFO - epoch 4, step 7250, training loss = 2.699900, validation loss = 4.557856
2018-12-08 19:30:58,542 - INFO - epoch 4, step 7300, training loss = 2.556217, validation loss = 5.238702
2018-12-08 19:31:16,902 - INFO - epoch 4, step 7350, training loss = 2.818135, validation loss = 4.976485
2018-12-08 19:31:34,818 - INFO - epoch 4, step 7400, training loss = 2.569564, validation loss = 4.855382
2018-12-08 19:31:51,579 - INFO - epoch 4, step 7450, training loss = 2.814020, validation loss = 5.061135
2018-12-08 19:32:07,730 - INFO - epoch 4, step 7500, training loss = 1.965167, validation loss = 5.455581
2018-12-08 19:32:24,163 - INFO - epoch 4, step 7550, training loss = 2.384312, validation loss = 5.013226
2018-12-08 19:32:42,042 - INFO - epoch 4, step 7600, training loss = 2.498233, validation loss = 5.169155
2018-12-08 19:33:00,308 - INFO - epoch 4, step 7650, training loss = 2.469493, validation loss = 4.854784
2018-12-08 19:33:18,374 - INFO - epoch 4, step 7700, training loss = 2.422465, validation loss = 5.171395
2018-12-08 19:33:36,570 - INFO - epoch 4, step 7750, training loss = 2.476533, validation loss = 4.857369
2018-12-08 19:33:54,992 - INFO - epoch 4, step 7800, training loss = 2.907461, validation loss = 4.930572
2018-12-08 19:34:14,105 - INFO - epoch 4, step 7850, training loss = 2.845981, validation loss = 5.338643
2018-12-08 19:34:33,238 - INFO - epoch 4, step 7900, training loss = 2.445662, validation loss = 5.258356
2018-12-08 19:34:52,658 - INFO - epoch 4, step 7950, training loss = 2.432083, validation loss = 5.356548
2018-12-08 19:35:13,009 - INFO - epoch 4, step 8000, training loss = 2.726797, validation loss = 4.999644
2018-12-08 19:35:33,706 - INFO - epoch 4, step 8050, training loss = 2.629245, validation loss = 4.230174
2018-12-08 19:35:54,433 - INFO - epoch 4, step 8100, training loss = 2.599642, validation loss = 4.679645
2018-12-08 19:36:15,915 - INFO - epoch 4, step 8150, training loss = 3.169776, validation loss = 5.024319
2018-12-08 19:36:37,066 - INFO - epoch 4, step 8200, training loss = 2.742023, validation loss = 4.577334
2018-12-08 19:36:57,373 - INFO - epoch 4, step 8250, training loss = 2.499243, validation loss = 5.089736
2018-12-08 19:37:16,084 - INFO - epoch 4, step 8300, training loss = 2.475804, validation loss = 4.308701
2018-12-08 19:37:32,752 - INFO - epoch 4, step 8350, training loss = 2.511451, validation loss = 4.972217
2018-12-08 19:37:49,309 - INFO - epoch 4, step 8400, training loss = 2.481646, validation loss = 4.786288
2018-12-08 19:38:08,836 - INFO - epoch 4, step 8450, training loss = 2.610857, validation loss = 4.241684
2018-12-08 19:38:28,741 - INFO - epoch 4, step 8500, training loss = 2.250343, validation loss = 4.680307
2018-12-08 19:38:46,574 - INFO - epoch 4, step 8550, training loss = 2.571233, validation loss = 4.767168
2018-12-08 19:39:03,859 - INFO - epoch 4, step 8600, training loss = 2.151617, validation loss = 4.858233
2018-12-08 19:39:20,769 - INFO - epoch 4, step 8650, training loss = 2.363018, validation loss = 5.205383
2018-12-08 19:39:38,802 - INFO - epoch 4, step 8700, training loss = 2.920970, validation loss = 5.125494
2018-12-08 19:39:57,114 - INFO - epoch 4, step 8750, training loss = 3.016697, validation loss = 4.765224
2018-12-08 19:40:14,830 - INFO - epoch 4, step 8800, training loss = 2.420710, validation loss = 5.040242
2018-12-08 19:40:31,841 - INFO - epoch 4, step 8850, training loss = 2.380329, validation loss = 5.577468
2018-12-08 19:40:49,708 - INFO - epoch 4, step 8900, training loss = 2.945967, validation loss = 5.204413
2018-12-08 19:41:07,767 - INFO - epoch 4, step 8950, training loss = 3.014465, validation loss = 5.000281
2018-12-08 19:41:24,530 - INFO - epoch 4, step 9000, training loss = 2.605432, validation loss = 4.507047
2018-12-08 19:41:41,373 - INFO - epoch 4, step 9050, training loss = 2.857374, validation loss = 5.118163
2018-12-08 19:41:59,539 - INFO - epoch 4, step 9100, training loss = 2.702720, validation loss = 4.506133
2018-12-08 19:42:18,463 - INFO - epoch 4, step 9150, training loss = 2.424102, validation loss = 3.942584
2018-12-08 19:42:34,806 - INFO - epoch 4, step 9200, training loss = 1.984938, validation loss = 4.999509
2018-12-08 19:42:51,490 - INFO - epoch 4, step 9250, training loss = 1.935486, validation loss = 5.120792
2018-12-08 19:43:09,032 - INFO - epoch 4, step 9300, training loss = 2.418013, validation loss = 4.618781
2018-12-08 19:43:26,843 - INFO - epoch 4, step 9350, training loss = 2.728682, validation loss = 4.809412
2018-12-08 19:43:46,606 - INFO - epoch 4, step 9400, training loss = 2.778479, validation loss = 4.855404
2018-12-08 19:44:07,196 - INFO - epoch 4, step 9450, training loss = 2.889627, validation loss = 4.581717
2018-12-08 19:44:25,831 - INFO - epoch 4, step 9500, training loss = 1.900310, validation loss = 4.846251
2018-12-08 19:44:42,530 - INFO - epoch 4, step 9550, training loss = 2.296978, validation loss = 4.981968
2018-12-08 19:44:59,212 - INFO - epoch 4, step 9600, training loss = 2.228823, validation loss = 5.320065
2018-12-08 19:45:17,054 - INFO - epoch 4, step 9650, training loss = 1.830969, validation loss = 5.239317
2018-12-08 19:45:35,178 - INFO - epoch 4, step 9700, training loss = 2.634385, validation loss = 5.114575
2018-12-08 19:45:57,106 - INFO - epoch 4, step 9750, training loss = 2.597497, validation loss = 4.773435
2018-12-08 19:46:18,753 - INFO - epoch 4, step 9800, training loss = 2.562703, validation loss = 5.162527
2018-12-08 19:46:39,008 - INFO - epoch 4, step 9850, training loss = 2.288283, validation loss = 4.672707
2018-12-08 19:46:56,524 - INFO - epoch 4, step 9900, training loss = 1.899856, validation loss = 4.719807
2018-12-08 19:47:14,430 - INFO - epoch 4, step 9950, training loss = 2.443585, validation loss = 4.982334
2018-12-08 19:47:32,313 - INFO - epoch 4, step 10000, training loss = 2.600877, validation loss = 4.619543
2018-12-08 19:47:49,876 - INFO - epoch 4, step 10050, training loss = 2.398564, validation loss = 4.633127
2018-12-08 19:48:07,027 - INFO - epoch 4, step 10100, training loss = 2.657274, validation loss = 4.679595
2018-12-08 19:48:23,647 - INFO - epoch 4, step 10150, training loss = 2.326747, validation loss = 4.547623
2018-12-08 19:48:42,183 - INFO - epoch 4, step 10200, training loss = 2.676760, validation loss = 4.175634
2018-12-08 19:49:00,473 - INFO - epoch 4, step 10250, training loss = 2.659948, validation loss = 4.921493
2018-12-08 19:49:17,559 - INFO - epoch 4, step 10300, training loss = 2.391790, validation loss = 5.038948
2018-12-08 19:49:36,030 - INFO - epoch 4, step 10350, training loss = 2.827442, validation loss = 4.490014
2018-12-08 19:49:56,858 - INFO - epoch 4, step 10400, training loss = 3.268362, validation loss = 4.465641
2018-12-08 19:50:18,909 - INFO - epoch 4, step 10450, training loss = 2.520560, validation loss = 4.725195
2018-12-08 19:50:39,619 - INFO - epoch 4, step 10500, training loss = 2.929191, validation loss = 4.514650
2018-12-08 19:50:59,549 - INFO - epoch 4, step 10550, training loss = 2.678296, validation loss = 4.616279
2018-12-08 19:51:18,466 - INFO - epoch 4, step 10600, training loss = 2.421419, validation loss = 5.228938
2018-12-08 19:51:36,905 - INFO - epoch 4, step 10650, training loss = 2.839083, validation loss = 4.955000
2018-12-08 19:51:55,656 - INFO - epoch 4, step 10700, training loss = 3.165101, validation loss = 5.531647
2018-12-08 19:52:14,455 - INFO - epoch 4, step 10750, training loss = 2.474383, validation loss = 5.813780
2018-12-08 19:52:33,303 - INFO - epoch 4, step 10800, training loss = 2.657604, validation loss = 5.120079
2018-12-08 19:52:51,923 - INFO - epoch 4, step 10850, training loss = 2.509272, validation loss = 4.738908
2018-12-08 19:53:09,980 - INFO - epoch 4, step 10900, training loss = 2.748787, validation loss = 5.257069
2018-12-08 19:53:26,666 - INFO - epoch 4, step 10950, training loss = 2.155620, validation loss = 5.146808
2018-12-08 19:53:43,545 - INFO - epoch 4, step 11000, training loss = 2.654567, validation loss = 4.891003
2018-12-08 19:54:01,284 - INFO - epoch 4, step 11050, training loss = 2.683748, validation loss = 4.934944
2018-12-08 19:54:20,878 - INFO - epoch 4, step 11100, training loss = 2.777552, validation loss = 4.958778
2018-12-08 19:54:39,387 - INFO - epoch 4, step 11150, training loss = 2.069517, validation loss = 4.923733
2018-12-08 19:54:57,693 - INFO - epoch 4, step 11200, training loss = 2.698264, validation loss = 4.949693
2018-12-08 19:55:15,667 - INFO - epoch 4, step 11250, training loss = 2.392700, validation loss = 4.663730
2018-12-08 19:55:32,533 - INFO - epoch 4, step 11300, training loss = 2.501817, validation loss = 5.498792
2018-12-08 19:55:50,238 - INFO - epoch 4, step 11350, training loss = 2.459306, validation loss = 5.562710
2018-12-08 19:56:08,062 - INFO - epoch 4, step 11400, training loss = 2.849646, validation loss = 5.608277
2018-12-08 19:56:25,788 - INFO - epoch 4, step 11450, training loss = 2.606657, validation loss = 4.937843
2018-12-08 19:56:45,589 - INFO - epoch 4, step 11500, training loss = 3.121385, validation loss = 4.860303
2018-12-08 19:57:04,978 - INFO - epoch 4, step 11550, training loss = 2.133628, validation loss = 5.198979
2018-12-08 19:57:25,632 - INFO - epoch 4, step 11600, training loss = 2.793483, validation loss = 4.871915
2018-12-08 19:57:45,585 - INFO - epoch 4, step 11650, training loss = 2.200436, validation loss = 5.252004
2018-12-08 19:58:03,263 - INFO - epoch 4, step 11700, training loss = 2.436099, validation loss = 5.171742
2018-12-08 19:58:21,095 - INFO - epoch 4, step 11750, training loss = 2.214017, validation loss = 4.763804
2018-12-08 19:58:40,122 - INFO - epoch 4, step 11800, training loss = 2.793838, validation loss = 5.285193
2018-12-08 19:58:59,749 - INFO - epoch 4, step 11850, training loss = 2.449173, validation loss = 5.076963
2018-12-08 19:59:19,162 - INFO - epoch 4, step 11900, training loss = 2.577106, validation loss = 4.449896
2018-12-08 19:59:37,434 - INFO - epoch 4, step 11950, training loss = 1.994636, validation loss = 5.209224
2018-12-08 19:59:55,411 - INFO - epoch 4, step 12000, training loss = 2.502539, validation loss = 4.575772
2018-12-08 20:00:13,718 - INFO - epoch 4, step 12050, training loss = 2.821844, validation loss = 4.352124
2018-12-08 20:00:34,740 - INFO - epoch 4, step 12100, training loss = 2.950294, validation loss = 4.766710
2018-12-08 20:00:55,574 - INFO - epoch 4, step 12150, training loss = 2.880802, validation loss = 5.415695
2018-12-08 20:01:16,441 - INFO - epoch 4, step 12200, training loss = 2.380785, validation loss = 4.196773
2018-12-08 20:01:37,260 - INFO - epoch 4, step 12250, training loss = 2.621687, validation loss = 4.378115
2018-12-08 20:01:57,871 - INFO - epoch 4, step 12300, training loss = 3.168549, validation loss = 4.504209
2018-12-08 20:02:16,252 - INFO - epoch 4, step 12350, training loss = 2.951126, validation loss = 4.648986
2018-12-08 20:02:34,139 - INFO - epoch 4, step 12400, training loss = 2.530161, validation loss = 4.958749
2018-12-08 20:02:54,657 - INFO - epoch 4, step 12450, training loss = 2.484695, validation loss = 4.227187
2018-12-08 20:03:14,613 - INFO - epoch 4, step 12500, training loss = 2.368693, validation loss = 4.423899
2018-12-08 20:03:34,295 - INFO - epoch 4, step 12550, training loss = 2.491624, validation loss = 4.416702
2018-12-08 20:03:52,860 - INFO - epoch 4, step 12600, training loss = 2.439435, validation loss = 5.235151
2018-12-08 20:04:11,249 - INFO - epoch 4, step 12650, training loss = 2.581574, validation loss = 3.926495
2018-12-08 20:04:29,024 - INFO - epoch 4, step 12700, training loss = 2.996236, validation loss = 4.719971
2018-12-08 20:04:45,851 - INFO - epoch 4, step 12750, training loss = 2.758144, validation loss = 4.924984
2018-12-08 20:05:03,173 - INFO - epoch 4, step 12800, training loss = 2.987230, validation loss = 5.408583
2018-12-08 20:05:22,829 - INFO - epoch 4, step 12850, training loss = 2.687216, validation loss = 5.880497
2018-12-08 20:05:41,315 - INFO - epoch 4, step 12900, training loss = 2.757202, validation loss = 4.716457
2018-12-08 20:05:58,212 - INFO - epoch 4, step 12950, training loss = 2.882564, validation loss = 4.800990
2018-12-08 20:06:14,780 - INFO - epoch 4, step 13000, training loss = 2.989942, validation loss = 4.213505
2018-12-08 20:06:31,599 - INFO - epoch 4, step 13050, training loss = 2.540016, validation loss = 4.763468
2018-12-08 20:06:51,801 - INFO - epoch 4, step 13100, training loss = 2.765839, validation loss = 4.937722
2018-12-08 20:07:11,596 - INFO - epoch 4, step 13150, training loss = 2.488506, validation loss = 4.467093
2018-12-08 20:07:30,958 - INFO - epoch 4, step 13200, training loss = 2.592360, validation loss = 4.900308
2018-12-08 20:07:47,576 - INFO - epoch 4, step 13250, training loss = 2.497900, validation loss = 4.479600
2018-12-08 20:08:04,790 - INFO - epoch 4, step 13300, training loss = 2.558838, validation loss = 4.908492
2018-12-08 20:08:22,354 - INFO - epoch 4, step 13350, training loss = 2.278962, validation loss = 4.753855
2018-12-08 20:08:40,237 - INFO - epoch 4, step 13400, training loss = 2.353861, validation loss = 4.089710
2018-12-08 20:08:57,745 - INFO - epoch 4, step 13450, training loss = 2.496364, validation loss = 4.659401
2018-12-08 20:09:17,544 - INFO - epoch 4, step 13500, training loss = 2.967880, validation loss = 4.437217
2018-12-08 20:09:38,521 - INFO - epoch 4, step 13550, training loss = 2.933847, validation loss = 4.491557
2018-12-08 20:09:59,415 - INFO - epoch 4, step 13600, training loss = 2.988072, validation loss = 4.904779
2018-12-08 20:10:16,576 - INFO - epoch 4, step 13650, training loss = 2.389703, validation loss = 4.853917
2018-12-08 20:10:33,897 - INFO - epoch 4, step 13700, training loss = 2.109254, validation loss = 4.755855
2018-12-08 20:10:52,344 - INFO - epoch 4, step 13750, training loss = 2.451785, validation loss = 4.544604
2018-12-08 20:11:11,598 - INFO - epoch 4, step 13800, training loss = 2.420565, validation loss = 4.603964
2018-12-08 20:11:29,243 - INFO - epoch 4, step 13850, training loss = 2.389365, validation loss = 4.480492
2018-12-08 20:11:48,396 - INFO - epoch 4, step 13900, training loss = 2.309944, validation loss = 4.474868
2018-12-08 20:12:09,422 - INFO - epoch 4, step 13950, training loss = 3.074484, validation loss = 4.738994
2018-12-08 20:12:31,010 - INFO - epoch 4, step 14000, training loss = 2.234190, validation loss = 5.134762
2018-12-08 20:12:50,954 - INFO - epoch 4, step 14050, training loss = 2.895094, validation loss = 5.230188
2018-12-08 20:13:08,736 - INFO - epoch 4, step 14100, training loss = 2.872791, validation loss = 5.101010
2018-12-08 20:13:27,689 - INFO - epoch 4, step 14150, training loss = 3.084582, validation loss = 4.910093
2018-12-08 20:13:46,496 - INFO - epoch 4, step 14200, training loss = 2.765241, validation loss = 4.827292
2018-12-08 20:14:06,690 - INFO - epoch 4, step 14250, training loss = 2.432182, validation loss = 4.981567
2018-12-08 20:14:27,810 - INFO - epoch 4, step 14300, training loss = 2.771120, validation loss = 5.278735
2018-12-08 20:14:48,486 - INFO - epoch 4, step 14350, training loss = 2.922676, validation loss = 4.463092
2018-12-08 20:15:04,342 - INFO - epoch 4, step 14400, training loss = 3.064309, validation loss = 4.808256
2018-12-08 20:15:20,019 - INFO - epoch 4, step 14450, training loss = 2.651162, validation loss = 4.670156
2018-12-08 20:15:36,077 - INFO - epoch 4, step 14500, training loss = 2.782364, validation loss = 4.815492
2018-12-08 20:15:53,414 - INFO - epoch 4, step 14550, training loss = 3.324552, validation loss = 4.521554
2018-12-08 20:16:11,462 - INFO - epoch 4, step 14600, training loss = 2.925868, validation loss = 4.344805
2018-12-08 20:16:34,705 - INFO - epoch 4, step 14650, training loss = 3.420588, validation loss = 4.370191
2018-12-08 20:16:58,094 - INFO - epoch 4, step 14700, training loss = 2.540925, validation loss = 4.990231
2018-12-08 20:17:14,160 - INFO - epoch 4, step 14750, training loss = 2.528197, validation loss = 4.705768
2018-12-08 20:17:29,572 - INFO - epoch 4, step 14800, training loss = 2.409817, validation loss = 4.743003
2018-12-08 20:17:45,251 - INFO - epoch 4, step 14850, training loss = 2.569525, validation loss = 4.760490
2018-12-08 20:18:12,214 - INFO - epoch 4, step 14900, training loss = 3.063784, validation loss = 4.585202
2018-12-08 20:18:39,451 - INFO - epoch 4, step 14950, training loss = 3.343050, validation loss = 4.060467
2018-12-08 20:19:07,835 - INFO - epoch 4, step 15000, training loss = 3.256062, validation loss = 4.818124
2018-12-08 20:19:34,965 - INFO - epoch 4, step 15050, training loss = 3.307439, validation loss = 4.818694
2018-12-08 20:20:04,304 - INFO - epoch 4, step 15100, training loss = 3.166539, validation loss = 4.944626
2018-12-08 20:20:35,876 - INFO - epoch 4, step 15150, training loss = 3.370818, validation loss = 5.582012
2018-12-08 20:21:06,670 - INFO - epoch 4, step 15200, training loss = 3.537093, validation loss = 4.990023
2018-12-08 20:21:36,100 - INFO - epoch 4, step 15250, training loss = 3.354674, validation loss = 4.701712
2018-12-08 20:22:05,749 - INFO - epoch 4, step 15300, training loss = 2.627348, validation loss = 4.227673
2018-12-08 20:22:32,901 - INFO - epoch 4, step 15350, training loss = 3.100549, validation loss = 4.713677
2018-12-08 20:22:57,892 - INFO - epoch 4, step 15400, training loss = 3.267696, validation loss = 4.522413
2018-12-08 20:23:13,788 - INFO - epoch 4, step 15450, training loss = 3.149875, validation loss = 4.776034
2018-12-08 20:23:29,463 - INFO - epoch 4, step 15500, training loss = 2.992676, validation loss = 4.175937
2018-12-08 20:23:45,089 - INFO - epoch 4, step 15550, training loss = 2.619945, validation loss = 4.969550
2018-12-08 20:24:03,009 - INFO - epoch 4, step 15600, training loss = 3.404780, validation loss = 4.314628
2018-12-08 20:24:27,000 - INFO - epoch 4, step 15650, training loss = 2.968760, validation loss = 4.750335
2018-12-08 20:24:50,166 - INFO - epoch 4, step 15700, training loss = 3.325403, validation loss = 4.791930
2018-12-08 20:25:17,596 - INFO - epoch 4, step 15750, training loss = 3.272459, validation loss = 4.646664
2018-12-08 20:25:45,017 - INFO - epoch 4, step 15800, training loss = 3.509897, validation loss = 4.503318
2018-12-08 20:26:12,434 - INFO - epoch 4, step 15850, training loss = 3.285880, validation loss = 4.654076
2018-12-08 20:26:40,676 - INFO - epoch 4, step 15900, training loss = 2.862058, validation loss = 4.609653
2018-12-08 20:27:03,826 - INFO - epoch 4, step 15950, training loss = 2.975711, validation loss = 4.628606
2018-12-08 20:27:25,319 - INFO - epoch 4, step 16000, training loss = 3.371061, validation loss = 5.112276
2018-12-08 20:27:41,296 - INFO - epoch 4, step 16050, training loss = 3.076125, validation loss = 4.561008
2018-12-08 20:27:53,268 - INFO - epoch 4, step 16100, training loss = 2.805489, validation loss = 5.023692
2018-12-08 20:28:05,212 - INFO - epoch 4, step 16150, training loss = 2.739702, validation loss = 4.881471
2018-12-08 20:28:18,988 - INFO - epoch 4, step 16200, training loss = 3.645877, validation loss = 5.026717
2018-12-08 20:28:36,437 - INFO - epoch 4, step 16250, training loss = 3.279507, validation loss = 5.354579
2018-12-08 20:28:54,529 - INFO - epoch 4, step 16300, training loss = 3.279821, validation loss = 4.776963
2018-12-08 20:29:07,764 - INFO - epoch 4, step 16350, training loss = 2.935771, validation loss = 4.778492
2018-12-08 20:29:19,664 - INFO - epoch 4, step 16400, training loss = 2.822956, validation loss = 4.522052
2018-12-08 20:29:39,633 - INFO - epoch 4, step 16450, training loss = 2.961380, validation loss = 4.335315
2018-12-08 20:30:05,097 - INFO - epoch 4, step 16500, training loss = 3.436796, validation loss = 5.207686
2018-12-08 20:30:30,514 - INFO - epoch 4, step 16550, training loss = 3.501006, validation loss = 4.189330
2018-12-08 20:30:56,181 - INFO - epoch 4, step 16600, training loss = 3.642064, validation loss = 4.405939
2018-12-08 20:31:19,855 - INFO - epoch 4, step 16650, training loss = 3.519682, validation loss = 4.586684
2018-12-08 20:31:38,711 - INFO - epoch 4, step 16700, training loss = 3.055528, validation loss = 4.378614
2018-12-08 20:32:00,243 - INFO - epoch 4, step 16750, training loss = 3.273846, validation loss = 4.140525
2018-12-08 20:32:16,788 - INFO - epoch 4, step 16800, training loss = 3.173052, validation loss = 4.321049
2018-12-08 20:32:32,560 - INFO - epoch 4, step 16850, training loss = 2.939842, validation loss = 4.799077
2018-12-08 20:32:48,722 - INFO - epoch 4, step 16900, training loss = 3.170231, validation loss = 4.314309
2018-12-08 20:33:05,100 - INFO - epoch 4, step 16950, training loss = 3.621795, validation loss = 4.672895
2018-12-08 20:33:29,035 - INFO - epoch 4, step 17000, training loss = 3.418701, validation loss = 4.760950
2018-12-08 20:33:52,914 - INFO - epoch 4, step 17050, training loss = 3.369139, validation loss = 4.929569
2018-12-08 20:34:17,994 - INFO - epoch 4, step 17100, training loss = 2.987502, validation loss = 4.763533
2018-12-08 20:34:43,808 - INFO - epoch 4, step 17150, training loss = 2.693313, validation loss = 4.500449
2018-12-08 20:35:08,873 - INFO - epoch 4, step 17200, training loss = 2.583795, validation loss = 4.240313
2018-12-08 20:35:34,483 - INFO - epoch 4, step 17250, training loss = 2.936420, validation loss = 5.393885
2018-12-08 20:35:59,822 - INFO - epoch 4, step 17300, training loss = 2.339640, validation loss = 4.579431
2018-12-08 20:36:25,326 - INFO - epoch 4, step 17350, training loss = 3.590095, validation loss = 4.705819
2018-12-08 20:36:48,287 - INFO - epoch 4, step 17400, training loss = 3.132723, validation loss = 4.912529
2018-12-08 20:37:03,884 - INFO - epoch 4, step 17450, training loss = 3.675483, validation loss = 5.418265
2018-12-08 20:37:18,436 - INFO - epoch 4, step 17500, training loss = 3.440516, validation loss = 5.275200
2018-12-08 20:37:39,598 - INFO - epoch 4, step 17550, training loss = 3.804395, validation loss = 4.524055
2018-12-08 20:38:06,126 - INFO - epoch 4, step 17600, training loss = 3.310623, validation loss = 4.593203
2018-12-08 20:38:32,379 - INFO - epoch 4, step 17650, training loss = 3.414624, validation loss = 4.954141
2018-12-08 20:38:58,617 - INFO - epoch 4, step 17700, training loss = 3.123668, validation loss = 4.443851
2018-12-08 20:39:25,246 - INFO - epoch 4, step 17750, training loss = 3.276992, validation loss = 4.626819
2018-12-08 20:39:46,901 - INFO - epoch 4, step 17800, training loss = 3.414737, validation loss = 4.488132
2018-12-08 20:40:05,257 - INFO - epoch 4, step 17850, training loss = 2.463290, validation loss = 4.432159
2018-12-08 20:40:21,002 - INFO - epoch 4, step 17900, training loss = 2.982940, validation loss = 4.698533
2018-12-08 20:40:36,338 - INFO - epoch 4, step 17950, training loss = 3.318268, validation loss = 4.518360
2018-12-08 20:40:52,156 - INFO - epoch 4, step 18000, training loss = 2.758384, validation loss = 4.493756
2018-12-08 20:41:05,489 - INFO - epoch 4, step 18050, training loss = 2.685148, validation loss = 5.135945
2018-12-08 20:41:17,458 - INFO - epoch 4, step 18100, training loss = 2.534538, validation loss = 4.778541
2018-12-08 20:41:43,142 - INFO - epoch 4, step 18150, training loss = 3.169258, validation loss = 4.820431
2018-12-08 20:42:09,101 - INFO - epoch 4, step 18200, training loss = 3.211599, validation loss = 4.586784
2018-12-08 20:42:34,327 - INFO - epoch 4, step 18250, training loss = 3.177148, validation loss = 4.638064
2018-12-08 20:42:59,770 - INFO - epoch 4, step 18300, training loss = 3.536072, validation loss = 4.488542
2018-12-08 20:43:26,046 - INFO - epoch 4, step 18350, training loss = 2.824463, validation loss = 4.917983
2018-12-08 20:43:43,387 - INFO - epoch 4, step 18400, training loss = 3.171595, validation loss = 4.514870
2018-12-08 20:43:58,637 - INFO - epoch 4, step 18450, training loss = 3.073984, validation loss = 4.914217
2018-12-08 20:44:14,768 - INFO - epoch 4, step 18500, training loss = 2.691114, validation loss = 5.470634
2018-12-08 20:44:30,898 - INFO - epoch 4, step 18550, training loss = 2.186776, validation loss = 4.826306
2018-12-08 20:44:48,329 - INFO - epoch 4, step 18600, training loss = 3.430961, validation loss = 4.736373
2018-12-08 20:45:11,518 - INFO - epoch 4, step 18650, training loss = 3.409542, validation loss = 4.456385
2018-12-08 20:45:37,155 - INFO - epoch 4, step 18700, training loss = 3.169983, validation loss = 4.368866
2018-12-08 20:46:02,047 - INFO - epoch 4, step 18750, training loss = 3.181425, validation loss = 4.810915
2018-12-08 20:46:18,138 - INFO - epoch 4, step 18800, training loss = 3.070068, validation loss = 4.104990
2018-12-08 20:46:33,264 - INFO - epoch 4, step 18850, training loss = 2.519959, validation loss = 4.248808
2018-12-08 20:46:48,688 - INFO - epoch 4, step 18900, training loss = 2.730980, validation loss = 4.352664
2018-12-08 20:47:04,280 - INFO - epoch 4, step 18950, training loss = 2.232700, validation loss = 5.003044
2018-12-08 20:47:24,427 - INFO - epoch 4, step 19000, training loss = 3.216564, validation loss = 4.844098
2018-12-08 20:47:42,692 - INFO - epoch 4, step 19050, training loss = 2.714913, validation loss = 4.296691
2018-12-08 20:47:58,037 - INFO - epoch 4, step 19100, training loss = 2.445501, validation loss = 4.535824
2018-12-08 20:48:13,160 - INFO - epoch 4, step 19150, training loss = 2.726573, validation loss = 4.520153
2018-12-08 20:48:28,883 - INFO - epoch 4, step 19200, training loss = 3.193425, validation loss = 4.986109
2018-12-08 20:48:49,788 - INFO - epoch 4, step 19250, training loss = 3.505363, validation loss = 4.304315
2018-12-08 20:49:14,792 - INFO - epoch 4, step 19300, training loss = 3.468990, validation loss = 4.118703
2018-12-08 20:49:39,956 - INFO - epoch 4, step 19350, training loss = 2.996709, validation loss = 4.452689
2018-12-08 20:50:08,794 - INFO - epoch 4, step 19400, training loss = 2.913575, validation loss = 5.049551
2018-12-08 20:50:36,822 - INFO - epoch 4, step 19450, training loss = 2.718152, validation loss = 4.524010
2018-12-08 20:51:05,822 - INFO - epoch 4, step 19500, training loss = 3.478189, validation loss = 4.346818
2018-12-08 20:51:32,098 - INFO - epoch 4, step 19550, training loss = 2.794166, validation loss = 4.848177
2018-12-08 20:51:52,846 - INFO - epoch 4, step 19600, training loss = 3.308443, validation loss = 4.913047
2018-12-08 20:52:13,576 - INFO - epoch 4, step 19650, training loss = 3.277570, validation loss = 4.946759
2018-12-08 20:52:40,336 - INFO - epoch 4, step 19700, training loss = 2.697656, validation loss = 5.211203
2018-12-08 20:53:08,435 - INFO - epoch 4, step 19750, training loss = 3.346566, validation loss = 4.422320
2018-12-08 20:53:35,924 - INFO - epoch 4, step 19800, training loss = 3.242702, validation loss = 4.389201
2018-12-08 20:54:03,218 - INFO - epoch 4, step 19850, training loss = 2.796181, validation loss = 4.862418
2018-12-08 20:54:26,206 - INFO - epoch 4, step 19900, training loss = 2.349935, validation loss = 4.462695
2018-12-08 20:54:42,020 - INFO - epoch 4, step 19950, training loss = 2.748481, validation loss = 4.380655
2018-12-08 20:54:58,109 - INFO - epoch 4, step 20000, training loss = 2.902929, validation loss = 4.223069
2018-12-08 20:55:13,678 - INFO - epoch 4, step 20050, training loss = 3.237712, validation loss = 4.565531
2018-12-08 20:55:29,332 - INFO - epoch 4, step 20100, training loss = 2.588013, validation loss = 3.830670
2018-12-08 20:55:45,167 - INFO - epoch 4, step 20150, training loss = 2.271666, validation loss = 4.578524
2018-12-08 20:56:00,527 - INFO - epoch 4, step 20200, training loss = 2.494224, validation loss = 4.381154
2018-12-08 20:56:20,108 - INFO - epoch 4, step 20250, training loss = 3.350638, validation loss = 4.337599
2018-12-08 20:56:41,734 - INFO - epoch 4, step 20300, training loss = 3.562218, validation loss = 4.318165
2018-12-08 20:57:02,724 - INFO - epoch 4, step 20350, training loss = 2.800506, validation loss = 4.055790
2018-12-08 20:57:23,423 - INFO - epoch 4, step 20400, training loss = 3.306771, validation loss = 4.221531
2018-12-08 20:57:44,969 - INFO - epoch 4, step 20450, training loss = 3.413527, validation loss = 4.410609
2018-12-08 20:58:08,415 - INFO - epoch 4, step 20500, training loss = 3.123168, validation loss = 4.718096
2018-12-08 20:58:33,420 - INFO - epoch 4, step 20550, training loss = 2.959812, validation loss = 4.452010
2018-12-08 20:58:58,199 - INFO - epoch 4, step 20600, training loss = 2.897492, validation loss = 4.525499
2018-12-08 20:59:18,500 - INFO - epoch 4, step 20650, training loss = 2.999753, validation loss = 4.503524
2018-12-08 20:59:36,386 - INFO - epoch 4, step 20700, training loss = 2.928065, validation loss = 5.374780
2018-12-08 20:59:56,820 - INFO - epoch 4, step 20750, training loss = 2.716059, validation loss = 4.935142
2018-12-08 21:00:17,567 - INFO - epoch 4, step 20800, training loss = 3.056751, validation loss = 4.877738
2018-12-08 21:00:33,278 - INFO - epoch 4, step 20850, training loss = 2.221655, validation loss = 4.215564
2018-12-08 21:00:48,953 - INFO - epoch 4, step 20900, training loss = 3.058472, validation loss = 4.672785
2018-12-08 21:01:04,497 - INFO - epoch 4, step 20950, training loss = 2.996019, validation loss = 4.811920
2018-12-08 21:01:33,381 - INFO - epoch 4, step 21000, training loss = 2.895444, validation loss = 4.578006
2018-12-08 21:02:02,697 - INFO - epoch 4, step 21050, training loss = 3.032571, validation loss = 4.190773
2018-12-08 21:02:27,833 - INFO - epoch 4, step 21100, training loss = 3.469388, validation loss = 4.754330
2018-12-08 21:02:52,717 - INFO - epoch 4, step 21150, training loss = 3.219793, validation loss = 4.417239
2018-12-08 21:03:17,494 - INFO - epoch 4, step 21200, training loss = 3.324923, validation loss = 3.879749
2018-12-08 21:03:42,504 - INFO - epoch 4, step 21250, training loss = 2.453529, validation loss = 4.084496
2018-12-08 21:04:08,004 - INFO - epoch 4, step 21300, training loss = 3.361055, validation loss = 4.773780
2018-12-08 21:04:33,557 - INFO - epoch 4, step 21350, training loss = 2.692615, validation loss = 5.728193
2018-12-08 21:04:59,440 - INFO - epoch 4, step 21400, training loss = 2.951397, validation loss = 5.063754
2018-12-08 21:05:25,391 - INFO - epoch 4, step 21450, training loss = 2.953222, validation loss = 5.211829
2018-12-08 21:05:51,875 - INFO - epoch 4, step 21500, training loss = 3.202383, validation loss = 5.444772
2018-12-08 21:06:08,623 - INFO - epoch 4, step 21550, training loss = 3.515849, validation loss = 4.954026
2018-12-08 21:06:24,572 - INFO - epoch 4, step 21600, training loss = 3.066025, validation loss = 5.083547
2018-12-08 21:06:42,017 - INFO - epoch 4, step 21650, training loss = 3.575057, validation loss = 5.189983
2018-12-08 21:07:05,608 - INFO - epoch 4, step 21700, training loss = 3.384490, validation loss = 4.720791
2018-12-08 21:07:28,722 - INFO - epoch 4, step 21750, training loss = 3.276487, validation loss = 4.964164
2018-12-08 21:07:53,005 - INFO - epoch 4, step 21800, training loss = 3.136311, validation loss = 5.793492
2018-12-08 21:08:16,997 - INFO - epoch 4, step 21850, training loss = 3.348408, validation loss = 4.807393
2018-12-08 21:08:37,276 - INFO - epoch 4, step 21900, training loss = 2.035680, validation loss = 5.874310
2018-12-08 21:08:49,174 - INFO - epoch 4, step 21950, training loss = 2.679595, validation loss = 5.102405
2018-12-08 21:09:00,787 - INFO - epoch 4, step 22000, training loss = 3.199586, validation loss = 5.173572
2018-12-08 21:09:13,820 - INFO - epoch 4, step 22050, training loss = 3.602539, validation loss = 5.318648
2018-12-08 21:09:35,841 - INFO - epoch 4, step 22100, training loss = 3.583953, validation loss = 5.273508
2018-12-08 21:09:57,646 - INFO - epoch 4, step 22150, training loss = 3.183442, validation loss = 5.427952
2018-12-08 21:10:19,192 - INFO - epoch 4, step 22200, training loss = 3.241528, validation loss = 5.578751
2018-12-08 21:10:45,096 - INFO - epoch 4, step 22250, training loss = 3.066940, validation loss = 5.315915
2018-12-08 21:11:14,351 - INFO - epoch 4, step 22300, training loss = 2.905778, validation loss = 5.271736
2018-12-08 21:11:43,905 - INFO - epoch 4, step 22350, training loss = 2.993514, validation loss = 5.162465
2018-12-08 21:12:11,880 - INFO - epoch 4, step 22400, training loss = 3.262218, validation loss = 5.477084
2018-12-08 21:12:40,631 - INFO - epoch 4, step 22450, training loss = 3.100841, validation loss = 4.967476
2018-12-08 21:13:07,220 - INFO - epoch 4, step 22500, training loss = 3.500596, validation loss = 4.998300
2018-12-08 21:13:35,646 - INFO - epoch 4, step 22550, training loss = 3.105542, validation loss = 5.363242
2018-12-08 21:14:04,132 - INFO - epoch 4, step 22600, training loss = 2.928315, validation loss = 4.935732
2018-12-08 21:14:26,256 - INFO - epoch 4, step 22650, training loss = 3.180924, validation loss = 5.333994
2018-12-08 21:14:45,566 - INFO - epoch 4, step 22700, training loss = 3.085094, validation loss = 5.622902
2018-12-08 21:15:02,786 - INFO - epoch 4, step 22750, training loss = 3.231524, validation loss = 5.417227
2018-12-08 21:15:20,225 - INFO - epoch 4, step 22800, training loss = 3.411592, validation loss = 4.861391
2018-12-08 21:15:37,172 - INFO - epoch 4, step 22850, training loss = 2.401069, validation loss = 5.156055
2018-12-08 21:15:53,358 - INFO - epoch 4, step 22900, training loss = 2.512093, validation loss = 5.328042
2018-12-08 21:16:09,076 - INFO - epoch 4, step 22950, training loss = 2.774543, validation loss = 5.331610
2018-12-08 21:16:24,886 - INFO - epoch 4, step 23000, training loss = 2.806591, validation loss = 5.362199
2018-12-08 21:16:46,743 - INFO - epoch 4, step 23050, training loss = 3.081944, validation loss = 5.630740
2018-12-08 21:17:07,760 - INFO - epoch 4, step 23100, training loss = 3.230232, validation loss = 5.047915
2018-12-08 21:17:23,829 - INFO - epoch 4, step 23150, training loss = 2.142794, validation loss = 4.862967
2018-12-08 21:17:35,299 - INFO - epoch 4, step 23200, training loss = 2.467843, validation loss = 5.285042
2018-12-08 21:17:46,859 - INFO - epoch 4, step 23250, training loss = 2.785090, validation loss = 5.380230
2018-12-08 21:18:00,127 - INFO - epoch 4, step 23300, training loss = 2.826204, validation loss = 4.776249
2018-12-08 21:18:16,032 - INFO - epoch 4, step 23350, training loss = 2.491887, validation loss = 4.883609
2018-12-08 21:18:31,541 - INFO - epoch 4, step 23400, training loss = 2.621979, validation loss = 5.039009
2018-12-08 21:18:48,651 - INFO - epoch 4, step 23450, training loss = 3.302503, validation loss = 4.336648
2018-12-08 21:19:13,840 - INFO - epoch 4, step 23500, training loss = 3.072050, validation loss = 4.782854
2018-12-08 21:19:36,772 - INFO - epoch 4, step 23550, training loss = 3.457733, validation loss = 5.257080
2018-12-08 21:19:57,805 - INFO - epoch 4, step 23600, training loss = 3.211035, validation loss = 4.834340
2018-12-08 21:20:18,322 - INFO - epoch 4, step 23650, training loss = 3.005908, validation loss = 5.216650
2018-12-08 21:20:39,544 - INFO - epoch 4, step 23700, training loss = 3.190567, validation loss = 4.919992
2018-12-08 21:21:03,257 - INFO - epoch 4, step 23750, training loss = 3.188831, validation loss = 5.415811
2018-12-08 21:21:27,219 - INFO - epoch 4, step 23800, training loss = 3.168957, validation loss = 5.568964
2018-12-08 21:21:52,047 - INFO - epoch 4, step 23850, training loss = 3.610564, validation loss = 4.689090
2018-12-08 21:22:17,284 - INFO - epoch 4, step 23900, training loss = 3.568154, validation loss = 5.157644
2018-12-08 21:22:41,674 - INFO - epoch 4, step 23950, training loss = 3.365186, validation loss = 4.716518
2018-12-08 21:23:04,787 - INFO - epoch 4, step 24000, training loss = 3.199529, validation loss = 5.338597
2018-12-08 21:23:31,544 - INFO - epoch 4, step 24050, training loss = 3.136225, validation loss = 4.922426
2018-12-08 21:24:01,959 - INFO - epoch 4, step 24100, training loss = 3.375062, validation loss = 4.909079
2018-12-08 21:24:31,162 - INFO - epoch 4, step 24150, training loss = 3.392631, validation loss = 4.885741
2018-12-08 21:24:59,502 - INFO - epoch 4, step 24200, training loss = 3.449714, validation loss = 4.746303
2018-12-08 21:25:25,531 - INFO - epoch 4, step 24250, training loss = 2.785484, validation loss = 5.353830
2018-12-08 21:25:41,472 - INFO - epoch 4, step 24300, training loss = 2.742846, validation loss = 5.279706
2018-12-08 21:25:57,061 - INFO - epoch 4, step 24350, training loss = 2.329121, validation loss = 5.537698
2018-12-08 21:26:13,019 - INFO - epoch 4, step 24400, training loss = 2.578939, validation loss = 5.385081
2018-12-08 21:26:28,872 - INFO - epoch 4, step 24450, training loss = 3.258015, validation loss = 4.689143
2018-12-08 21:26:44,701 - INFO - epoch 4, step 24500, training loss = 3.070322, validation loss = 4.711092
2018-12-08 21:27:00,165 - INFO - epoch 4, step 24550, training loss = 2.609316, validation loss = 5.220165
2018-12-08 21:27:16,117 - INFO - epoch 4, step 24600, training loss = 3.785165, validation loss = 5.333855
2018-12-08 21:27:32,646 - INFO - epoch 4, step 24650, training loss = 3.104889, validation loss = 4.833467
2018-12-08 21:27:47,797 - INFO - epoch 4, step 24700, training loss = 2.895462, validation loss = 4.792142
2018-12-08 21:28:03,233 - INFO - epoch 4, step 24750, training loss = 2.911124, validation loss = 5.241438
2018-12-08 21:28:19,094 - INFO - epoch 4, step 24800, training loss = 2.183283, validation loss = 5.197979
2018-12-08 21:28:35,524 - INFO - epoch 4, step 24850, training loss = 2.347404, validation loss = 5.086950
2018-12-08 21:28:53,487 - INFO - epoch 4, step 24900, training loss = 3.047264, validation loss = 5.534741
2018-12-08 21:29:15,044 - INFO - epoch 4, step 24950, training loss = 3.635103, validation loss = 4.962024
2018-12-08 21:29:41,745 - INFO - epoch 4, step 25000, training loss = 3.487566, validation loss = 5.299917
2018-12-08 21:30:08,771 - INFO - epoch 4, step 25050, training loss = 3.321664, validation loss = 4.770396
2018-12-08 21:30:35,311 - INFO - epoch 4, step 25100, training loss = 3.239165, validation loss = 5.545933
2018-12-08 21:31:01,970 - INFO - epoch 4, step 25150, training loss = 3.345221, validation loss = 4.963204
2018-12-08 21:31:20,927 - INFO - epoch 4, step 25200, training loss = 3.063135, validation loss = 4.976719
2018-12-08 21:31:38,623 - INFO - epoch 4, step 25250, training loss = 3.355300, validation loss = 4.610481
2018-12-08 21:32:02,041 - INFO - epoch 4, step 25300, training loss = 3.219058, validation loss = 5.102991
2018-12-08 21:32:29,319 - INFO - epoch 4, step 25350, training loss = 3.550382, validation loss = 5.218260
2018-12-08 21:32:57,082 - INFO - epoch 4, step 25400, training loss = 2.862110, validation loss = 4.774262
2018-12-08 21:33:23,694 - INFO - epoch 4, step 25450, training loss = 3.230709, validation loss = 4.939691
2018-12-08 21:33:41,728 - INFO - epoch 4, step 25500, training loss = 2.688793, validation loss = 4.934195
2018-12-08 21:33:57,308 - INFO - epoch 4, step 25550, training loss = 3.014704, validation loss = 5.258724
2018-12-08 21:34:17,664 - INFO - epoch 4, step 25600, training loss = 3.349315, validation loss = 4.573401
2018-12-08 21:34:44,645 - INFO - epoch 4, step 25650, training loss = 3.175220, validation loss = 4.606504
2018-12-08 21:35:13,290 - INFO - epoch 4, step 25700, training loss = 2.852306, validation loss = 4.580313
2018-12-08 21:35:40,614 - INFO - epoch 4, step 25750, training loss = 2.851174, validation loss = 4.795373
2018-12-08 21:36:01,606 - INFO - epoch 4, step 25800, training loss = 3.246937, validation loss = 4.782287
2018-12-08 21:36:18,702 - INFO - epoch 4, step 25850, training loss = 3.168402, validation loss = 4.896054
2018-12-08 21:36:34,037 - INFO - epoch 4, step 25900, training loss = 2.572792, validation loss = 5.137558
2018-12-08 21:36:49,568 - INFO - epoch 4, step 25950, training loss = 3.247467, validation loss = 5.023815
2018-12-08 21:37:15,629 - INFO - epoch 4, step 26000, training loss = 3.043589, validation loss = 5.093611
2018-12-08 21:37:41,525 - INFO - epoch 4, step 26050, training loss = 2.709849, validation loss = 4.997150
2018-12-08 21:38:06,692 - INFO - epoch 4, step 26100, training loss = 2.696596, validation loss = 5.060643
2018-12-08 21:38:31,987 - INFO - epoch 4, step 26150, training loss = 3.300107, validation loss = 4.883738
2018-12-08 21:39:00,223 - INFO - epoch 4, step 26200, training loss = 3.594568, validation loss = 5.295673
2018-12-08 21:39:27,158 - INFO - epoch 4, step 26250, training loss = 3.135512, validation loss = 5.155755
2018-12-08 21:39:55,099 - INFO - epoch 4, step 26300, training loss = 2.861532, validation loss = 4.683960
2018-12-08 21:40:20,915 - INFO - epoch 4, step 26350, training loss = 3.655976, validation loss = 3.120218
2018-12-08 21:40:47,181 - INFO - epoch 4, step 26400, training loss = 3.228148, validation loss = 2.797963
2018-12-08 21:41:12,998 - INFO - epoch 4, step 26450, training loss = 3.160486, validation loss = 3.284986
2018-12-08 21:41:32,677 - INFO - epoch 4, step 26500, training loss = 3.121328, validation loss = 2.898188
2018-12-08 21:41:49,199 - INFO - epoch 4, step 26550, training loss = 3.153232, validation loss = 3.193120
2018-12-08 21:42:04,505 - INFO - epoch 4, step 26600, training loss = 3.064003, validation loss = 3.389039
2018-12-08 21:42:19,962 - INFO - epoch 4, step 26650, training loss = 2.583136, validation loss = 3.073920
2018-12-08 21:42:35,512 - INFO - epoch 4, step 26700, training loss = 2.369979, validation loss = 2.801810
2018-12-08 21:43:00,906 - INFO - epoch 4, step 26750, training loss = 3.556138, validation loss = 2.709388
2018-12-08 21:43:29,064 - INFO - epoch 4, step 26800, training loss = 3.126485, validation loss = 3.260926
2018-12-08 21:43:56,815 - INFO - epoch 4, step 26850, training loss = 2.885320, validation loss = 3.085281
2018-12-08 21:44:22,767 - INFO - epoch 4, step 26900, training loss = 3.106556, validation loss = 3.216109
2018-12-08 21:44:48,542 - INFO - epoch 4, step 26950, training loss = 3.254075, validation loss = 3.308564
2018-12-08 21:45:15,177 - INFO - epoch 4, step 27000, training loss = 3.564986, validation loss = 3.208742
2018-12-08 21:45:40,656 - INFO - epoch 4, step 27050, training loss = 3.224087, validation loss = 3.166130
2018-12-08 21:46:01,899 - INFO - epoch 4, step 27100, training loss = 3.082659, validation loss = 2.986686
2018-12-08 21:46:20,633 - INFO - epoch 4, step 27150, training loss = 3.932304, validation loss = 2.805435
2018-12-08 21:46:44,214 - INFO - epoch 4, step 27200, training loss = 3.042857, validation loss = 3.029243
2018-12-08 21:47:09,713 - INFO - epoch 4, step 27250, training loss = 3.258603, validation loss = 3.125276
2018-12-08 21:47:34,626 - INFO - epoch 4, step 27300, training loss = 3.412121, validation loss = 3.298513
2018-12-08 21:47:56,597 - INFO - epoch 4, step 27350, training loss = 2.785973, validation loss = 2.717756
2018-12-08 21:48:17,500 - INFO - epoch 4, step 27400, training loss = 2.960946, validation loss = 3.024938
2018-12-08 21:48:32,951 - INFO - epoch 4, step 27450, training loss = 3.077409, validation loss = 3.212188
2018-12-08 21:48:48,587 - INFO - epoch 4, step 27500, training loss = 2.771076, validation loss = 2.693527
2018-12-08 21:49:04,443 - INFO - epoch 4, step 27550, training loss = 2.364944, validation loss = 2.723545
2018-12-08 21:49:23,308 - INFO - epoch 4, step 27600, training loss = 3.316838, validation loss = 3.305267
2018-12-08 21:49:48,301 - INFO - epoch 4, step 27650, training loss = 3.260791, validation loss = 3.283897
2018-12-08 21:50:16,613 - INFO - epoch 4, step 27700, training loss = 3.332655, validation loss = 2.896749
2018-12-08 21:50:45,436 - INFO - epoch 4, step 27750, training loss = 3.291677, validation loss = 3.405646
2018-12-08 21:51:11,318 - INFO - epoch 4, step 27800, training loss = 2.930197, validation loss = 3.040050
2018-12-08 21:51:36,573 - INFO - epoch 4, step 27850, training loss = 2.716506, validation loss = 2.923012
2018-12-08 21:52:02,123 - INFO - epoch 4, step 27900, training loss = 2.900273, validation loss = 3.370192
2018-12-08 21:52:27,385 - INFO - epoch 4, step 27950, training loss = 2.590444, validation loss = 3.152384
2018-12-08 21:52:53,126 - INFO - epoch 4, step 28000, training loss = 3.004469, validation loss = 3.309629
2018-12-08 21:53:19,331 - INFO - epoch 4, step 28050, training loss = 2.803403, validation loss = 3.174498
2018-12-08 21:53:46,485 - INFO - epoch 4, step 28100, training loss = 2.634358, validation loss = 3.216339
2018-12-08 21:54:12,326 - INFO - epoch 4, step 28150, training loss = 3.242067, validation loss = 3.023403
2018-12-08 21:54:37,815 - INFO - epoch 4, step 28200, training loss = 3.058265, validation loss = 3.462663
2018-12-08 21:55:03,295 - INFO - epoch 4, step 28250, training loss = 2.584993, validation loss = 3.295341
2018-12-08 21:55:28,765 - INFO - epoch 4, step 28300, training loss = 3.140080, validation loss = 3.066982
2018-12-08 21:55:54,283 - INFO - epoch 4, step 28350, training loss = 3.370142, validation loss = 3.204420
2018-12-08 21:56:16,466 - INFO - epoch 4, step 28400, training loss = 2.892121, validation loss = 2.911441
2018-12-08 21:56:43,212 - INFO - epoch 4, step 28450, training loss = 3.277044, validation loss = 3.390247
2018-12-08 21:57:12,392 - INFO - epoch 4, step 28500, training loss = 3.121083, validation loss = 2.922511
2018-12-08 21:57:30,681 - INFO - epoch 4, step 28550, training loss = 2.843204, validation loss = 2.930599
2018-12-08 21:57:46,384 - INFO - epoch 4, step 28600, training loss = 3.205846, validation loss = 2.862638
2018-12-08 21:58:01,858 - INFO - epoch 4, step 28650, training loss = 3.066142, validation loss = 3.376345
2018-12-08 21:58:23,112 - INFO - epoch 4, step 28700, training loss = 3.424797, validation loss = 3.160847
2018-12-08 21:58:48,260 - INFO - epoch 4, step 28750, training loss = 3.025817, validation loss = 3.111187
2018-12-08 21:59:13,442 - INFO - epoch 4, step 28800, training loss = 3.009394, validation loss = 3.263649
2018-12-08 21:59:39,010 - INFO - epoch 4, step 28850, training loss = 2.957963, validation loss = 3.242021
2018-12-08 22:00:04,289 - INFO - epoch 4, step 28900, training loss = 2.717625, validation loss = 3.059756
2018-12-08 22:00:30,020 - INFO - epoch 4, step 28950, training loss = 3.009440, validation loss = 3.353428
2018-12-08 22:00:56,436 - INFO - epoch 4, step 29000, training loss = 2.804535, validation loss = 2.975143
2018-12-08 22:01:21,843 - INFO - epoch 4, step 29050, training loss = 2.880804, validation loss = 3.010357
2018-12-08 22:01:43,392 - INFO - epoch 4, step 29100, training loss = 3.270905, validation loss = 2.993817
2018-12-08 22:02:09,909 - INFO - epoch 4, step 29150, training loss = 3.154620, validation loss = 3.380691
2018-12-08 22:02:38,316 - INFO - epoch 4, step 29200, training loss = 2.808151, validation loss = 2.701703
2018-12-08 22:03:05,624 - INFO - epoch 4, step 29250, training loss = 3.157796, validation loss = 3.013596
2018-12-08 22:03:31,928 - INFO - epoch 4, step 29300, training loss = 3.218753, validation loss = 2.932307
2018-12-08 22:03:57,751 - INFO - epoch 4, step 29350, training loss = 2.910176, validation loss = 3.380502
2018-12-08 22:04:24,563 - INFO - epoch 4, step 29400, training loss = 2.981120, validation loss = 2.803412
2018-12-08 22:04:50,939 - INFO - epoch 4, step 29450, training loss = 3.347422, validation loss = 2.947860
2018-12-08 22:05:16,621 - INFO - epoch 4, step 29500, training loss = 3.313496, validation loss = 3.381508
2018-12-08 22:05:43,352 - INFO - epoch 4, step 29550, training loss = 3.264859, validation loss = 3.110516
2018-12-08 22:06:09,568 - INFO - epoch 4, step 29600, training loss = 2.962752, validation loss = 3.073783
2018-12-08 22:06:35,991 - INFO - epoch 4, step 29650, training loss = 2.767511, validation loss = 2.775789
2018-12-08 22:07:01,062 - INFO - epoch 4, step 29700, training loss = 2.897246, validation loss = 3.310825
2018-12-08 22:07:22,277 - INFO - epoch 4, step 29750, training loss = 2.941704, validation loss = 2.818037
2018-12-08 22:07:46,956 - INFO - epoch 4, step 29800, training loss = 2.886558, validation loss = 2.793810
2018-12-08 22:08:13,668 - INFO - epoch 4, step 29850, training loss = 2.722193, validation loss = 3.145930
2018-12-08 22:08:40,329 - INFO - epoch 4, step 29900, training loss = 3.078820, validation loss = 3.043498
2018-12-08 22:09:06,061 - INFO - epoch 4, step 29950, training loss = 2.930216, validation loss = 2.985579
2018-12-08 22:09:32,215 - INFO - epoch 4, step 30000, training loss = 2.883945, validation loss = 2.939325
2018-12-08 22:09:57,845 - INFO - epoch 4, step 30050, training loss = 2.681348, validation loss = 2.709295
2018-12-08 22:10:19,604 - INFO - epoch 4, step 30100, training loss = 3.583946, validation loss = 2.826022
2018-12-08 22:10:35,599 - INFO - epoch 4, step 30150, training loss = 2.474192, validation loss = 2.895705
2018-12-08 22:10:51,406 - INFO - epoch 4, step 30200, training loss = 3.060541, validation loss = 2.624090
2018-12-08 22:11:15,043 - INFO - epoch 4, step 30250, training loss = 2.995844, validation loss = 3.013792
2018-12-08 22:11:40,247 - INFO - epoch 4, step 30300, training loss = 2.787722, validation loss = 2.953486
2018-12-08 22:12:05,356 - INFO - epoch 4, step 30350, training loss = 3.318097, validation loss = 2.880974
2018-12-08 22:12:33,877 - INFO - epoch 4, step 30400, training loss = 2.968076, validation loss = 2.467052
2018-12-08 22:13:01,999 - INFO - epoch 4, step 30450, training loss = 3.087301, validation loss = 2.793037
2018-12-08 22:13:29,036 - INFO - epoch 4, step 30500, training loss = 3.124757, validation loss = 2.456298
2018-12-08 22:13:56,207 - INFO - epoch 4, step 30550, training loss = 3.435599, validation loss = 2.824695
2018-12-08 22:14:23,500 - INFO - epoch 4, step 30600, training loss = 3.325481, validation loss = 3.007013
2018-12-08 22:14:52,767 - INFO - epoch 4, step 30650, training loss = 3.292531, validation loss = 2.720719
2018-12-08 22:15:21,560 - INFO - epoch 4, step 30700, training loss = 3.171794, validation loss = 2.879813
2018-12-08 22:15:48,624 - INFO - epoch 4, step 30750, training loss = 4.116002, validation loss = 2.834495
2018-12-08 22:16:02,196 - INFO - epoch 4, step 30800, training loss = 3.120986, validation loss = 3.236655
2018-12-08 22:16:16,908 - INFO - epoch 4, step 30850, training loss = 3.136107, validation loss = 2.960074
2018-12-08 22:16:37,521 - INFO - epoch 4, step 30900, training loss = 2.999157, validation loss = 2.699427
2018-12-08 22:17:04,122 - INFO - epoch 4, step 30950, training loss = 3.180313, validation loss = 2.666259
2018-12-08 22:17:34,494 - INFO - epoch 4, step 31000, training loss = 2.862990, validation loss = 2.977388
2018-12-08 22:18:03,633 - INFO - epoch 4, step 31050, training loss = 3.152508, validation loss = 2.862386
2018-12-08 22:18:21,606 - INFO - epoch 4, step 31100, training loss = 2.735687, validation loss = 2.700779
2018-12-08 22:18:37,333 - INFO - epoch 4, step 31150, training loss = 2.592017, validation loss = 2.847286
2018-12-08 22:18:53,916 - INFO - epoch 4, step 31200, training loss = 3.040653, validation loss = 2.787482
2018-12-08 22:19:14,456 - INFO - epoch 4, step 31250, training loss = 3.646420, validation loss = 2.994921
2018-12-08 22:19:32,498 - INFO - epoch 4, step 31300, training loss = 3.033862, validation loss = 3.001732
2018-12-08 22:19:44,419 - INFO - epoch 4, step 31350, training loss = 2.207862, validation loss = 3.137956
2018-12-08 22:19:56,483 - INFO - epoch 4, step 31400, training loss = 2.788219, validation loss = 2.924482
2018-12-08 22:20:08,835 - INFO - epoch 4, step 31450, training loss = 3.096812, validation loss = 3.316805
2018-12-08 22:20:24,564 - INFO - epoch 4, step 31500, training loss = 2.652478, validation loss = 2.911999
2018-12-08 22:20:40,448 - INFO - epoch 4, step 31550, training loss = 3.074537, validation loss = 3.010680
2018-12-08 22:21:02,904 - INFO - epoch 4, step 31600, training loss = 3.647218, validation loss = 2.757031
2018-12-08 22:21:28,316 - INFO - epoch 4, step 31650, training loss = 2.733487, validation loss = 2.678452
2018-12-08 22:21:54,682 - INFO - epoch 4, step 31700, training loss = 3.438276, validation loss = 3.238887
2018-12-08 22:22:20,121 - INFO - epoch 4, step 31750, training loss = 3.433232, validation loss = 3.163731
2018-12-08 22:22:42,345 - INFO - epoch 4, step 31800, training loss = 2.908506, validation loss = 3.123548
2018-12-08 22:22:53,953 - INFO - epoch 4, step 31850, training loss = 2.763986, validation loss = 3.054291
2018-12-08 22:23:05,473 - INFO - epoch 4, step 31900, training loss = 2.770220, validation loss = 3.100688
2018-12-08 22:23:23,724 - INFO - epoch 4, step 31950, training loss = 2.878129, validation loss = 2.614240
2018-12-08 22:23:53,455 - INFO - epoch 4, step 32000, training loss = 3.160310, validation loss = 3.063635
2018-12-08 22:24:21,488 - INFO - epoch 4, step 32050, training loss = 3.547189, validation loss = 2.514587
2018-12-08 22:24:51,496 - INFO - epoch 4, step 32100, training loss = 3.041203, validation loss = 2.894946
2018-12-08 22:25:09,607 - INFO - epoch 4, step 32150, training loss = 2.420435, validation loss = 3.318127
2018-12-08 22:25:21,387 - INFO - epoch 4, step 32200, training loss = 2.824516, validation loss = 2.991257
2018-12-08 22:25:33,238 - INFO - epoch 4, step 32250, training loss = 2.728707, validation loss = 2.594466
2018-12-08 22:25:54,182 - INFO - epoch 4, step 32300, training loss = 3.602052, validation loss = 2.527394
2018-12-08 22:26:19,916 - INFO - epoch 4, step 32350, training loss = 3.308231, validation loss = 3.070495
2018-12-08 22:26:45,620 - INFO - epoch 4, step 32400, training loss = 3.177831, validation loss = 2.531870
2018-12-08 22:27:10,865 - INFO - epoch 4, step 32450, training loss = 3.211312, validation loss = 2.579560
2018-12-08 22:27:36,550 - INFO - epoch 4, step 32500, training loss = 3.270785, validation loss = 2.857449
2018-12-08 22:27:59,082 - INFO - epoch 4, step 32550, training loss = 2.895702, validation loss = 2.585566
2018-12-08 22:28:18,815 - INFO - epoch 4, step 32600, training loss = 3.209305, validation loss = 2.680164
2018-12-08 22:28:34,933 - INFO - epoch 4, step 32650, training loss = 3.149953, validation loss = 2.856354
2018-12-08 22:29:00,525 - INFO - epoch 4, step 32700, training loss = 3.135831, validation loss = 2.756571
2018-12-08 22:29:26,431 - INFO - epoch 4, step 32750, training loss = 2.638618, validation loss = 2.992168
2018-12-08 22:29:51,164 - INFO - epoch 4, step 32800, training loss = 3.278574, validation loss = 2.542024
2018-12-08 22:30:17,094 - INFO - epoch 4, step 32850, training loss = 2.789168, validation loss = 2.704182
2018-12-08 22:30:43,112 - INFO - epoch 4, step 32900, training loss = 3.141750, validation loss = 2.735120
2018-12-08 22:31:11,306 - INFO - epoch 4, step 32950, training loss = 3.215814, validation loss = 3.114911
2018-12-08 22:31:39,609 - INFO - epoch 4, step 33000, training loss = 3.291859, validation loss = 2.736459
2018-12-08 22:32:00,798 - INFO - epoch 4, step 33050, training loss = 3.010344, validation loss = 2.807737
2018-12-08 22:32:19,629 - INFO - epoch 4, step 33100, training loss = 3.187845, validation loss = 2.872429
2018-12-08 22:32:37,678 - INFO - epoch 4, step 33150, training loss = 3.679268, validation loss = 2.989419
2018-12-08 22:33:01,773 - INFO - epoch 4, step 33200, training loss = 2.990520, validation loss = 2.512008
2018-12-08 22:33:29,781 - INFO - epoch 4, step 33250, training loss = 2.786579, validation loss = 2.525467
2018-12-08 22:33:56,912 - INFO - epoch 4, step 33300, training loss = 3.319624, validation loss = 2.760035
2018-12-08 22:34:25,682 - INFO - epoch 4, step 33350, training loss = 2.880554, validation loss = 2.575656
2018-12-08 22:34:50,590 - INFO - epoch 4, step 33400, training loss = 3.044245, validation loss = 3.075784
2018-12-08 22:35:14,264 - INFO - epoch 4, step 33450, training loss = 3.045111, validation loss = 3.018666
2018-12-08 22:35:39,227 - INFO - epoch 4, step 33500, training loss = 3.685246, validation loss = 2.399427
2018-12-08 22:36:05,217 - INFO - epoch 4, step 33550, training loss = 3.046406, validation loss = 2.732430
2018-12-08 22:36:31,171 - INFO - epoch 4, step 33600, training loss = 2.534407, validation loss = 2.789234
2018-12-08 22:36:58,380 - INFO - epoch 4, step 33650, training loss = 3.309927, validation loss = 2.856892
2018-12-08 22:37:25,925 - INFO - epoch 4, step 33700, training loss = 2.724447, validation loss = 3.137361
2018-12-08 22:37:53,161 - INFO - epoch 4, step 33750, training loss = 3.540371, validation loss = 2.653905
2018-12-08 22:38:20,954 - INFO - epoch 4, step 33800, training loss = 2.725674, validation loss = 2.848989
2018-12-08 22:38:49,149 - INFO - epoch 4, step 33850, training loss = 2.732748, validation loss = 2.890173
2018-12-08 22:39:15,313 - INFO - epoch 4, step 33900, training loss = 3.447534, validation loss = 2.911643
2018-12-08 22:39:43,100 - INFO - epoch 4, step 33950, training loss = 2.909099, validation loss = 3.017718
2018-12-08 22:40:10,446 - INFO - epoch 4, step 34000, training loss = 3.199400, validation loss = 2.534373
2018-12-08 22:40:36,216 - INFO - epoch 4, step 34050, training loss = 2.810952, validation loss = 3.215814
2018-12-08 22:40:58,119 - INFO - epoch 4, step 34100, training loss = 2.263238, validation loss = 2.775174
2018-12-08 22:41:09,919 - INFO - epoch 4, step 34150, training loss = 2.941018, validation loss = 3.266637
2018-12-08 22:41:22,134 - INFO - epoch 4, step 34200, training loss = 2.308627, validation loss = 3.251882
2018-12-08 22:41:43,141 - INFO - epoch 4, step 34250, training loss = 3.066669, validation loss = 3.093952
2018-12-08 22:42:09,385 - INFO - epoch 4, step 34300, training loss = 3.417675, validation loss = 3.045915
2018-12-08 22:42:36,364 - INFO - epoch 4, step 34350, training loss = 3.002896, validation loss = 2.702260
2018-12-08 22:43:03,312 - INFO - epoch 4, step 34400, training loss = 2.746509, validation loss = 3.263894
2018-12-08 22:43:29,779 - INFO - epoch 4, step 34450, training loss = 2.815372, validation loss = 2.981041
2018-12-08 22:43:49,022 - INFO - epoch 4, step 34500, training loss = 2.980788, validation loss = 2.958853
2018-12-08 22:44:04,748 - INFO - epoch 4, step 34550, training loss = 3.244233, validation loss = 2.873527
2018-12-08 22:44:20,778 - INFO - epoch 4, step 34600, training loss = 2.553639, validation loss = 2.621017
2018-12-08 22:44:39,137 - INFO - epoch 4, step 34650, training loss = 3.727855, validation loss = 2.752119
2018-12-08 22:45:07,946 - INFO - epoch 4, step 34700, training loss = 2.901783, validation loss = 2.905842
2018-12-08 22:45:36,390 - INFO - epoch 4, step 34750, training loss = 2.866911, validation loss = 2.953887
2018-12-08 22:46:06,040 - INFO - epoch 4, step 34800, training loss = 3.587531, validation loss = 3.221801
2018-12-08 22:46:31,197 - INFO - epoch 4, step 34850, training loss = 3.321715, validation loss = 2.860631
2018-12-08 22:47:03,987 - INFO - epoch 4, step 34900, training loss = 3.079576, validation loss = 3.166112
2018-12-08 22:47:31,482 - INFO - epoch 4, step 34950, training loss = 3.166003, validation loss = 2.819857
2018-12-08 22:47:57,563 - INFO - epoch 4, step 35000, training loss = 3.471826, validation loss = 3.112740
2018-12-08 22:48:23,204 - INFO - epoch 4, step 35050, training loss = 3.147829, validation loss = 2.779490
2018-12-08 22:48:37,630 - INFO - epoch 4, step 35100, training loss = 2.635936, validation loss = 3.052741
2018-12-08 22:48:49,772 - INFO - epoch 4, step 35150, training loss = 2.780823, validation loss = 3.005549
2018-12-08 22:49:01,433 - INFO - epoch 4, step 35200, training loss = 2.875809, validation loss = 2.751081
2018-12-08 22:49:19,014 - INFO - epoch 4, step 35250, training loss = 3.278838, validation loss = 2.811372
2018-12-08 22:49:41,609 - INFO - epoch 4, step 35300, training loss = 2.918618, validation loss = 2.733004
2018-12-08 22:50:05,186 - INFO - epoch 4, step 35350, training loss = 3.255336, validation loss = 2.701509
2018-12-08 22:50:28,465 - INFO - epoch 4, step 35400, training loss = 3.215899, validation loss = 2.898414
2018-12-08 22:50:51,793 - INFO - epoch 4, step 35450, training loss = 3.197220, validation loss = 2.962244
2018-12-08 22:51:14,912 - INFO - epoch 4, step 35500, training loss = 3.311343, validation loss = 2.731846
2018-12-08 22:51:37,967 - INFO - epoch 4, step 35550, training loss = 3.528758, validation loss = 3.256716
2018-12-08 22:52:04,551 - INFO - epoch 4, step 35600, training loss = 3.272059, validation loss = 2.817531
2018-12-08 22:52:35,229 - INFO - epoch 4, step 35650, training loss = 3.178291, validation loss = 2.990404
2018-12-08 22:53:03,266 - INFO - epoch 4, step 35700, training loss = 3.083148, validation loss = 3.128927
2018-12-08 22:53:25,024 - INFO - epoch 4, step 35750, training loss = 3.615111, validation loss = 2.951417
2018-12-08 22:53:44,406 - INFO - epoch 4, step 35800, training loss = 2.925676, validation loss = 2.993304
2018-12-08 22:54:04,280 - INFO - epoch 4, step 35850, training loss = 3.138930, validation loss = 2.769145
2018-12-08 22:54:23,822 - INFO - epoch 4, step 35900, training loss = 2.847623, validation loss = 2.679226
2018-12-08 22:54:43,840 - INFO - epoch 4, step 35950, training loss = 2.710944, validation loss = 2.515064
2018-12-08 22:55:04,073 - INFO - epoch 4, step 36000, training loss = 2.822413, validation loss = 2.863556
2018-12-08 22:55:24,070 - INFO - epoch 4, step 36050, training loss = 3.047750, validation loss = 2.537962
2018-12-08 22:55:44,750 - INFO - epoch 4, step 36100, training loss = 3.003827, validation loss = 2.645178
2018-12-08 22:56:05,217 - INFO - epoch 4, step 36150, training loss = 2.478820, validation loss = 2.606710
2018-12-08 22:56:24,573 - INFO - epoch 4, step 36200, training loss = 2.458259, validation loss = 2.577826
2018-12-08 22:56:43,700 - INFO - epoch 4, step 36250, training loss = 3.162265, validation loss = 2.999068
2018-12-08 22:57:03,193 - INFO - epoch 4, step 36300, training loss = 2.889298, validation loss = 2.779737
2018-12-08 22:57:22,303 - INFO - epoch 4, step 36350, training loss = 2.542430, validation loss = 3.060616
2018-12-08 22:57:41,201 - INFO - epoch 4, step 36400, training loss = 3.057101, validation loss = 2.840015
2018-12-08 22:57:59,662 - INFO - epoch 4, step 36450, training loss = 2.738719, validation loss = 2.853507
2018-12-08 22:58:18,893 - INFO - epoch 4, step 36500, training loss = 2.792452, validation loss = 2.689137
2018-12-08 22:58:38,634 - INFO - epoch 4, step 36550, training loss = 2.698260, validation loss = 3.167757
2018-12-08 22:58:58,191 - INFO - epoch 4, step 36600, training loss = 2.667192, validation loss = 2.526958
2018-12-08 22:59:17,793 - INFO - epoch 4, step 36650, training loss = 3.471340, validation loss = 2.717682
2018-12-08 22:59:37,065 - INFO - epoch 4, step 36700, training loss = 2.703188, validation loss = 2.761227
2018-12-08 22:59:57,679 - INFO - epoch 4, step 36750, training loss = 2.534889, validation loss = 3.042266
2018-12-08 23:00:17,348 - INFO - epoch 4, step 36800, training loss = 4.660812, validation loss = 2.803070
2018-12-08 23:00:37,168 - INFO - epoch 4, step 36850, training loss = 4.690796, validation loss = 2.562400
2018-12-08 23:00:56,531 - INFO - epoch 4, step 36900, training loss = 4.230447, validation loss = 2.804919
2018-12-08 23:01:14,872 - INFO - epoch 4, step 36950, training loss = 4.461478, validation loss = 2.710240
2018-12-08 23:01:33,210 - INFO - epoch 4, step 37000, training loss = 4.009925, validation loss = 2.819252
2018-12-08 23:01:51,693 - INFO - epoch 4, step 37050, training loss = 4.142337, validation loss = 2.709062
2018-12-08 23:02:10,012 - INFO - epoch 4, step 37100, training loss = 4.242533, validation loss = 2.759593
2018-12-08 23:02:27,557 - INFO - epoch 4, step 37150, training loss = 4.133977, validation loss = 2.593590
2018-12-08 23:02:45,766 - INFO - epoch 4, step 37200, training loss = 4.415378, validation loss = 2.868756
2018-12-08 23:03:04,085 - INFO - epoch 4, step 37250, training loss = 3.994781, validation loss = 2.594705
2018-12-08 23:03:21,655 - INFO - epoch 4, step 37300, training loss = 4.522451, validation loss = 3.011753
2018-12-08 23:03:38,456 - INFO - epoch 4, step 37350, training loss = 4.302148, validation loss = 3.025841
2018-12-08 23:03:56,060 - INFO - epoch 4, step 37400, training loss = 4.064836, validation loss = 2.972420
2018-12-08 23:04:13,687 - INFO - epoch 4, step 37450, training loss = 4.009542, validation loss = 2.825869
2018-12-08 23:04:31,885 - INFO - epoch 4, step 37500, training loss = 4.666871, validation loss = 3.047077
2018-12-08 23:04:49,687 - INFO - epoch 4, step 37550, training loss = 4.397255, validation loss = 3.213542
2018-12-08 23:05:07,748 - INFO - epoch 4, step 37600, training loss = 4.106222, validation loss = 2.820388
2018-12-08 23:05:25,995 - INFO - epoch 4, step 37650, training loss = 4.615499, validation loss = 3.032926
2018-12-08 23:05:46,345 - INFO - epoch 4, step 37700, training loss = 4.749546, validation loss = 3.048454
2018-12-08 23:06:06,677 - INFO - epoch 4, step 37750, training loss = 4.784898, validation loss = 2.909876
2018-12-08 23:06:25,857 - INFO - epoch 4, step 37800, training loss = 4.263379, validation loss = 2.943763
2018-12-08 23:06:46,652 - INFO - epoch 4, step 37850, training loss = 4.196188, validation loss = 3.033156
2018-12-08 23:07:07,576 - INFO - epoch 4, step 37900, training loss = 4.430320, validation loss = 2.706018
2018-12-08 23:07:26,436 - INFO - epoch 4, step 37950, training loss = 3.903494, validation loss = 2.946709
2018-12-08 23:07:45,214 - INFO - epoch 4, step 38000, training loss = 3.932339, validation loss = 2.946220
2018-12-08 23:08:05,236 - INFO - epoch 4, step 38050, training loss = 4.685544, validation loss = 2.653573
2018-12-08 23:08:24,592 - INFO - epoch 4, step 38100, training loss = 4.550373, validation loss = 2.750519
2018-12-08 23:08:43,377 - INFO - epoch 4, step 38150, training loss = 3.666735, validation loss = 3.313915
2018-12-08 23:09:03,545 - INFO - epoch 4, step 38200, training loss = 3.781814, validation loss = 2.948347
2018-12-08 23:09:25,042 - INFO - epoch 4, step 38250, training loss = 3.972790, validation loss = 2.851347
2018-12-08 23:09:48,576 - INFO - epoch 4, step 38300, training loss = 4.451762, validation loss = 3.434160
2018-12-08 23:10:17,400 - INFO - epoch 4, step 38350, training loss = 4.587549, validation loss = 3.004814
2018-12-08 23:10:48,131 - INFO - epoch 4, step 38400, training loss = 4.831583, validation loss = 2.850886
2018-12-08 23:11:09,858 - INFO - epoch 4, step 38450, training loss = 4.595635, validation loss = 2.984658
2018-12-08 23:11:37,889 - INFO - epoch 4, step 38500, training loss = 4.771693, validation loss = 3.462584
2018-12-08 23:12:05,636 - INFO - epoch 4, step 38550, training loss = 4.265275, validation loss = 2.891114
2018-12-08 23:12:26,078 - INFO - epoch 4, step 38600, training loss = 3.782039, validation loss = 2.890224
2018-12-08 23:12:48,251 - INFO - epoch 4, step 38650, training loss = 3.658363, validation loss = 2.811467
2018-12-08 23:13:09,802 - INFO - epoch 4, step 38700, training loss = 4.197189, validation loss = 2.905691
2018-12-08 23:13:37,651 - INFO - epoch 4, step 38750, training loss = 4.432324, validation loss = 3.018697
2018-12-08 23:14:07,414 - INFO - epoch 4, step 38800, training loss = 4.473899, validation loss = 2.915216
2018-12-08 23:14:36,885 - INFO - epoch 4, step 38850, training loss = 4.919550, validation loss = 2.858145
2018-12-08 23:15:05,853 - INFO - epoch 4, step 38900, training loss = 4.511980, validation loss = 3.099048
2018-12-08 23:15:34,442 - INFO - epoch 4, step 38950, training loss = 4.514286, validation loss = 3.018609
2018-12-08 23:15:58,110 - INFO - epoch 4, step 39000, training loss = 4.529238, validation loss = 3.117774
2018-12-08 23:16:25,527 - INFO - epoch 4, step 39050, training loss = 4.300392, validation loss = 2.957941
2018-12-08 23:16:54,196 - INFO - epoch 4, step 39100, training loss = 4.232862, validation loss = 3.020025
2018-12-08 23:17:15,960 - INFO - epoch 4, step 39150, training loss = 4.190437, validation loss = 3.271490
2018-12-08 23:17:37,319 - INFO - epoch 4, step 39200, training loss = 4.196067, validation loss = 2.911867
2018-12-08 23:18:06,551 - INFO - epoch 4, step 39250, training loss = 4.476631, validation loss = 3.188407
2018-12-08 23:18:35,119 - INFO - epoch 4, step 39300, training loss = 4.515655, validation loss = 3.036566
2018-12-08 23:18:58,802 - INFO - epoch 4, step 39350, training loss = 3.989481, validation loss = 3.303162
2018-12-08 23:19:18,774 - INFO - epoch 4, step 39400, training loss = 4.655425, validation loss = 3.242242
2018-12-08 23:19:48,363 - INFO - epoch 4, step 39450, training loss = 4.302885, validation loss = 3.232672
2018-12-08 23:20:12,678 - INFO - epoch 4, step 39500, training loss = 4.011658, validation loss = 3.219194
2018-12-08 23:20:35,778 - INFO - epoch 4, step 39550, training loss = 4.273252, validation loss = 3.022281
2018-12-08 23:21:03,637 - INFO - epoch 4, step 39600, training loss = 4.639398, validation loss = 3.090032
2018-12-08 23:21:32,738 - INFO - epoch 4, step 39650, training loss = 4.347738, validation loss = 2.816576
2018-12-08 23:22:03,451 - INFO - epoch 4, step 39700, training loss = 4.653360, validation loss = 2.945624
2018-12-08 23:22:30,661 - INFO - epoch 4, step 39750, training loss = 4.185531, validation loss = 3.075810
2018-12-08 23:22:52,298 - INFO - epoch 4, step 39800, training loss = 3.816776, validation loss = 3.186775
2018-12-08 23:23:15,123 - INFO - epoch 4, step 39850, training loss = 3.893632, validation loss = 3.127361
2018-12-08 23:23:42,341 - INFO - epoch 4, step 39900, training loss = 3.789815, validation loss = 2.960853
2018-12-08 23:24:11,909 - INFO - epoch 4, step 39950, training loss = 4.330686, validation loss = 2.962748
2018-12-08 23:24:37,217 - INFO - epoch 4, step 40000, training loss = 4.262804, validation loss = 3.264263
2018-12-08 23:24:57,226 - INFO - epoch 4, step 40050, training loss = 4.277842, validation loss = 3.074471
2018-12-08 23:25:18,313 - INFO - epoch 4, step 40100, training loss = 4.445411, validation loss = 3.196476
2018-12-08 23:25:38,312 - INFO - epoch 4, step 40150, training loss = 4.271574, validation loss = 2.907325
2018-12-08 23:25:59,381 - INFO - epoch 4, step 40200, training loss = 4.154397, validation loss = 3.321635
2018-12-08 23:26:21,110 - INFO - epoch 4, step 40250, training loss = 3.574950, validation loss = 3.222369
2018-12-08 23:26:43,789 - INFO - epoch 4, step 40300, training loss = 3.979067, validation loss = 2.919779
2018-12-08 23:27:05,799 - INFO - epoch 4, step 40350, training loss = 4.346603, validation loss = 2.990150
2018-12-08 23:27:26,966 - INFO - epoch 4, step 40400, training loss = 4.087468, validation loss = 3.161367
2018-12-08 23:27:53,990 - INFO - epoch 4, step 40450, training loss = 4.583515, validation loss = 2.953676
2018-12-08 23:28:15,392 - INFO - epoch 4, step 40500, training loss = 3.991454, validation loss = 3.000272
2018-12-08 23:28:36,492 - INFO - epoch 4, step 40550, training loss = 4.366177, validation loss = 3.257603
2018-12-08 23:29:02,468 - INFO - epoch 4, step 40600, training loss = 4.103790, validation loss = 3.016466
2018-12-08 23:29:30,569 - INFO - epoch 4, step 40650, training loss = 4.394825, validation loss = 3.227939
2018-12-08 23:30:00,289 - INFO - epoch 4, step 40700, training loss = 3.341130, validation loss = 3.410328
2018-12-08 23:30:23,832 - INFO - epoch 4, step 40750, training loss = 3.934415, validation loss = 3.159847
2018-12-08 23:30:46,794 - INFO - epoch 4, step 40800, training loss = 4.047496, validation loss = 2.739308
2018-12-08 23:31:10,304 - INFO - epoch 4, step 40850, training loss = 4.141841, validation loss = 3.322005
2018-12-08 23:31:31,945 - INFO - epoch 4, step 40900, training loss = 3.971975, validation loss = 3.035111
2018-12-08 23:31:53,865 - INFO - epoch 4, step 40950, training loss = 4.196944, validation loss = 3.312556
2018-12-08 23:32:16,688 - INFO - epoch 4, step 41000, training loss = 4.312600, validation loss = 2.964772
2018-12-08 23:32:39,664 - INFO - epoch 4, step 41050, training loss = 3.542484, validation loss = 3.228107
2018-12-08 23:33:02,282 - INFO - epoch 4, step 41100, training loss = 4.534204, validation loss = 3.629114
2018-12-08 23:33:24,389 - INFO - epoch 4, step 41150, training loss = 3.827154, validation loss = 3.220790
2018-12-08 23:33:46,648 - INFO - epoch 4, step 41200, training loss = 3.736630, validation loss = 2.827942
2018-12-08 23:34:09,035 - INFO - epoch 4, step 41250, training loss = 4.154004, validation loss = 2.821864
2018-12-08 23:34:30,880 - INFO - epoch 4, step 41300, training loss = 4.120979, validation loss = 3.122224
2018-12-08 23:34:51,713 - INFO - epoch 4, step 41350, training loss = 3.846012, validation loss = 2.617522
2018-12-08 23:35:18,136 - INFO - epoch 4, step 41400, training loss = 4.256649, validation loss = 3.225507
2018-12-08 23:35:49,529 - INFO - epoch 4, step 41450, training loss = 4.576240, validation loss = 3.306524
2018-12-08 23:36:17,242 - INFO - epoch 4, step 41500, training loss = 4.178822, validation loss = 2.632460
2018-12-08 23:36:40,317 - INFO - epoch 4, step 41550, training loss = 4.395441, validation loss = 2.852228
2018-12-08 23:37:09,929 - INFO - epoch 4, step 41600, training loss = 4.887436, validation loss = 3.261184
2018-12-08 23:37:37,916 - INFO - epoch 4, step 41650, training loss = 3.334397, validation loss = 2.805426
2018-12-08 23:38:00,778 - INFO - epoch 4, step 41700, training loss = 3.454573, validation loss = 3.304197
2018-12-08 23:38:27,205 - INFO - epoch 4, step 41750, training loss = 4.518194, validation loss = 3.443298
2018-12-08 23:38:50,775 - INFO - epoch 4, step 41800, training loss = 4.153428, validation loss = 3.135716
2018-12-08 23:39:12,540 - INFO - epoch 4, step 41850, training loss = 4.036408, validation loss = 2.852494
2018-12-08 23:39:33,807 - INFO - epoch 4, step 41900, training loss = 4.658698, validation loss = 3.342709
2018-12-08 23:40:02,721 - INFO - epoch 4, step 41950, training loss = 4.507766, validation loss = 2.881470
2018-12-08 23:40:30,910 - INFO - epoch 4, step 42000, training loss = 4.114846, validation loss = 2.948796
2018-12-08 23:40:50,985 - INFO - epoch 4, step 42050, training loss = 3.938479, validation loss = 3.257993
2018-12-08 23:41:11,847 - INFO - epoch 4, step 42100, training loss = 3.956480, validation loss = 2.861174
2018-12-08 23:41:37,935 - INFO - epoch 4, step 42150, training loss = 4.473935, validation loss = 2.988214
2018-12-08 23:42:06,546 - INFO - epoch 4, step 42200, training loss = 4.679556, validation loss = 2.829417
2018-12-08 23:42:29,254 - INFO - epoch 4, step 42250, training loss = 4.298649, validation loss = 2.712358
2018-12-08 23:42:50,463 - INFO - epoch 4, step 42300, training loss = 3.903584, validation loss = 3.062671
2018-12-08 23:43:11,344 - INFO - epoch 4, step 42350, training loss = 3.533135, validation loss = 2.796086
2018-12-08 23:43:33,025 - INFO - epoch 4, step 42400, training loss = 3.110423, validation loss = 3.007511
2018-12-08 23:43:59,311 - INFO - epoch 4, step 42450, training loss = 4.383223, validation loss = 2.923801
2018-12-08 23:44:26,372 - INFO - epoch 4, step 42500, training loss = 4.491706, validation loss = 3.015396
2018-12-08 23:44:52,311 - INFO - epoch 4, step 42550, training loss = 4.705949, validation loss = 3.065620
2018-12-08 23:45:11,733 - INFO - epoch 4, step 42600, training loss = 4.230370, validation loss = 3.351143
2018-12-08 23:45:31,786 - INFO - epoch 4, step 42650, training loss = 4.028295, validation loss = 3.373859
2018-12-08 23:45:52,668 - INFO - epoch 4, step 42700, training loss = 3.234374, validation loss = 3.187816
2018-12-08 23:46:13,984 - INFO - epoch 4, step 42750, training loss = 4.289433, validation loss = 3.375422
2018-12-08 23:46:44,402 - INFO - epoch 4, step 42800, training loss = 4.467936, validation loss = 3.260978
2018-12-08 23:47:10,260 - INFO - epoch 4, step 42850, training loss = 4.456020, validation loss = 2.966144
2018-12-08 23:47:29,346 - INFO - epoch 4, step 42900, training loss = 4.526267, validation loss = 2.980698
2018-12-08 23:47:48,732 - INFO - epoch 4, step 42950, training loss = 4.352127, validation loss = 3.024770
2018-12-08 23:48:10,597 - INFO - epoch 4, step 43000, training loss = 4.068178, validation loss = 3.015401
2018-12-08 23:48:36,676 - INFO - epoch 4, step 43050, training loss = 4.098468, validation loss = 3.069190
2018-12-08 23:49:03,504 - INFO - epoch 4, step 43100, training loss = 4.163529, validation loss = 3.022753
2018-12-08 23:49:24,990 - INFO - epoch 4, step 43150, training loss = 3.833216, validation loss = 2.911010
2018-12-08 23:49:46,877 - INFO - epoch 4, step 43200, training loss = 3.982768, validation loss = 2.721871
2018-12-08 23:50:08,136 - INFO - epoch 4, step 43250, training loss = 4.341809, validation loss = 3.424966
2018-12-08 23:50:37,930 - INFO - epoch 4, step 43300, training loss = 4.150709, validation loss = 3.139701
2018-12-08 23:51:00,168 - INFO - epoch 4, step 43350, training loss = 4.135410, validation loss = 3.023151
2018-12-08 23:51:21,776 - INFO - epoch 4, step 43400, training loss = 3.648201, validation loss = 2.966735
2018-12-08 23:51:44,552 - INFO - epoch 4, step 43450, training loss = 4.156986, validation loss = 3.143106
2018-12-08 23:52:06,629 - INFO - epoch 4, step 43500, training loss = 3.826072, validation loss = 3.004739
2018-12-08 23:52:31,632 - INFO - epoch 4, step 43550, training loss = 4.255665, validation loss = 3.067278
2018-12-08 23:52:53,838 - INFO - epoch 4, step 43600, training loss = 4.293275, validation loss = 3.266361
2018-12-08 23:53:17,263 - INFO - epoch 4, step 43650, training loss = 4.354171, validation loss = 3.003632
2018-12-08 23:53:42,067 - INFO - epoch 4, step 43700, training loss = 4.121686, validation loss = 2.716560
2018-12-08 23:54:03,100 - INFO - epoch 4, step 43750, training loss = 3.733279, validation loss = 3.196010
2018-12-08 23:54:27,557 - INFO - epoch 4, step 43800, training loss = 4.190449, validation loss = 3.359437
2018-12-08 23:54:49,592 - INFO - epoch 4, step 43850, training loss = 4.487041, validation loss = 2.857464
2018-12-08 23:55:09,894 - INFO - epoch 4, step 43900, training loss = 4.236964, validation loss = 3.316911
2018-12-08 23:55:30,972 - INFO - epoch 4, step 43950, training loss = 3.587893, validation loss = 3.557216
2018-12-08 23:55:52,523 - INFO - epoch 4, step 44000, training loss = 3.921632, validation loss = 2.754876
2018-12-08 23:56:13,366 - INFO - epoch 4, step 44050, training loss = 3.634937, validation loss = 2.871426
2018-12-08 23:56:34,537 - INFO - epoch 4, step 44100, training loss = 3.600323, validation loss = 3.106876
2018-12-08 23:56:55,861 - INFO - epoch 4, step 44150, training loss = 3.843721, validation loss = 3.243613
2018-12-08 23:57:16,498 - INFO - epoch 4, step 44200, training loss = 4.104084, validation loss = 3.230138
2018-12-08 23:57:37,404 - INFO - epoch 4, step 44250, training loss = 3.376627, validation loss = 3.252542
2018-12-08 23:57:59,452 - INFO - epoch 4, step 44300, training loss = 3.868046, validation loss = 3.107053
2018-12-08 23:58:20,930 - INFO - epoch 4, step 44350, training loss = 4.307666, validation loss = 2.965951
2018-12-08 23:58:41,287 - INFO - epoch 4, step 44400, training loss = 4.323839, validation loss = 3.133075
2018-12-08 23:59:00,968 - INFO - epoch 4, step 44450, training loss = 4.117668, validation loss = 3.349424
2018-12-08 23:59:22,826 - INFO - epoch 4, step 44500, training loss = 4.161750, validation loss = 3.020274
2018-12-08 23:59:46,794 - INFO - epoch 4, step 44550, training loss = 4.093639, validation loss = 3.950677
2018-12-09 00:00:07,939 - INFO - epoch 4, step 44600, training loss = 3.856569, validation loss = 3.322522
2018-12-09 00:00:32,927 - INFO - epoch 4, step 44650, training loss = 4.390211, validation loss = 3.255671
2018-12-09 00:01:01,154 - INFO - epoch 4, step 44700, training loss = 4.093938, validation loss = 2.645607
2018-12-09 00:01:25,619 - INFO - epoch 4, step 44750, training loss = 4.049845, validation loss = 3.180668
2018-12-09 00:01:48,555 - INFO - epoch 4, step 44800, training loss = 3.946732, validation loss = 2.942924
2018-12-09 00:02:11,173 - INFO - epoch 4, step 44850, training loss = 4.349126, validation loss = 3.094053
2018-12-09 00:02:30,349 - INFO - epoch 4, step 44900, training loss = 4.015756, validation loss = 3.164471
2018-12-09 00:02:51,134 - INFO - epoch 4, step 44950, training loss = 3.760180, validation loss = 2.857867
2018-12-09 00:03:15,240 - INFO - epoch 4, step 45000, training loss = 4.244380, validation loss = 3.190711
2018-12-09 00:03:39,791 - INFO - epoch 4, step 45050, training loss = 4.172209, validation loss = 3.138057
2018-12-09 00:04:03,508 - INFO - epoch 4, step 45100, training loss = 3.519757, validation loss = 2.828947
2018-12-09 00:04:23,606 - INFO - epoch 4, step 45150, training loss = 3.959836, validation loss = 3.445042
2018-12-09 00:04:48,860 - INFO - epoch 4, step 45200, training loss = 4.445501, validation loss = 3.020071
2018-12-09 00:05:10,973 - INFO - epoch 4, step 45250, training loss = 4.074419, validation loss = 3.207429
2018-12-09 00:05:34,063 - INFO - epoch 4, step 45300, training loss = 4.049879, validation loss = 3.230417
2018-12-09 00:06:02,195 - INFO - epoch 4, step 45350, training loss = 4.068698, validation loss = 3.258249
2018-12-09 00:06:29,750 - INFO - epoch 4, step 45400, training loss = 4.288241, validation loss = 3.247129
2018-12-09 00:06:58,073 - INFO - epoch 4, step 45450, training loss = 4.089477, validation loss = 3.255639
2018-12-09 00:07:18,590 - INFO - epoch 4, step 45500, training loss = 4.096403, validation loss = 3.352436
2018-12-09 00:07:43,427 - INFO - epoch 4, step 45550, training loss = 4.420766, validation loss = 3.274542
2018-12-09 00:08:03,188 - INFO - epoch 4, step 45600, training loss = 4.339677, validation loss = 3.396497
2018-12-09 00:08:22,791 - INFO - epoch 4, step 45650, training loss = 4.178539, validation loss = 3.161612
2018-12-09 00:08:43,353 - INFO - epoch 4, step 45700, training loss = 4.321565, validation loss = 3.095168
2018-12-09 00:09:03,942 - INFO - epoch 4, step 45750, training loss = 4.053827, validation loss = 2.962974
2018-12-09 00:09:24,779 - INFO - epoch 4, step 45800, training loss = 4.424086, validation loss = 2.885893
2018-12-09 00:09:52,478 - INFO - epoch 4, step 45850, training loss = 4.073978, validation loss = 3.293069
2018-12-09 00:10:21,715 - INFO - epoch 4, step 45900, training loss = 4.578029, validation loss = 3.295797
2018-12-09 00:10:52,683 - INFO - epoch 4, step 45950, training loss = 4.029663, validation loss = 2.971226
2018-12-09 00:11:21,740 - INFO - epoch 4, step 46000, training loss = 4.564275, validation loss = 3.236214
2018-12-09 00:11:44,258 - INFO - epoch 4, step 46050, training loss = 4.209706, validation loss = 3.441769
2018-12-09 00:12:05,174 - INFO - epoch 4, step 46100, training loss = 3.918974, validation loss = 3.057613
2018-12-09 00:12:26,378 - INFO - epoch 4, step 46150, training loss = 3.344556, validation loss = 3.483949
2018-12-09 00:12:46,725 - INFO - epoch 4, step 46200, training loss = 3.920344, validation loss = 2.908306
2018-12-09 00:13:07,518 - INFO - epoch 4, step 46250, training loss = 3.969867, validation loss = 3.175987
2018-12-09 00:13:29,768 - INFO - epoch 4, step 46300, training loss = 3.865340, validation loss = 2.856275
2018-12-09 00:13:50,726 - INFO - epoch 4, step 46350, training loss = 4.066025, validation loss = 2.739418
2018-12-09 00:14:10,687 - INFO - epoch 4, step 46400, training loss = 4.157619, validation loss = 3.452930
2018-12-09 00:14:30,293 - INFO - epoch 4, step 46450, training loss = 3.903738, validation loss = 2.842502
2018-12-09 00:14:54,713 - INFO - epoch 4, step 46500, training loss = 4.085072, validation loss = 2.920866
2018-12-09 00:15:18,849 - INFO - epoch 4, step 46550, training loss = 3.970721, validation loss = 3.068920
2018-12-09 00:15:40,922 - INFO - epoch 4, step 46600, training loss = 4.687900, validation loss = 3.140487
2018-12-09 00:16:10,130 - INFO - epoch 4, step 46650, training loss = 4.005994, validation loss = 2.940012
2018-12-09 00:16:29,727 - INFO - epoch 4, step 46700, training loss = 4.164772, validation loss = 2.935918
2018-12-09 00:16:52,702 - INFO - epoch 4, step 46750, training loss = 3.198716, validation loss = 3.108966
2018-12-09 00:17:15,113 - INFO - epoch 4, step 46800, training loss = 4.082885, validation loss = 2.829095
2018-12-09 00:17:36,342 - INFO - epoch 4, step 46850, training loss = 4.317554, validation loss = 3.183277
2018-12-09 00:17:57,881 - INFO - epoch 4, step 46900, training loss = 3.775944, validation loss = 2.755460
2018-12-09 00:18:26,664 - INFO - epoch 4, step 46950, training loss = 4.386632, validation loss = 3.042028
2018-12-09 00:18:57,309 - INFO - epoch 4, step 47000, training loss = 4.689831, validation loss = 3.004593
2018-12-09 00:19:25,310 - INFO - epoch 4, step 47050, training loss = 4.125945, validation loss = 3.173689
2018-12-09 00:19:48,923 - INFO - epoch 4, step 47100, training loss = 3.808443, validation loss = 2.898306
2018-12-09 00:20:11,635 - INFO - epoch 4, step 47150, training loss = 3.962319, validation loss = 2.915164
2018-12-09 00:20:33,167 - INFO - epoch 4, step 47200, training loss = 2.937780, validation loss = 3.330297
2018-12-09 00:20:49,488 - INFO - epoch 4, step 47250, training loss = 2.364209, validation loss = 2.543416
2018-12-09 00:21:08,637 - INFO - epoch 4, step 47300, training loss = 2.563276, validation loss = 2.707227
2018-12-09 00:21:28,559 - INFO - epoch 4, step 47350, training loss = 2.407479, validation loss = 2.907225
2018-12-09 00:21:45,030 - INFO - epoch 4, step 47400, training loss = 2.400825, validation loss = 2.544243
2018-12-09 00:22:02,372 - INFO - epoch 4, step 47450, training loss = 2.378066, validation loss = 2.887005
2018-12-09 00:22:21,277 - INFO - epoch 4, step 47500, training loss = 2.228579, validation loss = 2.711290
2018-12-09 00:22:39,659 - INFO - epoch 4, step 47550, training loss = 2.643676, validation loss = 2.461145
2018-12-09 00:22:57,511 - INFO - epoch 4, step 47600, training loss = 2.551870, validation loss = 2.556769
2018-12-09 00:23:14,379 - INFO - epoch 4, step 47650, training loss = 2.500765, validation loss = 2.522969
2018-12-09 00:23:29,873 - INFO - epoch 4, step 47700, training loss = 2.574505, validation loss = 2.251043
2018-12-09 00:23:47,306 - INFO - epoch 4, step 47750, training loss = 2.452470, validation loss = 2.396655
2018-12-09 00:24:06,387 - INFO - epoch 4, step 47800, training loss = 2.521892, validation loss = 2.782094
2018-12-09 00:24:27,088 - INFO - epoch 4, step 47850, training loss = 2.249886, validation loss = 2.379326
2018-12-09 00:24:50,580 - INFO - epoch 4, step 47900, training loss = 2.681445, validation loss = 2.520062
2018-12-09 00:25:14,197 - INFO - epoch 4, step 47950, training loss = 2.667709, validation loss = 2.365483
2018-12-09 00:25:35,793 - INFO - epoch 4, step 48000, training loss = 2.496457, validation loss = 2.573688
2018-12-09 00:25:53,595 - INFO - epoch 4, step 48050, training loss = 2.375062, validation loss = 2.062869
2018-12-09 00:26:10,664 - INFO - epoch 4, step 48100, training loss = 2.454592, validation loss = 2.611557
2018-12-09 00:26:29,315 - INFO - epoch 4, step 48150, training loss = 2.350626, validation loss = 2.564860
2018-12-09 00:26:51,648 - INFO - epoch 4, step 48200, training loss = 2.014022, validation loss = 2.594422
2018-12-09 00:27:14,204 - INFO - epoch 4, step 48250, training loss = 2.367365, validation loss = 2.164809
2018-12-09 00:27:35,097 - INFO - epoch 4, step 48300, training loss = 2.213358, validation loss = 2.543746
2018-12-09 00:27:58,734 - INFO - epoch 4, step 48350, training loss = 2.581573, validation loss = 2.631022
2018-12-09 00:28:22,552 - INFO - epoch 4, step 48400, training loss = 2.492074, validation loss = 2.456497
2018-12-09 00:28:45,067 - INFO - epoch 4, step 48450, training loss = 2.397206, validation loss = 2.316967
2018-12-09 00:29:04,679 - INFO - epoch 4, step 48500, training loss = 2.533222, validation loss = 2.427629
2018-12-09 00:29:22,117 - INFO - epoch 4, step 48550, training loss = 2.428359, validation loss = 2.631294
2018-12-09 00:29:40,974 - INFO - epoch 4, step 48600, training loss = 2.210660, validation loss = 2.628127
2018-12-09 00:30:01,864 - INFO - epoch 4, step 48650, training loss = 2.336544, validation loss = 2.339730
2018-12-09 00:30:24,587 - INFO - epoch 4, step 48700, training loss = 2.397412, validation loss = 2.244622
2018-12-09 00:30:47,496 - INFO - epoch 4, step 48750, training loss = 2.129683, validation loss = 2.463467
2018-12-09 00:31:11,326 - INFO - epoch 4, step 48800, training loss = 2.001311, validation loss = 2.530919
2018-12-09 00:31:35,458 - INFO - epoch 4, step 48850, training loss = 2.653573, validation loss = 2.654173
2018-12-09 00:31:57,643 - INFO - epoch 4, step 48900, training loss = 2.381815, validation loss = 2.668874
2018-12-09 00:32:18,939 - INFO - epoch 4, step 48950, training loss = 2.409835, validation loss = 2.639670
2018-12-09 00:32:39,048 - INFO - epoch 4, step 49000, training loss = 2.242527, validation loss = 2.720141
2018-12-09 00:32:57,160 - INFO - epoch 4, step 49050, training loss = 2.122325, validation loss = 2.549723
2018-12-09 00:33:18,798 - INFO - epoch 4, step 49100, training loss = 2.222477, validation loss = 2.471876
2018-12-09 00:33:39,492 - INFO - epoch 4, step 49150, training loss = 2.251633, validation loss = 2.257110
2018-12-09 00:33:59,555 - INFO - epoch 4, step 49200, training loss = 2.349075, validation loss = 2.355293
2018-12-09 00:34:22,515 - INFO - epoch 4, step 49250, training loss = 2.044618, validation loss = 2.354490
2018-12-09 00:34:42,237 - INFO - epoch 4, step 49300, training loss = 2.248717, validation loss = 2.282235
2018-12-09 00:34:59,048 - INFO - epoch 4, step 49350, training loss = 2.432324, validation loss = 2.249148
2018-12-09 00:35:15,772 - INFO - epoch 4, step 49400, training loss = 2.357229, validation loss = 2.446340
2018-12-09 00:35:30,958 - INFO - epoch 4, step 49450, training loss = 2.619538, validation loss = 2.523566
2018-12-09 00:35:47,945 - INFO - epoch 4, step 49500, training loss = 2.200885, validation loss = 2.338256
2018-12-09 00:36:03,378 - INFO - epoch 4, step 49550, training loss = 2.450189, validation loss = 2.500025
2018-12-09 00:36:20,324 - INFO - epoch 4, step 49600, training loss = 1.927384, validation loss = 2.883186
2018-12-09 00:36:40,137 - INFO - epoch 4, step 49650, training loss = 2.093052, validation loss = 2.325854
2018-12-09 00:37:02,209 - INFO - epoch 4, step 49700, training loss = 2.615297, validation loss = 2.736709
2018-12-09 00:37:23,811 - INFO - epoch 4, step 49750, training loss = 2.347849, validation loss = 2.471511
2018-12-09 00:37:43,738 - INFO - epoch 4, step 49800, training loss = 2.641082, validation loss = 2.976789
2018-12-09 00:37:59,873 - INFO - epoch 4, step 49850, training loss = 2.202712, validation loss = 2.268350
2018-12-09 00:38:17,611 - INFO - epoch 4, step 49900, training loss = 2.469346, validation loss = 2.428759
2018-12-09 00:38:36,733 - INFO - epoch 4, step 49950, training loss = 1.905697, validation loss = 2.776290
2018-12-09 00:38:56,947 - INFO - epoch 4, step 50000, training loss = 2.264518, validation loss = 2.576975
2018-12-09 00:39:17,408 - INFO - epoch 4, step 50050, training loss = 2.030483, validation loss = 2.298686
2018-12-09 00:39:36,627 - INFO - epoch 4, step 50100, training loss = 2.394209, validation loss = 2.346850
2018-12-09 00:39:53,647 - INFO - epoch 4, step 50150, training loss = 1.816561, validation loss = 2.310851
2018-12-09 00:40:14,268 - INFO - epoch 4, step 50200, training loss = 2.181735, validation loss = 2.834183
2018-12-09 00:40:34,522 - INFO - epoch 4, step 50250, training loss = 2.737004, validation loss = 2.573947
2018-12-09 00:40:55,389 - INFO - epoch 4, step 50300, training loss = 2.279875, validation loss = 2.705968
2018-12-09 00:41:16,574 - INFO - epoch 4, step 50350, training loss = 2.289095, validation loss = 2.431417
2018-12-09 00:41:37,515 - INFO - epoch 4, step 50400, training loss = 2.216456, validation loss = 2.274271
2018-12-09 00:41:55,608 - INFO - epoch 4, step 50450, training loss = 2.226347, validation loss = 3.005300
2018-12-09 00:42:12,271 - INFO - epoch 4, step 50500, training loss = 2.625249, validation loss = 2.413986
2018-12-09 00:42:27,772 - INFO - epoch 4, step 50550, training loss = 2.582264, validation loss = 2.454286
2018-12-09 00:42:47,820 - INFO - epoch 4, step 50600, training loss = 2.273452, validation loss = 2.831010
2018-12-09 00:43:08,197 - INFO - epoch 4, step 50650, training loss = 2.203900, validation loss = 2.627678
2018-12-09 00:43:28,579 - INFO - epoch 4, step 50700, training loss = 2.305960, validation loss = 2.496035
2018-12-09 00:43:45,946 - INFO - epoch 4, step 50750, training loss = 2.068221, validation loss = 2.620635
2018-12-09 00:44:02,541 - INFO - epoch 4, step 50800, training loss = 2.373198, validation loss = 2.585606
2018-12-09 00:44:19,545 - INFO - epoch 4, step 50850, training loss = 1.789846, validation loss = 2.673990
2018-12-09 00:44:37,574 - INFO - epoch 4, step 50900, training loss = 2.032512, validation loss = 2.477803
2018-12-09 00:44:54,731 - INFO - epoch 4, step 50950, training loss = 2.284141, validation loss = 2.822552
2018-12-09 00:45:11,327 - INFO - epoch 4, step 51000, training loss = 2.586105, validation loss = 2.488841
2018-12-09 00:45:28,264 - INFO - epoch 4, step 51050, training loss = 2.409220, validation loss = 2.756755
2018-12-09 00:45:47,704 - INFO - epoch 4, step 51100, training loss = 2.287225, validation loss = 2.569761
2018-12-09 00:46:06,768 - INFO - epoch 4, step 51150, training loss = 2.306975, validation loss = 2.596843
2018-12-09 00:46:24,861 - INFO - epoch 4, step 51200, training loss = 2.042984, validation loss = 2.368099
2018-12-09 00:46:41,988 - INFO - epoch 4, step 51250, training loss = 2.095694, validation loss = 2.507827
2018-12-09 00:46:58,780 - INFO - epoch 4, step 51300, training loss = 2.276535, validation loss = 2.332233
2018-12-09 00:47:15,762 - INFO - epoch 4, step 51350, training loss = 2.351410, validation loss = 2.533231
2018-12-09 00:47:33,495 - INFO - epoch 4, step 51400, training loss = 2.359862, validation loss = 2.507284
2018-12-09 00:47:54,421 - INFO - epoch 4, step 51450, training loss = 2.045178, validation loss = 2.856489
2018-12-09 00:48:18,189 - INFO - epoch 4, step 51500, training loss = 2.215312, validation loss = 2.495414
2018-12-09 00:48:41,719 - INFO - epoch 4, step 51550, training loss = 1.970971, validation loss = 2.909425
2018-12-09 00:49:03,759 - INFO - epoch 4, step 51600, training loss = 2.316600, validation loss = 2.283150
2018-12-09 00:49:26,961 - INFO - epoch 4, step 51650, training loss = 2.173261, validation loss = 2.670481
2018-12-09 00:49:49,155 - INFO - epoch 4, step 51700, training loss = 2.088042, validation loss = 2.316468
2018-12-09 00:50:13,215 - INFO - epoch 4, step 51750, training loss = 2.140182, validation loss = 2.396074
2018-12-09 00:50:38,237 - INFO - epoch 4, step 51800, training loss = 2.139490, validation loss = 2.584396
2018-12-09 00:51:02,429 - INFO - epoch 4, step 51850, training loss = 2.370025, validation loss = 2.835659
2018-12-09 00:51:20,339 - INFO - epoch 4, step 51900, training loss = 2.118393, validation loss = 2.575298
2018-12-09 00:51:39,230 - INFO - epoch 4, step 51950, training loss = 2.009726, validation loss = 2.753512
2018-12-09 00:51:59,123 - INFO - epoch 4, step 52000, training loss = 2.443859, validation loss = 2.665947
2018-12-09 00:52:22,427 - INFO - epoch 4, step 52050, training loss = 2.352475, validation loss = 2.580623
2018-12-09 00:52:46,838 - INFO - epoch 4, step 52100, training loss = 2.340941, validation loss = 3.036819
2018-12-09 00:53:10,449 - INFO - epoch 4, step 52150, training loss = 1.885156, validation loss = 2.507584
2018-12-09 00:53:29,413 - INFO - epoch 4, step 52200, training loss = 2.335271, validation loss = 2.193485
2018-12-09 00:53:47,907 - INFO - epoch 4, step 52250, training loss = 2.615550, validation loss = 2.451689
2018-12-09 00:54:06,847 - INFO - epoch 4, step 52300, training loss = 2.153620, validation loss = 2.641250
2018-12-09 00:54:32,032 - INFO - epoch 4, step 52350, training loss = 2.151134, validation loss = 2.383378
2018-12-09 00:54:53,888 - INFO - epoch 4, step 52400, training loss = 2.433573, validation loss = 2.623027
2018-12-09 00:55:12,439 - INFO - epoch 4, step 52450, training loss = 2.493698, validation loss = 2.286958
2018-12-09 00:55:31,382 - INFO - epoch 4, step 52500, training loss = 2.322101, validation loss = 2.433172
2018-12-09 00:55:53,317 - INFO - epoch 4, step 52550, training loss = 2.279876, validation loss = 2.412765
2018-12-09 00:56:15,751 - INFO - epoch 4, step 52600, training loss = 2.440258, validation loss = 2.429234
2018-12-09 00:56:35,284 - INFO - epoch 4, step 52650, training loss = 2.279651, validation loss = 2.220683
2018-12-09 00:56:58,398 - INFO - epoch 4, step 52700, training loss = 2.203963, validation loss = 2.152640
2018-12-09 00:57:22,738 - INFO - epoch 4, step 52750, training loss = 2.108786, validation loss = 2.258467
2018-12-09 00:57:47,288 - INFO - epoch 4, step 52800, training loss = 2.277823, validation loss = 2.817185
2018-12-09 00:58:12,704 - INFO - epoch 4, step 52850, training loss = 2.150097, validation loss = 2.641071
2018-12-09 00:58:33,593 - INFO - epoch 4, step 52900, training loss = 2.246578, validation loss = 2.454268
2018-12-09 00:58:52,096 - INFO - epoch 4, step 52950, training loss = 2.236293, validation loss = 2.440340
2018-12-09 00:59:10,455 - INFO - epoch 4, step 53000, training loss = 2.297189, validation loss = 2.228355
2018-12-09 00:59:30,372 - INFO - epoch 4, step 53050, training loss = 2.071338, validation loss = 2.426539
2018-12-09 00:59:51,883 - INFO - epoch 4, step 53100, training loss = 1.991868, validation loss = 2.095718
2018-12-09 01:00:15,198 - INFO - epoch 4, step 53150, training loss = 2.168888, validation loss = 2.451920
2018-12-09 01:00:35,510 - INFO - epoch 4, step 53200, training loss = 2.163140, validation loss = 2.337202
2018-12-09 01:00:56,447 - INFO - epoch 4, step 53250, training loss = 2.531813, validation loss = 2.811166
2018-12-09 01:01:20,028 - INFO - epoch 4, step 53300, training loss = 2.161079, validation loss = 2.163123
2018-12-09 01:01:45,109 - INFO - epoch 4, step 53350, training loss = 2.111051, validation loss = 2.457554
2018-12-09 01:02:11,278 - INFO - epoch 4, step 53400, training loss = 2.194579, validation loss = 2.058640
2018-12-09 01:02:38,097 - INFO - epoch 4, step 53450, training loss = 2.525084, validation loss = 2.672834
2018-12-09 01:03:02,658 - INFO - epoch 4, step 53500, training loss = 2.181765, validation loss = 1.987804
2018-12-09 01:03:23,967 - INFO - epoch 4, step 53550, training loss = 2.502319, validation loss = 2.645829
2018-12-09 01:03:43,865 - INFO - epoch 4, step 53600, training loss = 2.293988, validation loss = 2.301306
2018-12-09 01:04:06,423 - INFO - epoch 4, step 53650, training loss = 2.352840, validation loss = 2.182811
2018-12-09 01:04:29,625 - INFO - epoch 4, step 53700, training loss = 2.313011, validation loss = 2.276202
2018-12-09 01:04:54,568 - INFO - epoch 4, step 53750, training loss = 2.036607, validation loss = 2.425218
2018-12-09 01:05:17,963 - INFO - epoch 4, step 53800, training loss = 2.137032, validation loss = 2.569235
2018-12-09 01:05:38,677 - INFO - epoch 4, step 53850, training loss = 2.345765, validation loss = 2.416126
2018-12-09 01:05:58,028 - INFO - epoch 4, step 53900, training loss = 2.284961, validation loss = 2.682914
2018-12-09 01:06:18,173 - INFO - epoch 4, step 53950, training loss = 1.744108, validation loss = 2.390356
2018-12-09 01:06:39,898 - INFO - epoch 4, step 54000, training loss = 1.944941, validation loss = 2.603538
2018-12-09 01:07:07,123 - INFO - epoch 4, step 54050, training loss = 2.279680, validation loss = 2.589164
2018-12-09 01:07:29,411 - INFO - epoch 4, step 54100, training loss = 2.217872, validation loss = 2.532462
2018-12-09 01:07:48,766 - INFO - epoch 4, step 54150, training loss = 2.265326, validation loss = 2.213400
2018-12-09 01:08:08,630 - INFO - epoch 4, step 54200, training loss = 2.220101, validation loss = 2.085364
2018-12-09 01:08:31,538 - INFO - epoch 4, step 54250, training loss = 2.324034, validation loss = 2.508336
2018-12-09 01:08:56,352 - INFO - epoch 4, step 54300, training loss = 1.997818, validation loss = 2.464200
2018-12-09 01:09:17,014 - INFO - epoch 4, step 54350, training loss = 2.097043, validation loss = 2.188745
2018-12-09 01:09:37,645 - INFO - epoch 4, step 54400, training loss = 2.626507, validation loss = 2.543285
2018-12-09 01:09:58,669 - INFO - epoch 4, step 54450, training loss = 2.370855, validation loss = 1.932077
2018-12-09 01:10:24,769 - INFO - epoch 4, step 54500, training loss = 1.813687, validation loss = 2.313797
2018-12-09 01:10:47,725 - INFO - epoch 4, step 54550, training loss = 2.369709, validation loss = 2.209895
2018-12-09 01:11:09,824 - INFO - epoch 4, step 54600, training loss = 2.192162, validation loss = 2.541337
2018-12-09 01:11:33,270 - INFO - epoch 4, step 54650, training loss = 2.342469, validation loss = 2.663254
2018-12-09 01:11:57,775 - INFO - epoch 4, step 54700, training loss = 2.539542, validation loss = 2.691772
2018-12-09 01:12:21,990 - INFO - epoch 4, step 54750, training loss = 2.167274, validation loss = 2.513284
2018-12-09 01:12:41,783 - INFO - epoch 4, step 54800, training loss = 2.079366, validation loss = 2.186315
2018-12-09 01:13:05,979 - INFO - epoch 4, step 54850, training loss = 2.359006, validation loss = 2.517931
2018-12-09 01:13:32,653 - INFO - epoch 4, step 54900, training loss = 1.962178, validation loss = 2.517193
2018-12-09 01:13:58,067 - INFO - epoch 4, step 54950, training loss = 1.997100, validation loss = 2.409058
2018-12-09 01:14:21,773 - INFO - epoch 4, step 55000, training loss = 1.959679, validation loss = 2.527812
2018-12-09 01:14:43,614 - INFO - epoch 4, step 55050, training loss = 2.148051, validation loss = 2.370419
2018-12-09 01:15:04,157 - INFO - epoch 4, step 55100, training loss = 2.092125, validation loss = 2.389392
2018-12-09 01:15:23,793 - INFO - epoch 4, step 55150, training loss = 2.333996, validation loss = 2.431827
2018-12-09 01:15:41,336 - INFO - epoch 4, step 55200, training loss = 2.139155, validation loss = 2.248391
2018-12-09 01:16:01,940 - INFO - epoch 4, step 55250, training loss = 2.159776, validation loss = 2.351898
2018-12-09 01:16:23,575 - INFO - epoch 4, step 55300, training loss = 2.242532, validation loss = 2.659119
2018-12-09 01:16:46,000 - INFO - epoch 4, step 55350, training loss = 2.184061, validation loss = 2.304835
2018-12-09 01:17:04,913 - INFO - epoch 4, step 55400, training loss = 2.393363, validation loss = 2.376678
2018-12-09 01:17:20,567 - INFO - epoch 4, step 55450, training loss = 2.142027, validation loss = 2.171627
2018-12-09 01:17:39,301 - INFO - epoch 4, step 55500, training loss = 2.237888, validation loss = 2.239249
2018-12-09 01:17:57,907 - INFO - epoch 4, step 55550, training loss = 2.493863, validation loss = 2.476610
2018-12-09 01:18:15,029 - INFO - epoch 4, step 55600, training loss = 2.348957, validation loss = 2.581126
2018-12-09 01:18:36,289 - INFO - epoch 4, step 55650, training loss = 2.083066, validation loss = 2.192745
2018-12-09 01:18:56,710 - INFO - epoch 4, step 55700, training loss = 2.133462, validation loss = 2.419631
2018-12-09 01:19:16,632 - INFO - epoch 4, step 55750, training loss = 2.236998, validation loss = 2.846996
2018-12-09 01:19:34,392 - INFO - epoch 4, step 55800, training loss = 2.109340, validation loss = 2.417278
2018-12-09 01:19:53,317 - INFO - epoch 4, step 55850, training loss = 2.352484, validation loss = 2.490980
2018-12-09 01:20:14,764 - INFO - epoch 4, step 55900, training loss = 1.931592, validation loss = 2.622354
2018-12-09 01:20:34,971 - INFO - epoch 4, step 55950, training loss = 2.112628, validation loss = 2.578152
2018-12-09 01:20:54,914 - INFO - epoch 4, step 56000, training loss = 2.146647, validation loss = 1.928681
2018-12-09 01:21:13,903 - INFO - epoch 4, step 56050, training loss = 2.209768, validation loss = 2.199323
2018-12-09 01:21:31,926 - INFO - epoch 4, step 56100, training loss = 2.192496, validation loss = 2.171389
2018-12-09 01:21:52,895 - INFO - epoch 4, step 56150, training loss = 2.885426, validation loss = 2.132022
2018-12-09 01:22:12,990 - INFO - epoch 4, step 56200, training loss = 2.341701, validation loss = 2.462231
2018-12-09 01:22:28,372 - INFO - epoch 4, step 56250, training loss = 2.215308, validation loss = 2.117769
2018-12-09 01:22:43,799 - INFO - epoch 4, step 56300, training loss = 2.124260, validation loss = 2.300712
2018-12-09 01:23:00,759 - INFO - epoch 4, step 56350, training loss = 2.211612, validation loss = 2.660830
2018-12-09 01:23:20,790 - INFO - epoch 4, step 56400, training loss = 2.597132, validation loss = 2.415085
2018-12-09 01:23:41,275 - INFO - epoch 4, step 56450, training loss = 2.393378, validation loss = 2.245611
2018-12-09 01:24:02,796 - INFO - epoch 4, step 56500, training loss = 2.069961, validation loss = 2.498852
2018-12-09 01:24:23,586 - INFO - epoch 4, step 56550, training loss = 2.554903, validation loss = 2.450076
2018-12-09 01:24:40,919 - INFO - epoch 4, step 56600, training loss = 2.217675, validation loss = 2.366981
2018-12-09 01:24:58,329 - INFO - epoch 4, step 56650, training loss = 2.324789, validation loss = 2.335266
2018-12-09 01:25:15,241 - INFO - epoch 4, step 56700, training loss = 2.521479, validation loss = 2.276507
2018-12-09 01:25:35,777 - INFO - epoch 4, step 56750, training loss = 2.259619, validation loss = 2.282483
2018-12-09 01:25:54,451 - INFO - epoch 4, step 56800, training loss = 2.158877, validation loss = 2.440469
2018-12-09 01:26:12,703 - INFO - epoch 4, step 56850, training loss = 2.216162, validation loss = 2.135228
2018-12-09 01:26:29,057 - INFO - epoch 4, step 56900, training loss = 1.974007, validation loss = 2.373586
2018-12-09 01:26:45,824 - INFO - epoch 4, step 56950, training loss = 2.203030, validation loss = 2.038774
2018-12-09 01:27:03,935 - INFO - epoch 4, step 57000, training loss = 2.021002, validation loss = 2.175283
2018-12-09 01:27:25,355 - INFO - epoch 4, step 57050, training loss = 1.763570, validation loss = 2.254565
2018-12-09 01:27:45,397 - INFO - epoch 4, step 57100, training loss = 2.277231, validation loss = 2.215818
2018-12-09 01:28:04,464 - INFO - epoch 4, step 57150, training loss = 2.148285, validation loss = 2.401902
2018-12-09 01:28:25,523 - INFO - epoch 4, step 57200, training loss = 2.098571, validation loss = 2.194264
2018-12-09 01:28:46,776 - INFO - epoch 4, step 57250, training loss = 1.998637, validation loss = 2.627562
2018-12-09 01:29:06,562 - INFO - epoch 4, step 57300, training loss = 2.056565, validation loss = 2.571694
2018-12-09 01:29:24,544 - INFO - epoch 4, step 57350, training loss = 1.875526, validation loss = 2.301510
2018-12-09 01:29:41,276 - INFO - epoch 4, step 57400, training loss = 2.155530, validation loss = 2.305689
2018-12-09 01:29:57,267 - INFO - epoch 4, step 57450, training loss = 2.060876, validation loss = 2.682800
2018-12-09 01:30:12,948 - INFO - epoch 4, step 57500, training loss = 1.960517, validation loss = 2.271550
2018-12-09 01:30:28,908 - INFO - epoch 4, step 57550, training loss = 2.269410, validation loss = 2.262680
2018-12-09 01:30:44,841 - INFO - epoch 4, step 57600, training loss = 2.089154, validation loss = 2.375142
2018-12-09 01:31:00,529 - INFO - epoch 4, step 57650, training loss = 2.180696, validation loss = 2.105866
2018-12-09 01:31:21,103 - INFO - epoch 4, step 57700, training loss = 2.670779, validation loss = 2.165821
2018-12-09 01:31:40,466 - INFO - epoch 4, step 57750, training loss = 2.433657, validation loss = 2.073493
2018-12-09 01:31:59,225 - INFO - epoch 4, step 57800, training loss = 2.016408, validation loss = 2.150165
2018-12-09 01:32:18,572 - INFO - epoch 4, step 57850, training loss = 2.497029, validation loss = 2.176246
2018-12-09 01:32:39,491 - INFO - epoch 4, step 57900, training loss = 2.213769, validation loss = 2.326529
2018-12-09 01:33:00,067 - INFO - epoch 4, step 57950, training loss = 1.930566, validation loss = 2.280088
2018-12-09 01:33:20,801 - INFO - epoch 4, step 58000, training loss = 2.106443, validation loss = 2.159202
2018-12-09 01:33:41,027 - INFO - epoch 4, step 58050, training loss = 2.006611, validation loss = 2.107795
2018-12-09 01:34:00,347 - INFO - epoch 4, step 58100, training loss = 1.893969, validation loss = 2.376512
2018-12-09 01:34:17,373 - INFO - epoch 4, step 58150, training loss = 2.245348, validation loss = 2.187718
2018-12-09 01:34:33,003 - INFO - epoch 4, step 58200, training loss = 2.376741, validation loss = 2.299052
2018-12-09 01:34:52,188 - INFO - epoch 4, step 58250, training loss = 2.079436, validation loss = 2.218294
2018-12-09 01:35:12,671 - INFO - epoch 4, step 58300, training loss = 1.717155, validation loss = 2.453091
2018-12-09 01:35:33,003 - INFO - epoch 4, step 58350, training loss = 2.181821, validation loss = 1.982754
2018-12-09 01:35:53,005 - INFO - epoch 4, step 58400, training loss = 2.457749, validation loss = 2.433233
2018-12-09 01:36:10,990 - INFO - epoch 4, step 58450, training loss = 2.028627, validation loss = 2.536897
2018-12-09 01:36:29,111 - INFO - epoch 4, step 58500, training loss = 2.442676, validation loss = 2.504789
2018-12-09 01:36:47,287 - INFO - epoch 4, step 58550, training loss = 2.028575, validation loss = 2.204900
2018-12-09 01:37:07,685 - INFO - epoch 4, step 58600, training loss = 2.187328, validation loss = 2.161735
2018-12-09 01:37:25,332 - INFO - epoch 4, step 58650, training loss = 2.371166, validation loss = 2.156965
2018-12-09 01:37:41,387 - INFO - epoch 4, step 58700, training loss = 2.442605, validation loss = 2.386853
2018-12-09 01:38:01,664 - INFO - epoch 4, step 58750, training loss = 1.663208, validation loss = 3.109637
2018-12-09 01:38:22,449 - INFO - epoch 4, step 58800, training loss = 2.028069, validation loss = 2.880636
2018-12-09 01:38:42,287 - INFO - epoch 4, step 58850, training loss = 2.021721, validation loss = 2.805076
2018-12-09 01:39:02,657 - INFO - epoch 4, step 58900, training loss = 2.221316, validation loss = 3.284364
2018-12-09 01:39:21,217 - INFO - epoch 4, step 58950, training loss = 2.158751, validation loss = 3.058685
2018-12-09 01:39:37,618 - INFO - epoch 4, step 59000, training loss = 2.281006, validation loss = 3.141601
2018-12-09 01:39:57,126 - INFO - epoch 4, step 59050, training loss = 2.266019, validation loss = 3.247411
2018-12-09 01:40:16,036 - INFO - epoch 4, step 59100, training loss = 1.994427, validation loss = 3.467975
2018-12-09 01:40:33,719 - INFO - epoch 4, step 59150, training loss = 1.714952, validation loss = 3.330400
2018-12-09 01:40:51,946 - INFO - epoch 4, step 59200, training loss = 1.836681, validation loss = 3.145941
2018-12-09 01:41:12,263 - INFO - epoch 4, step 59250, training loss = 1.644179, validation loss = 3.149575
2018-12-09 01:41:33,246 - INFO - epoch 4, step 59300, training loss = 2.055529, validation loss = 3.044073
2018-12-09 01:41:54,691 - INFO - epoch 4, step 59350, training loss = 1.985257, validation loss = 3.072106
2018-12-09 01:42:11,643 - INFO - epoch 4, step 59400, training loss = 2.230943, validation loss = 3.124463
2018-12-09 01:42:24,350 - INFO - Model saved in dir ./models
