2018-12-04 18:31:43,621 - INFO - Load model parameters from models/params_0.pkl
2018-12-04 18:31:43,621 - INFO - Start to train...
2018-12-04 18:31:47,560 - INFO - epoch 0, step 10, training loss = 3.804425, validation loss = 3.486295
2018-12-04 18:31:51,292 - INFO - epoch 0, step 20, training loss = 2.695029, validation loss = 3.038888
2018-12-04 18:31:54,934 - INFO - epoch 0, step 30, training loss = 3.276284, validation loss = 3.436834
2018-12-04 18:31:58,576 - INFO - epoch 0, step 40, training loss = 3.469440, validation loss = 3.686801
2018-12-04 18:32:02,108 - INFO - epoch 0, step 50, training loss = 3.569876, validation loss = 3.692174
2018-12-04 18:32:05,874 - INFO - epoch 0, step 60, training loss = 3.015690, validation loss = 3.305608
2018-12-04 18:32:09,578 - INFO - epoch 0, step 70, training loss = 2.609729, validation loss = 3.419028
2018-12-04 18:32:13,215 - INFO - epoch 0, step 80, training loss = 3.188136, validation loss = 3.534675
2018-12-04 18:32:17,080 - INFO - epoch 0, step 90, training loss = 3.144054, validation loss = 3.347026
2018-12-04 18:32:21,000 - INFO - epoch 0, step 100, training loss = 2.630507, validation loss = 3.129909
2018-12-04 18:32:24,898 - INFO - epoch 0, step 110, training loss = 3.283627, validation loss = 3.091389
2018-12-04 18:32:28,796 - INFO - epoch 0, step 120, training loss = 3.035820, validation loss = 2.961709
2018-12-04 18:32:32,770 - INFO - epoch 0, step 130, training loss = 3.104304, validation loss = 3.239726
2018-12-04 18:32:36,782 - INFO - epoch 0, step 140, training loss = 3.275034, validation loss = 3.358290
2018-12-04 18:32:40,489 - INFO - epoch 0, step 150, training loss = 3.322926, validation loss = 3.313743
2018-12-04 18:32:44,711 - INFO - epoch 0, step 160, training loss = 2.889644, validation loss = 3.126657
2018-12-04 18:32:48,699 - INFO - epoch 0, step 170, training loss = 3.038347, validation loss = 3.238790
2018-12-04 18:32:53,078 - INFO - epoch 0, step 180, training loss = 2.923875, validation loss = 3.536799
2018-12-04 18:32:57,977 - INFO - epoch 0, step 190, training loss = 3.522068, validation loss = 3.283587
2018-12-04 18:33:02,022 - INFO - epoch 0, step 200, training loss = 2.871011, validation loss = 3.532641
2018-12-04 18:33:06,246 - INFO - epoch 0, step 210, training loss = 2.990682, validation loss = 3.797551
2018-12-04 18:33:10,471 - INFO - epoch 0, step 220, training loss = 3.175044, validation loss = 3.650982
2018-12-04 18:33:14,667 - INFO - epoch 0, step 230, training loss = 2.903456, validation loss = 3.533903
2018-12-04 18:33:19,035 - INFO - epoch 0, step 240, training loss = 2.972561, validation loss = 3.618094
2018-12-04 18:33:23,208 - INFO - epoch 0, step 250, training loss = 3.030200, validation loss = 3.168123
2018-12-04 18:33:27,510 - INFO - epoch 0, step 260, training loss = 2.955072, validation loss = 3.382454
2018-12-04 18:33:31,670 - INFO - epoch 0, step 270, training loss = 2.821530, validation loss = 3.111768
2018-12-04 18:33:35,770 - INFO - epoch 0, step 280, training loss = 3.412489, validation loss = 3.687585
2018-12-04 18:33:39,988 - INFO - epoch 0, step 290, training loss = 2.607780, validation loss = 3.029610
2018-12-04 18:33:44,371 - INFO - epoch 0, step 300, training loss = 2.417541, validation loss = 3.580331
2018-12-04 18:33:48,629 - INFO - epoch 0, step 310, training loss = 3.192277, validation loss = 3.601073
2018-12-04 18:33:52,865 - INFO - epoch 0, step 320, training loss = 2.931867, validation loss = 3.309835
2018-12-04 18:33:56,680 - INFO - epoch 0, step 330, training loss = 3.430115, validation loss = 3.292890
2018-12-04 18:34:00,749 - INFO - epoch 0, step 340, training loss = 2.989688, validation loss = 3.748618
2018-12-04 18:34:04,561 - INFO - epoch 0, step 350, training loss = 2.842573, validation loss = 3.261799
2018-12-04 18:34:08,550 - INFO - epoch 0, step 360, training loss = 3.043616, validation loss = 3.206322
2018-12-04 18:34:12,895 - INFO - epoch 0, step 370, training loss = 2.723148, validation loss = 3.121553
2018-12-04 18:34:16,764 - INFO - epoch 0, step 380, training loss = 2.800289, validation loss = 3.082808
2018-12-04 18:34:20,896 - INFO - epoch 0, step 390, training loss = 3.080904, validation loss = 3.297163
2018-12-04 18:34:25,052 - INFO - epoch 0, step 400, training loss = 2.984750, validation loss = 3.248367
2018-12-04 18:34:29,018 - INFO - epoch 0, step 410, training loss = 3.278527, validation loss = 3.609065
2018-12-04 18:34:32,993 - INFO - epoch 0, step 420, training loss = 2.803655, validation loss = 3.738570
2018-12-04 18:34:37,304 - INFO - epoch 0, step 430, training loss = 2.729103, validation loss = 3.420299
2018-12-04 18:34:41,511 - INFO - epoch 0, step 440, training loss = 2.670488, validation loss = 2.740335
2018-12-04 18:34:45,728 - INFO - epoch 0, step 450, training loss = 2.954624, validation loss = 3.358099
2018-12-04 18:34:49,964 - INFO - epoch 0, step 460, training loss = 2.792404, validation loss = 3.390682
2018-12-04 18:34:54,056 - INFO - epoch 0, step 470, training loss = 3.276170, validation loss = 3.129325
2018-12-04 18:34:58,444 - INFO - epoch 0, step 480, training loss = 2.347291, validation loss = 3.263163
2018-12-04 18:35:02,947 - INFO - epoch 0, step 490, training loss = 2.544190, validation loss = 2.795280
2018-12-04 18:35:07,316 - INFO - epoch 0, step 500, training loss = 3.475785, validation loss = 2.749300
2018-12-04 18:35:11,598 - INFO - epoch 0, step 510, training loss = 2.407363, validation loss = 2.835966
2018-12-04 18:35:15,886 - INFO - epoch 0, step 520, training loss = 2.819541, validation loss = 3.209187
2018-12-04 18:35:20,190 - INFO - epoch 0, step 530, training loss = 2.561911, validation loss = 3.155154
2018-12-04 18:35:24,300 - INFO - epoch 0, step 540, training loss = 2.959187, validation loss = 3.240308
2018-12-04 18:35:28,442 - INFO - epoch 0, step 550, training loss = 2.934994, validation loss = 2.743322
2018-12-04 18:35:32,469 - INFO - epoch 0, step 560, training loss = 2.781832, validation loss = 3.284330
2018-12-04 18:35:36,665 - INFO - epoch 0, step 570, training loss = 2.406050, validation loss = 3.404695
2018-12-04 18:35:40,846 - INFO - epoch 0, step 580, training loss = 3.189268, validation loss = 2.911876
2018-12-04 18:35:45,172 - INFO - epoch 0, step 590, training loss = 2.860358, validation loss = 3.180341
2018-12-04 18:35:49,330 - INFO - epoch 0, step 600, training loss = 2.889605, validation loss = 3.399859
2018-12-04 18:35:53,503 - INFO - epoch 0, step 610, training loss = 2.980784, validation loss = 3.532600
2018-12-04 18:35:57,759 - INFO - epoch 0, step 620, training loss = 3.474658, validation loss = 3.269683
2018-12-04 18:36:01,950 - INFO - epoch 0, step 630, training loss = 3.124222, validation loss = 2.928033
2018-12-04 18:36:06,410 - INFO - epoch 0, step 640, training loss = 2.707936, validation loss = 3.068429
2018-12-04 18:36:10,698 - INFO - epoch 0, step 650, training loss = 2.926504, validation loss = 2.926011
2018-12-04 18:36:14,599 - INFO - epoch 0, step 660, training loss = 2.739243, validation loss = 3.153774
2018-12-04 18:36:18,747 - INFO - epoch 0, step 670, training loss = 3.130588, validation loss = 3.311868
2018-12-04 18:36:22,915 - INFO - epoch 0, step 680, training loss = 2.942587, validation loss = 3.507227
2018-12-04 18:36:27,175 - INFO - epoch 0, step 690, training loss = 2.904499, validation loss = 3.304109
2018-12-04 18:36:31,529 - INFO - epoch 0, step 700, training loss = 2.927914, validation loss = 2.872846
2018-12-04 18:36:35,558 - INFO - epoch 0, step 710, training loss = 2.884075, validation loss = 3.332056
2018-12-04 18:36:39,761 - INFO - epoch 0, step 720, training loss = 2.991061, validation loss = 3.153196
2018-12-04 18:36:44,112 - INFO - epoch 0, step 730, training loss = 3.047534, validation loss = 3.110472
2018-12-04 18:36:48,320 - INFO - epoch 0, step 740, training loss = 2.355663, validation loss = 3.494371
2018-12-04 18:36:52,572 - INFO - epoch 0, step 750, training loss = 3.429142, validation loss = 3.307205
2018-12-04 18:36:56,686 - INFO - epoch 0, step 760, training loss = 2.090996, validation loss = 2.875675
2018-12-04 18:37:00,963 - INFO - epoch 0, step 770, training loss = 3.109814, validation loss = 3.025490
2018-12-04 18:37:05,413 - INFO - epoch 0, step 780, training loss = 2.920474, validation loss = 3.080245
2018-12-04 18:37:10,128 - INFO - epoch 0, step 790, training loss = 2.842060, validation loss = 2.852522
2018-12-04 18:37:14,428 - INFO - epoch 0, step 800, training loss = 3.196000, validation loss = 4.137249
2018-12-04 18:37:19,523 - INFO - epoch 0, step 810, training loss = 3.220644, validation loss = 3.133541
2018-12-04 18:37:23,861 - INFO - epoch 0, step 820, training loss = 2.829971, validation loss = 3.114785
2018-12-04 18:37:28,211 - INFO - epoch 0, step 830, training loss = 3.029245, validation loss = 3.198725
2018-12-04 18:37:32,627 - INFO - epoch 0, step 840, training loss = 2.572953, validation loss = 3.436196
2018-12-04 18:37:36,978 - INFO - epoch 0, step 850, training loss = 2.917112, validation loss = 3.302010
2018-12-04 18:37:41,527 - INFO - epoch 0, step 860, training loss = 2.556853, validation loss = 3.367196
2018-12-04 18:37:45,810 - INFO - epoch 0, step 870, training loss = 3.049818, validation loss = 3.146324
2018-12-04 18:37:50,123 - INFO - epoch 0, step 880, training loss = 3.358604, validation loss = 2.421473
2018-12-04 18:37:54,667 - INFO - epoch 0, step 890, training loss = 2.561469, validation loss = 2.958825
2018-12-04 18:37:58,935 - INFO - epoch 0, step 900, training loss = 3.211283, validation loss = 3.150728
2018-12-04 18:38:03,555 - INFO - epoch 0, step 910, training loss = 2.709132, validation loss = 2.958744
2018-12-04 18:38:08,071 - INFO - epoch 0, step 920, training loss = 2.930401, validation loss = 3.710836
2018-12-04 18:38:12,852 - INFO - epoch 0, step 930, training loss = 3.133396, validation loss = 3.107999
2018-12-04 18:38:17,313 - INFO - epoch 0, step 940, training loss = 2.748423, validation loss = 2.953816
2018-12-04 18:38:21,832 - INFO - epoch 0, step 950, training loss = 2.552089, validation loss = 3.403328
2018-12-04 18:38:26,316 - INFO - epoch 0, step 960, training loss = 3.124078, validation loss = 2.983299
2018-12-04 18:38:30,688 - INFO - epoch 0, step 970, training loss = 2.847399, validation loss = 3.215106
2018-12-04 18:38:35,259 - INFO - epoch 0, step 980, training loss = 2.559215, validation loss = 3.313016
2018-12-04 18:38:39,654 - INFO - epoch 0, step 990, training loss = 2.924808, validation loss = 2.912748
2018-12-04 18:38:44,025 - INFO - epoch 0, step 1000, training loss = 2.641126, validation loss = 3.287505
2018-12-04 18:38:48,481 - INFO - epoch 0, step 1010, training loss = 2.575890, validation loss = 3.641229
2018-12-04 18:38:52,663 - INFO - epoch 0, step 1020, training loss = 2.970013, validation loss = 3.678422
2018-12-04 18:38:56,896 - INFO - epoch 0, step 1030, training loss = 3.096160, validation loss = 3.202626
2018-12-04 18:39:01,115 - INFO - epoch 0, step 1040, training loss = 2.815615, validation loss = 3.170274
2018-12-04 18:39:05,535 - INFO - epoch 0, step 1050, training loss = 2.914361, validation loss = 2.616916
2018-12-04 18:39:09,681 - INFO - epoch 0, step 1060, training loss = 3.195652, validation loss = 3.352976
2018-12-04 18:39:13,763 - INFO - epoch 0, step 1070, training loss = 2.788730, validation loss = 3.282821
2018-12-04 18:39:18,103 - INFO - epoch 0, step 1080, training loss = 2.749914, validation loss = 3.582595
2018-12-04 18:39:22,626 - INFO - epoch 0, step 1090, training loss = 2.693099, validation loss = 2.977178
2018-12-04 18:39:26,858 - INFO - epoch 0, step 1100, training loss = 2.936383, validation loss = 2.961488
2018-12-04 18:39:31,269 - INFO - epoch 0, step 1110, training loss = 2.824097, validation loss = 3.120364
2018-12-04 18:39:35,434 - INFO - epoch 0, step 1120, training loss = 2.756920, validation loss = 2.972810
2018-12-04 18:39:39,676 - INFO - epoch 0, step 1130, training loss = 2.766216, validation loss = 3.287614
2018-12-04 18:39:44,023 - INFO - epoch 0, step 1140, training loss = 2.678387, validation loss = 3.731586
2018-12-04 18:39:48,362 - INFO - epoch 0, step 1150, training loss = 2.398687, validation loss = 3.142082
2018-12-04 18:39:52,699 - INFO - epoch 0, step 1160, training loss = 3.127348, validation loss = 3.535477
2018-12-04 18:39:57,016 - INFO - epoch 0, step 1170, training loss = 2.964456, validation loss = 3.386256
2018-12-04 18:40:01,253 - INFO - epoch 0, step 1180, training loss = 2.945313, validation loss = 3.130329
2018-12-04 18:40:05,399 - INFO - epoch 0, step 1190, training loss = 3.035318, validation loss = 2.811656
2018-12-04 18:40:09,510 - INFO - epoch 0, step 1200, training loss = 3.309443, validation loss = 3.057905
2018-12-04 18:40:13,939 - INFO - epoch 0, step 1210, training loss = 2.842160, validation loss = 3.727202
2018-12-04 18:40:18,370 - INFO - epoch 0, step 1220, training loss = 2.282170, validation loss = 3.247212
2018-12-04 18:40:22,448 - INFO - epoch 0, step 1230, training loss = 2.812136, validation loss = 3.624462
2018-12-04 18:40:26,988 - INFO - epoch 0, step 1240, training loss = 2.988155, validation loss = 2.618210
2018-12-04 18:40:31,226 - INFO - epoch 0, step 1250, training loss = 2.746510, validation loss = 3.009303
2018-12-04 18:40:35,433 - INFO - epoch 0, step 1260, training loss = 2.985249, validation loss = 3.128328
2018-12-04 18:40:39,766 - INFO - epoch 0, step 1270, training loss = 2.964541, validation loss = 3.223301
2018-12-04 18:40:43,848 - INFO - epoch 0, step 1280, training loss = 2.863176, validation loss = 2.956024
2018-12-04 18:40:48,237 - INFO - epoch 0, step 1290, training loss = 2.665492, validation loss = 2.836476
2018-12-04 18:40:52,559 - INFO - epoch 0, step 1300, training loss = 3.078353, validation loss = 2.791753
2018-12-04 18:40:56,327 - INFO - epoch 0, step 1310, training loss = 2.835031, validation loss = 2.795854
2018-12-04 18:41:00,391 - INFO - epoch 0, step 1320, training loss = 3.044633, validation loss = 2.936090
2018-12-04 18:41:04,106 - INFO - epoch 0, step 1330, training loss = 3.218643, validation loss = 3.437063
2018-12-04 18:41:07,705 - INFO - epoch 0, step 1340, training loss = 3.029166, validation loss = 3.446264
2018-12-04 18:41:11,564 - INFO - epoch 0, step 1350, training loss = 2.904897, validation loss = 3.336590
2018-12-04 18:41:15,640 - INFO - epoch 0, step 1360, training loss = 3.064370, validation loss = 3.108841
2018-12-04 18:41:19,454 - INFO - epoch 0, step 1370, training loss = 3.040471, validation loss = 2.844242
2018-12-04 18:41:23,325 - INFO - epoch 0, step 1380, training loss = 3.013042, validation loss = 3.131431
2018-12-04 18:41:27,064 - INFO - epoch 0, step 1390, training loss = 3.103463, validation loss = 3.082371
2018-12-04 18:41:30,797 - INFO - epoch 0, step 1400, training loss = 2.611008, validation loss = 3.076355
2018-12-04 18:41:34,824 - INFO - epoch 0, step 1410, training loss = 2.978160, validation loss = 3.262690
2018-12-04 18:41:38,503 - INFO - epoch 0, step 1420, training loss = 2.675011, validation loss = 2.819371
2018-12-04 18:41:42,529 - INFO - epoch 0, step 1430, training loss = 2.802787, validation loss = 2.285789
2018-12-04 18:41:46,784 - INFO - epoch 0, step 1440, training loss = 2.705895, validation loss = 3.004103
2018-12-04 18:41:50,771 - INFO - epoch 0, step 1450, training loss = 2.580788, validation loss = 3.029494
2018-12-04 18:41:54,831 - INFO - epoch 0, step 1460, training loss = 2.780539, validation loss = 3.437649
2018-12-04 18:41:58,795 - INFO - epoch 0, step 1470, training loss = 2.500488, validation loss = 3.295942
2018-12-04 18:42:02,497 - INFO - epoch 0, step 1480, training loss = 3.069364, validation loss = 3.377447
2018-12-04 18:42:06,485 - INFO - epoch 0, step 1490, training loss = 2.607132, validation loss = 3.039020
2018-12-04 18:42:13,282 - INFO - epoch 0, step 1500, training loss = 0.796656, validation loss = 3.001916
2018-12-04 18:42:17,365 - INFO - epoch 0, step 1510, training loss = 3.166893, validation loss = 3.570383
2018-12-04 18:42:21,404 - INFO - epoch 0, step 1520, training loss = 3.090891, validation loss = 2.879439
2018-12-04 18:42:25,385 - INFO - epoch 0, step 1530, training loss = 2.758622, validation loss = 2.736384
2018-12-04 18:42:29,387 - INFO - epoch 0, step 1540, training loss = 2.397997, validation loss = 3.192582
2018-12-04 18:42:33,439 - INFO - epoch 0, step 1550, training loss = 3.086523, validation loss = 3.746450
2018-12-04 18:42:37,490 - INFO - epoch 0, step 1560, training loss = 2.793761, validation loss = 2.997583
2018-12-04 18:42:41,901 - INFO - epoch 0, step 1570, training loss = 2.427515, validation loss = 3.477532
2018-12-04 18:42:45,749 - INFO - epoch 0, step 1580, training loss = 2.924431, validation loss = 2.671032
2018-12-04 18:42:49,585 - INFO - epoch 0, step 1590, training loss = 2.850245, validation loss = 2.742070
2018-12-04 18:42:53,226 - INFO - epoch 0, step 1600, training loss = 3.155519, validation loss = 3.165968
2018-12-04 18:42:57,105 - INFO - epoch 0, step 1610, training loss = 2.367447, validation loss = 3.157680
2018-12-04 18:43:01,060 - INFO - epoch 0, step 1620, training loss = 2.519047, validation loss = 3.307598
2018-12-04 18:43:04,860 - INFO - epoch 0, step 1630, training loss = 2.723741, validation loss = 3.170856
2018-12-04 18:43:08,691 - INFO - epoch 0, step 1640, training loss = 2.506218, validation loss = 2.979083
2018-12-04 18:43:12,687 - INFO - epoch 0, step 1650, training loss = 2.981977, validation loss = 2.403067
2018-12-04 18:43:17,755 - INFO - epoch 0, step 1660, training loss = 3.192158, validation loss = 2.780524
2018-12-04 18:43:23,090 - INFO - epoch 0, step 1670, training loss = 2.911505, validation loss = 3.184243
2018-12-04 18:43:26,966 - INFO - epoch 0, step 1680, training loss = 2.306435, validation loss = 2.714522
2018-12-04 18:43:30,820 - INFO - epoch 0, step 1690, training loss = 3.077179, validation loss = 2.829926
2018-12-04 18:43:34,644 - INFO - epoch 0, step 1700, training loss = 3.176671, validation loss = 3.120745
2018-12-04 18:43:38,381 - INFO - epoch 0, step 1710, training loss = 3.210536, validation loss = 2.872647
2018-12-04 18:43:42,315 - INFO - epoch 0, step 1720, training loss = 2.385636, validation loss = 2.520943
2018-12-04 18:43:46,024 - INFO - epoch 0, step 1730, training loss = 3.139283, validation loss = 2.572377
2018-12-04 18:43:49,515 - INFO - epoch 0, step 1740, training loss = 2.656036, validation loss = 2.973165
2018-12-04 18:43:52,969 - INFO - epoch 0, step 1750, training loss = 3.355716, validation loss = 2.837499
2018-12-04 18:43:56,572 - INFO - epoch 0, step 1760, training loss = 3.268537, validation loss = 3.523303
2018-12-04 18:44:00,180 - INFO - epoch 0, step 1770, training loss = 3.293598, validation loss = 3.168830
2018-12-04 18:44:03,827 - INFO - epoch 0, step 1780, training loss = 2.840299, validation loss = 2.710007
2018-12-04 18:44:07,257 - INFO - epoch 0, step 1790, training loss = 3.227787, validation loss = 2.919178
2018-12-04 18:44:10,828 - INFO - epoch 0, step 1800, training loss = 3.020982, validation loss = 3.246454
2018-12-04 18:44:14,406 - INFO - epoch 0, step 1810, training loss = 2.178902, validation loss = 3.205326
2018-12-04 18:44:18,075 - INFO - epoch 0, step 1820, training loss = 2.019336, validation loss = 3.385987
2018-12-04 18:44:21,616 - INFO - epoch 0, step 1830, training loss = 3.263874, validation loss = 3.440771
2018-12-04 18:44:25,484 - INFO - epoch 0, step 1840, training loss = 2.795857, validation loss = 3.096862
2018-12-04 18:44:29,153 - INFO - epoch 0, step 1850, training loss = 3.069561, validation loss = 3.359513
2018-12-04 18:44:33,613 - INFO - epoch 0, step 1860, training loss = 3.053829, validation loss = 3.123137
2018-12-04 18:44:37,845 - INFO - epoch 0, step 1870, training loss = 2.772887, validation loss = 3.066926
2018-12-04 18:44:42,281 - INFO - epoch 0, step 1880, training loss = 2.722379, validation loss = 2.904270
2018-12-04 18:44:46,708 - INFO - epoch 0, step 1890, training loss = 2.950801, validation loss = 2.940141
2018-12-04 18:44:51,309 - INFO - epoch 0, step 1900, training loss = 2.867129, validation loss = 2.534424
2018-12-04 18:44:55,857 - INFO - epoch 0, step 1910, training loss = 2.245303, validation loss = 2.714943
2018-12-04 18:45:00,176 - INFO - epoch 0, step 1920, training loss = 2.735726, validation loss = 2.861578
2018-12-04 18:45:04,610 - INFO - epoch 0, step 1930, training loss = 3.278670, validation loss = 3.204762
2018-12-04 18:45:09,416 - INFO - epoch 0, step 1940, training loss = 2.645071, validation loss = 3.162143
2018-12-04 18:45:13,867 - INFO - epoch 0, step 1950, training loss = 3.132714, validation loss = 2.958846
2018-12-04 18:45:17,366 - INFO - epoch 0, step 1960, training loss = 2.901555, validation loss = 2.539503
2018-12-04 18:45:20,989 - INFO - epoch 0, step 1970, training loss = 2.712764, validation loss = 2.759009
2018-12-04 18:45:24,470 - INFO - epoch 0, step 1980, training loss = 2.925699, validation loss = 3.141548
2018-12-04 18:45:28,105 - INFO - epoch 0, step 1990, training loss = 2.854135, validation loss = 2.971421
2018-12-04 18:45:31,603 - INFO - epoch 0, step 2000, training loss = 2.957681, validation loss = 3.063687
2018-12-04 18:45:35,107 - INFO - epoch 0, step 2010, training loss = 3.421244, validation loss = 2.748701
2018-12-04 18:45:38,680 - INFO - epoch 0, step 2020, training loss = 3.077902, validation loss = 2.648009
2018-12-04 18:45:42,092 - INFO - epoch 0, step 2030, training loss = 2.922308, validation loss = 2.992832
2018-12-04 18:45:45,489 - INFO - epoch 0, step 2040, training loss = 2.637660, validation loss = 3.051310
2018-12-04 18:45:49,111 - INFO - epoch 0, step 2050, training loss = 2.867717, validation loss = 3.078392
2018-12-04 18:45:52,759 - INFO - epoch 0, step 2060, training loss = 3.211909, validation loss = 3.327290
2018-12-04 18:45:56,370 - INFO - epoch 0, step 2070, training loss = 2.359699, validation loss = 2.587166
2018-12-04 18:45:59,996 - INFO - epoch 0, step 2080, training loss = 3.077621, validation loss = 2.541447
2018-12-04 18:46:03,467 - INFO - epoch 0, step 2090, training loss = 2.587183, validation loss = 2.822507
2018-12-04 18:46:07,107 - INFO - epoch 0, step 2100, training loss = 3.087470, validation loss = 2.830814
2018-12-04 18:46:10,681 - INFO - epoch 0, step 2110, training loss = 2.731165, validation loss = 3.288511
2018-12-04 18:46:14,201 - INFO - epoch 0, step 2120, training loss = 2.902663, validation loss = 2.909203
2018-12-04 18:46:17,882 - INFO - epoch 0, step 2130, training loss = 2.302975, validation loss = 3.166963
2018-12-04 18:46:21,373 - INFO - epoch 0, step 2140, training loss = 2.632925, validation loss = 2.478591
2018-12-04 18:46:24,941 - INFO - epoch 0, step 2150, training loss = 2.126388, validation loss = 2.926749
2018-12-04 18:46:28,638 - INFO - epoch 0, step 2160, training loss = 2.546748, validation loss = 2.690480
2018-12-04 18:46:32,165 - INFO - epoch 0, step 2170, training loss = 2.966120, validation loss = 3.250705
2018-12-04 18:46:35,643 - INFO - epoch 0, step 2180, training loss = 3.182770, validation loss = 3.500913
2018-12-04 18:46:39,539 - INFO - epoch 0, step 2190, training loss = 2.837704, validation loss = 2.726475
2018-12-04 18:46:43,292 - INFO - epoch 0, step 2200, training loss = 3.242857, validation loss = 2.974639
2018-12-04 18:46:47,231 - INFO - epoch 0, step 2210, training loss = 2.950654, validation loss = 3.045267
2018-12-04 18:46:51,052 - INFO - epoch 0, step 2220, training loss = 2.595124, validation loss = 3.541998
2018-12-04 18:46:54,800 - INFO - epoch 0, step 2230, training loss = 2.995317, validation loss = 3.517173
2018-12-04 18:46:58,623 - INFO - epoch 0, step 2240, training loss = 3.262484, validation loss = 2.481302
2018-12-04 18:47:02,480 - INFO - epoch 0, step 2250, training loss = 2.537075, validation loss = 2.669114
2018-12-04 18:47:06,159 - INFO - epoch 0, step 2260, training loss = 3.027422, validation loss = 2.908074
2018-12-04 18:47:10,035 - INFO - epoch 0, step 2270, training loss = 2.617333, validation loss = 3.439453
2018-12-04 18:47:13,950 - INFO - epoch 0, step 2280, training loss = 2.744087, validation loss = 2.889747
2018-12-04 18:47:18,208 - INFO - epoch 0, step 2290, training loss = 2.929574, validation loss = 2.621449
2018-12-04 18:47:22,597 - INFO - epoch 0, step 2300, training loss = 2.761507, validation loss = 2.758466
2018-12-04 18:47:26,821 - INFO - epoch 0, step 2310, training loss = 2.650965, validation loss = 3.055526
2018-12-04 18:47:31,069 - INFO - epoch 0, step 2320, training loss = 2.771546, validation loss = 2.985422
2018-12-04 18:47:35,523 - INFO - epoch 0, step 2330, training loss = 2.634813, validation loss = 3.174066
2018-12-04 18:47:39,596 - INFO - epoch 0, step 2340, training loss = 2.808748, validation loss = 3.206850
2018-12-04 18:47:43,757 - INFO - epoch 0, step 2350, training loss = 2.866244, validation loss = 3.367786
2018-12-04 18:47:48,099 - INFO - epoch 0, step 2360, training loss = 2.860019, validation loss = 2.301962
2018-12-04 18:47:52,210 - INFO - epoch 0, step 2370, training loss = 3.024636, validation loss = 2.844327
2018-12-04 18:47:56,581 - INFO - epoch 0, step 2380, training loss = 2.968447, validation loss = 2.802591
2018-12-04 18:48:00,885 - INFO - epoch 0, step 2390, training loss = 2.589412, validation loss = 3.267579
2018-12-04 18:48:05,081 - INFO - epoch 0, step 2400, training loss = 2.556839, validation loss = 3.208913
2018-12-04 18:48:09,227 - INFO - epoch 0, step 2410, training loss = 2.721829, validation loss = 2.775380
2018-12-04 18:48:14,011 - INFO - epoch 0, step 2420, training loss = 2.765950, validation loss = 2.803936
2018-12-04 18:48:17,916 - INFO - epoch 0, step 2430, training loss = 3.099756, validation loss = 3.161011
2018-12-04 18:48:21,800 - INFO - epoch 0, step 2440, training loss = 3.031292, validation loss = 2.984551
2018-12-04 18:48:25,557 - INFO - epoch 0, step 2450, training loss = 2.643089, validation loss = 2.775074
2018-12-04 18:48:29,372 - INFO - epoch 0, step 2460, training loss = 2.634513, validation loss = 2.776237
2018-12-04 18:48:33,252 - INFO - epoch 0, step 2470, training loss = 2.916838, validation loss = 2.658671
2018-12-04 18:48:37,046 - INFO - epoch 0, step 2480, training loss = 2.844434, validation loss = 3.227107
2018-12-04 18:48:40,933 - INFO - epoch 0, step 2490, training loss = 2.581543, validation loss = 3.302116
2018-12-04 18:48:44,758 - INFO - epoch 0, step 2500, training loss = 2.989254, validation loss = 2.218096
2018-12-04 18:48:48,581 - INFO - epoch 0, step 2510, training loss = 2.533094, validation loss = 2.725791
2018-12-04 18:48:52,252 - INFO - epoch 0, step 2520, training loss = 3.071685, validation loss = 3.220608
2018-12-04 18:48:55,981 - INFO - epoch 0, step 2530, training loss = 2.512409, validation loss = 3.187657
2018-12-04 18:48:59,686 - INFO - epoch 0, step 2540, training loss = 2.751597, validation loss = 3.432558
2018-12-04 18:49:03,452 - INFO - epoch 0, step 2550, training loss = 2.578916, validation loss = 2.584465
2018-12-04 18:49:07,340 - INFO - epoch 0, step 2560, training loss = 2.867551, validation loss = 2.483569
2018-12-04 18:49:11,265 - INFO - epoch 0, step 2570, training loss = 2.422738, validation loss = 2.930982
2018-12-04 18:49:15,085 - INFO - epoch 0, step 2580, training loss = 2.684320, validation loss = 2.743814
2018-12-04 18:49:18,894 - INFO - epoch 0, step 2590, training loss = 1.794625, validation loss = 3.199539
2018-12-04 18:49:22,825 - INFO - epoch 0, step 2600, training loss = 2.747369, validation loss = 3.500348
2018-12-04 18:49:26,812 - INFO - epoch 0, step 2610, training loss = 2.631812, validation loss = 2.924988
2018-12-04 18:49:30,756 - INFO - epoch 0, step 2620, training loss = 1.874781, validation loss = 2.770038
2018-12-04 18:49:34,399 - INFO - epoch 0, step 2630, training loss = 2.726034, validation loss = 2.905550
2018-12-04 18:49:38,127 - INFO - epoch 0, step 2640, training loss = 2.578155, validation loss = 2.665205
2018-12-04 18:49:42,253 - INFO - epoch 0, step 2650, training loss = 2.822087, validation loss = 3.068759
2018-12-04 18:49:46,811 - INFO - epoch 0, step 2660, training loss = 2.704976, validation loss = 2.633042
2018-12-04 18:49:51,083 - INFO - epoch 0, step 2670, training loss = 3.115148, validation loss = 3.162537
2018-12-04 18:49:55,406 - INFO - epoch 0, step 2680, training loss = 3.068107, validation loss = 2.471232
2018-12-04 18:50:00,012 - INFO - epoch 0, step 2690, training loss = 2.590995, validation loss = 2.523053
2018-12-04 18:50:04,417 - INFO - epoch 0, step 2700, training loss = 2.743340, validation loss = 2.559413
2018-12-04 18:50:08,824 - INFO - epoch 0, step 2710, training loss = 2.967455, validation loss = 3.175831
2018-12-04 18:50:13,203 - INFO - epoch 0, step 2720, training loss = 2.532755, validation loss = 3.006238
2018-12-04 18:50:17,625 - INFO - epoch 0, step 2730, training loss = 3.030910, validation loss = 2.443826
2018-12-04 18:50:22,098 - INFO - epoch 0, step 2740, training loss = 2.973011, validation loss = 2.469335
2018-12-04 18:50:26,607 - INFO - epoch 0, step 2750, training loss = 2.611824, validation loss = 2.839585
2018-12-04 18:50:31,111 - INFO - epoch 0, step 2760, training loss = 2.678546, validation loss = 3.393737
2018-12-04 18:50:35,660 - INFO - epoch 0, step 2770, training loss = 2.975245, validation loss = 3.003057
2018-12-04 18:50:40,098 - INFO - epoch 0, step 2780, training loss = 2.891124, validation loss = 2.624374
2018-12-04 18:50:44,286 - INFO - epoch 0, step 2790, training loss = 2.492321, validation loss = 2.855426
2018-12-04 18:50:48,625 - INFO - epoch 0, step 2800, training loss = 2.966500, validation loss = 2.920796
2018-12-04 18:50:52,783 - INFO - epoch 0, step 2810, training loss = 2.989248, validation loss = 3.585320
2018-12-04 18:50:56,920 - INFO - epoch 0, step 2820, training loss = 3.217163, validation loss = 2.537346
2018-12-04 18:51:00,859 - INFO - epoch 0, step 2830, training loss = 2.606893, validation loss = 2.722237
2018-12-04 18:51:04,769 - INFO - epoch 0, step 2840, training loss = 3.035389, validation loss = 2.693762
2018-12-04 18:51:08,440 - INFO - epoch 0, step 2850, training loss = 3.072388, validation loss = 2.996329
2018-12-04 18:51:12,333 - INFO - epoch 0, step 2860, training loss = 2.790611, validation loss = 3.220956
2018-12-04 18:51:16,027 - INFO - epoch 0, step 2870, training loss = 2.860150, validation loss = 3.037864
2018-12-04 18:51:19,921 - INFO - epoch 0, step 2880, training loss = 2.635170, validation loss = 2.744003
2018-12-04 18:51:23,962 - INFO - epoch 0, step 2890, training loss = 2.589834, validation loss = 2.379596
2018-12-04 18:51:27,925 - INFO - epoch 0, step 2900, training loss = 2.795866, validation loss = 2.399785
2018-12-04 18:51:31,966 - INFO - epoch 0, step 2910, training loss = 2.665626, validation loss = 2.608257
2018-12-04 18:51:35,933 - INFO - epoch 0, step 2920, training loss = 2.351468, validation loss = 2.795619
2018-12-04 18:51:39,837 - INFO - epoch 0, step 2930, training loss = 2.278821, validation loss = 2.827661
2018-12-04 18:51:43,728 - INFO - epoch 0, step 2940, training loss = 3.036500, validation loss = 2.532376
2018-12-04 18:51:48,156 - INFO - epoch 0, step 2950, training loss = 2.710241, validation loss = 2.421284
2018-12-04 18:51:52,760 - INFO - epoch 0, step 2960, training loss = 2.097119, validation loss = 2.949059
2018-12-04 18:51:57,270 - INFO - epoch 0, step 2970, training loss = 2.790834, validation loss = 3.127433
2018-12-04 18:52:01,902 - INFO - epoch 0, step 2980, training loss = 2.811743, validation loss = 2.879612
2018-12-04 18:52:06,569 - INFO - epoch 0, step 2990, training loss = 2.840206, validation loss = 2.773857
2018-12-04 18:52:11,154 - INFO - epoch 0, step 3000, training loss = 2.649477, validation loss = 2.680084
2018-12-04 18:52:15,852 - INFO - epoch 0, step 3010, training loss = 2.694571, validation loss = 3.041308
2018-12-04 18:52:20,335 - INFO - epoch 0, step 3020, training loss = 2.850707, validation loss = 3.132649
2018-12-04 18:52:24,819 - INFO - epoch 0, step 3030, training loss = 2.899001, validation loss = 3.176614
2018-12-04 18:52:29,063 - INFO - epoch 0, step 3040, training loss = 2.893084, validation loss = 2.516697
2018-12-04 18:52:33,449 - INFO - epoch 0, step 3050, training loss = 2.279850, validation loss = 2.776176
2018-12-04 18:52:37,686 - INFO - epoch 0, step 3060, training loss = 2.753980, validation loss = 3.127680
2018-12-04 18:52:42,294 - INFO - epoch 0, step 3070, training loss = 2.677818, validation loss = 2.779828
2018-12-04 18:52:46,609 - INFO - epoch 0, step 3080, training loss = 2.541636, validation loss = 2.400063
2018-12-04 18:52:51,129 - INFO - epoch 0, step 3090, training loss = 2.611185, validation loss = 2.538929
2018-12-04 18:52:55,447 - INFO - epoch 0, step 3100, training loss = 2.614418, validation loss = 3.123576
2018-12-04 18:52:59,859 - INFO - epoch 0, step 3110, training loss = 2.868765, validation loss = 3.551738
2018-12-04 18:53:04,159 - INFO - epoch 0, step 3120, training loss = 2.497198, validation loss = 3.141154
2018-12-04 18:53:08,499 - INFO - epoch 0, step 3130, training loss = 3.011078, validation loss = 2.927573
2018-12-04 18:53:12,741 - INFO - epoch 0, step 3140, training loss = 2.356662, validation loss = 3.261965
2018-12-04 18:53:17,210 - INFO - epoch 0, step 3150, training loss = 2.496584, validation loss = 3.187643
2018-12-04 18:53:21,586 - INFO - epoch 0, step 3160, training loss = 2.763529, validation loss = 2.729008
2018-12-04 18:53:25,964 - INFO - epoch 0, step 3170, training loss = 2.357906, validation loss = 2.592092
2018-12-04 18:53:30,344 - INFO - epoch 0, step 3180, training loss = 2.718903, validation loss = 2.902525
2018-12-04 18:53:34,726 - INFO - epoch 0, step 3190, training loss = 2.297066, validation loss = 2.985680
2018-12-04 18:53:39,044 - INFO - epoch 0, step 3200, training loss = 2.734546, validation loss = 2.498946
2018-12-04 18:53:43,552 - INFO - epoch 0, step 3210, training loss = 2.527481, validation loss = 2.201276
2018-12-04 18:53:47,968 - INFO - epoch 0, step 3220, training loss = 3.060871, validation loss = 2.714532
2018-12-04 18:53:52,525 - INFO - epoch 0, step 3230, training loss = 2.679268, validation loss = 2.869601
2018-12-04 18:53:57,005 - INFO - epoch 0, step 3240, training loss = 2.641401, validation loss = 3.522572
2018-12-04 18:54:01,662 - INFO - epoch 0, step 3250, training loss = 2.505069, validation loss = 2.505124
2018-12-04 18:54:05,971 - INFO - epoch 0, step 3260, training loss = 2.733506, validation loss = 2.617185
2018-12-04 18:54:10,330 - INFO - epoch 0, step 3270, training loss = 2.840085, validation loss = 3.088972
2018-12-04 18:54:14,445 - INFO - epoch 0, step 3280, training loss = 3.289430, validation loss = 3.265636
2018-12-04 18:54:18,290 - INFO - epoch 0, step 3290, training loss = 3.012565, validation loss = 3.268913
2018-12-04 18:54:22,300 - INFO - epoch 0, step 3300, training loss = 2.596676, validation loss = 2.996469
2018-12-04 18:54:26,220 - INFO - epoch 0, step 3310, training loss = 2.386325, validation loss = 2.432049
2018-12-04 18:54:30,399 - INFO - epoch 0, step 3320, training loss = 2.796282, validation loss = 2.960543
2018-12-04 18:54:34,227 - INFO - epoch 0, step 3330, training loss = 3.065725, validation loss = 3.306274
2018-12-04 18:54:38,144 - INFO - epoch 0, step 3340, training loss = 2.328888, validation loss = 2.991989
2018-12-04 18:54:42,217 - INFO - epoch 0, step 3350, training loss = 2.415360, validation loss = 2.417112
2018-12-04 18:54:46,042 - INFO - epoch 0, step 3360, training loss = 3.105265, validation loss = 2.375109
2018-12-04 18:54:50,171 - INFO - epoch 0, step 3370, training loss = 2.853166, validation loss = 3.106542
2018-12-04 18:54:54,501 - INFO - epoch 0, step 3380, training loss = 2.757384, validation loss = 3.061436
2018-12-04 18:54:58,360 - INFO - epoch 0, step 3390, training loss = 2.541511, validation loss = 3.290263
2018-12-04 18:55:02,460 - INFO - epoch 0, step 3400, training loss = 3.128691, validation loss = 3.136645
2018-12-04 18:55:06,800 - INFO - epoch 0, step 3410, training loss = 2.916022, validation loss = 3.056028
2018-12-04 18:55:11,096 - INFO - epoch 0, step 3420, training loss = 2.470991, validation loss = 2.663302
2018-12-04 18:55:15,551 - INFO - epoch 0, step 3430, training loss = 2.601563, validation loss = 2.870325
2018-12-04 18:55:19,571 - INFO - epoch 0, step 3440, training loss = 2.387571, validation loss = 2.969963
2018-12-04 18:55:23,583 - INFO - epoch 0, step 3450, training loss = 2.684303, validation loss = 2.883317
2018-12-04 18:55:27,922 - INFO - epoch 0, step 3460, training loss = 3.212649, validation loss = 2.550066
2018-12-04 18:55:32,361 - INFO - epoch 0, step 3470, training loss = 1.764709, validation loss = 2.685778
2018-12-04 18:55:36,317 - INFO - epoch 0, step 3480, training loss = 2.837222, validation loss = 2.887926
2018-12-04 18:55:40,454 - INFO - epoch 0, step 3490, training loss = 2.804306, validation loss = 3.203437
2018-12-04 18:55:44,458 - INFO - epoch 0, step 3500, training loss = 2.561666, validation loss = 2.873131
2018-12-04 18:55:48,473 - INFO - epoch 0, step 3510, training loss = 2.006031, validation loss = 2.581319
2018-12-04 18:55:52,403 - INFO - epoch 0, step 3520, training loss = 2.684495, validation loss = 2.563425
2018-12-04 18:55:56,512 - INFO - epoch 0, step 3530, training loss = 2.544906, validation loss = 2.824939
2018-12-04 18:56:00,217 - INFO - epoch 0, step 3540, training loss = 2.503230, validation loss = 2.344633
2018-12-04 18:56:04,112 - INFO - epoch 0, step 3550, training loss = 2.304547, validation loss = 3.075507
2018-12-04 18:56:07,896 - INFO - epoch 0, step 3560, training loss = 3.120314, validation loss = 2.850652
2018-12-04 18:56:11,689 - INFO - epoch 0, step 3570, training loss = 2.770787, validation loss = 2.559031
2018-12-04 18:56:15,582 - INFO - epoch 0, step 3580, training loss = 2.497330, validation loss = 3.121578
2018-12-04 18:56:19,689 - INFO - epoch 0, step 3590, training loss = 2.152863, validation loss = 2.894490
2018-12-04 18:56:23,576 - INFO - epoch 0, step 3600, training loss = 2.739721, validation loss = 2.810777
2018-12-04 18:56:27,748 - INFO - epoch 0, step 3610, training loss = 2.419166, validation loss = 2.947765
2018-12-04 18:56:31,549 - INFO - epoch 0, step 3620, training loss = 2.180110, validation loss = 2.040967
2018-12-04 18:56:35,436 - INFO - epoch 0, step 3630, training loss = 2.867562, validation loss = 2.559922
2018-12-04 18:56:39,503 - INFO - epoch 0, step 3640, training loss = 2.734161, validation loss = 3.487658
2018-12-04 18:56:43,295 - INFO - epoch 0, step 3650, training loss = 2.360278, validation loss = 2.556111
2018-12-04 18:56:47,513 - INFO - epoch 0, step 3660, training loss = 2.956461, validation loss = 2.291031
2018-12-04 18:56:51,659 - INFO - epoch 0, step 3670, training loss = 3.183767, validation loss = 2.649140
2018-12-04 18:56:55,459 - INFO - epoch 0, step 3680, training loss = 2.890636, validation loss = 2.908220
2018-12-04 18:56:59,095 - INFO - epoch 0, step 3690, training loss = 2.786494, validation loss = 2.733782
2018-12-04 18:57:03,492 - INFO - epoch 0, step 3700, training loss = 2.866678, validation loss = 2.763290
2018-12-04 18:57:07,387 - INFO - epoch 0, step 3710, training loss = 2.639148, validation loss = 2.556027
2018-12-04 18:57:11,055 - INFO - epoch 0, step 3720, training loss = 2.913263, validation loss = 3.300943
2018-12-04 18:57:14,842 - INFO - epoch 0, step 3730, training loss = 3.194261, validation loss = 2.798702
2018-12-04 18:57:18,875 - INFO - epoch 0, step 3740, training loss = 2.369423, validation loss = 3.049083
2018-12-04 18:57:22,383 - INFO - epoch 0, step 3750, training loss = 3.032514, validation loss = 2.653682
2018-12-04 18:57:26,072 - INFO - epoch 0, step 3760, training loss = 2.679823, validation loss = 2.631260
2018-12-04 18:57:29,667 - INFO - epoch 0, step 3770, training loss = 2.996929, validation loss = 2.337149
2018-12-04 18:57:33,307 - INFO - epoch 0, step 3780, training loss = 2.071486, validation loss = 2.369732
2018-12-04 18:57:36,730 - INFO - epoch 0, step 3790, training loss = 2.804306, validation loss = 2.771017
2018-12-04 18:57:40,129 - INFO - epoch 0, step 3800, training loss = 2.270786, validation loss = 2.555851
2018-12-04 18:57:43,798 - INFO - epoch 0, step 3810, training loss = 2.374150, validation loss = 2.587838
2018-12-04 18:57:47,382 - INFO - epoch 0, step 3820, training loss = 2.750177, validation loss = 2.553693
2018-12-04 18:57:50,946 - INFO - epoch 0, step 3830, training loss = 2.701460, validation loss = 2.395516
2018-12-04 18:57:54,493 - INFO - epoch 0, step 3840, training loss = 2.595042, validation loss = 2.959565
2018-12-04 18:57:58,019 - INFO - epoch 0, step 3850, training loss = 2.897450, validation loss = 2.798962
2018-12-04 18:58:01,597 - INFO - epoch 0, step 3860, training loss = 2.943389, validation loss = 2.527545
2018-12-04 18:58:05,097 - INFO - epoch 0, step 3870, training loss = 2.560932, validation loss = 2.809400
2018-12-04 18:58:08,907 - INFO - epoch 0, step 3880, training loss = 2.629536, validation loss = 2.885782
2018-12-04 18:58:13,273 - INFO - epoch 0, step 3890, training loss = 2.604847, validation loss = 2.584282
2018-12-04 18:58:17,554 - INFO - epoch 0, step 3900, training loss = 2.491264, validation loss = 2.194432
2018-12-04 18:58:22,013 - INFO - epoch 0, step 3910, training loss = 2.696712, validation loss = 2.554852
2018-12-04 18:58:26,460 - INFO - epoch 0, step 3920, training loss = 2.642107, validation loss = 2.942289
2018-12-04 18:58:30,704 - INFO - epoch 0, step 3930, training loss = 3.098235, validation loss = 2.698993
2018-12-04 18:58:35,136 - INFO - epoch 0, step 3940, training loss = 2.305572, validation loss = 2.187803
2018-12-04 18:58:39,360 - INFO - epoch 0, step 3950, training loss = 2.913440, validation loss = 2.982691
2018-12-04 18:58:43,431 - INFO - epoch 0, step 3960, training loss = 2.711396, validation loss = 3.152881
2018-12-04 18:58:47,464 - INFO - epoch 0, step 3970, training loss = 2.899180, validation loss = 2.724107
2018-12-04 18:58:51,862 - INFO - epoch 0, step 3980, training loss = 3.070826, validation loss = 2.243545
2018-12-04 18:58:56,180 - INFO - epoch 0, step 3990, training loss = 2.695714, validation loss = 2.747711
2018-12-04 18:59:00,538 - INFO - epoch 0, step 4000, training loss = 2.762811, validation loss = 2.937219
2018-12-04 18:59:04,936 - INFO - epoch 0, step 4010, training loss = 2.601800, validation loss = 2.897740
2018-12-04 18:59:08,683 - INFO - epoch 0, step 4020, training loss = 3.144399, validation loss = 2.676355
2018-12-04 18:59:12,272 - INFO - epoch 0, step 4030, training loss = 3.504009, validation loss = 2.637702
2018-12-04 18:59:15,803 - INFO - epoch 0, step 4040, training loss = 3.226189, validation loss = 2.605963
2018-12-04 18:59:19,603 - INFO - epoch 0, step 4050, training loss = 3.041879, validation loss = 3.267347
2018-12-04 18:59:23,148 - INFO - epoch 0, step 4060, training loss = 3.148870, validation loss = 2.911993
2018-12-04 18:59:26,713 - INFO - epoch 0, step 4070, training loss = 3.284807, validation loss = 2.435975
2018-12-04 18:59:30,235 - INFO - epoch 0, step 4080, training loss = 2.065039, validation loss = 2.997221
2018-12-04 18:59:34,326 - INFO - epoch 0, step 4090, training loss = 1.622225, validation loss = 3.215403
2018-12-04 18:59:38,151 - INFO - epoch 0, step 4100, training loss = 2.379873, validation loss = 3.119509
2018-12-04 18:59:42,131 - INFO - epoch 0, step 4110, training loss = 2.710580, validation loss = 2.602234
2018-12-04 18:59:45,969 - INFO - epoch 0, step 4120, training loss = 2.677045, validation loss = 3.103631
2018-12-04 18:59:49,853 - INFO - epoch 0, step 4130, training loss = 2.638980, validation loss = 2.812966
2018-12-04 18:59:53,498 - INFO - epoch 0, step 4140, training loss = 2.483368, validation loss = 2.550501
2018-12-04 18:59:57,373 - INFO - epoch 0, step 4150, training loss = 2.834027, validation loss = 2.706560
2018-12-04 19:00:01,083 - INFO - epoch 0, step 4160, training loss = 2.570808, validation loss = 3.254117
2018-12-04 19:00:04,919 - INFO - epoch 0, step 4170, training loss = 2.775613, validation loss = 2.544070
2018-12-04 19:00:08,758 - INFO - epoch 0, step 4180, training loss = 2.602488, validation loss = 2.499234
2018-12-04 19:00:12,584 - INFO - epoch 0, step 4190, training loss = 2.871845, validation loss = 2.816555
2018-12-04 19:00:16,137 - INFO - epoch 0, step 4200, training loss = 2.985667, validation loss = 2.797723
2018-12-04 19:00:19,870 - INFO - epoch 0, step 4210, training loss = 2.279243, validation loss = 2.586298
2018-12-04 19:00:23,634 - INFO - epoch 0, step 4220, training loss = 2.915554, validation loss = 2.721550
2018-12-04 19:00:27,491 - INFO - epoch 0, step 4230, training loss = 2.457219, validation loss = 2.657648
2018-12-04 19:00:31,593 - INFO - epoch 0, step 4240, training loss = 2.455734, validation loss = 3.018062
2018-12-04 19:00:35,788 - INFO - epoch 0, step 4250, training loss = 2.601855, validation loss = 2.927901
2018-12-04 19:00:39,935 - INFO - epoch 0, step 4260, training loss = 2.712217, validation loss = 2.640380
2018-12-04 19:00:43,703 - INFO - epoch 0, step 4270, training loss = 2.687735, validation loss = 2.408917
2018-12-04 19:00:47,774 - INFO - epoch 0, step 4280, training loss = 2.999028, validation loss = 2.800669
2018-12-04 19:00:51,619 - INFO - epoch 0, step 4290, training loss = 2.527805, validation loss = 2.955148
2018-12-04 19:00:55,579 - INFO - epoch 0, step 4300, training loss = 2.542006, validation loss = 2.667362
2018-12-04 19:00:59,292 - INFO - epoch 0, step 4310, training loss = 2.791888, validation loss = 2.524720
2018-12-04 19:01:03,153 - INFO - epoch 0, step 4320, training loss = 2.803318, validation loss = 2.732304
2018-12-04 19:01:07,183 - INFO - epoch 0, step 4330, training loss = 2.777984, validation loss = 3.198802
2018-12-04 19:01:11,286 - INFO - epoch 0, step 4340, training loss = 2.587130, validation loss = 2.493009
2018-12-04 19:01:15,344 - INFO - epoch 0, step 4350, training loss = 2.903977, validation loss = 2.654747
2018-12-04 19:01:19,239 - INFO - epoch 0, step 4360, training loss = 2.197604, validation loss = 3.152813
2018-12-04 19:01:23,159 - INFO - epoch 0, step 4370, training loss = 3.016362, validation loss = 2.927905
2018-12-04 19:01:26,999 - INFO - epoch 0, step 4380, training loss = 2.783931, validation loss = 2.369283
2018-12-04 19:01:30,670 - INFO - epoch 0, step 4390, training loss = 2.795336, validation loss = 3.004271
2018-12-04 19:01:34,469 - INFO - epoch 0, step 4400, training loss = 3.127722, validation loss = 3.019556
2018-12-04 19:01:38,229 - INFO - epoch 0, step 4410, training loss = 2.851298, validation loss = 2.878822
2018-12-04 19:01:42,221 - INFO - epoch 0, step 4420, training loss = 2.572441, validation loss = 3.059494
2018-12-04 19:01:46,088 - INFO - epoch 0, step 4430, training loss = 2.599585, validation loss = 2.889711
2018-12-04 19:01:50,222 - INFO - epoch 0, step 4440, training loss = 2.932928, validation loss = 2.840837
2018-12-04 19:01:54,068 - INFO - epoch 0, step 4450, training loss = 2.735632, validation loss = 3.131148
2018-12-04 19:01:57,901 - INFO - epoch 0, step 4460, training loss = 2.464563, validation loss = 2.321172
2018-12-04 19:02:01,902 - INFO - epoch 0, step 4470, training loss = 1.808087, validation loss = 3.360085
2018-12-04 19:02:05,722 - INFO - epoch 0, step 4480, training loss = 3.198531, validation loss = 3.110558
2018-12-04 19:02:09,352 - INFO - epoch 0, step 4490, training loss = 3.042380, validation loss = 2.961344
2018-12-04 19:02:13,214 - INFO - epoch 0, step 4500, training loss = 2.432765, validation loss = 2.852663
2018-12-04 19:02:17,210 - INFO - epoch 0, step 4510, training loss = 2.425799, validation loss = 2.545760
2018-12-04 19:02:20,921 - INFO - epoch 0, step 4520, training loss = 2.453416, validation loss = 2.716497
2018-12-04 19:02:24,657 - INFO - epoch 0, step 4530, training loss = 2.231126, validation loss = 2.941639
2018-12-04 19:02:28,569 - INFO - epoch 0, step 4540, training loss = 2.429416, validation loss = 2.945738
2018-12-04 19:02:32,295 - INFO - epoch 0, step 4550, training loss = 2.419302, validation loss = 2.932507
2018-12-04 19:02:36,201 - INFO - epoch 0, step 4560, training loss = 3.020491, validation loss = 3.365572
2018-12-04 19:02:40,008 - INFO - epoch 0, step 4570, training loss = 2.550024, validation loss = 2.224869
2018-12-04 19:02:43,670 - INFO - epoch 0, step 4580, training loss = 2.656962, validation loss = 2.742758
2018-12-04 19:02:47,403 - INFO - epoch 0, step 4590, training loss = 2.763065, validation loss = 3.335709
2018-12-04 19:02:51,226 - INFO - epoch 0, step 4600, training loss = 2.730922, validation loss = 3.024484
2018-12-04 19:02:55,071 - INFO - epoch 0, step 4610, training loss = 2.354191, validation loss = 3.071850
2018-12-04 19:02:58,804 - INFO - epoch 0, step 4620, training loss = 2.346771, validation loss = 2.850157
2018-12-04 19:03:02,625 - INFO - epoch 0, step 4630, training loss = 2.271321, validation loss = 2.511363
2018-12-04 19:03:06,508 - INFO - epoch 0, step 4640, training loss = 3.015243, validation loss = 2.862331
2018-12-04 19:03:10,275 - INFO - epoch 0, step 4650, training loss = 2.790931, validation loss = 2.771884
2018-12-04 19:03:14,615 - INFO - epoch 0, step 4660, training loss = 2.687912, validation loss = 3.016493
2018-12-04 19:03:19,163 - INFO - epoch 0, step 4670, training loss = 2.498569, validation loss = 3.206887
2018-12-04 19:03:23,872 - INFO - epoch 0, step 4680, training loss = 2.514986, validation loss = 2.800252
2018-12-04 19:03:28,165 - INFO - epoch 0, step 4690, training loss = 3.356551, validation loss = 3.114184
2018-12-04 19:03:32,734 - INFO - epoch 0, step 4700, training loss = 3.031277, validation loss = 3.157821
2018-12-04 19:03:37,001 - INFO - epoch 0, step 4710, training loss = 3.158439, validation loss = 2.802373
2018-12-04 19:03:41,460 - INFO - epoch 0, step 4720, training loss = 2.851573, validation loss = 3.080997
2018-12-04 19:03:45,869 - INFO - epoch 0, step 4730, training loss = 2.761437, validation loss = 3.466564
2018-12-04 19:03:50,156 - INFO - epoch 0, step 4740, training loss = 2.746616, validation loss = 3.085247
2018-12-04 19:03:54,588 - INFO - epoch 0, step 4750, training loss = 2.990339, validation loss = 2.656394
2018-12-04 19:03:59,075 - INFO - epoch 0, step 4760, training loss = 2.442610, validation loss = 3.282930
2018-12-04 19:04:03,448 - INFO - epoch 0, step 4770, training loss = 2.964706, validation loss = 2.953165
2018-12-04 19:04:08,029 - INFO - epoch 0, step 4780, training loss = 2.578928, validation loss = 2.980063
2018-12-04 19:04:12,173 - INFO - epoch 0, step 4790, training loss = 2.676308, validation loss = 2.950060
2018-12-04 19:04:16,121 - INFO - epoch 0, step 4800, training loss = 2.388284, validation loss = 3.356065
2018-12-04 19:04:20,077 - INFO - epoch 0, step 4810, training loss = 2.555024, validation loss = 2.186178
2018-12-04 19:04:24,135 - INFO - epoch 0, step 4820, training loss = 2.343271, validation loss = 3.160639
2018-12-04 19:04:28,011 - INFO - epoch 0, step 4830, training loss = 2.959828, validation loss = 2.734115
2018-12-04 19:04:32,244 - INFO - epoch 0, step 4840, training loss = 2.968068, validation loss = 2.986649
2018-12-04 19:04:36,424 - INFO - epoch 0, step 4850, training loss = 2.734163, validation loss = 2.811244
2018-12-04 19:04:40,470 - INFO - epoch 0, step 4860, training loss = 2.518910, validation loss = 2.838927
2018-12-04 19:04:44,582 - INFO - epoch 0, step 4870, training loss = 2.576412, validation loss = 3.267942
2018-12-04 19:04:48,695 - INFO - epoch 0, step 4880, training loss = 3.355456, validation loss = 2.618211
2018-12-04 19:04:52,265 - INFO - epoch 0, step 4890, training loss = 3.041500, validation loss = 2.703042
2018-12-04 19:04:55,880 - INFO - epoch 0, step 4900, training loss = 2.940051, validation loss = 3.009795
2018-12-04 19:04:59,306 - INFO - epoch 0, step 4910, training loss = 3.129535, validation loss = 2.923042
2018-12-04 19:05:02,921 - INFO - epoch 0, step 4920, training loss = 2.606728, validation loss = 3.253331
2018-12-04 19:05:06,430 - INFO - epoch 0, step 4930, training loss = 2.949991, validation loss = 2.983094
2018-12-04 19:05:09,937 - INFO - epoch 0, step 4940, training loss = 2.875653, validation loss = 2.706176
2018-12-04 19:05:13,554 - INFO - epoch 0, step 4950, training loss = 2.726252, validation loss = 3.212584
2018-12-04 19:05:17,299 - INFO - epoch 0, step 4960, training loss = 2.317071, validation loss = 2.578255
2018-12-04 19:05:21,016 - INFO - epoch 0, step 4970, training loss = 3.094249, validation loss = 3.228366
2018-12-04 19:05:24,627 - INFO - epoch 0, step 4980, training loss = 2.753640, validation loss = 2.736893
2018-12-04 19:05:28,197 - INFO - epoch 0, step 4990, training loss = 3.019531, validation loss = 2.476762
2018-12-04 19:05:32,012 - INFO - epoch 0, step 5000, training loss = 2.662407, validation loss = 3.068111
2018-12-04 19:05:36,852 - INFO - epoch 0, step 5010, training loss = 2.308132, validation loss = 3.073574
2018-12-04 19:05:41,333 - INFO - epoch 0, step 5020, training loss = 3.017120, validation loss = 2.856964
2018-12-04 19:05:45,660 - INFO - epoch 0, step 5030, training loss = 2.636916, validation loss = 3.092876
2018-12-04 19:05:50,067 - INFO - epoch 0, step 5040, training loss = 1.813594, validation loss = 3.048690
2018-12-04 19:05:54,323 - INFO - epoch 0, step 5050, training loss = 2.590191, validation loss = 2.881930
2018-12-04 19:05:58,495 - INFO - epoch 0, step 5060, training loss = 2.608526, validation loss = 3.308891
2018-12-04 19:06:03,081 - INFO - epoch 0, step 5070, training loss = 2.929472, validation loss = 2.894140
2018-12-04 19:06:07,498 - INFO - epoch 0, step 5080, training loss = 2.191509, validation loss = 3.099088
2018-12-04 19:06:11,975 - INFO - epoch 0, step 5090, training loss = 2.447489, validation loss = 3.035524
2018-12-04 19:06:16,371 - INFO - epoch 0, step 5100, training loss = 2.249824, validation loss = 2.640055
2018-12-04 19:06:20,620 - INFO - epoch 0, step 5110, training loss = 2.434979, validation loss = 3.270148
2018-12-04 19:06:24,631 - INFO - epoch 0, step 5120, training loss = 2.611682, validation loss = 3.054742
2018-12-04 19:06:28,587 - INFO - epoch 0, step 5130, training loss = 2.537451, validation loss = 3.278254
2018-12-04 19:06:32,412 - INFO - epoch 0, step 5140, training loss = 2.689168, validation loss = 3.080101
2018-12-04 19:06:36,444 - INFO - epoch 0, step 5150, training loss = 2.780061, validation loss = 2.918016
2018-12-04 19:06:40,242 - INFO - epoch 0, step 5160, training loss = 2.189572, validation loss = 2.751004
2018-12-04 19:06:44,058 - INFO - epoch 0, step 5170, training loss = 2.594742, validation loss = 2.949857
2018-12-04 19:06:47,893 - INFO - epoch 0, step 5180, training loss = 2.595300, validation loss = 3.268389
2018-12-04 19:06:51,779 - INFO - epoch 0, step 5190, training loss = 2.353616, validation loss = 3.165150
2018-12-04 19:06:55,605 - INFO - epoch 0, step 5200, training loss = 2.293031, validation loss = 2.770149
2018-12-04 19:07:00,161 - INFO - epoch 0, step 5210, training loss = 2.518441, validation loss = 2.872119
2018-12-04 19:07:04,278 - INFO - epoch 0, step 5220, training loss = 2.794858, validation loss = 2.914605
2018-12-04 19:07:08,572 - INFO - epoch 0, step 5230, training loss = 2.749063, validation loss = 2.961296
2018-12-04 19:07:12,978 - INFO - epoch 0, step 5240, training loss = 2.735145, validation loss = 2.665959
2018-12-04 19:07:17,278 - INFO - epoch 0, step 5250, training loss = 2.964560, validation loss = 2.894413
2018-12-04 19:07:21,603 - INFO - epoch 0, step 5260, training loss = 2.914382, validation loss = 3.092286
2018-12-04 19:07:25,960 - INFO - epoch 0, step 5270, training loss = 3.190612, validation loss = 2.890293
2018-12-04 19:07:30,305 - INFO - epoch 0, step 5280, training loss = 2.500525, validation loss = 2.971644
2018-12-04 19:07:34,690 - INFO - epoch 0, step 5290, training loss = 2.490890, validation loss = 2.811411
2018-12-04 19:07:38,810 - INFO - epoch 0, step 5300, training loss = 2.850880, validation loss = 3.066094
2018-12-04 19:07:43,230 - INFO - epoch 0, step 5310, training loss = 2.558096, validation loss = 2.803902
2018-12-04 19:07:47,157 - INFO - epoch 0, step 5320, training loss = 2.564275, validation loss = 2.632636
2018-12-04 19:07:50,921 - INFO - epoch 0, step 5330, training loss = 3.166978, validation loss = 2.518734
2018-12-04 19:07:54,929 - INFO - epoch 0, step 5340, training loss = 2.754049, validation loss = 3.138671
2018-12-04 19:07:58,896 - INFO - epoch 0, step 5350, training loss = 2.120808, validation loss = 2.840182
2018-12-04 19:08:02,888 - INFO - epoch 0, step 5360, training loss = 2.575846, validation loss = 2.836941
2018-12-04 19:08:06,935 - INFO - epoch 0, step 5370, training loss = 2.836890, validation loss = 2.757404
2018-12-04 19:08:11,087 - INFO - epoch 0, step 5380, training loss = 2.650834, validation loss = 2.751931
2018-12-04 19:08:14,982 - INFO - epoch 0, step 5390, training loss = 2.676612, validation loss = 2.891504
2018-12-04 19:08:19,018 - INFO - epoch 0, step 5400, training loss = 2.679728, validation loss = 2.930457
2018-12-04 19:08:23,034 - INFO - epoch 0, step 5410, training loss = 2.560151, validation loss = 2.849458
2018-12-04 19:08:26,978 - INFO - epoch 0, step 5420, training loss = 2.651002, validation loss = 2.565935
2018-12-04 19:08:30,940 - INFO - epoch 0, step 5430, training loss = 2.851281, validation loss = 3.001900
2018-12-04 19:08:34,950 - INFO - epoch 0, step 5440, training loss = 2.270075, validation loss = 2.949528
2018-12-04 19:08:38,770 - INFO - epoch 0, step 5450, training loss = 2.519114, validation loss = 2.884773
2018-12-04 19:08:42,585 - INFO - epoch 0, step 5460, training loss = 2.527957, validation loss = 3.180871
2018-12-04 19:08:46,606 - INFO - epoch 0, step 5470, training loss = 2.852612, validation loss = 2.716764
2018-12-04 19:08:50,511 - INFO - epoch 0, step 5480, training loss = 2.523414, validation loss = 3.008710
2018-12-04 19:08:54,334 - INFO - epoch 0, step 5490, training loss = 2.800145, validation loss = 2.932353
2018-12-04 19:08:58,326 - INFO - epoch 0, step 5500, training loss = 2.801387, validation loss = 2.942784
2018-12-04 19:09:02,179 - INFO - epoch 0, step 5510, training loss = 2.655481, validation loss = 2.711407
2018-12-04 19:09:06,042 - INFO - epoch 0, step 5520, training loss = 2.612411, validation loss = 2.932045
2018-12-04 19:09:09,879 - INFO - epoch 0, step 5530, training loss = 2.503336, validation loss = 2.963153
2018-12-04 19:09:14,075 - INFO - epoch 0, step 5540, training loss = 2.208261, validation loss = 2.908101
2018-12-04 19:09:18,148 - INFO - epoch 0, step 5550, training loss = 2.667631, validation loss = 2.548747
2018-12-04 19:09:22,270 - INFO - epoch 0, step 5560, training loss = 2.579549, validation loss = 2.908128
2018-12-04 19:09:26,449 - INFO - epoch 0, step 5570, training loss = 2.570181, validation loss = 2.744609
2018-12-04 19:09:30,461 - INFO - epoch 0, step 5580, training loss = 2.548235, validation loss = 2.958608
2018-12-04 19:09:34,668 - INFO - epoch 0, step 5590, training loss = 2.278986, validation loss = 2.943087
2018-12-04 19:09:38,836 - INFO - epoch 0, step 5600, training loss = 2.362291, validation loss = 2.568792
2018-12-04 19:09:43,109 - INFO - epoch 0, step 5610, training loss = 2.872946, validation loss = 2.829054
2018-12-04 19:09:47,183 - INFO - epoch 0, step 5620, training loss = 2.962624, validation loss = 3.037538
2018-12-04 19:09:51,580 - INFO - epoch 0, step 5630, training loss = 2.463443, validation loss = 2.848523
2018-12-04 19:09:55,970 - INFO - epoch 0, step 5640, training loss = 2.534716, validation loss = 2.823320
2018-12-04 19:10:00,244 - INFO - epoch 0, step 5650, training loss = 2.515997, validation loss = 2.835893
2018-12-04 19:10:04,599 - INFO - epoch 0, step 5660, training loss = 2.531796, validation loss = 3.200178
2018-12-04 19:10:09,008 - INFO - epoch 0, step 5670, training loss = 2.585641, validation loss = 3.015021
2018-12-04 19:10:13,454 - INFO - epoch 0, step 5680, training loss = 2.295362, validation loss = 2.915749
2018-12-04 19:10:17,913 - INFO - epoch 0, step 5690, training loss = 2.612838, validation loss = 3.298752
2018-12-04 19:10:22,299 - INFO - epoch 0, step 5700, training loss = 2.916235, validation loss = 3.317222
2018-12-04 19:10:26,785 - INFO - epoch 0, step 5710, training loss = 2.543120, validation loss = 3.031954
2018-12-04 19:10:31,080 - INFO - epoch 0, step 5720, training loss = 2.653877, validation loss = 3.196404
2018-12-04 19:10:35,551 - INFO - epoch 0, step 5730, training loss = 2.743913, validation loss = 3.201063
2018-12-04 19:10:39,968 - INFO - epoch 0, step 5740, training loss = 2.776797, validation loss = 2.716887
2018-12-04 19:10:44,259 - INFO - epoch 0, step 5750, training loss = 2.757893, validation loss = 2.609193
2018-12-04 19:10:49,029 - INFO - epoch 0, step 5760, training loss = 2.814595, validation loss = 2.643037
2018-12-04 19:10:53,536 - INFO - epoch 0, step 5770, training loss = 2.043037, validation loss = 2.649702
2018-12-04 19:10:57,784 - INFO - epoch 0, step 5780, training loss = 2.523355, validation loss = 2.601710
2018-12-04 19:11:02,184 - INFO - epoch 0, step 5790, training loss = 2.889430, validation loss = 2.922051
2018-12-04 19:11:06,767 - INFO - epoch 0, step 5800, training loss = 2.509339, validation loss = 2.451151
2018-12-04 19:11:11,270 - INFO - epoch 0, step 5810, training loss = 2.553195, validation loss = 3.052045
2018-12-04 19:11:15,925 - INFO - epoch 0, step 5820, training loss = 2.268107, validation loss = 2.775210
2018-12-04 19:11:20,520 - INFO - epoch 0, step 5830, training loss = 2.551695, validation loss = 3.158601
2018-12-04 19:11:25,003 - INFO - epoch 0, step 5840, training loss = 2.489115, validation loss = 2.864264
2018-12-04 19:11:28,565 - INFO - epoch 0, step 5850, training loss = 2.887360, validation loss = 2.814494
2018-12-04 19:11:32,176 - INFO - epoch 0, step 5860, training loss = 2.884534, validation loss = 2.357132
2018-12-04 19:11:35,788 - INFO - epoch 0, step 5870, training loss = 2.436218, validation loss = 2.397311
2018-12-04 19:11:39,395 - INFO - epoch 0, step 5880, training loss = 2.837792, validation loss = 3.482304
2018-12-04 19:11:42,838 - INFO - epoch 0, step 5890, training loss = 2.687250, validation loss = 2.959345
2018-12-04 19:11:46,453 - INFO - epoch 0, step 5900, training loss = 2.780103, validation loss = 2.151192
2018-12-04 19:11:50,062 - INFO - epoch 0, step 5910, training loss = 3.024084, validation loss = 2.931355
2018-12-04 19:11:53,469 - INFO - epoch 0, step 5920, training loss = 3.151443, validation loss = 2.466377
2018-12-04 19:11:56,945 - INFO - epoch 0, step 5930, training loss = 2.023463, validation loss = 3.101830
2018-12-04 19:12:00,533 - INFO - epoch 0, step 5940, training loss = 2.318094, validation loss = 3.336377
2018-12-04 19:12:04,027 - INFO - epoch 0, step 5950, training loss = 2.565599, validation loss = 2.393450
2018-12-04 19:12:07,562 - INFO - epoch 0, step 5960, training loss = 2.865882, validation loss = 2.901204
2018-12-04 19:12:11,914 - INFO - epoch 0, step 5970, training loss = 2.678656, validation loss = 2.918288
2018-12-04 19:12:16,270 - INFO - epoch 0, step 5980, training loss = 2.332572, validation loss = 3.002053
2018-12-04 19:12:20,877 - INFO - epoch 0, step 5990, training loss = 2.817727, validation loss = 2.550708
2018-12-04 19:12:25,319 - INFO - epoch 0, step 6000, training loss = 2.703248, validation loss = 3.047225
2018-12-04 19:12:29,612 - INFO - epoch 0, step 6010, training loss = 2.266652, validation loss = 2.435468
2018-12-04 19:12:34,020 - INFO - epoch 0, step 6020, training loss = 2.435275, validation loss = 2.908044
2018-12-04 19:12:38,481 - INFO - epoch 0, step 6030, training loss = 2.693612, validation loss = 2.586577
2018-12-04 19:12:42,915 - INFO - epoch 0, step 6040, training loss = 2.609462, validation loss = 3.194465
2018-12-04 19:12:47,533 - INFO - epoch 0, step 6050, training loss = 2.489929, validation loss = 3.022345
2018-12-04 19:12:51,845 - INFO - epoch 0, step 6060, training loss = 2.843491, validation loss = 3.098778
2018-12-04 19:12:56,164 - INFO - epoch 0, step 6070, training loss = 2.853689, validation loss = 2.996125
2018-12-04 19:13:00,670 - INFO - epoch 0, step 6080, training loss = 2.319749, validation loss = 2.853447
2018-12-04 19:13:04,974 - INFO - epoch 0, step 6090, training loss = 2.800159, validation loss = 2.673043
2018-12-04 19:13:09,375 - INFO - epoch 0, step 6100, training loss = 2.819632, validation loss = 2.270204
2018-12-04 19:13:13,783 - INFO - epoch 0, step 6110, training loss = 2.219499, validation loss = 3.137082
2018-12-04 19:13:18,918 - INFO - epoch 0, step 6120, training loss = 2.739007, validation loss = 2.787645
2018-12-04 19:13:23,292 - INFO - epoch 0, step 6130, training loss = 2.172455, validation loss = 2.909974
2018-12-04 19:13:27,543 - INFO - epoch 0, step 6140, training loss = 2.859105, validation loss = 2.614982
2018-12-04 19:13:31,799 - INFO - epoch 0, step 6150, training loss = 2.557974, validation loss = 2.901946
2018-12-04 19:13:36,236 - INFO - epoch 0, step 6160, training loss = 2.597883, validation loss = 2.854346
2018-12-04 19:13:40,639 - INFO - epoch 0, step 6170, training loss = 2.612282, validation loss = 2.342996
2018-12-04 19:13:44,974 - INFO - epoch 0, step 6180, training loss = 2.314789, validation loss = 2.408998
2018-12-04 19:13:49,310 - INFO - epoch 0, step 6190, training loss = 2.544815, validation loss = 2.858629
2018-12-04 19:13:53,847 - INFO - epoch 0, step 6200, training loss = 3.117601, validation loss = 2.414110
2018-12-04 19:13:58,207 - INFO - epoch 0, step 6210, training loss = 2.697340, validation loss = 3.047224
2018-12-04 19:14:02,898 - INFO - epoch 0, step 6220, training loss = 2.743808, validation loss = 2.923418
2018-12-04 19:14:07,279 - INFO - epoch 0, step 6230, training loss = 2.144144, validation loss = 2.609399
2018-12-04 19:14:11,495 - INFO - epoch 0, step 6240, training loss = 2.514093, validation loss = 3.140110
2018-12-04 19:14:15,843 - INFO - epoch 0, step 6250, training loss = 2.160820, validation loss = 3.115283
2018-12-04 19:14:20,148 - INFO - epoch 0, step 6260, training loss = 2.933962, validation loss = 2.519058
2018-12-04 19:14:24,534 - INFO - epoch 0, step 6270, training loss = 2.522899, validation loss = 3.311328
2018-12-04 19:14:28,514 - INFO - epoch 0, step 6280, training loss = 2.786533, validation loss = 2.875155
2018-12-04 19:14:32,744 - INFO - epoch 0, step 6290, training loss = 2.134128, validation loss = 3.391883
2018-12-04 19:14:36,545 - INFO - epoch 0, step 6300, training loss = 2.955652, validation loss = 2.680797
2018-12-04 19:14:40,515 - INFO - epoch 0, step 6310, training loss = 2.054783, validation loss = 2.335741
2018-12-04 19:14:44,524 - INFO - epoch 0, step 6320, training loss = 2.726438, validation loss = 2.491803
2018-12-04 19:14:48,395 - INFO - epoch 0, step 6330, training loss = 2.679460, validation loss = 2.727392
2018-12-04 19:14:52,483 - INFO - epoch 0, step 6340, training loss = 3.302567, validation loss = 2.693407
2018-12-04 19:14:56,386 - INFO - epoch 0, step 6350, training loss = 2.388122, validation loss = 3.440447
2018-12-04 19:15:00,069 - INFO - epoch 0, step 6360, training loss = 2.599544, validation loss = 2.839817
2018-12-04 19:15:04,063 - INFO - epoch 0, step 6370, training loss = 3.212628, validation loss = 2.464494
2018-12-04 19:15:07,954 - INFO - epoch 0, step 6380, training loss = 2.591651, validation loss = 2.365135
2018-12-04 19:15:12,076 - INFO - epoch 0, step 6390, training loss = 1.985468, validation loss = 2.825995
2018-12-04 19:15:16,094 - INFO - epoch 0, step 6400, training loss = 2.656209, validation loss = 2.239458
2018-12-04 19:15:20,007 - INFO - epoch 0, step 6410, training loss = 2.629508, validation loss = 2.898450
2018-12-04 19:15:23,973 - INFO - epoch 0, step 6420, training loss = 2.333901, validation loss = 3.184755
2018-12-04 19:15:27,963 - INFO - epoch 0, step 6430, training loss = 2.069634, validation loss = 2.543833
2018-12-04 19:15:31,852 - INFO - epoch 0, step 6440, training loss = 3.054054, validation loss = 3.050725
2018-12-04 19:15:35,799 - INFO - epoch 0, step 6450, training loss = 2.553757, validation loss = 3.067256
2018-12-04 19:15:39,617 - INFO - epoch 0, step 6460, training loss = 2.840242, validation loss = 3.031869
2018-12-04 19:15:43,696 - INFO - epoch 0, step 6470, training loss = 2.123116, validation loss = 2.302173
2018-12-04 19:15:47,407 - INFO - epoch 0, step 6480, training loss = 2.622346, validation loss = 3.132571
2018-12-04 19:15:51,493 - INFO - epoch 0, step 6490, training loss = 2.067130, validation loss = 3.080987
2018-12-04 19:15:55,456 - INFO - epoch 0, step 6500, training loss = 2.376103, validation loss = 2.888734
2018-12-04 19:15:59,400 - INFO - epoch 0, step 6510, training loss = 2.470859, validation loss = 2.557151
2018-12-04 19:16:03,319 - INFO - epoch 0, step 6520, training loss = 2.536414, validation loss = 2.727258
2018-12-04 19:16:07,238 - INFO - epoch 0, step 6530, training loss = 3.077549, validation loss = 3.370726
2018-12-04 19:16:10,973 - INFO - epoch 0, step 6540, training loss = 2.438827, validation loss = 3.163127
2018-12-04 19:16:14,976 - INFO - epoch 0, step 6550, training loss = 2.520314, validation loss = 2.872136
2018-12-04 19:16:18,839 - INFO - epoch 0, step 6560, training loss = 2.561867, validation loss = 2.560484
2018-12-04 19:16:22,466 - INFO - epoch 0, step 6570, training loss = 2.878437, validation loss = 3.287955
2018-12-04 19:16:26,236 - INFO - epoch 0, step 6580, training loss = 2.652030, validation loss = 3.278929
2018-12-04 19:16:30,141 - INFO - epoch 0, step 6590, training loss = 2.795485, validation loss = 2.505027
2018-12-04 19:16:33,805 - INFO - epoch 0, step 6600, training loss = 2.696019, validation loss = 2.758556
2018-12-04 19:16:37,723 - INFO - epoch 0, step 6610, training loss = 2.386678, validation loss = 3.322841
2018-12-04 19:16:41,601 - INFO - epoch 0, step 6620, training loss = 2.600239, validation loss = 3.125519
2018-12-04 19:16:45,635 - INFO - epoch 0, step 6630, training loss = 2.621355, validation loss = 3.098373
2018-12-04 19:16:49,555 - INFO - epoch 0, step 6640, training loss = 2.718323, validation loss = 3.110763
2018-12-04 19:16:53,488 - INFO - epoch 0, step 6650, training loss = 2.650669, validation loss = 3.170809
2018-12-04 19:16:57,649 - INFO - epoch 0, step 6660, training loss = 2.342630, validation loss = 3.764192
2018-12-04 19:17:01,766 - INFO - epoch 0, step 6670, training loss = 2.563785, validation loss = 2.804749
2018-12-04 19:17:05,635 - INFO - epoch 0, step 6680, training loss = 2.504033, validation loss = 2.763577
2018-12-04 19:17:09,969 - INFO - epoch 0, step 6690, training loss = 2.747279, validation loss = 2.721565
2018-12-04 19:17:13,774 - INFO - epoch 0, step 6700, training loss = 3.024828, validation loss = 3.017688
2018-12-04 19:17:17,715 - INFO - epoch 0, step 6710, training loss = 2.090608, validation loss = 3.434634
2018-12-04 19:17:21,540 - INFO - epoch 0, step 6720, training loss = 2.776610, validation loss = 3.174235
2018-12-04 19:17:25,633 - INFO - epoch 0, step 6730, training loss = 2.541650, validation loss = 3.041784
2018-12-04 19:17:29,638 - INFO - epoch 0, step 6740, training loss = 2.457118, validation loss = 2.091697
2018-12-04 19:17:33,790 - INFO - epoch 0, step 6750, training loss = 2.591322, validation loss = 3.633107
2018-12-04 19:17:37,697 - INFO - epoch 0, step 6760, training loss = 2.740323, validation loss = 2.847780
2018-12-04 19:17:41,572 - INFO - epoch 0, step 6770, training loss = 2.635053, validation loss = 3.365469
2018-12-04 19:17:45,455 - INFO - epoch 0, step 6780, training loss = 2.799275, validation loss = 3.088533
2018-12-04 19:17:49,388 - INFO - epoch 0, step 6790, training loss = 2.149844, validation loss = 3.305783
2018-12-04 19:17:53,138 - INFO - epoch 0, step 6800, training loss = 2.667049, validation loss = 3.057544
2018-12-04 19:17:56,893 - INFO - epoch 0, step 6810, training loss = 2.756605, validation loss = 3.338161
2018-12-04 19:18:00,738 - INFO - epoch 0, step 6820, training loss = 2.133652, validation loss = 3.304693
2018-12-04 19:18:04,865 - INFO - epoch 0, step 6830, training loss = 2.673597, validation loss = 2.741766
2018-12-04 19:18:08,633 - INFO - epoch 0, step 6840, training loss = 2.455635, validation loss = 2.957666
2018-12-04 19:18:12,354 - INFO - epoch 0, step 6850, training loss = 2.375945, validation loss = 2.967208
2018-12-04 19:18:16,138 - INFO - epoch 0, step 6860, training loss = 2.644481, validation loss = 3.037274
2018-12-04 19:18:19,794 - INFO - epoch 0, step 6870, training loss = 2.923685, validation loss = 3.654660
2018-12-04 19:18:23,740 - INFO - epoch 0, step 6880, training loss = 2.647190, validation loss = 2.956781
2018-12-04 19:18:27,448 - INFO - epoch 0, step 6890, training loss = 2.884344, validation loss = 2.698003
2018-12-04 19:18:31,198 - INFO - epoch 0, step 6900, training loss = 2.150572, validation loss = 3.698652
2018-12-04 19:18:35,390 - INFO - epoch 0, step 6910, training loss = 2.913519, validation loss = 3.608279
2018-12-04 19:18:39,434 - INFO - epoch 0, step 6920, training loss = 3.068237, validation loss = 3.507157
2018-12-04 19:18:43,734 - INFO - epoch 0, step 6930, training loss = 2.494251, validation loss = 2.787735
2018-12-04 19:18:47,694 - INFO - epoch 0, step 6940, training loss = 2.845965, validation loss = 2.821020
2018-12-04 19:18:51,775 - INFO - epoch 0, step 6950, training loss = 2.759613, validation loss = 3.293499
2018-12-04 19:18:56,001 - INFO - epoch 0, step 6960, training loss = 2.811679, validation loss = 3.086184
2018-12-04 19:19:00,227 - INFO - epoch 0, step 6970, training loss = 2.369552, validation loss = 3.048287
2018-12-04 19:19:04,574 - INFO - epoch 0, step 6980, training loss = 2.278095, validation loss = 2.722621
2018-12-04 19:19:08,951 - INFO - epoch 0, step 6990, training loss = 2.681698, validation loss = 3.016225
2018-12-04 19:19:13,237 - INFO - epoch 0, step 7000, training loss = 2.600215, validation loss = 3.306578
2018-12-04 19:19:17,875 - INFO - epoch 0, step 7010, training loss = 2.559792, validation loss = 3.190425
2018-12-04 19:19:22,196 - INFO - epoch 0, step 7020, training loss = 2.112789, validation loss = 3.129353
2018-12-04 19:19:26,660 - INFO - epoch 0, step 7030, training loss = 2.625731, validation loss = 3.549416
2018-12-04 19:19:31,216 - INFO - epoch 0, step 7040, training loss = 2.333452, validation loss = 3.062395
2018-12-04 19:19:35,856 - INFO - epoch 0, step 7050, training loss = 2.269168, validation loss = 3.065418
2018-12-04 19:19:40,237 - INFO - epoch 0, step 7060, training loss = 3.315706, validation loss = 2.805295
2018-12-04 19:19:44,394 - INFO - epoch 0, step 7070, training loss = 2.766274, validation loss = 3.066030
2018-12-04 19:19:48,853 - INFO - epoch 0, step 7080, training loss = 2.602194, validation loss = 3.166158
2018-12-04 19:19:53,244 - INFO - epoch 0, step 7090, training loss = 2.355249, validation loss = 3.000215
2018-12-04 19:19:57,492 - INFO - epoch 0, step 7100, training loss = 2.872849, validation loss = 3.051819
2018-12-04 19:20:01,777 - INFO - epoch 0, step 7110, training loss = 2.139615, validation loss = 3.462349
2018-12-04 19:20:06,267 - INFO - epoch 0, step 7120, training loss = 2.741537, validation loss = 2.764096
2018-12-04 19:20:10,837 - INFO - epoch 0, step 7130, training loss = 2.147789, validation loss = 3.296067
2018-12-04 19:20:15,313 - INFO - epoch 0, step 7140, training loss = 2.513603, validation loss = 2.870591
2018-12-04 19:20:19,651 - INFO - epoch 0, step 7150, training loss = 2.148888, validation loss = 3.143919
2018-12-04 19:20:23,767 - INFO - epoch 0, step 7160, training loss = 2.982104, validation loss = 3.186068
2018-12-04 19:20:28,083 - INFO - epoch 0, step 7170, training loss = 2.430152, validation loss = 2.806666
2018-12-04 19:20:32,394 - INFO - epoch 0, step 7180, training loss = 2.555151, validation loss = 3.264940
2018-12-04 19:20:36,992 - INFO - epoch 0, step 7190, training loss = 2.474354, validation loss = 3.108691
2018-12-04 19:20:41,339 - INFO - epoch 0, step 7200, training loss = 2.287808, validation loss = 3.438153
2018-12-04 19:20:46,179 - INFO - epoch 0, step 7210, training loss = 2.830418, validation loss = 3.432349
2018-12-04 19:20:50,700 - INFO - epoch 0, step 7220, training loss = 2.428196, validation loss = 3.380449
2018-12-04 19:20:54,436 - INFO - epoch 0, step 7230, training loss = 2.780334, validation loss = 2.801111
2018-12-04 19:20:58,144 - INFO - epoch 0, step 7240, training loss = 2.517706, validation loss = 3.113109
2018-12-04 19:21:01,951 - INFO - epoch 0, step 7250, training loss = 2.299953, validation loss = 2.553841
2018-12-04 19:21:05,729 - INFO - epoch 0, step 7260, training loss = 3.062078, validation loss = 2.753867
2018-12-04 19:21:09,663 - INFO - epoch 0, step 7270, training loss = 2.569607, validation loss = 3.118203
2018-12-04 19:21:13,418 - INFO - epoch 0, step 7280, training loss = 2.764424, validation loss = 3.192362
2018-12-04 19:21:17,317 - INFO - epoch 0, step 7290, training loss = 2.441803, validation loss = 2.770121
2018-12-04 19:21:21,333 - INFO - epoch 0, step 7300, training loss = 2.204890, validation loss = 3.055642
2018-12-04 19:21:25,352 - INFO - epoch 0, step 7310, training loss = 2.299500, validation loss = 3.305796
2018-12-04 19:21:29,342 - INFO - epoch 0, step 7320, training loss = 2.653930, validation loss = 2.734325
2018-12-04 19:21:33,089 - INFO - epoch 0, step 7330, training loss = 2.946847, validation loss = 2.871179
2018-12-04 19:21:36,944 - INFO - epoch 0, step 7340, training loss = 2.471651, validation loss = 2.926980
2018-12-04 19:21:40,963 - INFO - epoch 0, step 7350, training loss = 2.718411, validation loss = 3.388979
2018-12-04 19:21:44,776 - INFO - epoch 0, step 7360, training loss = 2.698051, validation loss = 3.578715
2018-12-04 19:21:48,343 - INFO - epoch 0, step 7370, training loss = 2.762911, validation loss = 3.414901
2018-12-04 19:21:52,269 - INFO - epoch 0, step 7380, training loss = 2.828963, validation loss = 3.238267
2018-12-04 19:21:56,135 - INFO - epoch 0, step 7390, training loss = 2.489169, validation loss = 3.743923
2018-12-04 19:22:00,063 - INFO - epoch 0, step 7400, training loss = 2.622359, validation loss = 3.100211
2018-12-04 19:22:03,907 - INFO - epoch 0, step 7410, training loss = 2.264349, validation loss = 3.036173
2018-12-04 19:22:07,556 - INFO - epoch 0, step 7420, training loss = 2.593305, validation loss = 3.566290
2018-12-04 19:22:10,845 - INFO - epoch 0, step 7430, training loss = 2.390855, validation loss = 3.508596
2018-12-04 19:22:14,515 - INFO - epoch 0, step 7440, training loss = 2.258772, validation loss = 2.795713
2018-12-04 19:22:18,042 - INFO - epoch 0, step 7450, training loss = 2.840704, validation loss = 3.423621
2018-12-04 19:22:21,521 - INFO - epoch 0, step 7460, training loss = 2.053058, validation loss = 2.998669
2018-12-04 19:22:25,079 - INFO - epoch 0, step 7470, training loss = 2.497110, validation loss = 3.312895
2018-12-04 19:22:28,694 - INFO - epoch 0, step 7480, training loss = 2.466943, validation loss = 2.977472
2018-12-04 19:22:32,180 - INFO - epoch 0, step 7490, training loss = 2.689038, validation loss = 3.200881
2018-12-04 19:22:35,641 - INFO - epoch 0, step 7500, training loss = 2.093482, validation loss = 3.285934
2018-12-04 19:22:39,388 - INFO - epoch 0, step 7510, training loss = 2.191708, validation loss = 2.661281
2018-12-04 19:22:42,955 - INFO - epoch 0, step 7520, training loss = 1.675727, validation loss = 3.218096
2018-12-04 19:22:46,575 - INFO - epoch 0, step 7530, training loss = 2.575192, validation loss = 3.693309
2018-12-04 19:22:50,015 - INFO - epoch 0, step 7540, training loss = 2.865547, validation loss = 2.792151
2018-12-04 19:22:53,512 - INFO - epoch 0, step 7550, training loss = 2.468704, validation loss = 3.110045
2018-12-04 19:22:57,502 - INFO - epoch 0, step 7560, training loss = 2.278103, validation loss = 3.752847
2018-12-04 19:23:01,350 - INFO - epoch 0, step 7570, training loss = 2.647543, validation loss = 2.779525
2018-12-04 19:23:05,015 - INFO - epoch 0, step 7580, training loss = 2.472982, validation loss = 3.283960
2018-12-04 19:23:08,920 - INFO - epoch 0, step 7590, training loss = 2.577821, validation loss = 2.980932
2018-12-04 19:23:12,745 - INFO - epoch 0, step 7600, training loss = 2.714288, validation loss = 3.263796
2018-12-04 19:23:16,441 - INFO - epoch 0, step 7610, training loss = 2.243252, validation loss = 3.496297
2018-12-04 19:23:20,391 - INFO - epoch 0, step 7620, training loss = 2.774363, validation loss = 3.865033
2018-12-04 19:23:24,529 - INFO - epoch 0, step 7630, training loss = 2.546829, validation loss = 3.516355
2018-12-04 19:23:28,357 - INFO - epoch 0, step 7640, training loss = 2.062987, validation loss = 3.608523
2018-12-04 19:23:32,257 - INFO - epoch 0, step 7650, training loss = 2.424143, validation loss = 3.281917
2018-12-04 19:23:36,124 - INFO - epoch 0, step 7660, training loss = 2.523045, validation loss = 2.800912
2018-12-04 19:23:39,980 - INFO - epoch 0, step 7670, training loss = 2.285382, validation loss = 3.271729
2018-12-04 19:23:43,955 - INFO - epoch 0, step 7680, training loss = 2.305385, validation loss = 4.028103
2018-12-04 19:23:48,036 - INFO - epoch 0, step 7690, training loss = 1.925831, validation loss = 3.008297
2018-12-04 19:23:51,871 - INFO - epoch 0, step 7700, training loss = 2.248711, validation loss = 3.433474
2018-12-04 19:23:55,753 - INFO - epoch 0, step 7710, training loss = 2.659136, validation loss = 2.468972
2018-12-04 19:23:59,739 - INFO - epoch 0, step 7720, training loss = 2.646379, validation loss = 3.278955
2018-12-04 19:24:03,440 - INFO - epoch 0, step 7730, training loss = 2.577678, validation loss = 3.306752
2018-12-04 19:24:07,356 - INFO - epoch 0, step 7740, training loss = 2.988555, validation loss = 3.447173
2018-12-04 19:24:11,363 - INFO - epoch 0, step 7750, training loss = 2.266095, validation loss = 2.815744
2018-12-04 19:24:15,294 - INFO - epoch 0, step 7760, training loss = 2.715800, validation loss = 3.293327
2018-12-04 19:24:19,208 - INFO - epoch 0, step 7770, training loss = 2.815025, validation loss = 3.426495
2018-12-04 19:24:23,189 - INFO - epoch 0, step 7780, training loss = 2.467720, validation loss = 3.205140
2018-12-04 19:24:27,234 - INFO - epoch 0, step 7790, training loss = 2.794062, validation loss = 3.515687
2018-12-04 19:24:31,066 - INFO - epoch 0, step 7800, training loss = 2.902232, validation loss = 3.673774
2018-12-04 19:24:35,276 - INFO - epoch 0, step 7810, training loss = 2.359942, validation loss = 3.017302
2018-12-04 19:24:39,258 - INFO - epoch 0, step 7820, training loss = 3.135955, validation loss = 3.464779
2018-12-04 19:24:43,442 - INFO - epoch 0, step 7830, training loss = 2.583848, validation loss = 3.397733
2018-12-04 19:24:47,427 - INFO - epoch 0, step 7840, training loss = 2.670796, validation loss = 3.315544
2018-12-04 19:24:51,745 - INFO - epoch 0, step 7850, training loss = 2.584754, validation loss = 3.642939
2018-12-04 19:24:55,744 - INFO - epoch 0, step 7860, training loss = 2.454918, validation loss = 3.716099
2018-12-04 19:24:59,792 - INFO - epoch 0, step 7870, training loss = 2.531471, validation loss = 3.581905
2018-12-04 19:25:03,960 - INFO - epoch 0, step 7880, training loss = 2.032821, validation loss = 2.967865
2018-12-04 19:25:08,088 - INFO - epoch 0, step 7890, training loss = 2.569614, validation loss = 3.280587
2018-12-04 19:25:12,219 - INFO - epoch 0, step 7900, training loss = 2.357449, validation loss = 3.491492
2018-12-04 19:25:16,317 - INFO - epoch 0, step 7910, training loss = 2.854645, validation loss = 3.524344
2018-12-04 19:25:20,834 - INFO - epoch 0, step 7920, training loss = 2.641340, validation loss = 3.425410
2018-12-04 19:25:24,761 - INFO - epoch 0, step 7930, training loss = 2.758823, validation loss = 3.283785
2018-12-04 19:25:28,844 - INFO - epoch 0, step 7940, training loss = 1.854114, validation loss = 3.604477
2018-12-04 19:25:33,039 - INFO - epoch 0, step 7950, training loss = 2.177788, validation loss = 3.596119
2018-12-04 19:25:37,456 - INFO - epoch 0, step 7960, training loss = 2.219956, validation loss = 2.976295
2018-12-04 19:25:41,910 - INFO - epoch 0, step 7970, training loss = 2.035796, validation loss = 3.381696
2018-12-04 19:25:46,355 - INFO - epoch 0, step 7980, training loss = 2.363819, validation loss = 3.116077
2018-12-04 19:25:50,626 - INFO - epoch 0, step 7990, training loss = 2.468885, validation loss = 3.449021
2018-12-04 19:25:54,798 - INFO - epoch 0, step 8000, training loss = 2.775755, validation loss = 2.966945
2018-12-04 19:25:59,163 - INFO - epoch 0, step 8010, training loss = 2.947211, validation loss = 3.343475
2018-12-04 19:26:03,424 - INFO - epoch 0, step 8020, training loss = 2.021693, validation loss = 3.524140
2018-12-04 19:26:07,882 - INFO - epoch 0, step 8030, training loss = 2.944085, validation loss = 3.855077
2018-12-04 19:26:12,496 - INFO - epoch 0, step 8040, training loss = 2.690962, validation loss = 2.943036
2018-12-04 19:26:16,894 - INFO - epoch 0, step 8050, training loss = 2.269842, validation loss = 3.299599
2018-12-04 19:26:21,416 - INFO - epoch 0, step 8060, training loss = 2.723786, validation loss = 2.812806
2018-12-04 19:26:25,960 - INFO - epoch 0, step 8070, training loss = 2.266025, validation loss = 2.667463
2018-12-04 19:26:30,287 - INFO - epoch 0, step 8080, training loss = 2.523141, validation loss = 3.640481
2018-12-04 19:26:34,585 - INFO - epoch 0, step 8090, training loss = 2.180848, validation loss = 3.088172
2018-12-04 19:26:39,095 - INFO - epoch 0, step 8100, training loss = 2.468058, validation loss = 3.114516
2018-12-04 19:26:43,547 - INFO - epoch 0, step 8110, training loss = 2.673212, validation loss = 3.058491
2018-12-04 19:26:47,978 - INFO - epoch 0, step 8120, training loss = 2.717001, validation loss = 3.797559
2018-12-04 19:26:52,635 - INFO - epoch 0, step 8130, training loss = 2.767985, validation loss = 3.895813
2018-12-04 19:26:57,135 - INFO - epoch 0, step 8140, training loss = 2.417196, validation loss = 3.805316
2018-12-04 19:27:01,769 - INFO - epoch 0, step 8150, training loss = 2.689879, validation loss = 3.292090
2018-12-04 19:27:06,116 - INFO - epoch 0, step 8160, training loss = 2.611679, validation loss = 3.360083
2018-12-04 19:27:10,616 - INFO - epoch 0, step 8170, training loss = 2.697437, validation loss = 3.369727
2018-12-04 19:27:15,192 - INFO - epoch 0, step 8180, training loss = 2.461256, validation loss = 2.916567
2018-12-04 19:27:19,895 - INFO - epoch 0, step 8190, training loss = 2.597032, validation loss = 3.410150
2018-12-04 19:27:24,358 - INFO - epoch 0, step 8200, training loss = 2.959052, validation loss = 3.487417
2018-12-04 19:27:28,742 - INFO - epoch 0, step 8210, training loss = 2.499244, validation loss = 2.977180
2018-12-04 19:27:33,200 - INFO - epoch 0, step 8220, training loss = 2.371467, validation loss = 3.429739
2018-12-04 19:27:37,687 - INFO - epoch 0, step 8230, training loss = 2.317894, validation loss = 3.031979
2018-12-04 19:27:41,966 - INFO - epoch 0, step 8240, training loss = 2.528967, validation loss = 3.254301
2018-12-04 19:27:46,158 - INFO - epoch 0, step 8250, training loss = 2.859703, validation loss = 3.575371
2018-12-04 19:27:50,109 - INFO - epoch 0, step 8260, training loss = 2.819013, validation loss = 3.961496
2018-12-04 19:27:54,194 - INFO - epoch 0, step 8270, training loss = 2.374931, validation loss = 3.529532
2018-12-04 19:27:58,269 - INFO - epoch 0, step 8280, training loss = 2.609609, validation loss = 3.414043
2018-12-04 19:28:02,236 - INFO - epoch 0, step 8290, training loss = 2.459842, validation loss = 3.235231
2018-12-04 19:28:06,125 - INFO - epoch 0, step 8300, training loss = 2.819791, validation loss = 3.362613
2018-12-04 19:28:09,728 - INFO - epoch 0, step 8310, training loss = 2.649640, validation loss = 3.472116
2018-12-04 19:28:13,258 - INFO - epoch 0, step 8320, training loss = 2.573596, validation loss = 2.908548
2018-12-04 19:28:16,892 - INFO - epoch 0, step 8330, training loss = 3.308065, validation loss = 3.644749
2018-12-04 19:28:20,554 - INFO - epoch 0, step 8340, training loss = 2.428319, validation loss = 4.058013
2018-12-04 19:28:24,225 - INFO - epoch 0, step 8350, training loss = 2.400254, validation loss = 3.817730
2018-12-04 19:28:27,715 - INFO - epoch 0, step 8360, training loss = 2.556727, validation loss = 3.991293
2018-12-04 19:28:31,150 - INFO - epoch 0, step 8370, training loss = 2.581483, validation loss = 3.105159
2018-12-04 19:28:34,790 - INFO - epoch 0, step 8380, training loss = 2.721492, validation loss = 3.900947
2018-12-04 19:28:38,414 - INFO - epoch 0, step 8390, training loss = 2.129182, validation loss = 3.680791
2018-12-04 19:28:42,063 - INFO - epoch 0, step 8400, training loss = 2.840452, validation loss = 2.959553
2018-12-04 19:28:45,683 - INFO - epoch 0, step 8410, training loss = 1.905882, validation loss = 3.556253
2018-12-04 19:28:49,894 - INFO - epoch 0, step 8420, training loss = 2.754061, validation loss = 3.175422
2018-12-04 19:28:54,331 - INFO - epoch 0, step 8430, training loss = 2.643624, validation loss = 3.061811
2018-12-04 19:28:58,742 - INFO - epoch 0, step 8440, training loss = 1.586820, validation loss = 3.699085
2018-12-04 19:29:03,033 - INFO - epoch 0, step 8450, training loss = 2.451795, validation loss = 3.020350
2018-12-04 19:29:07,410 - INFO - epoch 0, step 8460, training loss = 2.477030, validation loss = 4.006781
2018-12-04 19:29:11,686 - INFO - epoch 0, step 8470, training loss = 2.474335, validation loss = 3.386198
2018-12-04 19:29:16,001 - INFO - epoch 0, step 8480, training loss = 2.518772, validation loss = 2.714927
2018-12-04 19:29:20,136 - INFO - epoch 0, step 8490, training loss = 2.870751, validation loss = 3.544672
2018-12-04 19:29:24,435 - INFO - epoch 0, step 8500, training loss = 2.410452, validation loss = 3.556764
2018-12-04 19:29:28,863 - INFO - epoch 0, step 8510, training loss = 2.829698, validation loss = 3.043221
2018-12-04 19:29:33,105 - INFO - epoch 0, step 8520, training loss = 2.699359, validation loss = 3.347964
2018-12-04 19:29:36,558 - INFO - epoch 0, step 8530, training loss = 2.311829, validation loss = 3.016268
2018-12-04 19:29:40,018 - INFO - epoch 0, step 8540, training loss = 2.452464, validation loss = 3.744248
2018-12-04 19:29:43,792 - INFO - epoch 0, step 8550, training loss = 2.710965, validation loss = 3.600442
2018-12-04 19:29:47,461 - INFO - epoch 0, step 8560, training loss = 2.872018, validation loss = 3.759199
2018-12-04 19:29:51,371 - INFO - epoch 0, step 8570, training loss = 2.727501, validation loss = 3.041858
2018-12-04 19:29:54,933 - INFO - epoch 0, step 8580, training loss = 3.022545, validation loss = 4.019044
2018-12-04 19:29:58,734 - INFO - epoch 0, step 8590, training loss = 2.285244, validation loss = 3.012931
2018-12-04 19:30:02,381 - INFO - epoch 0, step 8600, training loss = 2.108665, validation loss = 3.870638
2018-12-04 19:30:06,180 - INFO - epoch 0, step 8610, training loss = 1.784214, validation loss = 2.745754
2018-12-04 19:30:09,872 - INFO - epoch 0, step 8620, training loss = 2.196615, validation loss = 3.644002
2018-12-04 19:30:13,631 - INFO - epoch 0, step 8630, training loss = 2.583395, validation loss = 3.172653
2018-12-04 19:30:17,252 - INFO - epoch 0, step 8640, training loss = 2.208150, validation loss = 2.888528
2018-12-04 19:30:20,821 - INFO - epoch 0, step 8650, training loss = 2.517758, validation loss = 3.064838
2018-12-04 19:30:24,620 - INFO - epoch 0, step 8660, training loss = 2.852380, validation loss = 3.245626
2018-12-04 19:30:28,671 - INFO - epoch 0, step 8670, training loss = 2.397671, validation loss = 3.396724
2018-12-04 19:30:32,580 - INFO - epoch 0, step 8680, training loss = 2.611010, validation loss = 3.215684
2018-12-04 19:30:36,354 - INFO - epoch 0, step 8690, training loss = 3.125360, validation loss = 3.161674
2018-12-04 19:30:40,301 - INFO - epoch 0, step 8700, training loss = 2.737391, validation loss = 2.789260
2018-12-04 19:30:44,444 - INFO - epoch 0, step 8710, training loss = 2.373116, validation loss = 3.474585
2018-12-04 19:30:48,515 - INFO - epoch 0, step 8720, training loss = 2.593123, validation loss = 3.488107
2018-12-04 19:30:52,346 - INFO - epoch 0, step 8730, training loss = 2.402958, validation loss = 3.074156
2018-12-04 19:30:56,287 - INFO - epoch 0, step 8740, training loss = 2.742005, validation loss = 2.666963
2018-12-04 19:31:00,196 - INFO - epoch 0, step 8750, training loss = 2.798430, validation loss = 3.256785
2018-12-04 19:31:04,897 - INFO - epoch 0, step 8760, training loss = 2.822384, validation loss = 3.558729
2018-12-04 19:31:08,501 - INFO - epoch 0, step 8770, training loss = 2.551926, validation loss = 3.284269
2018-12-04 19:31:12,064 - INFO - epoch 0, step 8780, training loss = 2.425082, validation loss = 2.300415
2018-12-04 19:31:15,592 - INFO - epoch 0, step 8790, training loss = 2.966559, validation loss = 2.636836
2018-12-04 19:31:19,053 - INFO - epoch 0, step 8800, training loss = 2.277197, validation loss = 2.708919
2018-12-04 19:31:22,673 - INFO - epoch 0, step 8810, training loss = 2.511834, validation loss = 3.345825
2018-12-04 19:31:26,580 - INFO - epoch 0, step 8820, training loss = 2.665064, validation loss = 2.481591
2018-12-04 19:31:30,178 - INFO - epoch 0, step 8830, training loss = 2.219054, validation loss = 3.318462
2018-12-04 19:31:33,842 - INFO - epoch 0, step 8840, training loss = 2.759742, validation loss = 3.096650
2018-12-04 19:31:37,443 - INFO - epoch 0, step 8850, training loss = 2.351865, validation loss = 2.762743
2018-12-04 19:31:41,064 - INFO - epoch 0, step 8860, training loss = 2.446826, validation loss = 3.188591
2018-12-04 19:31:44,807 - INFO - epoch 0, step 8870, training loss = 2.776236, validation loss = 4.130413
2018-12-04 19:31:48,558 - INFO - epoch 0, step 8880, training loss = 2.354792, validation loss = 3.089528
2018-12-04 19:31:52,447 - INFO - epoch 0, step 8890, training loss = 2.802318, validation loss = 3.154568
2018-12-04 19:31:56,530 - INFO - epoch 0, step 8900, training loss = 2.076161, validation loss = 2.997365
2018-12-04 19:32:00,631 - INFO - epoch 0, step 8910, training loss = 2.508705, validation loss = 2.914973
2018-12-04 19:32:04,338 - INFO - epoch 0, step 8920, training loss = 2.908037, validation loss = 2.602406
2018-12-04 19:32:08,144 - INFO - epoch 0, step 8930, training loss = 2.622172, validation loss = 2.184629
2018-12-04 19:32:12,080 - INFO - epoch 0, step 8940, training loss = 2.819747, validation loss = 2.536745
2018-12-04 19:32:15,886 - INFO - epoch 0, step 8950, training loss = 2.735825, validation loss = 3.184757
2018-12-04 19:32:19,923 - INFO - epoch 0, step 8960, training loss = 2.910875, validation loss = 3.129574
2018-12-04 19:32:23,529 - INFO - epoch 0, step 8970, training loss = 2.988629, validation loss = 3.088868
2018-12-04 19:32:27,084 - INFO - epoch 0, step 8980, training loss = 2.567997, validation loss = 3.053175
2018-12-04 19:32:30,683 - INFO - epoch 0, step 8990, training loss = 2.701298, validation loss = 3.277285
2018-12-04 19:32:34,242 - INFO - epoch 0, step 9000, training loss = 2.415312, validation loss = 3.360081
2018-12-04 19:32:37,874 - INFO - epoch 0, step 9010, training loss = 2.667371, validation loss = 3.243950
2018-12-04 19:32:41,405 - INFO - epoch 0, step 9020, training loss = 2.722189, validation loss = 3.382495
2018-12-04 19:32:45,050 - INFO - epoch 0, step 9030, training loss = 3.024853, validation loss = 3.454865
2018-12-04 19:32:48,881 - INFO - epoch 0, step 9040, training loss = 2.675870, validation loss = 3.181580
2018-12-04 19:32:52,503 - INFO - epoch 0, step 9050, training loss = 2.842571, validation loss = 3.128928
2018-12-04 19:32:56,180 - INFO - epoch 0, step 9060, training loss = 3.063699, validation loss = 2.494646
2018-12-04 19:32:59,837 - INFO - epoch 0, step 9070, training loss = 2.333627, validation loss = 3.301419
2018-12-04 19:33:03,453 - INFO - epoch 0, step 9080, training loss = 2.636156, validation loss = 3.018387
2018-12-04 19:33:07,673 - INFO - epoch 0, step 9090, training loss = 2.560318, validation loss = 2.697600
2018-12-04 19:33:11,989 - INFO - epoch 0, step 9100, training loss = 2.269965, validation loss = 2.980826
2018-12-04 19:33:16,438 - INFO - epoch 0, step 9110, training loss = 2.373359, validation loss = 3.052327
2018-12-04 19:33:20,881 - INFO - epoch 0, step 9120, training loss = 2.221209, validation loss = 3.591599
2018-12-04 19:33:24,787 - INFO - epoch 0, step 9130, training loss = 2.433212, validation loss = 2.604690
2018-12-04 19:33:28,410 - INFO - epoch 0, step 9140, training loss = 2.146615, validation loss = 3.124082
2018-12-04 19:33:32,218 - INFO - epoch 0, step 9150, training loss = 2.375684, validation loss = 3.062759
2018-12-04 19:33:35,708 - INFO - epoch 0, step 9160, training loss = 2.564184, validation loss = 3.353005
2018-12-04 19:33:39,135 - INFO - epoch 0, step 9170, training loss = 2.706689, validation loss = 3.129979
2018-12-04 19:33:42,559 - INFO - epoch 0, step 9180, training loss = 2.235942, validation loss = 2.572734
2018-12-04 19:33:46,380 - INFO - epoch 0, step 9190, training loss = 2.490958, validation loss = 3.385392
2018-12-04 19:33:49,919 - INFO - epoch 0, step 9200, training loss = 1.924716, validation loss = 3.103537
2018-12-04 19:33:53,600 - INFO - epoch 0, step 9210, training loss = 2.650944, validation loss = 3.115314
2018-12-04 19:33:57,181 - INFO - epoch 0, step 9220, training loss = 2.161481, validation loss = 2.557474
2018-12-04 19:34:00,693 - INFO - epoch 0, step 9230, training loss = 2.306800, validation loss = 2.624351
2018-12-04 19:34:04,442 - INFO - epoch 0, step 9240, training loss = 2.788709, validation loss = 2.690955
2018-12-04 19:34:08,024 - INFO - epoch 0, step 9250, training loss = 1.955393, validation loss = 3.176605
2018-12-04 19:34:11,687 - INFO - epoch 0, step 9260, training loss = 2.609123, validation loss = 3.557583
2018-12-04 19:34:15,456 - INFO - epoch 0, step 9270, training loss = 2.977670, validation loss = 3.204844
2018-12-04 19:34:19,371 - INFO - epoch 0, step 9280, training loss = 2.046974, validation loss = 3.214682
2018-12-04 19:34:22,926 - INFO - epoch 0, step 9290, training loss = 2.260426, validation loss = 3.789776
2018-12-04 19:34:26,863 - INFO - epoch 0, step 9300, training loss = 2.253207, validation loss = 1.972539
2018-12-04 19:34:30,522 - INFO - epoch 0, step 9310, training loss = 2.682050, validation loss = 3.371884
2018-12-04 19:34:34,180 - INFO - epoch 0, step 9320, training loss = 2.574631, validation loss = 3.014054
2018-12-04 19:34:37,988 - INFO - epoch 0, step 9330, training loss = 2.166818, validation loss = 3.269277
2018-12-04 19:34:42,050 - INFO - epoch 0, step 9340, training loss = 2.603819, validation loss = 3.498522
2018-12-04 19:34:45,900 - INFO - epoch 0, step 9350, training loss = 2.407931, validation loss = 3.049591
2018-12-04 19:34:49,728 - INFO - epoch 0, step 9360, training loss = 1.964347, validation loss = 3.721832
2018-12-04 19:34:53,681 - INFO - epoch 0, step 9370, training loss = 2.528136, validation loss = 3.463363
2018-12-04 19:34:57,966 - INFO - epoch 0, step 9380, training loss = 2.505886, validation loss = 4.138862
2018-12-04 19:35:02,293 - INFO - epoch 0, step 9390, training loss = 2.507541, validation loss = 3.670668
2018-12-04 19:35:06,545 - INFO - epoch 0, step 9400, training loss = 2.529142, validation loss = 3.422449
2018-12-04 19:35:10,909 - INFO - epoch 0, step 9410, training loss = 2.500053, validation loss = 3.164152
2018-12-04 19:35:15,167 - INFO - epoch 0, step 9420, training loss = 2.195711, validation loss = 3.171265
2018-12-04 19:35:19,423 - INFO - epoch 0, step 9430, training loss = 2.340823, validation loss = 4.375457
2018-12-04 19:35:23,943 - INFO - epoch 0, step 9440, training loss = 2.615101, validation loss = 3.470679
2018-12-04 19:35:28,205 - INFO - epoch 0, step 9450, training loss = 2.786347, validation loss = 2.842992
2018-12-04 19:35:32,473 - INFO - epoch 0, step 9460, training loss = 2.335094, validation loss = 3.069221
2018-12-04 19:35:36,910 - INFO - epoch 0, step 9470, training loss = 2.185748, validation loss = 3.386986
2018-12-04 19:35:40,718 - INFO - epoch 0, step 9480, training loss = 2.550626, validation loss = 3.351442
2018-12-04 19:35:44,293 - INFO - epoch 0, step 9490, training loss = 2.618541, validation loss = 3.888161
2018-12-04 19:35:48,019 - INFO - epoch 0, step 9500, training loss = 1.573109, validation loss = 3.694132
2018-12-04 19:35:51,646 - INFO - epoch 0, step 9510, training loss = 2.220162, validation loss = 3.802387
2018-12-04 19:35:55,112 - INFO - epoch 0, step 9520, training loss = 2.509543, validation loss = 3.565204
2018-12-04 19:35:58,513 - INFO - epoch 0, step 9530, training loss = 2.669461, validation loss = 3.510904
2018-12-04 19:36:02,107 - INFO - epoch 0, step 9540, training loss = 2.459263, validation loss = 2.986568
2018-12-04 19:36:05,734 - INFO - epoch 0, step 9550, training loss = 2.337994, validation loss = 3.538025
2018-12-04 19:36:09,360 - INFO - epoch 0, step 9560, training loss = 2.224937, validation loss = 3.717652
2018-12-04 19:36:12,913 - INFO - epoch 0, step 9570, training loss = 2.176891, validation loss = 3.579473
2018-12-04 19:36:16,294 - INFO - epoch 0, step 9580, training loss = 2.004147, validation loss = 4.123127
2018-12-04 19:36:19,841 - INFO - epoch 0, step 9590, training loss = 2.120127, validation loss = 3.595983
2018-12-04 19:36:23,641 - INFO - epoch 0, step 9600, training loss = 2.004719, validation loss = 3.198712
2018-12-04 19:36:27,437 - INFO - epoch 0, step 9610, training loss = 2.248127, validation loss = 3.165728
2018-12-04 19:36:31,324 - INFO - epoch 0, step 9620, training loss = 2.869449, validation loss = 3.306617
2018-12-04 19:36:35,202 - INFO - epoch 0, step 9630, training loss = 2.266330, validation loss = 3.267996
2018-12-04 19:36:39,072 - INFO - epoch 0, step 9640, training loss = 1.738841, validation loss = 2.938517
2018-12-04 19:36:42,951 - INFO - epoch 0, step 9650, training loss = 1.815882, validation loss = 3.357885
2018-12-04 19:36:46,839 - INFO - epoch 0, step 9660, training loss = 2.869919, validation loss = 3.721683
2018-12-04 19:36:50,683 - INFO - epoch 0, step 9670, training loss = 2.493723, validation loss = 3.479103
2018-12-04 19:36:54,507 - INFO - epoch 0, step 9680, training loss = 2.440140, validation loss = 4.313974
2018-12-04 19:36:58,362 - INFO - epoch 0, step 9690, training loss = 2.821100, validation loss = 2.855322
2018-12-04 19:37:02,315 - INFO - epoch 0, step 9700, training loss = 2.363402, validation loss = 2.973141
2018-12-04 19:37:07,031 - INFO - epoch 0, step 9710, training loss = 2.414297, validation loss = 3.169228
2018-12-04 19:37:11,745 - INFO - epoch 0, step 9720, training loss = 2.389764, validation loss = 3.534650
2018-12-04 19:37:16,203 - INFO - epoch 0, step 9730, training loss = 2.508673, validation loss = 3.214845
2018-12-04 19:37:20,699 - INFO - epoch 0, step 9740, training loss = 2.658356, validation loss = 4.253873
2018-12-04 19:37:25,227 - INFO - epoch 0, step 9750, training loss = 2.414706, validation loss = 4.009965
2018-12-04 19:37:29,567 - INFO - epoch 0, step 9760, training loss = 2.421511, validation loss = 3.748485
2018-12-04 19:37:33,950 - INFO - epoch 0, step 9770, training loss = 2.917871, validation loss = 3.337398
2018-12-04 19:37:38,771 - INFO - epoch 0, step 9780, training loss = 2.908209, validation loss = 3.279978
2018-12-04 19:37:43,385 - INFO - epoch 0, step 9790, training loss = 2.304853, validation loss = 3.900474
2018-12-04 19:37:48,013 - INFO - epoch 0, step 9800, training loss = 2.087477, validation loss = 3.696803
2018-12-04 19:37:52,501 - INFO - epoch 0, step 9810, training loss = 2.430118, validation loss = 3.184181
2018-12-04 19:37:56,975 - INFO - epoch 0, step 9820, training loss = 2.568523, validation loss = 3.353125
2018-12-04 19:38:01,271 - INFO - epoch 0, step 9830, training loss = 2.853821, validation loss = 3.734709
2018-12-04 19:38:05,179 - INFO - epoch 0, step 9840, training loss = 2.306843, validation loss = 3.144664
2018-12-04 19:38:09,144 - INFO - epoch 0, step 9850, training loss = 2.309408, validation loss = 3.227592
2018-12-04 19:38:12,770 - INFO - epoch 0, step 9860, training loss = 1.843262, validation loss = 3.407201
2018-12-04 19:38:16,313 - INFO - epoch 0, step 9870, training loss = 2.710864, validation loss = 3.510488
2018-12-04 19:38:19,866 - INFO - epoch 0, step 9880, training loss = 2.100462, validation loss = 3.732768
2018-12-04 19:38:23,450 - INFO - epoch 0, step 9890, training loss = 2.054019, validation loss = 3.499038
2018-12-04 19:38:27,171 - INFO - epoch 0, step 9900, training loss = 1.971756, validation loss = 3.913797
2018-12-04 19:38:30,862 - INFO - epoch 0, step 9910, training loss = 2.107811, validation loss = 3.377826
2018-12-04 19:38:34,412 - INFO - epoch 0, step 9920, training loss = 2.384112, validation loss = 2.934294
2018-12-04 19:38:38,366 - INFO - epoch 0, step 9930, training loss = 2.339355, validation loss = 2.911701
2018-12-04 19:38:41,940 - INFO - epoch 0, step 9940, training loss = 2.536733, validation loss = 3.185053
2018-12-04 19:38:45,723 - INFO - epoch 0, step 9950, training loss = 2.447231, validation loss = 3.696038
2018-12-04 19:38:49,180 - INFO - epoch 0, step 9960, training loss = 2.685555, validation loss = 3.396323
2018-12-04 19:38:53,131 - INFO - epoch 0, step 9970, training loss = 1.923297, validation loss = 3.592770
2018-12-04 19:38:56,838 - INFO - epoch 0, step 9980, training loss = 2.522643, validation loss = 3.441795
2018-12-04 19:39:00,555 - INFO - epoch 0, step 9990, training loss = 2.373510, validation loss = 3.256281
2018-12-04 19:39:04,210 - INFO - epoch 0, step 10000, training loss = 2.948963, validation loss = 3.043611
2018-12-04 19:39:07,973 - INFO - epoch 0, step 10010, training loss = 2.115198, validation loss = 3.459098
2018-12-04 19:39:11,584 - INFO - epoch 0, step 10020, training loss = 2.004151, validation loss = 3.740371
2018-12-04 19:39:15,138 - INFO - epoch 0, step 10030, training loss = 2.687780, validation loss = 3.421741
2018-12-04 19:39:18,807 - INFO - epoch 0, step 10040, training loss = 2.504834, validation loss = 3.918474
2018-12-04 19:39:22,361 - INFO - epoch 0, step 10050, training loss = 2.627061, validation loss = 3.146737
2018-12-04 19:39:25,887 - INFO - epoch 0, step 10060, training loss = 2.748168, validation loss = 3.060087
2018-12-04 19:39:29,330 - INFO - epoch 0, step 10070, training loss = 2.510810, validation loss = 3.799463
2018-12-04 19:39:32,770 - INFO - epoch 0, step 10080, training loss = 2.709543, validation loss = 3.675833
2018-12-04 19:39:36,446 - INFO - epoch 0, step 10090, training loss = 2.915746, validation loss = 3.628446
2018-12-04 19:39:39,859 - INFO - epoch 0, step 10100, training loss = 2.670961, validation loss = 3.711696
2018-12-04 19:39:43,347 - INFO - epoch 0, step 10110, training loss = 2.656051, validation loss = 3.684555
2018-12-04 19:39:46,772 - INFO - epoch 0, step 10120, training loss = 2.401386, validation loss = 3.517878
2018-12-04 19:39:50,187 - INFO - epoch 0, step 10130, training loss = 2.545430, validation loss = 3.693642
2018-12-04 19:39:53,630 - INFO - epoch 0, step 10140, training loss = 2.402053, validation loss = 3.886697
2018-12-04 19:39:57,104 - INFO - epoch 0, step 10150, training loss = 2.476902, validation loss = 4.261914
2018-12-04 19:40:00,823 - INFO - epoch 0, step 10160, training loss = 2.846105, validation loss = 3.551131
2018-12-04 19:40:04,570 - INFO - epoch 0, step 10170, training loss = 2.565845, validation loss = 3.017235
2018-12-04 19:40:08,386 - INFO - epoch 0, step 10180, training loss = 2.666845, validation loss = 3.319649
2018-12-04 19:40:12,387 - INFO - epoch 0, step 10190, training loss = 2.629220, validation loss = 3.712324
2018-12-04 19:40:16,240 - INFO - epoch 0, step 10200, training loss = 2.630393, validation loss = 3.441687
2018-12-04 19:40:19,990 - INFO - epoch 0, step 10210, training loss = 2.461459, validation loss = 4.123184
2018-12-04 19:40:23,832 - INFO - epoch 0, step 10220, training loss = 2.758529, validation loss = 4.253574
2018-12-04 19:40:27,710 - INFO - epoch 0, step 10230, training loss = 2.299364, validation loss = 3.569282
2018-12-04 19:40:31,251 - INFO - epoch 0, step 10240, training loss = 2.280326, validation loss = 3.289964
2018-12-04 19:40:34,830 - INFO - epoch 0, step 10250, training loss = 2.745929, validation loss = 3.615851
2018-12-04 19:40:38,339 - INFO - epoch 0, step 10260, training loss = 2.652249, validation loss = 3.297416
2018-12-04 19:40:41,951 - INFO - epoch 0, step 10270, training loss = 2.513805, validation loss = 3.619434
2018-12-04 19:40:45,519 - INFO - epoch 0, step 10280, training loss = 2.505038, validation loss = 3.622052
2018-12-04 19:40:49,033 - INFO - epoch 0, step 10290, training loss = 2.637215, validation loss = 3.542353
2018-12-04 19:40:52,531 - INFO - epoch 0, step 10300, training loss = 2.478590, validation loss = 3.770986
2018-12-04 19:40:55,952 - INFO - epoch 0, step 10310, training loss = 2.609488, validation loss = 3.648640
2018-12-04 19:40:59,453 - INFO - epoch 0, step 10320, training loss = 2.535831, validation loss = 2.784847
2018-12-04 19:41:03,172 - INFO - epoch 0, step 10330, training loss = 2.696332, validation loss = 2.951897
2018-12-04 19:41:07,313 - INFO - epoch 0, step 10340, training loss = 2.667909, validation loss = 3.375326
2018-12-04 19:41:11,648 - INFO - epoch 0, step 10350, training loss = 2.732525, validation loss = 3.553550
2018-12-04 19:41:16,006 - INFO - epoch 0, step 10360, training loss = 2.378175, validation loss = 3.836018
2018-12-04 19:41:20,497 - INFO - epoch 0, step 10370, training loss = 2.909312, validation loss = 3.851859
2018-12-04 19:41:24,748 - INFO - epoch 0, step 10380, training loss = 2.837616, validation loss = 4.124377
2018-12-04 19:41:28,888 - INFO - epoch 0, step 10390, training loss = 2.713666, validation loss = 3.596698
2018-12-04 19:41:32,930 - INFO - epoch 0, step 10400, training loss = 2.968897, validation loss = 3.701239
2018-12-04 19:41:37,946 - INFO - epoch 0, step 10410, training loss = 2.378874, validation loss = 3.921787
2018-12-04 19:41:42,875 - INFO - epoch 0, step 10420, training loss = 2.708760, validation loss = 3.830127
2018-12-04 19:41:47,329 - INFO - epoch 0, step 10430, training loss = 2.233619, validation loss = 3.749496
2018-12-04 19:41:51,371 - INFO - epoch 0, step 10440, training loss = 2.432839, validation loss = 3.814586
2018-12-04 19:41:55,619 - INFO - epoch 0, step 10450, training loss = 2.431497, validation loss = 3.981146
2018-12-04 19:41:59,785 - INFO - epoch 0, step 10460, training loss = 2.504273, validation loss = 2.960185
2018-12-04 19:42:04,080 - INFO - epoch 0, step 10470, training loss = 2.394621, validation loss = 3.089086
2018-12-04 19:42:08,210 - INFO - epoch 0, step 10480, training loss = 2.672515, validation loss = 3.033836
2018-12-04 19:42:12,457 - INFO - epoch 0, step 10490, training loss = 2.236971, validation loss = 3.396594
2018-12-04 19:42:16,952 - INFO - epoch 0, step 10500, training loss = 2.303908, validation loss = 3.718616
2018-12-04 19:42:21,145 - INFO - epoch 0, step 10510, training loss = 2.713926, validation loss = 3.466791
2018-12-04 19:42:25,259 - INFO - epoch 0, step 10520, training loss = 2.765073, validation loss = 3.554793
2018-12-04 19:42:29,231 - INFO - epoch 0, step 10530, training loss = 2.344075, validation loss = 3.799756
2018-12-04 19:42:33,222 - INFO - epoch 0, step 10540, training loss = 2.685754, validation loss = 2.814610
2018-12-04 19:42:37,352 - INFO - epoch 0, step 10550, training loss = 2.549605, validation loss = 2.780236
2018-12-04 19:42:41,254 - INFO - epoch 0, step 10560, training loss = 2.444901, validation loss = 3.324332
2018-12-04 19:42:45,181 - INFO - epoch 0, step 10570, training loss = 2.692739, validation loss = 3.050324
2018-12-04 19:42:49,282 - INFO - epoch 0, step 10580, training loss = 2.468441, validation loss = 2.666349
2018-12-04 19:42:53,237 - INFO - epoch 0, step 10590, training loss = 2.732153, validation loss = 3.689326
2018-12-04 19:42:57,030 - INFO - epoch 0, step 10600, training loss = 2.287891, validation loss = 3.534280
2018-12-04 19:43:00,856 - INFO - epoch 0, step 10610, training loss = 2.720425, validation loss = 2.682981
2018-12-04 19:43:04,800 - INFO - epoch 0, step 10620, training loss = 2.082914, validation loss = 2.545264
2018-12-04 19:43:08,768 - INFO - epoch 0, step 10630, training loss = 2.240209, validation loss = 2.214270
2018-12-04 19:43:12,791 - INFO - epoch 0, step 10640, training loss = 2.523397, validation loss = 2.000875
2018-12-04 19:43:16,697 - INFO - epoch 0, step 10650, training loss = 2.570471, validation loss = 2.832915
2018-12-04 19:43:20,646 - INFO - epoch 0, step 10660, training loss = 2.269559, validation loss = 2.433312
2018-12-04 19:43:24,662 - INFO - epoch 0, step 10670, training loss = 2.327724, validation loss = 2.380647
2018-12-04 19:43:28,606 - INFO - epoch 0, step 10680, training loss = 2.021991, validation loss = 2.872226
2018-12-04 19:43:32,682 - INFO - epoch 0, step 10690, training loss = 2.410689, validation loss = 2.692450
2018-12-04 19:43:36,352 - INFO - epoch 0, step 10700, training loss = 3.307666, validation loss = 2.779662
2018-12-04 19:43:40,390 - INFO - epoch 0, step 10710, training loss = 2.767735, validation loss = 3.132924
2018-12-04 19:43:44,125 - INFO - epoch 0, step 10720, training loss = 2.484860, validation loss = 2.573868
2018-12-04 19:43:48,220 - INFO - epoch 0, step 10730, training loss = 2.680374, validation loss = 2.624486
2018-12-04 19:43:52,219 - INFO - epoch 0, step 10740, training loss = 2.038641, validation loss = 2.424952
2018-12-04 19:43:56,256 - INFO - epoch 0, step 10750, training loss = 2.144417, validation loss = 2.637239
2018-12-04 19:44:00,036 - INFO - epoch 0, step 10760, training loss = 2.759386, validation loss = 3.644151
2018-12-04 19:44:04,205 - INFO - epoch 0, step 10770, training loss = 2.743563, validation loss = 2.949048
2018-12-04 19:44:08,142 - INFO - epoch 0, step 10780, training loss = 2.348438, validation loss = 3.105954
2018-12-04 19:44:12,132 - INFO - epoch 0, step 10790, training loss = 2.575731, validation loss = 3.082408
2018-12-04 19:44:16,192 - INFO - epoch 0, step 10800, training loss = 2.605007, validation loss = 2.306211
2018-12-04 19:44:20,321 - INFO - epoch 0, step 10810, training loss = 2.624835, validation loss = 2.233915
2018-12-04 19:44:24,211 - INFO - epoch 0, step 10820, training loss = 2.804169, validation loss = 2.762908
2018-12-04 19:44:27,966 - INFO - epoch 0, step 10830, training loss = 2.553581, validation loss = 2.848410
2018-12-04 19:44:32,003 - INFO - epoch 0, step 10840, training loss = 2.725922, validation loss = 2.517852
2018-12-04 19:44:35,969 - INFO - epoch 0, step 10850, training loss = 2.602038, validation loss = 2.637194
2018-12-04 19:44:40,143 - INFO - epoch 0, step 10860, training loss = 2.487233, validation loss = 3.122995
2018-12-04 19:44:43,792 - INFO - epoch 0, step 10870, training loss = 1.846796, validation loss = 2.578558
2018-12-04 19:44:47,541 - INFO - epoch 0, step 10880, training loss = 2.426396, validation loss = 2.550832
2018-12-04 19:44:51,249 - INFO - epoch 0, step 10890, training loss = 2.415793, validation loss = 2.288181
2018-12-04 19:44:55,075 - INFO - epoch 0, step 10900, training loss = 2.511110, validation loss = 3.163867
2018-12-04 19:44:58,718 - INFO - epoch 0, step 10910, training loss = 2.336639, validation loss = 2.548957
2018-12-04 19:45:02,176 - INFO - epoch 0, step 10920, training loss = 1.772089, validation loss = 3.102319
2018-12-04 19:45:05,609 - INFO - epoch 0, step 10930, training loss = 2.721875, validation loss = 2.753709
2018-12-04 19:45:09,228 - INFO - epoch 0, step 10940, training loss = 2.940587, validation loss = 2.361796
2018-12-04 19:45:12,840 - INFO - epoch 0, step 10950, training loss = 2.215014, validation loss = 2.589982
2018-12-04 19:45:16,461 - INFO - epoch 0, step 10960, training loss = 2.318447, validation loss = 3.092051
2018-12-04 19:45:20,071 - INFO - epoch 0, step 10970, training loss = 2.591240, validation loss = 3.169338
2018-12-04 19:45:23,627 - INFO - epoch 0, step 10980, training loss = 2.688976, validation loss = 3.120600
2018-12-04 19:45:27,276 - INFO - epoch 0, step 10990, training loss = 2.229935, validation loss = 2.449527
2018-12-04 19:45:30,575 - INFO - epoch 0, step 11000, training loss = 2.912731, validation loss = 2.714624
2018-12-04 19:45:33,989 - INFO - epoch 0, step 11010, training loss = 2.642714, validation loss = 2.846059
2018-12-04 19:45:37,334 - INFO - epoch 0, step 11020, training loss = 2.775702, validation loss = 3.179522
2018-12-04 19:45:41,061 - INFO - epoch 0, step 11030, training loss = 2.532812, validation loss = 3.135240
2018-12-04 19:45:45,021 - INFO - epoch 0, step 11040, training loss = 2.538979, validation loss = 3.023036
2018-12-04 19:45:49,297 - INFO - epoch 0, step 11050, training loss = 2.371055, validation loss = 2.971087
2018-12-04 19:45:53,376 - INFO - epoch 0, step 11060, training loss = 2.605688, validation loss = 2.548144
2018-12-04 19:45:57,584 - INFO - epoch 0, step 11070, training loss = 2.598771, validation loss = 2.965932
2018-12-04 19:46:01,540 - INFO - epoch 0, step 11080, training loss = 2.455852, validation loss = 3.295850
2018-12-04 19:46:05,884 - INFO - epoch 0, step 11090, training loss = 2.244876, validation loss = 3.024107
2018-12-04 19:46:09,884 - INFO - epoch 0, step 11100, training loss = 2.545391, validation loss = 3.213408
2018-12-04 19:46:13,976 - INFO - epoch 0, step 11110, training loss = 2.478925, validation loss = 2.806581
2018-12-04 19:46:18,156 - INFO - epoch 0, step 11120, training loss = 2.424025, validation loss = 2.860081
2018-12-04 19:46:21,899 - INFO - epoch 0, step 11130, training loss = 2.609433, validation loss = 2.424756
2018-12-04 19:46:25,487 - INFO - epoch 0, step 11140, training loss = 2.117159, validation loss = 2.500918
2018-12-04 19:46:29,228 - INFO - epoch 0, step 11150, training loss = 1.833519, validation loss = 2.629958
2018-12-04 19:46:32,905 - INFO - epoch 0, step 11160, training loss = 1.969830, validation loss = 2.946588
2018-12-04 19:46:36,963 - INFO - epoch 0, step 11170, training loss = 1.947520, validation loss = 2.852995
2018-12-04 19:46:40,736 - INFO - epoch 0, step 11180, training loss = 1.999557, validation loss = 2.992852
2018-12-04 19:46:44,543 - INFO - epoch 0, step 11190, training loss = 2.064016, validation loss = 2.900763
2018-12-04 19:46:48,383 - INFO - epoch 0, step 11200, training loss = 2.903150, validation loss = 2.739146
2018-12-04 19:46:52,061 - INFO - epoch 0, step 11210, training loss = 2.679013, validation loss = 2.946788
2018-12-04 19:46:55,903 - INFO - epoch 0, step 11220, training loss = 2.148280, validation loss = 2.269800
2018-12-04 19:46:59,659 - INFO - epoch 0, step 11230, training loss = 2.525161, validation loss = 3.077388
2018-12-04 19:47:03,501 - INFO - epoch 0, step 11240, training loss = 2.438622, validation loss = 3.044654
2018-12-04 19:47:07,217 - INFO - epoch 0, step 11250, training loss = 2.295549, validation loss = 3.206947
2018-12-04 19:47:10,725 - INFO - epoch 0, step 11260, training loss = 2.559579, validation loss = 2.569137
2018-12-04 19:47:14,183 - INFO - epoch 0, step 11270, training loss = 2.349437, validation loss = 3.041225
2018-12-04 19:47:17,670 - INFO - epoch 0, step 11280, training loss = 2.307926, validation loss = 3.108444
2018-12-04 19:47:21,204 - INFO - epoch 0, step 11290, training loss = 2.403403, validation loss = 3.796887
2018-12-04 19:47:25,119 - INFO - epoch 0, step 11300, training loss = 2.418701, validation loss = 2.133031
2018-12-04 19:47:28,771 - INFO - epoch 0, step 11310, training loss = 2.599596, validation loss = 2.999650
2018-12-04 19:47:32,475 - INFO - epoch 0, step 11320, training loss = 2.636833, validation loss = 2.633373
2018-12-04 19:47:36,213 - INFO - epoch 0, step 11330, training loss = 2.785262, validation loss = 2.435526
2018-12-04 19:47:40,007 - INFO - epoch 0, step 11340, training loss = 2.215749, validation loss = 3.326241
2018-12-04 19:47:43,855 - INFO - epoch 0, step 11350, training loss = 2.487083, validation loss = 2.935398
2018-12-04 19:47:47,778 - INFO - epoch 0, step 11360, training loss = 2.410219, validation loss = 3.226675
2018-12-04 19:47:51,395 - INFO - epoch 0, step 11370, training loss = 3.102649, validation loss = 3.520123
2018-12-04 19:47:55,154 - INFO - epoch 0, step 11380, training loss = 2.274042, validation loss = 2.722359
2018-12-04 19:47:58,868 - INFO - epoch 0, step 11390, training loss = 1.994802, validation loss = 2.633006
2018-12-04 19:48:02,563 - INFO - epoch 0, step 11400, training loss = 2.534087, validation loss = 2.930471
2018-12-04 19:48:06,323 - INFO - epoch 0, step 11410, training loss = 2.209632, validation loss = 2.859342
2018-12-04 19:48:09,871 - INFO - epoch 0, step 11420, training loss = 2.630761, validation loss = 3.008307
2018-12-04 19:48:13,534 - INFO - epoch 0, step 11430, training loss = 2.841907, validation loss = 2.793911
2018-12-04 19:48:17,406 - INFO - epoch 0, step 11440, training loss = 1.747446, validation loss = 3.180685
2018-12-04 19:48:21,087 - INFO - epoch 0, step 11450, training loss = 2.619417, validation loss = 3.390716
2018-12-04 19:48:24,839 - INFO - epoch 0, step 11460, training loss = 2.022368, validation loss = 2.594637
2018-12-04 19:48:29,012 - INFO - epoch 0, step 11470, training loss = 2.916373, validation loss = 2.716611
2018-12-04 19:48:33,132 - INFO - epoch 0, step 11480, training loss = 2.307842, validation loss = 2.616635
2018-12-04 19:48:37,471 - INFO - epoch 0, step 11490, training loss = 2.614165, validation loss = 2.746140
2018-12-04 19:48:41,707 - INFO - epoch 0, step 11500, training loss = 2.790476, validation loss = 3.012691
2018-12-04 19:48:45,755 - INFO - epoch 0, step 11510, training loss = 2.468557, validation loss = 3.219861
2018-12-04 19:48:49,682 - INFO - epoch 0, step 11520, training loss = 2.629277, validation loss = 2.865102
2018-12-04 19:48:53,502 - INFO - epoch 0, step 11530, training loss = 2.595039, validation loss = 2.649886
2018-12-04 19:48:57,489 - INFO - epoch 0, step 11540, training loss = 2.700788, validation loss = 2.926096
2018-12-04 19:49:01,780 - INFO - epoch 0, step 11550, training loss = 2.010781, validation loss = 2.891378
2018-12-04 19:49:05,974 - INFO - epoch 0, step 11560, training loss = 1.837656, validation loss = 2.572086
2018-12-04 19:49:10,422 - INFO - epoch 0, step 11570, training loss = 2.153399, validation loss = 3.371698
2018-12-04 19:49:14,715 - INFO - epoch 0, step 11580, training loss = 3.036613, validation loss = 3.189557
2018-12-04 19:49:19,025 - INFO - epoch 0, step 11590, training loss = 2.183017, validation loss = 3.124684
2018-12-04 19:49:23,255 - INFO - epoch 0, step 11600, training loss = 2.256865, validation loss = 2.604336
2018-12-04 19:49:27,543 - INFO - epoch 0, step 11610, training loss = 2.287124, validation loss = 2.831096
2018-12-04 19:49:31,738 - INFO - epoch 0, step 11620, training loss = 1.704734, validation loss = 2.388684
2018-12-04 19:49:35,978 - INFO - epoch 0, step 11630, training loss = 2.886143, validation loss = 3.298911
2018-12-04 19:49:40,281 - INFO - epoch 0, step 11640, training loss = 2.535719, validation loss = 3.087628
2018-12-04 19:49:44,228 - INFO - epoch 0, step 11650, training loss = 2.179085, validation loss = 3.143198
2018-12-04 19:49:48,076 - INFO - epoch 0, step 11660, training loss = 2.218233, validation loss = 3.304391
2018-12-04 19:49:51,625 - INFO - epoch 0, step 11670, training loss = 2.709980, validation loss = 3.006983
2018-12-04 19:49:55,262 - INFO - epoch 0, step 11680, training loss = 2.522457, validation loss = 2.973855
2018-12-04 19:49:59,012 - INFO - epoch 0, step 11690, training loss = 2.171872, validation loss = 3.549888
2018-12-04 19:50:02,592 - INFO - epoch 0, step 11700, training loss = 2.614774, validation loss = 3.723071
2018-12-04 19:50:06,282 - INFO - epoch 0, step 11710, training loss = 2.280773, validation loss = 3.151819
2018-12-04 19:50:09,727 - INFO - epoch 0, step 11720, training loss = 2.190111, validation loss = 3.470372
2018-12-04 19:50:13,785 - INFO - epoch 0, step 11730, training loss = 2.230271, validation loss = 2.963892
2018-12-04 19:50:17,408 - INFO - epoch 0, step 11740, training loss = 2.616567, validation loss = 3.108948
2018-12-04 19:50:21,219 - INFO - epoch 0, step 11750, training loss = 1.932034, validation loss = 2.862907
2018-12-04 19:50:24,872 - INFO - epoch 0, step 11760, training loss = 2.652026, validation loss = 2.597183
2018-12-04 19:50:28,576 - INFO - epoch 0, step 11770, training loss = 2.522132, validation loss = 2.820211
2018-12-04 19:50:32,459 - INFO - epoch 0, step 11780, training loss = 2.875583, validation loss = 3.234156
2018-12-04 19:50:36,885 - INFO - epoch 0, step 11790, training loss = 2.510700, validation loss = 2.666383
2018-12-04 19:50:40,951 - INFO - epoch 0, step 11800, training loss = 2.606929, validation loss = 3.400469
2018-12-04 19:50:45,003 - INFO - epoch 0, step 11810, training loss = 2.332386, validation loss = 2.450260
2018-12-04 19:50:49,297 - INFO - epoch 0, step 11820, training loss = 2.728484, validation loss = 2.786054
2018-12-04 19:50:53,325 - INFO - epoch 0, step 11830, training loss = 2.652258, validation loss = 3.037316
2018-12-04 19:50:57,459 - INFO - epoch 0, step 11840, training loss = 2.204716, validation loss = 2.978848
2018-12-04 19:51:01,474 - INFO - epoch 0, step 11850, training loss = 2.319493, validation loss = 2.752689
2018-12-04 19:51:05,708 - INFO - epoch 0, step 11860, training loss = 2.501437, validation loss = 2.680002
2018-12-04 19:51:09,650 - INFO - epoch 0, step 11870, training loss = 2.250474, validation loss = 3.021825
2018-12-04 19:51:13,743 - INFO - epoch 0, step 11880, training loss = 2.470857, validation loss = 2.888171
2018-12-04 19:51:17,775 - INFO - epoch 0, step 11890, training loss = 2.538508, validation loss = 2.944586
2018-12-04 19:51:21,881 - INFO - epoch 0, step 11900, training loss = 2.641021, validation loss = 2.464332
2018-12-04 19:51:25,885 - INFO - epoch 0, step 11910, training loss = 2.542739, validation loss = 2.883730
2018-12-04 19:51:29,891 - INFO - epoch 0, step 11920, training loss = 2.358770, validation loss = 2.883867
2018-12-04 19:51:33,692 - INFO - epoch 0, step 11930, training loss = 1.889317, validation loss = 3.151607
2018-12-04 19:51:37,492 - INFO - epoch 0, step 11940, training loss = 3.109248, validation loss = 2.473463
2018-12-04 19:51:41,221 - INFO - epoch 0, step 11950, training loss = 2.004579, validation loss = 2.986216
2018-12-04 19:51:45,121 - INFO - epoch 0, step 11960, training loss = 2.258244, validation loss = 2.551147
2018-12-04 19:51:48,734 - INFO - epoch 0, step 11970, training loss = 2.335130, validation loss = 3.291943
2018-12-04 19:51:52,415 - INFO - epoch 0, step 11980, training loss = 2.025078, validation loss = 2.835054
2018-12-04 19:51:55,990 - INFO - epoch 0, step 11990, training loss = 2.554005, validation loss = 3.429437
2018-12-04 19:51:59,768 - INFO - epoch 0, step 12000, training loss = 2.328545, validation loss = 2.940392
2018-12-04 19:52:03,573 - INFO - epoch 0, step 12010, training loss = 2.439939, validation loss = 3.238889
2018-12-04 19:52:07,290 - INFO - epoch 0, step 12020, training loss = 2.274792, validation loss = 2.887837
2018-12-04 19:52:10,983 - INFO - epoch 0, step 12030, training loss = 2.425111, validation loss = 2.549870
2018-12-04 19:52:14,837 - INFO - epoch 0, step 12040, training loss = 1.735461, validation loss = 2.779844
2018-12-04 19:52:18,810 - INFO - epoch 0, step 12050, training loss = 2.748049, validation loss = 2.348572
2018-12-04 19:52:23,135 - INFO - epoch 0, step 12060, training loss = 2.659132, validation loss = 2.715692
2018-12-04 19:52:27,355 - INFO - epoch 0, step 12070, training loss = 2.755132, validation loss = 2.942747
2018-12-04 19:52:31,855 - INFO - epoch 0, step 12080, training loss = 2.473212, validation loss = 2.721905
2018-12-04 19:52:36,359 - INFO - epoch 0, step 12090, training loss = 2.427990, validation loss = 2.461997
2018-12-04 19:52:40,757 - INFO - epoch 0, step 12100, training loss = 2.551484, validation loss = 2.864657
2018-12-04 19:52:45,047 - INFO - epoch 0, step 12110, training loss = 2.610983, validation loss = 2.676456
2018-12-04 19:52:49,355 - INFO - epoch 0, step 12120, training loss = 2.206271, validation loss = 2.647218
2018-12-04 19:52:53,710 - INFO - epoch 0, step 12130, training loss = 2.630754, validation loss = 3.063933
2018-12-04 19:52:57,921 - INFO - epoch 0, step 12140, training loss = 2.127301, validation loss = 2.700099
2018-12-04 19:53:02,330 - INFO - epoch 0, step 12150, training loss = 2.620223, validation loss = 2.773947
2018-12-04 19:53:06,601 - INFO - epoch 0, step 12160, training loss = 2.049845, validation loss = 3.503089
2018-12-04 19:53:11,018 - INFO - epoch 0, step 12170, training loss = 2.804285, validation loss = 3.028432
2018-12-04 19:53:15,196 - INFO - epoch 0, step 12180, training loss = 2.926161, validation loss = 2.568810
2018-12-04 19:53:19,717 - INFO - epoch 0, step 12190, training loss = 2.114784, validation loss = 2.373938
2018-12-04 19:53:23,922 - INFO - epoch 0, step 12200, training loss = 2.530298, validation loss = 2.999948
2018-12-04 19:53:28,201 - INFO - epoch 0, step 12210, training loss = 2.548441, validation loss = 3.230852
2018-12-04 19:53:32,674 - INFO - epoch 0, step 12220, training loss = 2.111058, validation loss = 2.653576
2018-12-04 19:53:37,139 - INFO - epoch 0, step 12230, training loss = 2.565371, validation loss = 2.238675
2018-12-04 19:53:41,271 - INFO - epoch 0, step 12240, training loss = 2.845548, validation loss = 2.701910
2018-12-04 19:53:45,641 - INFO - epoch 0, step 12250, training loss = 2.615678, validation loss = 2.943190
2018-12-04 19:53:49,990 - INFO - epoch 0, step 12260, training loss = 2.318907, validation loss = 2.941739
2018-12-04 19:53:54,228 - INFO - epoch 0, step 12270, training loss = 2.777499, validation loss = 2.442624
2018-12-04 19:53:58,572 - INFO - epoch 0, step 12280, training loss = 2.515817, validation loss = 1.974344
2018-12-04 19:54:02,938 - INFO - epoch 0, step 12290, training loss = 2.507336, validation loss = 2.225020
2018-12-04 19:54:07,234 - INFO - epoch 0, step 12300, training loss = 2.793648, validation loss = 2.942896
2018-12-04 19:54:11,440 - INFO - epoch 0, step 12310, training loss = 2.463069, validation loss = 2.200207
2018-12-04 19:54:15,402 - INFO - epoch 0, step 12320, training loss = 2.372446, validation loss = 3.115828
2018-12-04 19:54:19,260 - INFO - epoch 0, step 12330, training loss = 2.153196, validation loss = 2.913725
2018-12-04 19:54:22,955 - INFO - epoch 0, step 12340, training loss = 2.200153, validation loss = 2.897852
2018-12-04 19:54:26,591 - INFO - epoch 0, step 12350, training loss = 2.535973, validation loss = 2.842032
2018-12-04 19:54:30,155 - INFO - epoch 0, step 12360, training loss = 2.654415, validation loss = 3.177718
2018-12-04 19:54:33,992 - INFO - epoch 0, step 12370, training loss = 2.385434, validation loss = 3.033124
2018-12-04 19:54:37,617 - INFO - epoch 0, step 12380, training loss = 2.392213, validation loss = 2.785661
2018-12-04 19:54:41,318 - INFO - epoch 0, step 12390, training loss = 2.906558, validation loss = 2.726029
2018-12-04 19:54:45,195 - INFO - epoch 0, step 12400, training loss = 2.489827, validation loss = 3.043692
2018-12-04 19:54:49,527 - INFO - epoch 0, step 12410, training loss = 2.320268, validation loss = 2.998336
2018-12-04 19:54:53,874 - INFO - epoch 0, step 12420, training loss = 2.291105, validation loss = 2.761645
2018-12-04 19:54:58,009 - INFO - epoch 0, step 12430, training loss = 3.189889, validation loss = 2.443006
2018-12-04 19:55:02,279 - INFO - epoch 0, step 12440, training loss = 2.610676, validation loss = 2.697952
2018-12-04 19:55:06,454 - INFO - epoch 0, step 12450, training loss = 2.259737, validation loss = 2.912406
2018-12-04 19:55:10,519 - INFO - epoch 0, step 12460, training loss = 2.783051, validation loss = 3.524093
2018-12-04 19:55:14,731 - INFO - epoch 0, step 12470, training loss = 2.043385, validation loss = 3.175728
2018-12-04 19:55:18,790 - INFO - epoch 0, step 12480, training loss = 2.721686, validation loss = 3.597188
2018-12-04 19:55:22,943 - INFO - epoch 0, step 12490, training loss = 2.390972, validation loss = 2.966874
2018-12-04 19:55:27,127 - INFO - epoch 0, step 12500, training loss = 2.240550, validation loss = 3.369783
2018-12-04 19:55:31,332 - INFO - epoch 0, step 12510, training loss = 2.182828, validation loss = 2.914014
2018-12-04 19:55:35,551 - INFO - epoch 0, step 12520, training loss = 2.511686, validation loss = 3.625048
2018-12-04 19:55:39,514 - INFO - epoch 0, step 12530, training loss = 2.593094, validation loss = 3.028926
2018-12-04 19:55:43,581 - INFO - epoch 0, step 12540, training loss = 2.605442, validation loss = 2.686628
2018-12-04 19:55:47,635 - INFO - epoch 0, step 12550, training loss = 2.607733, validation loss = 3.171239
2018-12-04 19:55:51,551 - INFO - epoch 0, step 12560, training loss = 2.593762, validation loss = 3.441871
2018-12-04 19:55:55,267 - INFO - epoch 0, step 12570, training loss = 3.053972, validation loss = 2.751944
2018-12-04 19:55:59,206 - INFO - epoch 0, step 12580, training loss = 2.965112, validation loss = 2.731981
2018-12-04 19:56:02,804 - INFO - epoch 0, step 12590, training loss = 2.359091, validation loss = 3.355038
2018-12-04 19:56:06,710 - INFO - epoch 0, step 12600, training loss = 2.348036, validation loss = 2.937238
2018-12-04 19:56:10,704 - INFO - epoch 0, step 12610, training loss = 2.236815, validation loss = 3.090495
2018-12-04 19:56:14,438 - INFO - epoch 0, step 12620, training loss = 2.459381, validation loss = 3.316439
2018-12-04 19:56:18,280 - INFO - epoch 0, step 12630, training loss = 2.484799, validation loss = 3.648007
2018-12-04 19:56:21,936 - INFO - epoch 0, step 12640, training loss = 2.321562, validation loss = 3.274300
2018-12-04 19:56:25,710 - INFO - epoch 0, step 12650, training loss = 2.087912, validation loss = 3.302314
2018-12-04 19:56:29,375 - INFO - epoch 0, step 12660, training loss = 2.082253, validation loss = 2.982403
2018-12-04 19:56:33,167 - INFO - epoch 0, step 12670, training loss = 2.507749, validation loss = 2.866925
2018-12-04 19:56:36,795 - INFO - epoch 0, step 12680, training loss = 2.523716, validation loss = 3.754481
2018-12-04 19:56:40,412 - INFO - epoch 0, step 12690, training loss = 2.169773, validation loss = 3.037965
2018-12-04 19:56:43,969 - INFO - epoch 0, step 12700, training loss = 2.630898, validation loss = 3.194718
2018-12-04 19:56:47,270 - INFO - epoch 0, step 12710, training loss = 2.826003, validation loss = 3.721642
2018-12-04 19:56:50,754 - INFO - epoch 0, step 12720, training loss = 2.576643, validation loss = 3.044520
2018-12-04 19:56:54,357 - INFO - epoch 0, step 12730, training loss = 2.612858, validation loss = 2.904740
2018-12-04 19:56:57,998 - INFO - epoch 0, step 12740, training loss = 2.488129, validation loss = 2.602899
2018-12-04 19:57:01,501 - INFO - epoch 0, step 12750, training loss = 2.747745, validation loss = 3.476715
2018-12-04 19:57:05,098 - INFO - epoch 0, step 12760, training loss = 2.472457, validation loss = 3.356657
2018-12-04 19:57:08,569 - INFO - epoch 0, step 12770, training loss = 2.497464, validation loss = 3.808993
2018-12-04 19:57:12,298 - INFO - epoch 0, step 12780, training loss = 2.750545, validation loss = 4.033947
2018-12-04 19:57:15,949 - INFO - epoch 0, step 12790, training loss = 2.350464, validation loss = 3.303396
2018-12-04 19:57:19,550 - INFO - epoch 0, step 12800, training loss = 2.412304, validation loss = 3.700471
2018-12-04 19:57:23,746 - INFO - epoch 0, step 12810, training loss = 2.530710, validation loss = 2.870844
2018-12-04 19:57:27,652 - INFO - epoch 0, step 12820, training loss = 2.329775, validation loss = 3.073246
2018-12-04 19:57:31,788 - INFO - epoch 0, step 12830, training loss = 2.326303, validation loss = 2.631212
2018-12-04 19:57:35,575 - INFO - epoch 0, step 12840, training loss = 2.361398, validation loss = 2.930376
2018-12-04 19:57:39,737 - INFO - epoch 0, step 12850, training loss = 2.573744, validation loss = 3.059325
2018-12-04 19:57:43,641 - INFO - epoch 0, step 12860, training loss = 2.334643, validation loss = 3.559468
2018-12-04 19:57:47,476 - INFO - epoch 0, step 12870, training loss = 2.933669, validation loss = 3.403912
2018-12-04 19:57:51,615 - INFO - epoch 0, step 12880, training loss = 2.479586, validation loss = 3.163706
2018-12-04 19:57:55,691 - INFO - epoch 0, step 12890, training loss = 2.212028, validation loss = 2.920197
2018-12-04 19:57:59,284 - INFO - epoch 0, step 12900, training loss = 2.458442, validation loss = 4.021762
2018-12-04 19:58:02,835 - INFO - epoch 0, step 12910, training loss = 2.706197, validation loss = 3.409205
2018-12-04 19:58:06,342 - INFO - epoch 0, step 12920, training loss = 2.641887, validation loss = 3.227660
2018-12-04 19:58:09,823 - INFO - epoch 0, step 12930, training loss = 2.732379, validation loss = 3.325848
2018-12-04 19:58:13,366 - INFO - epoch 0, step 12940, training loss = 2.470950, validation loss = 2.978959
2018-12-04 19:58:16,816 - INFO - epoch 0, step 12950, training loss = 3.003923, validation loss = 3.139123
2018-12-04 19:58:20,379 - INFO - epoch 0, step 12960, training loss = 2.477875, validation loss = 3.026148
2018-12-04 19:58:23,834 - INFO - epoch 0, step 12970, training loss = 2.480896, validation loss = 3.037935
2018-12-04 19:58:27,361 - INFO - epoch 0, step 12980, training loss = 2.618932, validation loss = 3.433378
2018-12-04 19:58:30,814 - INFO - epoch 0, step 12990, training loss = 2.782886, validation loss = 2.838804
2018-12-04 19:58:34,210 - INFO - epoch 0, step 13000, training loss = 2.916184, validation loss = 2.747486
2018-12-04 19:58:37,844 - INFO - epoch 0, step 13010, training loss = 2.266452, validation loss = 2.799396
2018-12-04 19:58:41,344 - INFO - epoch 0, step 13020, training loss = 2.485857, validation loss = 3.938468
2018-12-04 19:58:44,756 - INFO - epoch 0, step 13030, training loss = 3.090807, validation loss = 4.028108
2018-12-04 19:58:48,107 - INFO - epoch 0, step 13040, training loss = 2.778326, validation loss = 3.636469
2018-12-04 19:58:51,609 - INFO - epoch 0, step 13050, training loss = 2.641838, validation loss = 3.360155
2018-12-04 19:58:55,232 - INFO - epoch 0, step 13060, training loss = 2.583970, validation loss = 3.727908
2018-12-04 19:58:59,371 - INFO - epoch 0, step 13070, training loss = 2.343134, validation loss = 3.216697
2018-12-04 19:59:03,746 - INFO - epoch 0, step 13080, training loss = 2.608947, validation loss = 3.147316
2018-12-04 19:59:08,017 - INFO - epoch 0, step 13090, training loss = 2.446105, validation loss = 3.256167
2018-12-04 19:59:12,681 - INFO - epoch 0, step 13100, training loss = 2.597807, validation loss = 3.427171
2018-12-04 19:59:17,203 - INFO - epoch 0, step 13110, training loss = 2.507081, validation loss = 3.064252
2018-12-04 19:59:21,225 - INFO - epoch 0, step 13120, training loss = 2.824224, validation loss = 3.152903
2018-12-04 19:59:25,275 - INFO - epoch 0, step 13130, training loss = 2.405851, validation loss = 2.911077
2018-12-04 19:59:29,430 - INFO - epoch 0, step 13140, training loss = 2.291063, validation loss = 3.193933
2018-12-04 19:59:33,375 - INFO - epoch 0, step 13150, training loss = 2.601101, validation loss = 3.831740
2018-12-04 19:59:37,379 - INFO - epoch 0, step 13160, training loss = 2.569356, validation loss = 3.236317
2018-12-04 19:59:41,402 - INFO - epoch 0, step 13170, training loss = 2.444661, validation loss = 3.090380
2018-12-04 19:59:45,596 - INFO - epoch 0, step 13180, training loss = 2.460485, validation loss = 3.325282
2018-12-04 19:59:49,390 - INFO - epoch 0, step 13190, training loss = 2.509121, validation loss = 3.403236
2018-12-04 19:59:53,381 - INFO - epoch 0, step 13200, training loss = 2.758606, validation loss = 3.542809
2018-12-04 19:59:56,819 - INFO - epoch 0, step 13210, training loss = 2.941126, validation loss = 3.220031
2018-12-04 20:00:00,284 - INFO - epoch 0, step 13220, training loss = 2.754927, validation loss = 3.475215
2018-12-04 20:00:03,957 - INFO - epoch 0, step 13230, training loss = 2.645072, validation loss = 3.484881
2018-12-04 20:00:07,375 - INFO - epoch 0, step 13240, training loss = 2.849420, validation loss = 3.006971
2018-12-04 20:00:10,830 - INFO - epoch 0, step 13250, training loss = 2.495087, validation loss = 3.463444
2018-12-04 20:00:14,262 - INFO - epoch 0, step 13260, training loss = 2.249638, validation loss = 3.212700
2018-12-04 20:00:17,975 - INFO - epoch 0, step 13270, training loss = 2.555394, validation loss = 3.450457
2018-12-04 20:00:21,558 - INFO - epoch 0, step 13280, training loss = 2.298557, validation loss = 3.550825
2018-12-04 20:00:25,227 - INFO - epoch 0, step 13290, training loss = 2.328459, validation loss = 2.515389
2018-12-04 20:00:28,820 - INFO - epoch 0, step 13300, training loss = 2.436312, validation loss = 3.068179
2018-12-04 20:00:32,512 - INFO - epoch 0, step 13310, training loss = 2.486120, validation loss = 3.619550
2018-12-04 20:00:36,069 - INFO - epoch 0, step 13320, training loss = 2.734632, validation loss = 2.618752
2018-12-04 20:00:39,539 - INFO - epoch 0, step 13330, training loss = 2.294036, validation loss = 3.366195
2018-12-04 20:00:43,278 - INFO - epoch 0, step 13340, training loss = 2.676046, validation loss = 2.813316
2018-12-04 20:00:47,040 - INFO - epoch 0, step 13350, training loss = 2.145253, validation loss = 3.702717
2018-12-04 20:00:50,727 - INFO - epoch 0, step 13360, training loss = 2.185634, validation loss = 3.055176
2018-12-04 20:00:54,369 - INFO - epoch 0, step 13370, training loss = 2.494895, validation loss = 3.570724
2018-12-04 20:00:58,233 - INFO - epoch 0, step 13380, training loss = 2.027052, validation loss = 3.049228
2018-12-04 20:01:01,877 - INFO - epoch 0, step 13390, training loss = 1.998129, validation loss = 3.411088
2018-12-04 20:01:05,637 - INFO - epoch 0, step 13400, training loss = 1.880475, validation loss = 3.508095
2018-12-04 20:01:09,249 - INFO - epoch 0, step 13410, training loss = 2.249136, validation loss = 4.236342
2018-12-04 20:01:13,113 - INFO - epoch 0, step 13420, training loss = 2.134697, validation loss = 3.784961
2018-12-04 20:01:16,640 - INFO - epoch 0, step 13430, training loss = 2.411820, validation loss = 3.377599
2018-12-04 20:01:20,236 - INFO - epoch 0, step 13440, training loss = 2.445164, validation loss = 3.110734
2018-12-04 20:01:23,809 - INFO - epoch 0, step 13450, training loss = 2.402778, validation loss = 3.358903
2018-12-04 20:01:27,645 - INFO - epoch 0, step 13460, training loss = 2.163341, validation loss = 3.265168
2018-12-04 20:01:31,715 - INFO - epoch 0, step 13470, training loss = 2.295812, validation loss = 3.410036
2018-12-04 20:01:35,869 - INFO - epoch 0, step 13480, training loss = 2.561129, validation loss = 3.443025
2018-12-04 20:01:40,269 - INFO - epoch 0, step 13490, training loss = 2.591685, validation loss = 2.619844
2018-12-04 20:01:44,662 - INFO - epoch 0, step 13500, training loss = 2.751107, validation loss = 2.603897
2018-12-04 20:01:48,904 - INFO - epoch 0, step 13510, training loss = 2.128418, validation loss = 3.206669
2018-12-04 20:01:53,451 - INFO - epoch 0, step 13520, training loss = 2.270406, validation loss = 3.155374
2018-12-04 20:01:57,904 - INFO - epoch 0, step 13530, training loss = 2.217088, validation loss = 3.142499
2018-12-04 20:02:02,199 - INFO - epoch 0, step 13540, training loss = 2.149622, validation loss = 2.703073
2018-12-04 20:02:06,650 - INFO - epoch 0, step 13550, training loss = 2.703789, validation loss = 3.242902
2018-12-04 20:02:10,938 - INFO - epoch 0, step 13560, training loss = 2.460238, validation loss = 3.341276
2018-12-04 20:02:15,346 - INFO - epoch 0, step 13570, training loss = 2.513919, validation loss = 2.329920
2018-12-04 20:02:19,756 - INFO - epoch 0, step 13580, training loss = 2.295533, validation loss = 3.296896
2018-12-04 20:02:24,185 - INFO - epoch 0, step 13590, training loss = 2.128525, validation loss = 3.645842
2018-12-04 20:02:28,451 - INFO - epoch 0, step 13600, training loss = 2.754973, validation loss = 3.501716
2018-12-04 20:02:32,493 - INFO - epoch 0, step 13610, training loss = 2.404164, validation loss = 2.758632
2018-12-04 20:02:35,836 - INFO - epoch 0, step 13620, training loss = 2.573392, validation loss = 2.946119
2018-12-04 20:02:39,198 - INFO - epoch 0, step 13630, training loss = 2.728259, validation loss = 3.522023
2018-12-04 20:02:42,606 - INFO - epoch 0, step 13640, training loss = 2.896410, validation loss = 4.223235
2018-12-04 20:02:46,265 - INFO - epoch 0, step 13650, training loss = 2.261316, validation loss = 3.262382
2018-12-04 20:02:49,854 - INFO - epoch 0, step 13660, training loss = 2.300190, validation loss = 3.386666
2018-12-04 20:02:53,559 - INFO - epoch 0, step 13670, training loss = 2.545720, validation loss = 3.117841
2018-12-04 20:02:57,173 - INFO - epoch 0, step 13680, training loss = 1.951821, validation loss = 2.820003
2018-12-04 20:03:00,764 - INFO - epoch 0, step 13690, training loss = 2.786513, validation loss = 3.341402
2018-12-04 20:03:04,430 - INFO - epoch 0, step 13700, training loss = 1.630190, validation loss = 3.409578
2018-12-04 20:03:07,917 - INFO - epoch 0, step 13710, training loss = 2.403411, validation loss = 3.730581
2018-12-04 20:03:11,377 - INFO - epoch 0, step 13720, training loss = 2.507837, validation loss = 2.381811
2018-12-04 20:03:15,104 - INFO - epoch 0, step 13730, training loss = 2.535815, validation loss = 3.685623
2018-12-04 20:03:19,209 - INFO - epoch 0, step 13740, training loss = 2.319808, validation loss = 3.150365
2018-12-04 20:03:23,499 - INFO - epoch 0, step 13750, training loss = 2.228845, validation loss = 3.330703
2018-12-04 20:03:27,493 - INFO - epoch 0, step 13760, training loss = 2.054497, validation loss = 3.072749
2018-12-04 20:03:31,612 - INFO - epoch 0, step 13770, training loss = 2.289066, validation loss = 2.448382
2018-12-04 20:03:35,670 - INFO - epoch 0, step 13780, training loss = 2.151783, validation loss = 2.986699
2018-12-04 20:03:39,707 - INFO - epoch 0, step 13790, training loss = 2.512973, validation loss = 2.906493
2018-12-04 20:03:43,510 - INFO - epoch 0, step 13800, training loss = 2.416976, validation loss = 2.881062
2018-12-04 20:03:47,339 - INFO - epoch 0, step 13810, training loss = 2.158507, validation loss = 2.446646
2018-12-04 20:03:50,929 - INFO - epoch 0, step 13820, training loss = 1.792678, validation loss = 3.306349
2018-12-04 20:03:54,552 - INFO - epoch 0, step 13830, training loss = 2.430177, validation loss = 2.823071
2018-12-04 20:03:58,160 - INFO - epoch 0, step 13840, training loss = 1.970489, validation loss = 2.161474
2018-12-04 20:04:01,767 - INFO - epoch 0, step 13850, training loss = 2.464007, validation loss = 2.583050
2018-12-04 20:04:05,534 - INFO - epoch 0, step 13860, training loss = 1.731952, validation loss = 2.156397
2018-12-04 20:04:09,334 - INFO - epoch 0, step 13870, training loss = 1.867104, validation loss = 2.861007
2018-12-04 20:04:12,829 - INFO - epoch 0, step 13880, training loss = 2.912544, validation loss = 3.137019
2018-12-04 20:04:17,066 - INFO - epoch 0, step 13890, training loss = 2.649348, validation loss = 2.995609
2018-12-04 20:04:21,488 - INFO - epoch 0, step 13900, training loss = 2.136423, validation loss = 2.578753
2018-12-04 20:04:25,986 - INFO - epoch 0, step 13910, training loss = 2.379191, validation loss = 2.341071
2018-12-04 20:04:30,157 - INFO - epoch 0, step 13920, training loss = 2.078466, validation loss = 2.566539
2018-12-04 20:04:34,589 - INFO - epoch 0, step 13930, training loss = 2.317546, validation loss = 2.539769
2018-12-04 20:04:38,994 - INFO - epoch 0, step 13940, training loss = 2.591233, validation loss = 2.671730
2018-12-04 20:04:43,246 - INFO - epoch 0, step 13950, training loss = 2.916819, validation loss = 3.287902
2018-12-04 20:04:47,748 - INFO - epoch 0, step 13960, training loss = 2.771075, validation loss = 3.582739
2018-12-04 20:04:52,203 - INFO - epoch 0, step 13970, training loss = 2.021526, validation loss = 3.560142
2018-12-04 20:04:56,719 - INFO - epoch 0, step 13980, training loss = 2.219065, validation loss = 2.762421
2018-12-04 20:05:00,949 - INFO - epoch 0, step 13990, training loss = 1.842954, validation loss = 3.324114
2018-12-04 20:05:05,227 - INFO - epoch 0, step 14000, training loss = 1.893245, validation loss = 2.850972
2018-12-04 20:05:09,600 - INFO - epoch 0, step 14010, training loss = 2.530307, validation loss = 2.477124
2018-12-04 20:05:13,518 - INFO - epoch 0, step 14020, training loss = 2.403339, validation loss = 2.990739
2018-12-04 20:05:17,259 - INFO - epoch 0, step 14030, training loss = 2.394639, validation loss = 2.743196
2018-12-04 20:05:21,725 - INFO - epoch 0, step 14040, training loss = 2.580363, validation loss = 3.354645
2018-12-04 20:05:25,968 - INFO - epoch 0, step 14050, training loss = 2.561881, validation loss = 3.175685
2018-12-04 20:05:29,697 - INFO - epoch 0, step 14060, training loss = 2.531410, validation loss = 3.176687
2018-12-04 20:05:33,321 - INFO - epoch 0, step 14070, training loss = 2.402243, validation loss = 3.210009
2018-12-04 20:05:36,983 - INFO - epoch 0, step 14080, training loss = 2.549394, validation loss = 2.445761
2018-12-04 20:05:40,777 - INFO - epoch 0, step 14090, training loss = 2.363122, validation loss = 2.700267
2018-12-04 20:05:44,635 - INFO - epoch 0, step 14100, training loss = 2.808407, validation loss = 2.730194
2018-12-04 20:05:48,481 - INFO - epoch 0, step 14110, training loss = 2.248389, validation loss = 2.672745
2018-12-04 20:05:52,583 - INFO - epoch 0, step 14120, training loss = 2.578259, validation loss = 2.749514
2018-12-04 20:05:56,481 - INFO - epoch 0, step 14130, training loss = 2.475080, validation loss = 2.737886
2018-12-04 20:06:00,355 - INFO - epoch 0, step 14140, training loss = 2.758579, validation loss = 2.745611
2018-12-04 20:06:04,399 - INFO - epoch 0, step 14150, training loss = 2.526972, validation loss = 2.641431
2018-12-04 20:06:08,267 - INFO - epoch 0, step 14160, training loss = 2.385101, validation loss = 2.646436
2018-12-04 20:06:12,201 - INFO - epoch 0, step 14170, training loss = 2.699728, validation loss = 2.440037
2018-12-04 20:06:16,143 - INFO - epoch 0, step 14180, training loss = 2.371837, validation loss = 3.020053
2018-12-04 20:06:20,103 - INFO - epoch 0, step 14190, training loss = 2.783298, validation loss = 2.847018
2018-12-04 20:06:23,905 - INFO - epoch 0, step 14200, training loss = 2.414014, validation loss = 2.972417
2018-12-04 20:06:27,991 - INFO - epoch 0, step 14210, training loss = 2.439945, validation loss = 2.565718
2018-12-04 20:06:32,299 - INFO - epoch 0, step 14220, training loss = 2.565523, validation loss = 2.238932
2018-12-04 20:06:36,606 - INFO - epoch 0, step 14230, training loss = 2.302673, validation loss = 2.326665
2018-12-04 20:06:40,929 - INFO - epoch 0, step 14240, training loss = 2.292008, validation loss = 3.226610
2018-12-04 20:06:45,146 - INFO - epoch 0, step 14250, training loss = 2.489143, validation loss = 2.955925
2018-12-04 20:06:49,560 - INFO - epoch 0, step 14260, training loss = 2.607153, validation loss = 2.582149
2018-12-04 20:06:53,751 - INFO - epoch 0, step 14270, training loss = 1.569640, validation loss = 3.023876
2018-12-04 20:06:58,058 - INFO - epoch 0, step 14280, training loss = 2.489816, validation loss = 3.045881
2018-12-04 20:07:02,477 - INFO - epoch 0, step 14290, training loss = 2.332265, validation loss = 3.281353
2018-12-04 20:07:06,816 - INFO - epoch 0, step 14300, training loss = 2.554617, validation loss = 2.950656
2018-12-04 20:07:11,062 - INFO - epoch 0, step 14310, training loss = 2.166107, validation loss = 3.471867
2018-12-04 20:07:15,362 - INFO - epoch 0, step 14320, training loss = 2.345983, validation loss = 3.120643
2018-12-04 20:07:19,602 - INFO - epoch 0, step 14330, training loss = 2.578996, validation loss = 2.607171
2018-12-04 20:07:23,888 - INFO - epoch 0, step 14340, training loss = 2.747062, validation loss = 2.770533
2018-12-04 20:07:28,001 - INFO - epoch 0, step 14350, training loss = 3.062131, validation loss = 2.266734
2018-12-04 20:07:31,226 - INFO - epoch 0, step 14360, training loss = 3.309262, validation loss = 3.228732
2018-12-04 20:07:34,364 - INFO - epoch 0, step 14370, training loss = 3.085066, validation loss = 3.373363
2018-12-04 20:07:37,637 - INFO - epoch 0, step 14380, training loss = 2.902111, validation loss = 3.212408
2018-12-04 20:07:40,934 - INFO - epoch 0, step 14390, training loss = 2.707681, validation loss = 3.226224
2018-12-04 20:07:44,250 - INFO - epoch 0, step 14400, training loss = 2.821640, validation loss = 3.075767
2018-12-04 20:07:47,571 - INFO - epoch 0, step 14410, training loss = 2.679073, validation loss = 2.985891
2018-12-04 20:07:50,922 - INFO - epoch 0, step 14420, training loss = 3.016522, validation loss = 2.583430
2018-12-04 20:07:54,038 - INFO - epoch 0, step 14430, training loss = 3.497200, validation loss = 3.094438
2018-12-04 20:07:57,222 - INFO - epoch 0, step 14440, training loss = 2.711144, validation loss = 3.090883
2018-12-04 20:08:00,688 - INFO - epoch 0, step 14450, training loss = 2.817968, validation loss = 3.414219
2018-12-04 20:08:04,027 - INFO - epoch 0, step 14460, training loss = 3.219258, validation loss = 3.478319
2018-12-04 20:08:07,324 - INFO - epoch 0, step 14470, training loss = 3.058270, validation loss = 2.899552
2018-12-04 20:08:10,627 - INFO - epoch 0, step 14480, training loss = 2.605243, validation loss = 3.191200
2018-12-04 20:08:14,043 - INFO - epoch 0, step 14490, training loss = 2.747739, validation loss = 3.236795
2018-12-04 20:08:17,514 - INFO - epoch 0, step 14500, training loss = 3.026131, validation loss = 2.696495
2018-12-04 20:08:20,924 - INFO - epoch 0, step 14510, training loss = 3.340760, validation loss = 3.157235
2018-12-04 20:08:24,413 - INFO - epoch 0, step 14520, training loss = 3.249804, validation loss = 3.273603
2018-12-04 20:08:28,150 - INFO - epoch 0, step 14530, training loss = 3.202758, validation loss = 2.768810
2018-12-04 20:08:31,789 - INFO - epoch 0, step 14540, training loss = 2.685532, validation loss = 2.950776
2018-12-04 20:08:35,508 - INFO - epoch 0, step 14550, training loss = 3.218684, validation loss = 3.066908
2018-12-04 20:08:39,291 - INFO - epoch 0, step 14560, training loss = 2.922348, validation loss = 2.648464
2018-12-04 20:08:43,004 - INFO - epoch 0, step 14570, training loss = 2.863561, validation loss = 2.915999
2018-12-04 20:08:46,630 - INFO - epoch 0, step 14580, training loss = 3.009457, validation loss = 2.702300
2018-12-04 20:08:50,532 - INFO - epoch 0, step 14590, training loss = 3.313940, validation loss = 2.452103
2018-12-04 20:08:54,260 - INFO - epoch 0, step 14600, training loss = 2.896048, validation loss = 3.138324
2018-12-04 20:08:57,882 - INFO - epoch 0, step 14610, training loss = 3.223454, validation loss = 3.146699
2018-12-04 20:09:01,564 - INFO - epoch 0, step 14620, training loss = 3.510034, validation loss = 2.422000
2018-12-04 20:09:06,820 - INFO - epoch 0, step 14630, training loss = 2.454214, validation loss = 2.800645
2018-12-04 20:09:12,819 - INFO - epoch 0, step 14640, training loss = 2.468487, validation loss = 2.910370
2018-12-04 20:09:18,499 - INFO - epoch 0, step 14650, training loss = 2.863977, validation loss = 2.922043
2018-12-04 20:09:23,733 - INFO - epoch 0, step 14660, training loss = 2.182656, validation loss = 3.257438
2018-12-04 20:09:29,866 - INFO - epoch 0, step 14670, training loss = 2.415951, validation loss = 2.571161
2018-12-04 20:09:35,858 - INFO - epoch 0, step 14680, training loss = 2.463936, validation loss = 2.267620
2018-12-04 20:09:40,163 - INFO - epoch 0, step 14690, training loss = 3.083779, validation loss = 2.072920
2018-12-04 20:09:43,593 - INFO - epoch 0, step 14700, training loss = 2.498593, validation loss = 2.696534
2018-12-04 20:09:47,265 - INFO - epoch 0, step 14710, training loss = 2.210561, validation loss = 2.644492
2018-12-04 20:09:50,803 - INFO - epoch 0, step 14720, training loss = 2.816838, validation loss = 2.117554
2018-12-04 20:09:54,221 - INFO - epoch 0, step 14730, training loss = 2.884546, validation loss = 2.838005
2018-12-04 20:09:57,768 - INFO - epoch 0, step 14740, training loss = 2.396701, validation loss = 2.555793
2018-12-04 20:10:01,187 - INFO - epoch 0, step 14750, training loss = 2.823971, validation loss = 2.554259
2018-12-04 20:10:04,606 - INFO - epoch 0, step 14760, training loss = 2.459105, validation loss = 2.620251
2018-12-04 20:10:07,944 - INFO - epoch 0, step 14770, training loss = 2.998702, validation loss = 2.926330
2018-12-04 20:10:11,251 - INFO - epoch 0, step 14780, training loss = 2.860939, validation loss = 2.651041
2018-12-04 20:10:14,609 - INFO - epoch 0, step 14790, training loss = 2.572228, validation loss = 2.268093
2018-12-04 20:10:17,872 - INFO - epoch 0, step 14800, training loss = 2.873052, validation loss = 2.842795
2018-12-04 20:10:21,151 - INFO - epoch 0, step 14810, training loss = 2.633161, validation loss = 2.566998
2018-12-04 20:10:24,444 - INFO - epoch 0, step 14820, training loss = 3.397682, validation loss = 2.768349
2018-12-04 20:10:27,801 - INFO - epoch 0, step 14830, training loss = 2.549486, validation loss = 3.441883
2018-12-04 20:10:31,195 - INFO - epoch 0, step 14840, training loss = 2.609647, validation loss = 2.707139
2018-12-04 20:10:34,875 - INFO - epoch 0, step 14850, training loss = 2.540246, validation loss = 2.961021
2018-12-04 20:10:38,572 - INFO - epoch 0, step 14860, training loss = 2.734871, validation loss = 2.713703
2018-12-04 20:10:45,114 - INFO - epoch 0, step 14870, training loss = 2.422323, validation loss = 2.877807
2018-12-04 20:10:51,497 - INFO - epoch 0, step 14880, training loss = 2.654086, validation loss = 2.751801
2018-12-04 20:10:57,713 - INFO - epoch 0, step 14890, training loss = 2.449511, validation loss = 3.356872
2018-12-04 20:11:03,421 - INFO - epoch 0, step 14900, training loss = 1.972096, validation loss = 2.702033
2018-12-04 20:11:09,130 - INFO - epoch 0, step 14910, training loss = 2.665764, validation loss = 2.813890
2018-12-04 20:11:14,907 - INFO - epoch 0, step 14920, training loss = 2.605570, validation loss = 2.267559
2018-12-04 20:11:20,327 - INFO - epoch 0, step 14930, training loss = 2.508295, validation loss = 2.765939
2018-12-04 20:11:25,959 - INFO - epoch 0, step 14940, training loss = 2.640720, validation loss = 2.855871
2018-12-04 20:11:32,150 - INFO - epoch 0, step 14950, training loss = 2.458357, validation loss = 2.973072
2018-12-04 20:11:38,020 - INFO - epoch 0, step 14960, training loss = 2.218355, validation loss = 2.546087
2018-12-04 20:11:43,899 - INFO - epoch 0, step 14970, training loss = 2.324614, validation loss = 2.813300
2018-12-04 20:11:50,127 - INFO - epoch 0, step 14980, training loss = 1.787946, validation loss = 2.693135
2018-12-04 20:11:56,318 - INFO - epoch 0, step 14990, training loss = 2.279586, validation loss = 1.840690
2018-12-04 20:12:02,324 - INFO - epoch 0, step 15000, training loss = 2.366037, validation loss = 2.581743
2018-12-04 20:12:07,702 - INFO - epoch 0, step 15010, training loss = 2.135569, validation loss = 2.998998
2018-12-04 20:12:13,360 - INFO - epoch 0, step 15020, training loss = 1.907076, validation loss = 2.870855
2018-12-04 20:12:19,555 - INFO - epoch 0, step 15030, training loss = 2.242824, validation loss = 2.752500
2018-12-04 20:12:25,298 - INFO - epoch 0, step 15040, training loss = 2.112589, validation loss = 2.937435
2018-12-04 20:12:31,179 - INFO - epoch 0, step 15050, training loss = 2.467773, validation loss = 2.507661
2018-12-04 20:12:37,205 - INFO - epoch 0, step 15060, training loss = 2.411714, validation loss = 2.334512
2018-12-04 20:12:43,523 - INFO - epoch 0, step 15070, training loss = 1.973877, validation loss = 2.545681
2018-12-04 20:12:50,380 - INFO - epoch 0, step 15080, training loss = 2.287161, validation loss = 2.934566
2018-12-04 20:12:56,216 - INFO - epoch 0, step 15090, training loss = 2.733670, validation loss = 2.822222
2018-12-04 20:13:01,743 - INFO - epoch 0, step 15100, training loss = 2.594757, validation loss = 2.187807
2018-12-04 20:13:08,900 - INFO - epoch 0, step 15110, training loss = 1.588077, validation loss = 2.890017
2018-12-04 20:13:15,139 - INFO - epoch 0, step 15120, training loss = 1.732161, validation loss = 2.276054
2018-12-04 20:13:21,801 - INFO - epoch 0, step 15130, training loss = 2.745341, validation loss = 1.915829
2018-12-04 20:13:28,584 - INFO - epoch 0, step 15140, training loss = 2.211900, validation loss = 2.022541
2018-12-04 20:13:34,598 - INFO - epoch 0, step 15150, training loss = 2.529985, validation loss = 2.419615
2018-12-04 20:13:41,315 - INFO - epoch 0, step 15160, training loss = 2.107269, validation loss = 2.884843
2018-12-04 20:13:48,281 - INFO - epoch 0, step 15170, training loss = 1.796504, validation loss = 3.136421
2018-12-04 20:13:54,225 - INFO - epoch 0, step 15180, training loss = 2.265883, validation loss = 3.049632
2018-12-04 20:14:00,972 - INFO - epoch 0, step 15190, training loss = 1.711926, validation loss = 2.743556
2018-12-04 20:14:06,586 - INFO - epoch 0, step 15200, training loss = 2.432613, validation loss = 2.315440
2018-12-04 20:14:12,744 - INFO - epoch 0, step 15210, training loss = 2.547765, validation loss = 2.528994
2018-12-04 20:14:18,749 - INFO - epoch 0, step 15220, training loss = 2.462624, validation loss = 2.736052
2018-12-04 20:14:24,499 - INFO - epoch 0, step 15230, training loss = 2.436087, validation loss = 2.596414
2018-12-04 20:14:30,577 - INFO - epoch 0, step 15240, training loss = 2.977671, validation loss = 2.341974
2018-12-04 20:14:37,187 - INFO - epoch 0, step 15250, training loss = 2.172865, validation loss = 2.550714
2018-12-04 20:14:44,286 - INFO - epoch 0, step 15260, training loss = 2.205815, validation loss = 2.229130
2018-12-04 20:14:49,844 - INFO - epoch 0, step 15270, training loss = 2.377619, validation loss = 2.481650
2018-12-04 20:14:55,977 - INFO - epoch 0, step 15280, training loss = 2.398481, validation loss = 2.328076
2018-12-04 20:15:01,904 - INFO - epoch 0, step 15290, training loss = 2.231802, validation loss = 2.606448
2018-12-04 20:15:08,019 - INFO - epoch 0, step 15300, training loss = 1.957682, validation loss = 2.833609
2018-12-04 20:15:13,635 - INFO - epoch 0, step 15310, training loss = 2.442972, validation loss = 2.754937
2018-12-04 20:15:19,217 - INFO - epoch 0, step 15320, training loss = 2.547650, validation loss = 2.681164
2018-12-04 20:15:24,918 - INFO - epoch 0, step 15330, training loss = 2.059793, validation loss = 2.264848
2018-12-04 20:15:31,100 - INFO - epoch 0, step 15340, training loss = 2.173685, validation loss = 2.654993
2018-12-04 20:15:36,482 - INFO - epoch 0, step 15350, training loss = 2.452545, validation loss = 2.629660
2018-12-04 20:15:42,260 - INFO - epoch 0, step 15360, training loss = 2.510197, validation loss = 2.375239
2018-12-04 20:15:47,723 - INFO - epoch 0, step 15370, training loss = 2.392297, validation loss = 2.659695
2018-12-04 20:15:53,731 - INFO - epoch 0, step 15380, training loss = 2.396062, validation loss = 2.938801
2018-12-04 20:15:59,191 - INFO - epoch 0, step 15390, training loss = 3.455730, validation loss = 2.450065
2018-12-04 20:16:02,433 - INFO - epoch 0, step 15400, training loss = 3.295807, validation loss = 2.444902
2018-12-04 20:16:05,927 - INFO - epoch 0, step 15410, training loss = 2.706578, validation loss = 2.729821
2018-12-04 20:16:09,277 - INFO - epoch 0, step 15420, training loss = 2.318998, validation loss = 2.923405
2018-12-04 20:16:12,692 - INFO - epoch 0, step 15430, training loss = 2.617410, validation loss = 1.996413
2018-12-04 20:16:16,236 - INFO - epoch 0, step 15440, training loss = 2.339737, validation loss = 2.931943
2018-12-04 20:16:19,613 - INFO - epoch 0, step 15450, training loss = 2.839877, validation loss = 2.726048
2018-12-04 20:16:22,933 - INFO - epoch 0, step 15460, training loss = 3.193906, validation loss = 2.793142
2018-12-04 20:16:26,480 - INFO - epoch 0, step 15470, training loss = 2.067549, validation loss = 2.831223
2018-12-04 20:16:29,863 - INFO - epoch 0, step 15480, training loss = 2.420609, validation loss = 3.109184
2018-12-04 20:16:33,209 - INFO - epoch 0, step 15490, training loss = 2.779590, validation loss = 3.369514
2018-12-04 20:16:36,552 - INFO - epoch 0, step 15500, training loss = 2.790529, validation loss = 2.566773
2018-12-04 20:16:39,936 - INFO - epoch 0, step 15510, training loss = 2.512150, validation loss = 2.683748
2018-12-04 20:16:43,121 - INFO - epoch 0, step 15520, training loss = 2.611410, validation loss = 3.116771
2018-12-04 20:16:46,418 - INFO - epoch 0, step 15530, training loss = 2.997446, validation loss = 2.726720
2018-12-04 20:16:49,791 - INFO - epoch 0, step 15540, training loss = 2.954655, validation loss = 3.260953
2018-12-04 20:16:53,166 - INFO - epoch 0, step 15550, training loss = 2.657686, validation loss = 2.835601
2018-12-04 20:16:56,548 - INFO - epoch 0, step 15560, training loss = 2.611486, validation loss = 2.910905
2018-12-04 20:17:00,162 - INFO - epoch 0, step 15570, training loss = 2.290950, validation loss = 3.485303
2018-12-04 20:17:03,477 - INFO - epoch 0, step 15580, training loss = 3.027576, validation loss = 3.438367
2018-12-04 20:17:06,905 - INFO - epoch 0, step 15590, training loss = 2.751697, validation loss = 3.008228
2018-12-04 20:17:12,146 - INFO - epoch 0, step 15600, training loss = 2.497352, validation loss = 2.906349
2018-12-04 20:17:17,231 - INFO - epoch 0, step 15610, training loss = 3.172596, validation loss = 2.851928
2018-12-04 20:17:22,160 - INFO - epoch 0, step 15620, training loss = 3.098756, validation loss = 3.020191
2018-12-04 20:17:27,112 - INFO - epoch 0, step 15630, training loss = 3.067113, validation loss = 2.573769
2018-12-04 20:17:32,264 - INFO - epoch 0, step 15640, training loss = 2.299247, validation loss = 2.482612
2018-12-04 20:17:37,199 - INFO - epoch 0, step 15650, training loss = 2.630646, validation loss = 2.416343
2018-12-04 20:17:41,906 - INFO - epoch 0, step 15660, training loss = 3.228315, validation loss = 2.659368
2018-12-04 20:17:46,897 - INFO - epoch 0, step 15670, training loss = 2.657248, validation loss = 3.144364
2018-12-04 20:17:51,715 - INFO - epoch 0, step 15680, training loss = 2.700889, validation loss = 3.175226
2018-12-04 20:17:56,574 - INFO - epoch 0, step 15690, training loss = 3.105208, validation loss = 2.433290
2018-12-04 20:18:01,506 - INFO - epoch 0, step 15700, training loss = 3.012927, validation loss = 2.896691
2018-12-04 20:18:06,280 - INFO - epoch 0, step 15710, training loss = 2.804387, validation loss = 2.963736
2018-12-04 20:18:12,135 - INFO - epoch 0, step 15720, training loss = 2.354917, validation loss = 3.745203
2018-12-04 20:18:18,070 - INFO - epoch 0, step 15730, training loss = 2.892739, validation loss = 2.514685
2018-12-04 20:18:24,359 - INFO - epoch 0, step 15740, training loss = 2.430856, validation loss = 2.648424
2018-12-04 20:18:30,056 - INFO - epoch 0, step 15750, training loss = 2.349679, validation loss = 2.710545
2018-12-04 20:18:36,102 - INFO - epoch 0, step 15760, training loss = 2.191503, validation loss = 2.918025
2018-12-04 20:18:41,784 - INFO - epoch 0, step 15770, training loss = 2.272713, validation loss = 2.836199
2018-12-04 20:18:47,761 - INFO - epoch 0, step 15780, training loss = 2.372809, validation loss = 3.059113
2018-12-04 20:18:53,133 - INFO - epoch 0, step 15790, training loss = 2.830910, validation loss = 2.612046
2018-12-04 20:18:58,502 - INFO - epoch 0, step 15800, training loss = 2.500575, validation loss = 2.539320
2018-12-04 20:19:03,999 - INFO - epoch 0, step 15810, training loss = 2.515637, validation loss = 2.937242
2018-12-04 20:19:09,662 - INFO - epoch 0, step 15820, training loss = 3.246107, validation loss = 2.725446
2018-12-04 20:19:15,625 - INFO - epoch 0, step 15830, training loss = 2.384524, validation loss = 3.078900
2018-12-04 20:19:21,399 - INFO - epoch 0, step 15840, training loss = 2.944167, validation loss = 2.755075
2018-12-04 20:19:27,097 - INFO - epoch 0, step 15850, training loss = 2.594657, validation loss = 2.646984
2018-12-04 20:19:32,819 - INFO - epoch 0, step 15860, training loss = 2.360250, validation loss = 2.385391
2018-12-04 20:19:38,853 - INFO - epoch 0, step 15870, training loss = 2.301269, validation loss = 2.782677
2018-12-04 20:19:44,429 - INFO - epoch 0, step 15880, training loss = 2.431893, validation loss = 3.153537
2018-12-04 20:19:50,254 - INFO - epoch 0, step 15890, training loss = 2.264106, validation loss = 2.779058
2018-12-04 20:19:56,251 - INFO - epoch 0, step 15900, training loss = 2.192024, validation loss = 3.000226
2018-12-04 20:20:01,675 - INFO - epoch 0, step 15910, training loss = 2.219337, validation loss = 2.994343
2018-12-04 20:20:06,836 - INFO - epoch 0, step 15920, training loss = 2.263914, validation loss = 2.410308
2018-12-04 20:20:11,416 - INFO - epoch 0, step 15930, training loss = 2.724917, validation loss = 2.773289
2018-12-04 20:20:15,856 - INFO - epoch 0, step 15940, training loss = 2.853555, validation loss = 2.839093
2018-12-04 20:20:20,025 - INFO - epoch 0, step 15950, training loss = 2.656131, validation loss = 3.285575
2018-12-04 20:20:24,561 - INFO - epoch 0, step 15960, training loss = 2.510343, validation loss = 2.533602
2018-12-04 20:20:28,916 - INFO - epoch 0, step 15970, training loss = 2.545746, validation loss = 2.873451
2018-12-04 20:20:33,078 - INFO - epoch 0, step 15980, training loss = 2.169481, validation loss = 2.938749
2018-12-04 20:20:37,813 - INFO - epoch 0, step 15990, training loss = 2.276439, validation loss = 2.586548
2018-12-04 20:20:42,400 - INFO - epoch 0, step 16000, training loss = 2.598670, validation loss = 2.487111
2018-12-04 20:20:46,795 - INFO - epoch 0, step 16010, training loss = 2.668775, validation loss = 2.420798
2018-12-04 20:20:50,778 - INFO - epoch 0, step 16020, training loss = 2.712605, validation loss = 3.412138
2018-12-04 20:20:54,330 - INFO - epoch 0, step 16030, training loss = 2.797786, validation loss = 2.698339
2018-12-04 20:20:56,717 - INFO - epoch 0, step 16040, training loss = 2.967159, validation loss = 2.692273
2018-12-04 20:20:59,232 - INFO - epoch 0, step 16050, training loss = 2.951414, validation loss = 3.637314
2018-12-04 20:21:01,785 - INFO - epoch 0, step 16060, training loss = 3.380945, validation loss = 3.353249
2018-12-04 20:21:04,291 - INFO - epoch 0, step 16070, training loss = 3.181608, validation loss = 3.258562
2018-12-04 20:21:06,889 - INFO - epoch 0, step 16080, training loss = 2.316459, validation loss = 3.617178
2018-12-04 20:21:09,465 - INFO - epoch 0, step 16090, training loss = 2.909845, validation loss = 3.590272
2018-12-04 20:21:12,051 - INFO - epoch 0, step 16100, training loss = 2.668586, validation loss = 3.369308
2018-12-04 20:21:14,551 - INFO - epoch 0, step 16110, training loss = 3.296364, validation loss = 3.702363
2018-12-04 20:21:17,083 - INFO - epoch 0, step 16120, training loss = 2.449834, validation loss = 3.147599
2018-12-04 20:21:19,722 - INFO - epoch 0, step 16130, training loss = 3.169306, validation loss = 2.934262
2018-12-04 20:21:22,345 - INFO - epoch 0, step 16140, training loss = 2.358825, validation loss = 3.022672
2018-12-04 20:21:24,918 - INFO - epoch 0, step 16150, training loss = 2.691633, validation loss = 3.279031
2018-12-04 20:21:27,434 - INFO - epoch 0, step 16160, training loss = 2.859259, validation loss = 3.382802
2018-12-04 20:21:29,945 - INFO - epoch 0, step 16170, training loss = 2.361362, validation loss = 3.384496
2018-12-04 20:21:32,555 - INFO - epoch 0, step 16180, training loss = 3.153772, validation loss = 3.220881
2018-12-04 20:21:35,699 - INFO - epoch 0, step 16190, training loss = 3.020695, validation loss = 3.214888
2018-12-04 20:21:39,663 - INFO - epoch 0, step 16200, training loss = 2.998389, validation loss = 2.249481
2018-12-04 20:21:43,297 - INFO - epoch 0, step 16210, training loss = 3.470837, validation loss = 2.890198
2018-12-04 20:21:47,159 - INFO - epoch 0, step 16220, training loss = 2.741805, validation loss = 3.005285
2018-12-04 20:21:50,674 - INFO - epoch 0, step 16230, training loss = 3.121140, validation loss = 3.118834
2018-12-04 20:21:54,231 - INFO - epoch 0, step 16240, training loss = 3.079538, validation loss = 3.331273
2018-12-04 20:21:57,911 - INFO - epoch 0, step 16250, training loss = 2.775898, validation loss = 2.494963
2018-12-04 20:22:01,795 - INFO - epoch 0, step 16260, training loss = 3.175678, validation loss = 3.370734
2018-12-04 20:22:05,702 - INFO - epoch 0, step 16270, training loss = 3.028425, validation loss = 3.109637
2018-12-04 20:22:09,559 - INFO - epoch 0, step 16280, training loss = 3.102778, validation loss = 2.920322
2018-12-04 20:22:13,312 - INFO - epoch 0, step 16290, training loss = 2.999974, validation loss = 2.615129
2018-12-04 20:22:17,023 - INFO - epoch 0, step 16300, training loss = 2.651070, validation loss = 3.020046
2018-12-04 20:22:20,815 - INFO - epoch 0, step 16310, training loss = 2.725308, validation loss = 2.803488
2018-12-04 20:22:23,425 - INFO - epoch 0, step 16320, training loss = 2.864604, validation loss = 3.053050
2018-12-04 20:22:25,872 - INFO - epoch 0, step 16330, training loss = 2.904869, validation loss = 3.740038
2018-12-04 20:22:28,453 - INFO - epoch 0, step 16340, training loss = 3.130321, validation loss = 3.876914
2018-12-04 20:22:31,002 - INFO - epoch 0, step 16350, training loss = 2.911821, validation loss = 2.568789
2018-12-04 20:22:33,535 - INFO - epoch 0, step 16360, training loss = 2.689239, validation loss = 3.275352
2018-12-04 20:22:36,106 - INFO - epoch 0, step 16370, training loss = 2.905682, validation loss = 3.603376
2018-12-04 20:22:38,693 - INFO - epoch 0, step 16380, training loss = 3.221197, validation loss = 3.785674
2018-12-04 20:22:41,193 - INFO - epoch 0, step 16390, training loss = 2.951409, validation loss = 3.181048
2018-12-04 20:22:43,768 - INFO - epoch 0, step 16400, training loss = 2.718152, validation loss = 3.209615
2018-12-04 20:22:46,225 - INFO - epoch 0, step 16410, training loss = 2.665076, validation loss = 3.454126
2018-12-04 20:22:48,733 - INFO - epoch 0, step 16420, training loss = 2.935758, validation loss = 3.837838
2018-12-04 20:22:54,049 - INFO - epoch 0, step 16430, training loss = 3.024571, validation loss = 2.611239
2018-12-04 20:22:59,528 - INFO - epoch 0, step 16440, training loss = 2.650442, validation loss = 2.926820
2018-12-04 20:23:04,647 - INFO - epoch 0, step 16450, training loss = 2.642607, validation loss = 3.029536
2018-12-04 20:23:10,028 - INFO - epoch 0, step 16460, training loss = 2.540490, validation loss = 3.192621
2018-12-04 20:23:15,338 - INFO - epoch 0, step 16470, training loss = 2.663821, validation loss = 2.895180
2018-12-04 20:23:20,835 - INFO - epoch 0, step 16480, training loss = 3.035011, validation loss = 2.585821
2018-12-04 20:23:26,066 - INFO - epoch 0, step 16490, training loss = 2.747677, validation loss = 2.734479
2018-12-04 20:23:31,369 - INFO - epoch 0, step 16500, training loss = 2.967530, validation loss = 2.341613
2018-12-04 20:23:36,615 - INFO - epoch 0, step 16510, training loss = 2.725299, validation loss = 2.868257
2018-12-04 20:23:41,852 - INFO - epoch 0, step 16520, training loss = 2.561751, validation loss = 2.630887
2018-12-04 20:23:47,338 - INFO - epoch 0, step 16530, training loss = 2.889568, validation loss = 3.387266
2018-12-04 20:23:52,635 - INFO - epoch 0, step 16540, training loss = 2.340863, validation loss = 2.764847
2018-12-04 20:23:57,742 - INFO - epoch 0, step 16550, training loss = 2.893794, validation loss = 2.511955
2018-12-04 20:24:02,927 - INFO - epoch 0, step 16560, training loss = 3.083608, validation loss = 3.007533
2018-12-04 20:24:08,416 - INFO - epoch 0, step 16570, training loss = 2.635138, validation loss = 2.955842
2018-12-04 20:24:13,640 - INFO - epoch 0, step 16580, training loss = 2.537305, validation loss = 2.829285
2018-12-04 20:24:18,957 - INFO - epoch 0, step 16590, training loss = 2.601620, validation loss = 2.964272
2018-12-04 20:24:24,355 - INFO - epoch 0, step 16600, training loss = 3.185875, validation loss = 3.050837
2018-12-04 20:24:29,662 - INFO - epoch 0, step 16610, training loss = 2.853684, validation loss = 3.220680
2018-12-04 20:24:35,130 - INFO - epoch 0, step 16620, training loss = 2.731397, validation loss = 2.947208
2018-12-04 20:24:40,463 - INFO - epoch 0, step 16630, training loss = 2.653717, validation loss = 3.505630
2018-12-04 20:24:45,335 - INFO - epoch 0, step 16640, training loss = 2.315386, validation loss = 2.449592
2018-12-04 20:24:49,372 - INFO - epoch 0, step 16650, training loss = 2.709183, validation loss = 2.799575
2018-12-04 20:24:53,323 - INFO - epoch 0, step 16660, training loss = 2.593231, validation loss = 3.262045
2018-12-04 20:24:57,148 - INFO - epoch 0, step 16670, training loss = 2.319743, validation loss = 3.356196
2018-12-04 20:25:01,033 - INFO - epoch 0, step 16680, training loss = 2.398313, validation loss = 3.330332
2018-12-04 20:25:04,792 - INFO - epoch 0, step 16690, training loss = 3.002082, validation loss = 3.665409
2018-12-04 20:25:09,478 - INFO - epoch 0, step 16700, training loss = 2.711577, validation loss = 3.096858
2018-12-04 20:25:14,018 - INFO - epoch 0, step 16710, training loss = 2.792619, validation loss = 2.662668
2018-12-04 20:25:18,813 - INFO - epoch 0, step 16720, training loss = 2.946195, validation loss = 2.495052
2018-12-04 20:25:23,511 - INFO - epoch 0, step 16730, training loss = 2.990812, validation loss = 2.903716
2018-12-04 20:25:27,894 - INFO - epoch 0, step 16740, training loss = 2.550675, validation loss = 3.227430
2018-12-04 20:25:32,287 - INFO - epoch 0, step 16750, training loss = 2.808678, validation loss = 2.860635
2018-12-04 20:25:36,541 - INFO - epoch 0, step 16760, training loss = 2.522196, validation loss = 2.958283
2018-12-04 20:25:39,812 - INFO - epoch 0, step 16770, training loss = 2.709094, validation loss = 2.774485
2018-12-04 20:25:43,021 - INFO - epoch 0, step 16780, training loss = 2.621355, validation loss = 3.096973
2018-12-04 20:25:46,327 - INFO - epoch 0, step 16790, training loss = 2.636853, validation loss = 2.915961
2018-12-04 20:25:49,777 - INFO - epoch 0, step 16800, training loss = 3.050408, validation loss = 2.972871
2018-12-04 20:25:53,278 - INFO - epoch 0, step 16810, training loss = 2.405436, validation loss = 2.600208
2018-12-04 20:25:56,658 - INFO - epoch 0, step 16820, training loss = 2.982104, validation loss = 3.190873
2018-12-04 20:25:59,950 - INFO - epoch 0, step 16830, training loss = 2.989681, validation loss = 2.984704
2018-12-04 20:26:03,359 - INFO - epoch 0, step 16840, training loss = 2.712106, validation loss = 2.747200
2018-12-04 20:26:06,775 - INFO - epoch 0, step 16850, training loss = 2.955780, validation loss = 3.210545
2018-12-04 20:26:10,209 - INFO - epoch 0, step 16860, training loss = 2.477608, validation loss = 3.910070
2018-12-04 20:26:13,464 - INFO - epoch 0, step 16870, training loss = 2.269307, validation loss = 4.216638
2018-12-04 20:26:17,122 - INFO - epoch 0, step 16880, training loss = 2.922967, validation loss = 3.799999
2018-12-04 20:26:20,553 - INFO - epoch 0, step 16890, training loss = 2.486455, validation loss = 3.862720
2018-12-04 20:26:23,903 - INFO - epoch 0, step 16900, training loss = 2.966779, validation loss = 3.811849
2018-12-04 20:26:27,268 - INFO - epoch 0, step 16910, training loss = 2.781232, validation loss = 3.736152
2018-12-04 20:26:30,475 - INFO - epoch 0, step 16920, training loss = 3.051740, validation loss = 3.972434
2018-12-04 20:26:33,996 - INFO - epoch 0, step 16930, training loss = 2.920784, validation loss = 3.646310
2018-12-04 20:26:37,345 - INFO - epoch 0, step 16940, training loss = 2.473580, validation loss = 3.592510
2018-12-04 20:26:41,138 - INFO - epoch 0, step 16950, training loss = 2.670829, validation loss = 3.113829
2018-12-04 20:26:46,428 - INFO - epoch 0, step 16960, training loss = 2.596709, validation loss = 3.904408
2018-12-04 20:26:51,165 - INFO - epoch 0, step 16970, training loss = 3.268780, validation loss = 3.945198
2018-12-04 20:26:56,307 - INFO - epoch 0, step 16980, training loss = 2.552103, validation loss = 3.584568
2018-12-04 20:27:01,261 - INFO - epoch 0, step 16990, training loss = 2.864727, validation loss = 3.109399
2018-12-04 20:27:06,208 - INFO - epoch 0, step 17000, training loss = 3.085714, validation loss = 3.223344
2018-12-04 20:27:11,119 - INFO - epoch 0, step 17010, training loss = 2.640085, validation loss = 3.789871
2018-12-04 20:27:15,876 - INFO - epoch 0, step 17020, training loss = 2.691273, validation loss = 4.262364
2018-12-04 20:27:20,784 - INFO - epoch 0, step 17030, training loss = 2.432295, validation loss = 3.634238
2018-12-04 20:27:25,810 - INFO - epoch 0, step 17040, training loss = 2.178235, validation loss = 4.026645
2018-12-04 20:27:30,665 - INFO - epoch 0, step 17050, training loss = 2.379103, validation loss = 3.535961
2018-12-04 20:27:35,457 - INFO - epoch 0, step 17060, training loss = 3.076614, validation loss = 3.949750
2018-12-04 20:27:40,681 - INFO - epoch 0, step 17070, training loss = 3.036714, validation loss = 3.202454
2018-12-04 20:27:46,205 - INFO - epoch 0, step 17080, training loss = 2.751500, validation loss = 3.725597
2018-12-04 20:27:51,403 - INFO - epoch 0, step 17090, training loss = 2.373551, validation loss = 3.449141
2018-12-04 20:27:56,745 - INFO - epoch 0, step 17100, training loss = 2.336069, validation loss = 3.838470
2018-12-04 20:28:02,104 - INFO - epoch 0, step 17110, training loss = 2.853096, validation loss = 3.683538
2018-12-04 20:28:07,460 - INFO - epoch 0, step 17120, training loss = 2.705730, validation loss = 3.814916
2018-12-04 20:28:12,720 - INFO - epoch 0, step 17130, training loss = 2.598565, validation loss = 4.168611
2018-12-04 20:28:18,119 - INFO - epoch 0, step 17140, training loss = 2.655351, validation loss = 3.463419
2018-12-04 20:28:23,558 - INFO - epoch 0, step 17150, training loss = 2.411983, validation loss = 3.608938
2018-12-04 20:28:28,836 - INFO - epoch 0, step 17160, training loss = 2.359396, validation loss = 3.165454
2018-12-04 20:28:33,921 - INFO - epoch 0, step 17170, training loss = 2.957931, validation loss = 3.799611
2018-12-04 20:28:38,913 - INFO - epoch 0, step 17180, training loss = 2.359351, validation loss = 3.752120
2018-12-04 20:28:44,286 - INFO - epoch 0, step 17190, training loss = 2.295996, validation loss = 3.445333
2018-12-04 20:28:49,672 - INFO - epoch 0, step 17200, training loss = 2.652107, validation loss = 3.374682
2018-12-04 20:28:55,013 - INFO - epoch 0, step 17210, training loss = 2.480264, validation loss = 3.416790
2018-12-04 20:29:00,208 - INFO - epoch 0, step 17220, training loss = 2.839359, validation loss = 3.410080
2018-12-04 20:29:05,736 - INFO - epoch 0, step 17230, training loss = 2.964476, validation loss = 3.887737
2018-12-04 20:29:10,853 - INFO - epoch 0, step 17240, training loss = 2.818226, validation loss = 3.650553
2018-12-04 20:29:16,210 - INFO - epoch 0, step 17250, training loss = 2.629450, validation loss = 3.640158
2018-12-04 20:29:21,385 - INFO - epoch 0, step 17260, training loss = 2.350260, validation loss = 3.168156
2018-12-04 20:29:26,668 - INFO - epoch 0, step 17270, training loss = 2.564169, validation loss = 3.291203
2018-12-04 20:29:31,792 - INFO - epoch 0, step 17280, training loss = 2.737864, validation loss = 3.949901
2018-12-04 20:29:36,939 - INFO - epoch 0, step 17290, training loss = 2.629284, validation loss = 3.428558
2018-12-04 20:29:42,420 - INFO - epoch 0, step 17300, training loss = 2.196622, validation loss = 3.711776
2018-12-04 20:29:47,719 - INFO - epoch 0, step 17310, training loss = 2.233737, validation loss = 4.050138
2018-12-04 20:29:52,918 - INFO - epoch 0, step 17320, training loss = 2.220164, validation loss = 3.674628
2018-12-04 20:29:58,085 - INFO - epoch 0, step 17330, training loss = 2.990792, validation loss = 3.641611
2018-12-04 20:30:03,320 - INFO - epoch 0, step 17340, training loss = 2.393150, validation loss = 3.952669
2018-12-04 20:30:08,894 - INFO - epoch 0, step 17350, training loss = 2.771909, validation loss = 3.810530
2018-12-04 20:30:14,263 - INFO - epoch 0, step 17360, training loss = 2.691469, validation loss = 3.798610
2018-12-04 20:30:19,502 - INFO - epoch 0, step 17370, training loss = 2.540101, validation loss = 3.501764
2018-12-04 20:30:24,008 - INFO - epoch 0, step 17380, training loss = 2.673925, validation loss = 3.012730
2018-12-04 20:30:28,392 - INFO - epoch 0, step 17390, training loss = 2.454993, validation loss = 3.811876
2018-12-04 20:30:32,917 - INFO - epoch 0, step 17400, training loss = 1.935544, validation loss = 3.577105
2018-12-04 20:30:37,576 - INFO - epoch 0, step 17410, training loss = 2.759693, validation loss = 3.497787
2018-12-04 20:30:41,384 - INFO - epoch 0, step 17420, training loss = 3.501733, validation loss = 3.561294
2018-12-04 20:30:44,080 - INFO - epoch 0, step 17430, training loss = 3.065014, validation loss = 3.481855
2018-12-04 20:30:46,749 - INFO - epoch 0, step 17440, training loss = 3.278018, validation loss = 4.189716
2018-12-04 20:30:49,449 - INFO - epoch 0, step 17450, training loss = 3.032737, validation loss = 3.919639
2018-12-04 20:30:52,363 - INFO - epoch 0, step 17460, training loss = 2.873195, validation loss = 3.249754
2018-12-04 20:30:55,184 - INFO - epoch 0, step 17470, training loss = 2.647966, validation loss = 4.197364
2018-12-04 20:30:57,937 - INFO - epoch 0, step 17480, training loss = 2.721579, validation loss = 4.076279
2018-12-04 20:31:00,866 - INFO - epoch 0, step 17490, training loss = 2.828715, validation loss = 3.658986
2018-12-04 20:31:04,893 - INFO - epoch 0, step 17500, training loss = 3.396060, validation loss = 4.154614
2018-12-04 20:31:09,018 - INFO - epoch 0, step 17510, training loss = 2.688090, validation loss = 3.983128
2018-12-04 20:31:13,243 - INFO - epoch 0, step 17520, training loss = 3.080717, validation loss = 3.625208
2018-12-04 20:31:17,566 - INFO - epoch 0, step 17530, training loss = 2.562671, validation loss = 3.601054
2018-12-04 20:31:21,840 - INFO - epoch 0, step 17540, training loss = 2.651603, validation loss = 3.195584
2018-12-04 20:31:27,053 - INFO - epoch 0, step 17550, training loss = 2.957360, validation loss = 3.755729
2018-12-04 20:31:32,476 - INFO - epoch 0, step 17560, training loss = 3.015043, validation loss = 4.319606
2018-12-04 20:31:37,890 - INFO - epoch 0, step 17570, training loss = 2.822308, validation loss = 3.833789
2018-12-04 20:31:43,583 - INFO - epoch 0, step 17580, training loss = 3.032077, validation loss = 4.241111
2018-12-04 20:31:49,014 - INFO - epoch 0, step 17590, training loss = 2.296752, validation loss = 4.267465
2018-12-04 20:31:54,553 - INFO - epoch 0, step 17600, training loss = 2.748708, validation loss = 4.690913
2018-12-04 20:31:59,912 - INFO - epoch 0, step 17610, training loss = 2.453991, validation loss = 4.067596
2018-12-04 20:32:05,134 - INFO - epoch 0, step 17620, training loss = 3.273137, validation loss = 4.123582
2018-12-04 20:32:10,638 - INFO - epoch 0, step 17630, training loss = 2.566356, validation loss = 4.403055
2018-12-04 20:32:15,947 - INFO - epoch 0, step 17640, training loss = 2.478370, validation loss = 3.972901
2018-12-04 20:32:21,082 - INFO - epoch 0, step 17650, training loss = 3.053095, validation loss = 4.009385
2018-12-04 20:32:26,231 - INFO - epoch 0, step 17660, training loss = 2.704486, validation loss = 3.812404
2018-12-04 20:32:31,557 - INFO - epoch 0, step 17670, training loss = 2.872590, validation loss = 3.515792
2018-12-04 20:32:37,101 - INFO - epoch 0, step 17680, training loss = 2.407542, validation loss = 3.922210
2018-12-04 20:32:42,721 - INFO - epoch 0, step 17690, training loss = 2.617892, validation loss = 3.717548
2018-12-04 20:32:48,072 - INFO - epoch 0, step 17700, training loss = 2.681400, validation loss = 3.793054
2018-12-04 20:32:53,608 - INFO - epoch 0, step 17710, training loss = 2.720447, validation loss = 3.215182
2018-12-04 20:32:59,258 - INFO - epoch 0, step 17720, training loss = 2.609500, validation loss = 4.296093
2018-12-04 20:33:04,726 - INFO - epoch 0, step 17730, training loss = 2.764845, validation loss = 3.957783
2018-12-04 20:33:10,246 - INFO - epoch 0, step 17740, training loss = 2.634304, validation loss = 3.635111
2018-12-04 20:33:15,668 - INFO - epoch 0, step 17750, training loss = 2.838593, validation loss = 3.683796
2018-12-04 20:33:20,528 - INFO - epoch 0, step 17760, training loss = 2.254200, validation loss = 4.033505
2018-12-04 20:33:24,758 - INFO - epoch 0, step 17770, training loss = 2.420708, validation loss = 3.954690
2018-12-04 20:33:29,142 - INFO - epoch 0, step 17780, training loss = 2.318799, validation loss = 3.668591
2018-12-04 20:33:33,352 - INFO - epoch 0, step 17790, training loss = 2.506762, validation loss = 3.468057
2018-12-04 20:33:37,822 - INFO - epoch 0, step 17800, training loss = 2.789087, validation loss = 3.887841
2018-12-04 20:33:42,463 - INFO - epoch 0, step 17810, training loss = 2.449138, validation loss = 3.651322
2018-12-04 20:33:46,596 - INFO - epoch 0, step 17820, training loss = 2.552575, validation loss = 3.474285
2018-12-04 20:33:49,975 - INFO - epoch 0, step 17830, training loss = 2.874849, validation loss = 3.612046
2018-12-04 20:33:53,464 - INFO - epoch 0, step 17840, training loss = 2.572547, validation loss = 4.104698
2018-12-04 20:33:56,919 - INFO - epoch 0, step 17850, training loss = 2.323529, validation loss = 3.665290
2018-12-04 20:34:00,162 - INFO - epoch 0, step 17860, training loss = 2.692518, validation loss = 3.872295
2018-12-04 20:34:03,255 - INFO - epoch 0, step 17870, training loss = 2.629806, validation loss = 3.227642
2018-12-04 20:34:06,547 - INFO - epoch 0, step 17880, training loss = 2.938551, validation loss = 4.337970
2018-12-04 20:34:09,875 - INFO - epoch 0, step 17890, training loss = 2.618850, validation loss = 3.706826
2018-12-04 20:34:13,136 - INFO - epoch 0, step 17900, training loss = 2.861228, validation loss = 3.927546
2018-12-04 20:34:16,248 - INFO - epoch 0, step 17910, training loss = 2.973593, validation loss = 3.680479
2018-12-04 20:34:19,409 - INFO - epoch 0, step 17920, training loss = 3.187845, validation loss = 4.237505
2018-12-04 20:34:22,547 - INFO - epoch 0, step 17930, training loss = 3.325786, validation loss = 3.733438
2018-12-04 20:34:25,796 - INFO - epoch 0, step 17940, training loss = 3.232379, validation loss = 3.514953
2018-12-04 20:34:28,994 - INFO - epoch 0, step 17950, training loss = 2.758624, validation loss = 3.632214
2018-12-04 20:34:32,233 - INFO - epoch 0, step 17960, training loss = 2.721880, validation loss = 3.461022
2018-12-04 20:34:35,587 - INFO - epoch 0, step 17970, training loss = 2.288542, validation loss = 3.477220
2018-12-04 20:34:38,930 - INFO - epoch 0, step 17980, training loss = 2.777697, validation loss = 3.536052
2018-12-04 20:34:42,083 - INFO - epoch 0, step 17990, training loss = 2.605217, validation loss = 3.995538
2018-12-04 20:34:45,303 - INFO - epoch 0, step 18000, training loss = 2.756122, validation loss = 3.542846
2018-12-04 20:34:48,670 - INFO - epoch 0, step 18010, training loss = 2.940030, validation loss = 3.962082
2018-12-04 20:34:51,858 - INFO - epoch 0, step 18020, training loss = 2.624892, validation loss = 4.182245
2018-12-04 20:34:54,316 - INFO - epoch 0, step 18030, training loss = 3.059008, validation loss = 3.655336
2018-12-04 20:34:56,807 - INFO - epoch 0, step 18040, training loss = 2.626834, validation loss = 3.357773
2018-12-04 20:34:59,334 - INFO - epoch 0, step 18050, training loss = 2.647558, validation loss = 3.629987
2018-12-04 20:35:01,800 - INFO - epoch 0, step 18060, training loss = 3.144732, validation loss = 3.560805
2018-12-04 20:35:04,227 - INFO - epoch 0, step 18070, training loss = 3.240544, validation loss = 4.273662
2018-12-04 20:35:06,919 - INFO - epoch 0, step 18080, training loss = 2.542134, validation loss = 3.958925
2018-12-04 20:35:09,475 - INFO - epoch 0, step 18090, training loss = 2.601854, validation loss = 4.149868
2018-12-04 20:35:12,045 - INFO - epoch 0, step 18100, training loss = 2.809715, validation loss = 4.593565
2018-12-04 20:35:15,975 - INFO - epoch 0, step 18110, training loss = 2.969324, validation loss = 4.124698
2018-12-04 20:35:21,416 - INFO - epoch 0, step 18120, training loss = 2.574796, validation loss = 4.458262
2018-12-04 20:35:26,768 - INFO - epoch 0, step 18130, training loss = 2.349307, validation loss = 3.820958
2018-12-04 20:35:32,146 - INFO - epoch 0, step 18140, training loss = 2.383103, validation loss = 3.855113
2018-12-04 20:35:38,291 - INFO - epoch 0, step 18150, training loss = 2.665975, validation loss = 3.813858
2018-12-04 20:35:43,622 - INFO - epoch 0, step 18160, training loss = 2.211998, validation loss = 3.648013
2018-12-04 20:35:49,039 - INFO - epoch 0, step 18170, training loss = 2.225182, validation loss = 4.329920
2018-12-04 20:35:54,246 - INFO - epoch 0, step 18180, training loss = 2.546801, validation loss = 4.479946
2018-12-04 20:35:59,359 - INFO - epoch 0, step 18190, training loss = 2.672592, validation loss = 3.796937
2018-12-04 20:36:04,840 - INFO - epoch 0, step 18200, training loss = 2.329571, validation loss = 4.093060
2018-12-04 20:36:10,068 - INFO - epoch 0, step 18210, training loss = 2.640889, validation loss = 3.552466
2018-12-04 20:36:15,122 - INFO - epoch 0, step 18220, training loss = 2.553412, validation loss = 3.554267
2018-12-04 20:36:20,308 - INFO - epoch 0, step 18230, training loss = 2.294485, validation loss = 3.725450
2018-12-04 20:36:25,421 - INFO - epoch 0, step 18240, training loss = 2.568887, validation loss = 4.294971
2018-12-04 20:36:30,647 - INFO - epoch 0, step 18250, training loss = 2.851444, validation loss = 4.219041
2018-12-04 20:36:35,844 - INFO - epoch 0, step 18260, training loss = 2.676286, validation loss = 4.017662
2018-12-04 20:36:41,002 - INFO - epoch 0, step 18270, training loss = 2.472705, validation loss = 3.749588
2018-12-04 20:36:46,379 - INFO - epoch 0, step 18280, training loss = 2.515402, validation loss = 3.722782
2018-12-04 20:36:51,489 - INFO - epoch 0, step 18290, training loss = 2.919093, validation loss = 4.030836
2018-12-04 20:36:56,555 - INFO - epoch 0, step 18300, training loss = 2.932918, validation loss = 4.104606
2018-12-04 20:37:01,715 - INFO - epoch 0, step 18310, training loss = 2.195309, validation loss = 3.455463
2018-12-04 20:37:07,208 - INFO - epoch 0, step 18320, training loss = 2.547593, validation loss = 3.802153
2018-12-04 20:37:12,565 - INFO - epoch 0, step 18330, training loss = 2.551707, validation loss = 4.079680
2018-12-04 20:37:18,032 - INFO - epoch 0, step 18340, training loss = 2.134932, validation loss = 3.793441
2018-12-04 20:37:23,310 - INFO - epoch 0, step 18350, training loss = 2.547511, validation loss = 3.842438
2018-12-04 20:37:28,313 - INFO - epoch 0, step 18360, training loss = 2.968502, validation loss = 3.875874
2018-12-04 20:37:31,811 - INFO - epoch 0, step 18370, training loss = 2.808769, validation loss = 3.976129
2018-12-04 20:37:35,014 - INFO - epoch 0, step 18380, training loss = 2.583117, validation loss = 3.861286
2018-12-04 20:37:38,356 - INFO - epoch 0, step 18390, training loss = 2.362854, validation loss = 3.573974
2018-12-04 20:37:41,680 - INFO - epoch 0, step 18400, training loss = 2.818844, validation loss = 4.091108
2018-12-04 20:37:44,908 - INFO - epoch 0, step 18410, training loss = 2.738548, validation loss = 3.793659
2018-12-04 20:37:48,177 - INFO - epoch 0, step 18420, training loss = 2.211962, validation loss = 3.858114
2018-12-04 20:37:51,366 - INFO - epoch 0, step 18430, training loss = 2.897799, validation loss = 4.043356
2018-12-04 20:37:54,526 - INFO - epoch 0, step 18440, training loss = 2.775801, validation loss = 4.231512
2018-12-04 20:37:57,656 - INFO - epoch 0, step 18450, training loss = 3.062615, validation loss = 4.073190
2018-12-04 20:38:01,083 - INFO - epoch 0, step 18460, training loss = 1.835950, validation loss = 3.865158
2018-12-04 20:38:04,375 - INFO - epoch 0, step 18470, training loss = 2.685779, validation loss = 4.062316
2018-12-04 20:38:07,643 - INFO - epoch 0, step 18480, training loss = 2.605080, validation loss = 3.838073
2018-12-04 20:38:11,197 - INFO - epoch 0, step 18490, training loss = 2.416460, validation loss = 3.672034
2018-12-04 20:38:14,589 - INFO - epoch 0, step 18500, training loss = 2.544574, validation loss = 3.770714
2018-12-04 20:38:17,979 - INFO - epoch 0, step 18510, training loss = 2.540046, validation loss = 3.594516
2018-12-04 20:38:21,199 - INFO - epoch 0, step 18520, training loss = 3.388002, validation loss = 4.212648
2018-12-04 20:38:24,692 - INFO - epoch 0, step 18530, training loss = 2.510637, validation loss = 4.315876
2018-12-04 20:38:27,985 - INFO - epoch 0, step 18540, training loss = 2.361642, validation loss = 3.735778
2018-12-04 20:38:31,257 - INFO - epoch 0, step 18550, training loss = 2.145096, validation loss = 4.295864
2018-12-04 20:38:34,519 - INFO - epoch 0, step 18560, training loss = 2.209107, validation loss = 4.288334
2018-12-04 20:38:38,224 - INFO - epoch 0, step 18570, training loss = 1.969949, validation loss = 3.862921
2018-12-04 20:38:41,708 - INFO - epoch 0, step 18580, training loss = 2.187656, validation loss = 3.632858
2018-12-04 20:38:45,492 - INFO - epoch 0, step 18590, training loss = 3.044040, validation loss = 3.520463
2018-12-04 20:38:49,363 - INFO - epoch 0, step 18600, training loss = 2.690782, validation loss = 3.085065
2018-12-04 20:38:53,015 - INFO - epoch 0, step 18610, training loss = 2.695008, validation loss = 4.376731
2018-12-04 20:38:57,535 - INFO - epoch 0, step 18620, training loss = 2.473686, validation loss = 3.733129
2018-12-04 20:39:02,710 - INFO - epoch 0, step 18630, training loss = 2.836024, validation loss = 3.537494
2018-12-04 20:39:07,981 - INFO - epoch 0, step 18640, training loss = 2.558561, validation loss = 3.352993
2018-12-04 20:39:13,371 - INFO - epoch 0, step 18650, training loss = 2.943215, validation loss = 4.183368
2018-12-04 20:39:18,499 - INFO - epoch 0, step 18660, training loss = 2.526462, validation loss = 4.235552
2018-12-04 20:39:24,102 - INFO - epoch 0, step 18670, training loss = 2.674981, validation loss = 3.569313
2018-12-04 20:39:29,450 - INFO - epoch 0, step 18680, training loss = 2.764004, validation loss = 3.770363
2018-12-04 20:39:34,530 - INFO - epoch 0, step 18690, training loss = 2.611693, validation loss = 3.716539
2018-12-04 20:39:39,779 - INFO - epoch 0, step 18700, training loss = 2.599450, validation loss = 3.788182
2018-12-04 20:39:44,863 - INFO - epoch 0, step 18710, training loss = 2.833937, validation loss = 3.873420
2018-12-04 20:39:50,352 - INFO - epoch 0, step 18720, training loss = 2.491412, validation loss = 3.365850
2018-12-04 20:39:55,874 - INFO - epoch 0, step 18730, training loss = 2.607199, validation loss = 3.830628
2018-12-04 20:40:01,122 - INFO - epoch 0, step 18740, training loss = 1.781741, validation loss = 3.674051
2018-12-04 20:40:05,533 - INFO - epoch 0, step 18750, training loss = 3.399223, validation loss = 4.242099
2018-12-04 20:40:08,665 - INFO - epoch 0, step 18760, training loss = 3.184686, validation loss = 3.659679
2018-12-04 20:40:11,932 - INFO - epoch 0, step 18770, training loss = 2.795056, validation loss = 3.668387
2018-12-04 20:40:15,190 - INFO - epoch 0, step 18780, training loss = 2.099040, validation loss = 3.981107
2018-12-04 20:40:18,866 - INFO - epoch 0, step 18790, training loss = 2.395811, validation loss = 3.996985
2018-12-04 20:40:22,102 - INFO - epoch 0, step 18800, training loss = 3.046021, validation loss = 4.076097
2018-12-04 20:40:25,244 - INFO - epoch 0, step 18810, training loss = 2.926340, validation loss = 3.543166
2018-12-04 20:40:28,349 - INFO - epoch 0, step 18820, training loss = 2.440643, validation loss = 3.662262
2018-12-04 20:40:31,472 - INFO - epoch 0, step 18830, training loss = 2.665665, validation loss = 3.723093
2018-12-04 20:40:34,749 - INFO - epoch 0, step 18840, training loss = 2.904973, validation loss = 3.738270
2018-12-04 20:40:38,018 - INFO - epoch 0, step 18850, training loss = 2.335811, validation loss = 3.475313
2018-12-04 20:40:41,300 - INFO - epoch 0, step 18860, training loss = 2.707693, validation loss = 3.489978
2018-12-04 20:40:44,426 - INFO - epoch 0, step 18870, training loss = 2.226252, validation loss = 3.891594
2018-12-04 20:40:47,636 - INFO - epoch 0, step 18880, training loss = 2.664131, validation loss = 3.380129
2018-12-04 20:40:50,814 - INFO - epoch 0, step 18890, training loss = 2.761440, validation loss = 4.496020
2018-12-04 20:40:54,046 - INFO - epoch 0, step 18900, training loss = 2.505014, validation loss = 4.043441
2018-12-04 20:40:57,536 - INFO - epoch 0, step 18910, training loss = 2.035402, validation loss = 3.595607
2018-12-04 20:41:00,653 - INFO - epoch 0, step 18920, training loss = 2.541709, validation loss = 3.799607
2018-12-04 20:41:03,895 - INFO - epoch 0, step 18930, training loss = 2.800226, validation loss = 3.698415
2018-12-04 20:41:07,097 - INFO - epoch 0, step 18940, training loss = 2.335158, validation loss = 3.829346
2018-12-04 20:41:10,314 - INFO - epoch 0, step 18950, training loss = 1.806313, validation loss = 4.108523
2018-12-04 20:41:13,692 - INFO - epoch 0, step 18960, training loss = 2.465413, validation loss = 3.664734
2018-12-04 20:41:18,269 - INFO - epoch 0, step 18970, training loss = 2.410509, validation loss = 3.796378
2018-12-04 20:41:22,514 - INFO - epoch 0, step 18980, training loss = 2.719373, validation loss = 3.832376
2018-12-04 20:41:26,565 - INFO - epoch 0, step 18990, training loss = 2.592229, validation loss = 3.474979
2018-12-04 20:41:31,114 - INFO - epoch 0, step 19000, training loss = 2.395009, validation loss = 3.726588
2018-12-04 20:41:35,605 - INFO - epoch 0, step 19010, training loss = 2.686935, validation loss = 3.617230
2018-12-04 20:41:39,695 - INFO - epoch 0, step 19020, training loss = 3.027850, validation loss = 3.729103
2018-12-04 20:41:43,276 - INFO - epoch 0, step 19030, training loss = 3.126133, validation loss = 3.670205
2018-12-04 20:41:46,521 - INFO - epoch 0, step 19040, training loss = 2.473650, validation loss = 3.777432
2018-12-04 20:41:49,772 - INFO - epoch 0, step 19050, training loss = 2.471065, validation loss = 3.711134
2018-12-04 20:41:52,950 - INFO - epoch 0, step 19060, training loss = 2.737289, validation loss = 4.024240
2018-12-04 20:41:56,107 - INFO - epoch 0, step 19070, training loss = 2.245844, validation loss = 3.780468
2018-12-04 20:41:59,296 - INFO - epoch 0, step 19080, training loss = 3.062673, validation loss = 3.879574
2018-12-04 20:42:02,384 - INFO - epoch 0, step 19090, training loss = 2.758951, validation loss = 3.722276
2018-12-04 20:42:05,597 - INFO - epoch 0, step 19100, training loss = 2.332500, validation loss = 4.130642
2018-12-04 20:42:08,627 - INFO - epoch 0, step 19110, training loss = 2.685109, validation loss = 3.762585
2018-12-04 20:42:11,749 - INFO - epoch 0, step 19120, training loss = 2.929320, validation loss = 3.822847
2018-12-04 20:42:14,841 - INFO - epoch 0, step 19130, training loss = 2.586383, validation loss = 3.907129
2018-12-04 20:42:18,100 - INFO - epoch 0, step 19140, training loss = 2.342556, validation loss = 3.727688
2018-12-04 20:42:21,365 - INFO - epoch 0, step 19150, training loss = 2.367007, validation loss = 3.745602
2018-12-04 20:42:24,606 - INFO - epoch 0, step 19160, training loss = 2.685282, validation loss = 3.591588
2018-12-04 20:42:27,856 - INFO - epoch 0, step 19170, training loss = 2.451648, validation loss = 4.033213
2018-12-04 20:42:30,968 - INFO - epoch 0, step 19180, training loss = 2.729538, validation loss = 3.511482
2018-12-04 20:42:34,207 - INFO - epoch 0, step 19190, training loss = 2.178230, validation loss = 4.082822
2018-12-04 20:42:37,586 - INFO - epoch 0, step 19200, training loss = 2.824241, validation loss = 3.898880
2018-12-04 20:42:40,781 - INFO - epoch 0, step 19210, training loss = 3.054710, validation loss = 3.490157
2018-12-04 20:42:43,826 - INFO - epoch 0, step 19220, training loss = 3.050841, validation loss = 4.045146
2018-12-04 20:42:48,411 - INFO - epoch 0, step 19230, training loss = 3.372879, validation loss = 3.644087
2018-12-04 20:42:53,528 - INFO - epoch 0, step 19240, training loss = 2.804609, validation loss = 3.396498
2018-12-04 20:42:59,223 - INFO - epoch 0, step 19250, training loss = 2.607275, validation loss = 4.038604
2018-12-04 20:43:04,282 - INFO - epoch 0, step 19260, training loss = 2.576962, validation loss = 3.978140
2018-12-04 20:43:09,585 - INFO - epoch 0, step 19270, training loss = 2.629316, validation loss = 3.644726
2018-12-04 20:43:14,634 - INFO - epoch 0, step 19280, training loss = 2.330761, validation loss = 3.444047
2018-12-04 20:43:19,591 - INFO - epoch 0, step 19290, training loss = 2.901561, validation loss = 3.423751
2018-12-04 20:43:24,905 - INFO - epoch 0, step 19300, training loss = 3.075182, validation loss = 3.763757
2018-12-04 20:43:30,157 - INFO - epoch 0, step 19310, training loss = 2.502341, validation loss = 3.434435
2018-12-04 20:43:35,525 - INFO - epoch 0, step 19320, training loss = 2.371150, validation loss = 4.001666
2018-12-04 20:43:40,704 - INFO - epoch 0, step 19330, training loss = 2.188359, validation loss = 3.474138
2018-12-04 20:43:45,733 - INFO - epoch 0, step 19340, training loss = 2.775991, validation loss = 3.616330
2018-12-04 20:43:50,922 - INFO - epoch 0, step 19350, training loss = 2.012633, validation loss = 3.812453
2018-12-04 20:43:56,794 - INFO - epoch 0, step 19360, training loss = 2.212415, validation loss = 3.803720
2018-12-04 20:44:02,975 - INFO - epoch 0, step 19370, training loss = 1.897788, validation loss = 3.116130
2018-12-04 20:44:08,965 - INFO - epoch 0, step 19380, training loss = 1.954320, validation loss = 3.804114
2018-12-04 20:44:14,950 - INFO - epoch 0, step 19390, training loss = 2.245267, validation loss = 3.967435
2018-12-04 20:44:20,559 - INFO - epoch 0, step 19400, training loss = 2.056867, validation loss = 3.721416
2018-12-04 20:44:26,446 - INFO - epoch 0, step 19410, training loss = 2.142907, validation loss = 3.852946
2018-12-04 20:44:32,685 - INFO - epoch 0, step 19420, training loss = 2.272894, validation loss = 3.855193
2018-12-04 20:44:38,253 - INFO - epoch 0, step 19430, training loss = 2.251450, validation loss = 3.878911
2018-12-04 20:44:43,783 - INFO - epoch 0, step 19440, training loss = 2.537364, validation loss = 4.157940
2018-12-04 20:44:49,174 - INFO - epoch 0, step 19450, training loss = 2.213762, validation loss = 4.102106
2018-12-04 20:44:54,518 - INFO - epoch 0, step 19460, training loss = 2.510463, validation loss = 3.878093
2018-12-04 20:45:00,888 - INFO - epoch 0, step 19470, training loss = 2.418732, validation loss = 3.993885
2018-12-04 20:45:06,462 - INFO - epoch 0, step 19480, training loss = 2.595944, validation loss = 4.089029
2018-12-04 20:45:12,419 - INFO - epoch 0, step 19490, training loss = 2.204362, validation loss = 3.189801
2018-12-04 20:45:18,646 - INFO - epoch 0, step 19500, training loss = 2.297071, validation loss = 3.494980
2018-12-04 20:45:24,624 - INFO - epoch 0, step 19510, training loss = 1.886562, validation loss = 3.876430
2018-12-04 20:45:30,699 - INFO - epoch 0, step 19520, training loss = 1.683902, validation loss = 3.641649
2018-12-04 20:45:37,062 - INFO - epoch 0, step 19530, training loss = 2.382158, validation loss = 3.591303
2018-12-04 20:45:41,106 - INFO - epoch 0, step 19540, training loss = 2.648042, validation loss = 3.651546
2018-12-04 20:45:45,585 - INFO - epoch 0, step 19550, training loss = 2.413707, validation loss = 3.543953
2018-12-04 20:45:49,838 - INFO - epoch 0, step 19560, training loss = 2.884881, validation loss = 3.894328
2018-12-04 20:45:54,010 - INFO - epoch 0, step 19570, training loss = 2.434365, validation loss = 3.698401
2018-12-04 20:45:58,472 - INFO - epoch 0, step 19580, training loss = 2.730555, validation loss = 3.711244
2018-12-04 20:46:02,759 - INFO - epoch 0, step 19590, training loss = 2.634959, validation loss = 3.771639
2018-12-04 20:46:06,867 - INFO - epoch 0, step 19600, training loss = 3.088190, validation loss = 4.216673
2018-12-04 20:46:10,899 - INFO - epoch 0, step 19610, training loss = 2.741103, validation loss = 3.440269
2018-12-04 20:46:15,113 - INFO - epoch 0, step 19620, training loss = 2.974159, validation loss = 4.049314
2018-12-04 20:46:19,351 - INFO - epoch 0, step 19630, training loss = 2.375863, validation loss = 4.208761
2018-12-04 20:46:23,582 - INFO - epoch 0, step 19640, training loss = 2.556387, validation loss = 4.137637
2018-12-04 20:46:28,013 - INFO - epoch 0, step 19650, training loss = 2.731406, validation loss = 3.795551
2018-12-04 20:46:33,448 - INFO - epoch 0, step 19660, training loss = 2.309585, validation loss = 3.697498
2018-12-04 20:46:39,174 - INFO - epoch 0, step 19670, training loss = 2.313949, validation loss = 3.756799
2018-12-04 20:46:44,526 - INFO - epoch 0, step 19680, training loss = 2.226409, validation loss = 4.102424
2018-12-04 20:46:49,632 - INFO - epoch 0, step 19690, training loss = 2.263548, validation loss = 3.619990
2018-12-04 20:46:55,553 - INFO - epoch 0, step 19700, training loss = 1.979685, validation loss = 3.762378
2018-12-04 20:47:01,458 - INFO - epoch 0, step 19710, training loss = 2.043196, validation loss = 3.651875
2018-12-04 20:47:06,926 - INFO - epoch 0, step 19720, training loss = 2.417293, validation loss = 3.265420
2018-12-04 20:47:13,147 - INFO - epoch 0, step 19730, training loss = 2.099098, validation loss = 3.835580
2018-12-04 20:47:18,986 - INFO - epoch 0, step 19740, training loss = 2.385070, validation loss = 3.878832
2018-12-04 20:47:24,507 - INFO - epoch 0, step 19750, training loss = 2.847610, validation loss = 3.558065
2018-12-04 20:47:29,888 - INFO - epoch 0, step 19760, training loss = 2.041415, validation loss = 3.601219
2018-12-04 20:47:35,662 - INFO - epoch 0, step 19770, training loss = 2.299390, validation loss = 3.849706
2018-12-04 20:47:41,414 - INFO - epoch 0, step 19780, training loss = 2.222214, validation loss = 3.635805
2018-12-04 20:47:47,267 - INFO - epoch 0, step 19790, training loss = 2.495677, validation loss = 4.172233
2018-12-04 20:47:52,662 - INFO - epoch 0, step 19800, training loss = 2.469068, validation loss = 3.718508
2018-12-04 20:47:58,432 - INFO - epoch 0, step 19810, training loss = 2.670377, validation loss = 3.856691
2018-12-04 20:48:03,974 - INFO - epoch 0, step 19820, training loss = 2.558687, validation loss = 3.973438
2018-12-04 20:48:09,633 - INFO - epoch 0, step 19830, training loss = 2.332108, validation loss = 3.657141
2018-12-04 20:48:15,100 - INFO - epoch 0, step 19840, training loss = 2.111940, validation loss = 3.738055
2018-12-04 20:48:20,712 - INFO - epoch 0, step 19850, training loss = 2.266699, validation loss = 4.161608
2018-12-04 20:48:26,243 - INFO - epoch 0, step 19860, training loss = 2.482917, validation loss = 3.525947
2018-12-04 20:48:32,015 - INFO - epoch 0, step 19870, training loss = 2.130167, validation loss = 3.642066
2018-12-04 20:48:37,041 - INFO - epoch 0, step 19880, training loss = 3.019295, validation loss = 3.949040
2018-12-04 20:48:40,175 - INFO - epoch 0, step 19890, training loss = 2.813823, validation loss = 3.976090
2018-12-04 20:48:44,362 - INFO - epoch 0, step 19900, training loss = 2.388685, validation loss = 3.730055
2018-12-04 20:48:47,717 - INFO - epoch 0, step 19910, training loss = 2.695819, validation loss = 3.466576
2018-12-04 20:48:51,039 - INFO - epoch 0, step 19920, training loss = 2.787299, validation loss = 3.413271
2018-12-04 20:48:54,473 - INFO - epoch 0, step 19930, training loss = 2.988497, validation loss = 3.167885
2018-12-04 20:48:57,698 - INFO - epoch 0, step 19940, training loss = 2.591252, validation loss = 3.736330
2018-12-04 20:49:00,981 - INFO - epoch 0, step 19950, training loss = 2.510706, validation loss = 3.918132
2018-12-04 20:49:04,312 - INFO - epoch 0, step 19960, training loss = 2.518275, validation loss = 3.908145
2018-12-04 20:49:07,863 - INFO - epoch 0, step 19970, training loss = 2.709794, validation loss = 3.420653
2018-12-04 20:49:11,117 - INFO - epoch 0, step 19980, training loss = 3.072073, validation loss = 3.600973
2018-12-04 20:49:14,388 - INFO - epoch 0, step 19990, training loss = 3.035777, validation loss = 4.029398
2018-12-04 20:49:17,816 - INFO - epoch 0, step 20000, training loss = 2.617961, validation loss = 3.384067
2018-12-04 20:49:21,032 - INFO - epoch 0, step 20010, training loss = 2.314867, validation loss = 4.208626
2018-12-04 20:49:24,344 - INFO - epoch 0, step 20020, training loss = 2.747041, validation loss = 4.045093
2018-12-04 20:49:27,634 - INFO - epoch 0, step 20030, training loss = 2.789117, validation loss = 3.716722
2018-12-04 20:49:30,817 - INFO - epoch 0, step 20040, training loss = 2.505273, validation loss = 4.419742
2018-12-04 20:49:34,049 - INFO - epoch 0, step 20050, training loss = 3.014467, validation loss = 3.562195
2018-12-04 20:49:37,292 - INFO - epoch 0, step 20060, training loss = 2.974112, validation loss = 3.705929
2018-12-04 20:49:40,535 - INFO - epoch 0, step 20070, training loss = 2.490365, validation loss = 3.743075
2018-12-04 20:49:43,832 - INFO - epoch 0, step 20080, training loss = 2.715509, validation loss = 3.876019
2018-12-04 20:49:47,207 - INFO - epoch 0, step 20090, training loss = 3.046629, validation loss = 3.670256
2018-12-04 20:49:50,528 - INFO - epoch 0, step 20100, training loss = 2.831955, validation loss = 4.053549
2018-12-04 20:49:53,732 - INFO - epoch 0, step 20110, training loss = 2.392542, validation loss = 3.942196
2018-12-04 20:49:57,111 - INFO - epoch 0, step 20120, training loss = 2.693554, validation loss = 3.801360
2018-12-04 20:50:00,424 - INFO - epoch 0, step 20130, training loss = 2.477998, validation loss = 3.662858
2018-12-04 20:50:03,621 - INFO - epoch 0, step 20140, training loss = 2.390815, validation loss = 3.908450
2018-12-04 20:50:06,937 - INFO - epoch 0, step 20150, training loss = 2.153557, validation loss = 4.676105
2018-12-04 20:50:10,265 - INFO - epoch 0, step 20160, training loss = 2.735363, validation loss = 3.121482
2018-12-04 20:50:13,508 - INFO - epoch 0, step 20170, training loss = 3.170382, validation loss = 3.824116
2018-12-04 20:50:16,689 - INFO - epoch 0, step 20180, training loss = 2.516398, validation loss = 3.534588
2018-12-04 20:50:19,786 - INFO - epoch 0, step 20190, training loss = 2.645917, validation loss = 3.205566
2018-12-04 20:50:22,987 - INFO - epoch 0, step 20200, training loss = 2.195074, validation loss = 3.588438
2018-12-04 20:50:26,159 - INFO - epoch 0, step 20210, training loss = 2.843120, validation loss = 3.988738
2018-12-04 20:50:29,648 - INFO - epoch 0, step 20220, training loss = 2.391822, validation loss = 3.752461
2018-12-04 20:50:33,845 - INFO - epoch 0, step 20230, training loss = 2.773183, validation loss = 3.631828
2018-12-04 20:50:38,511 - INFO - epoch 0, step 20240, training loss = 2.937514, validation loss = 3.280775
2018-12-04 20:50:43,107 - INFO - epoch 0, step 20250, training loss = 2.375140, validation loss = 4.018239
2018-12-04 20:50:47,375 - INFO - epoch 0, step 20260, training loss = 2.771892, validation loss = 3.390452
2018-12-04 20:50:51,913 - INFO - epoch 0, step 20270, training loss = 2.620242, validation loss = 3.644081
2018-12-04 20:50:56,575 - INFO - epoch 0, step 20280, training loss = 2.542095, validation loss = 4.346633
2018-12-04 20:51:00,993 - INFO - epoch 0, step 20290, training loss = 2.485640, validation loss = 3.302311
2018-12-04 20:51:05,500 - INFO - epoch 0, step 20300, training loss = 2.718661, validation loss = 3.657095
2018-12-04 20:51:09,788 - INFO - epoch 0, step 20310, training loss = 2.913419, validation loss = 3.383070
2018-12-04 20:51:14,156 - INFO - epoch 0, step 20320, training loss = 2.242600, validation loss = 3.447006
2018-12-04 20:51:18,533 - INFO - epoch 0, step 20330, training loss = 2.371394, validation loss = 3.601809
2018-12-04 20:51:22,814 - INFO - epoch 0, step 20340, training loss = 2.575378, validation loss = 3.466284
2018-12-04 20:51:27,343 - INFO - epoch 0, step 20350, training loss = 2.623699, validation loss = 3.945052
2018-12-04 20:51:31,545 - INFO - epoch 0, step 20360, training loss = 2.740283, validation loss = 4.083941
2018-12-04 20:51:35,807 - INFO - epoch 0, step 20370, training loss = 2.243062, validation loss = 3.618362
2018-12-04 20:51:40,101 - INFO - epoch 0, step 20380, training loss = 2.393167, validation loss = 3.568557
2018-12-04 20:51:44,279 - INFO - epoch 0, step 20390, training loss = 2.234952, validation loss = 3.798546
2018-12-04 20:51:49,022 - INFO - epoch 0, step 20400, training loss = 2.315376, validation loss = 3.742503
2018-12-04 20:51:53,734 - INFO - epoch 0, step 20410, training loss = 1.757730, validation loss = 3.816395
2018-12-04 20:51:58,298 - INFO - epoch 0, step 20420, training loss = 2.349514, validation loss = 3.322357
2018-12-04 20:52:02,809 - INFO - epoch 0, step 20430, training loss = 2.599803, validation loss = 3.963144
2018-12-04 20:52:07,078 - INFO - epoch 0, step 20440, training loss = 2.756075, validation loss = 3.880797
2018-12-04 20:52:11,404 - INFO - epoch 0, step 20450, training loss = 2.642272, validation loss = 4.202181
2018-12-04 20:52:15,709 - INFO - epoch 0, step 20460, training loss = 2.191366, validation loss = 4.435051
2018-12-04 20:52:19,841 - INFO - epoch 0, step 20470, training loss = 2.931856, validation loss = 3.521404
2018-12-04 20:52:25,132 - INFO - epoch 0, step 20480, training loss = 2.618720, validation loss = 3.526314
2018-12-04 20:52:30,262 - INFO - epoch 0, step 20490, training loss = 2.962511, validation loss = 3.372286
2018-12-04 20:52:35,638 - INFO - epoch 0, step 20500, training loss = 2.274962, validation loss = 3.796321
2018-12-04 20:52:40,787 - INFO - epoch 0, step 20510, training loss = 2.620847, validation loss = 3.671530
2018-12-04 20:52:45,896 - INFO - epoch 0, step 20520, training loss = 2.613189, validation loss = 3.129343
2018-12-04 20:52:51,180 - INFO - epoch 0, step 20530, training loss = 2.722471, validation loss = 3.655262
2018-12-04 20:52:56,364 - INFO - epoch 0, step 20540, training loss = 3.279922, validation loss = 4.066342
2018-12-04 20:53:01,557 - INFO - epoch 0, step 20550, training loss = 2.469795, validation loss = 3.841008
2018-12-04 20:53:06,775 - INFO - epoch 0, step 20560, training loss = 2.393329, validation loss = 3.779219
2018-12-04 20:53:11,864 - INFO - epoch 0, step 20570, training loss = 2.525745, validation loss = 3.433404
2018-12-04 20:53:16,884 - INFO - epoch 0, step 20580, training loss = 2.923021, validation loss = 3.719617
2018-12-04 20:53:22,142 - INFO - epoch 0, step 20590, training loss = 2.785650, validation loss = 4.049782
2018-12-04 20:53:27,174 - INFO - epoch 0, step 20600, training loss = 2.546782, validation loss = 3.138462
2018-12-04 20:53:32,428 - INFO - epoch 0, step 20610, training loss = 2.286710, validation loss = 3.559529
2018-12-04 20:53:37,148 - INFO - epoch 0, step 20620, training loss = 3.027675, validation loss = 3.515756
2018-12-04 20:53:40,811 - INFO - epoch 0, step 20630, training loss = 2.873587, validation loss = 3.620409
2018-12-04 20:53:44,466 - INFO - epoch 0, step 20640, training loss = 2.932150, validation loss = 3.454353
2018-12-04 20:53:48,166 - INFO - epoch 0, step 20650, training loss = 2.643740, validation loss = 3.788735
2018-12-04 20:53:51,938 - INFO - epoch 0, step 20660, training loss = 2.538211, validation loss = 3.384691
2018-12-04 20:53:55,673 - INFO - epoch 0, step 20670, training loss = 2.825440, validation loss = 3.829991
2018-12-04 20:53:59,350 - INFO - epoch 0, step 20680, training loss = 3.019578, validation loss = 3.823075
2018-12-04 20:54:03,097 - INFO - epoch 0, step 20690, training loss = 2.874443, validation loss = 3.890179
2018-12-04 20:54:06,866 - INFO - epoch 0, step 20700, training loss = 2.467283, validation loss = 3.353715
2018-12-04 20:54:10,506 - INFO - epoch 0, step 20710, training loss = 2.557986, validation loss = 4.178715
2018-12-04 20:54:14,397 - INFO - epoch 0, step 20720, training loss = 2.183155, validation loss = 3.681102
2018-12-04 20:54:18,933 - INFO - epoch 0, step 20730, training loss = 2.426266, validation loss = 3.413136
2018-12-04 20:54:23,654 - INFO - epoch 0, step 20740, training loss = 2.314340, validation loss = 3.848778
2018-12-04 20:54:28,225 - INFO - epoch 0, step 20750, training loss = 1.826797, validation loss = 3.983576
2018-12-04 20:54:32,449 - INFO - epoch 0, step 20760, training loss = 2.427334, validation loss = 3.427351
2018-12-04 20:54:36,843 - INFO - epoch 0, step 20770, training loss = 2.488040, validation loss = 3.690548
2018-12-04 20:54:41,544 - INFO - epoch 0, step 20780, training loss = 2.646648, validation loss = 4.025863
2018-12-04 20:54:46,408 - INFO - epoch 0, step 20790, training loss = 2.746929, validation loss = 3.689714
2018-12-04 20:54:49,558 - INFO - epoch 0, step 20800, training loss = 2.914156, validation loss = 3.524518
2018-12-04 20:54:52,736 - INFO - epoch 0, step 20810, training loss = 2.084998, validation loss = 3.437231
2018-12-04 20:54:56,198 - INFO - epoch 0, step 20820, training loss = 2.879495, validation loss = 3.747908
2018-12-04 20:54:59,525 - INFO - epoch 0, step 20830, training loss = 2.299415, validation loss = 3.781374
2018-12-04 20:55:02,742 - INFO - epoch 0, step 20840, training loss = 2.538586, validation loss = 3.859916
2018-12-04 20:55:05,988 - INFO - epoch 0, step 20850, training loss = 2.042608, validation loss = 3.548533
2018-12-04 20:55:09,218 - INFO - epoch 0, step 20860, training loss = 2.567852, validation loss = 3.883383
2018-12-04 20:55:12,609 - INFO - epoch 0, step 20870, training loss = 2.910287, validation loss = 3.344416
2018-12-04 20:55:15,760 - INFO - epoch 0, step 20880, training loss = 2.948608, validation loss = 3.579182
2018-12-04 20:55:19,022 - INFO - epoch 0, step 20890, training loss = 2.777755, validation loss = 3.957176
2018-12-04 20:55:22,363 - INFO - epoch 0, step 20900, training loss = 2.773973, validation loss = 3.335022
2018-12-04 20:55:25,705 - INFO - epoch 0, step 20910, training loss = 2.124063, validation loss = 3.705559
2018-12-04 20:55:29,030 - INFO - epoch 0, step 20920, training loss = 2.852859, validation loss = 4.212086
2018-12-04 20:55:32,219 - INFO - epoch 0, step 20930, training loss = 2.945746, validation loss = 3.446002
2018-12-04 20:55:35,467 - INFO - epoch 0, step 20940, training loss = 2.285782, validation loss = 3.873762
2018-12-04 20:55:38,801 - INFO - epoch 0, step 20950, training loss = 2.507900, validation loss = 3.798028
2018-12-04 20:55:44,529 - INFO - epoch 0, step 20960, training loss = 2.427033, validation loss = 3.718640
2018-12-04 20:55:50,999 - INFO - epoch 0, step 20970, training loss = 2.077002, validation loss = 4.032800
2018-12-04 20:55:56,834 - INFO - epoch 0, step 20980, training loss = 2.510892, validation loss = 3.683973
2018-12-04 20:56:02,660 - INFO - epoch 0, step 20990, training loss = 2.435400, validation loss = 3.191841
2018-12-04 20:56:08,390 - INFO - epoch 0, step 21000, training loss = 2.350170, validation loss = 4.345963
2018-12-04 20:56:14,513 - INFO - epoch 0, step 21010, training loss = 2.536474, validation loss = 3.761153
2018-12-04 20:56:20,726 - INFO - epoch 0, step 21020, training loss = 2.566686, validation loss = 4.127518
2018-12-04 20:56:26,340 - INFO - epoch 0, step 21030, training loss = 2.320454, validation loss = 4.043837
2018-12-04 20:56:33,040 - INFO - epoch 0, step 21040, training loss = 1.950995, validation loss = 3.808579
2018-12-04 20:56:38,569 - INFO - epoch 0, step 21050, training loss = 1.999218, validation loss = 3.588153
2018-12-04 20:56:43,929 - INFO - epoch 0, step 21060, training loss = 2.494921, validation loss = 3.784700
2018-12-04 20:56:49,504 - INFO - epoch 0, step 21070, training loss = 2.518240, validation loss = 3.989604
2018-12-04 20:56:54,758 - INFO - epoch 0, step 21080, training loss = 2.234411, validation loss = 4.049634
2018-12-04 20:56:59,828 - INFO - epoch 0, step 21090, training loss = 2.460173, validation loss = 4.127949
2018-12-04 20:57:04,816 - INFO - epoch 0, step 21100, training loss = 2.763673, validation loss = 3.664020
2018-12-04 20:57:10,087 - INFO - epoch 0, step 21110, training loss = 2.224092, validation loss = 3.952876
2018-12-04 20:57:15,234 - INFO - epoch 0, step 21120, training loss = 2.586657, validation loss = 3.185932
2018-12-04 20:57:20,448 - INFO - epoch 0, step 21130, training loss = 2.548642, validation loss = 3.933868
2018-12-04 20:57:25,507 - INFO - epoch 0, step 21140, training loss = 2.756455, validation loss = 4.057863
2018-12-04 20:57:30,611 - INFO - epoch 0, step 21150, training loss = 2.722085, validation loss = 3.636285
2018-12-04 20:57:35,695 - INFO - epoch 0, step 21160, training loss = 2.559183, validation loss = 3.787452
2018-12-04 20:57:40,872 - INFO - epoch 0, step 21170, training loss = 2.653495, validation loss = 3.656501
2018-12-04 20:57:45,889 - INFO - epoch 0, step 21180, training loss = 2.385581, validation loss = 3.586641
2018-12-04 20:57:51,105 - INFO - epoch 0, step 21190, training loss = 2.624782, validation loss = 3.941166
2018-12-04 20:57:56,299 - INFO - epoch 0, step 21200, training loss = 2.871936, validation loss = 3.337085
2018-12-04 20:58:01,478 - INFO - epoch 0, step 21210, training loss = 2.571225, validation loss = 3.848546
2018-12-04 20:58:06,640 - INFO - epoch 0, step 21220, training loss = 2.597558, validation loss = 4.003170
2018-12-04 20:58:12,076 - INFO - epoch 0, step 21230, training loss = 2.750297, validation loss = 3.777568
2018-12-04 20:58:17,245 - INFO - epoch 0, step 21240, training loss = 2.646489, validation loss = 3.589432
2018-12-04 20:58:22,275 - INFO - epoch 0, step 21250, training loss = 2.200313, validation loss = 3.467410
2018-12-04 20:58:27,342 - INFO - epoch 0, step 21260, training loss = 2.877376, validation loss = 4.161583
2018-12-04 20:58:32,438 - INFO - epoch 0, step 21270, training loss = 2.483187, validation loss = 3.215386
2018-12-04 20:58:38,097 - INFO - epoch 0, step 21280, training loss = 2.755058, validation loss = 4.047091
2018-12-04 20:58:43,419 - INFO - epoch 0, step 21290, training loss = 2.360955, validation loss = 3.731833
2018-12-04 20:58:48,609 - INFO - epoch 0, step 21300, training loss = 2.843941, validation loss = 3.529370
2018-12-04 20:58:53,746 - INFO - epoch 0, step 21310, training loss = 2.765981, validation loss = 3.848669
2018-12-04 20:58:58,833 - INFO - epoch 0, step 21320, training loss = 2.618267, validation loss = 3.889134
2018-12-04 20:59:04,190 - INFO - epoch 0, step 21330, training loss = 2.440461, validation loss = 3.613086
2018-12-04 20:59:09,577 - INFO - epoch 0, step 21340, training loss = 2.364051, validation loss = 3.811235
2018-12-04 20:59:14,855 - INFO - epoch 0, step 21350, training loss = 2.481986, validation loss = 3.582371
2018-12-04 20:59:20,247 - INFO - epoch 0, step 21360, training loss = 2.481571, validation loss = 4.018046
2018-12-04 20:59:25,460 - INFO - epoch 0, step 21370, training loss = 2.721661, validation loss = 4.298425
2018-12-04 20:59:31,118 - INFO - epoch 0, step 21380, training loss = 2.214354, validation loss = 4.273754
2018-12-04 20:59:36,577 - INFO - epoch 0, step 21390, training loss = 2.316615, validation loss = 4.306003
2018-12-04 20:59:41,661 - INFO - epoch 0, step 21400, training loss = 2.483761, validation loss = 3.399117
2018-12-04 20:59:46,836 - INFO - epoch 0, step 21410, training loss = 3.104249, validation loss = 4.098281
2018-12-04 20:59:52,080 - INFO - epoch 0, step 21420, training loss = 2.659088, validation loss = 4.047338
2018-12-04 20:59:57,531 - INFO - epoch 0, step 21430, training loss = 2.221367, validation loss = 3.751469
2018-12-04 21:00:03,272 - INFO - epoch 0, step 21440, training loss = 2.719242, validation loss = 3.935545
2018-12-04 21:00:08,577 - INFO - epoch 0, step 21450, training loss = 2.754203, validation loss = 3.406048
2018-12-04 21:00:13,628 - INFO - epoch 0, step 21460, training loss = 2.174444, validation loss = 3.511388
2018-12-04 21:00:18,981 - INFO - epoch 0, step 21470, training loss = 2.963209, validation loss = 3.691571
2018-12-04 21:00:25,013 - INFO - epoch 0, step 21480, training loss = 2.136199, validation loss = 4.155895
2018-12-04 21:00:30,780 - INFO - epoch 0, step 21490, training loss = 2.401706, validation loss = 3.682846
2018-12-04 21:00:35,908 - INFO - epoch 0, step 21500, training loss = 2.631951, validation loss = 4.282819
2018-12-04 21:00:40,005 - INFO - epoch 0, step 21510, training loss = 3.113201, validation loss = 3.238752
2018-12-04 21:00:43,350 - INFO - epoch 0, step 21520, training loss = 2.759095, validation loss = 4.025035
2018-12-04 21:00:46,711 - INFO - epoch 0, step 21530, training loss = 2.425085, validation loss = 4.334202
2018-12-04 21:00:49,990 - INFO - epoch 0, step 21540, training loss = 3.005923, validation loss = 3.779839
2018-12-04 21:00:53,521 - INFO - epoch 0, step 21550, training loss = 2.790363, validation loss = 3.562383
2018-12-04 21:00:56,841 - INFO - epoch 0, step 21560, training loss = 3.146742, validation loss = 4.020947
2018-12-04 21:01:00,134 - INFO - epoch 0, step 21570, training loss = 2.920765, validation loss = 3.553549
2018-12-04 21:01:03,479 - INFO - epoch 0, step 21580, training loss = 2.826143, validation loss = 4.138506
2018-12-04 21:01:06,785 - INFO - epoch 0, step 21590, training loss = 2.768289, validation loss = 4.465744
2018-12-04 21:01:10,138 - INFO - epoch 0, step 21600, training loss = 3.289530, validation loss = 3.494250
2018-12-04 21:01:13,510 - INFO - epoch 0, step 21610, training loss = 2.595019, validation loss = 4.045232
2018-12-04 21:01:16,891 - INFO - epoch 0, step 21620, training loss = 2.873683, validation loss = 3.871686
2018-12-04 21:01:20,107 - INFO - epoch 0, step 21630, training loss = 2.918753, validation loss = 4.156185
2018-12-04 21:01:23,914 - INFO - epoch 0, step 21640, training loss = 2.897657, validation loss = 4.023804
2018-12-04 21:01:28,693 - INFO - epoch 0, step 21650, training loss = 2.609589, validation loss = 3.575478
2018-12-04 21:01:33,845 - INFO - epoch 0, step 21660, training loss = 2.536872, validation loss = 3.734571
2018-12-04 21:01:38,793 - INFO - epoch 0, step 21670, training loss = 2.756870, validation loss = 3.358976
2018-12-04 21:01:43,518 - INFO - epoch 0, step 21680, training loss = 2.360786, validation loss = 4.384036
2018-12-04 21:01:48,259 - INFO - epoch 0, step 21690, training loss = 2.922144, validation loss = 3.573738
2018-12-04 21:01:53,236 - INFO - epoch 0, step 21700, training loss = 2.369956, validation loss = 3.732791
2018-12-04 21:01:58,189 - INFO - epoch 0, step 21710, training loss = 2.766685, validation loss = 3.996814
2018-12-04 21:02:02,955 - INFO - epoch 0, step 21720, training loss = 2.826428, validation loss = 4.025769
2018-12-04 21:02:07,643 - INFO - epoch 0, step 21730, training loss = 3.079605, validation loss = 3.727213
2018-12-04 21:02:12,608 - INFO - epoch 0, step 21740, training loss = 2.931831, validation loss = 3.686984
2018-12-04 21:02:17,326 - INFO - epoch 0, step 21750, training loss = 2.785367, validation loss = 3.793448
2018-12-04 21:02:22,138 - INFO - epoch 0, step 21760, training loss = 3.154412, validation loss = 3.642357
2018-12-04 21:02:27,250 - INFO - epoch 0, step 21770, training loss = 2.170882, validation loss = 4.390212
2018-12-04 21:02:32,040 - INFO - epoch 0, step 21780, training loss = 2.348777, validation loss = 3.950877
2018-12-04 21:02:37,300 - INFO - epoch 0, step 21790, training loss = 2.708342, validation loss = 3.461686
2018-12-04 21:02:42,470 - INFO - epoch 0, step 21800, training loss = 2.938293, validation loss = 3.985274
2018-12-04 21:02:47,498 - INFO - epoch 0, step 21810, training loss = 2.524040, validation loss = 3.666540
2018-12-04 21:02:52,503 - INFO - epoch 0, step 21820, training loss = 2.717028, validation loss = 3.617207
2018-12-04 21:02:57,586 - INFO - epoch 0, step 21830, training loss = 2.495899, validation loss = 3.853451
2018-12-04 21:03:03,072 - INFO - epoch 0, step 21840, training loss = 3.001484, validation loss = 3.800355
2018-12-04 21:03:07,456 - INFO - epoch 0, step 21850, training loss = 2.939884, validation loss = 3.372536
2018-12-04 21:03:12,572 - INFO - epoch 0, step 21860, training loss = 2.804494, validation loss = 3.838682
2018-12-04 21:03:17,558 - INFO - epoch 0, step 21870, training loss = 2.992169, validation loss = 3.688564
2018-12-04 21:03:22,647 - INFO - epoch 0, step 21880, training loss = 2.169313, validation loss = 4.068386
2018-12-04 21:03:25,944 - INFO - epoch 0, step 21890, training loss = 3.055058, validation loss = 3.432597
2018-12-04 21:03:28,496 - INFO - epoch 0, step 21900, training loss = 2.039890, validation loss = 4.349290
2018-12-04 21:03:31,055 - INFO - epoch 0, step 21910, training loss = 3.231856, validation loss = 3.809843
2018-12-04 21:03:33,633 - INFO - epoch 0, step 21920, training loss = 2.345076, validation loss = 4.195210
2018-12-04 21:03:36,227 - INFO - epoch 0, step 21930, training loss = 2.782593, validation loss = 4.251217
2018-12-04 21:03:38,789 - INFO - epoch 0, step 21940, training loss = 2.397847, validation loss = 3.721917
2018-12-04 21:03:41,254 - INFO - epoch 0, step 21950, training loss = 2.576726, validation loss = 4.270585
2018-12-04 21:03:43,745 - INFO - epoch 0, step 21960, training loss = 2.998091, validation loss = 3.921553
2018-12-04 21:03:46,237 - INFO - epoch 0, step 21970, training loss = 2.837945, validation loss = 4.166702
2018-12-04 21:03:48,747 - INFO - epoch 0, step 21980, training loss = 3.229530, validation loss = 4.173956
2018-12-04 21:03:51,272 - INFO - epoch 0, step 21990, training loss = 2.871196, validation loss = 4.387346
2018-12-04 21:03:53,933 - INFO - epoch 0, step 22000, training loss = 2.899319, validation loss = 4.158722
2018-12-04 21:03:56,536 - INFO - epoch 0, step 22010, training loss = 2.243988, validation loss = 4.308712
2018-12-04 21:03:59,139 - INFO - epoch 0, step 22020, training loss = 2.000582, validation loss = 4.003228
2018-12-04 21:04:02,079 - INFO - epoch 0, step 22030, training loss = 2.696889, validation loss = 4.143564
2018-12-04 21:04:04,606 - INFO - epoch 0, step 22040, training loss = 2.961833, validation loss = 3.850960
2018-12-04 21:04:08,045 - INFO - epoch 0, step 22050, training loss = 2.889029, validation loss = 3.983694
2018-12-04 21:04:12,447 - INFO - epoch 0, step 22060, training loss = 2.863885, validation loss = 3.368011
2018-12-04 21:04:17,230 - INFO - epoch 0, step 22070, training loss = 2.681282, validation loss = 4.284328
2018-12-04 21:04:21,915 - INFO - epoch 0, step 22080, training loss = 2.531255, validation loss = 3.583329
2018-12-04 21:04:26,755 - INFO - epoch 0, step 22090, training loss = 1.845610, validation loss = 3.556900
2018-12-04 21:04:31,376 - INFO - epoch 0, step 22100, training loss = 2.440381, validation loss = 3.749853
2018-12-04 21:04:36,045 - INFO - epoch 0, step 22110, training loss = 2.614991, validation loss = 3.634629
2018-12-04 21:04:40,410 - INFO - epoch 0, step 22120, training loss = 2.252524, validation loss = 3.267674
2018-12-04 21:04:44,963 - INFO - epoch 0, step 22130, training loss = 2.272852, validation loss = 3.153132
2018-12-04 21:04:49,690 - INFO - epoch 0, step 22140, training loss = 2.613439, validation loss = 3.601499
2018-12-04 21:04:54,180 - INFO - epoch 0, step 22150, training loss = 2.446124, validation loss = 3.673056
2018-12-04 21:04:59,090 - INFO - epoch 0, step 22160, training loss = 1.864600, validation loss = 3.565087
2018-12-04 21:05:03,608 - INFO - epoch 0, step 22170, training loss = 2.155132, validation loss = 3.068506
2018-12-04 21:05:08,095 - INFO - epoch 0, step 22180, training loss = 2.790477, validation loss = 2.974886
2018-12-04 21:05:12,470 - INFO - epoch 0, step 22190, training loss = 3.373729, validation loss = 3.365720
2018-12-04 21:05:16,812 - INFO - epoch 0, step 22200, training loss = 2.580743, validation loss = 3.398418
2018-12-04 21:05:21,220 - INFO - epoch 0, step 22210, training loss = 2.632002, validation loss = 2.555618
2018-12-04 21:05:26,079 - INFO - epoch 0, step 22220, training loss = 2.169554, validation loss = 3.746063
2018-12-04 21:05:32,028 - INFO - epoch 0, step 22230, training loss = 1.969683, validation loss = 3.161319
2018-12-04 21:05:38,116 - INFO - epoch 0, step 22240, training loss = 2.536227, validation loss = 3.031180
2018-12-04 21:05:44,157 - INFO - epoch 0, step 22250, training loss = 2.607536, validation loss = 3.580118
2018-12-04 21:05:49,894 - INFO - epoch 0, step 22260, training loss = 2.270692, validation loss = 2.294420
2018-12-04 21:05:55,585 - INFO - epoch 0, step 22270, training loss = 2.501342, validation loss = 3.100416
2018-12-04 21:06:01,785 - INFO - epoch 0, step 22280, training loss = 2.649246, validation loss = 2.987744
2018-12-04 21:06:08,871 - INFO - epoch 0, step 22290, training loss = 1.724783, validation loss = 3.255127
2018-12-04 21:06:15,096 - INFO - epoch 0, step 22300, training loss = 1.993091, validation loss = 3.147903
2018-12-04 21:06:21,365 - INFO - epoch 0, step 22310, training loss = 1.886678, validation loss = 3.176051
2018-12-04 21:06:27,427 - INFO - epoch 0, step 22320, training loss = 2.449084, validation loss = 2.885745
2018-12-04 21:06:33,497 - INFO - epoch 0, step 22330, training loss = 1.954658, validation loss = 2.784171
2018-12-04 21:06:39,899 - INFO - epoch 0, step 22340, training loss = 2.527269, validation loss = 2.571380
2018-12-04 21:06:46,053 - INFO - epoch 0, step 22350, training loss = 2.084493, validation loss = 2.560788
2018-12-04 21:06:52,263 - INFO - epoch 0, step 22360, training loss = 2.428269, validation loss = 3.192681
2018-12-04 21:06:58,413 - INFO - epoch 0, step 22370, training loss = 2.066687, validation loss = 3.207875
2018-12-04 21:07:04,163 - INFO - epoch 0, step 22380, training loss = 2.342347, validation loss = 2.398211
2018-12-04 21:07:09,548 - INFO - epoch 0, step 22390, training loss = 2.159818, validation loss = 3.512236
2018-12-04 21:07:15,304 - INFO - epoch 0, step 22400, training loss = 2.669463, validation loss = 3.215352
2018-12-04 21:07:21,553 - INFO - epoch 0, step 22410, training loss = 2.755897, validation loss = 2.670131
2018-12-04 21:07:27,253 - INFO - epoch 0, step 22420, training loss = 2.216105, validation loss = 3.485010
2018-12-04 21:07:33,328 - INFO - epoch 0, step 22430, training loss = 2.554229, validation loss = 3.437774
2018-12-04 21:07:39,349 - INFO - epoch 0, step 22440, training loss = 1.893084, validation loss = 3.479040
2018-12-04 21:07:45,307 - INFO - epoch 0, step 22450, training loss = 2.401414, validation loss = 3.019214
2018-12-04 21:07:50,775 - INFO - epoch 0, step 22460, training loss = 2.849241, validation loss = 2.925740
2018-12-04 21:07:56,565 - INFO - epoch 0, step 22470, training loss = 2.444424, validation loss = 3.522053
2018-12-04 21:08:02,167 - INFO - epoch 0, step 22480, training loss = 2.570895, validation loss = 2.692775
2018-12-04 21:08:07,752 - INFO - epoch 0, step 22490, training loss = 2.484045, validation loss = 3.332683
2018-12-04 21:08:13,297 - INFO - epoch 0, step 22500, training loss = 2.732619, validation loss = 2.624370
2018-12-04 21:08:18,802 - INFO - epoch 0, step 22510, training loss = 2.603021, validation loss = 3.109610
2018-12-04 21:08:25,121 - INFO - epoch 0, step 22520, training loss = 2.489794, validation loss = 3.020615
2018-12-04 21:08:30,940 - INFO - epoch 0, step 22530, training loss = 2.332925, validation loss = 2.588611
2018-12-04 21:08:37,173 - INFO - epoch 0, step 22540, training loss = 2.526436, validation loss = 2.796328
2018-12-04 21:08:43,059 - INFO - epoch 0, step 22550, training loss = 2.349964, validation loss = 3.250857
2018-12-04 21:08:49,197 - INFO - epoch 0, step 22560, training loss = 2.003739, validation loss = 3.663165
2018-12-04 21:08:55,079 - INFO - epoch 0, step 22570, training loss = 2.134284, validation loss = 3.498263
2018-12-04 21:09:01,438 - INFO - epoch 0, step 22580, training loss = 2.200412, validation loss = 3.452583
2018-12-04 21:09:07,096 - INFO - epoch 0, step 22590, training loss = 2.670625, validation loss = 3.906784
2018-12-04 21:09:12,698 - INFO - epoch 0, step 22600, training loss = 2.026875, validation loss = 3.636388
2018-12-04 21:09:17,865 - INFO - epoch 0, step 22610, training loss = 2.707404, validation loss = 3.824696
2018-12-04 21:09:22,759 - INFO - epoch 0, step 22620, training loss = 2.808116, validation loss = 4.040481
2018-12-04 21:09:27,318 - INFO - epoch 0, step 22630, training loss = 2.818057, validation loss = 3.436940
2018-12-04 21:09:31,514 - INFO - epoch 0, step 22640, training loss = 2.593708, validation loss = 4.181211
2018-12-04 21:09:35,737 - INFO - epoch 0, step 22650, training loss = 2.513792, validation loss = 3.974579
2018-12-04 21:09:40,171 - INFO - epoch 0, step 22660, training loss = 2.732340, validation loss = 3.600846
2018-12-04 21:09:44,496 - INFO - epoch 0, step 22670, training loss = 2.692598, validation loss = 3.652565
2018-12-04 21:09:48,591 - INFO - epoch 0, step 22680, training loss = 3.009998, validation loss = 3.506658
2018-12-04 21:09:52,210 - INFO - epoch 0, step 22690, training loss = 2.816314, validation loss = 4.233661
2018-12-04 21:09:55,852 - INFO - epoch 0, step 22700, training loss = 2.490916, validation loss = 3.513059
2018-12-04 21:09:59,388 - INFO - epoch 0, step 22710, training loss = 2.690036, validation loss = 4.276754
2018-12-04 21:10:02,990 - INFO - epoch 0, step 22720, training loss = 2.887237, validation loss = 3.676730
2018-12-04 21:10:06,579 - INFO - epoch 0, step 22730, training loss = 2.758487, validation loss = 3.852051
2018-12-04 21:10:10,236 - INFO - epoch 0, step 22740, training loss = 2.534900, validation loss = 4.504134
2018-12-04 21:10:13,989 - INFO - epoch 0, step 22750, training loss = 2.693978, validation loss = 3.467214
2018-12-04 21:10:17,771 - INFO - epoch 0, step 22760, training loss = 2.719594, validation loss = 3.612761
2018-12-04 21:10:21,473 - INFO - epoch 0, step 22770, training loss = 2.607987, validation loss = 4.195278
2018-12-04 21:10:25,094 - INFO - epoch 0, step 22780, training loss = 2.247650, validation loss = 3.431337
2018-12-04 21:10:29,151 - INFO - epoch 0, step 22790, training loss = 2.317759, validation loss = 3.304673
2018-12-04 21:10:32,619 - INFO - epoch 0, step 22800, training loss = 2.235460, validation loss = 3.477033
2018-12-04 21:10:35,972 - INFO - epoch 0, step 22810, training loss = 2.558938, validation loss = 4.047187
2018-12-04 21:10:40,138 - INFO - epoch 0, step 22820, training loss = 1.923354, validation loss = 3.675466
2018-12-04 21:10:43,530 - INFO - epoch 0, step 22830, training loss = 2.680997, validation loss = 3.519795
2018-12-04 21:10:47,005 - INFO - epoch 0, step 22840, training loss = 2.561626, validation loss = 4.123476
2018-12-04 21:10:50,411 - INFO - epoch 0, step 22850, training loss = 2.068672, validation loss = 3.247890
2018-12-04 21:10:53,958 - INFO - epoch 0, step 22860, training loss = 2.533510, validation loss = 3.448901
2018-12-04 21:10:57,360 - INFO - epoch 0, step 22870, training loss = 2.164636, validation loss = 4.126181
2018-12-04 21:11:00,758 - INFO - epoch 0, step 22880, training loss = 2.898700, validation loss = 3.817182
2018-12-04 21:11:04,069 - INFO - epoch 0, step 22890, training loss = 2.519125, validation loss = 3.526366
2018-12-04 21:11:07,556 - INFO - epoch 0, step 22900, training loss = 2.674289, validation loss = 3.206758
2018-12-04 21:11:10,813 - INFO - epoch 0, step 22910, training loss = 2.535575, validation loss = 3.955121
2018-12-04 21:11:14,168 - INFO - epoch 0, step 22920, training loss = 2.600994, validation loss = 3.600459
2018-12-04 21:11:17,437 - INFO - epoch 0, step 22930, training loss = 2.085134, validation loss = 3.750384
2018-12-04 21:11:20,688 - INFO - epoch 0, step 22940, training loss = 2.353511, validation loss = 3.840977
2018-12-04 21:11:23,985 - INFO - epoch 0, step 22950, training loss = 2.559842, validation loss = 4.047330
2018-12-04 21:11:27,311 - INFO - epoch 0, step 22960, training loss = 3.016679, validation loss = 3.882473
2018-12-04 21:11:30,549 - INFO - epoch 0, step 22970, training loss = 3.181562, validation loss = 3.681353
2018-12-04 21:11:34,011 - INFO - epoch 0, step 22980, training loss = 2.690364, validation loss = 3.493221
2018-12-04 21:11:37,144 - INFO - epoch 0, step 22990, training loss = 2.566888, validation loss = 4.127627
2018-12-04 21:11:40,487 - INFO - epoch 0, step 23000, training loss = 2.792888, validation loss = 3.781998
2018-12-04 21:11:44,795 - INFO - epoch 0, step 23010, training loss = 2.577021, validation loss = 3.433578
2018-12-04 21:11:49,206 - INFO - epoch 0, step 23020, training loss = 2.898445, validation loss = 3.503129
2018-12-04 21:11:53,607 - INFO - epoch 0, step 23030, training loss = 2.700937, validation loss = 3.459525
2018-12-04 21:11:58,047 - INFO - epoch 0, step 23040, training loss = 2.998500, validation loss = 4.046280
2018-12-04 21:12:02,951 - INFO - epoch 0, step 23050, training loss = 2.388790, validation loss = 3.348009
2018-12-04 21:12:07,332 - INFO - epoch 0, step 23060, training loss = 2.353616, validation loss = 3.766455
2018-12-04 21:12:11,918 - INFO - epoch 0, step 23070, training loss = 1.714533, validation loss = 3.846209
2018-12-04 21:12:16,221 - INFO - epoch 0, step 23080, training loss = 2.482296, validation loss = 3.712359
2018-12-04 21:12:20,528 - INFO - epoch 0, step 23090, training loss = 2.798721, validation loss = 2.875216
2018-12-04 21:12:24,660 - INFO - epoch 0, step 23100, training loss = 2.702108, validation loss = 3.825012
2018-12-04 21:12:28,888 - INFO - epoch 0, step 23110, training loss = 2.904732, validation loss = 3.728583
2018-12-04 21:12:33,023 - INFO - epoch 0, step 23120, training loss = 2.349953, validation loss = 3.145959
2018-12-04 21:12:36,603 - INFO - epoch 0, step 23130, training loss = 2.929835, validation loss = 3.794279
2018-12-04 21:12:39,016 - INFO - epoch 0, step 23140, training loss = 3.091314, validation loss = 3.256701
2018-12-04 21:12:41,443 - INFO - epoch 0, step 23150, training loss = 2.425634, validation loss = 3.827072
2018-12-04 21:12:43,915 - INFO - epoch 0, step 23160, training loss = 2.434718, validation loss = 2.858129
2018-12-04 21:12:46,291 - INFO - epoch 0, step 23170, training loss = 2.586426, validation loss = 2.626439
2018-12-04 21:12:48,684 - INFO - epoch 0, step 23180, training loss = 2.190821, validation loss = 2.970603
2018-12-04 21:12:50,992 - INFO - epoch 0, step 23190, training loss = 3.191117, validation loss = 2.786956
2018-12-04 21:12:53,411 - INFO - epoch 0, step 23200, training loss = 2.469806, validation loss = 2.978018
2018-12-04 21:12:55,799 - INFO - epoch 0, step 23210, training loss = 2.571480, validation loss = 2.996822
2018-12-04 21:12:58,209 - INFO - epoch 0, step 23220, training loss = 2.425870, validation loss = 2.878310
2018-12-04 21:13:00,566 - INFO - epoch 0, step 23230, training loss = 2.569807, validation loss = 2.794861
2018-12-04 21:13:03,000 - INFO - epoch 0, step 23240, training loss = 2.638393, validation loss = 2.177904
2018-12-04 21:13:05,473 - INFO - epoch 0, step 23250, training loss = 2.693282, validation loss = 2.094353
2018-12-04 21:13:07,840 - INFO - epoch 0, step 23260, training loss = 2.327506, validation loss = 2.789200
2018-12-04 21:13:10,228 - INFO - epoch 0, step 23270, training loss = 2.883825, validation loss = 2.625911
2018-12-04 21:13:12,586 - INFO - epoch 0, step 23280, training loss = 2.898586, validation loss = 3.316958
2018-12-04 21:13:15,708 - INFO - epoch 0, step 23290, training loss = 2.897287, validation loss = 2.511677
2018-12-04 21:13:19,051 - INFO - epoch 0, step 23300, training loss = 2.714576, validation loss = 2.795740
2018-12-04 21:13:22,536 - INFO - epoch 0, step 23310, training loss = 2.635672, validation loss = 2.629523
2018-12-04 21:13:25,797 - INFO - epoch 0, step 23320, training loss = 2.638266, validation loss = 2.738915
2018-12-04 21:13:29,027 - INFO - epoch 0, step 23330, training loss = 2.943674, validation loss = 2.735917
2018-12-04 21:13:32,322 - INFO - epoch 0, step 23340, training loss = 2.532680, validation loss = 2.608471
2018-12-04 21:13:35,645 - INFO - epoch 0, step 23350, training loss = 2.382881, validation loss = 1.964836
2018-12-04 21:13:38,743 - INFO - epoch 0, step 23360, training loss = 3.363360, validation loss = 2.641435
2018-12-04 21:13:42,129 - INFO - epoch 0, step 23370, training loss = 2.416018, validation loss = 2.156901
2018-12-04 21:13:45,372 - INFO - epoch 0, step 23380, training loss = 2.572214, validation loss = 3.102690
2018-12-04 21:13:48,443 - INFO - epoch 0, step 23390, training loss = 2.716200, validation loss = 2.786660
2018-12-04 21:13:51,530 - INFO - epoch 0, step 23400, training loss = 2.509495, validation loss = 2.976072
2018-12-04 21:13:54,903 - INFO - epoch 0, step 23410, training loss = 2.612894, validation loss = 3.072302
2018-12-04 21:13:58,279 - INFO - epoch 0, step 23420, training loss = 2.701656, validation loss = 3.110056
2018-12-04 21:14:01,790 - INFO - epoch 0, step 23430, training loss = 2.347515, validation loss = 2.598621
2018-12-04 21:14:05,528 - INFO - epoch 0, step 23440, training loss = 2.403121, validation loss = 3.206643
2018-12-04 21:14:09,094 - INFO - epoch 0, step 23450, training loss = 2.293569, validation loss = 3.010505
2018-12-04 21:14:12,673 - INFO - epoch 0, step 23460, training loss = 2.200197, validation loss = 2.898241
2018-12-04 21:14:17,356 - INFO - epoch 0, step 23470, training loss = 2.629439, validation loss = 2.896156
2018-12-04 21:14:23,730 - INFO - epoch 0, step 23480, training loss = 2.500340, validation loss = 2.600048
2018-12-04 21:14:29,110 - INFO - epoch 0, step 23490, training loss = 2.664089, validation loss = 2.941072
2018-12-04 21:14:34,542 - INFO - epoch 0, step 23500, training loss = 2.123534, validation loss = 2.937560
2018-12-04 21:14:40,171 - INFO - epoch 0, step 23510, training loss = 3.098680, validation loss = 2.592497
2018-12-04 21:14:44,758 - INFO - epoch 0, step 23520, training loss = 2.382028, validation loss = 2.875321
2018-12-04 21:14:49,027 - INFO - epoch 0, step 23530, training loss = 2.449611, validation loss = 2.625124
2018-12-04 21:14:53,594 - INFO - epoch 0, step 23540, training loss = 2.489543, validation loss = 2.718591
2018-12-04 21:14:58,308 - INFO - epoch 0, step 23550, training loss = 2.678288, validation loss = 2.777670
2018-12-04 21:15:02,476 - INFO - epoch 0, step 23560, training loss = 2.625354, validation loss = 2.739431
2018-12-04 21:15:06,848 - INFO - epoch 0, step 23570, training loss = 2.547020, validation loss = 2.768179
2018-12-04 21:15:11,015 - INFO - epoch 0, step 23580, training loss = 2.446655, validation loss = 2.798444
2018-12-04 21:15:15,419 - INFO - epoch 0, step 23590, training loss = 2.176999, validation loss = 3.005503
2018-12-04 21:15:19,689 - INFO - epoch 0, step 23600, training loss = 2.571903, validation loss = 2.824681
2018-12-04 21:15:23,660 - INFO - epoch 0, step 23610, training loss = 2.513753, validation loss = 2.545885
2018-12-04 21:15:27,784 - INFO - epoch 0, step 23620, training loss = 2.263512, validation loss = 3.033875
2018-12-04 21:15:31,953 - INFO - epoch 0, step 23630, training loss = 2.756009, validation loss = 2.686328
2018-12-04 21:15:36,564 - INFO - epoch 0, step 23640, training loss = 2.380474, validation loss = 2.870881
2018-12-04 21:15:40,622 - INFO - epoch 0, step 23650, training loss = 2.237228, validation loss = 2.876349
2018-12-04 21:15:45,043 - INFO - epoch 0, step 23660, training loss = 2.615130, validation loss = 2.573687
2018-12-04 21:15:49,479 - INFO - epoch 0, step 23670, training loss = 2.484778, validation loss = 2.767186
2018-12-04 21:15:53,545 - INFO - epoch 0, step 23680, training loss = 2.496633, validation loss = 2.678211
2018-12-04 21:15:57,644 - INFO - epoch 0, step 23690, training loss = 2.780875, validation loss = 2.215500
2018-12-04 21:16:02,127 - INFO - epoch 0, step 23700, training loss = 2.174533, validation loss = 2.679180
2018-12-04 21:16:06,934 - INFO - epoch 0, step 23710, training loss = 2.658599, validation loss = 2.857759
2018-12-04 21:16:11,881 - INFO - epoch 0, step 23720, training loss = 2.343575, validation loss = 3.029375
2018-12-04 21:16:16,541 - INFO - epoch 0, step 23730, training loss = 2.891827, validation loss = 2.673682
2018-12-04 21:16:21,299 - INFO - epoch 0, step 23740, training loss = 2.752320, validation loss = 2.503435
2018-12-04 21:16:26,282 - INFO - epoch 0, step 23750, training loss = 2.772053, validation loss = 2.578186
2018-12-04 21:16:31,311 - INFO - epoch 0, step 23760, training loss = 2.608916, validation loss = 1.971511
2018-12-04 21:16:36,197 - INFO - epoch 0, step 23770, training loss = 2.511289, validation loss = 1.822905
2018-12-04 21:16:40,904 - INFO - epoch 0, step 23780, training loss = 2.710984, validation loss = 2.766241
2018-12-04 21:16:45,587 - INFO - epoch 0, step 23790, training loss = 2.171776, validation loss = 2.893815
2018-12-04 21:16:50,792 - INFO - epoch 0, step 23800, training loss = 3.088984, validation loss = 2.700827
2018-12-04 21:16:55,760 - INFO - epoch 0, step 23810, training loss = 2.858004, validation loss = 2.549017
2018-12-04 21:17:01,092 - INFO - epoch 0, step 23820, training loss = 2.766620, validation loss = 2.687902
2018-12-04 21:17:06,173 - INFO - epoch 0, step 23830, training loss = 2.652204, validation loss = 2.949138
2018-12-04 21:17:11,197 - INFO - epoch 0, step 23840, training loss = 3.009304, validation loss = 2.577367
2018-12-04 21:17:16,180 - INFO - epoch 0, step 23850, training loss = 2.838935, validation loss = 2.423787
2018-12-04 21:17:21,109 - INFO - epoch 0, step 23860, training loss = 2.315703, validation loss = 2.897549
2018-12-04 21:17:26,108 - INFO - epoch 0, step 23870, training loss = 2.610999, validation loss = 2.711177
2018-12-04 21:17:31,228 - INFO - epoch 0, step 23880, training loss = 2.427344, validation loss = 2.296224
2018-12-04 21:17:36,275 - INFO - epoch 0, step 23890, training loss = 2.520549, validation loss = 2.686383
2018-12-04 21:17:41,996 - INFO - epoch 0, step 23900, training loss = 2.786568, validation loss = 2.309740
2018-12-04 21:17:46,951 - INFO - epoch 0, step 23910, training loss = 2.769435, validation loss = 2.056377
2018-12-04 21:17:52,078 - INFO - epoch 0, step 23920, training loss = 2.382686, validation loss = 2.454389
2018-12-04 21:17:57,023 - INFO - epoch 0, step 23930, training loss = 2.651125, validation loss = 2.545791
2018-12-04 21:18:02,019 - INFO - epoch 0, step 23940, training loss = 2.954056, validation loss = 2.371715
2018-12-04 21:18:07,144 - INFO - epoch 0, step 23950, training loss = 2.524276, validation loss = 2.636324
2018-12-04 21:18:11,849 - INFO - epoch 0, step 23960, training loss = 2.391160, validation loss = 2.345686
2018-12-04 21:18:16,647 - INFO - epoch 0, step 23970, training loss = 2.187591, validation loss = 1.859315
2018-12-04 21:18:21,511 - INFO - epoch 0, step 23980, training loss = 2.227887, validation loss = 2.444619
2018-12-04 21:18:26,300 - INFO - epoch 0, step 23990, training loss = 3.077480, validation loss = 2.177008
2018-12-04 21:18:30,982 - INFO - epoch 0, step 24000, training loss = 2.405366, validation loss = 2.558561
2018-12-04 21:18:35,748 - INFO - epoch 0, step 24010, training loss = 2.340181, validation loss = 2.508759
2018-12-04 21:18:40,804 - INFO - epoch 0, step 24020, training loss = 2.004767, validation loss = 2.236178
2018-12-04 21:18:46,861 - INFO - epoch 0, step 24030, training loss = 1.895294, validation loss = 2.241254
2018-12-04 21:18:52,582 - INFO - epoch 0, step 24040, training loss = 2.121128, validation loss = 2.336047
2018-12-04 21:18:58,291 - INFO - epoch 0, step 24050, training loss = 1.752073, validation loss = 2.763131
2018-12-04 21:19:04,332 - INFO - epoch 0, step 24060, training loss = 1.904287, validation loss = 2.346759
2018-12-04 21:19:10,550 - INFO - epoch 0, step 24070, training loss = 1.929801, validation loss = 2.140163
2018-12-04 21:19:16,827 - INFO - epoch 0, step 24080, training loss = 2.206724, validation loss = 2.515756
2018-12-04 21:19:22,509 - INFO - epoch 0, step 24090, training loss = 2.453158, validation loss = 2.830329
2018-12-04 21:19:29,276 - INFO - epoch 0, step 24100, training loss = 2.410391, validation loss = 2.128930
2018-12-04 21:19:35,314 - INFO - epoch 0, step 24110, training loss = 2.313161, validation loss = 2.189301
2018-12-04 21:19:41,103 - INFO - epoch 0, step 24120, training loss = 1.968127, validation loss = 2.655542
2018-12-04 21:19:46,937 - INFO - epoch 0, step 24130, training loss = 2.254182, validation loss = 2.539286
2018-12-04 21:19:53,409 - INFO - epoch 0, step 24140, training loss = 1.826458, validation loss = 2.443773
2018-12-04 21:19:59,279 - INFO - epoch 0, step 24150, training loss = 2.071218, validation loss = 2.328521
2018-12-04 21:20:04,931 - INFO - epoch 0, step 24160, training loss = 2.685288, validation loss = 2.269038
2018-12-04 21:20:11,012 - INFO - epoch 0, step 24170, training loss = 2.045171, validation loss = 2.110049
2018-12-04 21:20:16,693 - INFO - epoch 0, step 24180, training loss = 2.100218, validation loss = 2.766234
2018-12-04 21:20:22,689 - INFO - epoch 0, step 24190, training loss = 2.239125, validation loss = 2.264482
2018-12-04 21:20:28,317 - INFO - epoch 0, step 24200, training loss = 1.993230, validation loss = 2.541994
2018-12-04 21:20:33,814 - INFO - epoch 0, step 24210, training loss = 2.208680, validation loss = 2.471063
2018-12-04 21:20:40,587 - INFO - epoch 0, step 24220, training loss = 1.637257, validation loss = 2.350942
2018-12-04 21:20:46,684 - INFO - epoch 0, step 24230, training loss = 2.265709, validation loss = 2.787855
2018-12-04 21:20:51,598 - INFO - epoch 0, step 24240, training loss = 3.357207, validation loss = 2.548471
2018-12-04 21:20:54,847 - INFO - epoch 0, step 24250, training loss = 2.523793, validation loss = 2.558978
2018-12-04 21:20:58,080 - INFO - epoch 0, step 24260, training loss = 2.660228, validation loss = 2.652858
2018-12-04 21:21:01,272 - INFO - epoch 0, step 24270, training loss = 3.032787, validation loss = 2.465398
2018-12-04 21:21:04,828 - INFO - epoch 0, step 24280, training loss = 2.170146, validation loss = 2.237859
2018-12-04 21:21:08,053 - INFO - epoch 0, step 24290, training loss = 2.037853, validation loss = 2.766375
2018-12-04 21:21:11,315 - INFO - epoch 0, step 24300, training loss = 2.658073, validation loss = 2.315933
2018-12-04 21:21:14,555 - INFO - epoch 0, step 24310, training loss = 2.312103, validation loss = 2.682939
2018-12-04 21:21:17,756 - INFO - epoch 0, step 24320, training loss = 2.808041, validation loss = 2.791043
2018-12-04 21:21:21,206 - INFO - epoch 0, step 24330, training loss = 3.183654, validation loss = 2.423533
2018-12-04 21:21:24,416 - INFO - epoch 0, step 24340, training loss = 2.921656, validation loss = 2.129277
2018-12-04 21:21:27,626 - INFO - epoch 0, step 24350, training loss = 2.370487, validation loss = 2.222100
2018-12-04 21:21:30,860 - INFO - epoch 0, step 24360, training loss = 2.375962, validation loss = 2.724022
2018-12-04 21:21:34,332 - INFO - epoch 0, step 24370, training loss = 2.541170, validation loss = 2.032690
2018-12-04 21:21:37,498 - INFO - epoch 0, step 24380, training loss = 2.668612, validation loss = 2.569011
2018-12-04 21:21:40,650 - INFO - epoch 0, step 24390, training loss = 2.872465, validation loss = 2.791730
2018-12-04 21:21:44,116 - INFO - epoch 0, step 24400, training loss = 2.385608, validation loss = 2.306736
2018-12-04 21:21:47,361 - INFO - epoch 0, step 24410, training loss = 2.740053, validation loss = 2.438050
2018-12-04 21:21:50,833 - INFO - epoch 0, step 24420, training loss = 2.680575, validation loss = 2.598717
2018-12-04 21:21:53,935 - INFO - epoch 0, step 24430, training loss = 2.496107, validation loss = 2.382476
2018-12-04 21:21:57,235 - INFO - epoch 0, step 24440, training loss = 2.651608, validation loss = 2.374025
2018-12-04 21:22:00,481 - INFO - epoch 0, step 24450, training loss = 2.962705, validation loss = 2.277634
2018-12-04 21:22:03,515 - INFO - epoch 0, step 24460, training loss = 3.373095, validation loss = 2.620340
2018-12-04 21:22:06,787 - INFO - epoch 0, step 24470, training loss = 2.788440, validation loss = 2.480172
2018-12-04 21:22:09,830 - INFO - epoch 0, step 24480, training loss = 2.471489, validation loss = 2.800259
2018-12-04 21:22:13,361 - INFO - epoch 0, step 24490, training loss = 2.951423, validation loss = 2.563043
2018-12-04 21:22:16,743 - INFO - epoch 0, step 24500, training loss = 2.515951, validation loss = 2.812904
2018-12-04 21:22:19,972 - INFO - epoch 0, step 24510, training loss = 2.728983, validation loss = 2.279144
2018-12-04 21:22:23,185 - INFO - epoch 0, step 24520, training loss = 2.969616, validation loss = 2.805138
2018-12-04 21:22:26,377 - INFO - epoch 0, step 24530, training loss = 2.994138, validation loss = 2.446167
2018-12-04 21:22:29,648 - INFO - epoch 0, step 24540, training loss = 2.295973, validation loss = 2.086457
2018-12-04 21:22:32,899 - INFO - epoch 0, step 24550, training loss = 2.522764, validation loss = 2.737562
2018-12-04 21:22:36,313 - INFO - epoch 0, step 24560, training loss = 2.389513, validation loss = 2.546345
2018-12-04 21:22:39,490 - INFO - epoch 0, step 24570, training loss = 2.770188, validation loss = 3.147368
2018-12-04 21:22:42,991 - INFO - epoch 0, step 24580, training loss = 2.205936, validation loss = 2.722767
2018-12-04 21:22:46,204 - INFO - epoch 0, step 24590, training loss = 2.590345, validation loss = 2.413091
2018-12-04 21:22:49,312 - INFO - epoch 0, step 24600, training loss = 3.551252, validation loss = 2.385165
2018-12-04 21:22:52,604 - INFO - epoch 0, step 24610, training loss = 3.092257, validation loss = 2.501921
2018-12-04 21:22:55,870 - INFO - epoch 0, step 24620, training loss = 3.267423, validation loss = 2.434413
2018-12-04 21:22:59,388 - INFO - epoch 0, step 24630, training loss = 2.407652, validation loss = 2.355728
2018-12-04 21:23:02,663 - INFO - epoch 0, step 24640, training loss = 2.659328, validation loss = 2.150710
2018-12-04 21:23:06,505 - INFO - epoch 0, step 24650, training loss = 1.113475, validation loss = 2.462133
2018-12-04 21:23:09,638 - INFO - epoch 0, step 24660, training loss = 2.420688, validation loss = 2.695661
2018-12-04 21:23:12,877 - INFO - epoch 0, step 24670, training loss = 2.237937, validation loss = 2.460344
2018-12-04 21:23:16,076 - INFO - epoch 0, step 24680, training loss = 2.992981, validation loss = 2.808822
2018-12-04 21:23:19,261 - INFO - epoch 0, step 24690, training loss = 2.495767, validation loss = 2.255576
2018-12-04 21:23:22,300 - INFO - epoch 0, step 24700, training loss = 2.717020, validation loss = 2.853443
2018-12-04 21:23:25,420 - INFO - epoch 0, step 24710, training loss = 2.648995, validation loss = 2.379988
2018-12-04 21:23:28,690 - INFO - epoch 0, step 24720, training loss = 2.407807, validation loss = 2.961448
2018-12-04 21:23:32,114 - INFO - epoch 0, step 24730, training loss = 2.060749, validation loss = 2.688404
2018-12-04 21:23:35,258 - INFO - epoch 0, step 24740, training loss = 2.331420, validation loss = 2.809598
2018-12-04 21:23:38,387 - INFO - epoch 0, step 24750, training loss = 2.906360, validation loss = 2.724591
2018-12-04 21:23:41,579 - INFO - epoch 0, step 24760, training loss = 3.199544, validation loss = 2.577604
2018-12-04 21:23:44,855 - INFO - epoch 0, step 24770, training loss = 2.417787, validation loss = 3.111679
2018-12-04 21:23:48,066 - INFO - epoch 0, step 24780, training loss = 2.930836, validation loss = 2.648165
2018-12-04 21:23:51,478 - INFO - epoch 0, step 24790, training loss = 2.502673, validation loss = 2.728966
2018-12-04 21:23:54,748 - INFO - epoch 0, step 24800, training loss = 2.169338, validation loss = 2.569166
2018-12-04 21:23:58,646 - INFO - epoch 0, step 24810, training loss = 2.592704, validation loss = 2.300266
2018-12-04 21:24:01,868 - INFO - epoch 0, step 24820, training loss = 2.732920, validation loss = 2.677037
2018-12-04 21:24:04,977 - INFO - epoch 0, step 24830, training loss = 2.469840, validation loss = 2.596115
2018-12-04 21:24:08,132 - INFO - epoch 0, step 24840, training loss = 3.316817, validation loss = 2.452758
2018-12-04 21:24:11,695 - INFO - epoch 0, step 24850, training loss = 1.977644, validation loss = 2.942439
2018-12-04 21:24:15,147 - INFO - epoch 0, step 24860, training loss = 2.178104, validation loss = 2.612775
2018-12-04 21:24:18,429 - INFO - epoch 0, step 24870, training loss = 2.357757, validation loss = 2.781979
2018-12-04 21:24:21,737 - INFO - epoch 0, step 24880, training loss = 2.428573, validation loss = 2.733688
2018-12-04 21:24:25,916 - INFO - epoch 0, step 24890, training loss = 2.927897, validation loss = 2.630351
2018-12-04 21:24:30,337 - INFO - epoch 0, step 24900, training loss = 2.442964, validation loss = 2.469729
2018-12-04 21:24:34,571 - INFO - epoch 0, step 24910, training loss = 3.127530, validation loss = 2.459274
2018-12-04 21:24:39,111 - INFO - epoch 0, step 24920, training loss = 2.489404, validation loss = 2.218772
2018-12-04 21:24:43,586 - INFO - epoch 0, step 24930, training loss = 2.299079, validation loss = 1.993912
2018-12-04 21:24:47,953 - INFO - epoch 0, step 24940, training loss = 2.360568, validation loss = 2.598541
2018-12-04 21:24:52,583 - INFO - epoch 0, step 24950, training loss = 2.760551, validation loss = 2.642148
2018-12-04 21:24:58,025 - INFO - epoch 0, step 24960, training loss = 3.113942, validation loss = 2.272444
2018-12-04 21:25:03,482 - INFO - epoch 0, step 24970, training loss = 2.779875, validation loss = 2.882326
2018-12-04 21:25:09,081 - INFO - epoch 0, step 24980, training loss = 2.305851, validation loss = 2.786496
2018-12-04 21:25:14,323 - INFO - epoch 0, step 24990, training loss = 2.604590, validation loss = 2.492565
2018-12-04 21:25:19,972 - INFO - epoch 0, step 25000, training loss = 2.650544, validation loss = 2.775500
2018-12-04 21:25:25,462 - INFO - epoch 0, step 25010, training loss = 2.870055, validation loss = 2.858764
2018-12-04 21:25:30,810 - INFO - epoch 0, step 25020, training loss = 3.125573, validation loss = 2.841874
2018-12-04 21:25:36,327 - INFO - epoch 0, step 25030, training loss = 2.904737, validation loss = 2.748451
2018-12-04 21:25:42,112 - INFO - epoch 0, step 25040, training loss = 2.721450, validation loss = 2.579722
2018-12-04 21:25:47,417 - INFO - epoch 0, step 25050, training loss = 2.710080, validation loss = 2.529649
2018-12-04 21:25:52,907 - INFO - epoch 0, step 25060, training loss = 2.297251, validation loss = 2.303237
2018-12-04 21:25:58,334 - INFO - epoch 0, step 25070, training loss = 2.449617, validation loss = 2.306909
2018-12-04 21:26:03,828 - INFO - epoch 0, step 25080, training loss = 2.805420, validation loss = 1.910933
2018-12-04 21:26:09,587 - INFO - epoch 0, step 25090, training loss = 2.858981, validation loss = 2.381233
2018-12-04 21:26:14,807 - INFO - epoch 0, step 25100, training loss = 2.947989, validation loss = 2.324672
2018-12-04 21:26:20,314 - INFO - epoch 0, step 25110, training loss = 3.103965, validation loss = 2.688176
2018-12-04 21:26:25,614 - INFO - epoch 0, step 25120, training loss = 2.831759, validation loss = 2.437701
2018-12-04 21:26:30,888 - INFO - epoch 0, step 25130, training loss = 2.619919, validation loss = 2.578362
2018-12-04 21:26:36,487 - INFO - epoch 0, step 25140, training loss = 2.775675, validation loss = 2.732859
2018-12-04 21:26:41,912 - INFO - epoch 0, step 25150, training loss = 2.704589, validation loss = 2.612770
2018-12-04 21:26:46,576 - INFO - epoch 0, step 25160, training loss = 2.808427, validation loss = 3.058046
2018-12-04 21:26:50,569 - INFO - epoch 0, step 25170, training loss = 2.880663, validation loss = 2.477143
2018-12-04 21:26:54,209 - INFO - epoch 0, step 25180, training loss = 3.151967, validation loss = 2.308705
2018-12-04 21:26:57,808 - INFO - epoch 0, step 25190, training loss = 2.891149, validation loss = 2.515626
2018-12-04 21:27:01,508 - INFO - epoch 0, step 25200, training loss = 2.517962, validation loss = 2.996539
2018-12-04 21:27:05,107 - INFO - epoch 0, step 25210, training loss = 2.557172, validation loss = 2.196598
2018-12-04 21:27:08,604 - INFO - epoch 0, step 25220, training loss = 2.683510, validation loss = 2.436872
2018-12-04 21:27:12,420 - INFO - epoch 0, step 25230, training loss = 2.339579, validation loss = 2.460942
2018-12-04 21:27:16,346 - INFO - epoch 0, step 25240, training loss = 2.320365, validation loss = 2.595275
2018-12-04 21:27:19,753 - INFO - epoch 0, step 25250, training loss = 2.643427, validation loss = 2.688607
2018-12-04 21:27:23,178 - INFO - epoch 0, step 25260, training loss = 2.747679, validation loss = 2.293258
2018-12-04 21:27:27,062 - INFO - epoch 0, step 25270, training loss = 2.231429, validation loss = 2.432981
2018-12-04 21:27:32,931 - INFO - epoch 0, step 25280, training loss = 2.523480, validation loss = 2.442739
2018-12-04 21:27:38,446 - INFO - epoch 0, step 25290, training loss = 2.144124, validation loss = 2.506646
2018-12-04 21:27:43,841 - INFO - epoch 0, step 25300, training loss = 2.592529, validation loss = 2.399903
2018-12-04 21:27:49,308 - INFO - epoch 0, step 25310, training loss = 2.023867, validation loss = 2.485059
2018-12-04 21:27:55,197 - INFO - epoch 0, step 25320, training loss = 2.322159, validation loss = 2.502706
2018-12-04 21:28:00,672 - INFO - epoch 0, step 25330, training loss = 2.530243, validation loss = 2.237306
2018-12-04 21:28:05,742 - INFO - epoch 0, step 25340, training loss = 2.342817, validation loss = 2.481394
2018-12-04 21:28:11,403 - INFO - epoch 0, step 25350, training loss = 2.932749, validation loss = 2.928727
2018-12-04 21:28:17,891 - INFO - epoch 0, step 25360, training loss = 2.220837, validation loss = 3.168644
2018-12-04 21:28:23,381 - INFO - epoch 0, step 25370, training loss = 2.216756, validation loss = 2.877887
2018-12-04 21:28:28,657 - INFO - epoch 0, step 25380, training loss = 2.701712, validation loss = 2.492065
2018-12-04 21:28:33,950 - INFO - epoch 0, step 25390, training loss = 2.819355, validation loss = 2.929348
2018-12-04 21:28:39,234 - INFO - epoch 0, step 25400, training loss = 2.250542, validation loss = 2.682194
2018-12-04 21:28:44,730 - INFO - epoch 0, step 25410, training loss = 2.246169, validation loss = 2.304621
2018-12-04 21:28:50,201 - INFO - epoch 0, step 25420, training loss = 2.464532, validation loss = 2.792822
2018-12-04 21:28:55,355 - INFO - epoch 0, step 25430, training loss = 2.129174, validation loss = 2.840818
2018-12-04 21:29:00,663 - INFO - epoch 0, step 25440, training loss = 2.386706, validation loss = 2.607508
2018-12-04 21:29:06,343 - INFO - epoch 0, step 25450, training loss = 1.688535, validation loss = 2.309649
2018-12-04 21:29:11,844 - INFO - epoch 0, step 25460, training loss = 3.032866, validation loss = 2.671451
2018-12-04 21:29:14,923 - INFO - epoch 0, step 25470, training loss = 2.991181, validation loss = 2.959637
2018-12-04 21:29:18,156 - INFO - epoch 0, step 25480, training loss = 1.853198, validation loss = 2.848748
2018-12-04 21:29:21,359 - INFO - epoch 0, step 25490, training loss = 2.520428, validation loss = 2.632097
2018-12-04 21:29:24,848 - INFO - epoch 0, step 25500, training loss = 2.904206, validation loss = 2.624572
2018-12-04 21:29:28,071 - INFO - epoch 0, step 25510, training loss = 2.625736, validation loss = 2.657455
2018-12-04 21:29:31,279 - INFO - epoch 0, step 25520, training loss = 2.537794, validation loss = 2.446583
2018-12-04 21:29:34,539 - INFO - epoch 0, step 25530, training loss = 2.933075, validation loss = 2.910850
2018-12-04 21:29:37,713 - INFO - epoch 0, step 25540, training loss = 2.667923, validation loss = 2.728209
2018-12-04 21:29:40,935 - INFO - epoch 0, step 25550, training loss = 2.641414, validation loss = 2.998965
2018-12-04 21:29:44,180 - INFO - epoch 0, step 25560, training loss = 2.606009, validation loss = 2.824528
2018-12-04 21:29:47,448 - INFO - epoch 0, step 25570, training loss = 2.375557, validation loss = 2.693539
2018-12-04 21:29:50,725 - INFO - epoch 0, step 25580, training loss = 2.652075, validation loss = 2.876473
2018-12-04 21:29:56,079 - INFO - epoch 0, step 25590, training loss = 2.766346, validation loss = 2.366096
2018-12-04 21:30:01,913 - INFO - epoch 0, step 25600, training loss = 2.155026, validation loss = 2.506765
2018-12-04 21:30:07,836 - INFO - epoch 0, step 25610, training loss = 2.441171, validation loss = 2.814251
2018-12-04 21:30:13,240 - INFO - epoch 0, step 25620, training loss = 2.334166, validation loss = 2.530219
2018-12-04 21:30:18,858 - INFO - epoch 0, step 25630, training loss = 2.554972, validation loss = 2.587163
2018-12-04 21:30:24,359 - INFO - epoch 0, step 25640, training loss = 2.474257, validation loss = 2.342599
2018-12-04 21:30:29,428 - INFO - epoch 0, step 25650, training loss = 2.500423, validation loss = 2.930474
2018-12-04 21:30:34,826 - INFO - epoch 0, step 25660, training loss = 2.072802, validation loss = 2.702223
2018-12-04 21:30:40,505 - INFO - epoch 0, step 25670, training loss = 2.555288, validation loss = 2.916996
2018-12-04 21:30:46,393 - INFO - epoch 0, step 25680, training loss = 1.914175, validation loss = 2.899255
2018-12-04 21:30:51,899 - INFO - epoch 0, step 25690, training loss = 2.610201, validation loss = 2.926819
2018-12-04 21:30:58,504 - INFO - epoch 0, step 25700, training loss = 2.067423, validation loss = 2.348601
2018-12-04 21:31:04,041 - INFO - epoch 0, step 25710, training loss = 2.751497, validation loss = 2.722112
2018-12-04 21:31:09,618 - INFO - epoch 0, step 25720, training loss = 2.353019, validation loss = 2.684846
2018-12-04 21:31:15,483 - INFO - epoch 0, step 25730, training loss = 2.394281, validation loss = 2.673302
2018-12-04 21:31:21,455 - INFO - epoch 0, step 25740, training loss = 1.779727, validation loss = 2.664060
2018-12-04 21:31:26,555 - INFO - epoch 0, step 25750, training loss = 2.697215, validation loss = 2.658387
2018-12-04 21:31:31,052 - INFO - epoch 0, step 25760, training loss = 2.872665, validation loss = 2.972546
2018-12-04 21:31:35,263 - INFO - epoch 0, step 25770, training loss = 2.479080, validation loss = 2.953975
2018-12-04 21:31:39,545 - INFO - epoch 0, step 25780, training loss = 2.602952, validation loss = 2.732211
2018-12-04 21:31:43,996 - INFO - epoch 0, step 25790, training loss = 2.711109, validation loss = 2.717132
2018-12-04 21:31:48,140 - INFO - epoch 0, step 25800, training loss = 2.364439, validation loss = 2.331611
2018-12-04 21:31:52,393 - INFO - epoch 0, step 25810, training loss = 2.675037, validation loss = 2.585174
2018-12-04 21:31:55,711 - INFO - epoch 0, step 25820, training loss = 2.362622, validation loss = 2.409861
2018-12-04 21:31:59,176 - INFO - epoch 0, step 25830, training loss = 2.192303, validation loss = 2.863204
2018-12-04 21:32:02,389 - INFO - epoch 0, step 25840, training loss = 2.819915, validation loss = 2.659803
2018-12-04 21:32:05,735 - INFO - epoch 0, step 25850, training loss = 2.450054, validation loss = 2.703068
2018-12-04 21:32:08,891 - INFO - epoch 0, step 25860, training loss = 2.492584, validation loss = 2.732731
2018-12-04 21:32:12,129 - INFO - epoch 0, step 25870, training loss = 2.655821, validation loss = 1.892825
2018-12-04 21:32:15,374 - INFO - epoch 0, step 25880, training loss = 2.210679, validation loss = 2.665296
2018-12-04 21:32:18,371 - INFO - epoch 0, step 25890, training loss = 2.360272, validation loss = 3.144067
2018-12-04 21:32:21,635 - INFO - epoch 0, step 25900, training loss = 2.474945, validation loss = 2.671064
2018-12-04 21:32:24,730 - INFO - epoch 0, step 25910, training loss = 2.920135, validation loss = 3.122501
2018-12-04 21:32:27,811 - INFO - epoch 0, step 25920, training loss = 2.498050, validation loss = 2.567224
2018-12-04 21:32:31,197 - INFO - epoch 0, step 25930, training loss = 2.312774, validation loss = 3.028663
2018-12-04 21:32:34,358 - INFO - epoch 0, step 25940, training loss = 2.762010, validation loss = 2.860976
2018-12-04 21:32:37,734 - INFO - epoch 0, step 25950, training loss = 2.583813, validation loss = 2.625566
2018-12-04 21:32:42,854 - INFO - epoch 0, step 25960, training loss = 2.638332, validation loss = 2.886706
2018-12-04 21:32:48,048 - INFO - epoch 0, step 25970, training loss = 2.664975, validation loss = 3.152763
2018-12-04 21:32:53,345 - INFO - epoch 0, step 25980, training loss = 2.438997, validation loss = 3.031160
2018-12-04 21:32:59,014 - INFO - epoch 0, step 25990, training loss = 2.654967, validation loss = 2.623901
2018-12-04 21:33:04,215 - INFO - epoch 0, step 26000, training loss = 2.442105, validation loss = 2.670474
2018-12-04 21:33:09,371 - INFO - epoch 0, step 26010, training loss = 2.863576, validation loss = 2.565828
2018-12-04 21:33:15,006 - INFO - epoch 0, step 26020, training loss = 2.870006, validation loss = 3.027123
2018-12-04 21:33:20,129 - INFO - epoch 0, step 26030, training loss = 2.753149, validation loss = 3.221687
2018-12-04 21:33:25,698 - INFO - epoch 0, step 26040, training loss = 2.593755, validation loss = 3.089813
2018-12-04 21:33:30,816 - INFO - epoch 0, step 26050, training loss = 2.226479, validation loss = 2.717525
2018-12-04 21:33:36,168 - INFO - epoch 0, step 26060, training loss = 2.669734, validation loss = 3.210088
2018-12-04 21:33:41,223 - INFO - epoch 0, step 26070, training loss = 2.421449, validation loss = 2.700576
2018-12-04 21:33:46,309 - INFO - epoch 0, step 26080, training loss = 2.848265, validation loss = 3.181953
2018-12-04 21:33:51,740 - INFO - epoch 0, step 26090, training loss = 2.756018, validation loss = 2.239528
2018-12-04 21:33:56,677 - INFO - epoch 0, step 26100, training loss = 2.129062, validation loss = 3.122757
2018-12-04 21:34:01,769 - INFO - epoch 0, step 26110, training loss = 2.238090, validation loss = 2.554470
2018-12-04 21:34:06,779 - INFO - epoch 0, step 26120, training loss = 2.518675, validation loss = 3.417091
2018-12-04 21:34:12,006 - INFO - epoch 0, step 26130, training loss = 2.701540, validation loss = 2.592092
2018-12-04 21:34:17,445 - INFO - epoch 0, step 26140, training loss = 2.612952, validation loss = 2.010302
2018-12-04 21:34:22,626 - INFO - epoch 0, step 26150, training loss = 2.525322, validation loss = 2.714147
2018-12-04 21:34:28,406 - INFO - epoch 0, step 26160, training loss = 2.132820, validation loss = 2.396536
2018-12-04 21:34:34,044 - INFO - epoch 0, step 26170, training loss = 2.662600, validation loss = 2.514965
2018-12-04 21:34:40,076 - INFO - epoch 0, step 26180, training loss = 2.175462, validation loss = 2.903368
2018-12-04 21:34:45,506 - INFO - epoch 0, step 26190, training loss = 2.187546, validation loss = 2.562382
2018-12-04 21:34:51,848 - INFO - epoch 0, step 26200, training loss = 2.832535, validation loss = 2.407919
2018-12-04 21:34:57,792 - INFO - epoch 0, step 26210, training loss = 2.638717, validation loss = 2.617821
2018-12-04 21:35:03,170 - INFO - epoch 0, step 26220, training loss = 2.509978, validation loss = 2.482211
2018-12-04 21:35:08,765 - INFO - epoch 0, step 26230, training loss = 2.080587, validation loss = 3.005696
2018-12-04 21:35:14,087 - INFO - epoch 0, step 26240, training loss = 2.173390, validation loss = 2.836666
2018-12-04 21:35:19,616 - INFO - epoch 0, step 26250, training loss = 2.734150, validation loss = 2.603313
2018-12-04 21:35:25,174 - INFO - epoch 0, step 26260, training loss = 2.282056, validation loss = 2.725332
2018-12-04 21:35:30,987 - INFO - epoch 0, step 26270, training loss = 2.492007, validation loss = 2.747096
2018-12-04 21:35:36,649 - INFO - epoch 0, step 26280, training loss = 2.287633, validation loss = 2.376494
2018-12-04 21:35:42,905 - INFO - epoch 0, step 26290, training loss = 2.286469, validation loss = 2.570191
2018-12-04 21:35:48,501 - INFO - epoch 0, step 26300, training loss = 2.030947, validation loss = 2.470913
2018-12-04 21:35:53,725 - INFO - epoch 0, step 26310, training loss = 2.654007, validation loss = 2.474808
2018-12-04 21:35:59,197 - INFO - epoch 0, step 26320, training loss = 2.484638, validation loss = 2.668444
2018-12-04 21:36:04,528 - INFO - epoch 0, step 26330, training loss = 2.693446, validation loss = 2.581473
2018-12-04 21:36:09,841 - INFO - epoch 0, step 26340, training loss = 3.015558, validation loss = 2.059448
2018-12-04 21:36:14,947 - INFO - epoch 0, step 26350, training loss = 3.205683, validation loss = 2.634886
2018-12-04 21:36:20,199 - INFO - epoch 0, step 26360, training loss = 2.582499, validation loss = 2.704980
2018-12-04 21:36:25,601 - INFO - epoch 0, step 26370, training loss = 2.173515, validation loss = 2.422955
2018-12-04 21:36:31,088 - INFO - epoch 0, step 26380, training loss = 2.881336, validation loss = 2.385347
2018-12-04 21:36:36,511 - INFO - epoch 0, step 26390, training loss = 2.401911, validation loss = 2.578029
2018-12-04 21:36:41,930 - INFO - epoch 0, step 26400, training loss = 2.500304, validation loss = 2.293751
2018-12-04 21:36:47,231 - INFO - epoch 0, step 26410, training loss = 2.599423, validation loss = 2.454520
2018-12-04 21:36:52,747 - INFO - epoch 0, step 26420, training loss = 2.186411, validation loss = 3.239427
2018-12-04 21:36:58,149 - INFO - epoch 0, step 26430, training loss = 2.601171, validation loss = 2.651079
2018-12-04 21:37:03,244 - INFO - epoch 0, step 26440, training loss = 2.363056, validation loss = 2.967703
2018-12-04 21:37:08,336 - INFO - epoch 0, step 26450, training loss = 2.559896, validation loss = 2.696904
2018-12-04 21:37:13,805 - INFO - epoch 0, step 26460, training loss = 2.852939, validation loss = 2.399049
2018-12-04 21:37:18,375 - INFO - epoch 0, step 26470, training loss = 2.981704, validation loss = 2.440494
2018-12-04 21:37:22,014 - INFO - epoch 0, step 26480, training loss = 3.228503, validation loss = 2.041662
2018-12-04 21:37:25,431 - INFO - epoch 0, step 26490, training loss = 2.552888, validation loss = 2.207511
2018-12-04 21:37:28,810 - INFO - epoch 0, step 26500, training loss = 2.266079, validation loss = 2.735964
2018-12-04 21:37:32,224 - INFO - epoch 0, step 26510, training loss = 2.403215, validation loss = 2.681880
2018-12-04 21:37:35,761 - INFO - epoch 0, step 26520, training loss = 2.327464, validation loss = 2.622788
2018-12-04 21:37:39,167 - INFO - epoch 0, step 26530, training loss = 2.497924, validation loss = 2.241726
2018-12-04 21:37:42,591 - INFO - epoch 0, step 26540, training loss = 2.449051, validation loss = 2.421420
2018-12-04 21:37:45,942 - INFO - epoch 0, step 26550, training loss = 3.015751, validation loss = 2.652747
2018-12-04 21:37:49,218 - INFO - epoch 0, step 26560, training loss = 2.736231, validation loss = 2.639664
2018-12-04 21:37:52,400 - INFO - epoch 0, step 26570, training loss = 2.766362, validation loss = 2.798355
2018-12-04 21:37:55,568 - INFO - epoch 0, step 26580, training loss = 2.978278, validation loss = 2.370042
2018-12-04 21:37:58,783 - INFO - epoch 0, step 26590, training loss = 3.084065, validation loss = 2.462957
2018-12-04 21:38:01,955 - INFO - epoch 0, step 26600, training loss = 2.904454, validation loss = 2.335011
2018-12-04 21:38:05,255 - INFO - epoch 0, step 26610, training loss = 2.730043, validation loss = 2.403516
2018-12-04 21:38:08,329 - INFO - epoch 0, step 26620, training loss = 2.832064, validation loss = 2.578204
2018-12-04 21:38:11,547 - INFO - epoch 0, step 26630, training loss = 2.640947, validation loss = 2.345526
2018-12-04 21:38:14,823 - INFO - epoch 0, step 26640, training loss = 2.958987, validation loss = 2.196946
2018-12-04 21:38:18,171 - INFO - epoch 0, step 26650, training loss = 2.658379, validation loss = 2.554771
2018-12-04 21:38:21,412 - INFO - epoch 0, step 26660, training loss = 2.490813, validation loss = 2.517882
2018-12-04 21:38:24,679 - INFO - epoch 0, step 26670, training loss = 2.568821, validation loss = 2.721215
2018-12-04 21:38:27,969 - INFO - epoch 0, step 26680, training loss = 2.673363, validation loss = 2.829225
2018-12-04 21:38:31,182 - INFO - epoch 0, step 26690, training loss = 2.432902, validation loss = 2.305856
2018-12-04 21:38:34,482 - INFO - epoch 0, step 26700, training loss = 2.592474, validation loss = 2.252944
2018-12-04 21:38:37,714 - INFO - epoch 0, step 26710, training loss = 2.782558, validation loss = 2.722401
2018-12-04 21:38:42,608 - INFO - epoch 0, step 26720, training loss = 2.441620, validation loss = 2.393065
2018-12-04 21:38:48,375 - INFO - epoch 0, step 26730, training loss = 2.898524, validation loss = 2.802503
2018-12-04 21:38:54,460 - INFO - epoch 0, step 26740, training loss = 2.303852, validation loss = 2.137451
2018-12-04 21:39:00,569 - INFO - epoch 0, step 26750, training loss = 2.387313, validation loss = 2.744449
2018-12-04 21:39:06,773 - INFO - epoch 0, step 26760, training loss = 2.241653, validation loss = 2.541031
2018-12-04 21:39:12,798 - INFO - epoch 0, step 26770, training loss = 2.020357, validation loss = 2.600080
2018-12-04 21:39:18,303 - INFO - epoch 0, step 26780, training loss = 2.399411, validation loss = 2.437033
2018-12-04 21:39:23,794 - INFO - epoch 0, step 26790, training loss = 2.718246, validation loss = 2.639285
2018-12-04 21:39:29,372 - INFO - epoch 0, step 26800, training loss = 2.521060, validation loss = 3.163337
2018-12-04 21:39:34,755 - INFO - epoch 0, step 26810, training loss = 1.750789, validation loss = 2.861615
2018-12-04 21:39:40,631 - INFO - epoch 0, step 26820, training loss = 2.030285, validation loss = 2.552882
2018-12-04 21:39:46,208 - INFO - epoch 0, step 26830, training loss = 2.289353, validation loss = 2.023198
2018-12-04 21:39:52,312 - INFO - epoch 0, step 26840, training loss = 2.004578, validation loss = 2.445302
2018-12-04 21:39:57,794 - INFO - epoch 0, step 26850, training loss = 2.391608, validation loss = 2.833633
2018-12-04 21:40:03,038 - INFO - epoch 0, step 26860, training loss = 2.717961, validation loss = 2.669925
2018-12-04 21:40:08,245 - INFO - epoch 0, step 26870, training loss = 2.917602, validation loss = 2.559412
2018-12-04 21:40:13,589 - INFO - epoch 0, step 26880, training loss = 2.763049, validation loss = 2.680139
2018-12-04 21:40:18,768 - INFO - epoch 0, step 26890, training loss = 2.780417, validation loss = 2.565532
2018-12-04 21:40:24,497 - INFO - epoch 0, step 26900, training loss = 2.497542, validation loss = 2.776449
2018-12-04 21:40:29,789 - INFO - epoch 0, step 26910, training loss = 2.641717, validation loss = 2.652397
2018-12-04 21:40:35,032 - INFO - epoch 0, step 26920, training loss = 2.699599, validation loss = 3.086605
2018-12-04 21:40:40,553 - INFO - epoch 0, step 26930, training loss = 2.740386, validation loss = 2.588242
2018-12-04 21:40:45,635 - INFO - epoch 0, step 26940, training loss = 2.700227, validation loss = 2.694877
2018-12-04 21:40:50,845 - INFO - epoch 0, step 26950, training loss = 2.977319, validation loss = 2.353180
2018-12-04 21:40:56,180 - INFO - epoch 0, step 26960, training loss = 2.554962, validation loss = 2.453858
2018-12-04 21:41:01,658 - INFO - epoch 0, step 26970, training loss = 2.790987, validation loss = 2.662312
2018-12-04 21:41:07,353 - INFO - epoch 0, step 26980, training loss = 2.720802, validation loss = 3.068737
2018-12-04 21:41:12,765 - INFO - epoch 0, step 26990, training loss = 2.799364, validation loss = 3.009725
2018-12-04 21:41:18,167 - INFO - epoch 0, step 27000, training loss = 2.988800, validation loss = 2.029062
2018-12-04 21:41:23,387 - INFO - epoch 0, step 27010, training loss = 3.073857, validation loss = 2.508738
2018-12-04 21:41:28,767 - INFO - epoch 0, step 27020, training loss = 2.198899, validation loss = 2.747241
2018-12-04 21:41:33,845 - INFO - epoch 0, step 27030, training loss = 2.513043, validation loss = 3.047106
2018-12-04 21:41:39,060 - INFO - epoch 0, step 27040, training loss = 2.948883, validation loss = 2.391179
2018-12-04 21:41:44,300 - INFO - epoch 0, step 27050, training loss = 2.735736, validation loss = 2.253038
2018-12-04 21:41:49,061 - INFO - epoch 0, step 27060, training loss = 2.853313, validation loss = 2.746874
2018-12-04 21:41:53,304 - INFO - epoch 0, step 27070, training loss = 2.673065, validation loss = 2.315023
2018-12-04 21:41:57,617 - INFO - epoch 0, step 27080, training loss = 2.662170, validation loss = 2.810115
2018-12-04 21:42:01,829 - INFO - epoch 0, step 27090, training loss = 2.523774, validation loss = 2.958284
2018-12-04 21:42:06,223 - INFO - epoch 0, step 27100, training loss = 2.154559, validation loss = 2.636449
2018-12-04 21:42:10,374 - INFO - epoch 0, step 27110, training loss = 2.163532, validation loss = 2.097347
2018-12-04 21:42:14,093 - INFO - epoch 0, step 27120, training loss = 2.495988, validation loss = 2.839136
2018-12-04 21:42:17,988 - INFO - epoch 0, step 27130, training loss = 2.133398, validation loss = 2.608191
2018-12-04 21:42:21,891 - INFO - epoch 0, step 27140, training loss = 2.372089, validation loss = 2.561215
2018-12-04 21:42:25,501 - INFO - epoch 0, step 27150, training loss = 2.595439, validation loss = 2.559355
2018-12-04 21:42:29,228 - INFO - epoch 0, step 27160, training loss = 2.394786, validation loss = 2.287923
2018-12-04 21:42:34,376 - INFO - epoch 0, step 27170, training loss = 2.357475, validation loss = 2.730296
2018-12-04 21:42:39,289 - INFO - epoch 0, step 27180, training loss = 2.579567, validation loss = 2.364353
2018-12-04 21:42:44,296 - INFO - epoch 0, step 27190, training loss = 2.564792, validation loss = 2.376541
2018-12-04 21:42:49,504 - INFO - epoch 0, step 27200, training loss = 2.601723, validation loss = 2.592038
2018-12-04 21:42:54,728 - INFO - epoch 0, step 27210, training loss = 2.534080, validation loss = 2.636825
2018-12-04 21:42:59,860 - INFO - epoch 0, step 27220, training loss = 2.603568, validation loss = 2.597939
2018-12-04 21:43:05,130 - INFO - epoch 0, step 27230, training loss = 2.345725, validation loss = 2.488352
2018-12-04 21:43:10,432 - INFO - epoch 0, step 27240, training loss = 2.405415, validation loss = 2.668012
2018-12-04 21:43:15,606 - INFO - epoch 0, step 27250, training loss = 2.413807, validation loss = 2.707571
2018-12-04 21:43:21,214 - INFO - epoch 0, step 27260, training loss = 1.789528, validation loss = 2.386302
2018-12-04 21:43:26,338 - INFO - epoch 0, step 27270, training loss = 2.828146, validation loss = 2.312681
2018-12-04 21:43:31,401 - INFO - epoch 0, step 27280, training loss = 2.634058, validation loss = 2.538882
2018-12-04 21:43:36,422 - INFO - epoch 0, step 27290, training loss = 2.670445, validation loss = 2.242511
2018-12-04 21:43:40,896 - INFO - epoch 0, step 27300, training loss = 2.481843, validation loss = 2.921473
2018-12-04 21:43:45,117 - INFO - epoch 0, step 27310, training loss = 2.485317, validation loss = 2.451198
2018-12-04 21:43:49,980 - INFO - epoch 0, step 27320, training loss = 2.238308, validation loss = 2.397588
2018-12-04 21:43:54,839 - INFO - epoch 0, step 27330, training loss = 2.645836, validation loss = 2.647672
2018-12-04 21:43:59,293 - INFO - epoch 0, step 27340, training loss = 2.392488, validation loss = 2.042648
2018-12-04 21:44:03,405 - INFO - epoch 0, step 27350, training loss = 2.167760, validation loss = 2.344193
2018-12-04 21:44:07,726 - INFO - epoch 0, step 27360, training loss = 2.621398, validation loss = 2.815547
2018-12-04 21:44:11,892 - INFO - epoch 0, step 27370, training loss = 2.661166, validation loss = 2.462668
2018-12-04 21:44:16,540 - INFO - epoch 0, step 27380, training loss = 2.500634, validation loss = 2.779354
2018-12-04 21:44:21,095 - INFO - epoch 0, step 27390, training loss = 2.387067, validation loss = 2.578080
2018-12-04 21:44:24,812 - INFO - epoch 0, step 27400, training loss = 2.673100, validation loss = 2.023226
2018-12-04 21:44:28,039 - INFO - epoch 0, step 27410, training loss = 2.822973, validation loss = 2.546239
2018-12-04 21:44:31,224 - INFO - epoch 0, step 27420, training loss = 2.580108, validation loss = 2.574579
2018-12-04 21:44:34,409 - INFO - epoch 0, step 27430, training loss = 2.528845, validation loss = 2.141470
2018-12-04 21:44:37,868 - INFO - epoch 0, step 27440, training loss = 2.728022, validation loss = 2.592197
2018-12-04 21:44:41,149 - INFO - epoch 0, step 27450, training loss = 2.581197, validation loss = 2.628742
2018-12-04 21:44:44,538 - INFO - epoch 0, step 27460, training loss = 2.690702, validation loss = 2.233733
2018-12-04 21:44:47,795 - INFO - epoch 0, step 27470, training loss = 2.868040, validation loss = 2.348428
2018-12-04 21:44:51,032 - INFO - epoch 0, step 27480, training loss = 2.777654, validation loss = 2.585485
2018-12-04 21:44:54,380 - INFO - epoch 0, step 27490, training loss = 2.575975, validation loss = 2.884838
2018-12-04 21:44:57,574 - INFO - epoch 0, step 27500, training loss = 2.572753, validation loss = 2.007939
2018-12-04 21:45:00,878 - INFO - epoch 0, step 27510, training loss = 2.387504, validation loss = 2.527400
2018-12-04 21:45:04,154 - INFO - epoch 0, step 27520, training loss = 2.312755, validation loss = 2.709743
2018-12-04 21:45:07,443 - INFO - epoch 0, step 27530, training loss = 2.562781, validation loss = 2.665775
2018-12-04 21:45:10,788 - INFO - epoch 0, step 27540, training loss = 2.121800, validation loss = 2.237403
2018-12-04 21:45:14,127 - INFO - epoch 0, step 27550, training loss = 1.915700, validation loss = 2.728848
2018-12-04 21:45:17,528 - INFO - epoch 0, step 27560, training loss = 2.629600, validation loss = 2.585851
2018-12-04 21:45:21,081 - INFO - epoch 0, step 27570, training loss = 2.686872, validation loss = 2.810081
2018-12-04 21:45:25,369 - INFO - epoch 0, step 27580, training loss = 2.439784, validation loss = 2.584620
2018-12-04 21:45:29,495 - INFO - epoch 0, step 27590, training loss = 2.888037, validation loss = 2.724103
2018-12-04 21:45:33,727 - INFO - epoch 0, step 27600, training loss = 2.753563, validation loss = 2.406038
2018-12-04 21:45:38,334 - INFO - epoch 0, step 27610, training loss = 2.006123, validation loss = 2.376069
2018-12-04 21:45:42,686 - INFO - epoch 0, step 27620, training loss = 2.755517, validation loss = 2.407730
2018-12-04 21:45:47,779 - INFO - epoch 0, step 27630, training loss = 2.314497, validation loss = 1.967548
2018-12-04 21:45:53,754 - INFO - epoch 0, step 27640, training loss = 2.248184, validation loss = 2.693463
2018-12-04 21:45:59,324 - INFO - epoch 0, step 27650, training loss = 1.821717, validation loss = 2.753407
2018-12-04 21:46:04,871 - INFO - epoch 0, step 27660, training loss = 2.548928, validation loss = 3.303877
2018-12-04 21:46:10,909 - INFO - epoch 0, step 27670, training loss = 1.966080, validation loss = 2.678704
2018-12-04 21:46:16,833 - INFO - epoch 0, step 27680, training loss = 2.235272, validation loss = 2.965660
2018-12-04 21:46:22,488 - INFO - epoch 0, step 27690, training loss = 2.252053, validation loss = 2.986140
2018-12-04 21:46:27,988 - INFO - epoch 0, step 27700, training loss = 2.065892, validation loss = 2.738344
2018-12-04 21:46:34,463 - INFO - epoch 0, step 27710, training loss = 2.255570, validation loss = 2.867727
2018-12-04 21:46:40,158 - INFO - epoch 0, step 27720, training loss = 2.353002, validation loss = 2.023942
2018-12-04 21:46:46,004 - INFO - epoch 0, step 27730, training loss = 2.018361, validation loss = 2.460697
2018-12-04 21:46:51,784 - INFO - epoch 0, step 27740, training loss = 2.572243, validation loss = 2.943536
2018-12-04 21:46:57,329 - INFO - epoch 0, step 27750, training loss = 2.298171, validation loss = 2.299429
2018-12-04 21:47:02,572 - INFO - epoch 0, step 27760, training loss = 2.433730, validation loss = 2.688771
2018-12-04 21:47:08,102 - INFO - epoch 0, step 27770, training loss = 2.210793, validation loss = 2.770756
2018-12-04 21:47:13,444 - INFO - epoch 0, step 27780, training loss = 2.124479, validation loss = 2.646547
2018-12-04 21:47:18,801 - INFO - epoch 0, step 27790, training loss = 2.562638, validation loss = 2.766358
2018-12-04 21:47:23,739 - INFO - epoch 0, step 27800, training loss = 2.477481, validation loss = 2.799814
2018-12-04 21:47:28,894 - INFO - epoch 0, step 27810, training loss = 2.809349, validation loss = 2.506991
2018-12-04 21:47:33,940 - INFO - epoch 0, step 27820, training loss = 2.497178, validation loss = 2.844097
2018-12-04 21:47:39,032 - INFO - epoch 0, step 27830, training loss = 2.496367, validation loss = 3.389337
2018-12-04 21:47:44,607 - INFO - epoch 0, step 27840, training loss = 2.013432, validation loss = 2.684110
2018-12-04 21:47:49,653 - INFO - epoch 0, step 27850, training loss = 2.178297, validation loss = 3.611123
2018-12-04 21:47:54,676 - INFO - epoch 0, step 27860, training loss = 2.441478, validation loss = 2.093935
2018-12-04 21:48:00,018 - INFO - epoch 0, step 27870, training loss = 1.765913, validation loss = 3.092345
2018-12-04 21:48:05,419 - INFO - epoch 0, step 27880, training loss = 2.098897, validation loss = 3.033009
2018-12-04 21:48:10,515 - INFO - epoch 0, step 27890, training loss = 2.512812, validation loss = 2.653340
2018-12-04 21:48:15,751 - INFO - epoch 0, step 27900, training loss = 2.627662, validation loss = 2.506351
2018-12-04 21:48:20,671 - INFO - epoch 0, step 27910, training loss = 2.360268, validation loss = 2.951504
2018-12-04 21:48:25,823 - INFO - epoch 0, step 27920, training loss = 2.572211, validation loss = 2.881702
2018-12-04 21:48:31,030 - INFO - epoch 0, step 27930, training loss = 2.752557, validation loss = 3.324705
2018-12-04 21:48:36,401 - INFO - epoch 0, step 27940, training loss = 1.973594, validation loss = 2.821743
2018-12-04 21:48:41,557 - INFO - epoch 0, step 27950, training loss = 2.323295, validation loss = 3.176862
2018-12-04 21:48:47,059 - INFO - epoch 0, step 27960, training loss = 1.667104, validation loss = 2.930336
2018-12-04 21:48:52,329 - INFO - epoch 0, step 27970, training loss = 2.350659, validation loss = 2.929475
2018-12-04 21:48:57,562 - INFO - epoch 0, step 27980, training loss = 2.076458, validation loss = 2.579992
2018-12-04 21:49:02,741 - INFO - epoch 0, step 27990, training loss = 2.438763, validation loss = 2.852135
2018-12-04 21:49:07,834 - INFO - epoch 0, step 28000, training loss = 2.396435, validation loss = 3.051794
2018-12-04 21:49:13,201 - INFO - epoch 0, step 28010, training loss = 2.374253, validation loss = 2.853990
2018-12-04 21:49:18,661 - INFO - epoch 0, step 28020, training loss = 2.385695, validation loss = 3.252249
2018-12-04 21:49:24,086 - INFO - epoch 0, step 28030, training loss = 2.679065, validation loss = 3.179643
2018-12-04 21:49:29,330 - INFO - epoch 0, step 28040, training loss = 2.349352, validation loss = 2.740655
2018-12-04 21:49:34,626 - INFO - epoch 0, step 28050, training loss = 2.159499, validation loss = 2.976451
2018-12-04 21:49:39,854 - INFO - epoch 0, step 28060, training loss = 2.042364, validation loss = 3.281602
2018-12-04 21:49:46,284 - INFO - epoch 0, step 28070, training loss = 1.852602, validation loss = 3.121881
2018-12-04 21:49:51,663 - INFO - epoch 0, step 28080, training loss = 2.368247, validation loss = 3.908110
2018-12-04 21:49:56,945 - INFO - epoch 0, step 28090, training loss = 1.954437, validation loss = 3.543447
2018-12-04 21:50:02,049 - INFO - epoch 0, step 28100, training loss = 2.277218, validation loss = 2.835979
2018-12-04 21:50:07,391 - INFO - epoch 0, step 28110, training loss = 2.373442, validation loss = 3.076534
2018-12-04 21:50:12,724 - INFO - epoch 0, step 28120, training loss = 2.487490, validation loss = 2.479121
2018-12-04 21:50:17,731 - INFO - epoch 0, step 28130, training loss = 2.307981, validation loss = 3.030426
2018-12-04 21:50:22,800 - INFO - epoch 0, step 28140, training loss = 2.301823, validation loss = 2.796354
2018-12-04 21:50:28,147 - INFO - epoch 0, step 28150, training loss = 2.897205, validation loss = 2.870216
2018-12-04 21:50:33,418 - INFO - epoch 0, step 28160, training loss = 2.360802, validation loss = 2.790332
2018-12-04 21:50:38,629 - INFO - epoch 0, step 28170, training loss = 2.447876, validation loss = 2.431585
2018-12-04 21:50:43,833 - INFO - epoch 0, step 28180, training loss = 2.193684, validation loss = 2.662398
2018-12-04 21:50:48,921 - INFO - epoch 0, step 28190, training loss = 2.329931, validation loss = 3.165985
2018-12-04 21:50:54,162 - INFO - epoch 0, step 28200, training loss = 2.379905, validation loss = 3.399928
2018-12-04 21:50:59,314 - INFO - epoch 0, step 28210, training loss = 2.529438, validation loss = 2.739338
2018-12-04 21:51:04,661 - INFO - epoch 0, step 28220, training loss = 2.887896, validation loss = 3.147075
2018-12-04 21:51:09,945 - INFO - epoch 0, step 28230, training loss = 2.512001, validation loss = 2.960159
2018-12-04 21:51:15,121 - INFO - epoch 0, step 28240, training loss = 2.509618, validation loss = 2.997099
2018-12-04 21:51:20,147 - INFO - epoch 0, step 28250, training loss = 2.187710, validation loss = 2.809514
2018-12-04 21:51:25,320 - INFO - epoch 0, step 28260, training loss = 2.091959, validation loss = 3.159556
2018-12-04 21:51:30,767 - INFO - epoch 0, step 28270, training loss = 2.311954, validation loss = 2.853438
2018-12-04 21:51:35,903 - INFO - epoch 0, step 28280, training loss = 2.319874, validation loss = 2.913163
2018-12-04 21:51:41,123 - INFO - epoch 0, step 28290, training loss = 2.543809, validation loss = 2.942611
2018-12-04 21:51:46,183 - INFO - epoch 0, step 28300, training loss = 2.706166, validation loss = 2.697522
2018-12-04 21:51:51,455 - INFO - epoch 0, step 28310, training loss = 2.335086, validation loss = 3.279083
2018-12-04 21:51:56,568 - INFO - epoch 0, step 28320, training loss = 2.727643, validation loss = 2.530337
2018-12-04 21:52:02,126 - INFO - epoch 0, step 28330, training loss = 2.743448, validation loss = 2.528201
2018-12-04 21:52:07,231 - INFO - epoch 0, step 28340, training loss = 2.713827, validation loss = 2.861575
2018-12-04 21:52:12,354 - INFO - epoch 0, step 28350, training loss = 2.525649, validation loss = 3.043962
2018-12-04 21:52:17,385 - INFO - epoch 0, step 28360, training loss = 3.028766, validation loss = 2.934153
2018-12-04 21:52:21,670 - INFO - epoch 0, step 28370, training loss = 2.610242, validation loss = 3.122184
2018-12-04 21:52:25,971 - INFO - epoch 0, step 28380, training loss = 2.889760, validation loss = 2.634083
2018-12-04 21:52:30,334 - INFO - epoch 0, step 28390, training loss = 2.604828, validation loss = 2.450691
2018-12-04 21:52:34,896 - INFO - epoch 0, step 28400, training loss = 1.786102, validation loss = 2.470330
2018-12-04 21:52:39,469 - INFO - epoch 0, step 28410, training loss = 2.064577, validation loss = 2.851940
2018-12-04 21:52:45,025 - INFO - epoch 0, step 28420, training loss = 2.388039, validation loss = 2.577548
2018-12-04 21:52:50,871 - INFO - epoch 0, step 28430, training loss = 2.210764, validation loss = 2.625972
2018-12-04 21:52:56,398 - INFO - epoch 0, step 28440, training loss = 1.865238, validation loss = 2.880802
2018-12-04 21:53:02,112 - INFO - epoch 0, step 28450, training loss = 2.146076, validation loss = 2.586837
2018-12-04 21:53:08,208 - INFO - epoch 0, step 28460, training loss = 2.273362, validation loss = 2.702088
2018-12-04 21:53:14,070 - INFO - epoch 0, step 28470, training loss = 1.883832, validation loss = 2.750733
2018-12-04 21:53:20,125 - INFO - epoch 0, step 28480, training loss = 2.486631, validation loss = 2.471347
2018-12-04 21:53:25,564 - INFO - epoch 0, step 28490, training loss = 2.733476, validation loss = 2.543037
2018-12-04 21:53:31,915 - INFO - epoch 0, step 28500, training loss = 2.086302, validation loss = 3.084918
2018-12-04 21:53:38,061 - INFO - epoch 0, step 28510, training loss = 1.765147, validation loss = 2.718786
2018-12-04 21:53:41,444 - INFO - epoch 0, step 28520, training loss = 2.457467, validation loss = 2.774723
2018-12-04 21:53:44,612 - INFO - epoch 0, step 28530, training loss = 2.255438, validation loss = 2.858267
2018-12-04 21:53:47,982 - INFO - epoch 0, step 28540, training loss = 3.655621, validation loss = 2.918235
2018-12-04 21:53:51,229 - INFO - epoch 0, step 28550, training loss = 3.072499, validation loss = 2.501026
2018-12-04 21:53:54,551 - INFO - epoch 0, step 28560, training loss = 2.485502, validation loss = 2.458901
2018-12-04 21:53:57,838 - INFO - epoch 0, step 28570, training loss = 2.453457, validation loss = 2.486117
2018-12-04 21:54:01,096 - INFO - epoch 0, step 28580, training loss = 2.807732, validation loss = 2.818564
2018-12-04 21:54:04,436 - INFO - epoch 0, step 28590, training loss = 2.321194, validation loss = 2.676644
2018-12-04 21:54:07,626 - INFO - epoch 0, step 28600, training loss = 3.000456, validation loss = 3.159505
2018-12-04 21:54:10,730 - INFO - epoch 0, step 28610, training loss = 2.508403, validation loss = 3.043103
2018-12-04 21:54:13,895 - INFO - epoch 0, step 28620, training loss = 2.237530, validation loss = 2.678055
2018-12-04 21:54:17,083 - INFO - epoch 0, step 28630, training loss = 2.243597, validation loss = 2.594735
2018-12-04 21:54:20,243 - INFO - epoch 0, step 28640, training loss = 2.292471, validation loss = 2.623775
2018-12-04 21:54:23,669 - INFO - epoch 0, step 28650, training loss = 2.666956, validation loss = 3.028584
2018-12-04 21:54:27,932 - INFO - epoch 0, step 28660, training loss = 2.045184, validation loss = 2.806766
2018-12-04 21:54:32,628 - INFO - epoch 0, step 28670, training loss = 2.437166, validation loss = 2.868597
2018-12-04 21:54:36,765 - INFO - epoch 0, step 28680, training loss = 2.641338, validation loss = 2.520533
2018-12-04 21:54:40,967 - INFO - epoch 0, step 28690, training loss = 2.618695, validation loss = 2.879910
2018-12-04 21:54:45,359 - INFO - epoch 0, step 28700, training loss = 2.733418, validation loss = 2.917881
2018-12-04 21:54:50,310 - INFO - epoch 0, step 28710, training loss = 3.127402, validation loss = 3.143146
2018-12-04 21:54:55,687 - INFO - epoch 0, step 28720, training loss = 2.627582, validation loss = 2.590148
2018-12-04 21:55:01,088 - INFO - epoch 0, step 28730, training loss = 2.529479, validation loss = 2.633404
2018-12-04 21:55:06,016 - INFO - epoch 0, step 28740, training loss = 2.543634, validation loss = 2.952309
2018-12-04 21:55:11,174 - INFO - epoch 0, step 28750, training loss = 2.637406, validation loss = 2.490685
2018-12-04 21:55:16,454 - INFO - epoch 0, step 28760, training loss = 2.556811, validation loss = 2.479307
2018-12-04 21:55:21,617 - INFO - epoch 0, step 28770, training loss = 2.708755, validation loss = 2.603027
2018-12-04 21:55:26,951 - INFO - epoch 0, step 28780, training loss = 2.848864, validation loss = 2.502704
2018-12-04 21:55:31,946 - INFO - epoch 0, step 28790, training loss = 2.544410, validation loss = 2.341258
2018-12-04 21:55:37,183 - INFO - epoch 0, step 28800, training loss = 2.586757, validation loss = 2.805099
2018-12-04 21:55:42,438 - INFO - epoch 0, step 28810, training loss = 2.394974, validation loss = 2.604941
2018-12-04 21:55:47,745 - INFO - epoch 0, step 28820, training loss = 2.590506, validation loss = 2.093995
2018-12-04 21:55:52,910 - INFO - epoch 0, step 28830, training loss = 2.001177, validation loss = 2.746889
2018-12-04 21:55:58,141 - INFO - epoch 0, step 28840, training loss = 2.643394, validation loss = 2.790483
2018-12-04 21:56:03,544 - INFO - epoch 0, step 28850, training loss = 2.069667, validation loss = 2.762881
2018-12-04 21:56:08,967 - INFO - epoch 0, step 28860, training loss = 2.855757, validation loss = 2.978029
2018-12-04 21:56:14,160 - INFO - epoch 0, step 28870, training loss = 3.027591, validation loss = 2.711549
2018-12-04 21:56:19,337 - INFO - epoch 0, step 28880, training loss = 2.373721, validation loss = 2.717016
2018-12-04 21:56:24,581 - INFO - epoch 0, step 28890, training loss = 2.217390, validation loss = 2.763457
2018-12-04 21:56:29,684 - INFO - epoch 0, step 28900, training loss = 2.309694, validation loss = 2.363760
2018-12-04 21:56:35,079 - INFO - epoch 0, step 28910, training loss = 2.695002, validation loss = 2.909235
2018-12-04 21:56:40,271 - INFO - epoch 0, step 28920, training loss = 2.710847, validation loss = 2.848528
2018-12-04 21:56:45,448 - INFO - epoch 0, step 28930, training loss = 2.452352, validation loss = 2.897432
2018-12-04 21:56:50,845 - INFO - epoch 0, step 28940, training loss = 2.673646, validation loss = 2.648287
2018-12-04 21:56:56,247 - INFO - epoch 0, step 28950, training loss = 2.626752, validation loss = 2.290675
2018-12-04 21:57:01,652 - INFO - epoch 0, step 28960, training loss = 2.686297, validation loss = 2.844675
2018-12-04 21:57:07,072 - INFO - epoch 0, step 28970, training loss = 2.709074, validation loss = 3.122664
2018-12-04 21:57:12,497 - INFO - epoch 0, step 28980, training loss = 2.759117, validation loss = 2.581681
2018-12-04 21:57:17,815 - INFO - epoch 0, step 28990, training loss = 2.453894, validation loss = 2.913620
2018-12-04 21:57:23,432 - INFO - epoch 0, step 29000, training loss = 2.531162, validation loss = 2.661440
2018-12-04 21:57:28,550 - INFO - epoch 0, step 29010, training loss = 2.680197, validation loss = 2.707396
2018-12-04 21:57:33,898 - INFO - epoch 0, step 29020, training loss = 2.396102, validation loss = 2.910522
2018-12-04 21:57:39,281 - INFO - epoch 0, step 29030, training loss = 2.821741, validation loss = 2.899209
2018-12-04 21:57:44,365 - INFO - epoch 0, step 29040, training loss = 2.853457, validation loss = 3.151492
2018-12-04 21:57:49,671 - INFO - epoch 0, step 29050, training loss = 2.534609, validation loss = 3.046138
2018-12-04 21:57:54,225 - INFO - epoch 0, step 29060, training loss = 2.146836, validation loss = 2.621682
2018-12-04 21:57:58,738 - INFO - epoch 0, step 29070, training loss = 2.649207, validation loss = 2.719505
2018-12-04 21:58:03,226 - INFO - epoch 0, step 29080, training loss = 2.300330, validation loss = 2.698419
2018-12-04 21:58:07,619 - INFO - epoch 0, step 29090, training loss = 2.601070, validation loss = 2.364279
2018-12-04 21:58:11,995 - INFO - epoch 0, step 29100, training loss = 2.240004, validation loss = 2.446413
2018-12-04 21:58:16,317 - INFO - epoch 0, step 29110, training loss = 2.546522, validation loss = 2.535262
2018-12-04 21:58:21,981 - INFO - epoch 0, step 29120, training loss = 2.323912, validation loss = 2.391854
2018-12-04 21:58:27,983 - INFO - epoch 0, step 29130, training loss = 2.625216, validation loss = 2.389761
2018-12-04 21:58:33,641 - INFO - epoch 0, step 29140, training loss = 2.506835, validation loss = 2.389856
2018-12-04 21:58:39,226 - INFO - epoch 0, step 29150, training loss = 2.454399, validation loss = 2.667727
2018-12-04 21:58:44,825 - INFO - epoch 0, step 29160, training loss = 2.020647, validation loss = 2.599818
2018-12-04 21:58:50,635 - INFO - epoch 0, step 29170, training loss = 2.554231, validation loss = 2.529748
2018-12-04 21:58:56,478 - INFO - epoch 0, step 29180, training loss = 2.028502, validation loss = 2.315368
2018-12-04 21:59:02,727 - INFO - epoch 0, step 29190, training loss = 1.859685, validation loss = 2.750727
2018-12-04 21:59:08,430 - INFO - epoch 0, step 29200, training loss = 2.110414, validation loss = 2.719358
2018-12-04 21:59:14,786 - INFO - epoch 0, step 29210, training loss = 2.380058, validation loss = 2.518931
2018-12-04 21:59:20,386 - INFO - epoch 0, step 29220, training loss = 2.648856, validation loss = 2.848368
2018-12-04 21:59:25,742 - INFO - epoch 0, step 29230, training loss = 2.426097, validation loss = 2.588812
2018-12-04 21:59:31,474 - INFO - epoch 0, step 29240, training loss = 2.202629, validation loss = 2.530720
2018-12-04 21:59:36,660 - INFO - epoch 0, step 29250, training loss = 2.478102, validation loss = 2.705850
2018-12-04 21:59:42,109 - INFO - epoch 0, step 29260, training loss = 2.596685, validation loss = 2.771982
2018-12-04 21:59:47,600 - INFO - epoch 0, step 29270, training loss = 2.666381, validation loss = 2.684139
2018-12-04 21:59:53,216 - INFO - epoch 0, step 29280, training loss = 2.482409, validation loss = 2.418611
2018-12-04 21:59:58,410 - INFO - epoch 0, step 29290, training loss = 2.658113, validation loss = 2.482439
2018-12-04 22:00:03,616 - INFO - epoch 0, step 29300, training loss = 2.738706, validation loss = 2.876568
2018-12-04 22:00:08,748 - INFO - epoch 0, step 29310, training loss = 2.899821, validation loss = 2.633723
2018-12-04 22:00:14,027 - INFO - epoch 0, step 29320, training loss = 2.637706, validation loss = 2.731912
2018-12-04 22:00:19,311 - INFO - epoch 0, step 29330, training loss = 2.859701, validation loss = 2.280346
2018-12-04 22:00:24,514 - INFO - epoch 0, step 29340, training loss = 2.557030, validation loss = 2.784861
2018-12-04 22:00:30,256 - INFO - epoch 0, step 29350, training loss = 1.952452, validation loss = 2.908170
2018-12-04 22:00:35,775 - INFO - epoch 0, step 29360, training loss = 2.231727, validation loss = 2.704194
2018-12-04 22:00:40,873 - INFO - epoch 0, step 29370, training loss = 2.110671, validation loss = 2.524860
2018-12-04 22:00:46,525 - INFO - epoch 0, step 29380, training loss = 2.198959, validation loss = 2.682017
2018-12-04 22:00:52,032 - INFO - epoch 0, step 29390, training loss = 2.251512, validation loss = 2.627922
2018-12-04 22:00:57,847 - INFO - epoch 0, step 29400, training loss = 2.386522, validation loss = 2.633177
2018-12-04 22:01:03,313 - INFO - epoch 0, step 29410, training loss = 2.862345, validation loss = 2.686913
2018-12-04 22:01:08,563 - INFO - epoch 0, step 29420, training loss = 2.497462, validation loss = 2.478023
2018-12-04 22:01:14,125 - INFO - epoch 0, step 29430, training loss = 2.375485, validation loss = 2.679825
2018-12-04 22:01:19,440 - INFO - epoch 0, step 29440, training loss = 2.478674, validation loss = 2.408560
2018-12-04 22:01:24,987 - INFO - epoch 0, step 29450, training loss = 2.640992, validation loss = 2.544076
2018-12-04 22:01:30,466 - INFO - epoch 0, step 29460, training loss = 2.399685, validation loss = 2.429092
2018-12-04 22:01:35,672 - INFO - epoch 0, step 29470, training loss = 2.756110, validation loss = 2.256311
2018-12-04 22:01:40,959 - INFO - epoch 0, step 29480, training loss = 2.487368, validation loss = 2.837412
2018-12-04 22:01:46,263 - INFO - epoch 0, step 29490, training loss = 2.507006, validation loss = 2.469126
2018-12-04 22:01:51,308 - INFO - epoch 0, step 29500, training loss = 2.848218, validation loss = 2.563357
2018-12-04 22:01:57,165 - INFO - epoch 0, step 29510, training loss = 2.157947, validation loss = 2.748309
2018-12-04 22:02:02,549 - INFO - epoch 0, step 29520, training loss = 2.178658, validation loss = 2.385876
2018-12-04 22:02:07,744 - INFO - epoch 0, step 29530, training loss = 2.541489, validation loss = 2.304222
2018-12-04 22:02:13,656 - INFO - epoch 0, step 29540, training loss = 2.710213, validation loss = 2.328244
2018-12-04 22:02:18,872 - INFO - epoch 0, step 29550, training loss = 2.723541, validation loss = 2.531767
2018-12-04 22:02:24,528 - INFO - epoch 0, step 29560, training loss = 2.244910, validation loss = 2.393179
2018-12-04 22:02:30,197 - INFO - epoch 0, step 29570, training loss = 2.289593, validation loss = 2.580087
2018-12-04 22:02:35,500 - INFO - epoch 0, step 29580, training loss = 2.572774, validation loss = 2.868047
2018-12-04 22:02:40,976 - INFO - epoch 0, step 29590, training loss = 2.775666, validation loss = 2.649982
2018-12-04 22:02:46,084 - INFO - epoch 0, step 29600, training loss = 2.398945, validation loss = 2.591969
2018-12-04 22:02:51,427 - INFO - epoch 0, step 29610, training loss = 2.333102, validation loss = 2.661840
2018-12-04 22:02:56,931 - INFO - epoch 0, step 29620, training loss = 2.327092, validation loss = 2.484938
2018-12-04 22:03:02,213 - INFO - epoch 0, step 29630, training loss = 2.242174, validation loss = 2.476124
2018-12-04 22:03:07,794 - INFO - epoch 0, step 29640, training loss = 2.690990, validation loss = 2.675115
2018-12-04 22:03:13,126 - INFO - epoch 0, step 29650, training loss = 2.598033, validation loss = 2.385824
2018-12-04 22:03:18,497 - INFO - epoch 0, step 29660, training loss = 2.116277, validation loss = 2.610421
2018-12-04 22:03:23,583 - INFO - epoch 0, step 29670, training loss = 2.730555, validation loss = 2.908468
2018-12-04 22:03:28,949 - INFO - epoch 0, step 29680, training loss = 2.437108, validation loss = 2.891633
2018-12-04 22:03:34,193 - INFO - epoch 0, step 29690, training loss = 2.778257, validation loss = 2.545959
2018-12-04 22:03:38,901 - INFO - epoch 0, step 29700, training loss = 2.701363, validation loss = 2.640656
2018-12-04 22:03:43,019 - INFO - epoch 0, step 29710, training loss = 2.400168, validation loss = 2.711270
2018-12-04 22:03:47,463 - INFO - epoch 0, step 29720, training loss = 2.658448, validation loss = 2.593825
2018-12-04 22:03:52,274 - INFO - epoch 0, step 29730, training loss = 2.358510, validation loss = 2.444216
2018-12-04 22:03:56,636 - INFO - epoch 0, step 29740, training loss = 2.446966, validation loss = 2.458944
2018-12-04 22:04:00,934 - INFO - epoch 0, step 29750, training loss = 2.448111, validation loss = 2.235727
2018-12-04 22:04:05,698 - INFO - epoch 0, step 29760, training loss = 2.293170, validation loss = 2.519591
2018-12-04 22:04:11,026 - INFO - epoch 0, step 29770, training loss = 2.464482, validation loss = 2.569226
2018-12-04 22:04:16,146 - INFO - epoch 0, step 29780, training loss = 2.561348, validation loss = 2.707723
2018-12-04 22:04:21,194 - INFO - epoch 0, step 29790, training loss = 2.471523, validation loss = 2.454075
2018-12-04 22:04:26,324 - INFO - epoch 0, step 29800, training loss = 2.362321, validation loss = 2.540585
2018-12-04 22:04:31,788 - INFO - epoch 0, step 29810, training loss = 2.285757, validation loss = 2.733672
2018-12-04 22:04:36,976 - INFO - epoch 0, step 29820, training loss = 2.445044, validation loss = 2.791806
2018-12-04 22:04:42,062 - INFO - epoch 0, step 29830, training loss = 2.655580, validation loss = 2.880908
2018-12-04 22:04:47,897 - INFO - epoch 0, step 29840, training loss = 2.553135, validation loss = 3.033778
2018-12-04 22:04:53,132 - INFO - epoch 0, step 29850, training loss = 2.236617, validation loss = 2.907328
2018-12-04 22:04:58,569 - INFO - epoch 0, step 29860, training loss = 2.746088, validation loss = 3.071952
2018-12-04 22:05:03,699 - INFO - epoch 0, step 29870, training loss = 2.481522, validation loss = 3.015882
2018-12-04 22:05:09,494 - INFO - epoch 0, step 29880, training loss = 2.723242, validation loss = 2.580219
2018-12-04 22:05:14,876 - INFO - epoch 0, step 29890, training loss = 2.494851, validation loss = 2.766512
2018-12-04 22:05:20,287 - INFO - epoch 0, step 29900, training loss = 2.700294, validation loss = 2.590211
2018-12-04 22:05:25,565 - INFO - epoch 0, step 29910, training loss = 2.566265, validation loss = 3.081282
2018-12-04 22:05:30,828 - INFO - epoch 0, step 29920, training loss = 2.548470, validation loss = 2.453089
2018-12-04 22:05:36,071 - INFO - epoch 0, step 29930, training loss = 2.307670, validation loss = 2.980488
2018-12-04 22:05:41,417 - INFO - epoch 0, step 29940, training loss = 2.301206, validation loss = 2.897068
2018-12-04 22:05:46,758 - INFO - epoch 0, step 29950, training loss = 2.625731, validation loss = 2.696008
2018-12-04 22:05:52,128 - INFO - epoch 0, step 29960, training loss = 3.131634, validation loss = 2.711339
2018-12-04 22:05:57,328 - INFO - epoch 0, step 29970, training loss = 2.316744, validation loss = 3.094954
2018-12-04 22:06:02,661 - INFO - epoch 0, step 29980, training loss = 2.356632, validation loss = 2.721678
2018-12-04 22:06:07,906 - INFO - epoch 0, step 29990, training loss = 2.418221, validation loss = 2.602431
2018-12-04 22:06:13,539 - INFO - epoch 0, step 30000, training loss = 2.316523, validation loss = 2.537330
2018-12-04 22:06:18,855 - INFO - epoch 0, step 30010, training loss = 2.690724, validation loss = 2.531420
2018-12-04 22:06:23,974 - INFO - epoch 0, step 30020, training loss = 2.625601, validation loss = 2.719081
2018-12-04 22:06:29,296 - INFO - epoch 0, step 30030, training loss = 2.446667, validation loss = 2.600610
2018-12-04 22:06:34,549 - INFO - epoch 0, step 30040, training loss = 2.495838, validation loss = 3.068991
2018-12-04 22:06:39,737 - INFO - epoch 0, step 30050, training loss = 2.196791, validation loss = 3.202574
2018-12-04 22:06:44,637 - INFO - epoch 0, step 30060, training loss = 2.467647, validation loss = 2.745042
2018-12-04 22:06:49,185 - INFO - epoch 0, step 30070, training loss = 2.167863, validation loss = 2.218967
2018-12-04 22:06:53,501 - INFO - epoch 0, step 30080, training loss = 2.477859, validation loss = 2.784590
2018-12-04 22:06:57,799 - INFO - epoch 0, step 30090, training loss = 2.582779, validation loss = 2.810832
2018-12-04 22:07:01,949 - INFO - epoch 0, step 30100, training loss = 2.926572, validation loss = 2.607044
2018-12-04 22:07:05,717 - INFO - epoch 0, step 30110, training loss = 2.680962, validation loss = 2.689165
2018-12-04 22:07:09,020 - INFO - epoch 0, step 30120, training loss = 2.589260, validation loss = 2.336765
2018-12-04 22:07:12,185 - INFO - epoch 0, step 30130, training loss = 2.718135, validation loss = 2.346507
2018-12-04 22:07:15,464 - INFO - epoch 0, step 30140, training loss = 2.427238, validation loss = 2.414588
2018-12-04 22:07:18,671 - INFO - epoch 0, step 30150, training loss = 2.231285, validation loss = 2.648702
2018-12-04 22:07:21,876 - INFO - epoch 0, step 30160, training loss = 2.646509, validation loss = 2.498983
2018-12-04 22:07:25,082 - INFO - epoch 0, step 30170, training loss = 2.599545, validation loss = 2.667924
2018-12-04 22:07:28,372 - INFO - epoch 0, step 30180, training loss = 2.197654, validation loss = 2.324492
2018-12-04 22:07:31,719 - INFO - epoch 0, step 30190, training loss = 2.315397, validation loss = 2.733048
2018-12-04 22:07:35,162 - INFO - epoch 0, step 30200, training loss = 2.838293, validation loss = 2.776616
2018-12-04 22:07:38,449 - INFO - epoch 0, step 30210, training loss = 2.853571, validation loss = 2.434312
2018-12-04 22:07:43,335 - INFO - epoch 0, step 30220, training loss = 2.492474, validation loss = 2.643108
2018-12-04 22:07:48,449 - INFO - epoch 0, step 30230, training loss = 2.920642, validation loss = 2.794782
2018-12-04 22:07:54,127 - INFO - epoch 0, step 30240, training loss = 2.797329, validation loss = 3.002632
2018-12-04 22:07:59,171 - INFO - epoch 0, step 30250, training loss = 2.563718, validation loss = 2.699496
2018-12-04 22:08:04,140 - INFO - epoch 0, step 30260, training loss = 2.198726, validation loss = 2.380186
2018-12-04 22:08:09,191 - INFO - epoch 0, step 30270, training loss = 2.413532, validation loss = 2.555045
2018-12-04 22:08:14,516 - INFO - epoch 0, step 30280, training loss = 2.842305, validation loss = 2.443448
2018-12-04 22:08:19,634 - INFO - epoch 0, step 30290, training loss = 2.193366, validation loss = 2.613606
2018-12-04 22:08:24,918 - INFO - epoch 0, step 30300, training loss = 2.399823, validation loss = 2.893168
2018-12-04 22:08:30,101 - INFO - epoch 0, step 30310, training loss = 2.457839, validation loss = 2.931010
2018-12-04 22:08:35,099 - INFO - epoch 0, step 30320, training loss = 2.722012, validation loss = 2.786838
2018-12-04 22:08:40,199 - INFO - epoch 0, step 30330, training loss = 2.183120, validation loss = 2.440124
2018-12-04 22:08:45,469 - INFO - epoch 0, step 30340, training loss = 2.378716, validation loss = 2.813819
2018-12-04 22:08:50,531 - INFO - epoch 0, step 30350, training loss = 2.563027, validation loss = 2.688236
2018-12-04 22:08:56,268 - INFO - epoch 0, step 30360, training loss = 2.614327, validation loss = 2.641080
2018-12-04 22:09:02,039 - INFO - epoch 0, step 30370, training loss = 2.400227, validation loss = 2.899531
2018-12-04 22:09:07,340 - INFO - epoch 0, step 30380, training loss = 2.455669, validation loss = 2.763577
2018-12-04 22:09:13,156 - INFO - epoch 0, step 30390, training loss = 2.333343, validation loss = 2.403719
2018-12-04 22:09:19,530 - INFO - epoch 0, step 30400, training loss = 1.636131, validation loss = 2.506140
2018-12-04 22:09:25,654 - INFO - epoch 0, step 30410, training loss = 1.543600, validation loss = 2.574967
2018-12-04 22:09:31,111 - INFO - epoch 0, step 30420, training loss = 1.984989, validation loss = 2.424571
2018-12-04 22:09:37,106 - INFO - epoch 0, step 30430, training loss = 1.971403, validation loss = 3.465058
2018-12-04 22:09:42,610 - INFO - epoch 0, step 30440, training loss = 2.311310, validation loss = 2.631972
2018-12-04 22:09:47,898 - INFO - epoch 0, step 30450, training loss = 2.233160, validation loss = 2.665440
2018-12-04 22:09:53,523 - INFO - epoch 0, step 30460, training loss = 1.788888, validation loss = 2.676773
2018-12-04 22:09:59,168 - INFO - epoch 0, step 30470, training loss = 2.358732, validation loss = 2.942058
2018-12-04 22:10:04,731 - INFO - epoch 0, step 30480, training loss = 1.944265, validation loss = 2.939400
2018-12-04 22:10:10,036 - INFO - epoch 0, step 30490, training loss = 2.617858, validation loss = 2.845898
2018-12-04 22:10:15,483 - INFO - epoch 0, step 30500, training loss = 2.478325, validation loss = 2.628651
2018-12-04 22:10:21,382 - INFO - epoch 0, step 30510, training loss = 1.920535, validation loss = 2.070505
2018-12-04 22:10:26,928 - INFO - epoch 0, step 30520, training loss = 2.646322, validation loss = 2.538006
2018-12-04 22:10:31,986 - INFO - epoch 0, step 30530, training loss = 2.545255, validation loss = 2.681701
2018-12-04 22:10:37,430 - INFO - epoch 0, step 30540, training loss = 2.190926, validation loss = 2.477642
2018-12-04 22:10:42,836 - INFO - epoch 0, step 30550, training loss = 2.361505, validation loss = 3.112627
2018-12-04 22:10:48,402 - INFO - epoch 0, step 30560, training loss = 2.354597, validation loss = 2.682405
2018-12-04 22:10:54,096 - INFO - epoch 0, step 30570, training loss = 2.699534, validation loss = 2.474552
2018-12-04 22:10:59,669 - INFO - epoch 0, step 30580, training loss = 2.130081, validation loss = 2.824917
2018-12-04 22:11:05,188 - INFO - epoch 0, step 30590, training loss = 2.030949, validation loss = 2.414026
2018-12-04 22:11:10,459 - INFO - epoch 0, step 30600, training loss = 2.391876, validation loss = 2.606380
2018-12-04 22:11:16,469 - INFO - epoch 0, step 30610, training loss = 2.247249, validation loss = 2.745363
2018-12-04 22:11:21,846 - INFO - epoch 0, step 30620, training loss = 2.150044, validation loss = 2.522407
2018-12-04 22:11:28,238 - INFO - epoch 0, step 30630, training loss = 2.145982, validation loss = 2.745372
2018-12-04 22:11:34,236 - INFO - epoch 0, step 30640, training loss = 2.155113, validation loss = 3.167295
2018-12-04 22:11:39,557 - INFO - epoch 0, step 30650, training loss = 2.249638, validation loss = 3.036520
2018-12-04 22:11:45,469 - INFO - epoch 0, step 30660, training loss = 2.121529, validation loss = 2.727189
2018-12-04 22:11:51,071 - INFO - epoch 0, step 30670, training loss = 2.353586, validation loss = 2.781090
2018-12-04 22:11:56,660 - INFO - epoch 0, step 30680, training loss = 2.380048, validation loss = 2.243691
2018-12-04 22:12:02,445 - INFO - epoch 0, step 30690, training loss = 2.234683, validation loss = 3.095526
2018-12-04 22:12:08,318 - INFO - epoch 0, step 30700, training loss = 1.820907, validation loss = 2.710793
2018-12-04 22:12:14,019 - INFO - epoch 0, step 30710, training loss = 2.205973, validation loss = 3.080014
2018-12-04 22:12:19,586 - INFO - epoch 0, step 30720, training loss = 2.604013, validation loss = 2.621666
2018-12-04 22:12:24,943 - INFO - epoch 0, step 30730, training loss = 2.182410, validation loss = 2.582101
2018-12-04 22:12:30,789 - INFO - epoch 0, step 30740, training loss = 2.210495, validation loss = 2.733325
2018-12-04 22:12:35,317 - INFO - epoch 0, step 30750, training loss = 4.052496, validation loss = 2.527878
2018-12-04 22:12:38,088 - INFO - epoch 0, step 30760, training loss = 2.471507, validation loss = 2.760338
2018-12-04 22:12:40,868 - INFO - epoch 0, step 30770, training loss = 3.584698, validation loss = 3.374374
2018-12-04 22:12:43,823 - INFO - epoch 0, step 30780, training loss = 2.520596, validation loss = 2.774876
2018-12-04 22:12:46,639 - INFO - epoch 0, step 30790, training loss = 3.180064, validation loss = 3.203996
2018-12-04 22:12:49,540 - INFO - epoch 0, step 30800, training loss = 2.284253, validation loss = 2.978374
2018-12-04 22:12:52,428 - INFO - epoch 0, step 30810, training loss = 3.169487, validation loss = 2.858450
2018-12-04 22:12:55,293 - INFO - epoch 0, step 30820, training loss = 2.582330, validation loss = 2.674372
2018-12-04 22:12:58,096 - INFO - epoch 0, step 30830, training loss = 2.887892, validation loss = 2.730668
2018-12-04 22:13:01,142 - INFO - epoch 0, step 30840, training loss = 2.356730, validation loss = 3.370859
2018-12-04 22:13:04,767 - INFO - epoch 0, step 30850, training loss = 1.954262, validation loss = 2.876862
2018-12-04 22:13:08,226 - INFO - epoch 0, step 30860, training loss = 2.849577, validation loss = 3.183070
2018-12-04 22:13:11,522 - INFO - epoch 0, step 30870, training loss = 3.009897, validation loss = 2.441654
2018-12-04 22:13:14,697 - INFO - epoch 0, step 30880, training loss = 2.342993, validation loss = 2.708472
2018-12-04 22:13:20,212 - INFO - epoch 0, step 30890, training loss = 2.279485, validation loss = 2.730627
2018-12-04 22:13:25,872 - INFO - epoch 0, step 30900, training loss = 2.322661, validation loss = 2.779419
2018-12-04 22:13:31,091 - INFO - epoch 0, step 30910, training loss = 2.599034, validation loss = 2.465244
2018-12-04 22:13:36,697 - INFO - epoch 0, step 30920, training loss = 2.713068, validation loss = 2.482818
2018-12-04 22:13:41,943 - INFO - epoch 0, step 30930, training loss = 2.377504, validation loss = 2.500044
2018-12-04 22:13:47,179 - INFO - epoch 0, step 30940, training loss = 2.269453, validation loss = 2.415213
2018-12-04 22:13:52,805 - INFO - epoch 0, step 30950, training loss = 2.455055, validation loss = 2.653139
2018-12-04 22:13:58,874 - INFO - epoch 0, step 30960, training loss = 2.307768, validation loss = 3.016527
2018-12-04 22:14:05,036 - INFO - epoch 0, step 30970, training loss = 2.805988, validation loss = 2.994065
2018-12-04 22:14:10,701 - INFO - epoch 0, step 30980, training loss = 2.065170, validation loss = 2.831744
2018-12-04 22:14:16,664 - INFO - epoch 0, step 30990, training loss = 2.303395, validation loss = 2.703799
2018-12-04 22:14:22,641 - INFO - epoch 0, step 31000, training loss = 1.992384, validation loss = 2.550798
2018-12-04 22:14:28,768 - INFO - epoch 0, step 31010, training loss = 2.437368, validation loss = 2.709626
2018-12-04 22:14:34,348 - INFO - epoch 0, step 31020, training loss = 2.172318, validation loss = 2.623372
2018-12-04 22:14:40,236 - INFO - epoch 0, step 31030, training loss = 2.428921, validation loss = 2.600329
2018-12-04 22:14:45,650 - INFO - epoch 0, step 31040, training loss = 2.815413, validation loss = 2.925090
2018-12-04 22:14:51,912 - INFO - epoch 0, step 31050, training loss = 1.897901, validation loss = 2.410212
2018-12-04 22:14:57,539 - INFO - epoch 0, step 31060, training loss = 3.006808, validation loss = 2.009463
2018-12-04 22:15:00,724 - INFO - epoch 0, step 31070, training loss = 2.506093, validation loss = 2.584479
2018-12-04 22:15:04,055 - INFO - epoch 0, step 31080, training loss = 2.540414, validation loss = 2.601156
2018-12-04 22:15:07,347 - INFO - epoch 0, step 31090, training loss = 2.840441, validation loss = 3.024155
2018-12-04 22:15:10,621 - INFO - epoch 0, step 31100, training loss = 2.644028, validation loss = 2.997416
2018-12-04 22:15:13,874 - INFO - epoch 0, step 31110, training loss = 2.724663, validation loss = 2.919529
2018-12-04 22:15:17,178 - INFO - epoch 0, step 31120, training loss = 3.303491, validation loss = 2.721229
2018-12-04 22:15:20,499 - INFO - epoch 0, step 31130, training loss = 2.490192, validation loss = 2.663482
2018-12-04 22:15:23,682 - INFO - epoch 0, step 31140, training loss = 2.649119, validation loss = 3.217104
2018-12-04 22:15:27,028 - INFO - epoch 0, step 31150, training loss = 2.592417, validation loss = 2.505832
2018-12-04 22:15:30,182 - INFO - epoch 0, step 31160, training loss = 2.539037, validation loss = 2.511884
2018-12-04 22:15:33,523 - INFO - epoch 0, step 31170, training loss = 2.834029, validation loss = 2.877621
2018-12-04 22:15:36,919 - INFO - epoch 0, step 31180, training loss = 2.745566, validation loss = 3.374002
2018-12-04 22:15:40,203 - INFO - epoch 0, step 31190, training loss = 2.696099, validation loss = 2.590044
2018-12-04 22:15:44,305 - INFO - epoch 0, step 31200, training loss = 2.720338, validation loss = 3.030415
2018-12-04 22:15:48,365 - INFO - epoch 0, step 31210, training loss = 2.367633, validation loss = 2.453230
2018-12-04 22:15:52,454 - INFO - epoch 0, step 31220, training loss = 2.534911, validation loss = 2.455755
2018-12-04 22:15:56,572 - INFO - epoch 0, step 31230, training loss = 2.718576, validation loss = 2.856316
2018-12-04 22:16:00,774 - INFO - epoch 0, step 31240, training loss = 2.517560, validation loss = 2.785795
2018-12-04 22:16:05,219 - INFO - epoch 0, step 31250, training loss = 2.643022, validation loss = 2.808411
2018-12-04 22:16:08,844 - INFO - epoch 0, step 31260, training loss = 2.225442, validation loss = 2.777315
2018-12-04 22:16:12,622 - INFO - epoch 0, step 31270, training loss = 2.136577, validation loss = 2.751931
2018-12-04 22:16:16,356 - INFO - epoch 0, step 31280, training loss = 2.296565, validation loss = 2.272990
2018-12-04 22:16:20,417 - INFO - epoch 0, step 31290, training loss = 2.146171, validation loss = 2.655827
2018-12-04 22:16:24,012 - INFO - epoch 0, step 31300, training loss = 2.873103, validation loss = 2.984626
2018-12-04 22:16:26,595 - INFO - epoch 0, step 31310, training loss = 2.041103, validation loss = 2.460842
2018-12-04 22:16:29,194 - INFO - epoch 0, step 31320, training loss = 2.331143, validation loss = 2.636356
2018-12-04 22:16:31,706 - INFO - epoch 0, step 31330, training loss = 3.132006, validation loss = 2.995144
2018-12-04 22:16:34,152 - INFO - epoch 0, step 31340, training loss = 2.160146, validation loss = 2.828701
2018-12-04 22:16:36,726 - INFO - epoch 0, step 31350, training loss = 1.997467, validation loss = 2.551169
2018-12-04 22:16:39,231 - INFO - epoch 0, step 31360, training loss = 2.821558, validation loss = 2.530420
2018-12-04 22:16:41,763 - INFO - epoch 0, step 31370, training loss = 2.646135, validation loss = 2.852665
2018-12-04 22:16:44,279 - INFO - epoch 0, step 31380, training loss = 2.856530, validation loss = 2.666811
2018-12-04 22:16:46,920 - INFO - epoch 0, step 31390, training loss = 2.914431, validation loss = 3.218965
2018-12-04 22:16:49,513 - INFO - epoch 0, step 31400, training loss = 2.474082, validation loss = 3.011663
2018-12-04 22:16:52,093 - INFO - epoch 0, step 31410, training loss = 3.364632, validation loss = 2.678351
2018-12-04 22:16:54,640 - INFO - epoch 0, step 31420, training loss = 2.241491, validation loss = 2.680111
2018-12-04 22:16:57,049 - INFO - epoch 0, step 31430, training loss = 2.704755, validation loss = 3.219174
2018-12-04 22:16:59,490 - INFO - epoch 0, step 31440, training loss = 2.919210, validation loss = 2.897389
2018-12-04 22:17:02,455 - INFO - epoch 0, step 31450, training loss = 2.794749, validation loss = 3.026317
2018-12-04 22:17:05,755 - INFO - epoch 0, step 31460, training loss = 2.644038, validation loss = 2.856779
2018-12-04 22:17:09,035 - INFO - epoch 0, step 31470, training loss = 2.692960, validation loss = 2.706826
2018-12-04 22:17:12,250 - INFO - epoch 0, step 31480, training loss = 3.016802, validation loss = 2.952910
2018-12-04 22:17:15,462 - INFO - epoch 0, step 31490, training loss = 2.312011, validation loss = 2.789466
2018-12-04 22:17:18,890 - INFO - epoch 0, step 31500, training loss = 2.635041, validation loss = 2.806530
2018-12-04 22:17:22,215 - INFO - epoch 0, step 31510, training loss = 2.740129, validation loss = 2.536579
2018-12-04 22:17:25,451 - INFO - epoch 0, step 31520, training loss = 2.754577, validation loss = 2.751985
2018-12-04 22:17:28,772 - INFO - epoch 0, step 31530, training loss = 2.254983, validation loss = 2.463564
2018-12-04 22:17:32,153 - INFO - epoch 0, step 31540, training loss = 2.920434, validation loss = 2.443056
2018-12-04 22:17:35,568 - INFO - epoch 0, step 31550, training loss = 2.716374, validation loss = 2.540953
2018-12-04 22:17:38,886 - INFO - epoch 0, step 31560, training loss = 2.712224, validation loss = 2.716911
2018-12-04 22:17:42,671 - INFO - epoch 0, step 31570, training loss = 2.974371, validation loss = 2.761133
2018-12-04 22:17:48,024 - INFO - epoch 0, step 31580, training loss = 2.932535, validation loss = 2.830077
2018-12-04 22:17:53,243 - INFO - epoch 0, step 31590, training loss = 2.656035, validation loss = 2.325981
2018-12-04 22:17:58,279 - INFO - epoch 0, step 31600, training loss = 2.685242, validation loss = 2.511237
2018-12-04 22:18:03,336 - INFO - epoch 0, step 31610, training loss = 2.635824, validation loss = 2.871316
2018-12-04 22:18:08,629 - INFO - epoch 0, step 31620, training loss = 2.222298, validation loss = 2.651001
2018-12-04 22:18:13,784 - INFO - epoch 0, step 31630, training loss = 2.853526, validation loss = 2.704857
2018-12-04 22:18:19,074 - INFO - epoch 0, step 31640, training loss = 2.480924, validation loss = 2.578995
2018-12-04 22:18:24,291 - INFO - epoch 0, step 31650, training loss = 2.156185, validation loss = 2.382411
2018-12-04 22:18:29,378 - INFO - epoch 0, step 31660, training loss = 2.387561, validation loss = 2.726029
2018-12-04 22:18:35,110 - INFO - epoch 0, step 31670, training loss = 2.714163, validation loss = 2.808179
2018-12-04 22:18:40,363 - INFO - epoch 0, step 31680, training loss = 2.526765, validation loss = 2.772308
2018-12-04 22:18:45,678 - INFO - epoch 0, step 31690, training loss = 2.249401, validation loss = 2.955348
2018-12-04 22:18:51,037 - INFO - epoch 0, step 31700, training loss = 2.778389, validation loss = 2.298069
2018-12-04 22:18:56,288 - INFO - epoch 0, step 31710, training loss = 2.491181, validation loss = 2.337871
2018-12-04 22:19:01,688 - INFO - epoch 0, step 31720, training loss = 2.553554, validation loss = 2.596327
2018-12-04 22:19:06,844 - INFO - epoch 0, step 31730, training loss = 2.313360, validation loss = 2.591613
2018-12-04 22:19:12,041 - INFO - epoch 0, step 31740, training loss = 2.557682, validation loss = 3.054977
2018-12-04 22:19:17,316 - INFO - epoch 0, step 31750, training loss = 3.163462, validation loss = 2.502872
2018-12-04 22:19:22,626 - INFO - epoch 0, step 31760, training loss = 2.548714, validation loss = 2.939583
2018-12-04 22:19:27,836 - INFO - epoch 0, step 31770, training loss = 2.338891, validation loss = 2.187552
2018-12-04 22:19:33,518 - INFO - epoch 0, step 31780, training loss = 2.764898, validation loss = 2.588047
2018-12-04 22:19:37,428 - INFO - epoch 0, step 31790, training loss = 3.361827, validation loss = 2.413774
2018-12-04 22:19:39,775 - INFO - epoch 0, step 31800, training loss = 2.698527, validation loss = 2.925575
2018-12-04 22:19:42,224 - INFO - epoch 0, step 31810, training loss = 2.779097, validation loss = 3.221624
2018-12-04 22:19:44,657 - INFO - epoch 0, step 31820, training loss = 2.550193, validation loss = 2.646353
2018-12-04 22:19:47,066 - INFO - epoch 0, step 31830, training loss = 2.211221, validation loss = 2.843203
2018-12-04 22:19:49,505 - INFO - epoch 0, step 31840, training loss = 2.667162, validation loss = 2.827568
2018-12-04 22:19:51,908 - INFO - epoch 0, step 31850, training loss = 2.395181, validation loss = 3.347712
2018-12-04 22:19:54,309 - INFO - epoch 0, step 31860, training loss = 2.823932, validation loss = 3.313357
2018-12-04 22:19:56,837 - INFO - epoch 0, step 31870, training loss = 2.326340, validation loss = 2.500211
2018-12-04 22:19:59,205 - INFO - epoch 0, step 31880, training loss = 2.679452, validation loss = 2.566781
2018-12-04 22:20:01,646 - INFO - epoch 0, step 31890, training loss = 2.496632, validation loss = 2.762455
2018-12-04 22:20:04,111 - INFO - epoch 0, step 31900, training loss = 2.941966, validation loss = 3.342050
2018-12-04 22:20:06,682 - INFO - epoch 0, step 31910, training loss = 2.617818, validation loss = 2.768486
2018-12-04 22:20:09,095 - INFO - epoch 0, step 31920, training loss = 2.457917, validation loss = 2.741324
2018-12-04 22:20:11,571 - INFO - epoch 0, step 31930, training loss = 2.723115, validation loss = 2.747611
2018-12-04 22:20:17,195 - INFO - epoch 0, step 31940, training loss = 2.611251, validation loss = 2.836692
2018-12-04 22:20:23,006 - INFO - epoch 0, step 31950, training loss = 2.415159, validation loss = 2.693157
2018-12-04 22:20:29,067 - INFO - epoch 0, step 31960, training loss = 1.950132, validation loss = 2.853032
2018-12-04 22:20:34,903 - INFO - epoch 0, step 31970, training loss = 2.294270, validation loss = 2.770929
2018-12-04 22:20:40,399 - INFO - epoch 0, step 31980, training loss = 2.077111, validation loss = 3.023079
2018-12-04 22:20:46,688 - INFO - epoch 0, step 31990, training loss = 2.367503, validation loss = 2.095107
2018-12-04 22:20:53,262 - INFO - epoch 0, step 32000, training loss = 2.324744, validation loss = 2.522650
2018-12-04 22:20:59,272 - INFO - epoch 0, step 32010, training loss = 1.631541, validation loss = 2.588211
2018-12-04 22:21:05,125 - INFO - epoch 0, step 32020, training loss = 1.972222, validation loss = 2.788425
2018-12-04 22:21:10,751 - INFO - epoch 0, step 32030, training loss = 2.206454, validation loss = 2.828953
2018-12-04 22:21:16,060 - INFO - epoch 0, step 32040, training loss = 2.274301, validation loss = 2.556793
2018-12-04 22:21:21,901 - INFO - epoch 0, step 32050, training loss = 2.764144, validation loss = 2.466267
2018-12-04 22:21:27,920 - INFO - epoch 0, step 32060, training loss = 2.227508, validation loss = 2.757102
2018-12-04 22:21:34,445 - INFO - epoch 0, step 32070, training loss = 1.993276, validation loss = 2.621754
2018-12-04 22:21:40,430 - INFO - epoch 0, step 32080, training loss = 1.999452, validation loss = 2.457412
2018-12-04 22:21:46,008 - INFO - epoch 0, step 32090, training loss = 2.160838, validation loss = 2.433591
2018-12-04 22:21:51,963 - INFO - epoch 0, step 32100, training loss = 1.682423, validation loss = 2.316885
2018-12-04 22:21:57,658 - INFO - epoch 0, step 32110, training loss = 2.395707, validation loss = 2.790261
2018-12-04 22:22:02,969 - INFO - epoch 0, step 32120, training loss = 3.460658, validation loss = 2.967633
2018-12-04 22:22:05,645 - INFO - epoch 0, step 32130, training loss = 2.736805, validation loss = 2.003109
2018-12-04 22:22:08,164 - INFO - epoch 0, step 32140, training loss = 2.546766, validation loss = 2.561316
2018-12-04 22:22:10,653 - INFO - epoch 0, step 32150, training loss = 2.275727, validation loss = 3.026224
2018-12-04 22:22:13,110 - INFO - epoch 0, step 32160, training loss = 2.632509, validation loss = 3.004714
2018-12-04 22:22:15,671 - INFO - epoch 0, step 32170, training loss = 2.196255, validation loss = 3.272665
2018-12-04 22:22:18,195 - INFO - epoch 0, step 32180, training loss = 2.375780, validation loss = 2.554206
2018-12-04 22:22:20,720 - INFO - epoch 0, step 32190, training loss = 2.063061, validation loss = 2.443625
2018-12-04 22:22:23,178 - INFO - epoch 0, step 32200, training loss = 2.554119, validation loss = 2.763794
2018-12-04 22:22:25,753 - INFO - epoch 0, step 32210, training loss = 1.929117, validation loss = 2.565110
2018-12-04 22:22:28,229 - INFO - epoch 0, step 32220, training loss = 2.219755, validation loss = 3.107780
2018-12-04 22:22:30,705 - INFO - epoch 0, step 32230, training loss = 3.100144, validation loss = 3.233313
2018-12-04 22:22:33,328 - INFO - epoch 0, step 32240, training loss = 1.595985, validation loss = 2.775946
2018-12-04 22:22:35,813 - INFO - epoch 0, step 32250, training loss = 2.652076, validation loss = 2.667326
2018-12-04 22:22:38,312 - INFO - epoch 0, step 32260, training loss = 2.405320, validation loss = 2.781168
2018-12-04 22:22:40,759 - INFO - epoch 0, step 32270, training loss = 2.879107, validation loss = 2.675056
2018-12-04 22:22:45,826 - INFO - epoch 0, step 32280, training loss = 2.300909, validation loss = 2.788713
2018-12-04 22:22:51,397 - INFO - epoch 0, step 32290, training loss = 2.423545, validation loss = 2.439413
2018-12-04 22:22:57,158 - INFO - epoch 0, step 32300, training loss = 2.886130, validation loss = 2.856110
2018-12-04 22:23:02,488 - INFO - epoch 0, step 32310, training loss = 2.494201, validation loss = 2.341955
2018-12-04 22:23:07,842 - INFO - epoch 0, step 32320, training loss = 2.486083, validation loss = 2.425353
2018-12-04 22:23:13,163 - INFO - epoch 0, step 32330, training loss = 2.536781, validation loss = 2.369721
2018-12-04 22:23:18,273 - INFO - epoch 0, step 32340, training loss = 2.408981, validation loss = 2.867658
2018-12-04 22:23:23,414 - INFO - epoch 0, step 32350, training loss = 2.602524, validation loss = 2.642050
2018-12-04 22:23:28,712 - INFO - epoch 0, step 32360, training loss = 2.618310, validation loss = 2.320810
2018-12-04 22:23:34,402 - INFO - epoch 0, step 32370, training loss = 2.705884, validation loss = 2.296523
2018-12-04 22:23:39,573 - INFO - epoch 0, step 32380, training loss = 2.896687, validation loss = 2.567440
2018-12-04 22:23:44,534 - INFO - epoch 0, step 32390, training loss = 2.546565, validation loss = 3.026719
2018-12-04 22:23:49,768 - INFO - epoch 0, step 32400, training loss = 2.814326, validation loss = 2.676679
2018-12-04 22:23:54,773 - INFO - epoch 0, step 32410, training loss = 2.354361, validation loss = 2.428531
2018-12-04 22:23:59,754 - INFO - epoch 0, step 32420, training loss = 2.692737, validation loss = 2.661123
2018-12-04 22:24:05,075 - INFO - epoch 0, step 32430, training loss = 2.656472, validation loss = 2.602558
2018-12-04 22:24:10,353 - INFO - epoch 0, step 32440, training loss = 2.329779, validation loss = 3.156438
2018-12-04 22:24:15,459 - INFO - epoch 0, step 32450, training loss = 2.258643, validation loss = 2.267065
2018-12-04 22:24:20,855 - INFO - epoch 0, step 32460, training loss = 2.680696, validation loss = 2.361986
2018-12-04 22:24:25,918 - INFO - epoch 0, step 32470, training loss = 2.636523, validation loss = 2.391576
2018-12-04 22:24:31,286 - INFO - epoch 0, step 32480, training loss = 1.837708, validation loss = 2.689020
2018-12-04 22:24:36,291 - INFO - epoch 0, step 32490, training loss = 2.483071, validation loss = 2.784953
2018-12-04 22:24:41,477 - INFO - epoch 0, step 32500, training loss = 2.881643, validation loss = 2.670748
2018-12-04 22:24:46,643 - INFO - epoch 0, step 32510, training loss = 2.545340, validation loss = 2.487228
2018-12-04 22:24:51,595 - INFO - epoch 0, step 32520, training loss = 2.609114, validation loss = 2.008024
2018-12-04 22:24:55,821 - INFO - epoch 0, step 32530, training loss = 2.489202, validation loss = 2.180061
2018-12-04 22:25:00,271 - INFO - epoch 0, step 32540, training loss = 2.878418, validation loss = 2.290199
2018-12-04 22:25:04,565 - INFO - epoch 0, step 32550, training loss = 2.496891, validation loss = 2.461047
2018-12-04 22:25:08,802 - INFO - epoch 0, step 32560, training loss = 2.423077, validation loss = 2.526338
2018-12-04 22:25:13,056 - INFO - epoch 0, step 32570, training loss = 2.303061, validation loss = 2.294093
2018-12-04 22:25:17,430 - INFO - epoch 0, step 32580, training loss = 2.404908, validation loss = 2.209246
2018-12-04 22:25:21,831 - INFO - epoch 0, step 32590, training loss = 2.110203, validation loss = 2.514736
2018-12-04 22:25:25,083 - INFO - epoch 0, step 32600, training loss = 2.279488, validation loss = 2.756708
2018-12-04 22:25:28,510 - INFO - epoch 0, step 32610, training loss = 2.750944, validation loss = 2.699256
2018-12-04 22:25:32,023 - INFO - epoch 0, step 32620, training loss = 2.193169, validation loss = 2.678947
2018-12-04 22:25:35,322 - INFO - epoch 0, step 32630, training loss = 2.406245, validation loss = 2.502651
2018-12-04 22:25:38,602 - INFO - epoch 0, step 32640, training loss = 2.519973, validation loss = 2.892852
2018-12-04 22:25:41,886 - INFO - epoch 0, step 32650, training loss = 2.222388, validation loss = 2.908931
2018-12-04 22:25:45,272 - INFO - epoch 0, step 32660, training loss = 2.298216, validation loss = 2.932820
2018-12-04 22:25:50,272 - INFO - epoch 0, step 32670, training loss = 2.477625, validation loss = 2.352530
2018-12-04 22:25:55,978 - INFO - epoch 0, step 32680, training loss = 2.226357, validation loss = 2.543696
2018-12-04 22:26:01,530 - INFO - epoch 0, step 32690, training loss = 2.274903, validation loss = 2.725152
2018-12-04 22:26:07,665 - INFO - epoch 0, step 32700, training loss = 2.407561, validation loss = 2.461379
2018-12-04 22:26:13,035 - INFO - epoch 0, step 32710, training loss = 2.268188, validation loss = 2.198198
2018-12-04 22:26:18,298 - INFO - epoch 0, step 32720, training loss = 2.291259, validation loss = 2.218807
2018-12-04 22:26:23,611 - INFO - epoch 0, step 32730, training loss = 2.514643, validation loss = 2.786474
2018-12-04 22:26:28,603 - INFO - epoch 0, step 32740, training loss = 2.573678, validation loss = 3.148236
2018-12-04 22:26:33,787 - INFO - epoch 0, step 32750, training loss = 2.255922, validation loss = 2.796021
2018-12-04 22:26:38,790 - INFO - epoch 0, step 32760, training loss = 2.362436, validation loss = 2.577596
2018-12-04 22:26:43,914 - INFO - epoch 0, step 32770, training loss = 2.299882, validation loss = 2.883482
2018-12-04 22:26:48,877 - INFO - epoch 0, step 32780, training loss = 2.731276, validation loss = 2.767955
2018-12-04 22:26:54,025 - INFO - epoch 0, step 32790, training loss = 2.243855, validation loss = 2.487100
2018-12-04 22:26:59,155 - INFO - epoch 0, step 32800, training loss = 2.544232, validation loss = 2.402590
2018-12-04 22:27:04,514 - INFO - epoch 0, step 32810, training loss = 2.334243, validation loss = 2.607922
2018-12-04 22:27:09,686 - INFO - epoch 0, step 32820, training loss = 3.033266, validation loss = 2.693328
2018-12-04 22:27:14,850 - INFO - epoch 0, step 32830, training loss = 2.442277, validation loss = 2.251465
2018-12-04 22:27:20,285 - INFO - epoch 0, step 32840, training loss = 2.828890, validation loss = 2.052892
2018-12-04 22:27:25,695 - INFO - epoch 0, step 32850, training loss = 2.129164, validation loss = 2.414818
2018-12-04 22:27:30,651 - INFO - epoch 0, step 32860, training loss = 2.717369, validation loss = 2.622166
2018-12-04 22:27:35,984 - INFO - epoch 0, step 32870, training loss = 2.657112, validation loss = 3.104390
2018-12-04 22:27:41,335 - INFO - epoch 0, step 32880, training loss = 2.316400, validation loss = 2.375429
2018-12-04 22:27:46,918 - INFO - epoch 0, step 32890, training loss = 2.204487, validation loss = 2.402513
2018-12-04 22:27:52,311 - INFO - epoch 0, step 32900, training loss = 2.301324, validation loss = 2.832610
2018-12-04 22:27:58,037 - INFO - epoch 0, step 32910, training loss = 1.936241, validation loss = 2.910554
2018-12-04 22:28:03,711 - INFO - epoch 0, step 32920, training loss = 2.385730, validation loss = 2.855658
2018-12-04 22:28:09,437 - INFO - epoch 0, step 32930, training loss = 2.158992, validation loss = 2.657573
2018-12-04 22:28:14,889 - INFO - epoch 0, step 32940, training loss = 2.404101, validation loss = 2.146610
2018-12-04 22:28:21,054 - INFO - epoch 0, step 32950, training loss = 1.760968, validation loss = 2.553181
2018-12-04 22:28:26,945 - INFO - epoch 0, step 32960, training loss = 1.890185, validation loss = 2.933303
2018-12-04 22:28:32,925 - INFO - epoch 0, step 32970, training loss = 1.895521, validation loss = 2.636371
2018-12-04 22:28:39,235 - INFO - epoch 0, step 32980, training loss = 2.624693, validation loss = 2.287773
2018-12-04 22:28:44,720 - INFO - epoch 0, step 32990, training loss = 2.380434, validation loss = 2.201935
2018-12-04 22:28:49,680 - INFO - epoch 0, step 33000, training loss = 2.233037, validation loss = 2.875723
2018-12-04 22:28:53,887 - INFO - epoch 0, step 33010, training loss = 2.551512, validation loss = 2.713356
2018-12-04 22:28:58,528 - INFO - epoch 0, step 33020, training loss = 2.225988, validation loss = 3.002559
2018-12-04 22:29:02,929 - INFO - epoch 0, step 33030, training loss = 2.481416, validation loss = 2.861670
2018-12-04 22:29:07,216 - INFO - epoch 0, step 33040, training loss = 1.986124, validation loss = 2.787783
2018-12-04 22:29:11,664 - INFO - epoch 0, step 33050, training loss = 2.185082, validation loss = 2.373065
2018-12-04 22:29:16,558 - INFO - epoch 0, step 33060, training loss = 2.235662, validation loss = 2.641297
2018-12-04 22:29:20,380 - INFO - epoch 0, step 33070, training loss = 2.433572, validation loss = 2.752816
2018-12-04 22:29:24,141 - INFO - epoch 0, step 33080, training loss = 3.362197, validation loss = 2.657748
2018-12-04 22:29:27,717 - INFO - epoch 0, step 33090, training loss = 2.387848, validation loss = 2.450228
2018-12-04 22:29:31,522 - INFO - epoch 0, step 33100, training loss = 2.677580, validation loss = 2.499423
2018-12-04 22:29:35,311 - INFO - epoch 0, step 33110, training loss = 2.764935, validation loss = 2.696237
2018-12-04 22:29:39,129 - INFO - epoch 0, step 33120, training loss = 2.646058, validation loss = 2.863485
2018-12-04 22:29:42,750 - INFO - epoch 0, step 33130, training loss = 2.866489, validation loss = 2.692905
2018-12-04 22:29:46,710 - INFO - epoch 0, step 33140, training loss = 2.579190, validation loss = 2.340710
2018-12-04 22:29:50,581 - INFO - epoch 0, step 33150, training loss = 3.120756, validation loss = 2.406124
2018-12-04 22:29:54,062 - INFO - epoch 0, step 33160, training loss = 2.720448, validation loss = 2.612653
2018-12-04 22:29:57,850 - INFO - epoch 0, step 33170, training loss = 2.968573, validation loss = 2.146237
2018-12-04 22:30:03,504 - INFO - epoch 0, step 33180, training loss = 2.034199, validation loss = 2.751842
2018-12-04 22:30:09,144 - INFO - epoch 0, step 33190, training loss = 2.298084, validation loss = 2.504689
2018-12-04 22:30:15,037 - INFO - epoch 0, step 33200, training loss = 2.030001, validation loss = 2.446983
2018-12-04 22:30:21,381 - INFO - epoch 0, step 33210, training loss = 2.267218, validation loss = 2.848797
2018-12-04 22:30:26,879 - INFO - epoch 0, step 33220, training loss = 2.461423, validation loss = 2.531721
2018-12-04 22:30:32,071 - INFO - epoch 0, step 33230, training loss = 2.606088, validation loss = 2.481476
2018-12-04 22:30:37,719 - INFO - epoch 0, step 33240, training loss = 1.907508, validation loss = 2.604208
2018-12-04 22:30:43,244 - INFO - epoch 0, step 33250, training loss = 1.962145, validation loss = 1.872066
2018-12-04 22:30:48,836 - INFO - epoch 0, step 33260, training loss = 2.302505, validation loss = 2.337359
2018-12-04 22:30:53,982 - INFO - epoch 0, step 33270, training loss = 2.189680, validation loss = 3.157471
2018-12-04 22:31:00,046 - INFO - epoch 0, step 33280, training loss = 2.213356, validation loss = 2.265596
2018-12-04 22:31:05,717 - INFO - epoch 0, step 33290, training loss = 2.251227, validation loss = 2.114240
2018-12-04 22:31:11,035 - INFO - epoch 0, step 33300, training loss = 2.289013, validation loss = 2.302211
2018-12-04 22:31:17,530 - INFO - epoch 0, step 33310, training loss = 2.575560, validation loss = 2.530345
2018-12-04 22:31:22,979 - INFO - epoch 0, step 33320, training loss = 2.310662, validation loss = 2.509953
2018-12-04 22:31:28,564 - INFO - epoch 0, step 33330, training loss = 1.934561, validation loss = 2.515701
2018-12-04 22:31:34,425 - INFO - epoch 0, step 33340, training loss = 2.124422, validation loss = 2.208688
2018-12-04 22:31:40,267 - INFO - epoch 0, step 33350, training loss = 1.804354, validation loss = 2.936727
2018-12-04 22:31:45,787 - INFO - epoch 0, step 33360, training loss = 3.090025, validation loss = 2.510488
2018-12-04 22:31:50,833 - INFO - epoch 0, step 33370, training loss = 3.061666, validation loss = 2.771458
2018-12-04 22:31:55,796 - INFO - epoch 0, step 33380, training loss = 2.969545, validation loss = 2.358351
2018-12-04 22:32:00,721 - INFO - epoch 0, step 33390, training loss = 2.451460, validation loss = 2.382599
2018-12-04 22:32:05,850 - INFO - epoch 0, step 33400, training loss = 1.980926, validation loss = 2.098925
2018-12-04 22:32:10,945 - INFO - epoch 0, step 33410, training loss = 2.261289, validation loss = 2.227597
2018-12-04 22:32:15,935 - INFO - epoch 0, step 33420, training loss = 2.571909, validation loss = 2.519911
2018-12-04 22:32:20,713 - INFO - epoch 0, step 33430, training loss = 2.674674, validation loss = 2.305103
2018-12-04 22:32:25,464 - INFO - epoch 0, step 33440, training loss = 2.405877, validation loss = 2.337616
2018-12-04 22:32:30,292 - INFO - epoch 0, step 33450, training loss = 2.791888, validation loss = 2.291594
2018-12-04 22:32:34,999 - INFO - epoch 0, step 33460, training loss = 2.280900, validation loss = 2.099862
2018-12-04 22:32:39,910 - INFO - epoch 0, step 33470, training loss = 2.588125, validation loss = 2.649693
2018-12-04 22:32:44,913 - INFO - epoch 0, step 33480, training loss = 2.182496, validation loss = 2.580323
2018-12-04 22:32:50,464 - INFO - epoch 0, step 33490, training loss = 2.394885, validation loss = 2.347862
2018-12-04 22:32:55,724 - INFO - epoch 0, step 33500, training loss = 2.399102, validation loss = 2.640336
2018-12-04 22:33:00,865 - INFO - epoch 0, step 33510, training loss = 2.080108, validation loss = 2.664721
2018-12-04 22:33:05,845 - INFO - epoch 0, step 33520, training loss = 2.476670, validation loss = 2.376649
2018-12-04 22:33:11,352 - INFO - epoch 0, step 33530, training loss = 2.101799, validation loss = 1.985513
2018-12-04 22:33:16,864 - INFO - epoch 0, step 33540, training loss = 2.351027, validation loss = 2.269689
2018-12-04 22:33:21,930 - INFO - epoch 0, step 33550, training loss = 2.714772, validation loss = 2.627347
2018-12-04 22:33:27,214 - INFO - epoch 0, step 33560, training loss = 2.398031, validation loss = 2.444628
2018-12-04 22:33:32,480 - INFO - epoch 0, step 33570, training loss = 2.256277, validation loss = 2.063775
2018-12-04 22:33:37,657 - INFO - epoch 0, step 33580, training loss = 2.484704, validation loss = 2.693401
2018-12-04 22:33:43,267 - INFO - epoch 0, step 33590, training loss = 1.673530, validation loss = 2.881212
2018-12-04 22:33:48,614 - INFO - epoch 0, step 33600, training loss = 2.062880, validation loss = 2.523540
2018-12-04 22:33:55,140 - INFO - epoch 0, step 33610, training loss = 2.490940, validation loss = 2.113079
2018-12-04 22:34:00,688 - INFO - epoch 0, step 33620, training loss = 1.808660, validation loss = 2.559373
2018-12-04 22:34:05,712 - INFO - epoch 0, step 33630, training loss = 2.703391, validation loss = 2.647667
2018-12-04 22:34:11,188 - INFO - epoch 0, step 33640, training loss = 2.413304, validation loss = 2.637511
2018-12-04 22:34:16,416 - INFO - epoch 0, step 33650, training loss = 2.625254, validation loss = 2.446842
2018-12-04 22:34:21,900 - INFO - epoch 0, step 33660, training loss = 2.268981, validation loss = 2.490925
2018-12-04 22:34:27,536 - INFO - epoch 0, step 33670, training loss = 2.343268, validation loss = 2.391045
2018-12-04 22:34:32,856 - INFO - epoch 0, step 33680, training loss = 2.481219, validation loss = 2.998022
2018-12-04 22:34:38,134 - INFO - epoch 0, step 33690, training loss = 2.195060, validation loss = 2.670542
2018-12-04 22:34:43,473 - INFO - epoch 0, step 33700, training loss = 2.271272, validation loss = 2.290541
2018-12-04 22:34:48,624 - INFO - epoch 0, step 33710, training loss = 2.201080, validation loss = 2.794516
2018-12-04 22:34:53,960 - INFO - epoch 0, step 33720, training loss = 2.144500, validation loss = 2.933089
2018-12-04 22:34:59,154 - INFO - epoch 0, step 33730, training loss = 2.388211, validation loss = 2.944459
2018-12-04 22:35:04,396 - INFO - epoch 0, step 33740, training loss = 2.529352, validation loss = 2.381189
2018-12-04 22:35:09,688 - INFO - epoch 0, step 33750, training loss = 2.788280, validation loss = 2.786717
2018-12-04 22:35:14,817 - INFO - epoch 0, step 33760, training loss = 1.995863, validation loss = 2.505471
2018-12-04 22:35:20,238 - INFO - epoch 0, step 33770, training loss = 2.595498, validation loss = 2.427447
2018-12-04 22:35:25,836 - INFO - epoch 0, step 33780, training loss = 2.923435, validation loss = 2.486351
2018-12-04 22:35:31,203 - INFO - epoch 0, step 33790, training loss = 2.272776, validation loss = 2.909387
2018-12-04 22:35:36,521 - INFO - epoch 0, step 33800, training loss = 2.433197, validation loss = 2.333707
2018-12-04 22:35:41,823 - INFO - epoch 0, step 33810, training loss = 2.152446, validation loss = 2.414244
2018-12-04 22:35:47,206 - INFO - epoch 0, step 33820, training loss = 2.521284, validation loss = 2.588860
2018-12-04 22:35:52,775 - INFO - epoch 0, step 33830, training loss = 2.439884, validation loss = 2.673564
2018-12-04 22:35:57,861 - INFO - epoch 0, step 33840, training loss = 2.301466, validation loss = 2.371459
2018-12-04 22:36:03,368 - INFO - epoch 0, step 33850, training loss = 2.647618, validation loss = 2.399253
2018-12-04 22:36:08,746 - INFO - epoch 0, step 33860, training loss = 2.493844, validation loss = 2.520818
2018-12-04 22:36:14,181 - INFO - epoch 0, step 33870, training loss = 2.182464, validation loss = 2.901040
2018-12-04 22:36:19,485 - INFO - epoch 0, step 33880, training loss = 2.475886, validation loss = 2.812393
2018-12-04 22:36:24,700 - INFO - epoch 0, step 33890, training loss = 2.756625, validation loss = 2.476160
2018-12-04 22:36:29,916 - INFO - epoch 0, step 33900, training loss = 2.708450, validation loss = 2.269030
2018-12-04 22:36:35,258 - INFO - epoch 0, step 33910, training loss = 2.697151, validation loss = 2.680190
2018-12-04 22:36:40,491 - INFO - epoch 0, step 33920, training loss = 2.387421, validation loss = 2.762407
2018-12-04 22:36:46,117 - INFO - epoch 0, step 33930, training loss = 2.521930, validation loss = 2.536648
2018-12-04 22:36:51,585 - INFO - epoch 0, step 33940, training loss = 2.251204, validation loss = 2.421084
2018-12-04 22:36:57,013 - INFO - epoch 0, step 33950, training loss = 2.521128, validation loss = 2.530459
2018-12-04 22:37:02,156 - INFO - epoch 0, step 33960, training loss = 2.620554, validation loss = 3.006947
2018-12-04 22:37:07,467 - INFO - epoch 0, step 33970, training loss = 2.448127, validation loss = 2.310687
2018-12-04 22:37:13,637 - INFO - epoch 0, step 33980, training loss = 2.469508, validation loss = 2.347474
2018-12-04 22:37:18,676 - INFO - epoch 0, step 33990, training loss = 2.701218, validation loss = 2.906877
2018-12-04 22:37:23,943 - INFO - epoch 0, step 34000, training loss = 2.636077, validation loss = 2.713422
2018-12-04 22:37:29,321 - INFO - epoch 0, step 34010, training loss = 2.363973, validation loss = 2.104768
2018-12-04 22:37:34,442 - INFO - epoch 0, step 34020, training loss = 2.522082, validation loss = 2.770395
2018-12-04 22:37:39,554 - INFO - epoch 0, step 34030, training loss = 2.631754, validation loss = 2.803060
2018-12-04 22:37:44,749 - INFO - epoch 0, step 34040, training loss = 2.657134, validation loss = 2.618108
2018-12-04 22:37:50,091 - INFO - epoch 0, step 34050, training loss = 2.009349, validation loss = 2.924789
2018-12-04 22:37:55,458 - INFO - epoch 0, step 34060, training loss = 2.519437, validation loss = 2.769742
2018-12-04 22:38:00,516 - INFO - epoch 0, step 34070, training loss = 2.472788, validation loss = 2.689482
2018-12-04 22:38:05,536 - INFO - epoch 0, step 34080, training loss = 2.603407, validation loss = 3.026897
2018-12-04 22:38:09,663 - INFO - epoch 0, step 34090, training loss = 2.775379, validation loss = 2.204411
2018-12-04 22:38:12,325 - INFO - epoch 0, step 34100, training loss = 2.101845, validation loss = 3.123602
2018-12-04 22:38:14,964 - INFO - epoch 0, step 34110, training loss = 3.273307, validation loss = 3.015455
2018-12-04 22:38:17,644 - INFO - epoch 0, step 34120, training loss = 2.336977, validation loss = 2.873970
2018-12-04 22:38:20,238 - INFO - epoch 0, step 34130, training loss = 2.426590, validation loss = 2.795345
2018-12-04 22:38:22,864 - INFO - epoch 0, step 34140, training loss = 2.403206, validation loss = 2.509629
2018-12-04 22:38:25,272 - INFO - epoch 0, step 34150, training loss = 2.958634, validation loss = 2.559475
2018-12-04 22:38:27,817 - INFO - epoch 0, step 34160, training loss = 2.002115, validation loss = 2.846949
2018-12-04 22:38:30,452 - INFO - epoch 0, step 34170, training loss = 2.251170, validation loss = 2.821763
2018-12-04 22:38:33,149 - INFO - epoch 0, step 34180, training loss = 2.719092, validation loss = 2.764485
2018-12-04 22:38:35,670 - INFO - epoch 0, step 34190, training loss = 2.861055, validation loss = 3.289243
2018-12-04 22:38:38,350 - INFO - epoch 0, step 34200, training loss = 1.826405, validation loss = 2.346906
2018-12-04 22:38:40,992 - INFO - epoch 0, step 34210, training loss = 2.092958, validation loss = 2.786968
2018-12-04 22:38:43,490 - INFO - epoch 0, step 34220, training loss = 2.715868, validation loss = 3.251488
2018-12-04 22:38:48,507 - INFO - epoch 0, step 34230, training loss = 2.552427, validation loss = 2.760399
2018-12-04 22:38:53,737 - INFO - epoch 0, step 34240, training loss = 2.261642, validation loss = 3.012816
2018-12-04 22:38:59,305 - INFO - epoch 0, step 34250, training loss = 2.421432, validation loss = 2.756702
2018-12-04 22:39:04,522 - INFO - epoch 0, step 34260, training loss = 2.316253, validation loss = 2.388323
2018-12-04 22:39:09,764 - INFO - epoch 0, step 34270, training loss = 2.372604, validation loss = 2.679379
2018-12-04 22:39:15,348 - INFO - epoch 0, step 34280, training loss = 2.764914, validation loss = 2.629208
2018-12-04 22:39:20,605 - INFO - epoch 0, step 34290, training loss = 2.504924, validation loss = 2.856665
2018-12-04 22:39:25,864 - INFO - epoch 0, step 34300, training loss = 2.987113, validation loss = 3.029074
2018-12-04 22:39:31,053 - INFO - epoch 0, step 34310, training loss = 2.536004, validation loss = 2.632558
2018-12-04 22:39:36,315 - INFO - epoch 0, step 34320, training loss = 2.185314, validation loss = 2.986060
2018-12-04 22:39:41,718 - INFO - epoch 0, step 34330, training loss = 2.261577, validation loss = 3.002179
2018-12-04 22:39:47,048 - INFO - epoch 0, step 34340, training loss = 2.422731, validation loss = 2.609169
2018-12-04 22:39:52,715 - INFO - epoch 0, step 34350, training loss = 2.400015, validation loss = 2.898148
2018-12-04 22:39:58,134 - INFO - epoch 0, step 34360, training loss = 2.098809, validation loss = 3.307546
2018-12-04 22:40:03,402 - INFO - epoch 0, step 34370, training loss = 2.396236, validation loss = 2.977547
2018-12-04 22:40:08,701 - INFO - epoch 0, step 34380, training loss = 2.529914, validation loss = 2.476633
2018-12-04 22:40:14,229 - INFO - epoch 0, step 34390, training loss = 2.736318, validation loss = 3.116646
2018-12-04 22:40:19,406 - INFO - epoch 0, step 34400, training loss = 2.491140, validation loss = 2.766018
2018-12-04 22:40:24,537 - INFO - epoch 0, step 34410, training loss = 2.553615, validation loss = 2.761753
2018-12-04 22:40:29,811 - INFO - epoch 0, step 34420, training loss = 2.612527, validation loss = 2.819932
2018-12-04 22:40:35,076 - INFO - epoch 0, step 34430, training loss = 2.523306, validation loss = 3.198664
2018-12-04 22:40:40,197 - INFO - epoch 0, step 34440, training loss = 2.337045, validation loss = 2.035478
2018-12-04 22:40:45,395 - INFO - epoch 0, step 34450, training loss = 2.611135, validation loss = 3.060903
2018-12-04 22:40:50,774 - INFO - epoch 0, step 34460, training loss = 2.396506, validation loss = 2.633517
2018-12-04 22:40:54,990 - INFO - epoch 0, step 34470, training loss = 2.260220, validation loss = 2.941135
2018-12-04 22:40:58,335 - INFO - epoch 0, step 34480, training loss = 3.280080, validation loss = 2.606582
2018-12-04 22:41:01,716 - INFO - epoch 0, step 34490, training loss = 2.006379, validation loss = 2.692679
2018-12-04 22:41:05,148 - INFO - epoch 0, step 34500, training loss = 2.715287, validation loss = 3.042916
2018-12-04 22:41:08,289 - INFO - epoch 0, step 34510, training loss = 2.843905, validation loss = 2.441178
2018-12-04 22:41:11,560 - INFO - epoch 0, step 34520, training loss = 2.618218, validation loss = 2.572383
2018-12-04 22:41:14,861 - INFO - epoch 0, step 34530, training loss = 2.549780, validation loss = 2.778586
2018-12-04 22:41:18,159 - INFO - epoch 0, step 34540, training loss = 2.686923, validation loss = 2.740766
2018-12-04 22:41:21,523 - INFO - epoch 0, step 34550, training loss = 2.520736, validation loss = 3.052255
2018-12-04 22:41:25,056 - INFO - epoch 0, step 34560, training loss = 2.700147, validation loss = 2.816295
2018-12-04 22:41:28,375 - INFO - epoch 0, step 34570, training loss = 2.485634, validation loss = 2.615859
2018-12-04 22:41:31,611 - INFO - epoch 0, step 34580, training loss = 2.748733, validation loss = 2.947447
2018-12-04 22:41:34,856 - INFO - epoch 0, step 34590, training loss = 2.556382, validation loss = 2.496958
2018-12-04 22:41:38,317 - INFO - epoch 0, step 34600, training loss = 2.062394, validation loss = 3.017955
2018-12-04 22:41:41,554 - INFO - epoch 0, step 34610, training loss = 2.797019, validation loss = 2.587459
2018-12-04 22:41:44,867 - INFO - epoch 0, step 34620, training loss = 2.679621, validation loss = 2.360934
2018-12-04 22:41:48,107 - INFO - epoch 0, step 34630, training loss = 2.415082, validation loss = 2.839245
2018-12-04 22:41:51,392 - INFO - epoch 0, step 34640, training loss = 2.505407, validation loss = 2.914550
2018-12-04 22:41:56,851 - INFO - epoch 0, step 34650, training loss = 2.760883, validation loss = 2.704330
2018-12-04 22:42:02,019 - INFO - epoch 0, step 34660, training loss = 2.317897, validation loss = 3.069472
2018-12-04 22:42:07,409 - INFO - epoch 0, step 34670, training loss = 2.894740, validation loss = 2.980487
2018-12-04 22:42:12,822 - INFO - epoch 0, step 34680, training loss = 2.732552, validation loss = 2.858353
2018-12-04 22:42:18,425 - INFO - epoch 0, step 34690, training loss = 2.845374, validation loss = 3.127809
2018-12-04 22:42:24,026 - INFO - epoch 0, step 34700, training loss = 2.036515, validation loss = 2.799095
2018-12-04 22:42:29,637 - INFO - epoch 0, step 34710, training loss = 2.441791, validation loss = 3.040237
2018-12-04 22:42:35,091 - INFO - epoch 0, step 34720, training loss = 2.463657, validation loss = 3.045033
2018-12-04 22:42:40,713 - INFO - epoch 0, step 34730, training loss = 2.406107, validation loss = 2.598997
2018-12-04 22:42:46,045 - INFO - epoch 0, step 34740, training loss = 2.877163, validation loss = 3.223906
2018-12-04 22:42:51,648 - INFO - epoch 0, step 34750, training loss = 2.399777, validation loss = 3.101786
2018-12-04 22:42:57,342 - INFO - epoch 0, step 34760, training loss = 2.570521, validation loss = 3.110964
2018-12-04 22:43:02,891 - INFO - epoch 0, step 34770, training loss = 2.938557, validation loss = 3.047286
2018-12-04 22:43:08,702 - INFO - epoch 0, step 34780, training loss = 2.654676, validation loss = 2.914533
2018-12-04 22:43:14,415 - INFO - epoch 0, step 34790, training loss = 2.468906, validation loss = 2.781656
2018-12-04 22:43:19,879 - INFO - epoch 0, step 34800, training loss = 2.917405, validation loss = 2.943901
2018-12-04 22:43:25,116 - INFO - epoch 0, step 34810, training loss = 2.603732, validation loss = 3.171782
2018-12-04 22:43:30,213 - INFO - epoch 0, step 34820, training loss = 2.370388, validation loss = 3.037331
2018-12-04 22:43:33,891 - INFO - epoch 0, step 34830, training loss = 2.836694, validation loss = 2.662829
2018-12-04 22:43:38,046 - INFO - epoch 0, step 34840, training loss = 2.419811, validation loss = 2.750221
2018-12-04 22:43:44,139 - INFO - epoch 0, step 34850, training loss = 2.273013, validation loss = 2.683191
2018-12-04 22:43:49,635 - INFO - epoch 0, step 34860, training loss = 2.242270, validation loss = 2.702013
2018-12-04 22:43:55,926 - INFO - epoch 0, step 34870, training loss = 2.269893, validation loss = 2.520177
2018-12-04 22:44:02,375 - INFO - epoch 0, step 34880, training loss = 2.495043, validation loss = 2.703197
2018-12-04 22:44:08,841 - INFO - epoch 0, step 34890, training loss = 2.544325, validation loss = 2.907916
2018-12-04 22:44:15,354 - INFO - epoch 0, step 34900, training loss = 1.933573, validation loss = 2.819914
2018-12-04 22:44:20,616 - INFO - epoch 0, step 34910, training loss = 2.585882, validation loss = 2.851758
2018-12-04 22:44:26,194 - INFO - epoch 0, step 34920, training loss = 1.854187, validation loss = 2.692114
2018-12-04 22:44:31,995 - INFO - epoch 0, step 34930, training loss = 2.250626, validation loss = 2.844798
2018-12-04 22:44:36,985 - INFO - epoch 0, step 34940, training loss = 2.772917, validation loss = 2.670063
2018-12-04 22:44:41,957 - INFO - epoch 0, step 34950, training loss = 2.679286, validation loss = 2.522892
2018-12-04 22:44:46,788 - INFO - epoch 0, step 34960, training loss = 2.401328, validation loss = 2.480873
2018-12-04 22:44:51,960 - INFO - epoch 0, step 34970, training loss = 2.353676, validation loss = 2.954221
2018-12-04 22:44:57,491 - INFO - epoch 0, step 34980, training loss = 2.719556, validation loss = 2.684711
2018-12-04 22:45:02,234 - INFO - epoch 0, step 34990, training loss = 2.189682, validation loss = 2.667210
2018-12-04 22:45:06,928 - INFO - epoch 0, step 35000, training loss = 2.263527, validation loss = 2.637483
2018-12-04 22:45:12,038 - INFO - epoch 0, step 35010, training loss = 2.271168, validation loss = 2.590830
2018-12-04 22:45:16,730 - INFO - epoch 0, step 35020, training loss = 2.507406, validation loss = 2.844568
2018-12-04 22:45:21,576 - INFO - epoch 0, step 35030, training loss = 2.651303, validation loss = 2.792836
2018-12-04 22:45:26,534 - INFO - epoch 0, step 35040, training loss = 2.096304, validation loss = 2.761938
2018-12-04 22:45:31,442 - INFO - epoch 0, step 35050, training loss = 2.535788, validation loss = 2.527501
2018-12-04 22:45:36,363 - INFO - epoch 0, step 35060, training loss = 1.897994, validation loss = 2.966283
2018-12-04 22:45:38,844 - INFO - epoch 0, step 35070, training loss = 2.942280, validation loss = 2.847560
2018-12-04 22:45:41,351 - INFO - epoch 0, step 35080, training loss = 2.880173, validation loss = 2.875840
2018-12-04 22:45:43,771 - INFO - epoch 0, step 35090, training loss = 2.993603, validation loss = 3.174304
2018-12-04 22:45:46,317 - INFO - epoch 0, step 35100, training loss = 2.617114, validation loss = 2.659069
2018-12-04 22:45:48,924 - INFO - epoch 0, step 35110, training loss = 2.975282, validation loss = 2.901458
2018-12-04 22:45:51,545 - INFO - epoch 0, step 35120, training loss = 2.696711, validation loss = 3.060619
2018-12-04 22:45:53,995 - INFO - epoch 0, step 35130, training loss = 2.296566, validation loss = 3.020942
2018-12-04 22:45:56,456 - INFO - epoch 0, step 35140, training loss = 2.627931, validation loss = 2.749349
2018-12-04 22:45:59,005 - INFO - epoch 0, step 35150, training loss = 2.047631, validation loss = 3.014640
2018-12-04 22:46:01,490 - INFO - epoch 0, step 35160, training loss = 2.989033, validation loss = 2.955072
2018-12-04 22:46:03,846 - INFO - epoch 0, step 35170, training loss = 2.303604, validation loss = 3.101985
2018-12-04 22:46:06,207 - INFO - epoch 0, step 35180, training loss = 2.559210, validation loss = 2.543050
2018-12-04 22:46:08,628 - INFO - epoch 0, step 35190, training loss = 2.594637, validation loss = 2.993551
2018-12-04 22:46:11,140 - INFO - epoch 0, step 35200, training loss = 2.510795, validation loss = 2.866392
2018-12-04 22:46:13,586 - INFO - epoch 0, step 35210, training loss = 1.764810, validation loss = 3.189979
2018-12-04 22:46:16,032 - INFO - epoch 0, step 35220, training loss = 2.509008, validation loss = 3.002489
2018-12-04 22:46:19,726 - INFO - epoch 0, step 35230, training loss = 2.319890, validation loss = 2.473103
2018-12-04 22:46:24,188 - INFO - epoch 0, step 35240, training loss = 2.343349, validation loss = 2.753710
2018-12-04 22:46:28,678 - INFO - epoch 0, step 35250, training loss = 1.822922, validation loss = 2.848806
2018-12-04 22:46:33,106 - INFO - epoch 0, step 35260, training loss = 2.865410, validation loss = 2.690350
2018-12-04 22:46:37,551 - INFO - epoch 0, step 35270, training loss = 2.634678, validation loss = 2.613774
2018-12-04 22:46:42,121 - INFO - epoch 0, step 35280, training loss = 2.012199, validation loss = 2.697390
2018-12-04 22:46:46,534 - INFO - epoch 0, step 35290, training loss = 2.282997, validation loss = 2.902615
2018-12-04 22:46:50,733 - INFO - epoch 0, step 35300, training loss = 2.204553, validation loss = 2.765255
2018-12-04 22:46:55,150 - INFO - epoch 0, step 35310, training loss = 2.492074, validation loss = 2.667446
2018-12-04 22:46:59,626 - INFO - epoch 0, step 35320, training loss = 2.520827, validation loss = 3.023006
2018-12-04 22:47:04,355 - INFO - epoch 0, step 35330, training loss = 2.811257, validation loss = 3.099364
2018-12-04 22:47:09,227 - INFO - epoch 0, step 35340, training loss = 2.770800, validation loss = 2.726326
2018-12-04 22:47:14,028 - INFO - epoch 0, step 35350, training loss = 2.317376, validation loss = 2.870109
2018-12-04 22:47:18,746 - INFO - epoch 0, step 35360, training loss = 2.633090, validation loss = 2.935837
2018-12-04 22:47:23,551 - INFO - epoch 0, step 35370, training loss = 2.908675, validation loss = 2.537579
2018-12-04 22:47:28,047 - INFO - epoch 0, step 35380, training loss = 2.721257, validation loss = 2.486048
2018-12-04 22:47:32,698 - INFO - epoch 0, step 35390, training loss = 2.943099, validation loss = 2.567544
2018-12-04 22:47:37,784 - INFO - epoch 0, step 35400, training loss = 2.791861, validation loss = 2.534978
2018-12-04 22:47:42,318 - INFO - epoch 0, step 35410, training loss = 2.708566, validation loss = 2.564247
2018-12-04 22:47:46,883 - INFO - epoch 0, step 35420, training loss = 2.665234, validation loss = 2.768814
2018-12-04 22:47:51,584 - INFO - epoch 0, step 35430, training loss = 2.588972, validation loss = 2.222685
2018-12-04 22:47:56,226 - INFO - epoch 0, step 35440, training loss = 2.782871, validation loss = 2.824895
2018-12-04 22:48:00,779 - INFO - epoch 0, step 35450, training loss = 2.334191, validation loss = 2.680208
2018-12-04 22:48:05,522 - INFO - epoch 0, step 35460, training loss = 2.369374, validation loss = 2.973213
2018-12-04 22:48:09,890 - INFO - epoch 0, step 35470, training loss = 2.661454, validation loss = 2.761198
2018-12-04 22:48:14,399 - INFO - epoch 0, step 35480, training loss = 1.635401, validation loss = 2.659959
2018-12-04 22:48:18,905 - INFO - epoch 0, step 35490, training loss = 2.041967, validation loss = 2.201220
2018-12-04 22:48:23,450 - INFO - epoch 0, step 35500, training loss = 2.397441, validation loss = 2.168242
2018-12-04 22:48:27,707 - INFO - epoch 0, step 35510, training loss = 2.588443, validation loss = 3.225941
2018-12-04 22:48:31,939 - INFO - epoch 0, step 35520, training loss = 2.807736, validation loss = 2.817849
2018-12-04 22:48:36,625 - INFO - epoch 0, step 35530, training loss = 2.319353, validation loss = 1.994783
2018-12-04 22:48:40,931 - INFO - epoch 0, step 35540, training loss = 2.942472, validation loss = 2.706231
2018-12-04 22:48:45,758 - INFO - epoch 0, step 35550, training loss = 2.369081, validation loss = 2.134929
2018-12-04 22:48:50,289 - INFO - epoch 0, step 35560, training loss = 2.582549, validation loss = 2.833696
2018-12-04 22:48:54,929 - INFO - epoch 0, step 35570, training loss = 2.065621, validation loss = 3.078325
2018-12-04 22:48:59,478 - INFO - epoch 0, step 35580, training loss = 2.819632, validation loss = 2.173945
2018-12-04 22:49:05,735 - INFO - epoch 0, step 35590, training loss = 2.522759, validation loss = 2.709036
2018-12-04 22:49:11,359 - INFO - epoch 0, step 35600, training loss = 2.191097, validation loss = 2.806365
2018-12-04 22:49:17,443 - INFO - epoch 0, step 35610, training loss = 2.203796, validation loss = 2.833608
2018-12-04 22:49:22,915 - INFO - epoch 0, step 35620, training loss = 2.206449, validation loss = 2.403103
2018-12-04 22:49:28,735 - INFO - epoch 0, step 35630, training loss = 2.575477, validation loss = 2.891972
2018-12-04 22:49:34,589 - INFO - epoch 0, step 35640, training loss = 1.921508, validation loss = 2.281333
2018-12-04 22:49:40,474 - INFO - epoch 0, step 35650, training loss = 2.290777, validation loss = 2.684657
2018-12-04 22:49:46,173 - INFO - epoch 0, step 35660, training loss = 2.103416, validation loss = 2.390880
2018-12-04 22:49:52,139 - INFO - epoch 0, step 35670, training loss = 2.109857, validation loss = 3.125735
2018-12-04 22:49:57,986 - INFO - epoch 0, step 35680, training loss = 2.683204, validation loss = 2.774854
2018-12-04 22:50:02,198 - INFO - epoch 0, step 35690, training loss = 2.039997, validation loss = 2.832165
2018-12-04 22:50:06,768 - INFO - epoch 0, step 35700, training loss = 2.441240, validation loss = 2.748886
2018-12-04 22:50:11,011 - INFO - epoch 0, step 35710, training loss = 2.426564, validation loss = 2.664802
2018-12-04 22:50:15,402 - INFO - epoch 0, step 35720, training loss = 2.475713, validation loss = 2.446228
2018-12-04 22:50:19,710 - INFO - epoch 0, step 35730, training loss = 2.696479, validation loss = 2.171771
2018-12-04 22:50:24,202 - INFO - epoch 0, step 35740, training loss = 2.427667, validation loss = 2.874941
2018-12-04 22:50:28,414 - INFO - epoch 0, step 35750, training loss = 3.220975, validation loss = 2.587988
2018-12-04 22:50:32,432 - INFO - epoch 0, step 35760, training loss = 3.094565, validation loss = 2.792421
2018-12-04 22:50:36,391 - INFO - epoch 0, step 35770, training loss = 2.890644, validation loss = 2.539985
2018-12-04 22:50:40,111 - INFO - epoch 0, step 35780, training loss = 2.715750, validation loss = 2.771788
2018-12-04 22:50:44,196 - INFO - epoch 0, step 35790, training loss = 2.592016, validation loss = 2.789704
2018-12-04 22:50:48,239 - INFO - epoch 0, step 35800, training loss = 2.674693, validation loss = 2.249066
2018-12-04 22:50:52,267 - INFO - epoch 0, step 35810, training loss = 2.940127, validation loss = 2.276991
2018-12-04 22:50:56,148 - INFO - epoch 0, step 35820, training loss = 2.614582, validation loss = 2.793866
2018-12-04 22:51:00,153 - INFO - epoch 0, step 35830, training loss = 2.857947, validation loss = 2.300751
2018-12-04 22:51:04,049 - INFO - epoch 0, step 35840, training loss = 2.948078, validation loss = 2.889526
2018-12-04 22:51:07,885 - INFO - epoch 0, step 35850, training loss = 2.789955, validation loss = 2.788367
2018-12-04 22:51:11,902 - INFO - epoch 0, step 35860, training loss = 2.926010, validation loss = 2.378992
2018-12-04 22:51:15,717 - INFO - epoch 0, step 35870, training loss = 2.526495, validation loss = 2.711339
2018-12-04 22:51:19,708 - INFO - epoch 0, step 35880, training loss = 2.776785, validation loss = 2.690588
2018-12-04 22:51:23,587 - INFO - epoch 0, step 35890, training loss = 2.537552, validation loss = 2.110892
2018-12-04 22:51:27,491 - INFO - epoch 0, step 35900, training loss = 2.613208, validation loss = 2.967346
2018-12-04 22:51:31,470 - INFO - epoch 0, step 35910, training loss = 2.350297, validation loss = 2.496742
2018-12-04 22:51:35,705 - INFO - epoch 0, step 35920, training loss = 2.449073, validation loss = 2.941308
2018-12-04 22:51:39,767 - INFO - epoch 0, step 35930, training loss = 2.468384, validation loss = 2.253934
2018-12-04 22:51:43,464 - INFO - epoch 0, step 35940, training loss = 2.521048, validation loss = 2.088899
2018-12-04 22:51:47,385 - INFO - epoch 0, step 35950, training loss = 2.490939, validation loss = 2.286572
2018-12-04 22:51:51,397 - INFO - epoch 0, step 35960, training loss = 2.874972, validation loss = 2.480230
2018-12-04 22:51:55,397 - INFO - epoch 0, step 35970, training loss = 2.872459, validation loss = 2.458045
2018-12-04 22:51:59,319 - INFO - epoch 0, step 35980, training loss = 2.552057, validation loss = 3.074476
2018-12-04 22:52:03,360 - INFO - epoch 0, step 35990, training loss = 2.214504, validation loss = 2.563189
2018-12-04 22:52:07,360 - INFO - epoch 0, step 36000, training loss = 2.549338, validation loss = 2.189932
2018-12-04 22:52:11,302 - INFO - epoch 0, step 36010, training loss = 2.519875, validation loss = 2.078047
2018-12-04 22:52:15,343 - INFO - epoch 0, step 36020, training loss = 2.088312, validation loss = 2.532323
2018-12-04 22:52:19,256 - INFO - epoch 0, step 36030, training loss = 2.486440, validation loss = 2.015974
2018-12-04 22:52:23,081 - INFO - epoch 0, step 36040, training loss = 2.304921, validation loss = 2.611629
2018-12-04 22:52:26,827 - INFO - epoch 0, step 36050, training loss = 2.552356, validation loss = 2.883278
2018-12-04 22:52:31,007 - INFO - epoch 0, step 36060, training loss = 2.728276, validation loss = 2.241575
2018-12-04 22:52:35,382 - INFO - epoch 0, step 36070, training loss = 2.244226, validation loss = 2.779051
2018-12-04 22:52:39,337 - INFO - epoch 0, step 36080, training loss = 2.490201, validation loss = 2.711297
2018-12-04 22:52:43,098 - INFO - epoch 0, step 36090, training loss = 2.264985, validation loss = 2.733409
2018-12-04 22:52:47,090 - INFO - epoch 0, step 36100, training loss = 2.437768, validation loss = 2.054206
2018-12-04 22:52:51,003 - INFO - epoch 0, step 36110, training loss = 2.642765, validation loss = 2.792201
2018-12-04 22:52:55,103 - INFO - epoch 0, step 36120, training loss = 2.665581, validation loss = 2.755079
2018-12-04 22:52:59,090 - INFO - epoch 0, step 36130, training loss = 2.623279, validation loss = 2.597791
2018-12-04 22:53:03,030 - INFO - epoch 0, step 36140, training loss = 2.573365, validation loss = 2.275474
2018-12-04 22:53:07,032 - INFO - epoch 0, step 36150, training loss = 2.299341, validation loss = 2.404856
2018-12-04 22:53:10,902 - INFO - epoch 0, step 36160, training loss = 2.614179, validation loss = 2.939496
2018-12-04 22:53:14,673 - INFO - epoch 0, step 36170, training loss = 2.234138, validation loss = 2.724215
2018-12-04 22:53:18,714 - INFO - epoch 0, step 36180, training loss = 2.495212, validation loss = 2.550145
2018-12-04 22:53:22,645 - INFO - epoch 0, step 36190, training loss = 2.741014, validation loss = 2.208752
2018-12-04 22:53:26,609 - INFO - epoch 0, step 36200, training loss = 2.181163, validation loss = 3.006760
2018-12-04 22:53:30,452 - INFO - epoch 0, step 36210, training loss = 2.716265, validation loss = 2.933784
2018-12-04 22:53:34,332 - INFO - epoch 0, step 36220, training loss = 2.429207, validation loss = 2.191983
2018-12-04 22:53:38,029 - INFO - epoch 0, step 36230, training loss = 2.338288, validation loss = 2.483544
2018-12-04 22:53:41,972 - INFO - epoch 0, step 36240, training loss = 2.325349, validation loss = 3.056805
2018-12-04 22:53:45,755 - INFO - epoch 0, step 36250, training loss = 2.646885, validation loss = 2.731483
2018-12-04 22:53:49,619 - INFO - epoch 0, step 36260, training loss = 2.481029, validation loss = 2.709986
2018-12-04 22:53:53,671 - INFO - epoch 0, step 36270, training loss = 2.825908, validation loss = 2.846550
2018-12-04 22:53:57,525 - INFO - epoch 0, step 36280, training loss = 2.423302, validation loss = 2.842060
2018-12-04 22:54:01,290 - INFO - epoch 0, step 36290, training loss = 2.400801, validation loss = 3.252134
2018-12-04 22:54:05,281 - INFO - epoch 0, step 36300, training loss = 2.477103, validation loss = 2.534361
2018-12-04 22:54:09,253 - INFO - epoch 0, step 36310, training loss = 2.512327, validation loss = 2.393523
2018-12-04 22:54:13,045 - INFO - epoch 0, step 36320, training loss = 2.415150, validation loss = 2.351818
2018-12-04 22:54:16,989 - INFO - epoch 0, step 36330, training loss = 2.432548, validation loss = 2.622373
2018-12-04 22:54:20,983 - INFO - epoch 0, step 36340, training loss = 2.321918, validation loss = 2.988118
2018-12-04 22:54:24,982 - INFO - epoch 0, step 36350, training loss = 2.270612, validation loss = 2.860772
2018-12-04 22:54:28,706 - INFO - epoch 0, step 36360, training loss = 2.257819, validation loss = 2.650526
2018-12-04 22:54:32,776 - INFO - epoch 0, step 36370, training loss = 2.538791, validation loss = 1.866748
2018-12-04 22:54:36,699 - INFO - epoch 0, step 36380, training loss = 2.207955, validation loss = 3.300614
2018-12-04 22:54:40,615 - INFO - epoch 0, step 36390, training loss = 2.653572, validation loss = 2.510505
2018-12-04 22:54:44,418 - INFO - epoch 0, step 36400, training loss = 2.702975, validation loss = 3.075302
2018-12-04 22:54:48,200 - INFO - epoch 0, step 36410, training loss = 2.489068, validation loss = 2.683733
2018-12-04 22:54:51,917 - INFO - epoch 0, step 36420, training loss = 2.508136, validation loss = 2.995263
2018-12-04 22:54:55,733 - INFO - epoch 0, step 36430, training loss = 2.647476, validation loss = 2.789875
2018-12-04 22:54:59,614 - INFO - epoch 0, step 36440, training loss = 2.771293, validation loss = 2.912506
2018-12-04 22:55:03,461 - INFO - epoch 0, step 36450, training loss = 2.521088, validation loss = 2.967908
2018-12-04 22:55:07,254 - INFO - epoch 0, step 36460, training loss = 2.159689, validation loss = 2.491065
2018-12-04 22:55:11,210 - INFO - epoch 0, step 36470, training loss = 2.595710, validation loss = 2.602399
2018-12-04 22:55:15,317 - INFO - epoch 0, step 36480, training loss = 2.515536, validation loss = 2.529609
2018-12-04 22:55:19,119 - INFO - epoch 0, step 36490, training loss = 2.463720, validation loss = 2.608041
2018-12-04 22:55:23,012 - INFO - epoch 0, step 36500, training loss = 2.537112, validation loss = 3.096130
2018-12-04 22:55:27,139 - INFO - epoch 0, step 36510, training loss = 2.373955, validation loss = 2.554547
2018-12-04 22:55:31,353 - INFO - epoch 0, step 36520, training loss = 2.529108, validation loss = 2.383496
2018-12-04 22:55:35,189 - INFO - epoch 0, step 36530, training loss = 2.364387, validation loss = 3.136102
2018-12-04 22:55:39,241 - INFO - epoch 0, step 36540, training loss = 2.337287, validation loss = 3.038373
2018-12-04 22:55:43,090 - INFO - epoch 0, step 36550, training loss = 2.441142, validation loss = 3.212930
2018-12-04 22:55:47,054 - INFO - epoch 0, step 36560, training loss = 2.189672, validation loss = 2.452172
2018-12-04 22:55:51,131 - INFO - epoch 0, step 36570, training loss = 2.545597, validation loss = 2.485553
2018-12-04 22:55:55,089 - INFO - epoch 0, step 36580, training loss = 2.613600, validation loss = 2.995308
2018-12-04 22:55:59,047 - INFO - epoch 0, step 36590, training loss = 2.547401, validation loss = 2.632540
2018-12-04 22:56:02,891 - INFO - epoch 0, step 36600, training loss = 2.200727, validation loss = 2.679911
2018-12-04 22:56:06,951 - INFO - epoch 0, step 36610, training loss = 2.721440, validation loss = 2.403451
2018-12-04 22:56:11,044 - INFO - epoch 0, step 36620, training loss = 2.604378, validation loss = 2.704673
2018-12-04 22:56:15,044 - INFO - epoch 0, step 36630, training loss = 2.456265, validation loss = 2.973263
2018-12-04 22:56:18,707 - INFO - epoch 0, step 36640, training loss = 2.649903, validation loss = 2.730633
2018-12-04 22:56:22,677 - INFO - epoch 0, step 36650, training loss = 2.617831, validation loss = 2.700146
2018-12-04 22:56:26,618 - INFO - epoch 0, step 36660, training loss = 2.136565, validation loss = 3.168635
2018-12-04 22:56:30,586 - INFO - epoch 0, step 36670, training loss = 2.227147, validation loss = 2.641255
2018-12-04 22:56:34,540 - INFO - epoch 0, step 36680, training loss = 2.280418, validation loss = 2.700051
2018-12-04 22:56:38,422 - INFO - epoch 0, step 36690, training loss = 2.231183, validation loss = 2.609634
2018-12-04 22:56:42,129 - INFO - epoch 0, step 36700, training loss = 2.246559, validation loss = 2.781992
2018-12-04 22:56:45,923 - INFO - epoch 0, step 36710, training loss = 2.569672, validation loss = 2.828063
2018-12-04 22:56:49,807 - INFO - epoch 0, step 36720, training loss = 2.083938, validation loss = 2.594978
2018-12-04 22:56:53,651 - INFO - epoch 0, step 36730, training loss = 2.411415, validation loss = 2.709767
2018-12-04 22:56:57,635 - INFO - epoch 0, step 36740, training loss = 2.655556, validation loss = 3.037505
2018-12-04 22:57:01,706 - INFO - epoch 0, step 36750, training loss = 2.289076, validation loss = 2.466476
2018-12-04 22:57:05,591 - INFO - epoch 0, step 36760, training loss = 2.763546, validation loss = 2.974315
2018-12-04 22:57:09,386 - INFO - epoch 0, step 36770, training loss = 2.569794, validation loss = 2.494010
2018-12-04 22:57:13,091 - INFO - epoch 0, step 36780, training loss = 3.057936, validation loss = 2.743639
2018-12-04 22:57:16,787 - INFO - epoch 0, step 36790, training loss = 3.488330, validation loss = 2.784910
2018-12-04 22:57:20,569 - INFO - epoch 0, step 36800, training loss = 3.843091, validation loss = 2.543030
2018-12-04 22:57:24,229 - INFO - epoch 0, step 36810, training loss = 3.324647, validation loss = 2.943021
2018-12-04 22:57:27,786 - INFO - epoch 0, step 36820, training loss = 3.217129, validation loss = 2.745213
2018-12-04 22:57:31,551 - INFO - epoch 0, step 36830, training loss = 2.934184, validation loss = 3.123352
2018-12-04 22:57:35,620 - INFO - epoch 0, step 36840, training loss = 2.857684, validation loss = 3.122357
2018-12-04 22:57:39,366 - INFO - epoch 0, step 36850, training loss = 3.288835, validation loss = 2.965193
2018-12-04 22:57:43,301 - INFO - epoch 0, step 36860, training loss = 2.948982, validation loss = 2.568489
2018-12-04 22:57:46,805 - INFO - epoch 0, step 36870, training loss = 3.136946, validation loss = 2.814404
2018-12-04 22:57:50,658 - INFO - epoch 0, step 36880, training loss = 2.640387, validation loss = 2.237252
2018-12-04 22:57:54,576 - INFO - epoch 0, step 36890, training loss = 3.548408, validation loss = 2.467361
2018-12-04 22:57:58,129 - INFO - epoch 0, step 36900, training loss = 3.532630, validation loss = 2.805984
2018-12-04 22:58:01,622 - INFO - epoch 0, step 36910, training loss = 3.149499, validation loss = 2.803443
2018-12-04 22:58:05,200 - INFO - epoch 0, step 36920, training loss = 2.878060, validation loss = 2.567340
2018-12-04 22:58:08,926 - INFO - epoch 0, step 36930, training loss = 3.117210, validation loss = 2.745483
2018-12-04 22:58:12,578 - INFO - epoch 0, step 36940, training loss = 2.917048, validation loss = 2.925811
2018-12-04 22:58:16,455 - INFO - epoch 0, step 36950, training loss = 3.207627, validation loss = 2.429504
2018-12-04 22:58:20,561 - INFO - epoch 0, step 36960, training loss = 3.128549, validation loss = 2.605838
2018-12-04 22:58:24,632 - INFO - epoch 0, step 36970, training loss = 3.674675, validation loss = 2.571733
2018-12-04 22:58:28,351 - INFO - epoch 0, step 36980, training loss = 2.901243, validation loss = 3.063629
2018-12-04 22:58:31,934 - INFO - epoch 0, step 36990, training loss = 3.348682, validation loss = 3.142202
2018-12-04 22:58:35,457 - INFO - epoch 0, step 37000, training loss = 3.071472, validation loss = 3.128183
2018-12-04 22:58:39,064 - INFO - epoch 0, step 37010, training loss = 2.758125, validation loss = 2.899940
2018-12-04 22:58:42,993 - INFO - epoch 0, step 37020, training loss = 2.902493, validation loss = 3.357773
2018-12-04 22:58:46,751 - INFO - epoch 0, step 37030, training loss = 3.022341, validation loss = 2.810531
2018-12-04 22:58:50,799 - INFO - epoch 0, step 37040, training loss = 3.277398, validation loss = 2.691002
2018-12-04 22:58:54,275 - INFO - epoch 0, step 37050, training loss = 3.125441, validation loss = 3.224312
2018-12-04 22:58:57,896 - INFO - epoch 0, step 37060, training loss = 2.837763, validation loss = 3.150934
2018-12-04 22:59:01,906 - INFO - epoch 0, step 37070, training loss = 3.119644, validation loss = 2.359003
2018-12-04 22:59:05,481 - INFO - epoch 0, step 37080, training loss = 3.044588, validation loss = 3.019774
2018-12-04 22:59:09,404 - INFO - epoch 0, step 37090, training loss = 3.575404, validation loss = 2.697811
2018-12-04 22:59:13,354 - INFO - epoch 0, step 37100, training loss = 3.256548, validation loss = 2.926591
2018-12-04 22:59:17,005 - INFO - epoch 0, step 37110, training loss = 2.791012, validation loss = 2.611227
2018-12-04 22:59:20,980 - INFO - epoch 0, step 37120, training loss = 2.892051, validation loss = 2.694229
2018-12-04 22:59:24,454 - INFO - epoch 0, step 37130, training loss = 2.979372, validation loss = 2.921235
2018-12-04 22:59:28,068 - INFO - epoch 0, step 37140, training loss = 2.679646, validation loss = 2.373252
2018-12-04 22:59:31,596 - INFO - epoch 0, step 37150, training loss = 2.948656, validation loss = 2.763920
2018-12-04 22:59:35,294 - INFO - epoch 0, step 37160, training loss = 3.384614, validation loss = 3.280766
2018-12-04 22:59:38,805 - INFO - epoch 0, step 37170, training loss = 2.972065, validation loss = 2.378939
2018-12-04 22:59:42,803 - INFO - epoch 0, step 37180, training loss = 3.271778, validation loss = 2.552744
2018-12-04 22:59:46,512 - INFO - epoch 0, step 37190, training loss = 3.701529, validation loss = 3.310413
2018-12-04 22:59:50,057 - INFO - epoch 0, step 37200, training loss = 3.096938, validation loss = 2.555492
2018-12-04 22:59:53,777 - INFO - epoch 0, step 37210, training loss = 3.199642, validation loss = 2.971733
2018-12-04 22:59:57,335 - INFO - epoch 0, step 37220, training loss = 3.292913, validation loss = 2.713480
2018-12-04 23:00:01,153 - INFO - epoch 0, step 37230, training loss = 3.157734, validation loss = 2.851131
2018-12-04 23:00:05,049 - INFO - epoch 0, step 37240, training loss = 2.759568, validation loss = 2.935184
2018-12-04 23:00:08,876 - INFO - epoch 0, step 37250, training loss = 2.440702, validation loss = 3.227455
2018-12-04 23:00:12,415 - INFO - epoch 0, step 37260, training loss = 3.380947, validation loss = 3.197737
2018-12-04 23:00:16,387 - INFO - epoch 0, step 37270, training loss = 2.843691, validation loss = 3.162781
2018-12-04 23:00:19,933 - INFO - epoch 0, step 37280, training loss = 2.927793, validation loss = 2.872563
2018-12-04 23:00:23,503 - INFO - epoch 0, step 37290, training loss = 3.406189, validation loss = 2.525597
2018-12-04 23:00:27,293 - INFO - epoch 0, step 37300, training loss = 3.068324, validation loss = 2.802717
2018-12-04 23:00:30,823 - INFO - epoch 0, step 37310, training loss = 3.054389, validation loss = 3.661310
2018-12-04 23:00:34,534 - INFO - epoch 0, step 37320, training loss = 3.632086, validation loss = 2.691751
2018-12-04 23:00:37,964 - INFO - epoch 0, step 37330, training loss = 2.889158, validation loss = 2.990278
2018-12-04 23:00:41,468 - INFO - epoch 0, step 37340, training loss = 3.218847, validation loss = 2.204112
2018-12-04 23:00:45,064 - INFO - epoch 0, step 37350, training loss = 3.206290, validation loss = 2.963743
2018-12-04 23:00:48,731 - INFO - epoch 0, step 37360, training loss = 3.045315, validation loss = 2.952079
2018-12-04 23:00:52,258 - INFO - epoch 0, step 37370, training loss = 3.334124, validation loss = 3.144546
2018-12-04 23:00:55,984 - INFO - epoch 0, step 37380, training loss = 3.248763, validation loss = 2.465877
2018-12-04 23:00:59,669 - INFO - epoch 0, step 37390, training loss = 2.955087, validation loss = 2.925165
2018-12-04 23:01:03,431 - INFO - epoch 0, step 37400, training loss = 3.236920, validation loss = 3.098239
2018-12-04 23:01:07,096 - INFO - epoch 0, step 37410, training loss = 2.971082, validation loss = 2.996332
2018-12-04 23:01:10,762 - INFO - epoch 0, step 37420, training loss = 3.657892, validation loss = 3.364460
2018-12-04 23:01:14,633 - INFO - epoch 0, step 37430, training loss = 3.665171, validation loss = 3.294275
2018-12-04 23:01:18,238 - INFO - epoch 0, step 37440, training loss = 2.844682, validation loss = 2.507259
2018-12-04 23:01:21,707 - INFO - epoch 0, step 37450, training loss = 3.056658, validation loss = 3.019421
2018-12-04 23:01:25,423 - INFO - epoch 0, step 37460, training loss = 3.168402, validation loss = 3.075142
2018-12-04 23:01:29,274 - INFO - epoch 0, step 37470, training loss = 3.361427, validation loss = 2.960531
2018-12-04 23:01:33,142 - INFO - epoch 0, step 37480, training loss = 2.778922, validation loss = 3.205267
2018-12-04 23:01:36,701 - INFO - epoch 0, step 37490, training loss = 2.902888, validation loss = 3.311682
2018-12-04 23:01:40,129 - INFO - epoch 0, step 37500, training loss = 3.342722, validation loss = 3.221333
2018-12-04 23:01:43,652 - INFO - epoch 0, step 37510, training loss = 2.817602, validation loss = 2.717485
2018-12-04 23:01:47,180 - INFO - epoch 0, step 37520, training loss = 2.953596, validation loss = 3.051067
2018-12-04 23:01:51,208 - INFO - epoch 0, step 37530, training loss = 3.392889, validation loss = 3.100965
2018-12-04 23:01:54,992 - INFO - epoch 0, step 37540, training loss = 3.025007, validation loss = 3.138527
2018-12-04 23:01:58,796 - INFO - epoch 0, step 37550, training loss = 2.723722, validation loss = 2.999353
2018-12-04 23:02:02,476 - INFO - epoch 0, step 37560, training loss = 2.611236, validation loss = 2.986750
2018-12-04 23:02:06,175 - INFO - epoch 0, step 37570, training loss = 3.621045, validation loss = 3.390017
2018-12-04 23:02:09,940 - INFO - epoch 0, step 37580, training loss = 3.237000, validation loss = 3.197766
2018-12-04 23:02:13,858 - INFO - epoch 0, step 37590, training loss = 2.770977, validation loss = 2.761403
2018-12-04 23:02:17,478 - INFO - epoch 0, step 37600, training loss = 2.933279, validation loss = 3.244479
2018-12-04 23:02:21,015 - INFO - epoch 0, step 37610, training loss = 3.058107, validation loss = 2.932508
2018-12-04 23:02:24,698 - INFO - epoch 0, step 37620, training loss = 3.025348, validation loss = 3.252893
2018-12-04 23:02:28,586 - INFO - epoch 0, step 37630, training loss = 3.383086, validation loss = 2.612346
2018-12-04 23:02:32,697 - INFO - epoch 0, step 37640, training loss = 3.418229, validation loss = 3.068233
2018-12-04 23:02:36,380 - INFO - epoch 0, step 37650, training loss = 2.922140, validation loss = 3.223035
2018-12-04 23:02:40,227 - INFO - epoch 0, step 37660, training loss = 3.542820, validation loss = 3.446670
2018-12-04 23:02:44,210 - INFO - epoch 0, step 37670, training loss = 2.540434, validation loss = 2.652669
2018-12-04 23:02:47,909 - INFO - epoch 0, step 37680, training loss = 3.421498, validation loss = 2.877637
2018-12-04 23:02:51,932 - INFO - epoch 0, step 37690, training loss = 2.483213, validation loss = 2.536957
2018-12-04 23:02:56,005 - INFO - epoch 0, step 37700, training loss = 3.254480, validation loss = 2.447277
2018-12-04 23:02:59,708 - INFO - epoch 0, step 37710, training loss = 2.732632, validation loss = 3.273813
2018-12-04 23:03:03,475 - INFO - epoch 0, step 37720, training loss = 3.530614, validation loss = 2.792009
2018-12-04 23:03:07,492 - INFO - epoch 0, step 37730, training loss = 2.774613, validation loss = 2.801069
2018-12-04 23:03:11,258 - INFO - epoch 0, step 37740, training loss = 3.530598, validation loss = 2.760717
2018-12-04 23:03:15,259 - INFO - epoch 0, step 37750, training loss = 3.362462, validation loss = 3.405153
2018-12-04 23:03:19,073 - INFO - epoch 0, step 37760, training loss = 3.227892, validation loss = 3.519005
2018-12-04 23:03:22,721 - INFO - epoch 0, step 37770, training loss = 2.813685, validation loss = 3.385714
2018-12-04 23:03:26,442 - INFO - epoch 0, step 37780, training loss = 3.236615, validation loss = 2.997690
2018-12-04 23:03:30,038 - INFO - epoch 0, step 37790, training loss = 3.398142, validation loss = 3.063244
2018-12-04 23:03:33,489 - INFO - epoch 0, step 37800, training loss = 3.290956, validation loss = 3.115885
2018-12-04 23:03:37,565 - INFO - epoch 0, step 37810, training loss = 3.221666, validation loss = 2.703955
2018-12-04 23:03:41,576 - INFO - epoch 0, step 37820, training loss = 3.043993, validation loss = 3.139976
2018-12-04 23:03:45,556 - INFO - epoch 0, step 37830, training loss = 3.538831, validation loss = 3.178151
2018-12-04 23:03:49,330 - INFO - epoch 0, step 37840, training loss = 3.106734, validation loss = 2.641958
2018-12-04 23:03:53,068 - INFO - epoch 0, step 37850, training loss = 2.968406, validation loss = 3.088500
2018-12-04 23:03:57,087 - INFO - epoch 0, step 37860, training loss = 2.611853, validation loss = 2.759917
2018-12-04 23:04:01,065 - INFO - epoch 0, step 37870, training loss = 3.791089, validation loss = 2.882337
2018-12-04 23:04:05,149 - INFO - epoch 0, step 37880, training loss = 2.801505, validation loss = 3.110592
2018-12-04 23:04:09,072 - INFO - epoch 0, step 37890, training loss = 3.180143, validation loss = 3.475088
2018-12-04 23:04:12,905 - INFO - epoch 0, step 37900, training loss = 3.096223, validation loss = 3.183633
2018-12-04 23:04:16,376 - INFO - epoch 0, step 37910, training loss = 2.936548, validation loss = 3.094316
2018-12-04 23:04:19,990 - INFO - epoch 0, step 37920, training loss = 2.846762, validation loss = 2.944645
2018-12-04 23:04:23,601 - INFO - epoch 0, step 37930, training loss = 2.910260, validation loss = 3.108002
2018-12-04 23:04:27,160 - INFO - epoch 0, step 37940, training loss = 3.011896, validation loss = 3.002175
2018-12-04 23:04:31,141 - INFO - epoch 0, step 37950, training loss = 3.300203, validation loss = 2.651366
2018-12-04 23:04:35,075 - INFO - epoch 0, step 37960, training loss = 2.910393, validation loss = 3.166614
2018-12-04 23:04:38,660 - INFO - epoch 0, step 37970, training loss = 2.818490, validation loss = 3.608522
2018-12-04 23:04:42,180 - INFO - epoch 0, step 37980, training loss = 3.429182, validation loss = 3.320159
2018-12-04 23:04:45,758 - INFO - epoch 0, step 37990, training loss = 2.963318, validation loss = 3.499245
2018-12-04 23:04:49,245 - INFO - epoch 0, step 38000, training loss = 3.032672, validation loss = 2.756600
2018-12-04 23:04:52,834 - INFO - epoch 0, step 38010, training loss = 2.996270, validation loss = 3.419376
2018-12-04 23:04:56,498 - INFO - epoch 0, step 38020, training loss = 2.731259, validation loss = 3.233451
2018-12-04 23:05:00,456 - INFO - epoch 0, step 38030, training loss = 2.982834, validation loss = 2.527025
2018-12-04 23:05:04,435 - INFO - epoch 0, step 38040, training loss = 3.011076, validation loss = 3.120470
2018-12-04 23:05:08,243 - INFO - epoch 0, step 38050, training loss = 3.285220, validation loss = 2.936625
2018-12-04 23:05:11,965 - INFO - epoch 0, step 38060, training loss = 2.319262, validation loss = 2.914589
2018-12-04 23:05:15,748 - INFO - epoch 0, step 38070, training loss = 2.922103, validation loss = 3.374811
2018-12-04 23:05:19,470 - INFO - epoch 0, step 38080, training loss = 2.916867, validation loss = 2.805481
2018-12-04 23:05:23,222 - INFO - epoch 0, step 38090, training loss = 3.213677, validation loss = 3.594714
2018-12-04 23:05:26,704 - INFO - epoch 0, step 38100, training loss = 3.446759, validation loss = 3.165040
2018-12-04 23:05:30,257 - INFO - epoch 0, step 38110, training loss = 3.212504, validation loss = 2.546837
2018-12-04 23:05:33,788 - INFO - epoch 0, step 38120, training loss = 3.340343, validation loss = 3.287099
2018-12-04 23:05:37,338 - INFO - epoch 0, step 38130, training loss = 3.285104, validation loss = 3.175464
2018-12-04 23:05:41,063 - INFO - epoch 0, step 38140, training loss = 3.149988, validation loss = 2.691363
2018-12-04 23:05:44,656 - INFO - epoch 0, step 38150, training loss = 2.885808, validation loss = 3.030225
2018-12-04 23:05:48,235 - INFO - epoch 0, step 38160, training loss = 3.141608, validation loss = 2.807005
2018-12-04 23:05:52,013 - INFO - epoch 0, step 38170, training loss = 3.342287, validation loss = 3.273533
2018-12-04 23:05:55,852 - INFO - epoch 0, step 38180, training loss = 3.074209, validation loss = 3.168789
2018-12-04 23:05:59,721 - INFO - epoch 0, step 38190, training loss = 3.038550, validation loss = 3.194804
2018-12-04 23:06:03,321 - INFO - epoch 0, step 38200, training loss = 2.822246, validation loss = 2.729491
2018-12-04 23:06:06,764 - INFO - epoch 0, step 38210, training loss = 3.056986, validation loss = 3.425822
2018-12-04 23:06:10,798 - INFO - epoch 0, step 38220, training loss = 2.571990, validation loss = 2.698147
2018-12-04 23:06:14,808 - INFO - epoch 0, step 38230, training loss = 3.533755, validation loss = 3.396383
2018-12-04 23:06:18,845 - INFO - epoch 0, step 38240, training loss = 3.164816, validation loss = 2.311131
2018-12-04 23:06:22,696 - INFO - epoch 0, step 38250, training loss = 3.069686, validation loss = 3.112972
2018-12-04 23:06:26,781 - INFO - epoch 0, step 38260, training loss = 3.058743, validation loss = 2.807052
2018-12-04 23:06:30,701 - INFO - epoch 0, step 38270, training loss = 3.322643, validation loss = 2.541109
2018-12-04 23:06:35,010 - INFO - epoch 0, step 38280, training loss = 3.054232, validation loss = 2.786970
2018-12-04 23:06:40,114 - INFO - epoch 0, step 38290, training loss = 2.345645, validation loss = 2.713356
2018-12-04 23:06:45,164 - INFO - epoch 0, step 38300, training loss = 2.985431, validation loss = 2.934050
2018-12-04 23:06:50,094 - INFO - epoch 0, step 38310, training loss = 2.349603, validation loss = 2.855348
2018-12-04 23:06:55,553 - INFO - epoch 0, step 38320, training loss = 2.492194, validation loss = 2.828683
2018-12-04 23:07:00,899 - INFO - epoch 0, step 38330, training loss = 2.448094, validation loss = 2.488672
2018-12-04 23:07:06,094 - INFO - epoch 0, step 38340, training loss = 3.661519, validation loss = 2.986346
2018-12-04 23:07:11,292 - INFO - epoch 0, step 38350, training loss = 3.583505, validation loss = 3.105932
2018-12-04 23:07:17,078 - INFO - epoch 0, step 38360, training loss = 2.843475, validation loss = 2.724699
2018-12-04 23:07:22,709 - INFO - epoch 0, step 38370, training loss = 2.800816, validation loss = 2.348469
2018-12-04 23:07:28,766 - INFO - epoch 0, step 38380, training loss = 3.057622, validation loss = 2.833595
2018-12-04 23:07:35,241 - INFO - epoch 0, step 38390, training loss = 1.679512, validation loss = 3.190971
2018-12-04 23:07:39,370 - INFO - epoch 0, step 38400, training loss = 3.350142, validation loss = 3.008148
2018-12-04 23:07:43,298 - INFO - epoch 0, step 38410, training loss = 3.394581, validation loss = 2.089107
2018-12-04 23:07:47,335 - INFO - epoch 0, step 38420, training loss = 3.294133, validation loss = 2.350559
2018-12-04 23:07:51,404 - INFO - epoch 0, step 38430, training loss = 3.474884, validation loss = 2.441681
2018-12-04 23:07:55,390 - INFO - epoch 0, step 38440, training loss = 2.764493, validation loss = 2.984681
2018-12-04 23:07:59,398 - INFO - epoch 0, step 38450, training loss = 3.585702, validation loss = 2.172524
2018-12-04 23:08:04,123 - INFO - epoch 0, step 38460, training loss = 2.474330, validation loss = 2.804645
2018-12-04 23:08:09,413 - INFO - epoch 0, step 38470, training loss = 2.244766, validation loss = 2.735250
2018-12-04 23:08:14,557 - INFO - epoch 0, step 38480, training loss = 2.882218, validation loss = 2.383426
2018-12-04 23:08:19,515 - INFO - epoch 0, step 38490, training loss = 3.040178, validation loss = 2.744882
2018-12-04 23:08:24,618 - INFO - epoch 0, step 38500, training loss = 2.991002, validation loss = 3.531352
2018-12-04 23:08:30,266 - INFO - epoch 0, step 38510, training loss = 2.427979, validation loss = 2.754491
2018-12-04 23:08:35,256 - INFO - epoch 0, step 38520, training loss = 2.341832, validation loss = 2.871381
2018-12-04 23:08:40,771 - INFO - epoch 0, step 38530, training loss = 2.470544, validation loss = 2.674349
2018-12-04 23:08:46,059 - INFO - epoch 0, step 38540, training loss = 2.668510, validation loss = 2.637026
2018-12-04 23:08:50,240 - INFO - epoch 0, step 38550, training loss = 2.942241, validation loss = 2.367116
2018-12-04 23:08:54,043 - INFO - epoch 0, step 38560, training loss = 2.577802, validation loss = 1.981919
2018-12-04 23:08:58,006 - INFO - epoch 0, step 38570, training loss = 2.992188, validation loss = 2.305765
2018-12-04 23:09:01,838 - INFO - epoch 0, step 38580, training loss = 3.266056, validation loss = 2.839329
2018-12-04 23:09:05,612 - INFO - epoch 0, step 38590, training loss = 3.310629, validation loss = 2.807698
2018-12-04 23:09:09,708 - INFO - epoch 0, step 38600, training loss = 3.052232, validation loss = 2.817320
2018-12-04 23:09:14,005 - INFO - epoch 0, step 38610, training loss = 2.383455, validation loss = 2.725182
2018-12-04 23:09:18,174 - INFO - epoch 0, step 38620, training loss = 2.830543, validation loss = 2.997221
2018-12-04 23:09:22,248 - INFO - epoch 0, step 38630, training loss = 2.769795, validation loss = 2.887417
2018-12-04 23:09:26,242 - INFO - epoch 0, step 38640, training loss = 2.616662, validation loss = 2.944748
2018-12-04 23:09:30,255 - INFO - epoch 0, step 38650, training loss = 2.602953, validation loss = 3.029136
2018-12-04 23:09:34,315 - INFO - epoch 0, step 38660, training loss = 3.202063, validation loss = 3.053485
2018-12-04 23:09:38,635 - INFO - epoch 0, step 38670, training loss = 2.843831, validation loss = 2.785800
2018-12-04 23:09:42,719 - INFO - epoch 0, step 38680, training loss = 3.376364, validation loss = 2.782400
2018-12-04 23:09:46,555 - INFO - epoch 0, step 38690, training loss = 3.295160, validation loss = 2.189884
2018-12-04 23:09:50,774 - INFO - epoch 0, step 38700, training loss = 3.300368, validation loss = 2.981348
2018-12-04 23:09:54,937 - INFO - epoch 0, step 38710, training loss = 2.839241, validation loss = 2.508201
2018-12-04 23:09:59,443 - INFO - epoch 0, step 38720, training loss = 2.820068, validation loss = 2.361809
2018-12-04 23:10:03,951 - INFO - epoch 0, step 38730, training loss = 2.108596, validation loss = 2.645564
2018-12-04 23:10:10,028 - INFO - epoch 0, step 38740, training loss = 2.967973, validation loss = 2.672043
2018-12-04 23:10:16,389 - INFO - epoch 0, step 38750, training loss = 1.823268, validation loss = 3.130237
2018-12-04 23:10:21,682 - INFO - epoch 0, step 38760, training loss = 2.075991, validation loss = 2.253165
2018-12-04 23:10:27,575 - INFO - epoch 0, step 38770, training loss = 2.267661, validation loss = 2.748234
2018-12-04 23:10:32,975 - INFO - epoch 0, step 38780, training loss = 2.568627, validation loss = 2.657572
2018-12-04 23:10:38,424 - INFO - epoch 0, step 38790, training loss = 2.443659, validation loss = 2.929085
2018-12-04 23:10:43,786 - INFO - epoch 0, step 38800, training loss = 2.378542, validation loss = 2.754350
2018-12-04 23:10:48,988 - INFO - epoch 0, step 38810, training loss = 2.619808, validation loss = 2.260831
2018-12-04 23:10:54,287 - INFO - epoch 0, step 38820, training loss = 3.592658, validation loss = 2.851980
2018-12-04 23:10:59,753 - INFO - epoch 0, step 38830, training loss = 2.305904, validation loss = 2.782203
2018-12-04 23:11:05,715 - INFO - epoch 0, step 38840, training loss = 2.213455, validation loss = 2.733400
2018-12-04 23:11:11,302 - INFO - epoch 0, step 38850, training loss = 2.571218, validation loss = 2.321059
2018-12-04 23:11:16,980 - INFO - epoch 0, step 38860, training loss = 2.123546, validation loss = 2.299546
2018-12-04 23:11:22,399 - INFO - epoch 0, step 38870, training loss = 2.322862, validation loss = 2.390364
2018-12-04 23:11:27,638 - INFO - epoch 0, step 38880, training loss = 2.780768, validation loss = 2.863300
2018-12-04 23:11:32,997 - INFO - epoch 0, step 38890, training loss = 3.581311, validation loss = 3.165214
2018-12-04 23:11:38,561 - INFO - epoch 0, step 38900, training loss = 2.271260, validation loss = 2.788259
2018-12-04 23:11:44,196 - INFO - epoch 0, step 38910, training loss = 2.060531, validation loss = 2.916449
2018-12-04 23:11:49,613 - INFO - epoch 0, step 38920, training loss = 2.448631, validation loss = 3.441393
2018-12-04 23:11:54,775 - INFO - epoch 0, step 38930, training loss = 2.931047, validation loss = 1.725853
2018-12-04 23:12:00,605 - INFO - epoch 0, step 38940, training loss = 2.679802, validation loss = 2.959642
2018-12-04 23:12:05,916 - INFO - epoch 0, step 38950, training loss = 2.583179, validation loss = 2.843676
2018-12-04 23:12:11,237 - INFO - epoch 0, step 38960, training loss = 1.898539, validation loss = 2.910693
2018-12-04 23:12:16,499 - INFO - epoch 0, step 38970, training loss = 3.074557, validation loss = 3.218746
2018-12-04 23:12:20,707 - INFO - epoch 0, step 38980, training loss = 3.548546, validation loss = 2.670140
2018-12-04 23:12:24,743 - INFO - epoch 0, step 38990, training loss = 3.389895, validation loss = 3.255101
2018-12-04 23:12:29,000 - INFO - epoch 0, step 39000, training loss = 2.751529, validation loss = 2.981172
2018-12-04 23:12:33,077 - INFO - epoch 0, step 39010, training loss = 2.771670, validation loss = 3.658920
2018-12-04 23:12:37,880 - INFO - epoch 0, step 39020, training loss = 2.850630, validation loss = 3.317245
2018-12-04 23:12:44,053 - INFO - epoch 0, step 39030, training loss = 2.608707, validation loss = 3.086116
2018-12-04 23:12:49,644 - INFO - epoch 0, step 39040, training loss = 2.425440, validation loss = 2.966171
2018-12-04 23:12:55,104 - INFO - epoch 0, step 39050, training loss = 2.324944, validation loss = 2.865495
2018-12-04 23:13:00,737 - INFO - epoch 0, step 39060, training loss = 2.209374, validation loss = 3.926435
2018-12-04 23:13:06,160 - INFO - epoch 0, step 39070, training loss = 2.266564, validation loss = 2.990984
2018-12-04 23:13:11,581 - INFO - epoch 0, step 39080, training loss = 2.519439, validation loss = 2.422481
2018-12-04 23:13:16,624 - INFO - epoch 0, step 39090, training loss = 2.203001, validation loss = 2.694750
2018-12-04 23:13:21,756 - INFO - epoch 0, step 39100, training loss = 2.776783, validation loss = 2.927537
2018-12-04 23:13:26,056 - INFO - epoch 0, step 39110, training loss = 3.326726, validation loss = 3.088695
2018-12-04 23:13:30,032 - INFO - epoch 0, step 39120, training loss = 3.164834, validation loss = 3.414774
2018-12-04 23:13:34,211 - INFO - epoch 0, step 39130, training loss = 3.244307, validation loss = 3.299853
2018-12-04 23:13:38,579 - INFO - epoch 0, step 39140, training loss = 3.127010, validation loss = 3.539231
2018-12-04 23:13:43,072 - INFO - epoch 0, step 39150, training loss = 3.252825, validation loss = 3.132464
2018-12-04 23:13:47,161 - INFO - epoch 0, step 39160, training loss = 3.120086, validation loss = 3.109956
2018-12-04 23:13:51,202 - INFO - epoch 0, step 39170, training loss = 3.346930, validation loss = 2.776361
2018-12-04 23:13:55,467 - INFO - epoch 0, step 39180, training loss = 2.699473, validation loss = 3.136312
2018-12-04 23:13:59,574 - INFO - epoch 0, step 39190, training loss = 3.125325, validation loss = 3.330672
2018-12-04 23:14:04,040 - INFO - epoch 0, step 39200, training loss = 2.853379, validation loss = 3.219122
2018-12-04 23:14:09,316 - INFO - epoch 0, step 39210, training loss = 2.466058, validation loss = 3.837710
2018-12-04 23:14:14,175 - INFO - epoch 0, step 39220, training loss = 2.817122, validation loss = 3.081736
2018-12-04 23:14:19,781 - INFO - epoch 0, step 39230, training loss = 2.781677, validation loss = 2.859473
2018-12-04 23:14:25,277 - INFO - epoch 0, step 39240, training loss = 2.275105, validation loss = 2.955098
2018-12-04 23:14:30,690 - INFO - epoch 0, step 39250, training loss = 2.258718, validation loss = 3.025105
2018-12-04 23:14:35,884 - INFO - epoch 0, step 39260, training loss = 2.326468, validation loss = 2.956633
2018-12-04 23:14:41,307 - INFO - epoch 0, step 39270, training loss = 2.311318, validation loss = 2.602985
2018-12-04 23:14:46,290 - INFO - epoch 0, step 39280, training loss = 3.041479, validation loss = 2.905071
2018-12-04 23:14:51,725 - INFO - epoch 0, step 39290, training loss = 2.542468, validation loss = 3.324551
2018-12-04 23:14:57,018 - INFO - epoch 0, step 39300, training loss = 2.009582, validation loss = 3.054017
2018-12-04 23:15:01,864 - INFO - epoch 0, step 39310, training loss = 3.003780, validation loss = 3.802820
2018-12-04 23:15:06,290 - INFO - epoch 0, step 39320, training loss = 2.303875, validation loss = 2.564649
2018-12-04 23:15:11,671 - INFO - epoch 0, step 39330, training loss = 2.347823, validation loss = 2.692581
2018-12-04 23:15:15,717 - INFO - epoch 0, step 39340, training loss = 3.039100, validation loss = 2.800519
2018-12-04 23:15:19,386 - INFO - epoch 0, step 39350, training loss = 3.073605, validation loss = 3.137705
2018-12-04 23:15:23,195 - INFO - epoch 0, step 39360, training loss = 2.978440, validation loss = 2.865974
2018-12-04 23:15:27,117 - INFO - epoch 0, step 39370, training loss = 2.618536, validation loss = 3.807660
2018-12-04 23:15:30,744 - INFO - epoch 0, step 39380, training loss = 3.452842, validation loss = 3.634168
2018-12-04 23:15:34,419 - INFO - epoch 0, step 39390, training loss = 2.691723, validation loss = 3.320970
2018-12-04 23:15:39,135 - INFO - epoch 0, step 39400, training loss = 2.629053, validation loss = 2.959304
2018-12-04 23:15:44,970 - INFO - epoch 0, step 39410, training loss = 2.667509, validation loss = 2.899734
2018-12-04 23:15:50,601 - INFO - epoch 0, step 39420, training loss = 2.201586, validation loss = 3.211314
2018-12-04 23:15:55,940 - INFO - epoch 0, step 39430, training loss = 3.128341, validation loss = 3.219594
2018-12-04 23:16:01,572 - INFO - epoch 0, step 39440, training loss = 2.411064, validation loss = 2.782487
2018-12-04 23:16:07,081 - INFO - epoch 0, step 39450, training loss = 2.322154, validation loss = 2.968071
2018-12-04 23:16:12,784 - INFO - epoch 0, step 39460, training loss = 1.841148, validation loss = 3.266741
2018-12-04 23:16:18,229 - INFO - epoch 0, step 39470, training loss = 2.648196, validation loss = 2.793415
2018-12-04 23:16:22,597 - INFO - epoch 0, step 39480, training loss = 2.669460, validation loss = 2.943148
2018-12-04 23:16:26,316 - INFO - epoch 0, step 39490, training loss = 2.959910, validation loss = 3.158427
2018-12-04 23:16:30,104 - INFO - epoch 0, step 39500, training loss = 3.265453, validation loss = 3.146831
2018-12-04 23:16:34,036 - INFO - epoch 0, step 39510, training loss = 3.149279, validation loss = 3.295972
2018-12-04 23:16:38,074 - INFO - epoch 0, step 39520, training loss = 3.009418, validation loss = 3.078486
2018-12-04 23:16:42,080 - INFO - epoch 0, step 39530, training loss = 3.126043, validation loss = 3.498104
2018-12-04 23:16:47,253 - INFO - epoch 0, step 39540, training loss = 2.338628, validation loss = 3.098089
2018-12-04 23:16:52,514 - INFO - epoch 0, step 39550, training loss = 2.139523, validation loss = 2.688226
2018-12-04 23:16:57,508 - INFO - epoch 0, step 39560, training loss = 2.497265, validation loss = 2.567134
2018-12-04 23:17:02,561 - INFO - epoch 0, step 39570, training loss = 2.788165, validation loss = 2.818575
2018-12-04 23:17:07,847 - INFO - epoch 0, step 39580, training loss = 2.133683, validation loss = 3.228449
2018-12-04 23:17:13,491 - INFO - epoch 0, step 39590, training loss = 2.321048, validation loss = 2.928422
2018-12-04 23:17:18,925 - INFO - epoch 0, step 39600, training loss = 2.497398, validation loss = 3.022391
2018-12-04 23:17:24,439 - INFO - epoch 0, step 39610, training loss = 2.168546, validation loss = 2.862755
2018-12-04 23:17:29,285 - INFO - epoch 0, step 39620, training loss = 2.784185, validation loss = 2.797209
2018-12-04 23:17:34,817 - INFO - epoch 0, step 39630, training loss = 1.764294, validation loss = 2.721659
2018-12-04 23:17:39,732 - INFO - epoch 0, step 39640, training loss = 2.563210, validation loss = 2.920820
2018-12-04 23:17:45,478 - INFO - epoch 0, step 39650, training loss = 2.462281, validation loss = 3.204354
2018-12-04 23:17:51,248 - INFO - epoch 0, step 39660, training loss = 1.873200, validation loss = 2.963857
2018-12-04 23:17:56,850 - INFO - epoch 0, step 39670, training loss = 2.612116, validation loss = 3.380505
2018-12-04 23:18:02,566 - INFO - epoch 0, step 39680, training loss = 2.877313, validation loss = 2.829911
2018-12-04 23:18:08,513 - INFO - epoch 0, step 39690, training loss = 1.880335, validation loss = 2.749953
2018-12-04 23:18:13,295 - INFO - epoch 0, step 39700, training loss = 2.927268, validation loss = 3.373945
2018-12-04 23:18:18,778 - INFO - epoch 0, step 39710, training loss = 2.779665, validation loss = 3.148925
2018-12-04 23:18:24,009 - INFO - epoch 0, step 39720, training loss = 2.314726, validation loss = 3.271202
2018-12-04 23:18:29,628 - INFO - epoch 0, step 39730, training loss = 2.943299, validation loss = 3.415276
2018-12-04 23:18:33,446 - INFO - epoch 0, step 39740, training loss = 3.164583, validation loss = 3.242080
2018-12-04 23:18:37,393 - INFO - epoch 0, step 39750, training loss = 3.080509, validation loss = 3.342674
2018-12-04 23:18:41,258 - INFO - epoch 0, step 39760, training loss = 2.902651, validation loss = 3.240613
2018-12-04 23:18:45,290 - INFO - epoch 0, step 39770, training loss = 3.094812, validation loss = 3.461396
2018-12-04 23:18:48,936 - INFO - epoch 0, step 39780, training loss = 3.036284, validation loss = 3.632617
2018-12-04 23:18:52,866 - INFO - epoch 0, step 39790, training loss = 3.319891, validation loss = 3.196580
2018-12-04 23:18:56,875 - INFO - epoch 0, step 39800, training loss = 3.057855, validation loss = 2.696547
2018-12-04 23:19:01,125 - INFO - epoch 0, step 39810, training loss = 3.132612, validation loss = 2.981141
2018-12-04 23:19:05,045 - INFO - epoch 0, step 39820, training loss = 3.225330, validation loss = 3.200188
2018-12-04 23:19:09,109 - INFO - epoch 0, step 39830, training loss = 3.348953, validation loss = 3.127990
2018-12-04 23:19:13,165 - INFO - epoch 0, step 39840, training loss = 3.045634, validation loss = 3.650582
2018-12-04 23:19:17,033 - INFO - epoch 0, step 39850, training loss = 3.295747, validation loss = 3.614517
2018-12-04 23:19:21,043 - INFO - epoch 0, step 39860, training loss = 3.314262, validation loss = 3.146008
2018-12-04 23:19:25,088 - INFO - epoch 0, step 39870, training loss = 2.857476, validation loss = 2.823501
2018-12-04 23:19:30,198 - INFO - epoch 0, step 39880, training loss = 3.227928, validation loss = 3.241594
2018-12-04 23:19:35,149 - INFO - epoch 0, step 39890, training loss = 2.832232, validation loss = 3.010422
2018-12-04 23:19:40,483 - INFO - epoch 0, step 39900, training loss = 2.417909, validation loss = 3.327485
2018-12-04 23:19:45,417 - INFO - epoch 0, step 39910, training loss = 2.545292, validation loss = 3.325034
2018-12-04 23:19:50,896 - INFO - epoch 0, step 39920, training loss = 2.123994, validation loss = 3.013195
2018-12-04 23:19:56,272 - INFO - epoch 0, step 39930, training loss = 1.950171, validation loss = 3.226983
2018-12-04 23:20:01,492 - INFO - epoch 0, step 39940, training loss = 2.025180, validation loss = 3.133593
2018-12-04 23:20:06,963 - INFO - epoch 0, step 39950, training loss = 2.516618, validation loss = 2.511800
2018-12-04 23:20:12,296 - INFO - epoch 0, step 39960, training loss = 2.149780, validation loss = 2.656660
2018-12-04 23:20:17,956 - INFO - epoch 0, step 39970, training loss = 2.911128, validation loss = 2.971758
2018-12-04 23:20:22,368 - INFO - epoch 0, step 39980, training loss = 3.030984, validation loss = 3.180738
2018-12-04 23:20:26,322 - INFO - epoch 0, step 39990, training loss = 3.389633, validation loss = 3.492675
2018-12-04 23:20:30,121 - INFO - epoch 0, step 40000, training loss = 2.947624, validation loss = 3.431508
2018-12-04 23:20:33,886 - INFO - epoch 0, step 40010, training loss = 3.310706, validation loss = 3.455665
2018-12-04 23:20:37,641 - INFO - epoch 0, step 40020, training loss = 3.278416, validation loss = 3.117059
2018-12-04 23:20:41,733 - INFO - epoch 0, step 40030, training loss = 3.429080, validation loss = 3.268390
2018-12-04 23:20:45,777 - INFO - epoch 0, step 40040, training loss = 2.858247, validation loss = 3.347423
2018-12-04 23:20:49,841 - INFO - epoch 0, step 40050, training loss = 3.560567, validation loss = 3.264861
2018-12-04 23:20:53,941 - INFO - epoch 0, step 40060, training loss = 3.265116, validation loss = 3.358624
2018-12-04 23:20:57,893 - INFO - epoch 0, step 40070, training loss = 2.720458, validation loss = 3.363632
2018-12-04 23:21:01,915 - INFO - epoch 0, step 40080, training loss = 2.936049, validation loss = 3.440366
2018-12-04 23:21:05,979 - INFO - epoch 0, step 40090, training loss = 3.321863, validation loss = 2.685078
2018-12-04 23:21:10,182 - INFO - epoch 0, step 40100, training loss = 3.248386, validation loss = 2.885343
2018-12-04 23:21:13,776 - INFO - epoch 0, step 40110, training loss = 2.895432, validation loss = 2.600361
2018-12-04 23:21:17,413 - INFO - epoch 0, step 40120, training loss = 3.198552, validation loss = 3.026044
2018-12-04 23:21:21,236 - INFO - epoch 0, step 40130, training loss = 2.933981, validation loss = 3.312382
2018-12-04 23:21:25,168 - INFO - epoch 0, step 40140, training loss = 3.023729, validation loss = 3.048283
2018-12-04 23:21:28,890 - INFO - epoch 0, step 40150, training loss = 3.266956, validation loss = 3.151518
2018-12-04 23:21:32,723 - INFO - epoch 0, step 40160, training loss = 2.744809, validation loss = 3.247801
2018-12-04 23:21:36,459 - INFO - epoch 0, step 40170, training loss = 3.175381, validation loss = 2.389668
2018-12-04 23:21:40,498 - INFO - epoch 0, step 40180, training loss = 2.911803, validation loss = 2.418278
2018-12-04 23:21:44,465 - INFO - epoch 0, step 40190, training loss = 3.234857, validation loss = 2.813949
2018-12-04 23:21:48,117 - INFO - epoch 0, step 40200, training loss = 2.978482, validation loss = 2.720260
2018-12-04 23:21:51,946 - INFO - epoch 0, step 40210, training loss = 2.869517, validation loss = 2.480963
2018-12-04 23:21:55,631 - INFO - epoch 0, step 40220, training loss = 3.144869, validation loss = 3.288458
2018-12-04 23:21:59,570 - INFO - epoch 0, step 40230, training loss = 3.340228, validation loss = 3.136607
2018-12-04 23:22:03,658 - INFO - epoch 0, step 40240, training loss = 3.141896, validation loss = 2.395787
2018-12-04 23:22:07,874 - INFO - epoch 0, step 40250, training loss = 2.612232, validation loss = 2.270629
2018-12-04 23:22:12,200 - INFO - epoch 0, step 40260, training loss = 2.609952, validation loss = 2.017996
2018-12-04 23:22:16,426 - INFO - epoch 0, step 40270, training loss = 2.258100, validation loss = 1.870279
2018-12-04 23:22:20,686 - INFO - epoch 0, step 40280, training loss = 2.936947, validation loss = 2.599864
2018-12-04 23:22:25,179 - INFO - epoch 0, step 40290, training loss = 2.737030, validation loss = 2.255857
2018-12-04 23:22:29,523 - INFO - epoch 0, step 40300, training loss = 3.060513, validation loss = 2.185002
2018-12-04 23:22:34,026 - INFO - epoch 0, step 40310, training loss = 2.955291, validation loss = 2.589538
2018-12-04 23:22:37,916 - INFO - epoch 0, step 40320, training loss = 3.147054, validation loss = 2.499985
2018-12-04 23:22:41,793 - INFO - epoch 0, step 40330, training loss = 2.920304, validation loss = 2.599145
2018-12-04 23:22:46,239 - INFO - epoch 0, step 40340, training loss = 2.879514, validation loss = 2.725736
2018-12-04 23:22:50,194 - INFO - epoch 0, step 40350, training loss = 3.113732, validation loss = 2.143061
2018-12-04 23:22:54,206 - INFO - epoch 0, step 40360, training loss = 3.601571, validation loss = 2.296924
2018-12-04 23:22:58,173 - INFO - epoch 0, step 40370, training loss = 3.119202, validation loss = 2.220042
2018-12-04 23:23:02,443 - INFO - epoch 0, step 40380, training loss = 2.416374, validation loss = 2.401693
2018-12-04 23:23:06,315 - INFO - epoch 0, step 40390, training loss = 3.129714, validation loss = 3.205747
2018-12-04 23:23:10,213 - INFO - epoch 0, step 40400, training loss = 2.953592, validation loss = 2.635276
2018-12-04 23:23:14,410 - INFO - epoch 0, step 40410, training loss = 3.526973, validation loss = 2.722174
2018-12-04 23:23:18,580 - INFO - epoch 0, step 40420, training loss = 2.636292, validation loss = 2.753467
2018-12-04 23:23:24,130 - INFO - epoch 0, step 40430, training loss = 2.585370, validation loss = 2.053771
2018-12-04 23:23:29,647 - INFO - epoch 0, step 40440, training loss = 2.715579, validation loss = 2.049647
2018-12-04 23:23:35,286 - INFO - epoch 0, step 40450, training loss = 2.493255, validation loss = 2.425352
2018-12-04 23:23:39,479 - INFO - epoch 0, step 40460, training loss = 2.998038, validation loss = 2.468307
2018-12-04 23:23:43,309 - INFO - epoch 0, step 40470, training loss = 3.019420, validation loss = 2.179741
2018-12-04 23:23:47,206 - INFO - epoch 0, step 40480, training loss = 3.732178, validation loss = 2.361642
2018-12-04 23:23:50,962 - INFO - epoch 0, step 40490, training loss = 2.758916, validation loss = 2.669211
2018-12-04 23:23:54,627 - INFO - epoch 0, step 40500, training loss = 2.682612, validation loss = 2.305496
2018-12-04 23:23:58,486 - INFO - epoch 0, step 40510, training loss = 2.583411, validation loss = 2.344573
2018-12-04 23:24:02,566 - INFO - epoch 0, step 40520, training loss = 2.910607, validation loss = 2.015576
2018-12-04 23:24:06,376 - INFO - epoch 0, step 40530, training loss = 2.415662, validation loss = 2.906895
2018-12-04 23:24:10,140 - INFO - epoch 0, step 40540, training loss = 2.886370, validation loss = 2.348951
2018-12-04 23:24:14,182 - INFO - epoch 0, step 40550, training loss = 3.220891, validation loss = 2.743410
2018-12-04 23:24:18,130 - INFO - epoch 0, step 40560, training loss = 2.739949, validation loss = 2.398350
2018-12-04 23:24:22,473 - INFO - epoch 0, step 40570, training loss = 2.470595, validation loss = 2.023414
2018-12-04 23:24:27,914 - INFO - epoch 0, step 40580, training loss = 2.032268, validation loss = 2.286874
2018-12-04 23:24:32,973 - INFO - epoch 0, step 40590, training loss = 3.171208, validation loss = 2.710035
2018-12-04 23:24:37,972 - INFO - epoch 0, step 40600, training loss = 2.510439, validation loss = 2.698337
2018-12-04 23:24:43,027 - INFO - epoch 0, step 40610, training loss = 2.033952, validation loss = 2.767562
2018-12-04 23:24:48,392 - INFO - epoch 0, step 40620, training loss = 2.489473, validation loss = 2.118968
2018-12-04 23:24:53,479 - INFO - epoch 0, step 40630, training loss = 2.105511, validation loss = 2.512241
2018-12-04 23:24:58,709 - INFO - epoch 0, step 40640, training loss = 2.704908, validation loss = 2.533802
2018-12-04 23:25:04,061 - INFO - epoch 0, step 40650, training loss = 2.889933, validation loss = 2.710650
2018-12-04 23:25:09,547 - INFO - epoch 0, step 40660, training loss = 2.597250, validation loss = 2.628379
2018-12-04 23:25:15,034 - INFO - epoch 0, step 40670, training loss = 2.571651, validation loss = 2.625788
2018-12-04 23:25:20,447 - INFO - epoch 0, step 40680, training loss = 2.676932, validation loss = 2.737433
2018-12-04 23:25:26,220 - INFO - epoch 0, step 40690, training loss = 2.579587, validation loss = 2.295124
2018-12-04 23:25:30,672 - INFO - epoch 0, step 40700, training loss = 2.807097, validation loss = 2.773511
2018-12-04 23:25:35,012 - INFO - epoch 0, step 40710, training loss = 2.523077, validation loss = 2.948340
2018-12-04 23:25:39,433 - INFO - epoch 0, step 40720, training loss = 3.241614, validation loss = 2.740374
2018-12-04 23:25:43,841 - INFO - epoch 0, step 40730, training loss = 2.894587, validation loss = 2.804753
2018-12-04 23:25:48,343 - INFO - epoch 0, step 40740, training loss = 2.802087, validation loss = 2.453689
2018-12-04 23:25:52,619 - INFO - epoch 0, step 40750, training loss = 3.280752, validation loss = 2.568410
2018-12-04 23:25:57,051 - INFO - epoch 0, step 40760, training loss = 2.284257, validation loss = 2.108960
2018-12-04 23:26:01,340 - INFO - epoch 0, step 40770, training loss = 3.016442, validation loss = 2.263320
2018-12-04 23:26:05,447 - INFO - epoch 0, step 40780, training loss = 3.048956, validation loss = 2.427957
2018-12-04 23:26:09,540 - INFO - epoch 0, step 40790, training loss = 2.860646, validation loss = 2.613181
2018-12-04 23:26:13,393 - INFO - epoch 0, step 40800, training loss = 2.958611, validation loss = 2.580944
2018-12-04 23:26:17,747 - INFO - epoch 0, step 40810, training loss = 3.066087, validation loss = 2.667807
2018-12-04 23:26:21,972 - INFO - epoch 0, step 40820, training loss = 3.260724, validation loss = 2.470156
2018-12-04 23:26:26,541 - INFO - epoch 0, step 40830, training loss = 2.664646, validation loss = 2.339283
2018-12-04 23:26:30,724 - INFO - epoch 0, step 40840, training loss = 2.991494, validation loss = 2.586638
2018-12-04 23:26:35,171 - INFO - epoch 0, step 40850, training loss = 2.497823, validation loss = 1.907084
2018-12-04 23:26:39,109 - INFO - epoch 0, step 40860, training loss = 2.749914, validation loss = 2.722589
2018-12-04 23:26:43,202 - INFO - epoch 0, step 40870, training loss = 3.432337, validation loss = 2.713407
2018-12-04 23:26:47,105 - INFO - epoch 0, step 40880, training loss = 2.958883, validation loss = 2.833531
2018-12-04 23:26:51,241 - INFO - epoch 0, step 40890, training loss = 2.941979, validation loss = 2.296610
2018-12-04 23:26:55,331 - INFO - epoch 0, step 40900, training loss = 2.999091, validation loss = 2.622096
2018-12-04 23:26:59,535 - INFO - epoch 0, step 40910, training loss = 3.145221, validation loss = 2.654062
2018-12-04 23:27:03,402 - INFO - epoch 0, step 40920, training loss = 2.320855, validation loss = 3.240267
2018-12-04 23:27:07,549 - INFO - epoch 0, step 40930, training loss = 3.227584, validation loss = 1.836881
2018-12-04 23:27:11,455 - INFO - epoch 0, step 40940, training loss = 3.339052, validation loss = 2.739724
2018-12-04 23:27:15,500 - INFO - epoch 0, step 40950, training loss = 3.223927, validation loss = 2.362170
2018-12-04 23:27:19,783 - INFO - epoch 0, step 40960, training loss = 2.083448, validation loss = 2.102874
2018-12-04 23:27:23,650 - INFO - epoch 0, step 40970, training loss = 2.858952, validation loss = 2.817916
2018-12-04 23:27:27,773 - INFO - epoch 0, step 40980, training loss = 3.117859, validation loss = 2.589313
2018-12-04 23:27:32,078 - INFO - epoch 0, step 40990, training loss = 2.730615, validation loss = 2.715695
2018-12-04 23:27:36,185 - INFO - epoch 0, step 41000, training loss = 2.706640, validation loss = 3.046061
2018-12-04 23:27:40,573 - INFO - epoch 0, step 41010, training loss = 2.804092, validation loss = 2.448272
2018-12-04 23:27:44,965 - INFO - epoch 0, step 41020, training loss = 2.676592, validation loss = 2.362173
2018-12-04 23:27:49,177 - INFO - epoch 0, step 41030, training loss = 2.969151, validation loss = 2.636829
2018-12-04 23:27:53,348 - INFO - epoch 0, step 41040, training loss = 3.074079, validation loss = 2.493164
2018-12-04 23:27:57,874 - INFO - epoch 0, step 41050, training loss = 2.690724, validation loss = 2.695021
2018-12-04 23:28:01,975 - INFO - epoch 0, step 41060, training loss = 2.766510, validation loss = 2.480394
2018-12-04 23:28:06,198 - INFO - epoch 0, step 41070, training loss = 2.802033, validation loss = 2.911947
2018-12-04 23:28:10,283 - INFO - epoch 0, step 41080, training loss = 2.765724, validation loss = 3.054323
2018-12-04 23:28:14,640 - INFO - epoch 0, step 41090, training loss = 2.901959, validation loss = 2.274059
2018-12-04 23:28:18,533 - INFO - epoch 0, step 41100, training loss = 3.492201, validation loss = 2.474314
2018-12-04 23:28:22,658 - INFO - epoch 0, step 41110, training loss = 2.632846, validation loss = 2.410151
2018-12-04 23:28:26,612 - INFO - epoch 0, step 41120, training loss = 2.742870, validation loss = 2.419171
2018-12-04 23:28:30,878 - INFO - epoch 0, step 41130, training loss = 3.448726, validation loss = 2.665104
2018-12-04 23:28:35,061 - INFO - epoch 0, step 41140, training loss = 3.113912, validation loss = 2.814714
2018-12-04 23:28:39,016 - INFO - epoch 0, step 41150, training loss = 2.914060, validation loss = 2.542254
2018-12-04 23:28:43,242 - INFO - epoch 0, step 41160, training loss = 3.032319, validation loss = 2.426375
2018-12-04 23:28:47,598 - INFO - epoch 0, step 41170, training loss = 2.755564, validation loss = 2.773643
2018-12-04 23:28:51,521 - INFO - epoch 0, step 41180, training loss = 2.486281, validation loss = 2.673829
2018-12-04 23:28:55,743 - INFO - epoch 0, step 41190, training loss = 2.782465, validation loss = 2.311107
2018-12-04 23:28:59,710 - INFO - epoch 0, step 41200, training loss = 2.999646, validation loss = 3.078831
2018-12-04 23:29:04,063 - INFO - epoch 0, step 41210, training loss = 3.062881, validation loss = 2.927919
2018-12-04 23:29:08,171 - INFO - epoch 0, step 41220, training loss = 3.114300, validation loss = 2.773298
2018-12-04 23:29:12,227 - INFO - epoch 0, step 41230, training loss = 2.809168, validation loss = 2.338926
2018-12-04 23:29:16,264 - INFO - epoch 0, step 41240, training loss = 2.565633, validation loss = 2.596371
2018-12-04 23:29:20,513 - INFO - epoch 0, step 41250, training loss = 2.973903, validation loss = 2.183826
2018-12-04 23:29:24,627 - INFO - epoch 0, step 41260, training loss = 2.716626, validation loss = 2.962553
2018-12-04 23:29:28,856 - INFO - epoch 0, step 41270, training loss = 2.881249, validation loss = 2.855246
2018-12-04 23:29:32,630 - INFO - epoch 0, step 41280, training loss = 3.425505, validation loss = 2.724857
2018-12-04 23:29:36,536 - INFO - epoch 0, step 41290, training loss = 3.505684, validation loss = 3.002538
2018-12-04 23:29:40,662 - INFO - epoch 0, step 41300, training loss = 2.844440, validation loss = 2.726253
2018-12-04 23:29:44,623 - INFO - epoch 0, step 41310, training loss = 3.092295, validation loss = 2.618171
2018-12-04 23:29:48,492 - INFO - epoch 0, step 41320, training loss = 2.750673, validation loss = 3.263716
2018-12-04 23:29:52,469 - INFO - epoch 0, step 41330, training loss = 2.900383, validation loss = 3.301697
2018-12-04 23:29:56,559 - INFO - epoch 0, step 41340, training loss = 3.353110, validation loss = 2.819457
2018-12-04 23:30:00,669 - INFO - epoch 0, step 41350, training loss = 2.685377, validation loss = 2.992813
2018-12-04 23:30:04,567 - INFO - epoch 0, step 41360, training loss = 2.918392, validation loss = 2.498360
2018-12-04 23:30:08,564 - INFO - epoch 0, step 41370, training loss = 2.718983, validation loss = 2.846268
2018-12-04 23:30:13,967 - INFO - epoch 0, step 41380, training loss = 2.400548, validation loss = 2.621617
2018-12-04 23:30:19,327 - INFO - epoch 0, step 41390, training loss = 2.966932, validation loss = 2.335445
2018-12-04 23:30:24,580 - INFO - epoch 0, step 41400, training loss = 2.644791, validation loss = 2.544380
2018-12-04 23:30:29,868 - INFO - epoch 0, step 41410, training loss = 2.893518, validation loss = 2.910334
2018-12-04 23:30:35,950 - INFO - epoch 0, step 41420, training loss = 2.105267, validation loss = 2.345385
2018-12-04 23:30:42,161 - INFO - epoch 0, step 41430, training loss = 2.124859, validation loss = 3.005748
2018-12-04 23:30:47,289 - INFO - epoch 0, step 41440, training loss = 2.336513, validation loss = 2.145190
2018-12-04 23:30:52,944 - INFO - epoch 0, step 41450, training loss = 2.802738, validation loss = 2.558890
2018-12-04 23:30:58,787 - INFO - epoch 0, step 41460, training loss = 2.300532, validation loss = 2.711741
2018-12-04 23:31:04,262 - INFO - epoch 0, step 41470, training loss = 2.667854, validation loss = 2.769374
2018-12-04 23:31:09,741 - INFO - epoch 0, step 41480, training loss = 2.509116, validation loss = 2.445338
2018-12-04 23:31:14,504 - INFO - epoch 0, step 41490, training loss = 3.082307, validation loss = 2.414139
2018-12-04 23:31:18,641 - INFO - epoch 0, step 41500, training loss = 2.890815, validation loss = 2.669274
2018-12-04 23:31:22,885 - INFO - epoch 0, step 41510, training loss = 2.758851, validation loss = 2.671077
2018-12-04 23:31:27,093 - INFO - epoch 0, step 41520, training loss = 3.131892, validation loss = 2.688310
2018-12-04 23:31:31,480 - INFO - epoch 0, step 41530, training loss = 3.005511, validation loss = 2.321038
2018-12-04 23:31:35,872 - INFO - epoch 0, step 41540, training loss = 3.120252, validation loss = 2.541971
2018-12-04 23:31:39,990 - INFO - epoch 0, step 41550, training loss = 3.316307, validation loss = 2.685374
2018-12-04 23:31:44,725 - INFO - epoch 0, step 41560, training loss = 2.788371, validation loss = 2.830596
2018-12-04 23:31:50,654 - INFO - epoch 0, step 41570, training loss = 2.558560, validation loss = 2.182170
2018-12-04 23:31:56,056 - INFO - epoch 0, step 41580, training loss = 2.429740, validation loss = 2.612248
2018-12-04 23:32:01,604 - INFO - epoch 0, step 41590, training loss = 1.710331, validation loss = 2.257753
2018-12-04 23:32:06,888 - INFO - epoch 0, step 41600, training loss = 2.435091, validation loss = 3.006691
2018-12-04 23:32:12,114 - INFO - epoch 0, step 41610, training loss = 1.741851, validation loss = 2.564881
2018-12-04 23:32:17,583 - INFO - epoch 0, step 41620, training loss = 2.620832, validation loss = 2.999312
2018-12-04 23:32:23,506 - INFO - epoch 0, step 41630, training loss = 1.906440, validation loss = 2.540591
2018-12-04 23:32:28,671 - INFO - epoch 0, step 41640, training loss = 2.770596, validation loss = 2.831569
2018-12-04 23:32:32,962 - INFO - epoch 0, step 41650, training loss = 2.834094, validation loss = 2.463938
2018-12-04 23:32:37,076 - INFO - epoch 0, step 41660, training loss = 2.962698, validation loss = 2.222856
2018-12-04 23:32:41,155 - INFO - epoch 0, step 41670, training loss = 3.173346, validation loss = 2.464364
2018-12-04 23:32:45,461 - INFO - epoch 0, step 41680, training loss = 2.627881, validation loss = 2.129518
2018-12-04 23:32:49,795 - INFO - epoch 0, step 41690, training loss = 3.260595, validation loss = 2.527929
2018-12-04 23:32:54,047 - INFO - epoch 0, step 41700, training loss = 2.358097, validation loss = 2.632217
2018-12-04 23:32:58,436 - INFO - epoch 0, step 41710, training loss = 3.107409, validation loss = 2.369510
2018-12-04 23:33:02,653 - INFO - epoch 0, step 41720, training loss = 2.835425, validation loss = 2.199907
2018-12-04 23:33:07,255 - INFO - epoch 0, step 41730, training loss = 2.550436, validation loss = 2.601078
2018-12-04 23:33:12,860 - INFO - epoch 0, step 41740, training loss = 1.993511, validation loss = 2.498704
2018-12-04 23:33:17,987 - INFO - epoch 0, step 41750, training loss = 2.262087, validation loss = 2.535329
2018-12-04 23:33:23,303 - INFO - epoch 0, step 41760, training loss = 2.643019, validation loss = 2.816061
2018-12-04 23:33:27,355 - INFO - epoch 0, step 41770, training loss = 2.972997, validation loss = 2.458276
2018-12-04 23:33:31,520 - INFO - epoch 0, step 41780, training loss = 3.260426, validation loss = 2.524973
2018-12-04 23:33:35,636 - INFO - epoch 0, step 41790, training loss = 3.126340, validation loss = 3.147174
2018-12-04 23:33:39,678 - INFO - epoch 0, step 41800, training loss = 3.265657, validation loss = 2.809399
2018-12-04 23:33:43,770 - INFO - epoch 0, step 41810, training loss = 3.104811, validation loss = 2.357263
2018-12-04 23:33:47,768 - INFO - epoch 0, step 41820, training loss = 2.734795, validation loss = 2.257258
2018-12-04 23:33:51,989 - INFO - epoch 0, step 41830, training loss = 3.009166, validation loss = 2.875207
2018-12-04 23:33:56,110 - INFO - epoch 0, step 41840, training loss = 2.937308, validation loss = 3.097273
2018-12-04 23:34:00,469 - INFO - epoch 0, step 41850, training loss = 3.027088, validation loss = 2.330696
2018-12-04 23:34:04,442 - INFO - epoch 0, step 41860, training loss = 3.110127, validation loss = 2.122204
2018-12-04 23:34:08,515 - INFO - epoch 0, step 41870, training loss = 3.120111, validation loss = 2.509686
2018-12-04 23:34:12,484 - INFO - epoch 0, step 41880, training loss = 2.806547, validation loss = 2.694573
2018-12-04 23:34:16,405 - INFO - epoch 0, step 41890, training loss = 3.141593, validation loss = 2.647326
2018-12-04 23:34:21,143 - INFO - epoch 0, step 41900, training loss = 2.306828, validation loss = 2.393028
2018-12-04 23:34:27,142 - INFO - epoch 0, step 41910, training loss = 2.223412, validation loss = 1.929492
2018-12-04 23:34:32,414 - INFO - epoch 0, step 41920, training loss = 2.659609, validation loss = 2.111943
2018-12-04 23:34:37,558 - INFO - epoch 0, step 41930, training loss = 2.489963, validation loss = 2.589669
2018-12-04 23:34:42,719 - INFO - epoch 0, step 41940, training loss = 2.737812, validation loss = 2.062580
2018-12-04 23:34:48,090 - INFO - epoch 0, step 41950, training loss = 2.241480, validation loss = 2.894742
2018-12-04 23:34:53,578 - INFO - epoch 0, step 41960, training loss = 2.144329, validation loss = 2.637869
2018-12-04 23:34:59,279 - INFO - epoch 0, step 41970, training loss = 2.931527, validation loss = 2.539025
2018-12-04 23:35:04,926 - INFO - epoch 0, step 41980, training loss = 2.399036, validation loss = 2.565597
2018-12-04 23:35:10,799 - INFO - epoch 0, step 41990, training loss = 1.898453, validation loss = 2.856004
2018-12-04 23:35:14,746 - INFO - epoch 0, step 42000, training loss = 2.623788, validation loss = 2.807002
2018-12-04 23:35:18,713 - INFO - epoch 0, step 42010, training loss = 3.066665, validation loss = 2.490603
2018-12-04 23:35:22,799 - INFO - epoch 0, step 42020, training loss = 3.033422, validation loss = 2.499305
2018-12-04 23:35:27,038 - INFO - epoch 0, step 42030, training loss = 2.752349, validation loss = 2.791062
2018-12-04 23:35:30,949 - INFO - epoch 0, step 42040, training loss = 3.076921, validation loss = 2.831287
2018-12-04 23:35:35,142 - INFO - epoch 0, step 42050, training loss = 3.326663, validation loss = 2.537535
2018-12-04 23:35:39,509 - INFO - epoch 0, step 42060, training loss = 3.158995, validation loss = 2.177763
2018-12-04 23:35:43,943 - INFO - epoch 0, step 42070, training loss = 2.812480, validation loss = 2.397882
2018-12-04 23:35:48,232 - INFO - epoch 0, step 42080, training loss = 3.424346, validation loss = 2.536867
2018-12-04 23:35:52,365 - INFO - epoch 0, step 42090, training loss = 2.850598, validation loss = 3.204948
2018-12-04 23:35:56,652 - INFO - epoch 0, step 42100, training loss = 2.965674, validation loss = 2.964447
2018-12-04 23:36:00,815 - INFO - epoch 0, step 42110, training loss = 3.135507, validation loss = 3.294641
2018-12-04 23:36:05,250 - INFO - epoch 0, step 42120, training loss = 3.220860, validation loss = 2.649528
2018-12-04 23:36:09,617 - INFO - epoch 0, step 42130, training loss = 2.675132, validation loss = 3.033146
2018-12-04 23:36:14,940 - INFO - epoch 0, step 42140, training loss = 2.529049, validation loss = 2.738123
2018-12-04 23:36:20,782 - INFO - epoch 0, step 42150, training loss = 2.254180, validation loss = 3.333614
2018-12-04 23:36:26,394 - INFO - epoch 0, step 42160, training loss = 3.166997, validation loss = 2.807978
2018-12-04 23:36:32,339 - INFO - epoch 0, step 42170, training loss = 2.329719, validation loss = 2.525789
2018-12-04 23:36:38,036 - INFO - epoch 0, step 42180, training loss = 2.031565, validation loss = 2.843421
2018-12-04 23:36:42,694 - INFO - epoch 0, step 42190, training loss = 3.227536, validation loss = 3.152549
2018-12-04 23:36:46,838 - INFO - epoch 0, step 42200, training loss = 3.244894, validation loss = 2.557637
2018-12-04 23:36:50,966 - INFO - epoch 0, step 42210, training loss = 3.254694, validation loss = 2.464774
2018-12-04 23:36:54,952 - INFO - epoch 0, step 42220, training loss = 3.048971, validation loss = 3.025103
2018-12-04 23:36:59,249 - INFO - epoch 0, step 42230, training loss = 3.131838, validation loss = 2.585981
2018-12-04 23:37:03,521 - INFO - epoch 0, step 42240, training loss = 3.048378, validation loss = 2.874171
2018-12-04 23:37:07,741 - INFO - epoch 0, step 42250, training loss = 3.497492, validation loss = 3.083348
2018-12-04 23:37:12,068 - INFO - epoch 0, step 42260, training loss = 2.326035, validation loss = 3.318522
2018-12-04 23:37:16,022 - INFO - epoch 0, step 42270, training loss = 2.977614, validation loss = 3.053191
2018-12-04 23:37:19,961 - INFO - epoch 0, step 42280, training loss = 3.255644, validation loss = 2.901851
2018-12-04 23:37:23,832 - INFO - epoch 0, step 42290, training loss = 3.384742, validation loss = 2.741887
2018-12-04 23:37:27,656 - INFO - epoch 0, step 42300, training loss = 2.590318, validation loss = 2.577225
2018-12-04 23:37:31,599 - INFO - epoch 0, step 42310, training loss = 2.898667, validation loss = 3.405539
2018-12-04 23:37:35,407 - INFO - epoch 0, step 42320, training loss = 2.857308, validation loss = 2.769644
2018-12-04 23:37:39,544 - INFO - epoch 0, step 42330, training loss = 2.693731, validation loss = 2.922271
2018-12-04 23:37:43,432 - INFO - epoch 0, step 42340, training loss = 3.513227, validation loss = 3.279017
2018-12-04 23:37:47,651 - INFO - epoch 0, step 42350, training loss = 2.797614, validation loss = 2.687366
2018-12-04 23:37:52,086 - INFO - epoch 0, step 42360, training loss = 2.215378, validation loss = 2.478659
2018-12-04 23:37:56,314 - INFO - epoch 0, step 42370, training loss = 2.764945, validation loss = 2.281522
2018-12-04 23:38:00,713 - INFO - epoch 0, step 42380, training loss = 3.073515, validation loss = 2.997345
2018-12-04 23:38:04,650 - INFO - epoch 0, step 42390, training loss = 2.595078, validation loss = 3.018397
2018-12-04 23:38:08,786 - INFO - epoch 0, step 42400, training loss = 2.694631, validation loss = 3.350421
2018-12-04 23:38:13,126 - INFO - epoch 0, step 42410, training loss = 2.529304, validation loss = 3.538507
2018-12-04 23:38:18,014 - INFO - epoch 0, step 42420, training loss = 2.889633, validation loss = 2.961214
2018-12-04 23:38:23,399 - INFO - epoch 0, step 42430, training loss = 2.127653, validation loss = 3.110842
2018-12-04 23:38:28,609 - INFO - epoch 0, step 42440, training loss = 2.393662, validation loss = 2.590402
2018-12-04 23:38:34,496 - INFO - epoch 0, step 42450, training loss = 2.189237, validation loss = 2.917165
2018-12-04 23:38:40,203 - INFO - epoch 0, step 42460, training loss = 1.934340, validation loss = 2.421849
2018-12-04 23:38:45,775 - INFO - epoch 0, step 42470, training loss = 2.351403, validation loss = 2.629590
2018-12-04 23:38:51,067 - INFO - epoch 0, step 42480, training loss = 2.864036, validation loss = 2.840318
2018-12-04 23:38:56,195 - INFO - epoch 0, step 42490, training loss = 2.573963, validation loss = 3.133917
2018-12-04 23:39:01,288 - INFO - epoch 0, step 42500, training loss = 2.675547, validation loss = 3.156386
2018-12-04 23:39:06,475 - INFO - epoch 0, step 42510, training loss = 2.427774, validation loss = 2.974639
2018-12-04 23:39:11,869 - INFO - epoch 0, step 42520, training loss = 2.228211, validation loss = 2.654168
2018-12-04 23:39:17,191 - INFO - epoch 0, step 42530, training loss = 2.215281, validation loss = 3.584932
2018-12-04 23:39:23,298 - INFO - epoch 0, step 42540, training loss = 1.660973, validation loss = 3.082081
2018-12-04 23:39:27,127 - INFO - epoch 0, step 42550, training loss = 3.405869, validation loss = 3.044967
2018-12-04 23:39:31,190 - INFO - epoch 0, step 42560, training loss = 3.012736, validation loss = 2.954364
2018-12-04 23:39:35,199 - INFO - epoch 0, step 42570, training loss = 2.895889, validation loss = 2.815407
2018-12-04 23:39:39,144 - INFO - epoch 0, step 42580, training loss = 3.264102, validation loss = 2.809366
2018-12-04 23:39:42,983 - INFO - epoch 0, step 42590, training loss = 2.680818, validation loss = 2.716464
2018-12-04 23:39:47,291 - INFO - epoch 0, step 42600, training loss = 2.902317, validation loss = 2.828241
2018-12-04 23:39:51,450 - INFO - epoch 0, step 42610, training loss = 2.897864, validation loss = 3.156402
2018-12-04 23:39:55,539 - INFO - epoch 0, step 42620, training loss = 2.842925, validation loss = 2.474578
2018-12-04 23:39:59,570 - INFO - epoch 0, step 42630, training loss = 2.695844, validation loss = 2.365479
2018-12-04 23:40:03,765 - INFO - epoch 0, step 42640, training loss = 3.645807, validation loss = 2.478109
2018-12-04 23:40:07,843 - INFO - epoch 0, step 42650, training loss = 3.317152, validation loss = 3.437687
2018-12-04 23:40:12,143 - INFO - epoch 0, step 42660, training loss = 2.594069, validation loss = 3.699545
2018-12-04 23:40:16,270 - INFO - epoch 0, step 42670, training loss = 3.312674, validation loss = 3.136202
2018-12-04 23:40:20,481 - INFO - epoch 0, step 42680, training loss = 2.899489, validation loss = 2.930141
2018-12-04 23:40:24,767 - INFO - epoch 0, step 42690, training loss = 2.789464, validation loss = 3.325303
2018-12-04 23:40:28,927 - INFO - epoch 0, step 42700, training loss = 2.596142, validation loss = 2.850772
2018-12-04 23:40:32,949 - INFO - epoch 0, step 42710, training loss = 2.816753, validation loss = 2.866965
2018-12-04 23:40:37,278 - INFO - epoch 0, step 42720, training loss = 2.697149, validation loss = 2.892430
2018-12-04 23:40:41,587 - INFO - epoch 0, step 42730, training loss = 3.188915, validation loss = 3.072662
2018-12-04 23:40:45,902 - INFO - epoch 0, step 42740, training loss = 2.682945, validation loss = 2.915327
2018-12-04 23:40:50,316 - INFO - epoch 0, step 42750, training loss = 2.232402, validation loss = 2.970154
2018-12-04 23:40:56,511 - INFO - epoch 0, step 42760, training loss = 2.148567, validation loss = 2.663231
2018-12-04 23:41:02,683 - INFO - epoch 0, step 42770, training loss = 3.225863, validation loss = 2.798722
2018-12-04 23:41:08,272 - INFO - epoch 0, step 42780, training loss = 2.838434, validation loss = 3.410222
2018-12-04 23:41:13,630 - INFO - epoch 0, step 42790, training loss = 2.626937, validation loss = 2.983877
2018-12-04 23:41:19,484 - INFO - epoch 0, step 42800, training loss = 2.687118, validation loss = 2.956182
2018-12-04 23:41:25,325 - INFO - epoch 0, step 42810, training loss = 2.365482, validation loss = 3.042994
2018-12-04 23:41:30,862 - INFO - epoch 0, step 42820, training loss = 2.367216, validation loss = 3.245763
2018-12-04 23:41:36,413 - INFO - epoch 0, step 42830, training loss = 2.604478, validation loss = 3.160940
2018-12-04 23:41:40,537 - INFO - epoch 0, step 42840, training loss = 3.243994, validation loss = 2.925600
2018-12-04 23:41:44,266 - INFO - epoch 0, step 42850, training loss = 3.208172, validation loss = 3.072345
2018-12-04 23:41:48,041 - INFO - epoch 0, step 42860, training loss = 3.190834, validation loss = 3.224937
2018-12-04 23:41:51,737 - INFO - epoch 0, step 42870, training loss = 2.694579, validation loss = 2.797473
2018-12-04 23:41:55,536 - INFO - epoch 0, step 42880, training loss = 2.676058, validation loss = 2.943948
2018-12-04 23:41:59,336 - INFO - epoch 0, step 42890, training loss = 3.675449, validation loss = 3.000706
2018-12-04 23:42:03,345 - INFO - epoch 0, step 42900, training loss = 3.228190, validation loss = 3.100656
2018-12-04 23:42:07,326 - INFO - epoch 0, step 42910, training loss = 3.436341, validation loss = 3.037550
2018-12-04 23:42:11,272 - INFO - epoch 0, step 42920, training loss = 3.038990, validation loss = 2.263256
2018-12-04 23:42:15,261 - INFO - epoch 0, step 42930, training loss = 2.792601, validation loss = 2.766891
2018-12-04 23:42:19,147 - INFO - epoch 0, step 42940, training loss = 3.014381, validation loss = 3.134790
2018-12-04 23:42:23,012 - INFO - epoch 0, step 42950, training loss = 3.240889, validation loss = 2.307790
2018-12-04 23:42:27,059 - INFO - epoch 0, step 42960, training loss = 2.719012, validation loss = 2.999642
2018-12-04 23:42:31,015 - INFO - epoch 0, step 42970, training loss = 3.062155, validation loss = 2.545817
2018-12-04 23:42:35,066 - INFO - epoch 0, step 42980, training loss = 2.633662, validation loss = 3.285968
2018-12-04 23:42:38,897 - INFO - epoch 0, step 42990, training loss = 2.948306, validation loss = 2.813191
2018-12-04 23:42:44,113 - INFO - epoch 0, step 43000, training loss = 2.777315, validation loss = 3.015755
2018-12-04 23:42:49,480 - INFO - epoch 0, step 43010, training loss = 2.465635, validation loss = 2.780704
2018-12-04 23:42:54,752 - INFO - epoch 0, step 43020, training loss = 2.472348, validation loss = 3.069993
2018-12-04 23:42:59,489 - INFO - epoch 0, step 43030, training loss = 2.735022, validation loss = 3.099619
2018-12-04 23:43:03,969 - INFO - epoch 0, step 43040, training loss = 2.313329, validation loss = 3.803084
2018-12-04 23:43:08,775 - INFO - epoch 0, step 43050, training loss = 2.755199, validation loss = 3.433900
2018-12-04 23:43:14,541 - INFO - epoch 0, step 43060, training loss = 1.965425, validation loss = 3.054379
2018-12-04 23:43:20,049 - INFO - epoch 0, step 43070, training loss = 3.150705, validation loss = 2.805563
2018-12-04 23:43:25,874 - INFO - epoch 0, step 43080, training loss = 1.619173, validation loss = 3.033793
2018-12-04 23:43:30,103 - INFO - epoch 0, step 43090, training loss = 2.745804, validation loss = 2.956287
2018-12-04 23:43:34,277 - INFO - epoch 0, step 43100, training loss = 3.033209, validation loss = 3.147271
2018-12-04 23:43:38,099 - INFO - epoch 0, step 43110, training loss = 3.038837, validation loss = 3.229942
2018-12-04 23:43:42,417 - INFO - epoch 0, step 43120, training loss = 3.193884, validation loss = 2.406825
2018-12-04 23:43:46,976 - INFO - epoch 0, step 43130, training loss = 2.584853, validation loss = 2.392699
2018-12-04 23:43:50,866 - INFO - epoch 0, step 43140, training loss = 3.246073, validation loss = 2.885917
2018-12-04 23:43:54,733 - INFO - epoch 0, step 43150, training loss = 3.114442, validation loss = 2.890409
2018-12-04 23:43:58,725 - INFO - epoch 0, step 43160, training loss = 2.892955, validation loss = 2.943779
2018-12-04 23:44:03,155 - INFO - epoch 0, step 43170, training loss = 2.697043, validation loss = 2.618836
2018-12-04 23:44:07,258 - INFO - epoch 0, step 43180, training loss = 2.812567, validation loss = 3.014161
2018-12-04 23:44:11,520 - INFO - epoch 0, step 43190, training loss = 2.892381, validation loss = 3.060201
2018-12-04 23:44:16,084 - INFO - epoch 0, step 43200, training loss = 2.725152, validation loss = 2.146181
2018-12-04 23:44:20,231 - INFO - epoch 0, step 43210, training loss = 3.149841, validation loss = 3.068733
2018-12-04 23:44:24,363 - INFO - epoch 0, step 43220, training loss = 2.654617, validation loss = 3.362074
2018-12-04 23:44:28,267 - INFO - epoch 0, step 43230, training loss = 2.543108, validation loss = 3.094620
2018-12-04 23:44:32,159 - INFO - epoch 0, step 43240, training loss = 2.717062, validation loss = 2.424940
2018-12-04 23:44:36,560 - INFO - epoch 0, step 43250, training loss = 3.130307, validation loss = 2.664107
2018-12-04 23:44:41,704 - INFO - epoch 0, step 43260, training loss = 2.626664, validation loss = 3.064481
2018-12-04 23:44:47,261 - INFO - epoch 0, step 43270, training loss = 2.641208, validation loss = 3.720837
2018-12-04 23:44:52,930 - INFO - epoch 0, step 43280, training loss = 3.091761, validation loss = 2.875220
2018-12-04 23:44:58,484 - INFO - epoch 0, step 43290, training loss = 2.539497, validation loss = 3.018062
2018-12-04 23:45:04,258 - INFO - epoch 0, step 43300, training loss = 2.903233, validation loss = 2.681144
2018-12-04 23:45:09,603 - INFO - epoch 0, step 43310, training loss = 3.167876, validation loss = 2.511080
2018-12-04 23:45:13,563 - INFO - epoch 0, step 43320, training loss = 3.431429, validation loss = 2.939453
2018-12-04 23:45:17,822 - INFO - epoch 0, step 43330, training loss = 3.099617, validation loss = 2.968793
2018-12-04 23:45:22,160 - INFO - epoch 0, step 43340, training loss = 3.328894, validation loss = 3.356448
2018-12-04 23:45:26,415 - INFO - epoch 0, step 43350, training loss = 3.216954, validation loss = 2.181735
2018-12-04 23:45:30,440 - INFO - epoch 0, step 43360, training loss = 2.828760, validation loss = 3.290440
2018-12-04 23:45:34,552 - INFO - epoch 0, step 43370, training loss = 2.895443, validation loss = 2.913395
2018-12-04 23:45:39,015 - INFO - epoch 0, step 43380, training loss = 2.909348, validation loss = 3.073739
2018-12-04 23:45:43,694 - INFO - epoch 0, step 43390, training loss = 1.756875, validation loss = 2.676776
2018-12-04 23:45:47,538 - INFO - epoch 0, step 43400, training loss = 2.781308, validation loss = 2.338097
2018-12-04 23:45:51,856 - INFO - epoch 0, step 43410, training loss = 3.040891, validation loss = 2.792404
2018-12-04 23:45:56,311 - INFO - epoch 0, step 43420, training loss = 3.027949, validation loss = 2.672379
2018-12-04 23:46:00,410 - INFO - epoch 0, step 43430, training loss = 3.381575, validation loss = 2.639143
2018-12-04 23:46:04,924 - INFO - epoch 0, step 43440, training loss = 2.407545, validation loss = 2.253794
2018-12-04 23:46:09,136 - INFO - epoch 0, step 43450, training loss = 3.196954, validation loss = 2.895897
2018-12-04 23:46:13,307 - INFO - epoch 0, step 43460, training loss = 2.856415, validation loss = 2.494287
2018-12-04 23:46:17,508 - INFO - epoch 0, step 43470, training loss = 2.984709, validation loss = 1.917717
2018-12-04 23:46:21,677 - INFO - epoch 0, step 43480, training loss = 2.918284, validation loss = 2.381974
2018-12-04 23:46:26,201 - INFO - epoch 0, step 43490, training loss = 2.843378, validation loss = 1.948991
2018-12-04 23:46:30,338 - INFO - epoch 0, step 43500, training loss = 2.936359, validation loss = 2.602393
2018-12-04 23:46:34,653 - INFO - epoch 0, step 43510, training loss = 2.843131, validation loss = 2.796415
2018-12-04 23:46:38,797 - INFO - epoch 0, step 43520, training loss = 2.559462, validation loss = 2.710321
2018-12-04 23:46:43,980 - INFO - epoch 0, step 43530, training loss = 2.165718, validation loss = 2.354127
2018-12-04 23:46:49,556 - INFO - epoch 0, step 43540, training loss = 2.328039, validation loss = 2.126762
2018-12-04 23:46:54,717 - INFO - epoch 0, step 43550, training loss = 2.188623, validation loss = 2.407625
2018-12-04 23:46:59,943 - INFO - epoch 0, step 43560, training loss = 2.287784, validation loss = 2.378521
2018-12-04 23:47:04,218 - INFO - epoch 0, step 43570, training loss = 3.005211, validation loss = 2.517090
2018-12-04 23:47:08,334 - INFO - epoch 0, step 43580, training loss = 3.042792, validation loss = 3.020076
2018-12-04 23:47:12,345 - INFO - epoch 0, step 43590, training loss = 3.104384, validation loss = 3.242869
2018-12-04 23:47:16,394 - INFO - epoch 0, step 43600, training loss = 2.827419, validation loss = 3.187642
2018-12-04 23:47:20,365 - INFO - epoch 0, step 43610, training loss = 2.749238, validation loss = 2.519680
2018-12-04 23:47:24,386 - INFO - epoch 0, step 43620, training loss = 3.128082, validation loss = 3.012889
2018-12-04 23:47:28,483 - INFO - epoch 0, step 43630, training loss = 2.971729, validation loss = 2.731740
2018-12-04 23:47:33,072 - INFO - epoch 0, step 43640, training loss = 2.210607, validation loss = 2.330411
2018-12-04 23:47:38,339 - INFO - epoch 0, step 43650, training loss = 2.245647, validation loss = 2.723609
2018-12-04 23:47:43,931 - INFO - epoch 0, step 43660, training loss = 2.572907, validation loss = 2.415828
2018-12-04 23:47:49,345 - INFO - epoch 0, step 43670, training loss = 2.177069, validation loss = 3.031603
2018-12-04 23:47:53,788 - INFO - epoch 0, step 43680, training loss = 3.166039, validation loss = 2.885767
2018-12-04 23:47:57,918 - INFO - epoch 0, step 43690, training loss = 2.874813, validation loss = 2.961603
2018-12-04 23:48:02,059 - INFO - epoch 0, step 43700, training loss = 2.530693, validation loss = 2.905056
2018-12-04 23:48:06,024 - INFO - epoch 0, step 43710, training loss = 2.722117, validation loss = 2.335112
2018-12-04 23:48:09,984 - INFO - epoch 0, step 43720, training loss = 2.931900, validation loss = 2.531573
2018-12-04 23:48:13,910 - INFO - epoch 0, step 43730, training loss = 2.510632, validation loss = 2.471335
2018-12-04 23:48:17,752 - INFO - epoch 0, step 43740, training loss = 3.063269, validation loss = 2.529189
2018-12-04 23:48:22,035 - INFO - epoch 0, step 43750, training loss = 3.031394, validation loss = 2.546461
2018-12-04 23:48:26,117 - INFO - epoch 0, step 43760, training loss = 3.071847, validation loss = 2.591560
2018-12-04 23:48:30,088 - INFO - epoch 0, step 43770, training loss = 2.660695, validation loss = 2.518990
2018-12-04 23:48:34,200 - INFO - epoch 0, step 43780, training loss = 3.489825, validation loss = 2.383305
2018-12-04 23:48:40,311 - INFO - epoch 0, step 43790, training loss = 2.089265, validation loss = 2.385229
2018-12-04 23:48:45,860 - INFO - epoch 0, step 43800, training loss = 2.027376, validation loss = 2.177942
2018-12-04 23:48:51,238 - INFO - epoch 0, step 43810, training loss = 2.123850, validation loss = 2.790566
2018-12-04 23:48:55,891 - INFO - epoch 0, step 43820, training loss = 3.438546, validation loss = 2.694356
2018-12-04 23:48:59,753 - INFO - epoch 0, step 43830, training loss = 3.059770, validation loss = 2.893199
2018-12-04 23:49:03,783 - INFO - epoch 0, step 43840, training loss = 2.800008, validation loss = 2.374359
2018-12-04 23:49:08,157 - INFO - epoch 0, step 43850, training loss = 2.911549, validation loss = 2.188563
2018-12-04 23:49:11,938 - INFO - epoch 0, step 43860, training loss = 3.053900, validation loss = 2.162266
2018-12-04 23:49:16,013 - INFO - epoch 0, step 43870, training loss = 2.926904, validation loss = 2.870513
2018-12-04 23:49:20,056 - INFO - epoch 0, step 43880, training loss = 3.393025, validation loss = 2.775750
2018-12-04 23:49:24,313 - INFO - epoch 0, step 43890, training loss = 2.894859, validation loss = 2.413302
2018-12-04 23:49:28,509 - INFO - epoch 0, step 43900, training loss = 3.209672, validation loss = 2.829875
2018-12-04 23:49:32,452 - INFO - epoch 0, step 43910, training loss = 3.166336, validation loss = 2.855873
2018-12-04 23:49:36,565 - INFO - epoch 0, step 43920, training loss = 3.152708, validation loss = 3.059784
2018-12-04 23:49:40,545 - INFO - epoch 0, step 43930, training loss = 3.346213, validation loss = 2.701676
2018-12-04 23:49:44,833 - INFO - epoch 0, step 43940, training loss = 3.066861, validation loss = 3.095889
2018-12-04 23:49:48,958 - INFO - epoch 0, step 43950, training loss = 2.924932, validation loss = 2.712880
2018-12-04 23:49:53,114 - INFO - epoch 0, step 43960, training loss = 2.982458, validation loss = 2.557177
2018-12-04 23:49:57,312 - INFO - epoch 0, step 43970, training loss = 3.264664, validation loss = 2.574151
2018-12-04 23:50:01,562 - INFO - epoch 0, step 43980, training loss = 3.191618, validation loss = 2.162907
2018-12-04 23:50:05,679 - INFO - epoch 0, step 43990, training loss = 3.028198, validation loss = 3.052378
2018-12-04 23:50:10,077 - INFO - epoch 0, step 44000, training loss = 3.103580, validation loss = 3.168625
2018-12-04 23:50:14,176 - INFO - epoch 0, step 44010, training loss = 2.921294, validation loss = 2.885746
2018-12-04 23:50:18,206 - INFO - epoch 0, step 44020, training loss = 2.653007, validation loss = 2.775915
2018-12-04 23:50:22,417 - INFO - epoch 0, step 44030, training loss = 2.782548, validation loss = 2.668323
2018-12-04 23:50:26,526 - INFO - epoch 0, step 44040, training loss = 3.337177, validation loss = 2.699169
2018-12-04 23:50:30,459 - INFO - epoch 0, step 44050, training loss = 2.578593, validation loss = 2.342321
2018-12-04 23:50:34,393 - INFO - epoch 0, step 44060, training loss = 2.774311, validation loss = 2.744722
2018-12-04 23:50:38,563 - INFO - epoch 0, step 44070, training loss = 2.947922, validation loss = 2.728126
2018-12-04 23:50:42,876 - INFO - epoch 0, step 44080, training loss = 2.795848, validation loss = 2.994079
2018-12-04 23:50:47,014 - INFO - epoch 0, step 44090, training loss = 3.056426, validation loss = 2.982221
2018-12-04 23:50:51,303 - INFO - epoch 0, step 44100, training loss = 2.729020, validation loss = 2.487347
2018-12-04 23:50:55,603 - INFO - epoch 0, step 44110, training loss = 2.682389, validation loss = 2.834292
2018-12-04 23:50:59,653 - INFO - epoch 0, step 44120, training loss = 3.085405, validation loss = 2.880123
2018-12-04 23:51:03,937 - INFO - epoch 0, step 44130, training loss = 2.842384, validation loss = 2.288736
2018-12-04 23:51:08,181 - INFO - epoch 0, step 44140, training loss = 2.595436, validation loss = 2.676274
2018-12-04 23:51:12,502 - INFO - epoch 0, step 44150, training loss = 2.717256, validation loss = 2.959108
2018-12-04 23:51:16,712 - INFO - epoch 0, step 44160, training loss = 2.877102, validation loss = 2.535786
2018-12-04 23:51:20,896 - INFO - epoch 0, step 44170, training loss = 2.929937, validation loss = 2.743426
2018-12-04 23:51:24,978 - INFO - epoch 0, step 44180, training loss = 2.977772, validation loss = 2.793393
2018-12-04 23:51:28,890 - INFO - epoch 0, step 44190, training loss = 2.853069, validation loss = 2.514095
2018-12-04 23:51:32,766 - INFO - epoch 0, step 44200, training loss = 3.355455, validation loss = 2.797309
2018-12-04 23:51:36,921 - INFO - epoch 0, step 44210, training loss = 2.805409, validation loss = 2.625937
2018-12-04 23:51:41,190 - INFO - epoch 0, step 44220, training loss = 3.123513, validation loss = 2.335425
2018-12-04 23:51:45,030 - INFO - epoch 0, step 44230, training loss = 2.982633, validation loss = 3.010628
2018-12-04 23:51:49,108 - INFO - epoch 0, step 44240, training loss = 2.595558, validation loss = 2.914666
2018-12-04 23:51:53,226 - INFO - epoch 0, step 44250, training loss = 2.844657, validation loss = 2.279900
2018-12-04 23:51:57,455 - INFO - epoch 0, step 44260, training loss = 2.950442, validation loss = 2.754867
2018-12-04 23:52:01,721 - INFO - epoch 0, step 44270, training loss = 2.695651, validation loss = 2.840270
2018-12-04 23:52:06,033 - INFO - epoch 0, step 44280, training loss = 2.753118, validation loss = 2.866133
2018-12-04 23:52:10,038 - INFO - epoch 0, step 44290, training loss = 2.896479, validation loss = 3.168643
2018-12-04 23:52:14,590 - INFO - epoch 0, step 44300, training loss = 3.071099, validation loss = 2.462116
2018-12-04 23:52:18,832 - INFO - epoch 0, step 44310, training loss = 2.816156, validation loss = 2.243684
2018-12-04 23:52:23,159 - INFO - epoch 0, step 44320, training loss = 3.239309, validation loss = 2.007482
2018-12-04 23:52:27,293 - INFO - epoch 0, step 44330, training loss = 2.540031, validation loss = 2.549610
2018-12-04 23:52:31,272 - INFO - epoch 0, step 44340, training loss = 2.901756, validation loss = 2.479332
2018-12-04 23:52:35,632 - INFO - epoch 0, step 44350, training loss = 3.321630, validation loss = 1.939121
2018-12-04 23:52:39,680 - INFO - epoch 0, step 44360, training loss = 3.399865, validation loss = 2.590246
2018-12-04 23:52:43,920 - INFO - epoch 0, step 44370, training loss = 2.698858, validation loss = 2.351024
2018-12-04 23:52:47,759 - INFO - epoch 0, step 44380, training loss = 3.091522, validation loss = 2.329630
2018-12-04 23:52:51,645 - INFO - epoch 0, step 44390, training loss = 3.087920, validation loss = 2.300211
2018-12-04 23:52:55,694 - INFO - epoch 0, step 44400, training loss = 2.829580, validation loss = 2.611808
2018-12-04 23:52:59,532 - INFO - epoch 0, step 44410, training loss = 2.596993, validation loss = 2.435778
2018-12-04 23:53:03,476 - INFO - epoch 0, step 44420, training loss = 2.950087, validation loss = 2.071270
2018-12-04 23:53:07,250 - INFO - epoch 0, step 44430, training loss = 3.301991, validation loss = 2.582331
2018-12-04 23:53:11,036 - INFO - epoch 0, step 44440, training loss = 3.080553, validation loss = 2.302099
2018-12-04 23:53:14,865 - INFO - epoch 0, step 44450, training loss = 2.722723, validation loss = 2.467599
2018-12-04 23:53:18,993 - INFO - epoch 0, step 44460, training loss = 2.812517, validation loss = 3.047747
2018-12-04 23:53:22,885 - INFO - epoch 0, step 44470, training loss = 3.568517, validation loss = 2.421145
2018-12-04 23:53:26,872 - INFO - epoch 0, step 44480, training loss = 3.575470, validation loss = 2.630999
2018-12-04 23:53:30,844 - INFO - epoch 0, step 44490, training loss = 2.720837, validation loss = 2.429978
2018-12-04 23:53:36,274 - INFO - epoch 0, step 44500, training loss = 1.693681, validation loss = 2.824576
2018-12-04 23:53:41,733 - INFO - epoch 0, step 44510, training loss = 2.009377, validation loss = 2.662359
2018-12-04 23:53:46,916 - INFO - epoch 0, step 44520, training loss = 2.620148, validation loss = 3.210759
2018-12-04 23:53:51,725 - INFO - epoch 0, step 44530, training loss = 2.826522, validation loss = 2.611379
2018-12-04 23:53:56,148 - INFO - epoch 0, step 44540, training loss = 2.702653, validation loss = 2.733488
2018-12-04 23:54:00,251 - INFO - epoch 0, step 44550, training loss = 3.189276, validation loss = 2.195302
2018-12-04 23:54:04,375 - INFO - epoch 0, step 44560, training loss = 3.255228, validation loss = 2.689143
2018-12-04 23:54:08,647 - INFO - epoch 0, step 44570, training loss = 3.238061, validation loss = 2.717450
2018-12-04 23:54:12,705 - INFO - epoch 0, step 44580, training loss = 3.109222, validation loss = 2.973374
2018-12-04 23:54:16,917 - INFO - epoch 0, step 44590, training loss = 2.854686, validation loss = 2.611316
2018-12-04 23:54:21,260 - INFO - epoch 0, step 44600, training loss = 2.909801, validation loss = 2.755164
2018-12-04 23:54:25,746 - INFO - epoch 0, step 44610, training loss = 2.636488, validation loss = 2.550541
2018-12-04 23:54:29,857 - INFO - epoch 0, step 44620, training loss = 3.010710, validation loss = 1.841759
2018-12-04 23:54:34,354 - INFO - epoch 0, step 44630, training loss = 2.215784, validation loss = 2.636975
2018-12-04 23:54:40,002 - INFO - epoch 0, step 44640, training loss = 2.000466, validation loss = 3.025134
2018-12-04 23:54:45,449 - INFO - epoch 0, step 44650, training loss = 2.325433, validation loss = 2.876299
2018-12-04 23:54:50,388 - INFO - epoch 0, step 44660, training loss = 2.136717, validation loss = 2.721661
2018-12-04 23:54:56,067 - INFO - epoch 0, step 44670, training loss = 2.243579, validation loss = 2.865381
2018-12-04 23:55:01,579 - INFO - epoch 0, step 44680, training loss = 1.842394, validation loss = 2.429504
2018-12-04 23:55:07,180 - INFO - epoch 0, step 44690, training loss = 2.786518, validation loss = 2.277728
2018-12-04 23:55:12,327 - INFO - epoch 0, step 44700, training loss = 2.657425, validation loss = 2.547017
2018-12-04 23:55:17,385 - INFO - epoch 0, step 44710, training loss = 2.537153, validation loss = 2.942281
2018-12-04 23:55:22,237 - INFO - epoch 0, step 44720, training loss = 2.730126, validation loss = 2.792690
2018-12-04 23:55:27,156 - INFO - epoch 0, step 44730, training loss = 3.006430, validation loss = 2.140690
2018-12-04 23:55:30,898 - INFO - epoch 0, step 44740, training loss = 2.933848, validation loss = 2.821461
2018-12-04 23:55:35,073 - INFO - epoch 0, step 44750, training loss = 2.945654, validation loss = 2.241113
2018-12-04 23:55:39,164 - INFO - epoch 0, step 44760, training loss = 3.065237, validation loss = 1.941231
2018-12-04 23:55:43,345 - INFO - epoch 0, step 44770, training loss = 2.864728, validation loss = 2.032255
2018-12-04 23:55:47,374 - INFO - epoch 0, step 44780, training loss = 2.484980, validation loss = 2.387002
2018-12-04 23:55:52,090 - INFO - epoch 0, step 44790, training loss = 2.065061, validation loss = 2.874393
2018-12-04 23:55:57,595 - INFO - epoch 0, step 44800, training loss = 2.289233, validation loss = 3.009115
2018-12-04 23:56:02,373 - INFO - epoch 0, step 44810, training loss = 3.300533, validation loss = 2.908555
2018-12-04 23:56:07,077 - INFO - epoch 0, step 44820, training loss = 3.434047, validation loss = 2.660230
2018-12-04 23:56:11,667 - INFO - epoch 0, step 44830, training loss = 3.020543, validation loss = 2.350575
2018-12-04 23:56:15,579 - INFO - epoch 0, step 44840, training loss = 2.750666, validation loss = 2.574054
2018-12-04 23:56:19,573 - INFO - epoch 0, step 44850, training loss = 3.265528, validation loss = 2.729807
2018-12-04 23:56:23,388 - INFO - epoch 0, step 44860, training loss = 3.193847, validation loss = 2.652164
2018-12-04 23:56:27,158 - INFO - epoch 0, step 44870, training loss = 2.821826, validation loss = 2.298841
2018-12-04 23:56:31,136 - INFO - epoch 0, step 44880, training loss = 2.895153, validation loss = 2.422440
2018-12-04 23:56:34,855 - INFO - epoch 0, step 44890, training loss = 2.843169, validation loss = 2.178799
2018-12-04 23:56:38,660 - INFO - epoch 0, step 44900, training loss = 3.412093, validation loss = 2.429060
2018-12-04 23:56:42,610 - INFO - epoch 0, step 44910, training loss = 2.885109, validation loss = 2.361016
2018-12-04 23:56:46,408 - INFO - epoch 0, step 44920, training loss = 2.814226, validation loss = 2.592689
2018-12-04 23:56:50,111 - INFO - epoch 0, step 44930, training loss = 3.001384, validation loss = 2.896627
2018-12-04 23:56:54,203 - INFO - epoch 0, step 44940, training loss = 2.435742, validation loss = 2.706905
2018-12-04 23:56:59,204 - INFO - epoch 0, step 44950, training loss = 2.656223, validation loss = 2.552089
2018-12-04 23:57:04,762 - INFO - epoch 0, step 44960, training loss = 2.131931, validation loss = 2.254760
2018-12-04 23:57:09,837 - INFO - epoch 0, step 44970, training loss = 2.502031, validation loss = 2.735725
2018-12-04 23:57:14,348 - INFO - epoch 0, step 44980, training loss = 2.658217, validation loss = 2.745181
2018-12-04 23:57:18,504 - INFO - epoch 0, step 44990, training loss = 2.903814, validation loss = 2.293477
2018-12-04 23:57:22,774 - INFO - epoch 0, step 45000, training loss = 3.023537, validation loss = 2.846452
2018-12-04 23:57:26,958 - INFO - epoch 0, step 45010, training loss = 2.921855, validation loss = 3.095598
2018-12-04 23:57:31,689 - INFO - epoch 0, step 45020, training loss = 2.235749, validation loss = 2.451445
2018-12-04 23:57:36,574 - INFO - epoch 0, step 45030, training loss = 3.032801, validation loss = 2.333037
2018-12-04 23:57:42,097 - INFO - epoch 0, step 45040, training loss = 1.932444, validation loss = 2.597972
2018-12-04 23:57:47,299 - INFO - epoch 0, step 45050, training loss = 3.076615, validation loss = 2.824223
2018-12-04 23:57:52,566 - INFO - epoch 0, step 45060, training loss = 2.369715, validation loss = 1.833394
2018-12-04 23:57:57,722 - INFO - epoch 0, step 45070, training loss = 3.422944, validation loss = 2.640735
2018-12-04 23:58:02,631 - INFO - epoch 0, step 45080, training loss = 3.187821, validation loss = 2.455485
2018-12-04 23:58:06,898 - INFO - epoch 0, step 45090, training loss = 3.013149, validation loss = 2.567393
2018-12-04 23:58:11,193 - INFO - epoch 0, step 45100, training loss = 2.823511, validation loss = 2.598021
2018-12-04 23:58:15,243 - INFO - epoch 0, step 45110, training loss = 2.985142, validation loss = 2.826106
2018-12-04 23:58:19,451 - INFO - epoch 0, step 45120, training loss = 3.223333, validation loss = 3.057194
2018-12-04 23:58:23,849 - INFO - epoch 0, step 45130, training loss = 2.581148, validation loss = 2.392741
2018-12-04 23:58:27,747 - INFO - epoch 0, step 45140, training loss = 3.353051, validation loss = 2.439887
2018-12-04 23:58:31,667 - INFO - epoch 0, step 45150, training loss = 2.981228, validation loss = 2.859568
2018-12-04 23:58:35,664 - INFO - epoch 0, step 45160, training loss = 2.444518, validation loss = 2.614937
2018-12-04 23:58:39,779 - INFO - epoch 0, step 45170, training loss = 3.132748, validation loss = 2.955215
2018-12-04 23:58:44,747 - INFO - epoch 0, step 45180, training loss = 3.119109, validation loss = 2.623837
2018-12-04 23:58:50,537 - INFO - epoch 0, step 45190, training loss = 2.206936, validation loss = 2.617512
2018-12-04 23:58:56,172 - INFO - epoch 0, step 45200, training loss = 3.099752, validation loss = 3.156197
2018-12-04 23:59:01,496 - INFO - epoch 0, step 45210, training loss = 2.337456, validation loss = 3.077032
2018-12-04 23:59:06,662 - INFO - epoch 0, step 45220, training loss = 2.816001, validation loss = 2.671566
2018-12-04 23:59:10,259 - INFO - epoch 0, step 45230, training loss = 3.355482, validation loss = 2.801057
2018-12-04 23:59:14,234 - INFO - epoch 0, step 45240, training loss = 2.947959, validation loss = 2.844266
2018-12-04 23:59:17,954 - INFO - epoch 0, step 45250, training loss = 3.340862, validation loss = 2.854476
2018-12-04 23:59:21,897 - INFO - epoch 0, step 45260, training loss = 2.877565, validation loss = 2.579041
2018-12-04 23:59:25,688 - INFO - epoch 0, step 45270, training loss = 2.665584, validation loss = 2.408654
2018-12-04 23:59:30,204 - INFO - epoch 0, step 45280, training loss = 2.694053, validation loss = 2.360054
2018-12-04 23:59:35,571 - INFO - epoch 0, step 45290, training loss = 2.482305, validation loss = 2.515022
2018-12-04 23:59:40,571 - INFO - epoch 0, step 45300, training loss = 2.254497, validation loss = 3.001755
2018-12-04 23:59:45,844 - INFO - epoch 0, step 45310, training loss = 2.461400, validation loss = 3.054325
2018-12-04 23:59:50,630 - INFO - epoch 0, step 45320, training loss = 2.598669, validation loss = 2.428484
2018-12-04 23:59:56,019 - INFO - epoch 0, step 45330, training loss = 2.330849, validation loss = 2.808365
2018-12-05 00:00:01,283 - INFO - epoch 0, step 45340, training loss = 2.474159, validation loss = 2.829864
2018-12-05 00:00:06,956 - INFO - epoch 0, step 45350, training loss = 2.517017, validation loss = 3.592818
2018-12-05 00:00:11,975 - INFO - epoch 0, step 45360, training loss = 2.721885, validation loss = 2.465147
2018-12-05 00:00:17,223 - INFO - epoch 0, step 45370, training loss = 2.592241, validation loss = 2.692380
2018-12-05 00:00:22,150 - INFO - epoch 0, step 45380, training loss = 2.672144, validation loss = 2.700398
2018-12-05 00:00:27,107 - INFO - epoch 0, step 45390, training loss = 2.600646, validation loss = 2.911348
2018-12-05 00:00:32,919 - INFO - epoch 0, step 45400, training loss = 2.305983, validation loss = 2.723016
2018-12-05 00:00:37,889 - INFO - epoch 0, step 45410, training loss = 2.839054, validation loss = 3.042793
2018-12-05 00:00:43,145 - INFO - epoch 0, step 45420, training loss = 2.337501, validation loss = 2.674032
2018-12-05 00:00:48,597 - INFO - epoch 0, step 45430, training loss = 2.499740, validation loss = 2.550637
2018-12-05 00:00:54,454 - INFO - epoch 0, step 45440, training loss = 2.371881, validation loss = 2.838768
2018-12-05 00:00:59,335 - INFO - epoch 0, step 45450, training loss = 2.897449, validation loss = 2.572673
2018-12-05 00:01:03,598 - INFO - epoch 0, step 45460, training loss = 2.961178, validation loss = 2.970021
2018-12-05 00:01:07,883 - INFO - epoch 0, step 45470, training loss = 3.180132, validation loss = 2.773236
2018-12-05 00:01:11,530 - INFO - epoch 0, step 45480, training loss = 3.334805, validation loss = 2.654921
2018-12-05 00:01:15,329 - INFO - epoch 0, step 45490, training loss = 3.153837, validation loss = 2.366693
2018-12-05 00:01:19,674 - INFO - epoch 0, step 45500, training loss = 2.035774, validation loss = 2.717062
2018-12-05 00:01:25,582 - INFO - epoch 0, step 45510, training loss = 1.753832, validation loss = 3.050523
2018-12-05 00:01:30,971 - INFO - epoch 0, step 45520, training loss = 2.236801, validation loss = 2.750329
2018-12-05 00:01:35,996 - INFO - epoch 0, step 45530, training loss = 3.081547, validation loss = 2.988083
2018-12-05 00:01:39,888 - INFO - epoch 0, step 45540, training loss = 2.879573, validation loss = 2.981019
2018-12-05 00:01:43,663 - INFO - epoch 0, step 45550, training loss = 3.345551, validation loss = 2.459084
2018-12-05 00:01:47,719 - INFO - epoch 0, step 45560, training loss = 3.158430, validation loss = 2.749079
2018-12-05 00:01:51,731 - INFO - epoch 0, step 45570, training loss = 3.201100, validation loss = 2.847795
2018-12-05 00:01:55,619 - INFO - epoch 0, step 45580, training loss = 2.897896, validation loss = 3.297079
2018-12-05 00:01:59,521 - INFO - epoch 0, step 45590, training loss = 2.810848, validation loss = 2.538874
2018-12-05 00:02:03,297 - INFO - epoch 0, step 45600, training loss = 3.119826, validation loss = 2.762465
2018-12-05 00:02:07,072 - INFO - epoch 0, step 45610, training loss = 3.405688, validation loss = 2.838050
2018-12-05 00:02:10,985 - INFO - epoch 0, step 45620, training loss = 3.247122, validation loss = 2.571434
2018-12-05 00:02:14,899 - INFO - epoch 0, step 45630, training loss = 3.070240, validation loss = 2.495500
2018-12-05 00:02:18,876 - INFO - epoch 0, step 45640, training loss = 3.183882, validation loss = 2.286454
2018-12-05 00:02:22,593 - INFO - epoch 0, step 45650, training loss = 3.016434, validation loss = 3.241075
2018-12-05 00:02:26,468 - INFO - epoch 0, step 45660, training loss = 2.964418, validation loss = 2.506274
2018-12-05 00:02:30,483 - INFO - epoch 0, step 45670, training loss = 2.332312, validation loss = 2.258697
2018-12-05 00:02:34,268 - INFO - epoch 0, step 45680, training loss = 3.019418, validation loss = 3.013144
2018-12-05 00:02:38,397 - INFO - epoch 0, step 45690, training loss = 2.772252, validation loss = 2.886104
2018-12-05 00:02:42,277 - INFO - epoch 0, step 45700, training loss = 3.290013, validation loss = 2.825551
2018-12-05 00:02:46,177 - INFO - epoch 0, step 45710, training loss = 2.853096, validation loss = 2.946308
2018-12-05 00:02:50,080 - INFO - epoch 0, step 45720, training loss = 2.663431, validation loss = 2.877218
2018-12-05 00:02:53,895 - INFO - epoch 0, step 45730, training loss = 3.132562, validation loss = 2.828454
2018-12-05 00:02:57,673 - INFO - epoch 0, step 45740, training loss = 3.453422, validation loss = 3.013887
2018-12-05 00:03:01,387 - INFO - epoch 0, step 45750, training loss = 3.091974, validation loss = 2.548079
2018-12-05 00:03:05,189 - INFO - epoch 0, step 45760, training loss = 2.774299, validation loss = 2.389292
2018-12-05 00:03:09,055 - INFO - epoch 0, step 45770, training loss = 2.860009, validation loss = 2.414261
2018-12-05 00:03:12,783 - INFO - epoch 0, step 45780, training loss = 3.233299, validation loss = 2.704619
2018-12-05 00:03:16,631 - INFO - epoch 0, step 45790, training loss = 3.021864, validation loss = 2.741375
2018-12-05 00:03:20,602 - INFO - epoch 0, step 45800, training loss = 2.970693, validation loss = 2.809578
2018-12-05 00:03:25,406 - INFO - epoch 0, step 45810, training loss = 2.693437, validation loss = 2.519260
2018-12-05 00:03:30,808 - INFO - epoch 0, step 45820, training loss = 2.772720, validation loss = 2.648847
2018-12-05 00:03:36,048 - INFO - epoch 0, step 45830, training loss = 2.919469, validation loss = 2.081700
2018-12-05 00:03:41,189 - INFO - epoch 0, step 45840, training loss = 2.482327, validation loss = 2.760061
2018-12-05 00:03:46,338 - INFO - epoch 0, step 45850, training loss = 2.556400, validation loss = 2.950975
2018-12-05 00:03:51,451 - INFO - epoch 0, step 45860, training loss = 2.482532, validation loss = 3.024648
2018-12-05 00:03:56,459 - INFO - epoch 0, step 45870, training loss = 2.622035, validation loss = 3.242028
2018-12-05 00:04:01,944 - INFO - epoch 0, step 45880, training loss = 2.093063, validation loss = 2.366760
2018-12-05 00:04:07,894 - INFO - epoch 0, step 45890, training loss = 2.292930, validation loss = 3.123979
2018-12-05 00:04:13,587 - INFO - epoch 0, step 45900, training loss = 1.969839, validation loss = 2.837337
2018-12-05 00:04:19,270 - INFO - epoch 0, step 45910, training loss = 1.778252, validation loss = 2.731820
2018-12-05 00:04:24,736 - INFO - epoch 0, step 45920, training loss = 3.196479, validation loss = 2.584466
2018-12-05 00:04:30,952 - INFO - epoch 0, step 45930, training loss = 1.868745, validation loss = 2.918813
2018-12-05 00:04:36,154 - INFO - epoch 0, step 45940, training loss = 2.489103, validation loss = 2.638827
2018-12-05 00:04:41,565 - INFO - epoch 0, step 45950, training loss = 2.392768, validation loss = 2.609787
2018-12-05 00:04:46,991 - INFO - epoch 0, step 45960, training loss = 2.648385, validation loss = 2.989729
2018-12-05 00:04:52,563 - INFO - epoch 0, step 45970, training loss = 2.322031, validation loss = 3.186455
2018-12-05 00:04:59,054 - INFO - epoch 0, step 45980, training loss = 1.929071, validation loss = 2.227575
2018-12-05 00:05:04,181 - INFO - epoch 0, step 45990, training loss = 2.606033, validation loss = 2.770777
2018-12-05 00:05:09,524 - INFO - epoch 0, step 46000, training loss = 2.083678, validation loss = 2.876510
2018-12-05 00:05:15,470 - INFO - epoch 0, step 46010, training loss = 2.593362, validation loss = 3.130485
2018-12-05 00:05:19,865 - INFO - epoch 0, step 46020, training loss = 2.982553, validation loss = 2.606577
2018-12-05 00:05:23,859 - INFO - epoch 0, step 46030, training loss = 3.253336, validation loss = 2.563328
2018-12-05 00:05:27,797 - INFO - epoch 0, step 46040, training loss = 3.068670, validation loss = 2.825411
2018-12-05 00:05:31,949 - INFO - epoch 0, step 46050, training loss = 3.344610, validation loss = 3.105752
2018-12-05 00:05:35,990 - INFO - epoch 0, step 46060, training loss = 3.196278, validation loss = 2.363611
2018-12-05 00:05:40,048 - INFO - epoch 0, step 46070, training loss = 3.277171, validation loss = 2.812752
2018-12-05 00:05:44,109 - INFO - epoch 0, step 46080, training loss = 3.093208, validation loss = 2.985122
2018-12-05 00:05:48,432 - INFO - epoch 0, step 46090, training loss = 2.715565, validation loss = 3.085045
2018-12-05 00:05:52,620 - INFO - epoch 0, step 46100, training loss = 2.866496, validation loss = 2.719584
2018-12-05 00:05:56,879 - INFO - epoch 0, step 46110, training loss = 2.524166, validation loss = 2.488348
2018-12-05 00:06:00,941 - INFO - epoch 0, step 46120, training loss = 2.983576, validation loss = 2.790910
2018-12-05 00:06:05,162 - INFO - epoch 0, step 46130, training loss = 3.321876, validation loss = 2.295063
2018-12-05 00:06:09,438 - INFO - epoch 0, step 46140, training loss = 2.828617, validation loss = 2.822116
2018-12-05 00:06:13,544 - INFO - epoch 0, step 46150, training loss = 2.642033, validation loss = 2.713268
2018-12-05 00:06:17,543 - INFO - epoch 0, step 46160, training loss = 2.973076, validation loss = 3.324089
2018-12-05 00:06:21,623 - INFO - epoch 0, step 46170, training loss = 3.111603, validation loss = 2.707134
2018-12-05 00:06:25,651 - INFO - epoch 0, step 46180, training loss = 3.109658, validation loss = 2.605029
2018-12-05 00:06:29,574 - INFO - epoch 0, step 46190, training loss = 2.812277, validation loss = 2.941975
2018-12-05 00:06:33,471 - INFO - epoch 0, step 46200, training loss = 2.877316, validation loss = 2.770136
2018-12-05 00:06:37,768 - INFO - epoch 0, step 46210, training loss = 2.368842, validation loss = 2.764306
2018-12-05 00:06:41,569 - INFO - epoch 0, step 46220, training loss = 3.300733, validation loss = 2.890066
2018-12-05 00:06:45,429 - INFO - epoch 0, step 46230, training loss = 2.797172, validation loss = 2.980322
2018-12-05 00:06:49,472 - INFO - epoch 0, step 46240, training loss = 2.769258, validation loss = 3.145376
2018-12-05 00:06:53,760 - INFO - epoch 0, step 46250, training loss = 3.002318, validation loss = 2.884175
2018-12-05 00:06:58,123 - INFO - epoch 0, step 46260, training loss = 3.041616, validation loss = 3.326177
2018-12-05 00:07:02,317 - INFO - epoch 0, step 46270, training loss = 2.345216, validation loss = 2.410206
2018-12-05 00:07:06,308 - INFO - epoch 0, step 46280, training loss = 2.949904, validation loss = 2.730798
2018-12-05 00:07:10,685 - INFO - epoch 0, step 46290, training loss = 2.618322, validation loss = 3.048442
2018-12-05 00:07:15,033 - INFO - epoch 0, step 46300, training loss = 2.687427, validation loss = 3.009103
2018-12-05 00:07:19,079 - INFO - epoch 0, step 46310, training loss = 2.906102, validation loss = 3.010265
2018-12-05 00:07:22,971 - INFO - epoch 0, step 46320, training loss = 3.002777, validation loss = 3.410504
2018-12-05 00:07:26,757 - INFO - epoch 0, step 46330, training loss = 3.082821, validation loss = 3.098686
2018-12-05 00:07:30,767 - INFO - epoch 0, step 46340, training loss = 2.936753, validation loss = 2.702052
2018-12-05 00:07:34,880 - INFO - epoch 0, step 46350, training loss = 3.133877, validation loss = 2.510419
2018-12-05 00:07:38,865 - INFO - epoch 0, step 46360, training loss = 2.576787, validation loss = 2.860148
2018-12-05 00:07:42,631 - INFO - epoch 0, step 46370, training loss = 3.153037, validation loss = 3.069078
2018-12-05 00:07:46,290 - INFO - epoch 0, step 46380, training loss = 2.988613, validation loss = 2.882308
2018-12-05 00:07:50,193 - INFO - epoch 0, step 46390, training loss = 3.182468, validation loss = 2.998565
2018-12-05 00:07:54,187 - INFO - epoch 0, step 46400, training loss = 2.950286, validation loss = 2.735419
2018-12-05 00:07:58,203 - INFO - epoch 0, step 46410, training loss = 2.947286, validation loss = 2.944859
2018-12-05 00:08:01,902 - INFO - epoch 0, step 46420, training loss = 3.220733, validation loss = 2.771096
2018-12-05 00:08:05,743 - INFO - epoch 0, step 46430, training loss = 2.624827, validation loss = 2.854860
2018-12-05 00:08:09,506 - INFO - epoch 0, step 46440, training loss = 3.080672, validation loss = 2.475022
2018-12-05 00:08:13,216 - INFO - epoch 0, step 46450, training loss = 2.763464, validation loss = 3.021612
2018-12-05 00:08:16,854 - INFO - epoch 0, step 46460, training loss = 2.990211, validation loss = 2.934309
2018-12-05 00:08:20,909 - INFO - epoch 0, step 46470, training loss = 2.491541, validation loss = 2.593780
2018-12-05 00:08:26,461 - INFO - epoch 0, step 46480, training loss = 1.818419, validation loss = 2.830780
2018-12-05 00:08:31,337 - INFO - epoch 0, step 46490, training loss = 2.667056, validation loss = 3.310112
2018-12-05 00:08:36,808 - INFO - epoch 0, step 46500, training loss = 2.065482, validation loss = 3.477049
2018-12-05 00:08:41,906 - INFO - epoch 0, step 46510, training loss = 2.755131, validation loss = 3.152774
2018-12-05 00:08:47,429 - INFO - epoch 0, step 46520, training loss = 2.471595, validation loss = 3.237586
2018-12-05 00:08:51,575 - INFO - epoch 0, step 46530, training loss = 2.974566, validation loss = 3.208017
2018-12-05 00:08:55,495 - INFO - epoch 0, step 46540, training loss = 2.729621, validation loss = 3.210795
2018-12-05 00:08:59,616 - INFO - epoch 0, step 46550, training loss = 2.861348, validation loss = 3.442609
2018-12-05 00:09:03,443 - INFO - epoch 0, step 46560, training loss = 2.890104, validation loss = 3.025856
2018-12-05 00:09:07,394 - INFO - epoch 0, step 46570, training loss = 2.927213, validation loss = 3.124870
2018-12-05 00:09:11,453 - INFO - epoch 0, step 46580, training loss = 2.637843, validation loss = 2.686356
2018-12-05 00:09:15,571 - INFO - epoch 0, step 46590, training loss = 2.068094, validation loss = 3.511509
2018-12-05 00:09:20,807 - INFO - epoch 0, step 46600, training loss = 2.470851, validation loss = 3.410880
2018-12-05 00:09:26,407 - INFO - epoch 0, step 46610, training loss = 2.160903, validation loss = 3.072734
2018-12-05 00:09:32,239 - INFO - epoch 0, step 46620, training loss = 3.652312, validation loss = 2.769287
2018-12-05 00:09:36,903 - INFO - epoch 0, step 46630, training loss = 2.702431, validation loss = 2.849766
2018-12-05 00:09:42,483 - INFO - epoch 0, step 46640, training loss = 2.043864, validation loss = 3.494918
2018-12-05 00:09:47,820 - INFO - epoch 0, step 46650, training loss = 2.795907, validation loss = 3.691618
2018-12-05 00:09:51,678 - INFO - epoch 0, step 46660, training loss = 3.202636, validation loss = 3.175446
2018-12-05 00:09:55,659 - INFO - epoch 0, step 46670, training loss = 2.763672, validation loss = 3.519378
2018-12-05 00:09:59,455 - INFO - epoch 0, step 46680, training loss = 3.002825, validation loss = 3.031629
2018-12-05 00:10:03,068 - INFO - epoch 0, step 46690, training loss = 3.024979, validation loss = 3.297097
2018-12-05 00:10:06,889 - INFO - epoch 0, step 46700, training loss = 3.047292, validation loss = 2.706591
2018-12-05 00:10:10,918 - INFO - epoch 0, step 46710, training loss = 2.536615, validation loss = 3.111597
2018-12-05 00:10:14,878 - INFO - epoch 0, step 46720, training loss = 3.021754, validation loss = 2.747555
2018-12-05 00:10:18,964 - INFO - epoch 0, step 46730, training loss = 3.278777, validation loss = 3.173589
2018-12-05 00:10:22,872 - INFO - epoch 0, step 46740, training loss = 3.061400, validation loss = 2.944339
2018-12-05 00:10:27,119 - INFO - epoch 0, step 46750, training loss = 2.556459, validation loss = 3.179752
2018-12-05 00:10:31,272 - INFO - epoch 0, step 46760, training loss = 2.522249, validation loss = 3.555058
2018-12-05 00:10:35,404 - INFO - epoch 0, step 46770, training loss = 2.912052, validation loss = 2.995689
2018-12-05 00:10:39,388 - INFO - epoch 0, step 46780, training loss = 2.440613, validation loss = 3.096497
2018-12-05 00:10:43,471 - INFO - epoch 0, step 46790, training loss = 2.995738, validation loss = 2.648372
2018-12-05 00:10:47,676 - INFO - epoch 0, step 46800, training loss = 3.153527, validation loss = 3.226996
2018-12-05 00:10:51,513 - INFO - epoch 0, step 46810, training loss = 3.043898, validation loss = 3.082915
2018-12-05 00:10:55,373 - INFO - epoch 0, step 46820, training loss = 2.914068, validation loss = 3.045330
2018-12-05 00:10:59,281 - INFO - epoch 0, step 46830, training loss = 3.283460, validation loss = 2.836166
2018-12-05 00:11:03,297 - INFO - epoch 0, step 46840, training loss = 2.961360, validation loss = 2.896627
2018-12-05 00:11:07,034 - INFO - epoch 0, step 46850, training loss = 3.253645, validation loss = 3.001459
2018-12-05 00:11:11,057 - INFO - epoch 0, step 46860, training loss = 2.620175, validation loss = 3.255181
2018-12-05 00:11:15,066 - INFO - epoch 0, step 46870, training loss = 2.570911, validation loss = 3.045260
2018-12-05 00:11:18,888 - INFO - epoch 0, step 46880, training loss = 2.541945, validation loss = 3.056053
2018-12-05 00:11:22,812 - INFO - epoch 0, step 46890, training loss = 3.099736, validation loss = 2.773772
2018-12-05 00:11:26,594 - INFO - epoch 0, step 46900, training loss = 2.680893, validation loss = 2.834019
2018-12-05 00:11:30,777 - INFO - epoch 0, step 46910, training loss = 2.734677, validation loss = 3.380175
2018-12-05 00:11:35,828 - INFO - epoch 0, step 46920, training loss = 2.362759, validation loss = 2.931589
2018-12-05 00:11:41,245 - INFO - epoch 0, step 46930, training loss = 2.629318, validation loss = 3.222535
2018-12-05 00:11:46,763 - INFO - epoch 0, step 46940, training loss = 2.001876, validation loss = 3.523426
2018-12-05 00:11:52,393 - INFO - epoch 0, step 46950, training loss = 2.745083, validation loss = 3.065198
2018-12-05 00:11:57,989 - INFO - epoch 0, step 46960, training loss = 2.306624, validation loss = 3.238522
2018-12-05 00:12:03,529 - INFO - epoch 0, step 46970, training loss = 2.500804, validation loss = 3.326287
2018-12-05 00:12:09,552 - INFO - epoch 0, step 46980, training loss = 2.344208, validation loss = 3.343231
2018-12-05 00:12:14,980 - INFO - epoch 0, step 46990, training loss = 2.584420, validation loss = 3.251056
2018-12-05 00:12:20,275 - INFO - epoch 0, step 47000, training loss = 3.179334, validation loss = 2.950811
2018-12-05 00:12:25,593 - INFO - epoch 0, step 47010, training loss = 2.588300, validation loss = 2.594334
2018-12-05 00:12:30,612 - INFO - epoch 0, step 47020, training loss = 2.084761, validation loss = 3.421600
2018-12-05 00:12:35,856 - INFO - epoch 0, step 47030, training loss = 2.043193, validation loss = 3.147127
2018-12-05 00:12:40,687 - INFO - epoch 0, step 47040, training loss = 3.245203, validation loss = 3.064996
2018-12-05 00:12:45,414 - INFO - epoch 0, step 47050, training loss = 2.481854, validation loss = 3.337281
2018-12-05 00:12:49,718 - INFO - epoch 0, step 47060, training loss = 2.977587, validation loss = 3.021292
2018-12-05 00:12:54,036 - INFO - epoch 0, step 47070, training loss = 2.578227, validation loss = 3.540224
2018-12-05 00:12:58,640 - INFO - epoch 0, step 47080, training loss = 2.272330, validation loss = 3.414221
2018-12-05 00:13:02,998 - INFO - epoch 0, step 47090, training loss = 2.582236, validation loss = 2.869251
2018-12-05 00:13:07,531 - INFO - epoch 0, step 47100, training loss = 2.557012, validation loss = 3.641225
2018-12-05 00:13:11,652 - INFO - epoch 0, step 47110, training loss = 3.066644, validation loss = 3.574000
2018-12-05 00:13:15,884 - INFO - epoch 0, step 47120, training loss = 2.856121, validation loss = 3.048475
2018-12-05 00:13:20,524 - INFO - epoch 0, step 47130, training loss = 2.835859, validation loss = 3.792473
2018-12-05 00:13:24,738 - INFO - epoch 0, step 47140, training loss = 3.088102, validation loss = 3.451864
2018-12-05 00:13:29,088 - INFO - epoch 0, step 47150, training loss = 2.689242, validation loss = 3.123960
2018-12-05 00:13:33,219 - INFO - epoch 0, step 47160, training loss = 2.792296, validation loss = 3.113806
2018-12-05 00:13:37,505 - INFO - epoch 0, step 47170, training loss = 2.577554, validation loss = 2.807597
2018-12-05 00:13:41,860 - INFO - epoch 0, step 47180, training loss = 2.968963, validation loss = 3.280108
2018-12-05 00:13:46,186 - INFO - epoch 0, step 47190, training loss = 2.903652, validation loss = 3.774384
2018-12-05 00:13:49,879 - INFO - epoch 0, step 47200, training loss = 2.438691, validation loss = 3.149117
2018-12-05 00:13:52,977 - INFO - epoch 0, step 47210, training loss = 2.636581, validation loss = 3.534500
2018-12-05 00:13:56,005 - INFO - epoch 0, step 47220, training loss = 2.467652, validation loss = 3.653928
2018-12-05 00:13:59,174 - INFO - epoch 0, step 47230, training loss = 2.087054, validation loss = 4.135088
2018-12-05 00:14:02,290 - INFO - epoch 0, step 47240, training loss = 2.486589, validation loss = 3.520620
2018-12-05 00:14:05,931 - INFO - epoch 0, step 47250, training loss = 2.224464, validation loss = 3.607605
2018-12-05 00:14:09,137 - INFO - epoch 0, step 47260, training loss = 2.100978, validation loss = 3.836559
2018-12-05 00:14:13,010 - INFO - epoch 0, step 47270, training loss = 2.083802, validation loss = 3.349766
2018-12-05 00:14:16,751 - INFO - epoch 0, step 47280, training loss = 2.070651, validation loss = 3.426756
2018-12-05 00:14:20,782 - INFO - epoch 0, step 47290, training loss = 2.136600, validation loss = 3.376768
2018-12-05 00:14:24,615 - INFO - epoch 0, step 47300, training loss = 2.412898, validation loss = 3.158231
2018-12-05 00:14:28,148 - INFO - epoch 0, step 47310, training loss = 2.641599, validation loss = 3.363140
2018-12-05 00:14:31,969 - INFO - epoch 0, step 47320, training loss = 1.936929, validation loss = 3.237263
2018-12-05 00:14:35,787 - INFO - epoch 0, step 47330, training loss = 2.333957, validation loss = 3.220863
2018-12-05 00:14:39,987 - INFO - epoch 0, step 47340, training loss = 1.974974, validation loss = 2.805250
2018-12-05 00:14:43,872 - INFO - epoch 0, step 47350, training loss = 2.135919, validation loss = 3.794796
2018-12-05 00:14:47,316 - INFO - epoch 0, step 47360, training loss = 1.979661, validation loss = 3.448529
2018-12-05 00:14:50,492 - INFO - epoch 0, step 47370, training loss = 1.952498, validation loss = 3.097349
2018-12-05 00:14:53,645 - INFO - epoch 0, step 47380, training loss = 2.314120, validation loss = 3.076554
2018-12-05 00:14:56,897 - INFO - epoch 0, step 47390, training loss = 2.407205, validation loss = 3.602282
2018-12-05 00:14:59,949 - INFO - epoch 0, step 47400, training loss = 2.495538, validation loss = 3.602218
2018-12-05 00:15:03,068 - INFO - epoch 0, step 47410, training loss = 2.199787, validation loss = 3.398952
2018-12-05 00:15:06,242 - INFO - epoch 0, step 47420, training loss = 2.173961, validation loss = 3.167575
2018-12-05 00:15:09,873 - INFO - epoch 0, step 47430, training loss = 2.010659, validation loss = 3.610399
2018-12-05 00:15:13,730 - INFO - epoch 0, step 47440, training loss = 2.240763, validation loss = 3.320433
2018-12-05 00:15:17,666 - INFO - epoch 0, step 47450, training loss = 2.209813, validation loss = 3.195401
2018-12-05 00:15:21,407 - INFO - epoch 0, step 47460, training loss = 2.282164, validation loss = 3.247255
2018-12-05 00:15:25,235 - INFO - epoch 0, step 47470, training loss = 1.821990, validation loss = 3.741095
2018-12-05 00:15:28,978 - INFO - epoch 0, step 47480, training loss = 2.421621, validation loss = 3.350263
2018-12-05 00:15:32,949 - INFO - epoch 0, step 47490, training loss = 1.802758, validation loss = 3.404754
2018-12-05 00:15:36,616 - INFO - epoch 0, step 47500, training loss = 2.012111, validation loss = 2.957593
2018-12-05 00:15:40,389 - INFO - epoch 0, step 47510, training loss = 2.023658, validation loss = 3.899951
2018-12-05 00:15:44,063 - INFO - epoch 0, step 47520, training loss = 2.071018, validation loss = 3.315392
2018-12-05 00:15:47,575 - INFO - epoch 0, step 47530, training loss = 2.310568, validation loss = 3.584969
2018-12-05 00:15:51,226 - INFO - epoch 0, step 47540, training loss = 2.239268, validation loss = 3.297825
2018-12-05 00:15:54,770 - INFO - epoch 0, step 47550, training loss = 2.113317, validation loss = 3.660896
2018-12-05 00:15:58,473 - INFO - epoch 0, step 47560, training loss = 2.160815, validation loss = 3.371994
2018-12-05 00:16:02,041 - INFO - epoch 0, step 47570, training loss = 1.936567, validation loss = 3.154479
2018-12-05 00:16:05,619 - INFO - epoch 0, step 47580, training loss = 2.375715, validation loss = 3.250348
2018-12-05 00:16:09,155 - INFO - epoch 0, step 47590, training loss = 2.029905, validation loss = 3.063911
2018-12-05 00:16:12,650 - INFO - epoch 0, step 47600, training loss = 2.073806, validation loss = 3.130648
2018-12-05 00:16:16,083 - INFO - epoch 0, step 47610, training loss = 2.471589, validation loss = 3.192934
2018-12-05 00:16:19,599 - INFO - epoch 0, step 47620, training loss = 2.371833, validation loss = 3.614690
2018-12-05 00:16:23,280 - INFO - epoch 0, step 47630, training loss = 2.582910, validation loss = 3.077240
2018-12-05 00:16:26,500 - INFO - epoch 0, step 47640, training loss = 2.264635, validation loss = 3.480014
2018-12-05 00:16:29,496 - INFO - epoch 0, step 47650, training loss = 2.408011, validation loss = 3.781219
2018-12-05 00:16:32,650 - INFO - epoch 0, step 47660, training loss = 1.939488, validation loss = 3.239604
2018-12-05 00:16:35,748 - INFO - epoch 0, step 47670, training loss = 2.130514, validation loss = 2.914032
2018-12-05 00:16:38,789 - INFO - epoch 0, step 47680, training loss = 2.244955, validation loss = 3.115512
2018-12-05 00:16:42,030 - INFO - epoch 0, step 47690, training loss = 1.984151, validation loss = 3.209046
2018-12-05 00:16:45,162 - INFO - epoch 0, step 47700, training loss = 2.335091, validation loss = 3.801937
2018-12-05 00:16:48,229 - INFO - epoch 0, step 47710, training loss = 2.054893, validation loss = 3.442605
2018-12-05 00:16:51,641 - INFO - epoch 0, step 47720, training loss = 1.686386, validation loss = 3.477810
2018-12-05 00:16:55,076 - INFO - epoch 0, step 47730, training loss = 2.160866, validation loss = 3.920877
2018-12-05 00:16:58,503 - INFO - epoch 0, step 47740, training loss = 2.081172, validation loss = 3.621401
2018-12-05 00:17:02,037 - INFO - epoch 0, step 47750, training loss = 1.885963, validation loss = 3.970530
2018-12-05 00:17:05,468 - INFO - epoch 0, step 47760, training loss = 1.933149, validation loss = 3.333815
2018-12-05 00:17:08,914 - INFO - epoch 0, step 47770, training loss = 1.957415, validation loss = 3.389135
2018-12-05 00:17:12,447 - INFO - epoch 0, step 47780, training loss = 2.476715, validation loss = 3.374024
2018-12-05 00:17:16,167 - INFO - epoch 0, step 47790, training loss = 2.185652, validation loss = 3.239338
2018-12-05 00:17:19,903 - INFO - epoch 0, step 47800, training loss = 1.754534, validation loss = 3.951375
2018-12-05 00:17:23,798 - INFO - epoch 0, step 47810, training loss = 1.885708, validation loss = 3.991439
2018-12-05 00:17:27,479 - INFO - epoch 0, step 47820, training loss = 1.955823, validation loss = 3.303709
2018-12-05 00:17:31,215 - INFO - epoch 0, step 47830, training loss = 1.694259, validation loss = 3.834047
2018-12-05 00:17:35,570 - INFO - epoch 0, step 47840, training loss = 2.126550, validation loss = 3.191558
2018-12-05 00:17:39,530 - INFO - epoch 0, step 47850, training loss = 2.110459, validation loss = 3.195791
2018-12-05 00:17:43,984 - INFO - epoch 0, step 47860, training loss = 2.268111, validation loss = 3.147704
2018-12-05 00:17:48,153 - INFO - epoch 0, step 47870, training loss = 2.303498, validation loss = 3.862862
2018-12-05 00:17:52,789 - INFO - epoch 0, step 47880, training loss = 2.084508, validation loss = 3.896687
2018-12-05 00:17:57,195 - INFO - epoch 0, step 47890, training loss = 2.387161, validation loss = 3.626119
2018-12-05 00:18:01,402 - INFO - epoch 0, step 47900, training loss = 2.292693, validation loss = 3.349005
2018-12-05 00:18:05,785 - INFO - epoch 0, step 47910, training loss = 2.401924, validation loss = 3.361768
2018-12-05 00:18:10,314 - INFO - epoch 0, step 47920, training loss = 1.834662, validation loss = 3.726553
2018-12-05 00:18:14,993 - INFO - epoch 0, step 47930, training loss = 2.067340, validation loss = 3.614135
2018-12-05 00:18:19,424 - INFO - epoch 0, step 47940, training loss = 1.890878, validation loss = 3.152755
2018-12-05 00:18:23,596 - INFO - epoch 0, step 47950, training loss = 2.339939, validation loss = 3.220947
2018-12-05 00:18:27,807 - INFO - epoch 0, step 47960, training loss = 2.003662, validation loss = 3.768308
2018-12-05 00:18:32,084 - INFO - epoch 0, step 47970, training loss = 1.806368, validation loss = 3.328999
2018-12-05 00:18:36,265 - INFO - epoch 0, step 47980, training loss = 2.292572, validation loss = 3.444447
2018-12-05 00:18:40,176 - INFO - epoch 0, step 47990, training loss = 2.200535, validation loss = 3.403359
2018-12-05 00:18:44,271 - INFO - epoch 0, step 48000, training loss = 2.109478, validation loss = 3.661173
2018-12-05 00:18:48,343 - INFO - epoch 0, step 48010, training loss = 2.182592, validation loss = 3.550531
2018-12-05 00:18:52,183 - INFO - epoch 0, step 48020, training loss = 2.421080, validation loss = 3.262142
2018-12-05 00:18:55,241 - INFO - epoch 0, step 48030, training loss = 2.489502, validation loss = 3.673023
2018-12-05 00:18:58,427 - INFO - epoch 0, step 48040, training loss = 2.245085, validation loss = 3.384997
2018-12-05 00:19:01,675 - INFO - epoch 0, step 48050, training loss = 2.084781, validation loss = 3.474590
2018-12-05 00:19:04,888 - INFO - epoch 0, step 48060, training loss = 2.371395, validation loss = 3.573887
2018-12-05 00:19:08,176 - INFO - epoch 0, step 48070, training loss = 2.134388, validation loss = 3.950679
2018-12-05 00:19:11,452 - INFO - epoch 0, step 48080, training loss = 2.289371, validation loss = 3.500420
2018-12-05 00:19:14,842 - INFO - epoch 0, step 48090, training loss = 1.953388, validation loss = 3.535074
2018-12-05 00:19:18,389 - INFO - epoch 0, step 48100, training loss = 2.167455, validation loss = 3.525215
2018-12-05 00:19:21,720 - INFO - epoch 0, step 48110, training loss = 1.964784, validation loss = 3.472115
2018-12-05 00:19:25,305 - INFO - epoch 0, step 48120, training loss = 2.164912, validation loss = 3.377247
2018-12-05 00:19:29,098 - INFO - epoch 0, step 48130, training loss = 1.947236, validation loss = 3.341258
2018-12-05 00:19:32,702 - INFO - epoch 0, step 48140, training loss = 2.061280, validation loss = 3.213893
2018-12-05 00:19:36,303 - INFO - epoch 0, step 48150, training loss = 1.897504, validation loss = 3.784518
2018-12-05 00:19:39,916 - INFO - epoch 0, step 48160, training loss = 2.026742, validation loss = 3.880130
2018-12-05 00:19:44,272 - INFO - epoch 0, step 48170, training loss = 2.182696, validation loss = 3.437213
2018-12-05 00:19:48,419 - INFO - epoch 0, step 48180, training loss = 2.042336, validation loss = 3.811109
2018-12-05 00:19:52,789 - INFO - epoch 0, step 48190, training loss = 2.040663, validation loss = 3.893551
2018-12-05 00:19:56,932 - INFO - epoch 0, step 48200, training loss = 1.523438, validation loss = 3.470021
2018-12-05 00:20:01,369 - INFO - epoch 0, step 48210, training loss = 1.647672, validation loss = 3.293252
2018-12-05 00:20:05,731 - INFO - epoch 0, step 48220, training loss = 1.928226, validation loss = 3.094228
2018-12-05 00:20:09,689 - INFO - epoch 0, step 48230, training loss = 1.997791, validation loss = 2.631407
2018-12-05 00:20:13,859 - INFO - epoch 0, step 48240, training loss = 1.517927, validation loss = 3.976934
2018-12-05 00:20:17,954 - INFO - epoch 0, step 48250, training loss = 2.027926, validation loss = 3.342985
2018-12-05 00:20:22,074 - INFO - epoch 0, step 48260, training loss = 2.047708, validation loss = 3.321701
2018-12-05 00:20:25,907 - INFO - epoch 0, step 48270, training loss = 2.097330, validation loss = 2.944317
2018-12-05 00:20:29,825 - INFO - epoch 0, step 48280, training loss = 1.769737, validation loss = 3.805648
2018-12-05 00:20:33,623 - INFO - epoch 0, step 48290, training loss = 2.194571, validation loss = 3.861431
2018-12-05 00:20:37,641 - INFO - epoch 0, step 48300, training loss = 1.852083, validation loss = 3.366725
2018-12-05 00:20:41,869 - INFO - epoch 0, step 48310, training loss = 2.386775, validation loss = 3.452902
2018-12-05 00:20:46,352 - INFO - epoch 0, step 48320, training loss = 1.798862, validation loss = 3.480663
2018-12-05 00:20:50,871 - INFO - epoch 0, step 48330, training loss = 1.898885, validation loss = 3.393890
2018-12-05 00:20:55,091 - INFO - epoch 0, step 48340, training loss = 1.756214, validation loss = 3.616321
2018-12-05 00:20:59,438 - INFO - epoch 0, step 48350, training loss = 2.097693, validation loss = 2.972334
2018-12-05 00:21:03,907 - INFO - epoch 0, step 48360, training loss = 1.846464, validation loss = 3.585879
2018-12-05 00:21:08,188 - INFO - epoch 0, step 48370, training loss = 1.658659, validation loss = 3.362959
2018-12-05 00:21:12,759 - INFO - epoch 0, step 48380, training loss = 1.641444, validation loss = 3.962737
2018-12-05 00:21:17,052 - INFO - epoch 0, step 48390, training loss = 1.765507, validation loss = 3.474913
2018-12-05 00:21:21,680 - INFO - epoch 0, step 48400, training loss = 2.037009, validation loss = 3.399103
2018-12-05 00:21:25,798 - INFO - epoch 0, step 48410, training loss = 2.035728, validation loss = 3.677301
2018-12-05 00:21:29,931 - INFO - epoch 0, step 48420, training loss = 1.746952, validation loss = 3.623013
2018-12-05 00:21:34,110 - INFO - epoch 0, step 48430, training loss = 1.928224, validation loss = 3.769782
2018-12-05 00:21:38,379 - INFO - epoch 0, step 48440, training loss = 1.779179, validation loss = 3.398181
2018-12-05 00:21:42,533 - INFO - epoch 0, step 48450, training loss = 1.969988, validation loss = 3.344287
2018-12-05 00:21:46,582 - INFO - epoch 0, step 48460, training loss = 2.185740, validation loss = 3.366693
2018-12-05 00:21:50,815 - INFO - epoch 0, step 48470, training loss = 2.529506, validation loss = 3.380559
2018-12-05 00:21:54,005 - INFO - epoch 0, step 48480, training loss = 2.345603, validation loss = 3.171996
2018-12-05 00:21:57,165 - INFO - epoch 0, step 48490, training loss = 1.849678, validation loss = 3.063341
2018-12-05 00:22:00,328 - INFO - epoch 0, step 48500, training loss = 2.208763, validation loss = 3.584570
2018-12-05 00:22:03,456 - INFO - epoch 0, step 48510, training loss = 2.112119, validation loss = 3.016214
2018-12-05 00:22:06,705 - INFO - epoch 0, step 48520, training loss = 2.171160, validation loss = 3.990117
2018-12-05 00:22:09,924 - INFO - epoch 0, step 48530, training loss = 2.330573, validation loss = 3.779230
2018-12-05 00:22:13,148 - INFO - epoch 0, step 48540, training loss = 2.069868, validation loss = 3.080161
2018-12-05 00:22:16,453 - INFO - epoch 0, step 48550, training loss = 2.102335, validation loss = 3.569149
2018-12-05 00:22:19,692 - INFO - epoch 0, step 48560, training loss = 1.653698, validation loss = 3.251769
2018-12-05 00:22:23,023 - INFO - epoch 0, step 48570, training loss = 2.045409, validation loss = 3.456884
2018-12-05 00:22:26,645 - INFO - epoch 0, step 48580, training loss = 2.039916, validation loss = 3.770508
2018-12-05 00:22:30,167 - INFO - epoch 0, step 48590, training loss = 1.876744, validation loss = 3.388247
2018-12-05 00:22:33,552 - INFO - epoch 0, step 48600, training loss = 1.723985, validation loss = 3.409180
2018-12-05 00:22:36,963 - INFO - epoch 0, step 48610, training loss = 1.534760, validation loss = 3.364857
2018-12-05 00:22:40,233 - INFO - epoch 0, step 48620, training loss = 2.419524, validation loss = 3.245415
2018-12-05 00:22:44,258 - INFO - epoch 0, step 48630, training loss = 2.099998, validation loss = 3.417646
2018-12-05 00:22:48,167 - INFO - epoch 0, step 48640, training loss = 2.005061, validation loss = 3.250695
2018-12-05 00:22:52,059 - INFO - epoch 0, step 48650, training loss = 1.751205, validation loss = 3.545578
2018-12-05 00:22:56,154 - INFO - epoch 0, step 48660, training loss = 1.983278, validation loss = 3.350356
2018-12-05 00:23:00,200 - INFO - epoch 0, step 48670, training loss = 1.932002, validation loss = 3.413946
2018-12-05 00:23:04,387 - INFO - epoch 0, step 48680, training loss = 1.754591, validation loss = 3.333647
2018-12-05 00:23:08,493 - INFO - epoch 0, step 48690, training loss = 1.905800, validation loss = 3.612281
2018-12-05 00:23:12,607 - INFO - epoch 0, step 48700, training loss = 2.114741, validation loss = 3.472324
2018-12-05 00:23:16,869 - INFO - epoch 0, step 48710, training loss = 2.031381, validation loss = 3.464324
2018-12-05 00:23:20,854 - INFO - epoch 0, step 48720, training loss = 1.953922, validation loss = 3.395769
2018-12-05 00:23:24,884 - INFO - epoch 0, step 48730, training loss = 2.179332, validation loss = 3.807910
2018-12-05 00:23:29,063 - INFO - epoch 0, step 48740, training loss = 1.944711, validation loss = 3.489769
2018-12-05 00:23:33,020 - INFO - epoch 0, step 48750, training loss = 1.890951, validation loss = 3.573073
2018-12-05 00:23:37,275 - INFO - epoch 0, step 48760, training loss = 1.475778, validation loss = 3.448563
2018-12-05 00:23:41,124 - INFO - epoch 0, step 48770, training loss = 1.961201, validation loss = 3.337904
2018-12-05 00:23:45,248 - INFO - epoch 0, step 48780, training loss = 2.242916, validation loss = 3.480675
2018-12-05 00:23:49,658 - INFO - epoch 0, step 48790, training loss = 2.286220, validation loss = 3.134742
2018-12-05 00:23:54,066 - INFO - epoch 0, step 48800, training loss = 1.712997, validation loss = 3.624964
2018-12-05 00:23:58,261 - INFO - epoch 0, step 48810, training loss = 2.120083, validation loss = 2.997417
2018-12-05 00:24:02,509 - INFO - epoch 0, step 48820, training loss = 1.797443, validation loss = 3.706796
2018-12-05 00:24:06,700 - INFO - epoch 0, step 48830, training loss = 2.041669, validation loss = 3.675960
2018-12-05 00:24:10,852 - INFO - epoch 0, step 48840, training loss = 2.133075, validation loss = 3.076363
2018-12-05 00:24:15,159 - INFO - epoch 0, step 48850, training loss = 2.266873, validation loss = 3.740479
2018-12-05 00:24:19,302 - INFO - epoch 0, step 48860, training loss = 1.962544, validation loss = 3.353110
2018-12-05 00:24:23,157 - INFO - epoch 0, step 48870, training loss = 2.052166, validation loss = 2.830900
2018-12-05 00:24:26,889 - INFO - epoch 0, step 48880, training loss = 2.213770, validation loss = 3.594066
2018-12-05 00:24:30,914 - INFO - epoch 0, step 48890, training loss = 1.532794, validation loss = 3.658514
2018-12-05 00:24:34,833 - INFO - epoch 0, step 48900, training loss = 2.167416, validation loss = 3.253065
2018-12-05 00:24:38,638 - INFO - epoch 0, step 48910, training loss = 1.910326, validation loss = 3.080124
2018-12-05 00:24:42,470 - INFO - epoch 0, step 48920, training loss = 2.099506, validation loss = 3.007517
2018-12-05 00:24:46,128 - INFO - epoch 0, step 48930, training loss = 2.278166, validation loss = 3.334840
2018-12-05 00:24:49,862 - INFO - epoch 0, step 48940, training loss = 2.155300, validation loss = 3.148848
2018-12-05 00:24:53,819 - INFO - epoch 0, step 48950, training loss = 2.024875, validation loss = 3.720369
2018-12-05 00:24:57,408 - INFO - epoch 0, step 48960, training loss = 1.798131, validation loss = 3.040539
2018-12-05 00:25:01,028 - INFO - epoch 0, step 48970, training loss = 1.750335, validation loss = 3.394798
2018-12-05 00:25:04,900 - INFO - epoch 0, step 48980, training loss = 1.586381, validation loss = 3.431809
2018-12-05 00:25:08,481 - INFO - epoch 0, step 48990, training loss = 2.457514, validation loss = 3.631207
2018-12-05 00:25:11,764 - INFO - epoch 0, step 49000, training loss = 2.435338, validation loss = 2.955104
2018-12-05 00:25:15,086 - INFO - epoch 0, step 49010, training loss = 1.983812, validation loss = 3.433133
2018-12-05 00:25:18,339 - INFO - epoch 0, step 49020, training loss = 2.146122, validation loss = 3.809700
2018-12-05 00:25:21,481 - INFO - epoch 0, step 49030, training loss = 2.505373, validation loss = 3.508308
2018-12-05 00:25:24,586 - INFO - epoch 0, step 49040, training loss = 2.120467, validation loss = 3.557899
2018-12-05 00:25:28,207 - INFO - epoch 0, step 49050, training loss = 1.829381, validation loss = 3.481558
2018-12-05 00:25:32,259 - INFO - epoch 0, step 49060, training loss = 1.962861, validation loss = 3.534008
2018-12-05 00:25:36,018 - INFO - epoch 0, step 49070, training loss = 2.215396, validation loss = 3.796409
2018-12-05 00:25:40,099 - INFO - epoch 0, step 49080, training loss = 1.690047, validation loss = 3.679446
2018-12-05 00:25:43,918 - INFO - epoch 0, step 49090, training loss = 1.967042, validation loss = 3.479310
2018-12-05 00:25:47,674 - INFO - epoch 0, step 49100, training loss = 2.208134, validation loss = 3.645770
2018-12-05 00:25:51,409 - INFO - epoch 0, step 49110, training loss = 2.156351, validation loss = 3.684492
2018-12-05 00:25:55,259 - INFO - epoch 0, step 49120, training loss = 1.951157, validation loss = 2.886337
2018-12-05 00:25:59,024 - INFO - epoch 0, step 49130, training loss = 1.709850, validation loss = 3.027392
2018-12-05 00:26:02,784 - INFO - epoch 0, step 49140, training loss = 1.887084, validation loss = 3.442108
2018-12-05 00:26:06,407 - INFO - epoch 0, step 49150, training loss = 1.892578, validation loss = 3.402091
2018-12-05 00:26:09,836 - INFO - epoch 0, step 49160, training loss = 2.201955, validation loss = 3.222826
2018-12-05 00:26:13,209 - INFO - epoch 0, step 49170, training loss = 1.755086, validation loss = 3.272247
2018-12-05 00:26:16,739 - INFO - epoch 0, step 49180, training loss = 2.114451, validation loss = 3.173810
2018-12-05 00:26:20,326 - INFO - epoch 0, step 49190, training loss = 1.790480, validation loss = 3.632147
2018-12-05 00:26:24,613 - INFO - epoch 0, step 49200, training loss = 2.210232, validation loss = 3.418053
2018-12-05 00:26:28,797 - INFO - epoch 0, step 49210, training loss = 1.839116, validation loss = 3.311666
2018-12-05 00:26:32,851 - INFO - epoch 0, step 49220, training loss = 1.995973, validation loss = 3.439183
2018-12-05 00:26:36,882 - INFO - epoch 0, step 49230, training loss = 1.935445, validation loss = 3.853088
2018-12-05 00:26:41,030 - INFO - epoch 0, step 49240, training loss = 1.843140, validation loss = 3.079756
2018-12-05 00:26:45,134 - INFO - epoch 0, step 49250, training loss = 1.992234, validation loss = 3.677713
2018-12-05 00:26:49,331 - INFO - epoch 0, step 49260, training loss = 1.848133, validation loss = 3.835251
2018-12-05 00:26:53,517 - INFO - epoch 0, step 49270, training loss = 1.929753, validation loss = 3.802133
2018-12-05 00:26:57,040 - INFO - epoch 0, step 49280, training loss = 2.139971, validation loss = 3.541579
2018-12-05 00:27:00,597 - INFO - epoch 0, step 49290, training loss = 2.163588, validation loss = 3.400625
2018-12-05 00:27:04,120 - INFO - epoch 0, step 49300, training loss = 1.917983, validation loss = 3.415987
2018-12-05 00:27:07,460 - INFO - epoch 0, step 49310, training loss = 1.912499, validation loss = 3.680651
2018-12-05 00:27:11,003 - INFO - epoch 0, step 49320, training loss = 2.080301, validation loss = 3.324481
2018-12-05 00:27:14,330 - INFO - epoch 0, step 49330, training loss = 2.101497, validation loss = 3.427375
2018-12-05 00:27:17,923 - INFO - epoch 0, step 49340, training loss = 2.208470, validation loss = 3.295755
2018-12-05 00:27:21,243 - INFO - epoch 0, step 49350, training loss = 2.131781, validation loss = 2.935126
2018-12-05 00:27:24,513 - INFO - epoch 0, step 49360, training loss = 2.006212, validation loss = 3.527258
2018-12-05 00:27:27,881 - INFO - epoch 0, step 49370, training loss = 2.119752, validation loss = 3.563081
2018-12-05 00:27:31,231 - INFO - epoch 0, step 49380, training loss = 1.847455, validation loss = 3.282733
2018-12-05 00:27:34,651 - INFO - epoch 0, step 49390, training loss = 1.784525, validation loss = 3.337552
2018-12-05 00:27:38,248 - INFO - epoch 0, step 49400, training loss = 2.096082, validation loss = 3.635828
2018-12-05 00:27:41,454 - INFO - epoch 0, step 49410, training loss = 2.548463, validation loss = 3.304926
2018-12-05 00:27:44,430 - INFO - epoch 0, step 49420, training loss = 2.072625, validation loss = 3.849095
2018-12-05 00:27:47,457 - INFO - epoch 0, step 49430, training loss = 2.121022, validation loss = 3.486466
2018-12-05 00:27:50,584 - INFO - epoch 0, step 49440, training loss = 2.275378, validation loss = 3.541739
2018-12-05 00:27:53,874 - INFO - epoch 0, step 49450, training loss = 2.283286, validation loss = 3.618202
2018-12-05 00:27:57,265 - INFO - epoch 0, step 49460, training loss = 2.116241, validation loss = 3.439659
2018-12-05 00:28:00,541 - INFO - epoch 0, step 49470, training loss = 2.338879, validation loss = 3.365418
2018-12-05 00:28:03,946 - INFO - epoch 0, step 49480, training loss = 1.972057, validation loss = 3.811870
2018-12-05 00:28:07,882 - INFO - epoch 0, step 49490, training loss = 2.208474, validation loss = 3.323184
2018-12-05 00:28:11,415 - INFO - epoch 0, step 49500, training loss = 2.298093, validation loss = 3.318084
2018-12-05 00:28:14,615 - INFO - epoch 0, step 49510, training loss = 1.816779, validation loss = 3.644147
2018-12-05 00:28:17,782 - INFO - epoch 0, step 49520, training loss = 1.959090, validation loss = 3.692082
2018-12-05 00:28:20,820 - INFO - epoch 0, step 49530, training loss = 2.395560, validation loss = 3.410393
2018-12-05 00:28:24,022 - INFO - epoch 0, step 49540, training loss = 2.280373, validation loss = 3.173111
2018-12-05 00:28:27,239 - INFO - epoch 0, step 49550, training loss = 2.322787, validation loss = 2.973789
2018-12-05 00:28:30,283 - INFO - epoch 0, step 49560, training loss = 1.985052, validation loss = 2.751687
2018-12-05 00:28:33,847 - INFO - epoch 0, step 49570, training loss = 1.799812, validation loss = 3.322360
2018-12-05 00:28:37,397 - INFO - epoch 0, step 49580, training loss = 2.251428, validation loss = 3.502724
2018-12-05 00:28:40,821 - INFO - epoch 0, step 49590, training loss = 1.953601, validation loss = 3.420476
2018-12-05 00:28:44,389 - INFO - epoch 0, step 49600, training loss = 1.810017, validation loss = 2.958156
2018-12-05 00:28:47,960 - INFO - epoch 0, step 49610, training loss = 1.816472, validation loss = 3.165218
2018-12-05 00:28:51,290 - INFO - epoch 0, step 49620, training loss = 1.743946, validation loss = 3.551083
2018-12-05 00:28:55,115 - INFO - epoch 0, step 49630, training loss = 1.890174, validation loss = 2.870010
2018-12-05 00:28:59,460 - INFO - epoch 0, step 49640, training loss = 1.784268, validation loss = 3.821450
2018-12-05 00:29:03,905 - INFO - epoch 0, step 49650, training loss = 2.003376, validation loss = 3.705615
2018-12-05 00:29:08,285 - INFO - epoch 0, step 49660, training loss = 2.292027, validation loss = 3.439152
2018-12-05 00:29:12,655 - INFO - epoch 0, step 49670, training loss = 2.056818, validation loss = 4.159521
2018-12-05 00:29:17,183 - INFO - epoch 0, step 49680, training loss = 1.658784, validation loss = 3.245066
2018-12-05 00:29:21,695 - INFO - epoch 0, step 49690, training loss = 1.753474, validation loss = 3.392014
2018-12-05 00:29:26,116 - INFO - epoch 0, step 49700, training loss = 2.073034, validation loss = 3.449085
2018-12-05 00:29:30,491 - INFO - epoch 0, step 49710, training loss = 2.101350, validation loss = 3.560769
2018-12-05 00:29:34,849 - INFO - epoch 0, step 49720, training loss = 1.862349, validation loss = 3.213189
2018-12-05 00:29:38,948 - INFO - epoch 0, step 49730, training loss = 1.968363, validation loss = 3.620235
2018-12-05 00:29:43,470 - INFO - epoch 0, step 49740, training loss = 1.792679, validation loss = 3.422319
2018-12-05 00:29:47,872 - INFO - epoch 0, step 49750, training loss = 1.994456, validation loss = 3.435440
2018-12-05 00:29:51,992 - INFO - epoch 0, step 49760, training loss = 1.819977, validation loss = 3.323129
2018-12-05 00:29:56,336 - INFO - epoch 0, step 49770, training loss = 2.000219, validation loss = 3.505969
2018-12-05 00:30:00,808 - INFO - epoch 0, step 49780, training loss = 1.809750, validation loss = 4.303270
2018-12-05 00:30:04,999 - INFO - epoch 0, step 49790, training loss = 2.149809, validation loss = 2.793515
2018-12-05 00:30:08,264 - INFO - epoch 0, step 49800, training loss = 2.270581, validation loss = 3.456586
2018-12-05 00:30:11,459 - INFO - epoch 0, step 49810, training loss = 2.071312, validation loss = 3.212085
2018-12-05 00:30:14,605 - INFO - epoch 0, step 49820, training loss = 2.287911, validation loss = 2.952995
2018-12-05 00:30:18,150 - INFO - epoch 0, step 49830, training loss = 1.964673, validation loss = 3.311639
2018-12-05 00:30:21,404 - INFO - epoch 0, step 49840, training loss = 2.022925, validation loss = 3.725201
2018-12-05 00:30:24,670 - INFO - epoch 0, step 49850, training loss = 1.941724, validation loss = 3.430481
2018-12-05 00:30:28,217 - INFO - epoch 0, step 49860, training loss = 1.770481, validation loss = 3.232606
2018-12-05 00:30:31,846 - INFO - epoch 0, step 49870, training loss = 1.826412, validation loss = 2.913601
2018-12-05 00:30:35,656 - INFO - epoch 0, step 49880, training loss = 1.975794, validation loss = 3.794446
2018-12-05 00:30:39,262 - INFO - epoch 0, step 49890, training loss = 1.729527, validation loss = 3.135765
2018-12-05 00:30:42,851 - INFO - epoch 0, step 49900, training loss = 2.064357, validation loss = 3.443808
2018-12-05 00:30:46,612 - INFO - epoch 0, step 49910, training loss = 2.075045, validation loss = 4.117049
2018-12-05 00:30:50,110 - INFO - epoch 0, step 49920, training loss = 1.905459, validation loss = 2.958427
2018-12-05 00:30:54,087 - INFO - epoch 0, step 49930, training loss = 2.044068, validation loss = 3.353022
2018-12-05 00:30:58,174 - INFO - epoch 0, step 49940, training loss = 1.684004, validation loss = 3.134971
2018-12-05 00:31:02,523 - INFO - epoch 0, step 49950, training loss = 1.560238, validation loss = 3.223496
2018-12-05 00:31:06,734 - INFO - epoch 0, step 49960, training loss = 1.976079, validation loss = 3.266827
2018-12-05 00:31:10,714 - INFO - epoch 0, step 49970, training loss = 2.364655, validation loss = 3.135408
2018-12-05 00:31:14,870 - INFO - epoch 0, step 49980, training loss = 1.889727, validation loss = 3.418817
2018-12-05 00:31:19,131 - INFO - epoch 0, step 49990, training loss = 2.058037, validation loss = 3.763944
2018-12-05 00:31:23,351 - INFO - epoch 0, step 50000, training loss = 1.881438, validation loss = 3.417803
2018-12-05 00:31:27,518 - INFO - epoch 0, step 50010, training loss = 1.974878, validation loss = 3.176683
2018-12-05 00:31:31,708 - INFO - epoch 0, step 50020, training loss = 1.901873, validation loss = 3.412651
2018-12-05 00:31:36,055 - INFO - epoch 0, step 50030, training loss = 1.604467, validation loss = 3.442652
2018-12-05 00:31:40,032 - INFO - epoch 0, step 50040, training loss = 2.055816, validation loss = 3.631708
2018-12-05 00:31:44,294 - INFO - epoch 0, step 50050, training loss = 1.844042, validation loss = 3.030111
2018-12-05 00:31:48,622 - INFO - epoch 0, step 50060, training loss = 2.006455, validation loss = 3.574157
2018-12-05 00:31:53,034 - INFO - epoch 0, step 50070, training loss = 1.934307, validation loss = 3.611037
2018-12-05 00:31:57,609 - INFO - epoch 0, step 50080, training loss = 2.017465, validation loss = 3.964144
2018-12-05 00:32:00,720 - INFO - epoch 0, step 50090, training loss = 2.344560, validation loss = 4.254724
2018-12-05 00:32:04,182 - INFO - epoch 0, step 50100, training loss = 1.892315, validation loss = 3.299339
2018-12-05 00:32:07,504 - INFO - epoch 0, step 50110, training loss = 1.730660, validation loss = 3.363566
2018-12-05 00:32:10,748 - INFO - epoch 0, step 50120, training loss = 2.082188, validation loss = 3.115831
2018-12-05 00:32:14,232 - INFO - epoch 0, step 50130, training loss = 1.521921, validation loss = 3.543731
2018-12-05 00:32:17,543 - INFO - epoch 0, step 50140, training loss = 2.067900, validation loss = 3.343321
2018-12-05 00:32:21,524 - INFO - epoch 0, step 50150, training loss = 1.307014, validation loss = 2.905811
2018-12-05 00:32:25,672 - INFO - epoch 0, step 50160, training loss = 1.671796, validation loss = 3.276879
2018-12-05 00:32:29,856 - INFO - epoch 0, step 50170, training loss = 1.852077, validation loss = 3.711808
2018-12-05 00:32:34,127 - INFO - epoch 0, step 50180, training loss = 1.730253, validation loss = 3.589156
2018-12-05 00:32:38,315 - INFO - epoch 0, step 50190, training loss = 2.041748, validation loss = 3.490110
2018-12-05 00:32:42,442 - INFO - epoch 0, step 50200, training loss = 1.993270, validation loss = 3.114321
2018-12-05 00:32:46,633 - INFO - epoch 0, step 50210, training loss = 1.512968, validation loss = 3.458912
2018-12-05 00:32:50,598 - INFO - epoch 0, step 50220, training loss = 1.462721, validation loss = 3.611729
2018-12-05 00:32:54,714 - INFO - epoch 0, step 50230, training loss = 1.585012, validation loss = 2.883135
2018-12-05 00:32:59,275 - INFO - epoch 0, step 50240, training loss = 1.806777, validation loss = 3.246200
2018-12-05 00:33:03,422 - INFO - epoch 0, step 50250, training loss = 2.181542, validation loss = 3.142168
2018-12-05 00:33:07,693 - INFO - epoch 0, step 50260, training loss = 1.774922, validation loss = 3.259780
2018-12-05 00:33:11,788 - INFO - epoch 0, step 50270, training loss = 2.007749, validation loss = 3.184329
2018-12-05 00:33:16,013 - INFO - epoch 0, step 50280, training loss = 2.004165, validation loss = 3.494855
2018-12-05 00:33:20,411 - INFO - epoch 0, step 50290, training loss = 1.739129, validation loss = 3.082127
2018-12-05 00:33:24,723 - INFO - epoch 0, step 50300, training loss = 1.753072, validation loss = 3.482026
2018-12-05 00:33:29,016 - INFO - epoch 0, step 50310, training loss = 1.893077, validation loss = 3.452317
2018-12-05 00:33:33,136 - INFO - epoch 0, step 50320, training loss = 2.045725, validation loss = 3.621776
2018-12-05 00:33:37,593 - INFO - epoch 0, step 50330, training loss = 1.922792, validation loss = 3.210625
2018-12-05 00:33:41,789 - INFO - epoch 0, step 50340, training loss = 1.736173, validation loss = 3.957725
2018-12-05 00:33:46,289 - INFO - epoch 0, step 50350, training loss = 1.848827, validation loss = 3.435920
2018-12-05 00:33:50,891 - INFO - epoch 0, step 50360, training loss = 1.850264, validation loss = 3.200492
2018-12-05 00:33:55,088 - INFO - epoch 0, step 50370, training loss = 1.934665, validation loss = 3.524224
2018-12-05 00:33:59,187 - INFO - epoch 0, step 50380, training loss = 2.022899, validation loss = 3.732942
2018-12-05 00:34:03,467 - INFO - epoch 0, step 50390, training loss = 1.933446, validation loss = 3.106436
2018-12-05 00:34:07,854 - INFO - epoch 0, step 50400, training loss = 1.875988, validation loss = 3.400813
2018-12-05 00:34:11,649 - INFO - epoch 0, step 50410, training loss = 2.017338, validation loss = 3.636403
2018-12-05 00:34:15,462 - INFO - epoch 0, step 50420, training loss = 1.898784, validation loss = 3.461251
2018-12-05 00:34:19,082 - INFO - epoch 0, step 50430, training loss = 1.986437, validation loss = 3.262053
2018-12-05 00:34:22,820 - INFO - epoch 0, step 50440, training loss = 2.244026, validation loss = 3.089164
2018-12-05 00:34:26,611 - INFO - epoch 0, step 50450, training loss = 1.787852, validation loss = 3.154132
2018-12-05 00:34:30,465 - INFO - epoch 0, step 50460, training loss = 1.625248, validation loss = 3.513912
2018-12-05 00:34:34,209 - INFO - epoch 0, step 50470, training loss = 1.714991, validation loss = 3.503210
2018-12-05 00:34:37,494 - INFO - epoch 0, step 50480, training loss = 2.165112, validation loss = 3.129295
2018-12-05 00:34:40,634 - INFO - epoch 0, step 50490, training loss = 2.507938, validation loss = 3.558835
2018-12-05 00:34:43,711 - INFO - epoch 0, step 50500, training loss = 2.301894, validation loss = 3.100541
2018-12-05 00:34:46,900 - INFO - epoch 0, step 50510, training loss = 1.750165, validation loss = 3.220310
2018-12-05 00:34:50,059 - INFO - epoch 0, step 50520, training loss = 1.777074, validation loss = 3.665810
2018-12-05 00:34:53,391 - INFO - epoch 0, step 50530, training loss = 2.057004, validation loss = 2.906556
2018-12-05 00:34:56,616 - INFO - epoch 0, step 50540, training loss = 1.723221, validation loss = 3.377821
2018-12-05 00:34:59,777 - INFO - epoch 0, step 50550, training loss = 2.273558, validation loss = 3.894878
2018-12-05 00:35:03,818 - INFO - epoch 0, step 50560, training loss = 1.480549, validation loss = 3.250013
2018-12-05 00:35:08,061 - INFO - epoch 0, step 50570, training loss = 1.844391, validation loss = 3.497308
2018-12-05 00:35:11,986 - INFO - epoch 0, step 50580, training loss = 2.223974, validation loss = 3.331784
2018-12-05 00:35:16,042 - INFO - epoch 0, step 50590, training loss = 1.897725, validation loss = 3.380085
2018-12-05 00:35:20,222 - INFO - epoch 0, step 50600, training loss = 1.859501, validation loss = 3.655092
2018-12-05 00:35:24,291 - INFO - epoch 0, step 50610, training loss = 1.327597, validation loss = 3.367237
2018-12-05 00:35:28,288 - INFO - epoch 0, step 50620, training loss = 1.985553, validation loss = 2.800211
2018-12-05 00:35:32,276 - INFO - epoch 0, step 50630, training loss = 2.084341, validation loss = 3.971474
2018-12-05 00:35:36,546 - INFO - epoch 0, step 50640, training loss = 1.825576, validation loss = 3.477026
2018-12-05 00:35:40,936 - INFO - epoch 0, step 50650, training loss = 2.061861, validation loss = 3.761185
2018-12-05 00:35:45,458 - INFO - epoch 0, step 50660, training loss = 1.805510, validation loss = 3.571842
2018-12-05 00:35:49,658 - INFO - epoch 0, step 50670, training loss = 1.622954, validation loss = 3.484430
2018-12-05 00:35:53,884 - INFO - epoch 0, step 50680, training loss = 1.639107, validation loss = 3.376571
2018-12-05 00:35:58,046 - INFO - epoch 0, step 50690, training loss = 1.758733, validation loss = 3.417534
2018-12-05 00:36:01,655 - INFO - epoch 0, step 50700, training loss = 1.994196, validation loss = 3.621823
2018-12-05 00:36:05,494 - INFO - epoch 0, step 50710, training loss = 2.181042, validation loss = 3.774290
2018-12-05 00:36:09,123 - INFO - epoch 0, step 50720, training loss = 1.746839, validation loss = 3.824666
2018-12-05 00:36:12,651 - INFO - epoch 0, step 50730, training loss = 1.948796, validation loss = 3.414461
2018-12-05 00:36:16,140 - INFO - epoch 0, step 50740, training loss = 2.044906, validation loss = 3.656263
2018-12-05 00:36:19,778 - INFO - epoch 0, step 50750, training loss = 1.681881, validation loss = 2.937127
2018-12-05 00:36:23,282 - INFO - epoch 0, step 50760, training loss = 1.732710, validation loss = 3.714480
2018-12-05 00:36:26,663 - INFO - epoch 0, step 50770, training loss = 2.092942, validation loss = 3.863716
2018-12-05 00:36:29,930 - INFO - epoch 0, step 50780, training loss = 1.743666, validation loss = 3.452805
2018-12-05 00:36:33,320 - INFO - epoch 0, step 50790, training loss = 2.346735, validation loss = 3.497844
2018-12-05 00:36:36,758 - INFO - epoch 0, step 50800, training loss = 2.132491, validation loss = 3.369091
2018-12-05 00:36:40,199 - INFO - epoch 0, step 50810, training loss = 2.188337, validation loss = 3.196907
2018-12-05 00:36:43,687 - INFO - epoch 0, step 50820, training loss = 1.686589, validation loss = 3.693500
2018-12-05 00:36:47,237 - INFO - epoch 0, step 50830, training loss = 2.229674, validation loss = 2.974194
2018-12-05 00:36:50,765 - INFO - epoch 0, step 50840, training loss = 1.648936, validation loss = 3.575051
2018-12-05 00:36:54,233 - INFO - epoch 0, step 50850, training loss = 1.606056, validation loss = 3.645630
2018-12-05 00:36:57,742 - INFO - epoch 0, step 50860, training loss = 1.859849, validation loss = 3.573655
2018-12-05 00:37:01,479 - INFO - epoch 0, step 50870, training loss = 1.768668, validation loss = 3.268404
2018-12-05 00:37:05,140 - INFO - epoch 0, step 50880, training loss = 1.752000, validation loss = 3.179664
2018-12-05 00:37:08,659 - INFO - epoch 0, step 50890, training loss = 2.007291, validation loss = 3.882413
2018-12-05 00:37:12,752 - INFO - epoch 0, step 50900, training loss = 1.945070, validation loss = 2.975921
2018-12-05 00:37:16,303 - INFO - epoch 0, step 50910, training loss = 1.913626, validation loss = 3.829111
2018-12-05 00:37:19,926 - INFO - epoch 0, step 50920, training loss = 1.708514, validation loss = 3.499628
2018-12-05 00:37:23,538 - INFO - epoch 0, step 50930, training loss = 1.987960, validation loss = 3.244896
2018-12-05 00:37:27,197 - INFO - epoch 0, step 50940, training loss = 1.735778, validation loss = 3.531448
2018-12-05 00:37:30,680 - INFO - epoch 0, step 50950, training loss = 1.746475, validation loss = 3.526032
2018-12-05 00:37:34,376 - INFO - epoch 0, step 50960, training loss = 2.005300, validation loss = 3.376392
2018-12-05 00:37:37,727 - INFO - epoch 0, step 50970, training loss = 1.892581, validation loss = 3.539135
2018-12-05 00:37:41,204 - INFO - epoch 0, step 50980, training loss = 2.238627, validation loss = 3.321879
2018-12-05 00:37:44,596 - INFO - epoch 0, step 50990, training loss = 2.110340, validation loss = 3.572741
2018-12-05 00:37:48,003 - INFO - epoch 0, step 51000, training loss = 2.497760, validation loss = 3.986357
2018-12-05 00:37:51,561 - INFO - epoch 0, step 51010, training loss = 1.874804, validation loss = 4.033696
2018-12-05 00:37:55,104 - INFO - epoch 0, step 51020, training loss = 1.673933, validation loss = 3.964525
2018-12-05 00:37:58,231 - INFO - epoch 0, step 51030, training loss = 2.163396, validation loss = 3.072079
2018-12-05 00:38:01,661 - INFO - epoch 0, step 51040, training loss = 1.818867, validation loss = 3.750790
2018-12-05 00:38:05,483 - INFO - epoch 0, step 51050, training loss = 2.098466, validation loss = 3.686281
2018-12-05 00:38:09,310 - INFO - epoch 0, step 51060, training loss = 2.112296, validation loss = 3.372704
2018-12-05 00:38:13,187 - INFO - epoch 0, step 51070, training loss = 2.165814, validation loss = 3.615303
2018-12-05 00:38:17,143 - INFO - epoch 0, step 51080, training loss = 1.601579, validation loss = 3.048946
2018-12-05 00:38:21,339 - INFO - epoch 0, step 51090, training loss = 2.137858, validation loss = 3.136394
2018-12-05 00:38:25,314 - INFO - epoch 0, step 51100, training loss = 1.862852, validation loss = 3.287842
2018-12-05 00:38:29,302 - INFO - epoch 0, step 51110, training loss = 2.018415, validation loss = 3.769058
2018-12-05 00:38:33,484 - INFO - epoch 0, step 51120, training loss = 1.746536, validation loss = 3.158148
2018-12-05 00:38:37,425 - INFO - epoch 0, step 51130, training loss = 1.543858, validation loss = 3.898417
2018-12-05 00:38:41,127 - INFO - epoch 0, step 51140, training loss = 1.620320, validation loss = 2.983856
2018-12-05 00:38:44,921 - INFO - epoch 0, step 51150, training loss = 1.431731, validation loss = 3.625421
2018-12-05 00:38:48,720 - INFO - epoch 0, step 51160, training loss = 1.448625, validation loss = 3.890892
2018-12-05 00:38:52,545 - INFO - epoch 0, step 51170, training loss = 1.975373, validation loss = 3.431436
2018-12-05 00:38:56,273 - INFO - epoch 0, step 51180, training loss = 2.153741, validation loss = 3.102609
2018-12-05 00:38:59,859 - INFO - epoch 0, step 51190, training loss = 1.879418, validation loss = 3.621297
2018-12-05 00:39:03,548 - INFO - epoch 0, step 51200, training loss = 1.930101, validation loss = 3.266473
2018-12-05 00:39:07,144 - INFO - epoch 0, step 51210, training loss = 1.986773, validation loss = 3.829332
2018-12-05 00:39:10,531 - INFO - epoch 0, step 51220, training loss = 1.782839, validation loss = 4.093485
2018-12-05 00:39:14,198 - INFO - epoch 0, step 51230, training loss = 1.981026, validation loss = 3.291831
2018-12-05 00:39:17,703 - INFO - epoch 0, step 51240, training loss = 1.901017, validation loss = 3.668901
2018-12-05 00:39:21,276 - INFO - epoch 0, step 51250, training loss = 1.814130, validation loss = 3.587483
2018-12-05 00:39:24,710 - INFO - epoch 0, step 51260, training loss = 1.671867, validation loss = 3.737907
2018-12-05 00:39:27,991 - INFO - epoch 0, step 51270, training loss = 2.180894, validation loss = 3.661385
2018-12-05 00:39:31,355 - INFO - epoch 0, step 51280, training loss = 2.246434, validation loss = 3.162340
2018-12-05 00:39:34,657 - INFO - epoch 0, step 51290, training loss = 1.950625, validation loss = 3.426039
2018-12-05 00:39:38,159 - INFO - epoch 0, step 51300, training loss = 2.196071, validation loss = 3.081463
2018-12-05 00:39:41,344 - INFO - epoch 0, step 51310, training loss = 2.107688, validation loss = 4.028115
2018-12-05 00:39:44,542 - INFO - epoch 0, step 51320, training loss = 2.021422, validation loss = 3.377921
2018-12-05 00:39:47,658 - INFO - epoch 0, step 51330, training loss = 1.986346, validation loss = 3.539036
2018-12-05 00:39:50,854 - INFO - epoch 0, step 51340, training loss = 2.174741, validation loss = 3.660380
2018-12-05 00:39:53,862 - INFO - epoch 0, step 51350, training loss = 2.371582, validation loss = 3.668654
2018-12-05 00:39:57,023 - INFO - epoch 0, step 51360, training loss = 1.861156, validation loss = 3.461081
2018-12-05 00:40:00,319 - INFO - epoch 0, step 51370, training loss = 2.230593, validation loss = 3.393296
2018-12-05 00:40:03,494 - INFO - epoch 0, step 51380, training loss = 2.021825, validation loss = 3.594623
2018-12-05 00:40:06,627 - INFO - epoch 0, step 51390, training loss = 2.049258, validation loss = 3.387574
2018-12-05 00:40:09,710 - INFO - epoch 0, step 51400, training loss = 2.250871, validation loss = 4.024223
2018-12-05 00:40:12,893 - INFO - epoch 0, step 51410, training loss = 2.459391, validation loss = 3.764550
2018-12-05 00:40:16,141 - INFO - epoch 0, step 51420, training loss = 2.234682, validation loss = 3.247008
2018-12-05 00:40:20,302 - INFO - epoch 0, step 51430, training loss = 1.604849, validation loss = 3.705150
2018-12-05 00:40:24,070 - INFO - epoch 0, step 51440, training loss = 1.734887, validation loss = 3.483206
2018-12-05 00:40:28,168 - INFO - epoch 0, step 51450, training loss = 1.760794, validation loss = 3.430279
2018-12-05 00:40:32,470 - INFO - epoch 0, step 51460, training loss = 1.878399, validation loss = 3.620417
2018-12-05 00:40:36,369 - INFO - epoch 0, step 51470, training loss = 1.983286, validation loss = 3.512036
2018-12-05 00:40:40,681 - INFO - epoch 0, step 51480, training loss = 1.831011, validation loss = 3.113010
2018-12-05 00:40:44,579 - INFO - epoch 0, step 51490, training loss = 1.758493, validation loss = 3.530653
2018-12-05 00:40:48,541 - INFO - epoch 0, step 51500, training loss = 1.690206, validation loss = 3.324980
2018-12-05 00:40:52,467 - INFO - epoch 0, step 51510, training loss = 1.930791, validation loss = 3.719714
2018-12-05 00:40:56,453 - INFO - epoch 0, step 51520, training loss = 1.961275, validation loss = 3.114077
2018-12-05 00:41:00,314 - INFO - epoch 0, step 51530, training loss = 1.386487, validation loss = 3.841348
2018-12-05 00:41:04,392 - INFO - epoch 0, step 51540, training loss = 1.826162, validation loss = 3.054487
2018-12-05 00:41:08,464 - INFO - epoch 0, step 51550, training loss = 1.903539, validation loss = 3.546057
2018-12-05 00:41:12,085 - INFO - epoch 0, step 51560, training loss = 1.981198, validation loss = 3.608429
2018-12-05 00:41:15,666 - INFO - epoch 0, step 51570, training loss = 2.135286, validation loss = 3.226275
2018-12-05 00:41:19,619 - INFO - epoch 0, step 51580, training loss = 2.096997, validation loss = 3.563014
2018-12-05 00:41:23,523 - INFO - epoch 0, step 51590, training loss = 1.988263, validation loss = 3.058028
2018-12-05 00:41:27,726 - INFO - epoch 0, step 51600, training loss = 1.929751, validation loss = 3.513557
2018-12-05 00:41:31,602 - INFO - epoch 0, step 51610, training loss = 1.830875, validation loss = 3.554067
2018-12-05 00:41:35,592 - INFO - epoch 0, step 51620, training loss = 2.148398, validation loss = 3.741438
2018-12-05 00:41:39,583 - INFO - epoch 0, step 51630, training loss = 2.214144, validation loss = 3.528264
2018-12-05 00:41:43,295 - INFO - epoch 0, step 51640, training loss = 1.725783, validation loss = 3.680398
2018-12-05 00:41:47,093 - INFO - epoch 0, step 51650, training loss = 1.844315, validation loss = 3.580061
2018-12-05 00:41:50,789 - INFO - epoch 0, step 51660, training loss = 2.023782, validation loss = 3.764724
2018-12-05 00:41:54,543 - INFO - epoch 0, step 51670, training loss = 1.668682, validation loss = 3.359628
2018-12-05 00:41:58,318 - INFO - epoch 0, step 51680, training loss = 1.964714, validation loss = 3.457361
2018-12-05 00:42:02,024 - INFO - epoch 0, step 51690, training loss = 1.505476, validation loss = 3.045414
2018-12-05 00:42:05,710 - INFO - epoch 0, step 51700, training loss = 1.933410, validation loss = 4.033747
2018-12-05 00:42:09,673 - INFO - epoch 0, step 51710, training loss = 1.712743, validation loss = 3.303446
2018-12-05 00:42:13,748 - INFO - epoch 0, step 51720, training loss = 1.595171, validation loss = 3.235388
2018-12-05 00:42:17,969 - INFO - epoch 0, step 51730, training loss = 1.537941, validation loss = 3.383034
2018-12-05 00:42:22,163 - INFO - epoch 0, step 51740, training loss = 2.044063, validation loss = 3.397789
2018-12-05 00:42:26,395 - INFO - epoch 0, step 51750, training loss = 1.846433, validation loss = 2.990441
2018-12-05 00:42:30,597 - INFO - epoch 0, step 51760, training loss = 1.558875, validation loss = 2.794396
2018-12-05 00:42:34,681 - INFO - epoch 0, step 51770, training loss = 1.987122, validation loss = 3.232006
2018-12-05 00:42:39,043 - INFO - epoch 0, step 51780, training loss = 1.756588, validation loss = 3.428999
2018-12-05 00:42:43,650 - INFO - epoch 0, step 51790, training loss = 2.163960, validation loss = 3.390285
2018-12-05 00:42:48,244 - INFO - epoch 0, step 51800, training loss = 2.051956, validation loss = 3.052204
2018-12-05 00:42:52,624 - INFO - epoch 0, step 51810, training loss = 2.100049, validation loss = 2.803537
2018-12-05 00:42:57,048 - INFO - epoch 0, step 51820, training loss = 1.756757, validation loss = 3.225519
2018-12-05 00:43:01,327 - INFO - epoch 0, step 51830, training loss = 1.990665, validation loss = 3.361659
2018-12-05 00:43:05,792 - INFO - epoch 0, step 51840, training loss = 1.679471, validation loss = 2.505226
2018-12-05 00:43:09,758 - INFO - epoch 0, step 51850, training loss = 2.244693, validation loss = 3.582082
2018-12-05 00:43:12,913 - INFO - epoch 0, step 51860, training loss = 1.882827, validation loss = 3.046061
2018-12-05 00:43:16,140 - INFO - epoch 0, step 51870, training loss = 2.197604, validation loss = 2.930035
2018-12-05 00:43:19,357 - INFO - epoch 0, step 51880, training loss = 2.388060, validation loss = 3.551910
2018-12-05 00:43:22,682 - INFO - epoch 0, step 51890, training loss = 1.685635, validation loss = 2.166416
2018-12-05 00:43:25,900 - INFO - epoch 0, step 51900, training loss = 1.932201, validation loss = 3.000127
2018-12-05 00:43:29,134 - INFO - epoch 0, step 51910, training loss = 1.877837, validation loss = 2.967393
2018-12-05 00:43:32,291 - INFO - epoch 0, step 51920, training loss = 1.940434, validation loss = 3.156753
2018-12-05 00:43:35,327 - INFO - epoch 0, step 51930, training loss = 2.450695, validation loss = 3.014805
2018-12-05 00:43:38,717 - INFO - epoch 0, step 51940, training loss = 2.101281, validation loss = 3.180943
2018-12-05 00:43:42,135 - INFO - epoch 0, step 51950, training loss = 2.006988, validation loss = 2.761494
2018-12-05 00:43:45,672 - INFO - epoch 0, step 51960, training loss = 2.222973, validation loss = 2.809345
2018-12-05 00:43:48,917 - INFO - epoch 0, step 51970, training loss = 2.055023, validation loss = 2.443779
2018-12-05 00:43:52,441 - INFO - epoch 0, step 51980, training loss = 1.938425, validation loss = 2.427536
2018-12-05 00:43:55,648 - INFO - epoch 0, step 51990, training loss = 2.044979, validation loss = 3.066082
2018-12-05 00:43:59,938 - INFO - epoch 0, step 52000, training loss = 2.138445, validation loss = 3.033754
2018-12-05 00:44:04,172 - INFO - epoch 0, step 52010, training loss = 1.733916, validation loss = 2.295509
2018-12-05 00:44:08,185 - INFO - epoch 0, step 52020, training loss = 1.689969, validation loss = 3.242472
2018-12-05 00:44:12,483 - INFO - epoch 0, step 52030, training loss = 1.807917, validation loss = 3.164632
2018-12-05 00:44:16,508 - INFO - epoch 0, step 52040, training loss = 2.210527, validation loss = 2.640803
2018-12-05 00:44:20,719 - INFO - epoch 0, step 52050, training loss = 2.084474, validation loss = 3.397296
2018-12-05 00:44:25,003 - INFO - epoch 0, step 52060, training loss = 1.605332, validation loss = 3.401181
2018-12-05 00:44:29,128 - INFO - epoch 0, step 52070, training loss = 2.085316, validation loss = 3.273220
2018-12-05 00:44:33,328 - INFO - epoch 0, step 52080, training loss = 1.565548, validation loss = 2.857653
2018-12-05 00:44:37,489 - INFO - epoch 0, step 52090, training loss = 1.773816, validation loss = 2.808042
2018-12-05 00:44:41,619 - INFO - epoch 0, step 52100, training loss = 1.752390, validation loss = 3.464915
2018-12-05 00:44:45,948 - INFO - epoch 0, step 52110, training loss = 1.724019, validation loss = 2.590148
2018-12-05 00:44:50,073 - INFO - epoch 0, step 52120, training loss = 1.703957, validation loss = 3.187162
2018-12-05 00:44:54,332 - INFO - epoch 0, step 52130, training loss = 1.735168, validation loss = 2.514799
2018-12-05 00:44:58,591 - INFO - epoch 0, step 52140, training loss = 1.736527, validation loss = 3.061048
2018-12-05 00:45:02,055 - INFO - epoch 0, step 52150, training loss = 1.756300, validation loss = 2.732373
2018-12-05 00:45:05,287 - INFO - epoch 0, step 52160, training loss = 2.277320, validation loss = 2.502300
2018-12-05 00:45:08,524 - INFO - epoch 0, step 52170, training loss = 2.011103, validation loss = 2.648151
2018-12-05 00:45:11,710 - INFO - epoch 0, step 52180, training loss = 2.136888, validation loss = 2.863044
2018-12-05 00:45:14,963 - INFO - epoch 0, step 52190, training loss = 1.677525, validation loss = 3.404007
2018-12-05 00:45:18,558 - INFO - epoch 0, step 52200, training loss = 2.026072, validation loss = 3.195330
2018-12-05 00:45:21,831 - INFO - epoch 0, step 52210, training loss = 2.138049, validation loss = 3.178317
2018-12-05 00:45:25,184 - INFO - epoch 0, step 52220, training loss = 1.889232, validation loss = 3.649237
2018-12-05 00:45:28,511 - INFO - epoch 0, step 52230, training loss = 2.071801, validation loss = 3.422312
2018-12-05 00:45:31,676 - INFO - epoch 0, step 52240, training loss = 2.152213, validation loss = 3.599341
2018-12-05 00:45:34,818 - INFO - epoch 0, step 52250, training loss = 2.289313, validation loss = 3.886890
2018-12-05 00:45:37,886 - INFO - epoch 0, step 52260, training loss = 1.826352, validation loss = 3.337477
2018-12-05 00:45:41,278 - INFO - epoch 0, step 52270, training loss = 1.894370, validation loss = 3.935671
2018-12-05 00:45:44,587 - INFO - epoch 0, step 52280, training loss = 1.429274, validation loss = 3.783513
2018-12-05 00:45:48,025 - INFO - epoch 0, step 52290, training loss = 1.973133, validation loss = 3.354909
2018-12-05 00:45:51,270 - INFO - epoch 0, step 52300, training loss = 1.914822, validation loss = 3.455661
2018-12-05 00:45:55,698 - INFO - epoch 0, step 52310, training loss = 2.069607, validation loss = 3.299091
2018-12-05 00:45:59,851 - INFO - epoch 0, step 52320, training loss = 2.176472, validation loss = 4.052448
2018-12-05 00:46:04,187 - INFO - epoch 0, step 52330, training loss = 2.071837, validation loss = 3.294034
2018-12-05 00:46:08,638 - INFO - epoch 0, step 52340, training loss = 1.595588, validation loss = 4.132658
2018-12-05 00:46:13,032 - INFO - epoch 0, step 52350, training loss = 1.632008, validation loss = 3.325034
2018-12-05 00:46:17,687 - INFO - epoch 0, step 52360, training loss = 1.837831, validation loss = 3.743602
2018-12-05 00:46:22,148 - INFO - epoch 0, step 52370, training loss = 1.685668, validation loss = 4.282781
2018-12-05 00:46:25,801 - INFO - epoch 0, step 52380, training loss = 2.045484, validation loss = 3.295401
2018-12-05 00:46:28,896 - INFO - epoch 0, step 52390, training loss = 2.042395, validation loss = 3.502743
2018-12-05 00:46:31,979 - INFO - epoch 0, step 52400, training loss = 2.098634, validation loss = 3.869021
2018-12-05 00:46:35,349 - INFO - epoch 0, step 52410, training loss = 1.988573, validation loss = 3.140558
2018-12-05 00:46:38,540 - INFO - epoch 0, step 52420, training loss = 2.197569, validation loss = 3.058226
2018-12-05 00:46:41,643 - INFO - epoch 0, step 52430, training loss = 2.084336, validation loss = 3.306341
2018-12-05 00:46:44,795 - INFO - epoch 0, step 52440, training loss = 1.840377, validation loss = 3.715708
2018-12-05 00:46:47,914 - INFO - epoch 0, step 52450, training loss = 2.134928, validation loss = 3.433941
2018-12-05 00:46:51,134 - INFO - epoch 0, step 52460, training loss = 1.887712, validation loss = 3.204810
2018-12-05 00:46:54,452 - INFO - epoch 0, step 52470, training loss = 2.028658, validation loss = 3.896393
2018-12-05 00:46:57,651 - INFO - epoch 0, step 52480, training loss = 1.854917, validation loss = 3.041139
2018-12-05 00:47:01,027 - INFO - epoch 0, step 52490, training loss = 1.970038, validation loss = 3.335692
2018-12-05 00:47:04,150 - INFO - epoch 0, step 52500, training loss = 1.660004, validation loss = 3.940492
2018-12-05 00:47:07,417 - INFO - epoch 0, step 52510, training loss = 1.923085, validation loss = 3.640022
2018-12-05 00:47:10,927 - INFO - epoch 0, step 52520, training loss = 2.053352, validation loss = 3.246021
2018-12-05 00:47:14,896 - INFO - epoch 0, step 52530, training loss = 1.605873, validation loss = 3.046293
2018-12-05 00:47:18,808 - INFO - epoch 0, step 52540, training loss = 2.182961, validation loss = 3.609976
2018-12-05 00:47:22,956 - INFO - epoch 0, step 52550, training loss = 1.988946, validation loss = 3.411788
2018-12-05 00:47:26,937 - INFO - epoch 0, step 52560, training loss = 2.100168, validation loss = 3.452412
2018-12-05 00:47:31,022 - INFO - epoch 0, step 52570, training loss = 2.033233, validation loss = 3.472975
2018-12-05 00:47:35,167 - INFO - epoch 0, step 52580, training loss = 1.947949, validation loss = 3.826099
2018-12-05 00:47:39,008 - INFO - epoch 0, step 52590, training loss = 1.840207, validation loss = 3.749976
2018-12-05 00:47:42,727 - INFO - epoch 0, step 52600, training loss = 2.135661, validation loss = 3.441171
2018-12-05 00:47:46,152 - INFO - epoch 0, step 52610, training loss = 2.089849, validation loss = 3.234394
2018-12-05 00:47:49,458 - INFO - epoch 0, step 52620, training loss = 1.664273, validation loss = 3.729112
2018-12-05 00:47:53,012 - INFO - epoch 0, step 52630, training loss = 1.531463, validation loss = 3.477136
2018-12-05 00:47:56,515 - INFO - epoch 0, step 52640, training loss = 1.797169, validation loss = 3.092025
2018-12-05 00:47:59,755 - INFO - epoch 0, step 52650, training loss = 1.924264, validation loss = 3.239345
2018-12-05 00:48:02,992 - INFO - epoch 0, step 52660, training loss = 2.038890, validation loss = 3.126191
2018-12-05 00:48:06,980 - INFO - epoch 0, step 52670, training loss = 2.016611, validation loss = 3.843019
2018-12-05 00:48:11,244 - INFO - epoch 0, step 52680, training loss = 1.966772, validation loss = 3.099890
2018-12-05 00:48:15,462 - INFO - epoch 0, step 52690, training loss = 1.915862, validation loss = 3.704521
2018-12-05 00:48:19,729 - INFO - epoch 0, step 52700, training loss = 1.797071, validation loss = 3.681076
2018-12-05 00:48:23,781 - INFO - epoch 0, step 52710, training loss = 1.942015, validation loss = 3.609606
2018-12-05 00:48:28,136 - INFO - epoch 0, step 52720, training loss = 1.245611, validation loss = 2.767380
2018-12-05 00:48:32,139 - INFO - epoch 0, step 52730, training loss = 1.916783, validation loss = 3.658346
2018-12-05 00:48:36,439 - INFO - epoch 0, step 52740, training loss = 2.005015, validation loss = 3.615333
2018-12-05 00:48:40,649 - INFO - epoch 0, step 52750, training loss = 1.904889, validation loss = 3.004254
2018-12-05 00:48:44,980 - INFO - epoch 0, step 52760, training loss = 1.619689, validation loss = 3.643699
2018-12-05 00:48:49,174 - INFO - epoch 0, step 52770, training loss = 1.912275, validation loss = 3.198386
2018-12-05 00:48:53,559 - INFO - epoch 0, step 52780, training loss = 1.985457, validation loss = 3.351441
2018-12-05 00:48:57,798 - INFO - epoch 0, step 52790, training loss = 1.792800, validation loss = 2.138550
2018-12-05 00:49:02,037 - INFO - epoch 0, step 52800, training loss = 1.908607, validation loss = 2.028204
2018-12-05 00:49:06,357 - INFO - epoch 0, step 52810, training loss = 1.813319, validation loss = 2.196073
2018-12-05 00:49:10,823 - INFO - epoch 0, step 52820, training loss = 2.019453, validation loss = 2.087147
2018-12-05 00:49:15,419 - INFO - epoch 0, step 52830, training loss = 1.630772, validation loss = 2.284996
2018-12-05 00:49:19,619 - INFO - epoch 0, step 52840, training loss = 2.229949, validation loss = 2.351351
2018-12-05 00:49:23,915 - INFO - epoch 0, step 52850, training loss = 1.941152, validation loss = 2.023964
2018-12-05 00:49:28,204 - INFO - epoch 0, step 52860, training loss = 2.000407, validation loss = 2.249953
2018-12-05 00:49:32,212 - INFO - epoch 0, step 52870, training loss = 1.979422, validation loss = 1.576696
2018-12-05 00:49:35,652 - INFO - epoch 0, step 52880, training loss = 1.859375, validation loss = 1.613862
2018-12-05 00:49:38,837 - INFO - epoch 0, step 52890, training loss = 1.966715, validation loss = 2.107076
2018-12-05 00:49:41,993 - INFO - epoch 0, step 52900, training loss = 1.892717, validation loss = 1.821321
2018-12-05 00:49:45,060 - INFO - epoch 0, step 52910, training loss = 2.158236, validation loss = 2.544393
2018-12-05 00:49:48,242 - INFO - epoch 0, step 52920, training loss = 2.050691, validation loss = 1.749894
2018-12-05 00:49:51,351 - INFO - epoch 0, step 52930, training loss = 1.620092, validation loss = 2.145079
2018-12-05 00:49:54,436 - INFO - epoch 0, step 52940, training loss = 1.876202, validation loss = 2.088208
2018-12-05 00:49:57,705 - INFO - epoch 0, step 52950, training loss = 1.853217, validation loss = 1.911277
2018-12-05 00:50:00,831 - INFO - epoch 0, step 52960, training loss = 2.100929, validation loss = 2.159348
2018-12-05 00:50:03,970 - INFO - epoch 0, step 52970, training loss = 1.943661, validation loss = 1.951864
2018-12-05 00:50:07,154 - INFO - epoch 0, step 52980, training loss = 2.060133, validation loss = 1.490032
2018-12-05 00:50:10,463 - INFO - epoch 0, step 52990, training loss = 1.409728, validation loss = 2.088938
2018-12-05 00:50:13,778 - INFO - epoch 0, step 53000, training loss = 1.755113, validation loss = 1.657112
2018-12-05 00:50:16,891 - INFO - epoch 0, step 53010, training loss = 2.367645, validation loss = 2.296455
2018-12-05 00:50:20,488 - INFO - epoch 0, step 53020, training loss = 1.956812, validation loss = 2.049959
2018-12-05 00:50:23,782 - INFO - epoch 0, step 53030, training loss = 2.080187, validation loss = 2.228039
2018-12-05 00:50:27,231 - INFO - epoch 0, step 53040, training loss = 1.710772, validation loss = 2.361175
2018-12-05 00:50:30,824 - INFO - epoch 0, step 53050, training loss = 1.776417, validation loss = 2.433050
2018-12-05 00:50:34,384 - INFO - epoch 0, step 53060, training loss = 1.683748, validation loss = 1.972934
2018-12-05 00:50:37,960 - INFO - epoch 0, step 53070, training loss = 2.203673, validation loss = 2.421678
2018-12-05 00:50:41,627 - INFO - epoch 0, step 53080, training loss = 1.865470, validation loss = 2.212413
2018-12-05 00:50:45,234 - INFO - epoch 0, step 53090, training loss = 1.691992, validation loss = 2.206761
2018-12-05 00:50:48,938 - INFO - epoch 0, step 53100, training loss = 1.584241, validation loss = 2.141680
2018-12-05 00:50:52,648 - INFO - epoch 0, step 53110, training loss = 1.832546, validation loss = 1.932176
2018-12-05 00:50:56,293 - INFO - epoch 0, step 53120, training loss = 1.942523, validation loss = 2.320688
2018-12-05 00:51:00,255 - INFO - epoch 0, step 53130, training loss = 1.824726, validation loss = 2.357765
2018-12-05 00:51:04,056 - INFO - epoch 0, step 53140, training loss = 1.876700, validation loss = 2.106247
2018-12-05 00:51:07,748 - INFO - epoch 0, step 53150, training loss = 1.983547, validation loss = 2.390512
2018-12-05 00:51:11,336 - INFO - epoch 0, step 53160, training loss = 2.130255, validation loss = 2.034718
2018-12-05 00:51:14,382 - INFO - epoch 0, step 53170, training loss = 1.962059, validation loss = 1.953123
2018-12-05 00:51:17,627 - INFO - epoch 0, step 53180, training loss = 1.741694, validation loss = 2.194734
2018-12-05 00:51:20,780 - INFO - epoch 0, step 53190, training loss = 1.838173, validation loss = 2.015765
2018-12-05 00:51:23,971 - INFO - epoch 0, step 53200, training loss = 1.909780, validation loss = 2.317395
2018-12-05 00:51:27,192 - INFO - epoch 0, step 53210, training loss = 1.871474, validation loss = 2.252413
2018-12-05 00:51:30,220 - INFO - epoch 0, step 53220, training loss = 2.187613, validation loss = 2.250670
2018-12-05 00:51:33,383 - INFO - epoch 0, step 53230, training loss = 2.064267, validation loss = 2.232069
2018-12-05 00:51:37,012 - INFO - epoch 0, step 53240, training loss = 1.804083, validation loss = 2.072737
2018-12-05 00:51:40,681 - INFO - epoch 0, step 53250, training loss = 2.079685, validation loss = 2.205801
2018-12-05 00:51:44,610 - INFO - epoch 0, step 53260, training loss = 1.886666, validation loss = 2.168312
2018-12-05 00:51:48,528 - INFO - epoch 0, step 53270, training loss = 1.852871, validation loss = 2.349808
2018-12-05 00:51:52,158 - INFO - epoch 0, step 53280, training loss = 1.689261, validation loss = 2.209492
2018-12-05 00:51:55,822 - INFO - epoch 0, step 53290, training loss = 1.775337, validation loss = 1.977541
2018-12-05 00:51:59,962 - INFO - epoch 0, step 53300, training loss = 1.564411, validation loss = 2.199597
2018-12-05 00:52:03,669 - INFO - epoch 0, step 53310, training loss = 2.174974, validation loss = 2.139974
2018-12-05 00:52:07,630 - INFO - epoch 0, step 53320, training loss = 1.802849, validation loss = 1.831630
2018-12-05 00:52:11,884 - INFO - epoch 0, step 53330, training loss = 2.122716, validation loss = 2.102835
2018-12-05 00:52:16,116 - INFO - epoch 0, step 53340, training loss = 1.980069, validation loss = 2.101065
2018-12-05 00:52:20,546 - INFO - epoch 0, step 53350, training loss = 1.697260, validation loss = 2.244605
2018-12-05 00:52:24,744 - INFO - epoch 0, step 53360, training loss = 2.216996, validation loss = 2.053060
2018-12-05 00:52:29,035 - INFO - epoch 0, step 53370, training loss = 1.802168, validation loss = 1.863033
2018-12-05 00:52:33,152 - INFO - epoch 0, step 53380, training loss = 1.754049, validation loss = 2.002774
2018-12-05 00:52:37,498 - INFO - epoch 0, step 53390, training loss = 2.068875, validation loss = 1.638805
2018-12-05 00:52:42,139 - INFO - epoch 0, step 53400, training loss = 1.657328, validation loss = 1.393955
2018-12-05 00:52:46,593 - INFO - epoch 0, step 53410, training loss = 1.699435, validation loss = 2.184544
2018-12-05 00:52:51,014 - INFO - epoch 0, step 53420, training loss = 1.337726, validation loss = 2.190440
2018-12-05 00:52:55,337 - INFO - epoch 0, step 53430, training loss = 2.050085, validation loss = 2.214306
2018-12-05 00:52:59,847 - INFO - epoch 0, step 53440, training loss = 1.330642, validation loss = 1.909785
2018-12-05 00:53:04,249 - INFO - epoch 0, step 53450, training loss = 2.169842, validation loss = 2.075211
2018-12-05 00:53:08,768 - INFO - epoch 0, step 53460, training loss = 1.627023, validation loss = 2.130356
2018-12-05 00:53:13,021 - INFO - epoch 0, step 53470, training loss = 1.581142, validation loss = 1.919554
2018-12-05 00:53:16,833 - INFO - epoch 0, step 53480, training loss = 1.817209, validation loss = 1.766597
2018-12-05 00:53:20,545 - INFO - epoch 0, step 53490, training loss = 1.687304, validation loss = 2.338966
2018-12-05 00:53:24,056 - INFO - epoch 0, step 53500, training loss = 1.834671, validation loss = 1.984904
2018-12-05 00:53:27,515 - INFO - epoch 0, step 53510, training loss = 1.773450, validation loss = 1.696440
2018-12-05 00:53:30,950 - INFO - epoch 0, step 53520, training loss = 1.740368, validation loss = 2.159731
2018-12-05 00:53:34,598 - INFO - epoch 0, step 53530, training loss = 1.751209, validation loss = 1.842385
2018-12-05 00:53:38,092 - INFO - epoch 0, step 53540, training loss = 1.943533, validation loss = 1.621377
2018-12-05 00:53:41,562 - INFO - epoch 0, step 53550, training loss = 2.152246, validation loss = 1.908322
2018-12-05 00:53:44,744 - INFO - epoch 0, step 53560, training loss = 1.718798, validation loss = 1.980510
2018-12-05 00:53:48,068 - INFO - epoch 0, step 53570, training loss = 2.033874, validation loss = 1.901682
2018-12-05 00:53:51,376 - INFO - epoch 0, step 53580, training loss = 1.830409, validation loss = 2.157534
2018-12-05 00:53:54,779 - INFO - epoch 0, step 53590, training loss = 2.197730, validation loss = 1.999102
2018-12-05 00:53:58,018 - INFO - epoch 0, step 53600, training loss = 1.926070, validation loss = 1.459497
2018-12-05 00:54:01,328 - INFO - epoch 0, step 53610, training loss = 1.666847, validation loss = 1.905762
2018-12-05 00:54:04,694 - INFO - epoch 0, step 53620, training loss = 1.899846, validation loss = 1.706606
2018-12-05 00:54:08,986 - INFO - epoch 0, step 53630, training loss = 1.751121, validation loss = 1.983337
2018-12-05 00:54:13,062 - INFO - epoch 0, step 53640, training loss = 1.497290, validation loss = 1.904864
2018-12-05 00:54:16,981 - INFO - epoch 0, step 53650, training loss = 2.051160, validation loss = 1.758407
2018-12-05 00:54:20,793 - INFO - epoch 0, step 53660, training loss = 1.759103, validation loss = 1.820491
2018-12-05 00:54:24,627 - INFO - epoch 0, step 53670, training loss = 1.723664, validation loss = 1.776332
2018-12-05 00:54:28,354 - INFO - epoch 0, step 53680, training loss = 2.137568, validation loss = 2.205183
2018-12-05 00:54:32,165 - INFO - epoch 0, step 53690, training loss = 1.534287, validation loss = 1.966038
2018-12-05 00:54:36,356 - INFO - epoch 0, step 53700, training loss = 1.715839, validation loss = 1.730792
2018-12-05 00:54:40,511 - INFO - epoch 0, step 53710, training loss = 1.396961, validation loss = 1.890516
2018-12-05 00:54:44,457 - INFO - epoch 0, step 53720, training loss = 1.631420, validation loss = 2.246447
2018-12-05 00:54:48,793 - INFO - epoch 0, step 53730, training loss = 1.603887, validation loss = 1.690236
2018-12-05 00:54:52,772 - INFO - epoch 0, step 53740, training loss = 1.952336, validation loss = 1.655804
2018-12-05 00:54:56,996 - INFO - epoch 0, step 53750, training loss = 1.608089, validation loss = 2.060764
2018-12-05 00:55:01,249 - INFO - epoch 0, step 53760, training loss = 1.947585, validation loss = 2.048284
2018-12-05 00:55:05,701 - INFO - epoch 0, step 53770, training loss = 1.996464, validation loss = 1.943617
2018-12-05 00:55:09,667 - INFO - epoch 0, step 53780, training loss = 1.998215, validation loss = 1.900896
2018-12-05 00:55:12,936 - INFO - epoch 0, step 53790, training loss = 2.040747, validation loss = 1.832328
2018-12-05 00:55:16,180 - INFO - epoch 0, step 53800, training loss = 2.160413, validation loss = 1.628489
2018-12-05 00:55:19,632 - INFO - epoch 0, step 53810, training loss = 1.897064, validation loss = 2.212639
2018-12-05 00:55:23,125 - INFO - epoch 0, step 53820, training loss = 1.763639, validation loss = 1.819338
2018-12-05 00:55:26,324 - INFO - epoch 0, step 53830, training loss = 1.989260, validation loss = 1.994498
2018-12-05 00:55:29,566 - INFO - epoch 0, step 53840, training loss = 2.017917, validation loss = 1.889923
2018-12-05 00:55:32,959 - INFO - epoch 0, step 53850, training loss = 2.303422, validation loss = 1.842415
2018-12-05 00:55:36,097 - INFO - epoch 0, step 53860, training loss = 1.857648, validation loss = 2.224194
2018-12-05 00:55:39,271 - INFO - epoch 0, step 53870, training loss = 1.936894, validation loss = 1.941921
2018-12-05 00:55:42,424 - INFO - epoch 0, step 53880, training loss = 1.905930, validation loss = 2.026446
2018-12-05 00:55:45,610 - INFO - epoch 0, step 53890, training loss = 1.684447, validation loss = 2.095571
2018-12-05 00:55:48,734 - INFO - epoch 0, step 53900, training loss = 2.225047, validation loss = 1.839832
2018-12-05 00:55:51,953 - INFO - epoch 0, step 53910, training loss = 1.856309, validation loss = 1.768683
2018-12-05 00:55:55,134 - INFO - epoch 0, step 53920, training loss = 1.847198, validation loss = 2.248660
2018-12-05 00:55:58,385 - INFO - epoch 0, step 53930, training loss = 1.929474, validation loss = 1.749798
2018-12-05 00:56:01,604 - INFO - epoch 0, step 53940, training loss = 2.394387, validation loss = 2.163273
2018-12-05 00:56:05,186 - INFO - epoch 0, step 53950, training loss = 1.471715, validation loss = 2.158192
2018-12-05 00:56:08,642 - INFO - epoch 0, step 53960, training loss = 1.891261, validation loss = 2.014329
2018-12-05 00:56:11,802 - INFO - epoch 0, step 53970, training loss = 1.797035, validation loss = 1.765254
2018-12-05 00:56:15,181 - INFO - epoch 0, step 53980, training loss = 1.909359, validation loss = 1.722723
2018-12-05 00:56:18,542 - INFO - epoch 0, step 53990, training loss = 1.767566, validation loss = 2.210057
2018-12-05 00:56:23,201 - INFO - epoch 0, step 54000, training loss = 1.826421, validation loss = 1.516665
2018-12-05 00:56:27,757 - INFO - epoch 0, step 54010, training loss = 1.959276, validation loss = 1.933512
2018-12-05 00:56:32,434 - INFO - epoch 0, step 54020, training loss = 1.941416, validation loss = 2.135076
2018-12-05 00:56:37,038 - INFO - epoch 0, step 54030, training loss = 1.185196, validation loss = 1.647426
2018-12-05 00:56:41,388 - INFO - epoch 0, step 54040, training loss = 1.946979, validation loss = 1.807095
2018-12-05 00:56:45,891 - INFO - epoch 0, step 54050, training loss = 1.962546, validation loss = 1.971742
2018-12-05 00:56:50,470 - INFO - epoch 0, step 54060, training loss = 1.938458, validation loss = 1.720299
2018-12-05 00:56:54,658 - INFO - epoch 0, step 54070, training loss = 1.945160, validation loss = 1.863980
2018-12-05 00:56:58,144 - INFO - epoch 0, step 54080, training loss = 2.255325, validation loss = 1.708981
2018-12-05 00:57:01,279 - INFO - epoch 0, step 54090, training loss = 1.797217, validation loss = 1.917167
2018-12-05 00:57:04,315 - INFO - epoch 0, step 54100, training loss = 1.856062, validation loss = 1.939721
2018-12-05 00:57:07,420 - INFO - epoch 0, step 54110, training loss = 1.733654, validation loss = 2.110229
2018-12-05 00:57:10,569 - INFO - epoch 0, step 54120, training loss = 1.932600, validation loss = 2.001086
2018-12-05 00:57:13,782 - INFO - epoch 0, step 54130, training loss = 1.930576, validation loss = 2.222468
2018-12-05 00:57:16,900 - INFO - epoch 0, step 54140, training loss = 1.906643, validation loss = 1.637751
2018-12-05 00:57:19,989 - INFO - epoch 0, step 54150, training loss = 1.994961, validation loss = 2.137457
2018-12-05 00:57:23,154 - INFO - epoch 0, step 54160, training loss = 1.862621, validation loss = 1.830553
2018-12-05 00:57:26,488 - INFO - epoch 0, step 54170, training loss = 1.870307, validation loss = 1.480264
2018-12-05 00:57:29,753 - INFO - epoch 0, step 54180, training loss = 1.894817, validation loss = 2.088335
2018-12-05 00:57:33,137 - INFO - epoch 0, step 54190, training loss = 2.152477, validation loss = 1.956124
2018-12-05 00:57:36,326 - INFO - epoch 0, step 54200, training loss = 1.825736, validation loss = 2.452777
2018-12-05 00:57:39,888 - INFO - epoch 0, step 54210, training loss = 2.160537, validation loss = 2.090652
2018-12-05 00:57:43,363 - INFO - epoch 0, step 54220, training loss = 2.013584, validation loss = 1.917159
2018-12-05 00:57:46,744 - INFO - epoch 0, step 54230, training loss = 1.634104, validation loss = 1.766944
2018-12-05 00:57:50,750 - INFO - epoch 0, step 54240, training loss = 2.146457, validation loss = 1.850451
2018-12-05 00:57:54,827 - INFO - epoch 0, step 54250, training loss = 2.235196, validation loss = 1.784204
2018-12-05 00:57:58,945 - INFO - epoch 0, step 54260, training loss = 1.936679, validation loss = 1.810362
2018-12-05 00:58:02,989 - INFO - epoch 0, step 54270, training loss = 1.945313, validation loss = 1.574081
2018-12-05 00:58:06,881 - INFO - epoch 0, step 54280, training loss = 1.550618, validation loss = 1.674863
2018-12-05 00:58:11,083 - INFO - epoch 0, step 54290, training loss = 2.058471, validation loss = 2.030365
2018-12-05 00:58:15,218 - INFO - epoch 0, step 54300, training loss = 1.477144, validation loss = 1.812538
2018-12-05 00:58:18,614 - INFO - epoch 0, step 54310, training loss = 2.146867, validation loss = 2.141630
2018-12-05 00:58:21,958 - INFO - epoch 0, step 54320, training loss = 1.910497, validation loss = 1.746119
2018-12-05 00:58:25,394 - INFO - epoch 0, step 54330, training loss = 1.814484, validation loss = 2.033486
2018-12-05 00:58:28,841 - INFO - epoch 0, step 54340, training loss = 2.172528, validation loss = 1.807356
2018-12-05 00:58:32,193 - INFO - epoch 0, step 54350, training loss = 2.037124, validation loss = 2.345638
2018-12-05 00:58:35,714 - INFO - epoch 0, step 54360, training loss = 1.879415, validation loss = 1.917237
2018-12-05 00:58:39,179 - INFO - epoch 0, step 54370, training loss = 1.801855, validation loss = 2.213460
2018-12-05 00:58:42,225 - INFO - epoch 0, step 54380, training loss = 2.195777, validation loss = 2.181300
2018-12-05 00:58:45,330 - INFO - epoch 0, step 54390, training loss = 1.983289, validation loss = 1.847998
2018-12-05 00:58:48,744 - INFO - epoch 0, step 54400, training loss = 2.274621, validation loss = 2.382296
2018-12-05 00:58:51,790 - INFO - epoch 0, step 54410, training loss = 2.233064, validation loss = 2.140225
2018-12-05 00:58:55,114 - INFO - epoch 0, step 54420, training loss = 1.834784, validation loss = 2.068173
2018-12-05 00:58:58,696 - INFO - epoch 0, step 54430, training loss = 1.791560, validation loss = 1.935962
2018-12-05 00:59:01,846 - INFO - epoch 0, step 54440, training loss = 2.109998, validation loss = 1.794315
2018-12-05 00:59:05,797 - INFO - epoch 0, step 54450, training loss = 1.845027, validation loss = 2.014889
2018-12-05 00:59:10,151 - INFO - epoch 0, step 54460, training loss = 1.937987, validation loss = 1.980717
2018-12-05 00:59:14,258 - INFO - epoch 0, step 54470, training loss = 2.002993, validation loss = 1.962638
2018-12-05 00:59:18,916 - INFO - epoch 0, step 54480, training loss = 1.424382, validation loss = 2.250961
2018-12-05 00:59:23,284 - INFO - epoch 0, step 54490, training loss = 1.974659, validation loss = 1.888349
2018-12-05 00:59:27,601 - INFO - epoch 0, step 54500, training loss = 1.590424, validation loss = 2.195340
2018-12-05 00:59:31,750 - INFO - epoch 0, step 54510, training loss = 2.080252, validation loss = 1.956848
2018-12-05 00:59:35,760 - INFO - epoch 0, step 54520, training loss = 2.411937, validation loss = 2.082406
2018-12-05 00:59:39,562 - INFO - epoch 0, step 54530, training loss = 1.941668, validation loss = 2.038796
2018-12-05 00:59:43,031 - INFO - epoch 0, step 54540, training loss = 1.944518, validation loss = 1.724702
2018-12-05 00:59:46,504 - INFO - epoch 0, step 54550, training loss = 1.885399, validation loss = 1.812852
2018-12-05 00:59:50,026 - INFO - epoch 0, step 54560, training loss = 2.164801, validation loss = 1.532428
2018-12-05 00:59:53,546 - INFO - epoch 0, step 54570, training loss = 1.741259, validation loss = 2.011294
2018-12-05 00:59:57,167 - INFO - epoch 0, step 54580, training loss = 1.837230, validation loss = 2.130001
2018-12-05 01:00:00,698 - INFO - epoch 0, step 54590, training loss = 1.730295, validation loss = 1.711462
2018-12-05 01:00:04,567 - INFO - epoch 0, step 54600, training loss = 1.279583, validation loss = 2.188221
2018-12-05 01:00:08,416 - INFO - epoch 0, step 54610, training loss = 1.768311, validation loss = 2.223964
2018-12-05 01:00:12,168 - INFO - epoch 0, step 54620, training loss = 2.001458, validation loss = 1.771781
2018-12-05 01:00:16,017 - INFO - epoch 0, step 54630, training loss = 1.931226, validation loss = 2.270151
2018-12-05 01:00:19,843 - INFO - epoch 0, step 54640, training loss = 1.824409, validation loss = 2.163626
2018-12-05 01:00:24,184 - INFO - epoch 0, step 54650, training loss = 1.967655, validation loss = 2.156831
2018-12-05 01:00:28,134 - INFO - epoch 0, step 54660, training loss = 1.676238, validation loss = 2.037481
2018-12-05 01:00:32,042 - INFO - epoch 0, step 54670, training loss = 1.897326, validation loss = 2.008025
2018-12-05 01:00:35,949 - INFO - epoch 0, step 54680, training loss = 1.791383, validation loss = 1.857510
2018-12-05 01:00:40,081 - INFO - epoch 0, step 54690, training loss = 1.628186, validation loss = 1.781358
2018-12-05 01:00:44,527 - INFO - epoch 0, step 54700, training loss = 1.915079, validation loss = 1.731519
2018-12-05 01:00:48,593 - INFO - epoch 0, step 54710, training loss = 1.905663, validation loss = 1.346122
2018-12-05 01:00:52,744 - INFO - epoch 0, step 54720, training loss = 1.877136, validation loss = 1.836229
2018-12-05 01:00:57,056 - INFO - epoch 0, step 54730, training loss = 1.544768, validation loss = 1.781420
2018-12-05 01:01:01,058 - INFO - epoch 0, step 54740, training loss = 1.473914, validation loss = 1.925158
2018-12-05 01:01:04,334 - INFO - epoch 0, step 54750, training loss = 1.768240, validation loss = 1.770989
2018-12-05 01:01:07,501 - INFO - epoch 0, step 54760, training loss = 2.308087, validation loss = 2.159727
2018-12-05 01:01:10,809 - INFO - epoch 0, step 54770, training loss = 2.119262, validation loss = 1.964947
2018-12-05 01:01:14,191 - INFO - epoch 0, step 54780, training loss = 1.968498, validation loss = 2.107919
2018-12-05 01:01:17,445 - INFO - epoch 0, step 54790, training loss = 2.061861, validation loss = 2.390501
2018-12-05 01:01:20,705 - INFO - epoch 0, step 54800, training loss = 1.888958, validation loss = 2.019312
2018-12-05 01:01:24,118 - INFO - epoch 0, step 54810, training loss = 1.704218, validation loss = 1.877751
2018-12-05 01:01:27,166 - INFO - epoch 0, step 54820, training loss = 2.043728, validation loss = 1.917627
2018-12-05 01:01:31,476 - INFO - epoch 0, step 54830, training loss = 1.910601, validation loss = 2.396652
2018-12-05 01:01:35,886 - INFO - epoch 0, step 54840, training loss = 2.033061, validation loss = 1.733711
2018-12-05 01:01:40,533 - INFO - epoch 0, step 54850, training loss = 1.825988, validation loss = 1.870493
2018-12-05 01:01:45,112 - INFO - epoch 0, step 54860, training loss = 1.775705, validation loss = 2.067726
2018-12-05 01:01:49,622 - INFO - epoch 0, step 54870, training loss = 1.768037, validation loss = 2.014771
2018-12-05 01:01:54,199 - INFO - epoch 0, step 54880, training loss = 1.839071, validation loss = 2.080819
2018-12-05 01:01:58,699 - INFO - epoch 0, step 54890, training loss = 1.784655, validation loss = 1.726277
2018-12-05 01:02:02,979 - INFO - epoch 0, step 54900, training loss = 1.664647, validation loss = 1.790723
2018-12-05 01:02:07,557 - INFO - epoch 0, step 54910, training loss = 1.805665, validation loss = 1.829813
2018-12-05 01:02:11,811 - INFO - epoch 0, step 54920, training loss = 1.537134, validation loss = 1.970381
2018-12-05 01:02:15,790 - INFO - epoch 0, step 54930, training loss = 2.049544, validation loss = 1.790611
2018-12-05 01:02:20,107 - INFO - epoch 0, step 54940, training loss = 1.659813, validation loss = 1.964315
2018-12-05 01:02:24,288 - INFO - epoch 0, step 54950, training loss = 1.791560, validation loss = 2.013204
2018-12-05 01:02:28,600 - INFO - epoch 0, step 54960, training loss = 1.811212, validation loss = 1.699115
2018-12-05 01:02:32,658 - INFO - epoch 0, step 54970, training loss = 1.632423, validation loss = 1.904389
2018-12-05 01:02:36,584 - INFO - epoch 0, step 54980, training loss = 1.862745, validation loss = 2.333506
2018-12-05 01:02:40,652 - INFO - epoch 0, step 54990, training loss = 1.933610, validation loss = 2.332118
2018-12-05 01:02:44,820 - INFO - epoch 0, step 55000, training loss = 1.650430, validation loss = 2.170326
2018-12-05 01:02:49,186 - INFO - epoch 0, step 55010, training loss = 1.791785, validation loss = 1.942213
2018-12-05 01:02:53,298 - INFO - epoch 0, step 55020, training loss = 1.604112, validation loss = 2.139975
2018-12-05 01:02:57,317 - INFO - epoch 0, step 55030, training loss = 2.020092, validation loss = 1.928145
2018-12-05 01:03:01,539 - INFO - epoch 0, step 55040, training loss = 1.402830, validation loss = 1.763063
2018-12-05 01:03:05,746 - INFO - epoch 0, step 55050, training loss = 1.958556, validation loss = 2.145301
2018-12-05 01:03:09,879 - INFO - epoch 0, step 55060, training loss = 1.725288, validation loss = 2.255100
2018-12-05 01:03:13,770 - INFO - epoch 0, step 55070, training loss = 1.783340, validation loss = 2.059295
2018-12-05 01:03:17,628 - INFO - epoch 0, step 55080, training loss = 1.794502, validation loss = 1.759924
2018-12-05 01:03:21,476 - INFO - epoch 0, step 55090, training loss = 1.981515, validation loss = 1.911712
2018-12-05 01:03:25,691 - INFO - epoch 0, step 55100, training loss = 1.654422, validation loss = 2.230904
2018-12-05 01:03:29,690 - INFO - epoch 0, step 55110, training loss = 1.636672, validation loss = 2.058771
2018-12-05 01:03:33,480 - INFO - epoch 0, step 55120, training loss = 1.774536, validation loss = 2.108760
2018-12-05 01:03:37,538 - INFO - epoch 0, step 55130, training loss = 1.461292, validation loss = 1.946095
2018-12-05 01:03:41,443 - INFO - epoch 0, step 55140, training loss = 1.722218, validation loss = 1.942360
2018-12-05 01:03:45,194 - INFO - epoch 0, step 55150, training loss = 1.601583, validation loss = 1.920760
2018-12-05 01:03:48,685 - INFO - epoch 0, step 55160, training loss = 1.836805, validation loss = 2.164299
2018-12-05 01:03:52,018 - INFO - epoch 0, step 55170, training loss = 1.931173, validation loss = 1.925757
2018-12-05 01:03:55,653 - INFO - epoch 0, step 55180, training loss = 1.688127, validation loss = 2.300703
2018-12-05 01:03:59,108 - INFO - epoch 0, step 55190, training loss = 1.900410, validation loss = 2.071710
2018-12-05 01:04:02,694 - INFO - epoch 0, step 55200, training loss = 2.105803, validation loss = 1.870569
2018-12-05 01:04:06,122 - INFO - epoch 0, step 55210, training loss = 1.837276, validation loss = 2.169323
2018-12-05 01:04:10,336 - INFO - epoch 0, step 55220, training loss = 1.910151, validation loss = 1.755804
2018-12-05 01:04:14,359 - INFO - epoch 0, step 55230, training loss = 1.941353, validation loss = 1.891111
2018-12-05 01:04:18,696 - INFO - epoch 0, step 55240, training loss = 1.871161, validation loss = 2.038307
2018-12-05 01:04:23,064 - INFO - epoch 0, step 55250, training loss = 1.837743, validation loss = 1.886026
2018-12-05 01:04:27,348 - INFO - epoch 0, step 55260, training loss = 1.809750, validation loss = 1.846320
2018-12-05 01:04:31,799 - INFO - epoch 0, step 55270, training loss = 1.999384, validation loss = 1.788935
2018-12-05 01:04:36,061 - INFO - epoch 0, step 55280, training loss = 1.813829, validation loss = 2.134972
2018-12-05 01:04:40,503 - INFO - epoch 0, step 55290, training loss = 1.877897, validation loss = 1.897993
2018-12-05 01:04:44,879 - INFO - epoch 0, step 55300, training loss = 1.411277, validation loss = 2.155948
2018-12-05 01:04:49,274 - INFO - epoch 0, step 55310, training loss = 2.105709, validation loss = 2.118666
2018-12-05 01:04:53,807 - INFO - epoch 0, step 55320, training loss = 1.689234, validation loss = 2.185532
2018-12-05 01:04:58,293 - INFO - epoch 0, step 55330, training loss = 1.623990, validation loss = 1.822323
2018-12-05 01:05:02,537 - INFO - epoch 0, step 55340, training loss = 2.168399, validation loss = 2.010064
2018-12-05 01:05:07,092 - INFO - epoch 0, step 55350, training loss = 1.741516, validation loss = 1.940118
2018-12-05 01:05:11,622 - INFO - epoch 0, step 55360, training loss = 2.171340, validation loss = 2.149939
2018-12-05 01:05:15,962 - INFO - epoch 0, step 55370, training loss = 1.735390, validation loss = 2.090039
2018-12-05 01:05:19,807 - INFO - epoch 0, step 55380, training loss = 2.398148, validation loss = 1.968795
2018-12-05 01:05:22,868 - INFO - epoch 0, step 55390, training loss = 1.747972, validation loss = 2.398039
2018-12-05 01:05:26,152 - INFO - epoch 0, step 55400, training loss = 2.035279, validation loss = 2.308841
2018-12-05 01:05:29,339 - INFO - epoch 0, step 55410, training loss = 2.059194, validation loss = 2.222844
2018-12-05 01:05:32,420 - INFO - epoch 0, step 55420, training loss = 1.976613, validation loss = 2.184925
2018-12-05 01:05:35,543 - INFO - epoch 0, step 55430, training loss = 1.951049, validation loss = 1.762792
2018-12-05 01:05:38,681 - INFO - epoch 0, step 55440, training loss = 1.951211, validation loss = 1.887759
2018-12-05 01:05:41,903 - INFO - epoch 0, step 55450, training loss = 2.010853, validation loss = 1.952414
2018-12-05 01:05:45,737 - INFO - epoch 0, step 55460, training loss = 1.804473, validation loss = 1.990807
2018-12-05 01:05:49,652 - INFO - epoch 0, step 55470, training loss = 1.922293, validation loss = 1.975776
2018-12-05 01:05:53,387 - INFO - epoch 0, step 55480, training loss = 1.546492, validation loss = 2.103426
2018-12-05 01:05:57,136 - INFO - epoch 0, step 55490, training loss = 1.866573, validation loss = 1.960676
2018-12-05 01:06:01,168 - INFO - epoch 0, step 55500, training loss = 1.754512, validation loss = 1.363329
2018-12-05 01:06:05,130 - INFO - epoch 0, step 55510, training loss = 1.879985, validation loss = 1.978230
2018-12-05 01:06:09,459 - INFO - epoch 0, step 55520, training loss = 1.780055, validation loss = 2.389740
2018-12-05 01:06:13,236 - INFO - epoch 0, step 55530, training loss = 1.579211, validation loss = 1.912207
2018-12-05 01:06:16,522 - INFO - epoch 0, step 55540, training loss = 1.568251, validation loss = 2.427143
2018-12-05 01:06:19,977 - INFO - epoch 0, step 55550, training loss = 2.119452, validation loss = 1.990373
2018-12-05 01:06:23,158 - INFO - epoch 0, step 55560, training loss = 2.044172, validation loss = 2.197064
2018-12-05 01:06:26,311 - INFO - epoch 0, step 55570, training loss = 2.038976, validation loss = 2.000815
2018-12-05 01:06:29,745 - INFO - epoch 0, step 55580, training loss = 1.670695, validation loss = 2.041135
2018-12-05 01:06:32,915 - INFO - epoch 0, step 55590, training loss = 2.023845, validation loss = 2.146085
2018-12-05 01:06:37,123 - INFO - epoch 0, step 55600, training loss = 1.804554, validation loss = 2.303650
2018-12-05 01:06:41,442 - INFO - epoch 0, step 55610, training loss = 1.648481, validation loss = 2.217478
2018-12-05 01:06:45,777 - INFO - epoch 0, step 55620, training loss = 1.620426, validation loss = 1.780673
2018-12-05 01:06:49,869 - INFO - epoch 0, step 55630, training loss = 2.140665, validation loss = 1.853899
2018-12-05 01:06:54,401 - INFO - epoch 0, step 55640, training loss = 1.675379, validation loss = 1.906906
2018-12-05 01:06:59,001 - INFO - epoch 0, step 55650, training loss = 1.711392, validation loss = 2.166429
2018-12-05 01:07:03,264 - INFO - epoch 0, step 55660, training loss = 1.901109, validation loss = 2.317085
2018-12-05 01:07:07,538 - INFO - epoch 0, step 55670, training loss = 1.840203, validation loss = 2.318365
2018-12-05 01:07:11,813 - INFO - epoch 0, step 55680, training loss = 1.870360, validation loss = 1.913127
2018-12-05 01:07:15,813 - INFO - epoch 0, step 55690, training loss = 1.633481, validation loss = 2.252771
2018-12-05 01:07:19,932 - INFO - epoch 0, step 55700, training loss = 1.793846, validation loss = 1.927952
2018-12-05 01:07:24,270 - INFO - epoch 0, step 55710, training loss = 1.913776, validation loss = 2.352329
2018-12-05 01:07:28,434 - INFO - epoch 0, step 55720, training loss = 2.146268, validation loss = 1.513870
2018-12-05 01:07:32,257 - INFO - epoch 0, step 55730, training loss = 1.610338, validation loss = 2.441666
2018-12-05 01:07:36,424 - INFO - epoch 0, step 55740, training loss = 1.601355, validation loss = 1.840177
2018-12-05 01:07:40,555 - INFO - epoch 0, step 55750, training loss = 1.725506, validation loss = 2.365006
2018-12-05 01:07:44,221 - INFO - epoch 0, step 55760, training loss = 1.814466, validation loss = 1.781155
2018-12-05 01:07:47,853 - INFO - epoch 0, step 55770, training loss = 1.987050, validation loss = 1.427637
2018-12-05 01:07:51,570 - INFO - epoch 0, step 55780, training loss = 2.103244, validation loss = 2.147434
2018-12-05 01:07:55,254 - INFO - epoch 0, step 55790, training loss = 1.604991, validation loss = 1.696405
2018-12-05 01:07:58,788 - INFO - epoch 0, step 55800, training loss = 1.898870, validation loss = 1.873557
2018-12-05 01:08:02,281 - INFO - epoch 0, step 55810, training loss = 1.994035, validation loss = 2.252779
2018-12-05 01:08:05,680 - INFO - epoch 0, step 55820, training loss = 2.109119, validation loss = 2.024730
2018-12-05 01:08:09,444 - INFO - epoch 0, step 55830, training loss = 1.960254, validation loss = 1.674612
2018-12-05 01:08:13,679 - INFO - epoch 0, step 55840, training loss = 1.951975, validation loss = 1.996738
2018-12-05 01:08:18,027 - INFO - epoch 0, step 55850, training loss = 1.827143, validation loss = 2.041378
2018-12-05 01:08:22,368 - INFO - epoch 0, step 55860, training loss = 1.520973, validation loss = 2.336334
2018-12-05 01:08:26,738 - INFO - epoch 0, step 55870, training loss = 1.475946, validation loss = 2.330682
2018-12-05 01:08:31,077 - INFO - epoch 0, step 55880, training loss = 1.682531, validation loss = 2.064487
2018-12-05 01:08:35,550 - INFO - epoch 0, step 55890, training loss = 1.888421, validation loss = 2.165500
2018-12-05 01:08:39,751 - INFO - epoch 0, step 55900, training loss = 1.651235, validation loss = 2.014876
2018-12-05 01:08:43,792 - INFO - epoch 0, step 55910, training loss = 1.781321, validation loss = 1.728290
2018-12-05 01:08:48,042 - INFO - epoch 0, step 55920, training loss = 1.852898, validation loss = 2.026928
2018-12-05 01:08:52,356 - INFO - epoch 0, step 55930, training loss = 1.677516, validation loss = 1.843298
2018-12-05 01:08:56,416 - INFO - epoch 0, step 55940, training loss = 1.922552, validation loss = 1.808696
2018-12-05 01:09:00,282 - INFO - epoch 0, step 55950, training loss = 1.938222, validation loss = 2.147784
2018-12-05 01:09:04,578 - INFO - epoch 0, step 55960, training loss = 1.371746, validation loss = 1.945678
2018-12-05 01:09:08,464 - INFO - epoch 0, step 55970, training loss = 1.907151, validation loss = 1.507893
2018-12-05 01:09:12,674 - INFO - epoch 0, step 55980, training loss = 1.710405, validation loss = 2.014015
2018-12-05 01:09:16,683 - INFO - epoch 0, step 55990, training loss = 1.861248, validation loss = 2.105920
2018-12-05 01:09:20,492 - INFO - epoch 0, step 56000, training loss = 1.974814, validation loss = 1.861886
2018-12-05 01:09:24,594 - INFO - epoch 0, step 56010, training loss = 1.335050, validation loss = 1.753763
2018-12-05 01:09:28,466 - INFO - epoch 0, step 56020, training loss = 1.852168, validation loss = 1.940481
2018-12-05 01:09:32,209 - INFO - epoch 0, step 56030, training loss = 2.146161, validation loss = 1.653883
2018-12-05 01:09:36,049 - INFO - epoch 0, step 56040, training loss = 1.977332, validation loss = 1.892529
2018-12-05 01:09:39,647 - INFO - epoch 0, step 56050, training loss = 1.832018, validation loss = 2.316045
2018-12-05 01:09:43,286 - INFO - epoch 0, step 56060, training loss = 1.399641, validation loss = 2.091384
2018-12-05 01:09:46,981 - INFO - epoch 0, step 56070, training loss = 1.624863, validation loss = 2.308840
2018-12-05 01:09:50,551 - INFO - epoch 0, step 56080, training loss = 1.479357, validation loss = 2.206572
2018-12-05 01:09:54,269 - INFO - epoch 0, step 56090, training loss = 1.826635, validation loss = 1.773858
2018-12-05 01:09:58,013 - INFO - epoch 0, step 56100, training loss = 1.896099, validation loss = 1.819316
2018-12-05 01:10:02,376 - INFO - epoch 0, step 56110, training loss = 1.810457, validation loss = 1.663595
2018-12-05 01:10:06,815 - INFO - epoch 0, step 56120, training loss = 1.739091, validation loss = 1.564388
2018-12-05 01:10:11,306 - INFO - epoch 0, step 56130, training loss = 2.041991, validation loss = 1.986201
2018-12-05 01:10:15,616 - INFO - epoch 0, step 56140, training loss = 2.093099, validation loss = 2.169031
2018-12-05 01:10:20,066 - INFO - epoch 0, step 56150, training loss = 2.277733, validation loss = 2.094995
2018-12-05 01:10:24,568 - INFO - epoch 0, step 56160, training loss = 1.649204, validation loss = 1.713012
2018-12-05 01:10:28,932 - INFO - epoch 0, step 56170, training loss = 1.829493, validation loss = 1.703839
2018-12-05 01:10:33,103 - INFO - epoch 0, step 56180, training loss = 1.891410, validation loss = 1.994304
2018-12-05 01:10:37,111 - INFO - epoch 0, step 56190, training loss = 1.825336, validation loss = 2.076383
2018-12-05 01:10:40,545 - INFO - epoch 0, step 56200, training loss = 1.958373, validation loss = 1.899912
2018-12-05 01:10:43,788 - INFO - epoch 0, step 56210, training loss = 2.116738, validation loss = 1.864483
2018-12-05 01:10:46,917 - INFO - epoch 0, step 56220, training loss = 2.183611, validation loss = 1.935515
2018-12-05 01:10:50,027 - INFO - epoch 0, step 56230, training loss = 2.114771, validation loss = 1.937254
2018-12-05 01:10:53,348 - INFO - epoch 0, step 56240, training loss = 2.111276, validation loss = 1.901008
2018-12-05 01:10:56,408 - INFO - epoch 0, step 56250, training loss = 2.144840, validation loss = 2.007212
2018-12-05 01:10:59,478 - INFO - epoch 0, step 56260, training loss = 1.652298, validation loss = 1.726503
2018-12-05 01:11:02,833 - INFO - epoch 0, step 56270, training loss = 1.463399, validation loss = 1.612728
2018-12-05 01:11:05,914 - INFO - epoch 0, step 56280, training loss = 2.151405, validation loss = 1.933938
2018-12-05 01:11:09,051 - INFO - epoch 0, step 56290, training loss = 1.982942, validation loss = 1.955526
2018-12-05 01:11:12,155 - INFO - epoch 0, step 56300, training loss = 1.801357, validation loss = 2.104824
2018-12-05 01:11:15,262 - INFO - epoch 0, step 56310, training loss = 1.737333, validation loss = 2.029988
2018-12-05 01:11:18,815 - INFO - epoch 0, step 56320, training loss = 1.714124, validation loss = 1.775016
2018-12-05 01:11:22,231 - INFO - epoch 0, step 56330, training loss = 1.863514, validation loss = 1.643887
2018-12-05 01:11:25,490 - INFO - epoch 0, step 56340, training loss = 1.874986, validation loss = 2.083431
2018-12-05 01:11:29,392 - INFO - epoch 0, step 56350, training loss = 1.769887, validation loss = 1.935301
2018-12-05 01:11:33,477 - INFO - epoch 0, step 56360, training loss = 1.721926, validation loss = 2.084985
2018-12-05 01:11:37,612 - INFO - epoch 0, step 56370, training loss = 1.828995, validation loss = 1.548957
2018-12-05 01:11:41,513 - INFO - epoch 0, step 56380, training loss = 2.146353, validation loss = 2.155004
2018-12-05 01:11:45,591 - INFO - epoch 0, step 56390, training loss = 1.729378, validation loss = 1.891546
2018-12-05 01:11:49,879 - INFO - epoch 0, step 56400, training loss = 2.264464, validation loss = 2.287531
2018-12-05 01:11:54,264 - INFO - epoch 0, step 56410, training loss = 1.922426, validation loss = 1.792018
2018-12-05 01:11:58,410 - INFO - epoch 0, step 56420, training loss = 1.819112, validation loss = 2.058378
2018-12-05 01:12:02,537 - INFO - epoch 0, step 56430, training loss = 1.978124, validation loss = 2.414454
2018-12-05 01:12:06,665 - INFO - epoch 0, step 56440, training loss = 1.909759, validation loss = 2.199114
2018-12-05 01:12:10,896 - INFO - epoch 0, step 56450, training loss = 1.895083, validation loss = 1.864219
2018-12-05 01:12:15,384 - INFO - epoch 0, step 56460, training loss = 1.752836, validation loss = 1.476771
2018-12-05 01:12:19,693 - INFO - epoch 0, step 56470, training loss = 1.760065, validation loss = 1.922061
2018-12-05 01:12:24,088 - INFO - epoch 0, step 56480, training loss = 1.729148, validation loss = 2.231281
2018-12-05 01:12:28,631 - INFO - epoch 0, step 56490, training loss = 1.752173, validation loss = 1.946004
2018-12-05 01:12:33,045 - INFO - epoch 0, step 56500, training loss = 1.761605, validation loss = 1.803623
2018-12-05 01:12:37,381 - INFO - epoch 0, step 56510, training loss = 1.771584, validation loss = 2.073205
2018-12-05 01:12:41,769 - INFO - epoch 0, step 56520, training loss = 1.996017, validation loss = 1.830078
2018-12-05 01:12:46,023 - INFO - epoch 0, step 56530, training loss = 1.870567, validation loss = 2.048528
2018-12-05 01:12:50,456 - INFO - epoch 0, step 56540, training loss = 1.650513, validation loss = 2.051710
2018-12-05 01:12:54,422 - INFO - epoch 0, step 56550, training loss = 2.102396, validation loss = 2.339513
2018-12-05 01:12:57,856 - INFO - epoch 0, step 56560, training loss = 1.949599, validation loss = 1.887330
2018-12-05 01:13:01,340 - INFO - epoch 0, step 56570, training loss = 1.734485, validation loss = 1.912916
2018-12-05 01:13:05,075 - INFO - epoch 0, step 56580, training loss = 1.792120, validation loss = 1.791852
2018-12-05 01:13:08,549 - INFO - epoch 0, step 56590, training loss = 2.070089, validation loss = 1.817753
2018-12-05 01:13:12,047 - INFO - epoch 0, step 56600, training loss = 1.836601, validation loss = 1.877808
2018-12-05 01:13:15,724 - INFO - epoch 0, step 56610, training loss = 1.810408, validation loss = 2.248372
2018-12-05 01:13:19,168 - INFO - epoch 0, step 56620, training loss = 1.795146, validation loss = 2.468440
2018-12-05 01:13:22,852 - INFO - epoch 0, step 56630, training loss = 1.837781, validation loss = 1.567801
2018-12-05 01:13:26,256 - INFO - epoch 0, step 56640, training loss = 1.769338, validation loss = 1.966222
2018-12-05 01:13:29,867 - INFO - epoch 0, step 56650, training loss = 1.839708, validation loss = 2.038365
2018-12-05 01:13:33,354 - INFO - epoch 0, step 56660, training loss = 1.698511, validation loss = 2.159518
2018-12-05 01:13:36,764 - INFO - epoch 0, step 56670, training loss = 1.770469, validation loss = 1.763798
2018-12-05 01:13:40,016 - INFO - epoch 0, step 56680, training loss = 1.840250, validation loss = 1.715791
2018-12-05 01:13:43,421 - INFO - epoch 0, step 56690, training loss = 1.808438, validation loss = 1.988754
2018-12-05 01:13:47,170 - INFO - epoch 0, step 56700, training loss = 2.049174, validation loss = 1.755586
2018-12-05 01:13:51,447 - INFO - epoch 0, step 56710, training loss = 1.758087, validation loss = 2.164168
2018-12-05 01:13:55,361 - INFO - epoch 0, step 56720, training loss = 1.569580, validation loss = 2.217937
2018-12-05 01:13:59,525 - INFO - epoch 0, step 56730, training loss = 1.909082, validation loss = 2.182121
2018-12-05 01:14:03,616 - INFO - epoch 0, step 56740, training loss = 1.923508, validation loss = 1.684756
2018-12-05 01:14:07,919 - INFO - epoch 0, step 56750, training loss = 1.926518, validation loss = 2.143265
2018-12-05 01:14:12,070 - INFO - epoch 0, step 56760, training loss = 1.685809, validation loss = 2.065300
2018-12-05 01:14:15,913 - INFO - epoch 0, step 56770, training loss = 1.800528, validation loss = 1.878216
2018-12-05 01:14:19,936 - INFO - epoch 0, step 56780, training loss = 1.764247, validation loss = 1.791148
2018-12-05 01:14:23,588 - INFO - epoch 0, step 56790, training loss = 2.032665, validation loss = 1.684502
2018-12-05 01:14:27,032 - INFO - epoch 0, step 56800, training loss = 1.757427, validation loss = 2.072718
2018-12-05 01:14:30,742 - INFO - epoch 0, step 56810, training loss = 1.570565, validation loss = 1.648603
2018-12-05 01:14:34,654 - INFO - epoch 0, step 56820, training loss = 1.515521, validation loss = 1.861593
2018-12-05 01:14:38,354 - INFO - epoch 0, step 56830, training loss = 1.850059, validation loss = 2.014348
2018-12-05 01:14:42,139 - INFO - epoch 0, step 56840, training loss = 1.970861, validation loss = 1.918570
2018-12-05 01:14:45,452 - INFO - epoch 0, step 56850, training loss = 1.979529, validation loss = 2.012008
2018-12-05 01:14:48,863 - INFO - epoch 0, step 56860, training loss = 1.991396, validation loss = 1.951454
2018-12-05 01:14:52,265 - INFO - epoch 0, step 56870, training loss = 2.293832, validation loss = 1.884833
2018-12-05 01:14:55,300 - INFO - epoch 0, step 56880, training loss = 2.401599, validation loss = 1.972823
2018-12-05 01:14:58,532 - INFO - epoch 0, step 56890, training loss = 2.113958, validation loss = 1.845045
2018-12-05 01:15:01,887 - INFO - epoch 0, step 56900, training loss = 1.942764, validation loss = 1.673403
2018-12-05 01:15:05,090 - INFO - epoch 0, step 56910, training loss = 2.002646, validation loss = 1.873451
2018-12-05 01:15:08,260 - INFO - epoch 0, step 56920, training loss = 1.987282, validation loss = 1.675541
2018-12-05 01:15:11,747 - INFO - epoch 0, step 56930, training loss = 1.773570, validation loss = 2.202447
2018-12-05 01:15:15,111 - INFO - epoch 0, step 56940, training loss = 2.216238, validation loss = 1.962825
2018-12-05 01:15:18,745 - INFO - epoch 0, step 56950, training loss = 2.110589, validation loss = 1.842953
2018-12-05 01:15:22,099 - INFO - epoch 0, step 56960, training loss = 1.874011, validation loss = 2.036179
2018-12-05 01:15:25,665 - INFO - epoch 0, step 56970, training loss = 1.819661, validation loss = 1.623557
2018-12-05 01:15:29,088 - INFO - epoch 0, step 56980, training loss = 2.252571, validation loss = 1.736466
2018-12-05 01:15:32,649 - INFO - epoch 0, step 56990, training loss = 1.907438, validation loss = 2.108556
2018-12-05 01:15:36,999 - INFO - epoch 0, step 57000, training loss = 1.694423, validation loss = 1.917950
2018-12-05 01:15:41,406 - INFO - epoch 0, step 57010, training loss = 1.699580, validation loss = 2.165130
2018-12-05 01:15:45,661 - INFO - epoch 0, step 57020, training loss = 1.494564, validation loss = 1.844534
2018-12-05 01:15:50,105 - INFO - epoch 0, step 57030, training loss = 1.768815, validation loss = 1.629641
2018-12-05 01:15:54,538 - INFO - epoch 0, step 57040, training loss = 1.645697, validation loss = 1.844723
2018-12-05 01:15:58,769 - INFO - epoch 0, step 57050, training loss = 1.672723, validation loss = 1.818572
2018-12-05 01:16:02,824 - INFO - epoch 0, step 57060, training loss = 1.624000, validation loss = 1.542745
2018-12-05 01:16:07,181 - INFO - epoch 0, step 57070, training loss = 1.669774, validation loss = 1.881503
2018-12-05 01:16:11,127 - INFO - epoch 0, step 57080, training loss = 1.655826, validation loss = 1.979890
2018-12-05 01:16:15,253 - INFO - epoch 0, step 57090, training loss = 1.942642, validation loss = 1.706206
2018-12-05 01:16:19,018 - INFO - epoch 0, step 57100, training loss = 1.898047, validation loss = 1.640743
2018-12-05 01:16:22,871 - INFO - epoch 0, step 57110, training loss = 2.004989, validation loss = 1.960658
2018-12-05 01:16:26,788 - INFO - epoch 0, step 57120, training loss = 1.491976, validation loss = 2.111192
2018-12-05 01:16:30,525 - INFO - epoch 0, step 57130, training loss = 1.713904, validation loss = 1.359131
2018-12-05 01:16:34,499 - INFO - epoch 0, step 57140, training loss = 1.850178, validation loss = 1.979713
2018-12-05 01:16:38,684 - INFO - epoch 0, step 57150, training loss = 1.765107, validation loss = 1.888288
2018-12-05 01:16:42,862 - INFO - epoch 0, step 57160, training loss = 1.409819, validation loss = 1.929091
2018-12-05 01:16:47,096 - INFO - epoch 0, step 57170, training loss = 1.890822, validation loss = 1.689297
2018-12-05 01:16:51,329 - INFO - epoch 0, step 57180, training loss = 1.816179, validation loss = 1.934637
2018-12-05 01:16:55,751 - INFO - epoch 0, step 57190, training loss = 1.418488, validation loss = 1.739437
2018-12-05 01:16:59,949 - INFO - epoch 0, step 57200, training loss = 1.758275, validation loss = 2.136092
2018-12-05 01:17:04,332 - INFO - epoch 0, step 57210, training loss = 1.550803, validation loss = 1.851111
2018-12-05 01:17:08,485 - INFO - epoch 0, step 57220, training loss = 1.940990, validation loss = 1.906981
2018-12-05 01:17:12,691 - INFO - epoch 0, step 57230, training loss = 1.421170, validation loss = 1.828050
2018-12-05 01:17:16,978 - INFO - epoch 0, step 57240, training loss = 1.773286, validation loss = 1.837426
2018-12-05 01:17:21,341 - INFO - epoch 0, step 57250, training loss = 1.713134, validation loss = 1.826593
2018-12-05 01:17:25,620 - INFO - epoch 0, step 57260, training loss = 1.527415, validation loss = 1.376567
2018-12-05 01:17:29,908 - INFO - epoch 0, step 57270, training loss = 1.806591, validation loss = 1.984900
2018-12-05 01:17:34,335 - INFO - epoch 0, step 57280, training loss = 1.690721, validation loss = 2.113954
2018-12-05 01:17:38,055 - INFO - epoch 0, step 57290, training loss = 1.877579, validation loss = 2.452796
2018-12-05 01:17:41,661 - INFO - epoch 0, step 57300, training loss = 1.667113, validation loss = 1.946860
2018-12-05 01:17:45,098 - INFO - epoch 0, step 57310, training loss = 1.665292, validation loss = 2.246301
2018-12-05 01:17:48,498 - INFO - epoch 0, step 57320, training loss = 1.903818, validation loss = 2.211010
2018-12-05 01:17:52,213 - INFO - epoch 0, step 57330, training loss = 1.862077, validation loss = 2.013008
2018-12-05 01:17:55,667 - INFO - epoch 0, step 57340, training loss = 1.800580, validation loss = 2.092071
2018-12-05 01:17:59,612 - INFO - epoch 0, step 57350, training loss = 1.361659, validation loss = 1.428611
2018-12-05 01:18:03,297 - INFO - epoch 0, step 57360, training loss = 1.893869, validation loss = 1.895998
2018-12-05 01:18:06,618 - INFO - epoch 0, step 57370, training loss = 1.828004, validation loss = 1.912769
2018-12-05 01:18:09,799 - INFO - epoch 0, step 57380, training loss = 2.004404, validation loss = 1.709729
2018-12-05 01:18:13,112 - INFO - epoch 0, step 57390, training loss = 1.886295, validation loss = 1.822950
2018-12-05 01:18:16,248 - INFO - epoch 0, step 57400, training loss = 2.069156, validation loss = 2.092096
2018-12-05 01:18:19,521 - INFO - epoch 0, step 57410, training loss = 1.887474, validation loss = 1.952363
2018-12-05 01:18:22,613 - INFO - epoch 0, step 57420, training loss = 2.075157, validation loss = 2.008805
2018-12-05 01:18:25,845 - INFO - epoch 0, step 57430, training loss = 1.820512, validation loss = 2.014478
2018-12-05 01:18:29,225 - INFO - epoch 0, step 57440, training loss = 1.750205, validation loss = 1.802981
2018-12-05 01:18:32,368 - INFO - epoch 0, step 57450, training loss = 1.815276, validation loss = 2.087029
2018-12-05 01:18:35,349 - INFO - epoch 0, step 57460, training loss = 2.290015, validation loss = 2.449555
2018-12-05 01:18:38,540 - INFO - epoch 0, step 57470, training loss = 2.086682, validation loss = 1.725690
2018-12-05 01:18:41,627 - INFO - epoch 0, step 57480, training loss = 2.069213, validation loss = 2.582685
2018-12-05 01:18:45,072 - INFO - epoch 0, step 57490, training loss = 1.683768, validation loss = 1.526291
2018-12-05 01:18:48,223 - INFO - epoch 0, step 57500, training loss = 1.771318, validation loss = 2.227826
2018-12-05 01:18:51,255 - INFO - epoch 0, step 57510, training loss = 1.771280, validation loss = 2.172714
2018-12-05 01:18:54,521 - INFO - epoch 0, step 57520, training loss = 2.020915, validation loss = 1.967584
2018-12-05 01:18:57,755 - INFO - epoch 0, step 57530, training loss = 1.726109, validation loss = 1.645740
2018-12-05 01:19:01,177 - INFO - epoch 0, step 57540, training loss = 1.941183, validation loss = 1.934924
2018-12-05 01:19:04,629 - INFO - epoch 0, step 57550, training loss = 1.950461, validation loss = 2.010863
2018-12-05 01:19:08,092 - INFO - epoch 0, step 57560, training loss = 1.581475, validation loss = 2.207209
2018-12-05 01:19:11,412 - INFO - epoch 0, step 57570, training loss = 2.058025, validation loss = 1.967094
2018-12-05 01:19:14,591 - INFO - epoch 0, step 57580, training loss = 2.346041, validation loss = 2.216534
2018-12-05 01:19:17,688 - INFO - epoch 0, step 57590, training loss = 2.114343, validation loss = 2.157406
2018-12-05 01:19:20,822 - INFO - epoch 0, step 57600, training loss = 1.853168, validation loss = 1.972589
2018-12-05 01:19:23,934 - INFO - epoch 0, step 57610, training loss = 2.214615, validation loss = 1.939190
2018-12-05 01:19:27,153 - INFO - epoch 0, step 57620, training loss = 1.677063, validation loss = 1.950417
2018-12-05 01:19:30,307 - INFO - epoch 0, step 57630, training loss = 1.882662, validation loss = 1.920405
2018-12-05 01:19:33,510 - INFO - epoch 0, step 57640, training loss = 1.514195, validation loss = 2.037095
2018-12-05 01:19:36,851 - INFO - epoch 0, step 57650, training loss = 1.598577, validation loss = 2.224118
2018-12-05 01:19:40,990 - INFO - epoch 0, step 57660, training loss = 1.686431, validation loss = 2.177718
2018-12-05 01:19:45,180 - INFO - epoch 0, step 57670, training loss = 2.066940, validation loss = 1.921214
2018-12-05 01:19:49,490 - INFO - epoch 0, step 57680, training loss = 1.786166, validation loss = 2.016544
2018-12-05 01:19:53,626 - INFO - epoch 0, step 57690, training loss = 1.929761, validation loss = 2.117878
2018-12-05 01:19:57,673 - INFO - epoch 0, step 57700, training loss = 2.247267, validation loss = 2.307344
2018-12-05 01:20:02,072 - INFO - epoch 0, step 57710, training loss = 1.418635, validation loss = 2.696949
2018-12-05 01:20:05,649 - INFO - epoch 0, step 57720, training loss = 1.959821, validation loss = 2.339711
2018-12-05 01:20:09,530 - INFO - epoch 0, step 57730, training loss = 1.915139, validation loss = 2.150705
2018-12-05 01:20:13,417 - INFO - epoch 0, step 57740, training loss = 1.646196, validation loss = 2.031684
2018-12-05 01:20:17,512 - INFO - epoch 0, step 57750, training loss = 2.263943, validation loss = 1.821530
2018-12-05 01:20:21,238 - INFO - epoch 0, step 57760, training loss = 1.826515, validation loss = 2.012338
2018-12-05 01:20:25,280 - INFO - epoch 0, step 57770, training loss = 1.829781, validation loss = 1.992164
2018-12-05 01:20:29,131 - INFO - epoch 0, step 57780, training loss = 1.797333, validation loss = 1.960267
2018-12-05 01:20:32,953 - INFO - epoch 0, step 57790, training loss = 1.679948, validation loss = 1.975747
2018-12-05 01:20:36,754 - INFO - epoch 0, step 57800, training loss = 1.710203, validation loss = 1.617819
2018-12-05 01:20:40,854 - INFO - epoch 0, step 57810, training loss = 1.820598, validation loss = 1.958317
2018-12-05 01:20:44,796 - INFO - epoch 0, step 57820, training loss = 1.843060, validation loss = 2.116190
2018-12-05 01:20:48,586 - INFO - epoch 0, step 57830, training loss = 2.113831, validation loss = 2.446534
2018-12-05 01:20:52,236 - INFO - epoch 0, step 57840, training loss = 2.149024, validation loss = 1.851401
2018-12-05 01:20:56,341 - INFO - epoch 0, step 57850, training loss = 2.065587, validation loss = 2.088422
2018-12-05 01:21:00,781 - INFO - epoch 0, step 57860, training loss = 1.910212, validation loss = 2.157639
2018-12-05 01:21:05,224 - INFO - epoch 0, step 57870, training loss = 1.931301, validation loss = 2.087763
2018-12-05 01:21:09,500 - INFO - epoch 0, step 57880, training loss = 1.787366, validation loss = 2.000624
2018-12-05 01:21:13,379 - INFO - epoch 0, step 57890, training loss = 1.872282, validation loss = 2.329979
2018-12-05 01:21:17,281 - INFO - epoch 0, step 57900, training loss = 1.953536, validation loss = 1.950083
2018-12-05 01:21:21,355 - INFO - epoch 0, step 57910, training loss = 1.915582, validation loss = 2.076267
2018-12-05 01:21:25,527 - INFO - epoch 0, step 57920, training loss = 1.879897, validation loss = 2.118406
2018-12-05 01:21:29,775 - INFO - epoch 0, step 57930, training loss = 1.813814, validation loss = 1.999941
2018-12-05 01:21:34,028 - INFO - epoch 0, step 57940, training loss = 2.104079, validation loss = 2.376783
2018-12-05 01:21:38,263 - INFO - epoch 0, step 57950, training loss = 1.376088, validation loss = 1.776441
2018-12-05 01:21:42,189 - INFO - epoch 0, step 57960, training loss = 1.883075, validation loss = 1.505756
2018-12-05 01:21:46,440 - INFO - epoch 0, step 57970, training loss = 1.683504, validation loss = 2.046724
2018-12-05 01:21:50,441 - INFO - epoch 0, step 57980, training loss = 1.589380, validation loss = 2.198012
2018-12-05 01:21:54,922 - INFO - epoch 0, step 57990, training loss = 2.186465, validation loss = 1.850393
2018-12-05 01:21:59,197 - INFO - epoch 0, step 58000, training loss = 1.644671, validation loss = 2.381732
2018-12-05 01:22:03,527 - INFO - epoch 0, step 58010, training loss = 1.806326, validation loss = 1.968516
2018-12-05 01:22:07,911 - INFO - epoch 0, step 58020, training loss = 1.669907, validation loss = 1.847221
2018-12-05 01:22:12,189 - INFO - epoch 0, step 58030, training loss = 1.883506, validation loss = 1.872016
2018-12-05 01:22:16,159 - INFO - epoch 0, step 58040, training loss = 1.888850, validation loss = 2.220453
2018-12-05 01:22:20,326 - INFO - epoch 0, step 58050, training loss = 1.510859, validation loss = 1.827785
2018-12-05 01:22:24,300 - INFO - epoch 0, step 58060, training loss = 1.921305, validation loss = 1.967929
2018-12-05 01:22:28,429 - INFO - epoch 0, step 58070, training loss = 1.894271, validation loss = 2.098865
2018-12-05 01:22:32,636 - INFO - epoch 0, step 58080, training loss = 1.879308, validation loss = 1.890282
2018-12-05 01:22:36,253 - INFO - epoch 0, step 58090, training loss = 1.717217, validation loss = 2.038795
2018-12-05 01:22:39,788 - INFO - epoch 0, step 58100, training loss = 1.801075, validation loss = 1.975755
2018-12-05 01:22:43,504 - INFO - epoch 0, step 58110, training loss = 1.850016, validation loss = 1.763043
2018-12-05 01:22:47,085 - INFO - epoch 0, step 58120, training loss = 1.609156, validation loss = 1.891223
2018-12-05 01:22:50,702 - INFO - epoch 0, step 58130, training loss = 1.912234, validation loss = 2.221913
2018-12-05 01:22:53,891 - INFO - epoch 0, step 58140, training loss = 1.907513, validation loss = 1.864115
2018-12-05 01:22:57,149 - INFO - epoch 0, step 58150, training loss = 1.984154, validation loss = 2.042722
2018-12-05 01:23:00,221 - INFO - epoch 0, step 58160, training loss = 1.787474, validation loss = 2.062770
2018-12-05 01:23:03,250 - INFO - epoch 0, step 58170, training loss = 2.064197, validation loss = 2.288285
2018-12-05 01:23:06,471 - INFO - epoch 0, step 58180, training loss = 2.378215, validation loss = 1.730713
2018-12-05 01:23:09,565 - INFO - epoch 0, step 58190, training loss = 2.060474, validation loss = 1.825621
2018-12-05 01:23:12,670 - INFO - epoch 0, step 58200, training loss = 2.197283, validation loss = 1.824673
2018-12-05 01:23:15,914 - INFO - epoch 0, step 58210, training loss = 2.107514, validation loss = 2.091528
2018-12-05 01:23:19,895 - INFO - epoch 0, step 58220, training loss = 1.648853, validation loss = 1.796207
2018-12-05 01:23:24,097 - INFO - epoch 0, step 58230, training loss = 1.697583, validation loss = 2.432542
2018-12-05 01:23:28,338 - INFO - epoch 0, step 58240, training loss = 1.624274, validation loss = 2.221350
2018-12-05 01:23:32,310 - INFO - epoch 0, step 58250, training loss = 1.745247, validation loss = 1.891970
2018-12-05 01:23:36,434 - INFO - epoch 0, step 58260, training loss = 1.466898, validation loss = 1.928759
2018-12-05 01:23:40,527 - INFO - epoch 0, step 58270, training loss = 1.535779, validation loss = 1.906859
2018-12-05 01:23:44,753 - INFO - epoch 0, step 58280, training loss = 1.717641, validation loss = 2.180499
2018-12-05 01:23:48,952 - INFO - epoch 0, step 58290, training loss = 1.751466, validation loss = 2.172175
2018-12-05 01:23:53,109 - INFO - epoch 0, step 58300, training loss = 1.507697, validation loss = 2.127535
2018-12-05 01:23:57,146 - INFO - epoch 0, step 58310, training loss = 1.857487, validation loss = 1.806154
2018-12-05 01:24:01,359 - INFO - epoch 0, step 58320, training loss = 1.617548, validation loss = 2.131098
2018-12-05 01:24:05,491 - INFO - epoch 0, step 58330, training loss = 1.667875, validation loss = 2.235214
2018-12-05 01:24:09,662 - INFO - epoch 0, step 58340, training loss = 1.567093, validation loss = 2.333988
2018-12-05 01:24:13,701 - INFO - epoch 0, step 58350, training loss = 1.932156, validation loss = 1.769096
2018-12-05 01:24:17,742 - INFO - epoch 0, step 58360, training loss = 1.790432, validation loss = 1.837632
2018-12-05 01:24:21,798 - INFO - epoch 0, step 58370, training loss = 1.547952, validation loss = 2.199855
2018-12-05 01:24:26,030 - INFO - epoch 0, step 58380, training loss = 1.714125, validation loss = 1.805313
2018-12-05 01:24:30,233 - INFO - epoch 0, step 58390, training loss = 1.642313, validation loss = 1.887716
2018-12-05 01:24:34,081 - INFO - epoch 0, step 58400, training loss = 2.097860, validation loss = 1.947791
2018-12-05 01:24:37,704 - INFO - epoch 0, step 58410, training loss = 1.969840, validation loss = 1.624208
2018-12-05 01:24:41,580 - INFO - epoch 0, step 58420, training loss = 1.866160, validation loss = 1.740836
2018-12-05 01:24:45,381 - INFO - epoch 0, step 58430, training loss = 1.428725, validation loss = 1.893253
2018-12-05 01:24:48,774 - INFO - epoch 0, step 58440, training loss = 1.983492, validation loss = 1.855173
2018-12-05 01:24:52,405 - INFO - epoch 0, step 58450, training loss = 1.635311, validation loss = 1.593255
2018-12-05 01:24:56,239 - INFO - epoch 0, step 58460, training loss = 1.870359, validation loss = 2.106449
2018-12-05 01:25:00,162 - INFO - epoch 0, step 58470, training loss = 1.390427, validation loss = 2.023005
2018-12-05 01:25:03,721 - INFO - epoch 0, step 58480, training loss = 1.623584, validation loss = 1.915476
2018-12-05 01:25:07,375 - INFO - epoch 0, step 58490, training loss = 1.757052, validation loss = 2.071742
2018-12-05 01:25:10,874 - INFO - epoch 0, step 58500, training loss = 1.903527, validation loss = 2.013605
2018-12-05 01:25:14,409 - INFO - epoch 0, step 58510, training loss = 1.698886, validation loss = 2.045408
2018-12-05 01:25:18,289 - INFO - epoch 0, step 58520, training loss = 1.699392, validation loss = 1.929289
2018-12-05 01:25:21,898 - INFO - epoch 0, step 58530, training loss = 1.664330, validation loss = 1.524432
2018-12-05 01:25:25,696 - INFO - epoch 0, step 58540, training loss = 1.569157, validation loss = 2.058215
2018-12-05 01:25:29,493 - INFO - epoch 0, step 58550, training loss = 1.828308, validation loss = 1.900615
2018-12-05 01:25:33,252 - INFO - epoch 0, step 58560, training loss = 2.192039, validation loss = 1.939407
2018-12-05 01:25:37,395 - INFO - epoch 0, step 58570, training loss = 1.830699, validation loss = 1.874811
2018-12-05 01:25:41,643 - INFO - epoch 0, step 58580, training loss = 1.494939, validation loss = 1.624205
2018-12-05 01:25:45,741 - INFO - epoch 0, step 58590, training loss = 1.636566, validation loss = 1.751357
2018-12-05 01:25:50,010 - INFO - epoch 0, step 58600, training loss = 1.680329, validation loss = 2.101237
2018-12-05 01:25:54,074 - INFO - epoch 0, step 58610, training loss = 1.992273, validation loss = 1.878431
2018-12-05 01:25:58,101 - INFO - epoch 0, step 58620, training loss = 1.671519, validation loss = 1.879912
2018-12-05 01:26:01,522 - INFO - epoch 0, step 58630, training loss = 2.208672, validation loss = 1.855532
2018-12-05 01:26:04,630 - INFO - epoch 0, step 58640, training loss = 2.126484, validation loss = 2.064550
2018-12-05 01:26:07,957 - INFO - epoch 0, step 58650, training loss = 1.748436, validation loss = 1.890982
2018-12-05 01:26:11,441 - INFO - epoch 0, step 58660, training loss = 1.973349, validation loss = 1.963017
2018-12-05 01:26:14,528 - INFO - epoch 0, step 58670, training loss = 1.995092, validation loss = 2.205572
2018-12-05 01:26:17,789 - INFO - epoch 0, step 58680, training loss = 1.673409, validation loss = 2.168768
2018-12-05 01:26:21,233 - INFO - epoch 0, step 58690, training loss = 2.053127, validation loss = 1.880275
2018-12-05 01:26:24,412 - INFO - epoch 0, step 58700, training loss = 1.955613, validation loss = 1.912363
2018-12-05 01:26:28,120 - INFO - epoch 0, step 58710, training loss = 1.897556, validation loss = 2.024412
2018-12-05 01:26:32,199 - INFO - epoch 0, step 58720, training loss = 1.916797, validation loss = 1.506968
2018-12-05 01:26:36,399 - INFO - epoch 0, step 58730, training loss = 1.801274, validation loss = 1.863269
2018-12-05 01:26:40,400 - INFO - epoch 0, step 58740, training loss = 1.552469, validation loss = 1.897573
2018-12-05 01:26:44,708 - INFO - epoch 0, step 58750, training loss = 1.293302, validation loss = 1.644891
2018-12-05 01:26:49,079 - INFO - epoch 0, step 58760, training loss = 1.904349, validation loss = 1.837461
2018-12-05 01:26:53,453 - INFO - epoch 0, step 58770, training loss = 1.770551, validation loss = 1.527448
2018-12-05 01:26:57,739 - INFO - epoch 0, step 58780, training loss = 1.746178, validation loss = 1.903046
2018-12-05 01:27:01,857 - INFO - epoch 0, step 58790, training loss = 1.527400, validation loss = 2.075025
2018-12-05 01:27:05,890 - INFO - epoch 0, step 58800, training loss = 1.525834, validation loss = 1.889669
2018-12-05 01:27:09,778 - INFO - epoch 0, step 58810, training loss = 1.795487, validation loss = 1.695164
2018-12-05 01:27:13,999 - INFO - epoch 0, step 58820, training loss = 1.627612, validation loss = 2.130132
2018-12-05 01:27:18,255 - INFO - epoch 0, step 58830, training loss = 2.037549, validation loss = 1.942774
2018-12-05 01:27:22,183 - INFO - epoch 0, step 58840, training loss = 1.550213, validation loss = 1.965415
2018-12-05 01:27:26,040 - INFO - epoch 0, step 58850, training loss = 1.703938, validation loss = 2.005919
2018-12-05 01:27:30,268 - INFO - epoch 0, step 58860, training loss = 1.501994, validation loss = 1.965013
2018-12-05 01:27:34,408 - INFO - epoch 0, step 58870, training loss = 1.552386, validation loss = 1.846674
2018-12-05 01:27:38,597 - INFO - epoch 0, step 58880, training loss = 1.978949, validation loss = 2.025827
2018-12-05 01:27:42,672 - INFO - epoch 0, step 58890, training loss = 1.973882, validation loss = 2.033132
2018-12-05 01:27:46,940 - INFO - epoch 0, step 58900, training loss = 1.969179, validation loss = 1.987695
2018-12-05 01:27:51,118 - INFO - epoch 0, step 58910, training loss = 2.009524, validation loss = 1.712043
2018-12-05 01:27:55,647 - INFO - epoch 0, step 58920, training loss = 2.149124, validation loss = 1.865105
2018-12-05 01:27:59,865 - INFO - epoch 0, step 58930, training loss = 1.621335, validation loss = 1.994025
2018-12-05 01:28:03,018 - INFO - epoch 0, step 58940, training loss = 2.180932, validation loss = 1.925219
2018-12-05 01:28:06,171 - INFO - epoch 0, step 58950, training loss = 2.084144, validation loss = 2.155654
2018-12-05 01:28:09,649 - INFO - epoch 0, step 58960, training loss = 2.100364, validation loss = 1.537001
2018-12-05 01:28:12,851 - INFO - epoch 0, step 58970, training loss = 2.184607, validation loss = 2.190231
2018-12-05 01:28:16,105 - INFO - epoch 0, step 58980, training loss = 2.012297, validation loss = 2.274158
2018-12-05 01:28:19,398 - INFO - epoch 0, step 58990, training loss = 2.161981, validation loss = 1.950144
2018-12-05 01:28:22,917 - INFO - epoch 0, step 59000, training loss = 1.769669, validation loss = 1.914355
2018-12-05 01:28:26,262 - INFO - epoch 0, step 59010, training loss = 2.004489, validation loss = 1.986059
2018-12-05 01:28:30,350 - INFO - epoch 0, step 59020, training loss = 2.056983, validation loss = 1.862172
2018-12-05 01:28:34,488 - INFO - epoch 0, step 59030, training loss = 1.750479, validation loss = 1.925537
2018-12-05 01:28:38,553 - INFO - epoch 0, step 59040, training loss = 1.826823, validation loss = 1.987221
2018-12-05 01:28:42,681 - INFO - epoch 0, step 59050, training loss = 1.716462, validation loss = 1.752545
2018-12-05 01:28:47,119 - INFO - epoch 0, step 59060, training loss = 1.786725, validation loss = 1.832430
2018-12-05 01:28:50,756 - INFO - epoch 0, step 59070, training loss = 1.640827, validation loss = 1.736442
2018-12-05 01:28:54,365 - INFO - epoch 0, step 59080, training loss = 1.971771, validation loss = 1.845124
2018-12-05 01:28:58,133 - INFO - epoch 0, step 59090, training loss = 1.908174, validation loss = 1.774822
2018-12-05 01:29:01,833 - INFO - epoch 0, step 59100, training loss = 1.560028, validation loss = 1.679975
2018-12-05 01:29:05,280 - INFO - epoch 0, step 59110, training loss = 1.858466, validation loss = 2.021327
2018-12-05 01:29:08,847 - INFO - epoch 0, step 59120, training loss = 1.652815, validation loss = 1.774368
2018-12-05 01:29:12,578 - INFO - epoch 0, step 59130, training loss = 1.862959, validation loss = 1.827664
2018-12-05 01:29:16,143 - INFO - epoch 0, step 59140, training loss = 1.569551, validation loss = 2.032457
2018-12-05 01:29:19,817 - INFO - epoch 0, step 59150, training loss = 1.652018, validation loss = 1.662291
2018-12-05 01:29:23,532 - INFO - epoch 0, step 59160, training loss = 1.844304, validation loss = 1.689836
2018-12-05 01:29:27,374 - INFO - epoch 0, step 59170, training loss = 1.671046, validation loss = 1.560945
2018-12-05 01:29:31,014 - INFO - epoch 0, step 59180, training loss = 2.074642, validation loss = 1.953751
2018-12-05 01:29:34,729 - INFO - epoch 0, step 59190, training loss = 1.705271, validation loss = 1.645930
2018-12-05 01:29:38,494 - INFO - epoch 0, step 59200, training loss = 1.558346, validation loss = 1.916463
2018-12-05 01:29:42,764 - INFO - epoch 0, step 59210, training loss = 1.559013, validation loss = 2.072835
2018-12-05 01:29:46,730 - INFO - epoch 0, step 59220, training loss = 1.872151, validation loss = 1.979228
2018-12-05 01:29:50,671 - INFO - epoch 0, step 59230, training loss = 1.683890, validation loss = 1.950720
2018-12-05 01:29:55,005 - INFO - epoch 0, step 59240, training loss = 1.759559, validation loss = 1.881301
2018-12-05 01:29:59,103 - INFO - epoch 0, step 59250, training loss = 1.380674, validation loss = 1.792288
2018-12-05 01:30:03,437 - INFO - epoch 0, step 59260, training loss = 1.705869, validation loss = 1.825487
2018-12-05 01:30:07,928 - INFO - epoch 0, step 59270, training loss = 1.790242, validation loss = 2.519034
2018-12-05 01:30:12,258 - INFO - epoch 0, step 59280, training loss = 1.646733, validation loss = 2.168344
2018-12-05 01:30:16,706 - INFO - epoch 0, step 59290, training loss = 1.809338, validation loss = 2.369817
2018-12-05 01:30:20,971 - INFO - epoch 0, step 59300, training loss = 1.926777, validation loss = 2.725243
2018-12-05 01:30:25,407 - INFO - epoch 0, step 59310, training loss = 1.846421, validation loss = 2.820427
2018-12-05 01:30:29,724 - INFO - epoch 0, step 59320, training loss = 1.806960, validation loss = 2.398264
2018-12-05 01:30:34,034 - INFO - epoch 0, step 59330, training loss = 1.753150, validation loss = 2.489040
2018-12-05 01:30:38,539 - INFO - epoch 0, step 59340, training loss = 1.834614, validation loss = 2.682177
2018-12-05 01:30:42,761 - INFO - epoch 0, step 59350, training loss = 1.664177, validation loss = 2.469351
2018-12-05 01:30:47,280 - INFO - epoch 0, step 59360, training loss = 1.785806, validation loss = 2.449243
2018-12-05 01:30:50,533 - INFO - epoch 0, step 59370, training loss = 2.111243, validation loss = 2.292995
2018-12-05 01:30:53,741 - INFO - epoch 0, step 59380, training loss = 2.006132, validation loss = 2.267301
2018-12-05 01:30:56,920 - INFO - epoch 0, step 59390, training loss = 2.018190, validation loss = 2.422507
2018-12-05 01:31:00,107 - INFO - epoch 0, step 59400, training loss = 2.122016, validation loss = 2.460374
2018-12-05 01:31:03,253 - INFO - epoch 0, step 59410, training loss = 1.837153, validation loss = 2.581525
2018-12-05 01:31:06,440 - INFO - epoch 0, step 59420, training loss = 1.788427, validation loss = 2.408255
2018-12-05 01:31:09,704 - INFO - epoch 0, step 59430, training loss = 1.832643, validation loss = 2.436688
2018-12-05 01:31:11,929 - INFO - Model saved in dir ./models
2018-12-05 01:31:15,776 - INFO - epoch 1, step 10, training loss = 2.730673, validation loss = 2.666810
2018-12-05 01:31:19,408 - INFO - epoch 1, step 20, training loss = 1.771433, validation loss = 2.607876
2018-12-05 01:31:22,936 - INFO - epoch 1, step 30, training loss = 2.355422, validation loss = 2.724001
2018-12-05 01:31:26,458 - INFO - epoch 1, step 40, training loss = 2.610279, validation loss = 2.878412
2018-12-05 01:31:29,927 - INFO - epoch 1, step 50, training loss = 2.749357, validation loss = 2.693736
2018-12-05 01:31:33,591 - INFO - epoch 1, step 60, training loss = 2.193864, validation loss = 2.785187
2018-12-05 01:31:37,221 - INFO - epoch 1, step 70, training loss = 1.894741, validation loss = 2.846478
2018-12-05 01:31:40,711 - INFO - epoch 1, step 80, training loss = 2.318068, validation loss = 2.394496
2018-12-05 01:31:44,375 - INFO - epoch 1, step 90, training loss = 2.248423, validation loss = 2.454417
2018-12-05 01:31:48,226 - INFO - epoch 1, step 100, training loss = 1.893817, validation loss = 2.447366
2018-12-05 01:31:51,977 - INFO - epoch 1, step 110, training loss = 2.440443, validation loss = 2.869175
2018-12-05 01:31:55,697 - INFO - epoch 1, step 120, training loss = 2.170055, validation loss = 2.284164
2018-12-05 01:31:59,458 - INFO - epoch 1, step 130, training loss = 2.321494, validation loss = 2.798864
2018-12-05 01:32:03,245 - INFO - epoch 1, step 140, training loss = 2.496983, validation loss = 2.717376
2018-12-05 01:32:06,787 - INFO - epoch 1, step 150, training loss = 2.409681, validation loss = 2.514990
2018-12-05 01:32:10,815 - INFO - epoch 1, step 160, training loss = 2.042394, validation loss = 2.497761
2018-12-05 01:32:14,656 - INFO - epoch 1, step 170, training loss = 2.367440, validation loss = 2.814316
2018-12-05 01:32:18,897 - INFO - epoch 1, step 180, training loss = 2.181032, validation loss = 2.540066
2018-12-05 01:32:23,593 - INFO - epoch 1, step 190, training loss = 2.646863, validation loss = 2.464568
2018-12-05 01:32:27,563 - INFO - epoch 1, step 200, training loss = 2.103687, validation loss = 2.306851
2018-12-05 01:32:31,795 - INFO - epoch 1, step 210, training loss = 2.344684, validation loss = 2.315109
2018-12-05 01:32:35,916 - INFO - epoch 1, step 220, training loss = 2.381298, validation loss = 2.562139
2018-12-05 01:32:39,847 - INFO - epoch 1, step 230, training loss = 2.145371, validation loss = 2.411613
2018-12-05 01:32:43,978 - INFO - epoch 1, step 240, training loss = 2.263632, validation loss = 2.743047
2018-12-05 01:32:47,996 - INFO - epoch 1, step 250, training loss = 2.260769, validation loss = 2.833647
2018-12-05 01:32:52,099 - INFO - epoch 1, step 260, training loss = 2.274086, validation loss = 2.541976
2018-12-05 01:32:56,106 - INFO - epoch 1, step 270, training loss = 2.072946, validation loss = 2.080891
2018-12-05 01:33:00,017 - INFO - epoch 1, step 280, training loss = 2.555450, validation loss = 2.585935
2018-12-05 01:33:04,022 - INFO - epoch 1, step 290, training loss = 1.998277, validation loss = 2.554209
2018-12-05 01:33:08,171 - INFO - epoch 1, step 300, training loss = 1.814883, validation loss = 2.396065
2018-12-05 01:33:12,230 - INFO - epoch 1, step 310, training loss = 2.554067, validation loss = 2.491882
2018-12-05 01:33:16,281 - INFO - epoch 1, step 320, training loss = 2.291953, validation loss = 2.149380
2018-12-05 01:33:19,991 - INFO - epoch 1, step 330, training loss = 2.643447, validation loss = 2.135692
2018-12-05 01:33:23,866 - INFO - epoch 1, step 340, training loss = 2.185053, validation loss = 2.229602
2018-12-05 01:33:27,457 - INFO - epoch 1, step 350, training loss = 2.119444, validation loss = 2.431140
2018-12-05 01:33:31,202 - INFO - epoch 1, step 360, training loss = 2.179398, validation loss = 2.257621
2018-12-05 01:33:35,315 - INFO - epoch 1, step 370, training loss = 2.083477, validation loss = 2.489901
2018-12-05 01:33:39,135 - INFO - epoch 1, step 380, training loss = 2.094675, validation loss = 2.047295
2018-12-05 01:33:43,052 - INFO - epoch 1, step 390, training loss = 2.399369, validation loss = 2.543993
2018-12-05 01:33:46,863 - INFO - epoch 1, step 400, training loss = 2.149051, validation loss = 2.565260
2018-12-05 01:33:50,585 - INFO - epoch 1, step 410, training loss = 2.500912, validation loss = 2.227480
2018-12-05 01:33:54,386 - INFO - epoch 1, step 420, training loss = 2.037894, validation loss = 2.466325
2018-12-05 01:33:58,520 - INFO - epoch 1, step 430, training loss = 2.119560, validation loss = 2.594713
2018-12-05 01:34:02,589 - INFO - epoch 1, step 440, training loss = 1.933630, validation loss = 2.691056
2018-12-05 01:34:06,664 - INFO - epoch 1, step 450, training loss = 2.246350, validation loss = 2.492796
2018-12-05 01:34:10,667 - INFO - epoch 1, step 460, training loss = 2.038332, validation loss = 2.177844
2018-12-05 01:34:14,528 - INFO - epoch 1, step 470, training loss = 2.486954, validation loss = 2.273201
2018-12-05 01:34:18,715 - INFO - epoch 1, step 480, training loss = 1.709227, validation loss = 2.179617
2018-12-05 01:34:22,956 - INFO - epoch 1, step 490, training loss = 1.888039, validation loss = 2.325766
2018-12-05 01:34:27,144 - INFO - epoch 1, step 500, training loss = 2.684806, validation loss = 2.758075
2018-12-05 01:34:31,202 - INFO - epoch 1, step 510, training loss = 1.785143, validation loss = 2.751827
2018-12-05 01:34:35,350 - INFO - epoch 1, step 520, training loss = 2.033294, validation loss = 2.586690
2018-12-05 01:34:39,496 - INFO - epoch 1, step 530, training loss = 2.001808, validation loss = 2.204723
2018-12-05 01:34:43,368 - INFO - epoch 1, step 540, training loss = 2.228635, validation loss = 2.533367
2018-12-05 01:34:47,285 - INFO - epoch 1, step 550, training loss = 2.188996, validation loss = 2.470131
2018-12-05 01:34:51,117 - INFO - epoch 1, step 560, training loss = 2.202578, validation loss = 2.480836
2018-12-05 01:34:55,071 - INFO - epoch 1, step 570, training loss = 1.729244, validation loss = 2.717500
2018-12-05 01:34:58,994 - INFO - epoch 1, step 580, training loss = 2.432029, validation loss = 2.613238
2018-12-05 01:35:03,035 - INFO - epoch 1, step 590, training loss = 2.148071, validation loss = 2.156325
2018-12-05 01:35:06,970 - INFO - epoch 1, step 600, training loss = 2.125132, validation loss = 2.318988
2018-12-05 01:35:11,027 - INFO - epoch 1, step 610, training loss = 2.175652, validation loss = 2.441010
2018-12-05 01:35:15,208 - INFO - epoch 1, step 620, training loss = 2.702806, validation loss = 2.213933
2018-12-05 01:35:19,204 - INFO - epoch 1, step 630, training loss = 2.333405, validation loss = 3.260210
2018-12-05 01:35:23,421 - INFO - epoch 1, step 640, training loss = 2.021377, validation loss = 2.453625
2018-12-05 01:35:27,430 - INFO - epoch 1, step 650, training loss = 2.185150, validation loss = 2.473193
2018-12-05 01:35:31,124 - INFO - epoch 1, step 660, training loss = 2.091881, validation loss = 2.415307
2018-12-05 01:35:35,110 - INFO - epoch 1, step 670, training loss = 2.439885, validation loss = 2.656031
2018-12-05 01:35:39,014 - INFO - epoch 1, step 680, training loss = 2.254120, validation loss = 2.615165
2018-12-05 01:35:43,037 - INFO - epoch 1, step 690, training loss = 2.207131, validation loss = 2.572335
2018-12-05 01:35:47,153 - INFO - epoch 1, step 700, training loss = 2.199240, validation loss = 2.378311
2018-12-05 01:35:51,058 - INFO - epoch 1, step 710, training loss = 2.077104, validation loss = 1.878667
2018-12-05 01:35:55,069 - INFO - epoch 1, step 720, training loss = 2.171447, validation loss = 2.158059
2018-12-05 01:35:59,108 - INFO - epoch 1, step 730, training loss = 2.310875, validation loss = 2.380015
2018-12-05 01:36:02,988 - INFO - epoch 1, step 740, training loss = 1.722199, validation loss = 2.104365
2018-12-05 01:36:07,058 - INFO - epoch 1, step 750, training loss = 2.631306, validation loss = 2.798704
2018-12-05 01:36:11,097 - INFO - epoch 1, step 760, training loss = 1.483871, validation loss = 2.308111
2018-12-05 01:36:15,217 - INFO - epoch 1, step 770, training loss = 2.469940, validation loss = 2.121138
2018-12-05 01:36:19,446 - INFO - epoch 1, step 780, training loss = 2.261065, validation loss = 2.562791
2018-12-05 01:36:23,886 - INFO - epoch 1, step 790, training loss = 2.202109, validation loss = 2.111931
2018-12-05 01:36:28,151 - INFO - epoch 1, step 800, training loss = 2.560912, validation loss = 2.376682
2018-12-05 01:36:33,079 - INFO - epoch 1, step 810, training loss = 2.413925, validation loss = 2.463858
2018-12-05 01:36:37,266 - INFO - epoch 1, step 820, training loss = 2.170490, validation loss = 2.231745
2018-12-05 01:36:41,551 - INFO - epoch 1, step 830, training loss = 2.355882, validation loss = 2.483051
2018-12-05 01:36:45,638 - INFO - epoch 1, step 840, training loss = 2.066596, validation loss = 2.758652
2018-12-05 01:36:49,884 - INFO - epoch 1, step 850, training loss = 2.334125, validation loss = 2.803705
2018-12-05 01:36:54,146 - INFO - epoch 1, step 860, training loss = 1.997540, validation loss = 2.398407
2018-12-05 01:36:58,225 - INFO - epoch 1, step 870, training loss = 2.501415, validation loss = 2.476490
2018-12-05 01:37:02,496 - INFO - epoch 1, step 880, training loss = 2.634857, validation loss = 1.980431
2018-12-05 01:37:06,915 - INFO - epoch 1, step 890, training loss = 1.957646, validation loss = 2.618370
2018-12-05 01:37:11,069 - INFO - epoch 1, step 900, training loss = 2.569778, validation loss = 2.451390
2018-12-05 01:37:15,397 - INFO - epoch 1, step 910, training loss = 2.040850, validation loss = 2.760506
2018-12-05 01:37:19,778 - INFO - epoch 1, step 920, training loss = 2.228610, validation loss = 2.195009
2018-12-05 01:37:24,382 - INFO - epoch 1, step 930, training loss = 2.475230, validation loss = 2.302622
2018-12-05 01:37:28,755 - INFO - epoch 1, step 940, training loss = 2.116073, validation loss = 2.472953
2018-12-05 01:37:33,183 - INFO - epoch 1, step 950, training loss = 2.009372, validation loss = 2.246804
2018-12-05 01:37:37,500 - INFO - epoch 1, step 960, training loss = 2.486938, validation loss = 2.539918
2018-12-05 01:37:41,626 - INFO - epoch 1, step 970, training loss = 2.121806, validation loss = 2.914440
2018-12-05 01:37:46,044 - INFO - epoch 1, step 980, training loss = 2.079654, validation loss = 2.387926
2018-12-05 01:37:50,144 - INFO - epoch 1, step 990, training loss = 2.270452, validation loss = 2.815623
2018-12-05 01:37:54,241 - INFO - epoch 1, step 1000, training loss = 2.181322, validation loss = 2.541738
2018-12-05 01:37:58,554 - INFO - epoch 1, step 1010, training loss = 1.976899, validation loss = 2.428626
2018-12-05 01:38:02,645 - INFO - epoch 1, step 1020, training loss = 2.308689, validation loss = 2.189967
2018-12-05 01:38:06,683 - INFO - epoch 1, step 1030, training loss = 2.340182, validation loss = 2.242092
2018-12-05 01:38:10,764 - INFO - epoch 1, step 1040, training loss = 2.266098, validation loss = 2.858304
2018-12-05 01:38:15,017 - INFO - epoch 1, step 1050, training loss = 2.320178, validation loss = 2.417089
2018-12-05 01:38:18,956 - INFO - epoch 1, step 1060, training loss = 2.450605, validation loss = 2.736782
2018-12-05 01:38:22,972 - INFO - epoch 1, step 1070, training loss = 2.187865, validation loss = 2.071353
2018-12-05 01:38:27,165 - INFO - epoch 1, step 1080, training loss = 2.196651, validation loss = 2.271201
2018-12-05 01:38:31,385 - INFO - epoch 1, step 1090, training loss = 2.053592, validation loss = 2.406461
2018-12-05 01:38:35,335 - INFO - epoch 1, step 1100, training loss = 2.300734, validation loss = 2.407067
2018-12-05 01:38:39,538 - INFO - epoch 1, step 1110, training loss = 2.232184, validation loss = 2.155951
2018-12-05 01:38:43,423 - INFO - epoch 1, step 1120, training loss = 2.147897, validation loss = 2.194704
2018-12-05 01:38:47,458 - INFO - epoch 1, step 1130, training loss = 2.178898, validation loss = 2.184122
2018-12-05 01:38:51,638 - INFO - epoch 1, step 1140, training loss = 2.035551, validation loss = 2.131037
2018-12-05 01:38:55,856 - INFO - epoch 1, step 1150, training loss = 1.903259, validation loss = 2.282944
2018-12-05 01:39:00,022 - INFO - epoch 1, step 1160, training loss = 2.367982, validation loss = 2.634625
2018-12-05 01:39:04,088 - INFO - epoch 1, step 1170, training loss = 2.250239, validation loss = 2.674309
2018-12-05 01:39:08,049 - INFO - epoch 1, step 1180, training loss = 2.251185, validation loss = 2.519622
2018-12-05 01:39:12,030 - INFO - epoch 1, step 1190, training loss = 2.369577, validation loss = 2.501055
2018-12-05 01:39:15,964 - INFO - epoch 1, step 1200, training loss = 2.572936, validation loss = 2.253590
2018-12-05 01:39:20,103 - INFO - epoch 1, step 1210, training loss = 2.258095, validation loss = 2.448561
2018-12-05 01:39:24,371 - INFO - epoch 1, step 1220, training loss = 1.768331, validation loss = 2.319173
2018-12-05 01:39:28,273 - INFO - epoch 1, step 1230, training loss = 2.236975, validation loss = 2.369976
2018-12-05 01:39:32,577 - INFO - epoch 1, step 1240, training loss = 2.293449, validation loss = 2.591178
2018-12-05 01:39:36,618 - INFO - epoch 1, step 1250, training loss = 2.020738, validation loss = 2.138025
2018-12-05 01:39:40,664 - INFO - epoch 1, step 1260, training loss = 2.335338, validation loss = 1.708457
2018-12-05 01:39:44,795 - INFO - epoch 1, step 1270, training loss = 2.257990, validation loss = 2.409189
2018-12-05 01:39:48,705 - INFO - epoch 1, step 1280, training loss = 2.160617, validation loss = 2.297151
2018-12-05 01:39:52,786 - INFO - epoch 1, step 1290, training loss = 1.987405, validation loss = 2.697093
2018-12-05 01:39:56,812 - INFO - epoch 1, step 1300, training loss = 2.389280, validation loss = 2.638141
2018-12-05 01:40:00,339 - INFO - epoch 1, step 1310, training loss = 2.089043, validation loss = 2.589063
2018-12-05 01:40:04,277 - INFO - epoch 1, step 1320, training loss = 2.427117, validation loss = 2.419420
2018-12-05 01:40:07,862 - INFO - epoch 1, step 1330, training loss = 2.403438, validation loss = 2.243036
2018-12-05 01:40:11,316 - INFO - epoch 1, step 1340, training loss = 2.399012, validation loss = 2.758531
2018-12-05 01:40:15,038 - INFO - epoch 1, step 1350, training loss = 2.268089, validation loss = 2.218957
2018-12-05 01:40:18,952 - INFO - epoch 1, step 1360, training loss = 2.390543, validation loss = 2.140135
2018-12-05 01:40:22,644 - INFO - epoch 1, step 1370, training loss = 2.354986, validation loss = 2.550313
2018-12-05 01:40:26,416 - INFO - epoch 1, step 1380, training loss = 2.306577, validation loss = 2.948111
2018-12-05 01:40:29,991 - INFO - epoch 1, step 1390, training loss = 2.433651, validation loss = 2.250819
2018-12-05 01:40:33,588 - INFO - epoch 1, step 1400, training loss = 1.952389, validation loss = 2.669416
2018-12-05 01:40:37,432 - INFO - epoch 1, step 1410, training loss = 2.387311, validation loss = 2.083374
2018-12-05 01:40:40,988 - INFO - epoch 1, step 1420, training loss = 2.078206, validation loss = 2.127302
2018-12-05 01:40:44,942 - INFO - epoch 1, step 1430, training loss = 2.137936, validation loss = 2.497930
2018-12-05 01:40:48,971 - INFO - epoch 1, step 1440, training loss = 2.050999, validation loss = 2.464965
2018-12-05 01:40:52,718 - INFO - epoch 1, step 1450, training loss = 1.941164, validation loss = 2.569487
2018-12-05 01:40:56,518 - INFO - epoch 1, step 1460, training loss = 2.143281, validation loss = 2.542086
2018-12-05 01:41:00,266 - INFO - epoch 1, step 1470, training loss = 1.817972, validation loss = 2.279633
2018-12-05 01:41:03,830 - INFO - epoch 1, step 1480, training loss = 2.356418, validation loss = 1.839426
2018-12-05 01:41:07,629 - INFO - epoch 1, step 1490, training loss = 2.037514, validation loss = 2.153354
2018-12-05 01:41:13,805 - INFO - epoch 1, step 1500, training loss = 0.641857, validation loss = 2.520372
2018-12-05 01:41:17,669 - INFO - epoch 1, step 1510, training loss = 2.408452, validation loss = 2.124466
2018-12-05 01:41:21,545 - INFO - epoch 1, step 1520, training loss = 2.344714, validation loss = 2.183571
2018-12-05 01:41:25,362 - INFO - epoch 1, step 1530, training loss = 2.000474, validation loss = 2.498428
2018-12-05 01:41:29,271 - INFO - epoch 1, step 1540, training loss = 1.853376, validation loss = 2.235076
2018-12-05 01:41:33,224 - INFO - epoch 1, step 1550, training loss = 2.368050, validation loss = 1.959446
2018-12-05 01:41:37,038 - INFO - epoch 1, step 1560, training loss = 2.205987, validation loss = 1.982652
2018-12-05 01:41:41,185 - INFO - epoch 1, step 1570, training loss = 1.858995, validation loss = 2.194384
2018-12-05 01:41:44,872 - INFO - epoch 1, step 1580, training loss = 2.334333, validation loss = 2.170127
2018-12-05 01:41:48,484 - INFO - epoch 1, step 1590, training loss = 2.186641, validation loss = 2.672189
2018-12-05 01:41:52,006 - INFO - epoch 1, step 1600, training loss = 2.463347, validation loss = 2.480132
2018-12-05 01:41:55,685 - INFO - epoch 1, step 1610, training loss = 1.821366, validation loss = 2.092277
2018-12-05 01:41:59,539 - INFO - epoch 1, step 1620, training loss = 1.848871, validation loss = 2.138442
2018-12-05 01:42:03,222 - INFO - epoch 1, step 1630, training loss = 2.060798, validation loss = 2.596465
2018-12-05 01:42:07,020 - INFO - epoch 1, step 1640, training loss = 1.953152, validation loss = 2.401260
2018-12-05 01:42:10,858 - INFO - epoch 1, step 1650, training loss = 2.281497, validation loss = 2.559814
2018-12-05 01:42:15,693 - INFO - epoch 1, step 1660, training loss = 2.482394, validation loss = 2.460582
2018-12-05 01:42:20,743 - INFO - epoch 1, step 1670, training loss = 2.258872, validation loss = 2.320413
2018-12-05 01:42:24,404 - INFO - epoch 1, step 1680, training loss = 1.795437, validation loss = 2.610887
2018-12-05 01:42:28,008 - INFO - epoch 1, step 1690, training loss = 2.377220, validation loss = 2.397562
2018-12-05 01:42:31,564 - INFO - epoch 1, step 1700, training loss = 2.448609, validation loss = 2.300577
2018-12-05 01:42:35,114 - INFO - epoch 1, step 1710, training loss = 2.431267, validation loss = 2.152518
2018-12-05 01:42:38,865 - INFO - epoch 1, step 1720, training loss = 1.825023, validation loss = 2.199517
2018-12-05 01:42:42,384 - INFO - epoch 1, step 1730, training loss = 2.286507, validation loss = 2.026577
2018-12-05 01:42:45,685 - INFO - epoch 1, step 1740, training loss = 2.015448, validation loss = 2.065383
2018-12-05 01:42:49,016 - INFO - epoch 1, step 1750, training loss = 2.445160, validation loss = 2.077442
2018-12-05 01:42:52,470 - INFO - epoch 1, step 1760, training loss = 2.478788, validation loss = 2.280576
2018-12-05 01:42:55,997 - INFO - epoch 1, step 1770, training loss = 2.592113, validation loss = 2.486945
2018-12-05 01:42:59,416 - INFO - epoch 1, step 1780, training loss = 2.064206, validation loss = 2.435249
2018-12-05 01:43:02,706 - INFO - epoch 1, step 1790, training loss = 2.484143, validation loss = 1.986115
2018-12-05 01:43:06,058 - INFO - epoch 1, step 1800, training loss = 2.391887, validation loss = 2.158988
2018-12-05 01:43:09,402 - INFO - epoch 1, step 1810, training loss = 1.655550, validation loss = 2.434424
2018-12-05 01:43:12,866 - INFO - epoch 1, step 1820, training loss = 1.547895, validation loss = 2.224755
2018-12-05 01:43:16,251 - INFO - epoch 1, step 1830, training loss = 2.535728, validation loss = 2.284129
2018-12-05 01:43:19,944 - INFO - epoch 1, step 1840, training loss = 2.203338, validation loss = 2.207909
2018-12-05 01:43:23,485 - INFO - epoch 1, step 1850, training loss = 2.344049, validation loss = 1.886844
2018-12-05 01:43:27,651 - INFO - epoch 1, step 1860, training loss = 2.460256, validation loss = 2.233318
2018-12-05 01:43:31,682 - INFO - epoch 1, step 1870, training loss = 2.150930, validation loss = 2.336135
2018-12-05 01:43:35,868 - INFO - epoch 1, step 1880, training loss = 2.217437, validation loss = 2.423556
2018-12-05 01:43:40,073 - INFO - epoch 1, step 1890, training loss = 2.320427, validation loss = 2.600162
2018-12-05 01:43:44,467 - INFO - epoch 1, step 1900, training loss = 2.275095, validation loss = 1.956101
2018-12-05 01:43:48,811 - INFO - epoch 1, step 1910, training loss = 1.783753, validation loss = 1.894704
2018-12-05 01:43:52,813 - INFO - epoch 1, step 1920, training loss = 2.195132, validation loss = 2.160496
2018-12-05 01:43:57,053 - INFO - epoch 1, step 1930, training loss = 2.656204, validation loss = 2.182490
2018-12-05 01:44:01,562 - INFO - epoch 1, step 1940, training loss = 2.134569, validation loss = 2.580146
2018-12-05 01:44:05,823 - INFO - epoch 1, step 1950, training loss = 2.554242, validation loss = 2.176846
2018-12-05 01:44:09,134 - INFO - epoch 1, step 1960, training loss = 2.328579, validation loss = 2.509752
2018-12-05 01:44:12,627 - INFO - epoch 1, step 1970, training loss = 2.150185, validation loss = 1.831156
2018-12-05 01:44:15,970 - INFO - epoch 1, step 1980, training loss = 2.243306, validation loss = 2.160965
2018-12-05 01:44:19,517 - INFO - epoch 1, step 1990, training loss = 2.255767, validation loss = 2.107671
2018-12-05 01:44:22,893 - INFO - epoch 1, step 2000, training loss = 2.322580, validation loss = 2.587705
2018-12-05 01:44:26,162 - INFO - epoch 1, step 2010, training loss = 2.710085, validation loss = 2.734342
2018-12-05 01:44:29,422 - INFO - epoch 1, step 2020, training loss = 2.420941, validation loss = 2.115911
2018-12-05 01:44:32,679 - INFO - epoch 1, step 2030, training loss = 2.319119, validation loss = 2.403684
2018-12-05 01:44:35,936 - INFO - epoch 1, step 2040, training loss = 2.095347, validation loss = 2.385118
2018-12-05 01:44:39,394 - INFO - epoch 1, step 2050, training loss = 2.263959, validation loss = 2.870939
2018-12-05 01:44:42,802 - INFO - epoch 1, step 2060, training loss = 2.448000, validation loss = 2.853121
2018-12-05 01:44:46,338 - INFO - epoch 1, step 2070, training loss = 1.908822, validation loss = 2.014992
2018-12-05 01:44:49,756 - INFO - epoch 1, step 2080, training loss = 2.598459, validation loss = 2.143335
2018-12-05 01:44:53,065 - INFO - epoch 1, step 2090, training loss = 2.099807, validation loss = 2.324802
2018-12-05 01:44:56,539 - INFO - epoch 1, step 2100, training loss = 2.421266, validation loss = 2.693845
2018-12-05 01:45:00,030 - INFO - epoch 1, step 2110, training loss = 2.028681, validation loss = 2.334709
2018-12-05 01:45:03,374 - INFO - epoch 1, step 2120, training loss = 2.188340, validation loss = 2.221373
2018-12-05 01:45:06,942 - INFO - epoch 1, step 2130, training loss = 1.683760, validation loss = 2.222934
2018-12-05 01:45:10,168 - INFO - epoch 1, step 2140, training loss = 2.073701, validation loss = 2.446180
2018-12-05 01:45:13,496 - INFO - epoch 1, step 2150, training loss = 1.605084, validation loss = 2.485507
2018-12-05 01:45:16,972 - INFO - epoch 1, step 2160, training loss = 1.953912, validation loss = 2.652412
2018-12-05 01:45:20,366 - INFO - epoch 1, step 2170, training loss = 2.319864, validation loss = 2.613049
2018-12-05 01:45:23,638 - INFO - epoch 1, step 2180, training loss = 2.603279, validation loss = 2.736998
2018-12-05 01:45:27,278 - INFO - epoch 1, step 2190, training loss = 2.221769, validation loss = 1.904996
2018-12-05 01:45:30,923 - INFO - epoch 1, step 2200, training loss = 2.536310, validation loss = 2.376502
2018-12-05 01:45:34,671 - INFO - epoch 1, step 2210, training loss = 2.222737, validation loss = 2.262526
2018-12-05 01:45:38,377 - INFO - epoch 1, step 2220, training loss = 1.948343, validation loss = 2.538312
2018-12-05 01:45:41,867 - INFO - epoch 1, step 2230, training loss = 2.277496, validation loss = 2.489556
2018-12-05 01:45:45,445 - INFO - epoch 1, step 2240, training loss = 2.582300, validation loss = 2.224247
2018-12-05 01:45:49,114 - INFO - epoch 1, step 2250, training loss = 1.913992, validation loss = 2.232669
2018-12-05 01:45:52,605 - INFO - epoch 1, step 2260, training loss = 2.402895, validation loss = 2.468984
2018-12-05 01:45:56,396 - INFO - epoch 1, step 2270, training loss = 2.056110, validation loss = 2.373800
2018-12-05 01:46:00,052 - INFO - epoch 1, step 2280, training loss = 2.084019, validation loss = 2.236040
2018-12-05 01:46:04,020 - INFO - epoch 1, step 2290, training loss = 2.419066, validation loss = 2.236157
2018-12-05 01:46:08,213 - INFO - epoch 1, step 2300, training loss = 2.205197, validation loss = 2.133253
2018-12-05 01:46:12,224 - INFO - epoch 1, step 2310, training loss = 2.126919, validation loss = 2.435472
2018-12-05 01:46:16,139 - INFO - epoch 1, step 2320, training loss = 2.279090, validation loss = 2.611814
2018-12-05 01:46:20,453 - INFO - epoch 1, step 2330, training loss = 2.124515, validation loss = 1.727070
2018-12-05 01:46:24,354 - INFO - epoch 1, step 2340, training loss = 2.282784, validation loss = 2.082913
2018-12-05 01:46:28,331 - INFO - epoch 1, step 2350, training loss = 2.270504, validation loss = 2.536211
2018-12-05 01:46:32,430 - INFO - epoch 1, step 2360, training loss = 2.229598, validation loss = 2.512014
2018-12-05 01:46:36,399 - INFO - epoch 1, step 2370, training loss = 2.454750, validation loss = 2.705966
2018-12-05 01:46:40,558 - INFO - epoch 1, step 2380, training loss = 2.340588, validation loss = 2.018251
2018-12-05 01:46:44,660 - INFO - epoch 1, step 2390, training loss = 2.030708, validation loss = 1.927044
2018-12-05 01:46:48,736 - INFO - epoch 1, step 2400, training loss = 1.972639, validation loss = 2.199849
2018-12-05 01:46:52,777 - INFO - epoch 1, step 2410, training loss = 2.119314, validation loss = 2.085032
2018-12-05 01:46:57,275 - INFO - epoch 1, step 2420, training loss = 2.185241, validation loss = 2.529675
2018-12-05 01:47:01,003 - INFO - epoch 1, step 2430, training loss = 2.456431, validation loss = 2.775224
2018-12-05 01:47:04,759 - INFO - epoch 1, step 2440, training loss = 2.440414, validation loss = 2.293028
2018-12-05 01:47:08,398 - INFO - epoch 1, step 2450, training loss = 2.060888, validation loss = 2.236498
2018-12-05 01:47:12,031 - INFO - epoch 1, step 2460, training loss = 2.111178, validation loss = 2.285385
2018-12-05 01:47:15,614 - INFO - epoch 1, step 2470, training loss = 2.186150, validation loss = 2.156265
2018-12-05 01:47:19,195 - INFO - epoch 1, step 2480, training loss = 2.179157, validation loss = 2.479258
2018-12-05 01:47:22,907 - INFO - epoch 1, step 2490, training loss = 2.013462, validation loss = 2.051148
2018-12-05 01:47:26,462 - INFO - epoch 1, step 2500, training loss = 2.391235, validation loss = 2.489957
2018-12-05 01:47:30,068 - INFO - epoch 1, step 2510, training loss = 2.016548, validation loss = 1.957622
2018-12-05 01:47:33,600 - INFO - epoch 1, step 2520, training loss = 2.348120, validation loss = 2.074397
2018-12-05 01:47:37,115 - INFO - epoch 1, step 2530, training loss = 1.956853, validation loss = 2.082821
2018-12-05 01:47:40,654 - INFO - epoch 1, step 2540, training loss = 2.131546, validation loss = 2.618587
2018-12-05 01:47:44,164 - INFO - epoch 1, step 2550, training loss = 1.979219, validation loss = 2.345515
2018-12-05 01:47:47,747 - INFO - epoch 1, step 2560, training loss = 2.254851, validation loss = 2.025490
2018-12-05 01:47:51,353 - INFO - epoch 1, step 2570, training loss = 1.848032, validation loss = 1.994549
2018-12-05 01:47:54,909 - INFO - epoch 1, step 2580, training loss = 2.104759, validation loss = 2.309952
2018-12-05 01:47:58,600 - INFO - epoch 1, step 2590, training loss = 1.363799, validation loss = 2.796587
2018-12-05 01:48:02,342 - INFO - epoch 1, step 2600, training loss = 2.117172, validation loss = 2.484449
2018-12-05 01:48:06,118 - INFO - epoch 1, step 2610, training loss = 2.028197, validation loss = 2.197023
2018-12-05 01:48:09,844 - INFO - epoch 1, step 2620, training loss = 1.400109, validation loss = 2.461218
2018-12-05 01:48:13,213 - INFO - epoch 1, step 2630, training loss = 2.086823, validation loss = 2.288573
2018-12-05 01:48:16,682 - INFO - epoch 1, step 2640, training loss = 2.060187, validation loss = 2.893109
2018-12-05 01:48:20,652 - INFO - epoch 1, step 2650, training loss = 2.128959, validation loss = 2.083010
2018-12-05 01:48:24,897 - INFO - epoch 1, step 2660, training loss = 2.136152, validation loss = 2.158229
2018-12-05 01:48:29,125 - INFO - epoch 1, step 2670, training loss = 2.395296, validation loss = 2.155875
2018-12-05 01:48:33,302 - INFO - epoch 1, step 2680, training loss = 2.419871, validation loss = 2.396225
2018-12-05 01:48:37,763 - INFO - epoch 1, step 2690, training loss = 2.044189, validation loss = 2.496008
2018-12-05 01:48:41,925 - INFO - epoch 1, step 2700, training loss = 2.258206, validation loss = 2.355945
2018-12-05 01:48:46,159 - INFO - epoch 1, step 2710, training loss = 2.373166, validation loss = 2.191814
2018-12-05 01:48:50,271 - INFO - epoch 1, step 2720, training loss = 2.080653, validation loss = 1.799949
2018-12-05 01:48:54,421 - INFO - epoch 1, step 2730, training loss = 2.517682, validation loss = 1.847380
2018-12-05 01:48:58,717 - INFO - epoch 1, step 2740, training loss = 2.389238, validation loss = 2.027927
2018-12-05 01:49:02,944 - INFO - epoch 1, step 2750, training loss = 2.054521, validation loss = 2.201715
2018-12-05 01:49:07,144 - INFO - epoch 1, step 2760, training loss = 2.173802, validation loss = 2.172551
2018-12-05 01:49:11,398 - INFO - epoch 1, step 2770, training loss = 2.318865, validation loss = 1.994812
2018-12-05 01:49:15,559 - INFO - epoch 1, step 2780, training loss = 2.294970, validation loss = 1.867450
2018-12-05 01:49:19,713 - INFO - epoch 1, step 2790, training loss = 2.023978, validation loss = 2.295130
2018-12-05 01:49:23,895 - INFO - epoch 1, step 2800, training loss = 2.383375, validation loss = 2.477057
2018-12-05 01:49:27,990 - INFO - epoch 1, step 2810, training loss = 2.316294, validation loss = 2.281601
2018-12-05 01:49:31,871 - INFO - epoch 1, step 2820, training loss = 2.644312, validation loss = 2.266506
2018-12-05 01:49:35,679 - INFO - epoch 1, step 2830, training loss = 2.097490, validation loss = 2.216635
2018-12-05 01:49:39,333 - INFO - epoch 1, step 2840, training loss = 2.351615, validation loss = 2.453801
2018-12-05 01:49:42,791 - INFO - epoch 1, step 2850, training loss = 2.384950, validation loss = 2.549533
2018-12-05 01:49:46,414 - INFO - epoch 1, step 2860, training loss = 2.277891, validation loss = 2.457466
2018-12-05 01:49:49,854 - INFO - epoch 1, step 2870, training loss = 2.226707, validation loss = 1.990800
2018-12-05 01:49:53,437 - INFO - epoch 1, step 2880, training loss = 2.041050, validation loss = 2.300674
2018-12-05 01:49:57,177 - INFO - epoch 1, step 2890, training loss = 2.028477, validation loss = 2.402424
2018-12-05 01:50:00,784 - INFO - epoch 1, step 2900, training loss = 2.183930, validation loss = 2.263018
2018-12-05 01:50:04,613 - INFO - epoch 1, step 2910, training loss = 2.058089, validation loss = 1.951941
2018-12-05 01:50:08,358 - INFO - epoch 1, step 2920, training loss = 1.806107, validation loss = 2.015288
2018-12-05 01:50:12,012 - INFO - epoch 1, step 2930, training loss = 1.816671, validation loss = 2.470053
2018-12-05 01:50:15,677 - INFO - epoch 1, step 2940, training loss = 2.473173, validation loss = 2.845439
2018-12-05 01:50:19,945 - INFO - epoch 1, step 2950, training loss = 2.148087, validation loss = 2.490587
2018-12-05 01:50:24,305 - INFO - epoch 1, step 2960, training loss = 1.704688, validation loss = 2.232015
2018-12-05 01:50:28,565 - INFO - epoch 1, step 2970, training loss = 2.238899, validation loss = 2.613170
2018-12-05 01:50:32,880 - INFO - epoch 1, step 2980, training loss = 2.224921, validation loss = 2.455602
2018-12-05 01:50:37,331 - INFO - epoch 1, step 2990, training loss = 2.305860, validation loss = 2.199767
2018-12-05 01:50:41,702 - INFO - epoch 1, step 3000, training loss = 2.045693, validation loss = 2.130076
2018-12-05 01:50:46,170 - INFO - epoch 1, step 3010, training loss = 2.170760, validation loss = 2.314858
2018-12-05 01:50:50,487 - INFO - epoch 1, step 3020, training loss = 2.380366, validation loss = 2.381189
2018-12-05 01:50:54,836 - INFO - epoch 1, step 3030, training loss = 2.310094, validation loss = 2.012401
2018-12-05 01:50:58,906 - INFO - epoch 1, step 3040, training loss = 2.364863, validation loss = 1.736395
2018-12-05 01:51:03,068 - INFO - epoch 1, step 3050, training loss = 1.875577, validation loss = 2.127037
2018-12-05 01:51:07,242 - INFO - epoch 1, step 3060, training loss = 2.255682, validation loss = 2.322400
2018-12-05 01:51:11,632 - INFO - epoch 1, step 3070, training loss = 2.147815, validation loss = 2.862113
2018-12-05 01:51:15,747 - INFO - epoch 1, step 3080, training loss = 2.083843, validation loss = 2.042037
2018-12-05 01:51:19,964 - INFO - epoch 1, step 3090, training loss = 2.103468, validation loss = 2.127113
2018-12-05 01:51:23,974 - INFO - epoch 1, step 3100, training loss = 2.120585, validation loss = 2.448988
2018-12-05 01:51:28,023 - INFO - epoch 1, step 3110, training loss = 2.359078, validation loss = 2.585372
2018-12-05 01:51:32,166 - INFO - epoch 1, step 3120, training loss = 1.980733, validation loss = 2.571332
2018-12-05 01:51:36,300 - INFO - epoch 1, step 3130, training loss = 2.499791, validation loss = 2.370627
2018-12-05 01:51:40,371 - INFO - epoch 1, step 3140, training loss = 1.891268, validation loss = 1.892357
2018-12-05 01:51:44,575 - INFO - epoch 1, step 3150, training loss = 1.988685, validation loss = 2.342854
2018-12-05 01:51:48,747 - INFO - epoch 1, step 3160, training loss = 2.213027, validation loss = 2.705980
2018-12-05 01:51:52,952 - INFO - epoch 1, step 3170, training loss = 1.853500, validation loss = 2.455357
2018-12-05 01:51:57,119 - INFO - epoch 1, step 3180, training loss = 2.166949, validation loss = 1.948127
2018-12-05 01:52:01,316 - INFO - epoch 1, step 3190, training loss = 1.908932, validation loss = 1.855874
2018-12-05 01:52:05,477 - INFO - epoch 1, step 3200, training loss = 2.217960, validation loss = 2.549830
2018-12-05 01:52:09,810 - INFO - epoch 1, step 3210, training loss = 1.945905, validation loss = 2.487213
2018-12-05 01:52:14,055 - INFO - epoch 1, step 3220, training loss = 2.509026, validation loss = 2.611572
2018-12-05 01:52:18,404 - INFO - epoch 1, step 3230, training loss = 2.201455, validation loss = 2.506898
2018-12-05 01:52:22,668 - INFO - epoch 1, step 3240, training loss = 2.139117, validation loss = 2.538171
2018-12-05 01:52:27,152 - INFO - epoch 1, step 3250, training loss = 2.027927, validation loss = 2.116801
2018-12-05 01:52:31,247 - INFO - epoch 1, step 3260, training loss = 2.158369, validation loss = 2.339333
2018-12-05 01:52:35,350 - INFO - epoch 1, step 3270, training loss = 2.360973, validation loss = 2.433641
2018-12-05 01:52:39,270 - INFO - epoch 1, step 3280, training loss = 2.556919, validation loss = 2.421169
2018-12-05 01:52:42,832 - INFO - epoch 1, step 3290, training loss = 2.427380, validation loss = 1.994396
2018-12-05 01:52:46,632 - INFO - epoch 1, step 3300, training loss = 2.068030, validation loss = 2.207468
2018-12-05 01:52:50,445 - INFO - epoch 1, step 3310, training loss = 1.888299, validation loss = 2.324725
2018-12-05 01:52:54,369 - INFO - epoch 1, step 3320, training loss = 2.245318, validation loss = 2.540948
2018-12-05 01:52:58,023 - INFO - epoch 1, step 3330, training loss = 2.425047, validation loss = 2.445643
2018-12-05 01:53:01,720 - INFO - epoch 1, step 3340, training loss = 1.830520, validation loss = 2.095194
2018-12-05 01:53:05,610 - INFO - epoch 1, step 3350, training loss = 1.904638, validation loss = 2.112065
2018-12-05 01:53:09,267 - INFO - epoch 1, step 3360, training loss = 2.432662, validation loss = 2.267337
2018-12-05 01:53:13,193 - INFO - epoch 1, step 3370, training loss = 2.230673, validation loss = 1.783563
2018-12-05 01:53:17,312 - INFO - epoch 1, step 3380, training loss = 2.238648, validation loss = 2.444908
2018-12-05 01:53:21,123 - INFO - epoch 1, step 3390, training loss = 2.001124, validation loss = 2.176254
2018-12-05 01:53:24,911 - INFO - epoch 1, step 3400, training loss = 2.539295, validation loss = 2.066211
2018-12-05 01:53:28,935 - INFO - epoch 1, step 3410, training loss = 2.381765, validation loss = 2.492168
2018-12-05 01:53:32,886 - INFO - epoch 1, step 3420, training loss = 1.964398, validation loss = 2.233843
2018-12-05 01:53:37,155 - INFO - epoch 1, step 3430, training loss = 2.035561, validation loss = 2.160001
2018-12-05 01:53:40,950 - INFO - epoch 1, step 3440, training loss = 1.931622, validation loss = 2.246412
2018-12-05 01:53:44,850 - INFO - epoch 1, step 3450, training loss = 2.111042, validation loss = 1.618593
2018-12-05 01:53:49,024 - INFO - epoch 1, step 3460, training loss = 2.564943, validation loss = 2.027316
2018-12-05 01:53:53,148 - INFO - epoch 1, step 3470, training loss = 1.409227, validation loss = 2.685497
2018-12-05 01:53:56,777 - INFO - epoch 1, step 3480, training loss = 2.202541, validation loss = 1.974967
2018-12-05 01:54:00,680 - INFO - epoch 1, step 3490, training loss = 2.220279, validation loss = 1.769652
2018-12-05 01:54:04,461 - INFO - epoch 1, step 3500, training loss = 1.989338, validation loss = 2.044751
2018-12-05 01:54:08,296 - INFO - epoch 1, step 3510, training loss = 1.618891, validation loss = 2.262294
2018-12-05 01:54:12,026 - INFO - epoch 1, step 3520, training loss = 2.067244, validation loss = 2.212471
2018-12-05 01:54:15,963 - INFO - epoch 1, step 3530, training loss = 1.961673, validation loss = 2.169561
2018-12-05 01:54:19,542 - INFO - epoch 1, step 3540, training loss = 1.991526, validation loss = 1.955659
2018-12-05 01:54:23,193 - INFO - epoch 1, step 3550, training loss = 1.844388, validation loss = 2.608189
2018-12-05 01:54:26,900 - INFO - epoch 1, step 3560, training loss = 2.541297, validation loss = 2.237713
2018-12-05 01:54:30,520 - INFO - epoch 1, step 3570, training loss = 2.210272, validation loss = 2.423719
2018-12-05 01:54:34,286 - INFO - epoch 1, step 3580, training loss = 1.948005, validation loss = 2.079313
2018-12-05 01:54:38,101 - INFO - epoch 1, step 3590, training loss = 1.716473, validation loss = 2.059672
2018-12-05 01:54:41,850 - INFO - epoch 1, step 3600, training loss = 2.204210, validation loss = 1.797644
2018-12-05 01:54:45,849 - INFO - epoch 1, step 3610, training loss = 1.963625, validation loss = 1.855377
2018-12-05 01:54:49,464 - INFO - epoch 1, step 3620, training loss = 1.753602, validation loss = 2.119953
2018-12-05 01:54:53,197 - INFO - epoch 1, step 3630, training loss = 2.365443, validation loss = 2.001343
2018-12-05 01:54:57,107 - INFO - epoch 1, step 3640, training loss = 2.111244, validation loss = 2.098809
2018-12-05 01:55:00,726 - INFO - epoch 1, step 3650, training loss = 2.006206, validation loss = 1.932901
2018-12-05 01:55:04,730 - INFO - epoch 1, step 3660, training loss = 2.333326, validation loss = 1.885299
2018-12-05 01:55:08,624 - INFO - epoch 1, step 3670, training loss = 2.597719, validation loss = 2.291852
2018-12-05 01:55:12,197 - INFO - epoch 1, step 3680, training loss = 2.255093, validation loss = 2.197782
2018-12-05 01:55:15,694 - INFO - epoch 1, step 3690, training loss = 2.169952, validation loss = 2.031521
2018-12-05 01:55:19,986 - INFO - epoch 1, step 3700, training loss = 2.268461, validation loss = 2.155916
2018-12-05 01:55:23,619 - INFO - epoch 1, step 3710, training loss = 2.036709, validation loss = 2.201329
2018-12-05 01:55:27,178 - INFO - epoch 1, step 3720, training loss = 2.311830, validation loss = 2.107852
2018-12-05 01:55:30,831 - INFO - epoch 1, step 3730, training loss = 2.575406, validation loss = 1.794967
2018-12-05 01:55:34,653 - INFO - epoch 1, step 3740, training loss = 1.818844, validation loss = 2.001357
2018-12-05 01:55:37,935 - INFO - epoch 1, step 3750, training loss = 2.409842, validation loss = 2.349118
2018-12-05 01:55:41,387 - INFO - epoch 1, step 3760, training loss = 2.231592, validation loss = 2.130530
2018-12-05 01:55:44,758 - INFO - epoch 1, step 3770, training loss = 2.386969, validation loss = 1.724447
2018-12-05 01:55:48,139 - INFO - epoch 1, step 3780, training loss = 1.697387, validation loss = 2.383910
2018-12-05 01:55:51,275 - INFO - epoch 1, step 3790, training loss = 2.143471, validation loss = 2.537089
2018-12-05 01:55:54,448 - INFO - epoch 1, step 3800, training loss = 1.747178, validation loss = 2.221464
2018-12-05 01:55:57,842 - INFO - epoch 1, step 3810, training loss = 1.811340, validation loss = 1.804373
2018-12-05 01:56:01,323 - INFO - epoch 1, step 3820, training loss = 2.126375, validation loss = 2.199917
2018-12-05 01:56:04,746 - INFO - epoch 1, step 3830, training loss = 2.171302, validation loss = 2.302069
2018-12-05 01:56:08,067 - INFO - epoch 1, step 3840, training loss = 2.013026, validation loss = 2.236465
2018-12-05 01:56:11,398 - INFO - epoch 1, step 3850, training loss = 2.281063, validation loss = 2.048627
2018-12-05 01:56:14,881 - INFO - epoch 1, step 3860, training loss = 2.343864, validation loss = 2.154920
2018-12-05 01:56:18,196 - INFO - epoch 1, step 3870, training loss = 2.094523, validation loss = 2.051786
2018-12-05 01:56:21,803 - INFO - epoch 1, step 3880, training loss = 2.136658, validation loss = 2.519308
2018-12-05 01:56:25,978 - INFO - epoch 1, step 3890, training loss = 2.116017, validation loss = 2.291559
2018-12-05 01:56:30,051 - INFO - epoch 1, step 3900, training loss = 2.005410, validation loss = 1.952511
2018-12-05 01:56:34,340 - INFO - epoch 1, step 3910, training loss = 2.156547, validation loss = 2.425009
2018-12-05 01:56:38,486 - INFO - epoch 1, step 3920, training loss = 2.201964, validation loss = 2.599304
2018-12-05 01:56:42,623 - INFO - epoch 1, step 3930, training loss = 2.462919, validation loss = 2.582844
2018-12-05 01:56:46,834 - INFO - epoch 1, step 3940, training loss = 1.934810, validation loss = 2.058280
2018-12-05 01:56:50,812 - INFO - epoch 1, step 3950, training loss = 2.332063, validation loss = 2.475643
2018-12-05 01:56:54,637 - INFO - epoch 1, step 3960, training loss = 2.184556, validation loss = 2.172705
2018-12-05 01:56:58,413 - INFO - epoch 1, step 3970, training loss = 2.435312, validation loss = 2.053396
2018-12-05 01:57:02,562 - INFO - epoch 1, step 3980, training loss = 2.492845, validation loss = 2.161218
2018-12-05 01:57:06,581 - INFO - epoch 1, step 3990, training loss = 2.160085, validation loss = 2.534208
2018-12-05 01:57:10,758 - INFO - epoch 1, step 4000, training loss = 2.201689, validation loss = 2.098925
2018-12-05 01:57:14,864 - INFO - epoch 1, step 4010, training loss = 2.054161, validation loss = 2.007826
2018-12-05 01:57:18,443 - INFO - epoch 1, step 4020, training loss = 2.532228, validation loss = 2.218547
2018-12-05 01:57:21,863 - INFO - epoch 1, step 4030, training loss = 2.907766, validation loss = 2.219415
2018-12-05 01:57:25,136 - INFO - epoch 1, step 4040, training loss = 2.631976, validation loss = 2.047000
2018-12-05 01:57:28,729 - INFO - epoch 1, step 4050, training loss = 2.425291, validation loss = 2.082847
2018-12-05 01:57:32,164 - INFO - epoch 1, step 4060, training loss = 2.623394, validation loss = 2.062335
2018-12-05 01:57:35,471 - INFO - epoch 1, step 4070, training loss = 2.639006, validation loss = 2.441668
2018-12-05 01:57:38,908 - INFO - epoch 1, step 4080, training loss = 1.682465, validation loss = 2.410652
2018-12-05 01:57:42,773 - INFO - epoch 1, step 4090, training loss = 1.336806, validation loss = 2.145832
2018-12-05 01:57:46,372 - INFO - epoch 1, step 4100, training loss = 1.971429, validation loss = 1.876512
2018-12-05 01:57:50,159 - INFO - epoch 1, step 4110, training loss = 2.276650, validation loss = 2.249764
2018-12-05 01:57:53,889 - INFO - epoch 1, step 4120, training loss = 2.194046, validation loss = 2.431745
2018-12-05 01:57:57,636 - INFO - epoch 1, step 4130, training loss = 2.118831, validation loss = 2.184667
2018-12-05 01:58:01,242 - INFO - epoch 1, step 4140, training loss = 1.922859, validation loss = 2.131298
2018-12-05 01:58:04,854 - INFO - epoch 1, step 4150, training loss = 2.374564, validation loss = 2.124841
2018-12-05 01:58:08,394 - INFO - epoch 1, step 4160, training loss = 2.157411, validation loss = 2.646726
2018-12-05 01:58:11,907 - INFO - epoch 1, step 4170, training loss = 2.330215, validation loss = 2.037086
2018-12-05 01:58:15,616 - INFO - epoch 1, step 4180, training loss = 2.067760, validation loss = 2.135259
2018-12-05 01:58:19,199 - INFO - epoch 1, step 4190, training loss = 2.268125, validation loss = 2.499537
2018-12-05 01:58:22,584 - INFO - epoch 1, step 4200, training loss = 2.455416, validation loss = 2.385426
2018-12-05 01:58:26,117 - INFO - epoch 1, step 4210, training loss = 1.822857, validation loss = 1.921015
2018-12-05 01:58:29,753 - INFO - epoch 1, step 4220, training loss = 2.247868, validation loss = 2.476732
2018-12-05 01:58:33,425 - INFO - epoch 1, step 4230, training loss = 1.893194, validation loss = 2.446356
2018-12-05 01:58:37,263 - INFO - epoch 1, step 4240, training loss = 1.903760, validation loss = 2.203783
2018-12-05 01:58:41,152 - INFO - epoch 1, step 4250, training loss = 2.136013, validation loss = 2.537334
2018-12-05 01:58:45,016 - INFO - epoch 1, step 4260, training loss = 2.158870, validation loss = 2.334888
2018-12-05 01:58:48,608 - INFO - epoch 1, step 4270, training loss = 2.044372, validation loss = 2.248768
2018-12-05 01:58:52,444 - INFO - epoch 1, step 4280, training loss = 2.440543, validation loss = 2.631137
2018-12-05 01:58:56,076 - INFO - epoch 1, step 4290, training loss = 2.012920, validation loss = 1.893770
2018-12-05 01:58:59,763 - INFO - epoch 1, step 4300, training loss = 2.097761, validation loss = 2.693307
2018-12-05 01:59:03,254 - INFO - epoch 1, step 4310, training loss = 2.195342, validation loss = 2.468560
2018-12-05 01:59:06,853 - INFO - epoch 1, step 4320, training loss = 2.262159, validation loss = 2.447424
2018-12-05 01:59:10,771 - INFO - epoch 1, step 4330, training loss = 2.176738, validation loss = 2.268629
2018-12-05 01:59:14,729 - INFO - epoch 1, step 4340, training loss = 2.058218, validation loss = 2.016455
2018-12-05 01:59:18,683 - INFO - epoch 1, step 4350, training loss = 2.359559, validation loss = 2.166746
2018-12-05 01:59:22,410 - INFO - epoch 1, step 4360, training loss = 1.756664, validation loss = 2.349175
2018-12-05 01:59:26,193 - INFO - epoch 1, step 4370, training loss = 2.492963, validation loss = 2.255836
2018-12-05 01:59:29,898 - INFO - epoch 1, step 4380, training loss = 2.248546, validation loss = 2.214406
2018-12-05 01:59:33,389 - INFO - epoch 1, step 4390, training loss = 2.306250, validation loss = 2.637374
2018-12-05 01:59:37,064 - INFO - epoch 1, step 4400, training loss = 2.602412, validation loss = 1.806451
2018-12-05 01:59:40,603 - INFO - epoch 1, step 4410, training loss = 2.350245, validation loss = 2.195937
2018-12-05 01:59:44,429 - INFO - epoch 1, step 4420, training loss = 2.074168, validation loss = 2.647127
2018-12-05 01:59:48,110 - INFO - epoch 1, step 4430, training loss = 2.147515, validation loss = 2.399692
2018-12-05 01:59:52,085 - INFO - epoch 1, step 4440, training loss = 2.334309, validation loss = 2.507002
2018-12-05 01:59:55,700 - INFO - epoch 1, step 4450, training loss = 2.233346, validation loss = 2.232232
2018-12-05 01:59:59,297 - INFO - epoch 1, step 4460, training loss = 1.983799, validation loss = 1.963657
2018-12-05 02:00:03,079 - INFO - epoch 1, step 4470, training loss = 1.401486, validation loss = 2.299959
2018-12-05 02:00:06,709 - INFO - epoch 1, step 4480, training loss = 2.677297, validation loss = 2.198239
2018-12-05 02:00:10,112 - INFO - epoch 1, step 4490, training loss = 2.497801, validation loss = 2.320493
2018-12-05 02:00:13,715 - INFO - epoch 1, step 4500, training loss = 1.954034, validation loss = 2.510845
2018-12-05 02:00:17,524 - INFO - epoch 1, step 4510, training loss = 1.915439, validation loss = 2.220398
2018-12-05 02:00:21,181 - INFO - epoch 1, step 4520, training loss = 2.014640, validation loss = 2.463556
2018-12-05 02:00:24,783 - INFO - epoch 1, step 4530, training loss = 1.774518, validation loss = 2.535541
2018-12-05 02:00:28,569 - INFO - epoch 1, step 4540, training loss = 1.924240, validation loss = 2.272644
2018-12-05 02:00:32,102 - INFO - epoch 1, step 4550, training loss = 1.969900, validation loss = 2.511838
2018-12-05 02:00:35,736 - INFO - epoch 1, step 4560, training loss = 2.439306, validation loss = 2.776568
2018-12-05 02:00:39,377 - INFO - epoch 1, step 4570, training loss = 2.040458, validation loss = 2.531129
2018-12-05 02:00:42,825 - INFO - epoch 1, step 4580, training loss = 2.079560, validation loss = 2.064164
2018-12-05 02:00:46,230 - INFO - epoch 1, step 4590, training loss = 2.216051, validation loss = 2.668351
2018-12-05 02:00:49,816 - INFO - epoch 1, step 4600, training loss = 2.231055, validation loss = 2.282190
2018-12-05 02:00:53,583 - INFO - epoch 1, step 4610, training loss = 1.902440, validation loss = 2.355021
2018-12-05 02:00:57,192 - INFO - epoch 1, step 4620, training loss = 1.960001, validation loss = 2.367153
2018-12-05 02:01:00,816 - INFO - epoch 1, step 4630, training loss = 1.827447, validation loss = 2.778618
2018-12-05 02:01:04,611 - INFO - epoch 1, step 4640, training loss = 2.414929, validation loss = 1.769300
2018-12-05 02:01:08,133 - INFO - epoch 1, step 4650, training loss = 2.306304, validation loss = 2.567394
2018-12-05 02:01:12,118 - INFO - epoch 1, step 4660, training loss = 2.175476, validation loss = 2.129217
2018-12-05 02:01:16,435 - INFO - epoch 1, step 4670, training loss = 2.042414, validation loss = 2.402543
2018-12-05 02:01:20,959 - INFO - epoch 1, step 4680, training loss = 2.034991, validation loss = 2.269249
2018-12-05 02:01:24,942 - INFO - epoch 1, step 4690, training loss = 2.714297, validation loss = 2.295424
2018-12-05 02:01:29,283 - INFO - epoch 1, step 4700, training loss = 2.465929, validation loss = 2.710313
2018-12-05 02:01:33,303 - INFO - epoch 1, step 4710, training loss = 2.542491, validation loss = 2.064886
2018-12-05 02:01:37,508 - INFO - epoch 1, step 4720, training loss = 2.311977, validation loss = 2.145449
2018-12-05 02:01:41,836 - INFO - epoch 1, step 4730, training loss = 2.286823, validation loss = 2.339350
2018-12-05 02:01:46,044 - INFO - epoch 1, step 4740, training loss = 2.211134, validation loss = 2.380095
2018-12-05 02:01:50,224 - INFO - epoch 1, step 4750, training loss = 2.467989, validation loss = 2.649527
2018-12-05 02:01:54,458 - INFO - epoch 1, step 4760, training loss = 1.998189, validation loss = 2.440125
2018-12-05 02:01:58,582 - INFO - epoch 1, step 4770, training loss = 2.559665, validation loss = 2.199774
2018-12-05 02:02:03,022 - INFO - epoch 1, step 4780, training loss = 2.151838, validation loss = 2.567038
2018-12-05 02:02:07,021 - INFO - epoch 1, step 4790, training loss = 2.097505, validation loss = 2.028495
2018-12-05 02:02:10,889 - INFO - epoch 1, step 4800, training loss = 1.885299, validation loss = 2.598891
2018-12-05 02:02:14,663 - INFO - epoch 1, step 4810, training loss = 1.997692, validation loss = 2.139220
2018-12-05 02:02:18,623 - INFO - epoch 1, step 4820, training loss = 1.907657, validation loss = 1.944188
2018-12-05 02:02:22,366 - INFO - epoch 1, step 4830, training loss = 2.379884, validation loss = 2.473917
2018-12-05 02:02:26,371 - INFO - epoch 1, step 4840, training loss = 2.413886, validation loss = 2.518321
2018-12-05 02:02:30,415 - INFO - epoch 1, step 4850, training loss = 2.179204, validation loss = 2.358140
2018-12-05 02:02:34,350 - INFO - epoch 1, step 4860, training loss = 2.048152, validation loss = 2.508533
2018-12-05 02:02:38,246 - INFO - epoch 1, step 4870, training loss = 2.086083, validation loss = 2.486708
2018-12-05 02:02:42,116 - INFO - epoch 1, step 4880, training loss = 2.807394, validation loss = 2.300160
2018-12-05 02:02:45,496 - INFO - epoch 1, step 4890, training loss = 2.547070, validation loss = 2.571277
2018-12-05 02:02:48,915 - INFO - epoch 1, step 4900, training loss = 2.461206, validation loss = 2.412890
2018-12-05 02:02:52,185 - INFO - epoch 1, step 4910, training loss = 2.537764, validation loss = 2.626469
2018-12-05 02:02:55,514 - INFO - epoch 1, step 4920, training loss = 2.077132, validation loss = 2.475997
2018-12-05 02:02:58,849 - INFO - epoch 1, step 4930, training loss = 2.442596, validation loss = 2.096642
2018-12-05 02:03:02,139 - INFO - epoch 1, step 4940, training loss = 2.358987, validation loss = 2.811253
2018-12-05 02:03:05,513 - INFO - epoch 1, step 4950, training loss = 2.213048, validation loss = 2.598031
2018-12-05 02:03:08,990 - INFO - epoch 1, step 4960, training loss = 1.881416, validation loss = 2.637620
2018-12-05 02:03:12,542 - INFO - epoch 1, step 4970, training loss = 2.471814, validation loss = 2.504497
2018-12-05 02:03:15,979 - INFO - epoch 1, step 4980, training loss = 2.195184, validation loss = 2.462396
2018-12-05 02:03:19,294 - INFO - epoch 1, step 4990, training loss = 2.421073, validation loss = 2.265611
2018-12-05 02:03:22,885 - INFO - epoch 1, step 5000, training loss = 2.137069, validation loss = 2.358963
2018-12-05 02:03:27,477 - INFO - epoch 1, step 5010, training loss = 1.807762, validation loss = 2.712772
2018-12-05 02:03:31,749 - INFO - epoch 1, step 5020, training loss = 2.524967, validation loss = 2.610980
2018-12-05 02:03:35,920 - INFO - epoch 1, step 5030, training loss = 2.130000, validation loss = 2.188163
2018-12-05 02:03:40,149 - INFO - epoch 1, step 5040, training loss = 1.405339, validation loss = 2.261578
2018-12-05 02:03:44,107 - INFO - epoch 1, step 5050, training loss = 2.031537, validation loss = 2.318632
2018-12-05 02:03:48,127 - INFO - epoch 1, step 5060, training loss = 2.144459, validation loss = 2.462200
2018-12-05 02:03:52,459 - INFO - epoch 1, step 5070, training loss = 2.367510, validation loss = 2.215644
2018-12-05 02:03:56,686 - INFO - epoch 1, step 5080, training loss = 1.684953, validation loss = 2.319933
2018-12-05 02:04:00,823 - INFO - epoch 1, step 5090, training loss = 2.044228, validation loss = 2.482975
2018-12-05 02:04:05,019 - INFO - epoch 1, step 5100, training loss = 1.848049, validation loss = 2.394507
2018-12-05 02:04:09,027 - INFO - epoch 1, step 5110, training loss = 1.998476, validation loss = 2.469008
2018-12-05 02:04:12,824 - INFO - epoch 1, step 5120, training loss = 2.035268, validation loss = 2.235913
2018-12-05 02:04:16,747 - INFO - epoch 1, step 5130, training loss = 2.004514, validation loss = 2.437922
2018-12-05 02:04:20,451 - INFO - epoch 1, step 5140, training loss = 2.112425, validation loss = 2.326151
2018-12-05 02:04:24,260 - INFO - epoch 1, step 5150, training loss = 2.171958, validation loss = 2.207649
2018-12-05 02:04:27,902 - INFO - epoch 1, step 5160, training loss = 1.701795, validation loss = 2.101770
2018-12-05 02:04:31,505 - INFO - epoch 1, step 5170, training loss = 2.070851, validation loss = 2.546582
2018-12-05 02:04:35,190 - INFO - epoch 1, step 5180, training loss = 2.083892, validation loss = 2.287741
2018-12-05 02:04:38,961 - INFO - epoch 1, step 5190, training loss = 1.860882, validation loss = 2.324489
2018-12-05 02:04:42,536 - INFO - epoch 1, step 5200, training loss = 1.789104, validation loss = 2.184914
2018-12-05 02:04:46,737 - INFO - epoch 1, step 5210, training loss = 1.990801, validation loss = 2.246043
2018-12-05 02:04:50,599 - INFO - epoch 1, step 5220, training loss = 2.332631, validation loss = 2.440578
2018-12-05 02:04:54,624 - INFO - epoch 1, step 5230, training loss = 2.227928, validation loss = 2.428277
2018-12-05 02:04:58,719 - INFO - epoch 1, step 5240, training loss = 2.092892, validation loss = 2.290533
2018-12-05 02:05:02,825 - INFO - epoch 1, step 5250, training loss = 2.414459, validation loss = 2.166675
2018-12-05 02:05:06,904 - INFO - epoch 1, step 5260, training loss = 2.437793, validation loss = 2.556882
2018-12-05 02:05:11,086 - INFO - epoch 1, step 5270, training loss = 2.643698, validation loss = 2.407110
2018-12-05 02:05:15,180 - INFO - epoch 1, step 5280, training loss = 2.011257, validation loss = 2.503500
2018-12-05 02:05:19,372 - INFO - epoch 1, step 5290, training loss = 2.051011, validation loss = 2.640477
2018-12-05 02:05:23,356 - INFO - epoch 1, step 5300, training loss = 2.355441, validation loss = 2.284394
2018-12-05 02:05:27,668 - INFO - epoch 1, step 5310, training loss = 2.093432, validation loss = 2.538920
2018-12-05 02:05:31,469 - INFO - epoch 1, step 5320, training loss = 2.067169, validation loss = 2.502049
2018-12-05 02:05:35,076 - INFO - epoch 1, step 5330, training loss = 2.531391, validation loss = 2.385353
2018-12-05 02:05:38,866 - INFO - epoch 1, step 5340, training loss = 2.154985, validation loss = 2.243765
2018-12-05 02:05:42,605 - INFO - epoch 1, step 5350, training loss = 1.740135, validation loss = 2.460613
2018-12-05 02:05:46,392 - INFO - epoch 1, step 5360, training loss = 2.100518, validation loss = 2.309166
2018-12-05 02:05:50,248 - INFO - epoch 1, step 5370, training loss = 2.266714, validation loss = 2.453557
2018-12-05 02:05:54,168 - INFO - epoch 1, step 5380, training loss = 2.180313, validation loss = 2.055694
2018-12-05 02:05:58,023 - INFO - epoch 1, step 5390, training loss = 2.176764, validation loss = 2.449531
2018-12-05 02:06:01,974 - INFO - epoch 1, step 5400, training loss = 2.188746, validation loss = 2.277491
2018-12-05 02:06:05,762 - INFO - epoch 1, step 5410, training loss = 2.017883, validation loss = 2.429127
2018-12-05 02:06:09,587 - INFO - epoch 1, step 5420, training loss = 2.197945, validation loss = 2.375641
2018-12-05 02:06:13,460 - INFO - epoch 1, step 5430, training loss = 2.305009, validation loss = 2.051654
2018-12-05 02:06:17,252 - INFO - epoch 1, step 5440, training loss = 1.809293, validation loss = 2.348278
2018-12-05 02:06:20,850 - INFO - epoch 1, step 5450, training loss = 2.022754, validation loss = 2.425150
2018-12-05 02:06:24,405 - INFO - epoch 1, step 5460, training loss = 2.055422, validation loss = 2.240130
2018-12-05 02:06:28,189 - INFO - epoch 1, step 5470, training loss = 2.340082, validation loss = 2.190234
2018-12-05 02:06:31,871 - INFO - epoch 1, step 5480, training loss = 1.988464, validation loss = 2.310287
2018-12-05 02:06:35,463 - INFO - epoch 1, step 5490, training loss = 2.340654, validation loss = 2.540781
2018-12-05 02:06:39,194 - INFO - epoch 1, step 5500, training loss = 2.263668, validation loss = 2.391023
2018-12-05 02:06:42,967 - INFO - epoch 1, step 5510, training loss = 2.115451, validation loss = 2.408563
2018-12-05 02:06:46,679 - INFO - epoch 1, step 5520, training loss = 2.119598, validation loss = 2.671329
2018-12-05 02:06:50,317 - INFO - epoch 1, step 5530, training loss = 1.952792, validation loss = 2.812616
2018-12-05 02:06:54,306 - INFO - epoch 1, step 5540, training loss = 1.761358, validation loss = 2.438650
2018-12-05 02:06:58,178 - INFO - epoch 1, step 5550, training loss = 2.236899, validation loss = 2.591628
2018-12-05 02:07:02,159 - INFO - epoch 1, step 5560, training loss = 2.071466, validation loss = 2.595865
2018-12-05 02:07:06,055 - INFO - epoch 1, step 5570, training loss = 2.024494, validation loss = 2.188489
2018-12-05 02:07:09,842 - INFO - epoch 1, step 5580, training loss = 2.064811, validation loss = 2.033406
2018-12-05 02:07:13,716 - INFO - epoch 1, step 5590, training loss = 1.782279, validation loss = 2.124378
2018-12-05 02:07:17,649 - INFO - epoch 1, step 5600, training loss = 1.918859, validation loss = 2.165595
2018-12-05 02:07:21,681 - INFO - epoch 1, step 5610, training loss = 2.375492, validation loss = 2.178032
2018-12-05 02:07:25,585 - INFO - epoch 1, step 5620, training loss = 2.423498, validation loss = 2.341808
2018-12-05 02:07:29,792 - INFO - epoch 1, step 5630, training loss = 2.057039, validation loss = 1.886736
2018-12-05 02:07:34,012 - INFO - epoch 1, step 5640, training loss = 2.078005, validation loss = 2.546512
2018-12-05 02:07:38,333 - INFO - epoch 1, step 5650, training loss = 2.122328, validation loss = 2.320564
2018-12-05 02:07:42,599 - INFO - epoch 1, step 5660, training loss = 2.102551, validation loss = 2.597872
2018-12-05 02:07:46,745 - INFO - epoch 1, step 5670, training loss = 2.150963, validation loss = 2.344112
2018-12-05 02:07:51,030 - INFO - epoch 1, step 5680, training loss = 1.903023, validation loss = 2.304056
2018-12-05 02:07:55,329 - INFO - epoch 1, step 5690, training loss = 2.121242, validation loss = 1.963788
2018-12-05 02:07:59,510 - INFO - epoch 1, step 5700, training loss = 2.384265, validation loss = 1.947865
2018-12-05 02:08:03,793 - INFO - epoch 1, step 5710, training loss = 2.081947, validation loss = 2.812304
2018-12-05 02:08:07,781 - INFO - epoch 1, step 5720, training loss = 2.126375, validation loss = 2.442208
2018-12-05 02:08:12,068 - INFO - epoch 1, step 5730, training loss = 2.251589, validation loss = 1.763077
2018-12-05 02:08:16,238 - INFO - epoch 1, step 5740, training loss = 2.262990, validation loss = 2.360878
2018-12-05 02:08:20,566 - INFO - epoch 1, step 5750, training loss = 2.305231, validation loss = 1.940119
2018-12-05 02:08:25,018 - INFO - epoch 1, step 5760, training loss = 2.330237, validation loss = 2.477621
2018-12-05 02:08:29,276 - INFO - epoch 1, step 5770, training loss = 1.708953, validation loss = 2.744652
2018-12-05 02:08:33,383 - INFO - epoch 1, step 5780, training loss = 2.154106, validation loss = 1.890692
2018-12-05 02:08:37,662 - INFO - epoch 1, step 5790, training loss = 2.444367, validation loss = 2.360568
2018-12-05 02:08:41,908 - INFO - epoch 1, step 5800, training loss = 2.049741, validation loss = 2.429155
2018-12-05 02:08:46,248 - INFO - epoch 1, step 5810, training loss = 2.060313, validation loss = 2.492241
2018-12-05 02:08:50,590 - INFO - epoch 1, step 5820, training loss = 1.871190, validation loss = 2.072074
2018-12-05 02:08:54,967 - INFO - epoch 1, step 5830, training loss = 2.086247, validation loss = 2.558459
2018-12-05 02:08:59,203 - INFO - epoch 1, step 5840, training loss = 2.068957, validation loss = 1.993639
2018-12-05 02:09:02,538 - INFO - epoch 1, step 5850, training loss = 2.333840, validation loss = 2.337330
2018-12-05 02:09:06,002 - INFO - epoch 1, step 5860, training loss = 2.392646, validation loss = 2.096853
2018-12-05 02:09:09,320 - INFO - epoch 1, step 5870, training loss = 1.975812, validation loss = 2.699466
2018-12-05 02:09:12,815 - INFO - epoch 1, step 5880, training loss = 2.264878, validation loss = 2.465739
2018-12-05 02:09:16,115 - INFO - epoch 1, step 5890, training loss = 2.181683, validation loss = 2.543534
2018-12-05 02:09:19,491 - INFO - epoch 1, step 5900, training loss = 2.221866, validation loss = 2.482039
2018-12-05 02:09:22,951 - INFO - epoch 1, step 5910, training loss = 2.421658, validation loss = 2.430951
2018-12-05 02:09:26,183 - INFO - epoch 1, step 5920, training loss = 2.639013, validation loss = 2.239931
2018-12-05 02:09:29,485 - INFO - epoch 1, step 5930, training loss = 1.692630, validation loss = 1.921723
2018-12-05 02:09:32,949 - INFO - epoch 1, step 5940, training loss = 1.944299, validation loss = 2.612807
2018-12-05 02:09:36,202 - INFO - epoch 1, step 5950, training loss = 2.036206, validation loss = 2.315885
2018-12-05 02:09:39,526 - INFO - epoch 1, step 5960, training loss = 2.453349, validation loss = 2.433804
2018-12-05 02:09:43,608 - INFO - epoch 1, step 5970, training loss = 2.282667, validation loss = 2.135061
2018-12-05 02:09:47,787 - INFO - epoch 1, step 5980, training loss = 1.966996, validation loss = 2.387653
2018-12-05 02:09:52,163 - INFO - epoch 1, step 5990, training loss = 2.299121, validation loss = 2.400405
2018-12-05 02:09:56,439 - INFO - epoch 1, step 6000, training loss = 2.167454, validation loss = 1.899513
2018-12-05 02:10:00,557 - INFO - epoch 1, step 6010, training loss = 1.829193, validation loss = 1.922124
2018-12-05 02:10:04,952 - INFO - epoch 1, step 6020, training loss = 2.079174, validation loss = 2.420551
2018-12-05 02:10:09,329 - INFO - epoch 1, step 6030, training loss = 2.268527, validation loss = 1.950012
2018-12-05 02:10:13,455 - INFO - epoch 1, step 6040, training loss = 2.079563, validation loss = 2.509812
2018-12-05 02:10:17,940 - INFO - epoch 1, step 6050, training loss = 2.067281, validation loss = 2.434577
2018-12-05 02:10:22,160 - INFO - epoch 1, step 6060, training loss = 2.350110, validation loss = 2.231328
2018-12-05 02:10:26,416 - INFO - epoch 1, step 6070, training loss = 2.419119, validation loss = 2.705767
2018-12-05 02:10:30,711 - INFO - epoch 1, step 6080, training loss = 1.946769, validation loss = 2.640217
2018-12-05 02:10:34,872 - INFO - epoch 1, step 6090, training loss = 2.280315, validation loss = 2.101531
2018-12-05 02:10:39,062 - INFO - epoch 1, step 6100, training loss = 2.331443, validation loss = 2.783021
2018-12-05 02:10:43,348 - INFO - epoch 1, step 6110, training loss = 1.847907, validation loss = 2.467840
2018-12-05 02:10:48,292 - INFO - epoch 1, step 6120, training loss = 2.284528, validation loss = 2.889099
2018-12-05 02:10:52,497 - INFO - epoch 1, step 6130, training loss = 1.797429, validation loss = 2.239605
2018-12-05 02:10:56,518 - INFO - epoch 1, step 6140, training loss = 2.358842, validation loss = 1.993342
2018-12-05 02:11:00,688 - INFO - epoch 1, step 6150, training loss = 2.076642, validation loss = 2.109675
2018-12-05 02:11:04,939 - INFO - epoch 1, step 6160, training loss = 2.131156, validation loss = 2.308449
2018-12-05 02:11:09,128 - INFO - epoch 1, step 6170, training loss = 2.218945, validation loss = 2.380364
2018-12-05 02:11:13,356 - INFO - epoch 1, step 6180, training loss = 1.940782, validation loss = 2.940143
2018-12-05 02:11:17,513 - INFO - epoch 1, step 6190, training loss = 2.100276, validation loss = 2.485009
2018-12-05 02:11:21,885 - INFO - epoch 1, step 6200, training loss = 2.665988, validation loss = 2.105684
2018-12-05 02:11:26,068 - INFO - epoch 1, step 6210, training loss = 2.196569, validation loss = 1.978915
2018-12-05 02:11:30,539 - INFO - epoch 1, step 6220, training loss = 2.231272, validation loss = 2.377330
2018-12-05 02:11:34,767 - INFO - epoch 1, step 6230, training loss = 1.757713, validation loss = 1.894601
2018-12-05 02:11:38,814 - INFO - epoch 1, step 6240, training loss = 2.103381, validation loss = 2.555973
2018-12-05 02:11:42,912 - INFO - epoch 1, step 6250, training loss = 1.800208, validation loss = 2.747233
2018-12-05 02:11:47,084 - INFO - epoch 1, step 6260, training loss = 2.406934, validation loss = 2.223453
2018-12-05 02:11:51,280 - INFO - epoch 1, step 6270, training loss = 2.109581, validation loss = 2.633409
2018-12-05 02:11:55,103 - INFO - epoch 1, step 6280, training loss = 2.245123, validation loss = 2.682483
2018-12-05 02:11:59,153 - INFO - epoch 1, step 6290, training loss = 1.762755, validation loss = 2.606637
2018-12-05 02:12:02,932 - INFO - epoch 1, step 6300, training loss = 2.402058, validation loss = 2.017436
2018-12-05 02:12:06,779 - INFO - epoch 1, step 6310, training loss = 1.684511, validation loss = 2.623164
2018-12-05 02:12:10,694 - INFO - epoch 1, step 6320, training loss = 2.237200, validation loss = 2.736535
2018-12-05 02:12:14,389 - INFO - epoch 1, step 6330, training loss = 2.193427, validation loss = 2.526683
2018-12-05 02:12:18,217 - INFO - epoch 1, step 6340, training loss = 2.678118, validation loss = 2.146019
2018-12-05 02:12:21,989 - INFO - epoch 1, step 6350, training loss = 1.951096, validation loss = 2.345756
2018-12-05 02:12:25,577 - INFO - epoch 1, step 6360, training loss = 2.069917, validation loss = 2.845371
2018-12-05 02:12:29,322 - INFO - epoch 1, step 6370, training loss = 2.711762, validation loss = 2.621588
2018-12-05 02:12:33,045 - INFO - epoch 1, step 6380, training loss = 2.152022, validation loss = 2.449354
2018-12-05 02:12:36,905 - INFO - epoch 1, step 6390, training loss = 1.545973, validation loss = 2.219254
2018-12-05 02:12:40,682 - INFO - epoch 1, step 6400, training loss = 2.150934, validation loss = 2.777843
2018-12-05 02:12:44,381 - INFO - epoch 1, step 6410, training loss = 2.081747, validation loss = 2.879626
2018-12-05 02:12:48,281 - INFO - epoch 1, step 6420, training loss = 1.824204, validation loss = 2.113495
2018-12-05 02:12:52,074 - INFO - epoch 1, step 6430, training loss = 1.674113, validation loss = 2.315363
2018-12-05 02:12:55,800 - INFO - epoch 1, step 6440, training loss = 2.501816, validation loss = 2.876607
2018-12-05 02:12:59,592 - INFO - epoch 1, step 6450, training loss = 2.111148, validation loss = 2.730445
2018-12-05 02:13:03,186 - INFO - epoch 1, step 6460, training loss = 2.224892, validation loss = 2.578676
2018-12-05 02:13:06,868 - INFO - epoch 1, step 6470, training loss = 1.726753, validation loss = 2.762237
2018-12-05 02:13:10,342 - INFO - epoch 1, step 6480, training loss = 2.159936, validation loss = 2.708305
2018-12-05 02:13:14,214 - INFO - epoch 1, step 6490, training loss = 1.684376, validation loss = 3.347631
2018-12-05 02:13:17,954 - INFO - epoch 1, step 6500, training loss = 2.028619, validation loss = 2.438118
2018-12-05 02:13:21,627 - INFO - epoch 1, step 6510, training loss = 2.037215, validation loss = 2.361161
2018-12-05 02:13:25,273 - INFO - epoch 1, step 6520, training loss = 2.084116, validation loss = 2.268311
2018-12-05 02:13:28,921 - INFO - epoch 1, step 6530, training loss = 2.604667, validation loss = 2.495185
2018-12-05 02:13:32,461 - INFO - epoch 1, step 6540, training loss = 1.957015, validation loss = 2.920074
2018-12-05 02:13:36,180 - INFO - epoch 1, step 6550, training loss = 2.048013, validation loss = 2.781277
2018-12-05 02:13:39,833 - INFO - epoch 1, step 6560, training loss = 2.178839, validation loss = 2.544046
2018-12-05 02:13:43,368 - INFO - epoch 1, step 6570, training loss = 2.427512, validation loss = 1.807354
2018-12-05 02:13:46,911 - INFO - epoch 1, step 6580, training loss = 2.154846, validation loss = 3.144662
2018-12-05 02:13:50,620 - INFO - epoch 1, step 6590, training loss = 2.271145, validation loss = 2.412826
2018-12-05 02:13:54,132 - INFO - epoch 1, step 6600, training loss = 2.253285, validation loss = 2.899293
2018-12-05 02:13:57,832 - INFO - epoch 1, step 6610, training loss = 1.931809, validation loss = 2.520646
2018-12-05 02:14:01,505 - INFO - epoch 1, step 6620, training loss = 2.127416, validation loss = 2.727324
2018-12-05 02:14:05,436 - INFO - epoch 1, step 6630, training loss = 2.178910, validation loss = 2.596108
2018-12-05 02:14:09,142 - INFO - epoch 1, step 6640, training loss = 2.210630, validation loss = 2.773942
2018-12-05 02:14:12,845 - INFO - epoch 1, step 6650, training loss = 2.221693, validation loss = 2.806986
2018-12-05 02:14:16,755 - INFO - epoch 1, step 6660, training loss = 1.933323, validation loss = 2.303048
2018-12-05 02:14:20,649 - INFO - epoch 1, step 6670, training loss = 2.133419, validation loss = 2.543826
2018-12-05 02:14:24,300 - INFO - epoch 1, step 6680, training loss = 2.047358, validation loss = 2.461930
2018-12-05 02:14:28,405 - INFO - epoch 1, step 6690, training loss = 2.275774, validation loss = 2.560089
2018-12-05 02:14:32,103 - INFO - epoch 1, step 6700, training loss = 2.514471, validation loss = 2.991867
2018-12-05 02:14:35,886 - INFO - epoch 1, step 6710, training loss = 1.706543, validation loss = 2.431453
2018-12-05 02:14:39,522 - INFO - epoch 1, step 6720, training loss = 2.318661, validation loss = 2.317867
2018-12-05 02:14:43,333 - INFO - epoch 1, step 6730, training loss = 2.101950, validation loss = 2.991507
2018-12-05 02:14:46,987 - INFO - epoch 1, step 6740, training loss = 2.032762, validation loss = 3.004770
2018-12-05 02:14:51,041 - INFO - epoch 1, step 6750, training loss = 2.103388, validation loss = 2.987556
2018-12-05 02:14:54,794 - INFO - epoch 1, step 6760, training loss = 2.261217, validation loss = 2.434349
2018-12-05 02:14:58,479 - INFO - epoch 1, step 6770, training loss = 2.139262, validation loss = 2.338685
2018-12-05 02:15:02,095 - INFO - epoch 1, step 6780, training loss = 2.311832, validation loss = 2.747128
2018-12-05 02:15:05,782 - INFO - epoch 1, step 6790, training loss = 1.785140, validation loss = 2.598361
2018-12-05 02:15:09,413 - INFO - epoch 1, step 6800, training loss = 2.113283, validation loss = 2.596355
2018-12-05 02:15:13,100 - INFO - epoch 1, step 6810, training loss = 2.307948, validation loss = 2.302038
2018-12-05 02:15:16,725 - INFO - epoch 1, step 6820, training loss = 1.755723, validation loss = 2.647298
2018-12-05 02:15:20,600 - INFO - epoch 1, step 6830, training loss = 2.204970, validation loss = 2.757762
2018-12-05 02:15:24,104 - INFO - epoch 1, step 6840, training loss = 2.031121, validation loss = 2.585072
2018-12-05 02:15:27,668 - INFO - epoch 1, step 6850, training loss = 1.938031, validation loss = 2.612776
2018-12-05 02:15:31,225 - INFO - epoch 1, step 6860, training loss = 2.169636, validation loss = 3.151529
2018-12-05 02:15:34,828 - INFO - epoch 1, step 6870, training loss = 2.487071, validation loss = 2.620649
2018-12-05 02:15:38,633 - INFO - epoch 1, step 6880, training loss = 2.110483, validation loss = 2.625832
2018-12-05 02:15:42,284 - INFO - epoch 1, step 6890, training loss = 2.408230, validation loss = 2.563308
2018-12-05 02:15:45,990 - INFO - epoch 1, step 6900, training loss = 1.741230, validation loss = 2.660832
2018-12-05 02:15:50,239 - INFO - epoch 1, step 6910, training loss = 2.411248, validation loss = 2.817157
2018-12-05 02:15:54,072 - INFO - epoch 1, step 6920, training loss = 2.579769, validation loss = 2.585464
2018-12-05 02:15:58,166 - INFO - epoch 1, step 6930, training loss = 2.045316, validation loss = 2.511631
2018-12-05 02:16:01,922 - INFO - epoch 1, step 6940, training loss = 2.310651, validation loss = 2.944847
2018-12-05 02:16:05,811 - INFO - epoch 1, step 6950, training loss = 2.299865, validation loss = 2.373778
2018-12-05 02:16:09,784 - INFO - epoch 1, step 6960, training loss = 2.381638, validation loss = 2.802930
2018-12-05 02:16:13,720 - INFO - epoch 1, step 6970, training loss = 1.994338, validation loss = 2.408161
2018-12-05 02:16:17,755 - INFO - epoch 1, step 6980, training loss = 1.880366, validation loss = 2.645869
2018-12-05 02:16:21,981 - INFO - epoch 1, step 6990, training loss = 2.131506, validation loss = 2.727116
2018-12-05 02:16:26,150 - INFO - epoch 1, step 7000, training loss = 2.211003, validation loss = 2.446177
2018-12-05 02:16:30,620 - INFO - epoch 1, step 7010, training loss = 2.148562, validation loss = 2.721342
2018-12-05 02:16:34,771 - INFO - epoch 1, step 7020, training loss = 1.724631, validation loss = 2.662159
2018-12-05 02:16:39,005 - INFO - epoch 1, step 7030, training loss = 2.190644, validation loss = 2.955957
2018-12-05 02:16:43,334 - INFO - epoch 1, step 7040, training loss = 1.901353, validation loss = 2.940859
2018-12-05 02:16:47,792 - INFO - epoch 1, step 7050, training loss = 1.935967, validation loss = 2.907780
2018-12-05 02:16:51,941 - INFO - epoch 1, step 7060, training loss = 2.811994, validation loss = 2.418131
2018-12-05 02:16:55,865 - INFO - epoch 1, step 7070, training loss = 2.242677, validation loss = 2.722839
2018-12-05 02:17:00,168 - INFO - epoch 1, step 7080, training loss = 2.196331, validation loss = 2.134630
2018-12-05 02:17:04,411 - INFO - epoch 1, step 7090, training loss = 1.937506, validation loss = 2.350920
2018-12-05 02:17:08,493 - INFO - epoch 1, step 7100, training loss = 2.409813, validation loss = 2.624207
2018-12-05 02:17:12,516 - INFO - epoch 1, step 7110, training loss = 1.731048, validation loss = 2.659053
2018-12-05 02:17:16,710 - INFO - epoch 1, step 7120, training loss = 2.296125, validation loss = 2.360403
2018-12-05 02:17:20,999 - INFO - epoch 1, step 7130, training loss = 1.849740, validation loss = 2.601873
2018-12-05 02:17:25,275 - INFO - epoch 1, step 7140, training loss = 2.097791, validation loss = 2.803606
2018-12-05 02:17:29,431 - INFO - epoch 1, step 7150, training loss = 1.787662, validation loss = 2.311146
2018-12-05 02:17:33,307 - INFO - epoch 1, step 7160, training loss = 2.453157, validation loss = 2.497290
2018-12-05 02:17:37,394 - INFO - epoch 1, step 7170, training loss = 2.016130, validation loss = 2.486209
2018-12-05 02:17:41,375 - INFO - epoch 1, step 7180, training loss = 2.080187, validation loss = 2.857996
2018-12-05 02:17:45,759 - INFO - epoch 1, step 7190, training loss = 2.047398, validation loss = 3.047398
2018-12-05 02:17:49,851 - INFO - epoch 1, step 7200, training loss = 1.893455, validation loss = 2.954301
2018-12-05 02:17:54,465 - INFO - epoch 1, step 7210, training loss = 2.288246, validation loss = 2.782690
2018-12-05 02:17:58,784 - INFO - epoch 1, step 7220, training loss = 2.052911, validation loss = 3.274868
2018-12-05 02:18:02,351 - INFO - epoch 1, step 7230, training loss = 2.258443, validation loss = 2.678817
2018-12-05 02:18:05,903 - INFO - epoch 1, step 7240, training loss = 2.046103, validation loss = 2.668486
2018-12-05 02:18:09,536 - INFO - epoch 1, step 7250, training loss = 1.930362, validation loss = 3.064065
2018-12-05 02:18:13,021 - INFO - epoch 1, step 7260, training loss = 2.560592, validation loss = 2.979247
2018-12-05 02:18:16,799 - INFO - epoch 1, step 7270, training loss = 2.132062, validation loss = 2.362018
2018-12-05 02:18:20,358 - INFO - epoch 1, step 7280, training loss = 2.254128, validation loss = 2.802276
2018-12-05 02:18:24,046 - INFO - epoch 1, step 7290, training loss = 2.063519, validation loss = 2.451155
2018-12-05 02:18:27,822 - INFO - epoch 1, step 7300, training loss = 1.788592, validation loss = 2.772751
2018-12-05 02:18:31,706 - INFO - epoch 1, step 7310, training loss = 1.808700, validation loss = 2.497262
2018-12-05 02:18:35,510 - INFO - epoch 1, step 7320, training loss = 2.238038, validation loss = 2.672807
2018-12-05 02:18:39,147 - INFO - epoch 1, step 7330, training loss = 2.488202, validation loss = 2.790473
2018-12-05 02:18:42,943 - INFO - epoch 1, step 7340, training loss = 2.016788, validation loss = 2.221285
2018-12-05 02:18:46,809 - INFO - epoch 1, step 7350, training loss = 2.229559, validation loss = 2.626562
2018-12-05 02:18:50,461 - INFO - epoch 1, step 7360, training loss = 2.298591, validation loss = 3.163710
2018-12-05 02:18:53,888 - INFO - epoch 1, step 7370, training loss = 2.250028, validation loss = 2.296627
2018-12-05 02:18:57,596 - INFO - epoch 1, step 7380, training loss = 2.252677, validation loss = 2.545213
2018-12-05 02:19:01,198 - INFO - epoch 1, step 7390, training loss = 2.114426, validation loss = 3.210185
2018-12-05 02:19:05,050 - INFO - epoch 1, step 7400, training loss = 2.147434, validation loss = 2.384239
2018-12-05 02:19:08,739 - INFO - epoch 1, step 7410, training loss = 1.902879, validation loss = 2.847000
2018-12-05 02:19:12,238 - INFO - epoch 1, step 7420, training loss = 2.056403, validation loss = 2.581805
2018-12-05 02:19:15,390 - INFO - epoch 1, step 7430, training loss = 2.020872, validation loss = 2.951658
2018-12-05 02:19:18,814 - INFO - epoch 1, step 7440, training loss = 1.879382, validation loss = 3.048731
2018-12-05 02:19:22,196 - INFO - epoch 1, step 7450, training loss = 2.368522, validation loss = 3.393627
2018-12-05 02:19:25,461 - INFO - epoch 1, step 7460, training loss = 1.658667, validation loss = 3.219218
2018-12-05 02:19:28,799 - INFO - epoch 1, step 7470, training loss = 2.169628, validation loss = 3.249081
2018-12-05 02:19:32,170 - INFO - epoch 1, step 7480, training loss = 2.107308, validation loss = 2.970667
2018-12-05 02:19:35,453 - INFO - epoch 1, step 7490, training loss = 2.320285, validation loss = 2.528306
2018-12-05 02:19:38,820 - INFO - epoch 1, step 7500, training loss = 1.671682, validation loss = 2.766582
2018-12-05 02:19:42,333 - INFO - epoch 1, step 7510, training loss = 1.815706, validation loss = 3.490141
2018-12-05 02:19:45,697 - INFO - epoch 1, step 7520, training loss = 1.305653, validation loss = 2.685099
2018-12-05 02:19:49,159 - INFO - epoch 1, step 7530, training loss = 2.122544, validation loss = 3.191672
2018-12-05 02:19:52,479 - INFO - epoch 1, step 7540, training loss = 2.315422, validation loss = 2.109841
2018-12-05 02:19:55,805 - INFO - epoch 1, step 7550, training loss = 1.986356, validation loss = 2.967034
2018-12-05 02:19:59,619 - INFO - epoch 1, step 7560, training loss = 1.820595, validation loss = 2.834743
2018-12-05 02:20:03,215 - INFO - epoch 1, step 7570, training loss = 2.163930, validation loss = 3.062043
2018-12-05 02:20:06,699 - INFO - epoch 1, step 7580, training loss = 2.080339, validation loss = 2.509879
2018-12-05 02:20:10,359 - INFO - epoch 1, step 7590, training loss = 2.074135, validation loss = 2.851591
2018-12-05 02:20:13,993 - INFO - epoch 1, step 7600, training loss = 2.231922, validation loss = 3.013175
2018-12-05 02:20:17,538 - INFO - epoch 1, step 7610, training loss = 1.844520, validation loss = 2.860256
2018-12-05 02:20:21,302 - INFO - epoch 1, step 7620, training loss = 2.201875, validation loss = 3.135865
2018-12-05 02:20:25,244 - INFO - epoch 1, step 7630, training loss = 2.154994, validation loss = 3.215486
2018-12-05 02:20:29,000 - INFO - epoch 1, step 7640, training loss = 1.677965, validation loss = 2.650841
2018-12-05 02:20:32,707 - INFO - epoch 1, step 7650, training loss = 1.968077, validation loss = 2.991930
2018-12-05 02:20:36,325 - INFO - epoch 1, step 7660, training loss = 2.004799, validation loss = 2.947456
2018-12-05 02:20:39,983 - INFO - epoch 1, step 7670, training loss = 1.845046, validation loss = 2.980852
2018-12-05 02:20:43,684 - INFO - epoch 1, step 7680, training loss = 1.987365, validation loss = 3.212081
2018-12-05 02:20:47,484 - INFO - epoch 1, step 7690, training loss = 1.611054, validation loss = 3.324817
2018-12-05 02:20:51,151 - INFO - epoch 1, step 7700, training loss = 1.861707, validation loss = 3.146476
2018-12-05 02:20:54,869 - INFO - epoch 1, step 7710, training loss = 2.195032, validation loss = 2.665587
2018-12-05 02:20:58,600 - INFO - epoch 1, step 7720, training loss = 2.101526, validation loss = 2.891233
2018-12-05 02:21:02,217 - INFO - epoch 1, step 7730, training loss = 2.122936, validation loss = 3.092126
2018-12-05 02:21:05,893 - INFO - epoch 1, step 7740, training loss = 2.515344, validation loss = 3.106275
2018-12-05 02:21:09,632 - INFO - epoch 1, step 7750, training loss = 1.848036, validation loss = 3.104825
2018-12-05 02:21:13,437 - INFO - epoch 1, step 7760, training loss = 2.256351, validation loss = 2.913795
2018-12-05 02:21:17,105 - INFO - epoch 1, step 7770, training loss = 2.312795, validation loss = 3.242850
2018-12-05 02:21:20,883 - INFO - epoch 1, step 7780, training loss = 2.045497, validation loss = 3.083827
2018-12-05 02:21:24,698 - INFO - epoch 1, step 7790, training loss = 2.316554, validation loss = 2.667805
2018-12-05 02:21:28,364 - INFO - epoch 1, step 7800, training loss = 2.469361, validation loss = 3.109655
2018-12-05 02:21:32,180 - INFO - epoch 1, step 7810, training loss = 1.884512, validation loss = 2.876307
2018-12-05 02:21:35,926 - INFO - epoch 1, step 7820, training loss = 2.513809, validation loss = 3.137539
2018-12-05 02:21:39,903 - INFO - epoch 1, step 7830, training loss = 2.192980, validation loss = 2.640233
2018-12-05 02:21:43,695 - INFO - epoch 1, step 7840, training loss = 2.265649, validation loss = 2.906924
2018-12-05 02:21:47,772 - INFO - epoch 1, step 7850, training loss = 2.126918, validation loss = 3.071093
2018-12-05 02:21:51,561 - INFO - epoch 1, step 7860, training loss = 2.018380, validation loss = 3.389766
2018-12-05 02:21:55,417 - INFO - epoch 1, step 7870, training loss = 2.036889, validation loss = 2.626022
2018-12-05 02:21:59,371 - INFO - epoch 1, step 7880, training loss = 1.660149, validation loss = 2.747019
2018-12-05 02:22:03,284 - INFO - epoch 1, step 7890, training loss = 2.106081, validation loss = 2.417307
2018-12-05 02:22:07,328 - INFO - epoch 1, step 7900, training loss = 1.965221, validation loss = 2.318147
2018-12-05 02:22:11,224 - INFO - epoch 1, step 7910, training loss = 2.361931, validation loss = 3.244241
2018-12-05 02:22:15,564 - INFO - epoch 1, step 7920, training loss = 2.110066, validation loss = 2.649712
2018-12-05 02:22:19,356 - INFO - epoch 1, step 7930, training loss = 2.314163, validation loss = 2.629369
2018-12-05 02:22:23,297 - INFO - epoch 1, step 7940, training loss = 1.524595, validation loss = 2.647043
2018-12-05 02:22:27,319 - INFO - epoch 1, step 7950, training loss = 1.835608, validation loss = 3.211974
2018-12-05 02:22:31,450 - INFO - epoch 1, step 7960, training loss = 1.861169, validation loss = 3.384439
2018-12-05 02:22:35,641 - INFO - epoch 1, step 7970, training loss = 1.662013, validation loss = 3.309183
2018-12-05 02:22:39,765 - INFO - epoch 1, step 7980, training loss = 1.975092, validation loss = 2.868536
2018-12-05 02:22:43,831 - INFO - epoch 1, step 7990, training loss = 1.928717, validation loss = 2.914107
2018-12-05 02:22:47,749 - INFO - epoch 1, step 8000, training loss = 2.232966, validation loss = 2.932105
2018-12-05 02:22:52,077 - INFO - epoch 1, step 8010, training loss = 2.469011, validation loss = 2.544329
2018-12-05 02:22:56,247 - INFO - epoch 1, step 8020, training loss = 1.647356, validation loss = 2.996524
2018-12-05 02:23:00,500 - INFO - epoch 1, step 8030, training loss = 2.482022, validation loss = 3.094401
2018-12-05 02:23:04,879 - INFO - epoch 1, step 8040, training loss = 2.186944, validation loss = 2.547824
2018-12-05 02:23:09,018 - INFO - epoch 1, step 8050, training loss = 1.930866, validation loss = 2.836411
2018-12-05 02:23:13,213 - INFO - epoch 1, step 8060, training loss = 2.310366, validation loss = 2.653383
2018-12-05 02:23:17,458 - INFO - epoch 1, step 8070, training loss = 1.902551, validation loss = 2.723875
2018-12-05 02:23:21,669 - INFO - epoch 1, step 8080, training loss = 2.094208, validation loss = 3.053780
2018-12-05 02:23:25,657 - INFO - epoch 1, step 8090, training loss = 1.829561, validation loss = 3.441571
2018-12-05 02:23:30,020 - INFO - epoch 1, step 8100, training loss = 2.048440, validation loss = 3.118603
2018-12-05 02:23:34,177 - INFO - epoch 1, step 8110, training loss = 2.291196, validation loss = 2.967522
2018-12-05 02:23:38,457 - INFO - epoch 1, step 8120, training loss = 2.260931, validation loss = 2.781719
2018-12-05 02:23:42,922 - INFO - epoch 1, step 8130, training loss = 2.371790, validation loss = 2.934812
2018-12-05 02:23:47,145 - INFO - epoch 1, step 8140, training loss = 2.047130, validation loss = 2.927554
2018-12-05 02:23:51,678 - INFO - epoch 1, step 8150, training loss = 2.276440, validation loss = 2.447805
2018-12-05 02:23:55,836 - INFO - epoch 1, step 8160, training loss = 2.191366, validation loss = 2.986210
2018-12-05 02:24:00,096 - INFO - epoch 1, step 8170, training loss = 2.314614, validation loss = 3.439185
2018-12-05 02:24:04,450 - INFO - epoch 1, step 8180, training loss = 2.064191, validation loss = 3.266104
2018-12-05 02:24:08,832 - INFO - epoch 1, step 8190, training loss = 2.245903, validation loss = 3.462649
2018-12-05 02:24:13,093 - INFO - epoch 1, step 8200, training loss = 2.478445, validation loss = 2.599183
2018-12-05 02:24:17,196 - INFO - epoch 1, step 8210, training loss = 2.113214, validation loss = 3.221086
2018-12-05 02:24:21,343 - INFO - epoch 1, step 8220, training loss = 1.973946, validation loss = 3.056674
2018-12-05 02:24:25,668 - INFO - epoch 1, step 8230, training loss = 1.885943, validation loss = 2.474654
2018-12-05 02:24:29,811 - INFO - epoch 1, step 8240, training loss = 2.162974, validation loss = 3.021962
2018-12-05 02:24:33,760 - INFO - epoch 1, step 8250, training loss = 2.343701, validation loss = 2.729382
2018-12-05 02:24:37,537 - INFO - epoch 1, step 8260, training loss = 2.195515, validation loss = 2.682477
2018-12-05 02:24:41,417 - INFO - epoch 1, step 8270, training loss = 1.990981, validation loss = 3.213297
2018-12-05 02:24:45,264 - INFO - epoch 1, step 8280, training loss = 2.161157, validation loss = 2.719693
2018-12-05 02:24:48,977 - INFO - epoch 1, step 8290, training loss = 1.980034, validation loss = 3.412158
2018-12-05 02:24:52,640 - INFO - epoch 1, step 8300, training loss = 2.277724, validation loss = 2.977136
2018-12-05 02:24:56,121 - INFO - epoch 1, step 8310, training loss = 2.230027, validation loss = 2.368731
2018-12-05 02:24:59,488 - INFO - epoch 1, step 8320, training loss = 2.119339, validation loss = 3.080395
2018-12-05 02:25:02,850 - INFO - epoch 1, step 8330, training loss = 2.790886, validation loss = 3.179566
2018-12-05 02:25:06,348 - INFO - epoch 1, step 8340, training loss = 2.063601, validation loss = 2.769916
2018-12-05 02:25:09,764 - INFO - epoch 1, step 8350, training loss = 2.045052, validation loss = 2.980530
2018-12-05 02:25:13,099 - INFO - epoch 1, step 8360, training loss = 2.068173, validation loss = 2.687255
2018-12-05 02:25:16,312 - INFO - epoch 1, step 8370, training loss = 2.125552, validation loss = 3.193405
2018-12-05 02:25:19,790 - INFO - epoch 1, step 8380, training loss = 2.276145, validation loss = 3.179111
2018-12-05 02:25:23,313 - INFO - epoch 1, step 8390, training loss = 1.809959, validation loss = 3.298784
2018-12-05 02:25:26,768 - INFO - epoch 1, step 8400, training loss = 2.294009, validation loss = 2.720592
2018-12-05 02:25:30,155 - INFO - epoch 1, step 8410, training loss = 1.541900, validation loss = 3.560208
2018-12-05 02:25:34,092 - INFO - epoch 1, step 8420, training loss = 2.332452, validation loss = 2.584354
2018-12-05 02:25:38,314 - INFO - epoch 1, step 8430, training loss = 2.220855, validation loss = 3.266596
2018-12-05 02:25:42,613 - INFO - epoch 1, step 8440, training loss = 1.313903, validation loss = 2.283905
2018-12-05 02:25:46,601 - INFO - epoch 1, step 8450, training loss = 2.007802, validation loss = 3.004278
2018-12-05 02:25:50,758 - INFO - epoch 1, step 8460, training loss = 2.080609, validation loss = 2.664944
2018-12-05 02:25:54,909 - INFO - epoch 1, step 8470, training loss = 2.034360, validation loss = 2.455510
2018-12-05 02:25:58,959 - INFO - epoch 1, step 8480, training loss = 2.134351, validation loss = 2.661009
2018-12-05 02:26:02,880 - INFO - epoch 1, step 8490, training loss = 2.459566, validation loss = 2.727523
2018-12-05 02:26:06,986 - INFO - epoch 1, step 8500, training loss = 1.946193, validation loss = 2.946948
2018-12-05 02:26:11,119 - INFO - epoch 1, step 8510, training loss = 2.369083, validation loss = 2.809368
2018-12-05 02:26:15,133 - INFO - epoch 1, step 8520, training loss = 2.285246, validation loss = 2.704142
2018-12-05 02:26:18,382 - INFO - epoch 1, step 8530, training loss = 1.929832, validation loss = 2.418710
2018-12-05 02:26:21,640 - INFO - epoch 1, step 8540, training loss = 1.979993, validation loss = 2.994030
2018-12-05 02:26:25,183 - INFO - epoch 1, step 8550, training loss = 2.314879, validation loss = 3.097193
2018-12-05 02:26:28,650 - INFO - epoch 1, step 8560, training loss = 2.427627, validation loss = 2.664690
2018-12-05 02:26:32,357 - INFO - epoch 1, step 8570, training loss = 2.183341, validation loss = 2.380570
2018-12-05 02:26:35,769 - INFO - epoch 1, step 8580, training loss = 2.602223, validation loss = 2.866706
2018-12-05 02:26:39,199 - INFO - epoch 1, step 8590, training loss = 1.952436, validation loss = 3.144482
2018-12-05 02:26:42,570 - INFO - epoch 1, step 8600, training loss = 1.794877, validation loss = 2.868621
2018-12-05 02:26:46,123 - INFO - epoch 1, step 8610, training loss = 1.524524, validation loss = 1.957220
2018-12-05 02:26:49,552 - INFO - epoch 1, step 8620, training loss = 1.799936, validation loss = 2.293776
2018-12-05 02:26:53,071 - INFO - epoch 1, step 8630, training loss = 2.199193, validation loss = 2.337996
2018-12-05 02:26:56,400 - INFO - epoch 1, step 8640, training loss = 1.835505, validation loss = 2.864361
2018-12-05 02:26:59,759 - INFO - epoch 1, step 8650, training loss = 2.075573, validation loss = 2.184379
2018-12-05 02:27:03,305 - INFO - epoch 1, step 8660, training loss = 2.405481, validation loss = 2.889061
2018-12-05 02:27:07,081 - INFO - epoch 1, step 8670, training loss = 1.962545, validation loss = 2.648944
2018-12-05 02:27:10,716 - INFO - epoch 1, step 8680, training loss = 2.149165, validation loss = 2.294261
2018-12-05 02:27:14,221 - INFO - epoch 1, step 8690, training loss = 2.600438, validation loss = 2.715340
2018-12-05 02:27:17,853 - INFO - epoch 1, step 8700, training loss = 2.330782, validation loss = 3.531849
2018-12-05 02:27:21,626 - INFO - epoch 1, step 8710, training loss = 1.988262, validation loss = 2.610764
2018-12-05 02:27:25,415 - INFO - epoch 1, step 8720, training loss = 2.163700, validation loss = 2.721178
2018-12-05 02:27:28,931 - INFO - epoch 1, step 8730, training loss = 2.015506, validation loss = 2.618764
2018-12-05 02:27:32,508 - INFO - epoch 1, step 8740, training loss = 2.273734, validation loss = 2.425602
2018-12-05 02:27:36,197 - INFO - epoch 1, step 8750, training loss = 2.342365, validation loss = 2.268674
2018-12-05 02:27:40,642 - INFO - epoch 1, step 8760, training loss = 2.214305, validation loss = 1.898555
2018-12-05 02:27:44,095 - INFO - epoch 1, step 8770, training loss = 1.967983, validation loss = 2.240605
2018-12-05 02:27:47,423 - INFO - epoch 1, step 8780, training loss = 1.951594, validation loss = 2.660018
2018-12-05 02:27:50,801 - INFO - epoch 1, step 8790, training loss = 2.480842, validation loss = 2.679607
2018-12-05 02:27:54,120 - INFO - epoch 1, step 8800, training loss = 1.907274, validation loss = 2.637382
2018-12-05 02:27:57,539 - INFO - epoch 1, step 8810, training loss = 2.116101, validation loss = 2.652155
2018-12-05 02:28:01,096 - INFO - epoch 1, step 8820, training loss = 2.366369, validation loss = 2.869581
2018-12-05 02:28:04,414 - INFO - epoch 1, step 8830, training loss = 1.824142, validation loss = 2.910512
2018-12-05 02:28:07,857 - INFO - epoch 1, step 8840, training loss = 2.366615, validation loss = 2.781437
2018-12-05 02:28:11,258 - INFO - epoch 1, step 8850, training loss = 1.972048, validation loss = 2.961644
2018-12-05 02:28:14,722 - INFO - epoch 1, step 8860, training loss = 2.013887, validation loss = 2.968657
2018-12-05 02:28:18,284 - INFO - epoch 1, step 8870, training loss = 2.309990, validation loss = 2.732565
2018-12-05 02:28:21,872 - INFO - epoch 1, step 8880, training loss = 1.957056, validation loss = 2.720369
2018-12-05 02:28:25,520 - INFO - epoch 1, step 8890, training loss = 2.329480, validation loss = 2.079586
2018-12-05 02:28:29,338 - INFO - epoch 1, step 8900, training loss = 1.744341, validation loss = 2.932863
2018-12-05 02:28:33,277 - INFO - epoch 1, step 8910, training loss = 2.120981, validation loss = 2.524260
2018-12-05 02:28:36,812 - INFO - epoch 1, step 8920, training loss = 2.454426, validation loss = 2.279941
2018-12-05 02:28:40,336 - INFO - epoch 1, step 8930, training loss = 2.177826, validation loss = 2.616649
2018-12-05 02:28:44,016 - INFO - epoch 1, step 8940, training loss = 2.367627, validation loss = 2.554132
2018-12-05 02:28:47,531 - INFO - epoch 1, step 8950, training loss = 2.275605, validation loss = 3.044109
2018-12-05 02:28:51,263 - INFO - epoch 1, step 8960, training loss = 2.396273, validation loss = 2.226213
2018-12-05 02:28:54,634 - INFO - epoch 1, step 8970, training loss = 2.528670, validation loss = 2.573124
2018-12-05 02:28:57,936 - INFO - epoch 1, step 8980, training loss = 2.094030, validation loss = 2.646049
2018-12-05 02:29:01,374 - INFO - epoch 1, step 8990, training loss = 2.279794, validation loss = 2.813519
2018-12-05 02:29:04,722 - INFO - epoch 1, step 9000, training loss = 2.046165, validation loss = 2.684549
2018-12-05 02:29:08,161 - INFO - epoch 1, step 9010, training loss = 2.300017, validation loss = 2.165984
2018-12-05 02:29:11,545 - INFO - epoch 1, step 9020, training loss = 2.259655, validation loss = 2.998914
2018-12-05 02:29:14,913 - INFO - epoch 1, step 9030, training loss = 2.601043, validation loss = 2.651031
2018-12-05 02:29:18,476 - INFO - epoch 1, step 9040, training loss = 2.286364, validation loss = 2.685052
2018-12-05 02:29:21,873 - INFO - epoch 1, step 9050, training loss = 2.466160, validation loss = 2.184886
2018-12-05 02:29:25,322 - INFO - epoch 1, step 9060, training loss = 2.689461, validation loss = 2.243775
2018-12-05 02:29:28,786 - INFO - epoch 1, step 9070, training loss = 1.951949, validation loss = 2.276730
2018-12-05 02:29:32,227 - INFO - epoch 1, step 9080, training loss = 2.225003, validation loss = 2.711526
2018-12-05 02:29:36,314 - INFO - epoch 1, step 9090, training loss = 2.135362, validation loss = 3.022756
2018-12-05 02:29:40,487 - INFO - epoch 1, step 9100, training loss = 1.864945, validation loss = 2.635046
2018-12-05 02:29:44,686 - INFO - epoch 1, step 9110, training loss = 1.920397, validation loss = 2.706833
2018-12-05 02:29:49,044 - INFO - epoch 1, step 9120, training loss = 1.821772, validation loss = 3.368245
2018-12-05 02:29:52,699 - INFO - epoch 1, step 9130, training loss = 2.018631, validation loss = 1.733244
2018-12-05 02:29:56,149 - INFO - epoch 1, step 9140, training loss = 1.825942, validation loss = 2.865909
2018-12-05 02:29:59,643 - INFO - epoch 1, step 9150, training loss = 1.979065, validation loss = 2.561284
2018-12-05 02:30:02,864 - INFO - epoch 1, step 9160, training loss = 2.103109, validation loss = 2.727565
2018-12-05 02:30:06,051 - INFO - epoch 1, step 9170, training loss = 2.227933, validation loss = 2.997819
2018-12-05 02:30:09,203 - INFO - epoch 1, step 9180, training loss = 1.910269, validation loss = 2.544532
2018-12-05 02:30:12,803 - INFO - epoch 1, step 9190, training loss = 2.153270, validation loss = 3.238621
2018-12-05 02:30:16,071 - INFO - epoch 1, step 9200, training loss = 1.579846, validation loss = 2.944852
2018-12-05 02:30:19,485 - INFO - epoch 1, step 9210, training loss = 2.220383, validation loss = 3.613307
2018-12-05 02:30:22,807 - INFO - epoch 1, step 9220, training loss = 1.828425, validation loss = 3.162258
2018-12-05 02:30:26,029 - INFO - epoch 1, step 9230, training loss = 1.894582, validation loss = 2.899819
2018-12-05 02:30:29,455 - INFO - epoch 1, step 9240, training loss = 2.335160, validation loss = 2.658024
2018-12-05 02:30:32,765 - INFO - epoch 1, step 9250, training loss = 1.642334, validation loss = 2.708932
2018-12-05 02:30:36,249 - INFO - epoch 1, step 9260, training loss = 2.130609, validation loss = 3.733221
2018-12-05 02:30:39,846 - INFO - epoch 1, step 9270, training loss = 2.519326, validation loss = 2.940118
2018-12-05 02:30:43,571 - INFO - epoch 1, step 9280, training loss = 1.706985, validation loss = 2.382851
2018-12-05 02:30:46,948 - INFO - epoch 1, step 9290, training loss = 1.903729, validation loss = 2.652817
2018-12-05 02:30:50,456 - INFO - epoch 1, step 9300, training loss = 1.859760, validation loss = 2.921611
2018-12-05 02:30:53,891 - INFO - epoch 1, step 9310, training loss = 2.387710, validation loss = 2.936978
2018-12-05 02:30:57,333 - INFO - epoch 1, step 9320, training loss = 2.184597, validation loss = 3.400173
2018-12-05 02:31:00,827 - INFO - epoch 1, step 9330, training loss = 1.811702, validation loss = 3.222942
2018-12-05 02:31:04,683 - INFO - epoch 1, step 9340, training loss = 2.172483, validation loss = 3.380169
2018-12-05 02:31:08,307 - INFO - epoch 1, step 9350, training loss = 2.014853, validation loss = 3.040091
2018-12-05 02:31:11,945 - INFO - epoch 1, step 9360, training loss = 1.604044, validation loss = 2.986963
2018-12-05 02:31:15,686 - INFO - epoch 1, step 9370, training loss = 2.101914, validation loss = 2.583084
2018-12-05 02:31:19,865 - INFO - epoch 1, step 9380, training loss = 2.068332, validation loss = 2.977791
2018-12-05 02:31:23,970 - INFO - epoch 1, step 9390, training loss = 2.136708, validation loss = 3.197640
2018-12-05 02:31:28,025 - INFO - epoch 1, step 9400, training loss = 2.108107, validation loss = 3.136732
2018-12-05 02:31:32,235 - INFO - epoch 1, step 9410, training loss = 2.057325, validation loss = 3.656955
2018-12-05 02:31:36,263 - INFO - epoch 1, step 9420, training loss = 1.791818, validation loss = 3.079950
2018-12-05 02:31:40,280 - INFO - epoch 1, step 9430, training loss = 1.975882, validation loss = 2.808525
2018-12-05 02:31:44,479 - INFO - epoch 1, step 9440, training loss = 2.151659, validation loss = 2.834247
2018-12-05 02:31:48,422 - INFO - epoch 1, step 9450, training loss = 2.350023, validation loss = 2.901444
2018-12-05 02:31:52,428 - INFO - epoch 1, step 9460, training loss = 1.942421, validation loss = 2.874273
2018-12-05 02:31:56,512 - INFO - epoch 1, step 9470, training loss = 1.808221, validation loss = 2.519391
2018-12-05 02:32:00,059 - INFO - epoch 1, step 9480, training loss = 2.081789, validation loss = 2.796122
2018-12-05 02:32:03,389 - INFO - epoch 1, step 9490, training loss = 2.175028, validation loss = 3.320451
2018-12-05 02:32:06,892 - INFO - epoch 1, step 9500, training loss = 1.319730, validation loss = 3.014301
2018-12-05 02:32:10,251 - INFO - epoch 1, step 9510, training loss = 1.905534, validation loss = 3.811821
2018-12-05 02:32:13,588 - INFO - epoch 1, step 9520, training loss = 2.076428, validation loss = 2.412615
2018-12-05 02:32:16,756 - INFO - epoch 1, step 9530, training loss = 2.175547, validation loss = 2.546888
2018-12-05 02:32:20,062 - INFO - epoch 1, step 9540, training loss = 2.086135, validation loss = 2.613847
2018-12-05 02:32:23,463 - INFO - epoch 1, step 9550, training loss = 1.877644, validation loss = 3.017917
2018-12-05 02:32:26,961 - INFO - epoch 1, step 9560, training loss = 1.853019, validation loss = 2.708485
2018-12-05 02:32:30,314 - INFO - epoch 1, step 9570, training loss = 1.860419, validation loss = 3.744567
2018-12-05 02:32:33,547 - INFO - epoch 1, step 9580, training loss = 1.682947, validation loss = 3.503387
2018-12-05 02:32:36,825 - INFO - epoch 1, step 9590, training loss = 1.786056, validation loss = 3.182049
2018-12-05 02:32:40,458 - INFO - epoch 1, step 9600, training loss = 1.707621, validation loss = 2.847291
2018-12-05 02:32:44,013 - INFO - epoch 1, step 9610, training loss = 1.884211, validation loss = 2.722991
2018-12-05 02:32:47,591 - INFO - epoch 1, step 9620, training loss = 2.418273, validation loss = 3.272266
2018-12-05 02:32:51,207 - INFO - epoch 1, step 9630, training loss = 1.906939, validation loss = 3.069238
2018-12-05 02:32:54,733 - INFO - epoch 1, step 9640, training loss = 1.433267, validation loss = 2.611714
2018-12-05 02:32:58,330 - INFO - epoch 1, step 9650, training loss = 1.464450, validation loss = 2.851424
2018-12-05 02:33:01,935 - INFO - epoch 1, step 9660, training loss = 2.392905, validation loss = 3.140186
2018-12-05 02:33:05,594 - INFO - epoch 1, step 9670, training loss = 2.123525, validation loss = 2.713173
2018-12-05 02:33:09,229 - INFO - epoch 1, step 9680, training loss = 2.061150, validation loss = 2.713533
2018-12-05 02:33:12,883 - INFO - epoch 1, step 9690, training loss = 2.352028, validation loss = 2.865481
2018-12-05 02:33:16,526 - INFO - epoch 1, step 9700, training loss = 1.976387, validation loss = 3.039647
2018-12-05 02:33:20,839 - INFO - epoch 1, step 9710, training loss = 2.064045, validation loss = 3.188180
2018-12-05 02:33:25,263 - INFO - epoch 1, step 9720, training loss = 2.044600, validation loss = 3.069565
2018-12-05 02:33:29,520 - INFO - epoch 1, step 9730, training loss = 2.143840, validation loss = 3.553232
2018-12-05 02:33:33,868 - INFO - epoch 1, step 9740, training loss = 2.287428, validation loss = 2.953786
2018-12-05 02:33:38,053 - INFO - epoch 1, step 9750, training loss = 2.040380, validation loss = 2.495194
2018-12-05 02:33:42,082 - INFO - epoch 1, step 9760, training loss = 2.062997, validation loss = 2.490571
2018-12-05 02:33:46,326 - INFO - epoch 1, step 9770, training loss = 2.541036, validation loss = 2.705797
2018-12-05 02:33:51,005 - INFO - epoch 1, step 9780, training loss = 2.449508, validation loss = 3.179676
2018-12-05 02:33:55,383 - INFO - epoch 1, step 9790, training loss = 1.948268, validation loss = 2.988894
2018-12-05 02:33:59,797 - INFO - epoch 1, step 9800, training loss = 1.779771, validation loss = 3.130566
2018-12-05 02:34:04,051 - INFO - epoch 1, step 9810, training loss = 2.098169, validation loss = 2.973010
2018-12-05 02:34:08,320 - INFO - epoch 1, step 9820, training loss = 2.116586, validation loss = 2.811253
2018-12-05 02:34:12,522 - INFO - epoch 1, step 9830, training loss = 2.415745, validation loss = 2.621434
2018-12-05 02:34:16,265 - INFO - epoch 1, step 9840, training loss = 1.997933, validation loss = 2.919063
2018-12-05 02:34:20,070 - INFO - epoch 1, step 9850, training loss = 1.941138, validation loss = 3.116545
2018-12-05 02:34:23,632 - INFO - epoch 1, step 9860, training loss = 1.562384, validation loss = 2.938586
2018-12-05 02:34:27,055 - INFO - epoch 1, step 9870, training loss = 2.266212, validation loss = 3.379490
2018-12-05 02:34:30,561 - INFO - epoch 1, step 9880, training loss = 1.784824, validation loss = 2.717476
2018-12-05 02:34:34,043 - INFO - epoch 1, step 9890, training loss = 1.709673, validation loss = 2.593506
2018-12-05 02:34:37,676 - INFO - epoch 1, step 9900, training loss = 1.655778, validation loss = 3.286964
2018-12-05 02:34:41,320 - INFO - epoch 1, step 9910, training loss = 1.859965, validation loss = 3.115818
2018-12-05 02:34:44,877 - INFO - epoch 1, step 9920, training loss = 1.973876, validation loss = 3.127161
2018-12-05 02:34:48,693 - INFO - epoch 1, step 9930, training loss = 1.893048, validation loss = 3.302213
2018-12-05 02:34:52,148 - INFO - epoch 1, step 9940, training loss = 2.221135, validation loss = 3.215291
2018-12-05 02:34:55,841 - INFO - epoch 1, step 9950, training loss = 2.046140, validation loss = 2.983147
2018-12-05 02:34:59,194 - INFO - epoch 1, step 9960, training loss = 2.226700, validation loss = 3.117095
2018-12-05 02:35:03,087 - INFO - epoch 1, step 9970, training loss = 1.672587, validation loss = 3.409466
2018-12-05 02:35:06,740 - INFO - epoch 1, step 9980, training loss = 2.045255, validation loss = 3.768943
2018-12-05 02:35:10,394 - INFO - epoch 1, step 9990, training loss = 1.937683, validation loss = 3.111926
2018-12-05 02:35:13,969 - INFO - epoch 1, step 10000, training loss = 2.467912, validation loss = 2.495752
2018-12-05 02:35:17,678 - INFO - epoch 1, step 10010, training loss = 1.685577, validation loss = 2.866676
2018-12-05 02:35:21,205 - INFO - epoch 1, step 10020, training loss = 1.629644, validation loss = 3.203959
2018-12-05 02:35:24,683 - INFO - epoch 1, step 10030, training loss = 2.262241, validation loss = 2.981496
2018-12-05 02:35:28,245 - INFO - epoch 1, step 10040, training loss = 2.067047, validation loss = 3.594818
2018-12-05 02:35:31,613 - INFO - epoch 1, step 10050, training loss = 2.131189, validation loss = 3.674359
2018-12-05 02:35:35,073 - INFO - epoch 1, step 10060, training loss = 2.334845, validation loss = 3.147168
2018-12-05 02:35:38,494 - INFO - epoch 1, step 10070, training loss = 2.091719, validation loss = 2.825578
2018-12-05 02:35:41,802 - INFO - epoch 1, step 10080, training loss = 2.270736, validation loss = 3.026897
2018-12-05 02:35:45,333 - INFO - epoch 1, step 10090, training loss = 2.440038, validation loss = 2.862576
2018-12-05 02:35:48,695 - INFO - epoch 1, step 10100, training loss = 2.268090, validation loss = 3.247931
2018-12-05 02:35:52,076 - INFO - epoch 1, step 10110, training loss = 2.216358, validation loss = 3.171347
2018-12-05 02:35:55,488 - INFO - epoch 1, step 10120, training loss = 2.068415, validation loss = 3.038888
2018-12-05 02:35:58,855 - INFO - epoch 1, step 10130, training loss = 2.144830, validation loss = 3.351781
2018-12-05 02:36:02,241 - INFO - epoch 1, step 10140, training loss = 2.002961, validation loss = 3.230819
2018-12-05 02:36:05,567 - INFO - epoch 1, step 10150, training loss = 2.116252, validation loss = 2.352624
2018-12-05 02:36:09,266 - INFO - epoch 1, step 10160, training loss = 2.355165, validation loss = 2.520186
2018-12-05 02:36:12,977 - INFO - epoch 1, step 10170, training loss = 2.091735, validation loss = 2.862142
2018-12-05 02:36:16,679 - INFO - epoch 1, step 10180, training loss = 2.245214, validation loss = 3.044348
2018-12-05 02:36:20,508 - INFO - epoch 1, step 10190, training loss = 2.198787, validation loss = 3.274229
2018-12-05 02:36:24,300 - INFO - epoch 1, step 10200, training loss = 2.226464, validation loss = 3.289150
2018-12-05 02:36:27,987 - INFO - epoch 1, step 10210, training loss = 2.049920, validation loss = 3.506620
2018-12-05 02:36:31,774 - INFO - epoch 1, step 10220, training loss = 2.346492, validation loss = 2.974040
2018-12-05 02:36:35,550 - INFO - epoch 1, step 10230, training loss = 1.926167, validation loss = 3.104589
2018-12-05 02:36:38,954 - INFO - epoch 1, step 10240, training loss = 1.965616, validation loss = 3.305746
2018-12-05 02:36:42,380 - INFO - epoch 1, step 10250, training loss = 2.266613, validation loss = 3.267614
2018-12-05 02:36:45,764 - INFO - epoch 1, step 10260, training loss = 2.340132, validation loss = 3.157019
2018-12-05 02:36:49,278 - INFO - epoch 1, step 10270, training loss = 1.962339, validation loss = 3.232867
2018-12-05 02:36:52,747 - INFO - epoch 1, step 10280, training loss = 2.078587, validation loss = 3.487387
2018-12-05 02:36:56,152 - INFO - epoch 1, step 10290, training loss = 2.253702, validation loss = 2.461108
2018-12-05 02:36:59,561 - INFO - epoch 1, step 10300, training loss = 2.089560, validation loss = 2.686578
2018-12-05 02:37:02,935 - INFO - epoch 1, step 10310, training loss = 2.244337, validation loss = 2.432597
2018-12-05 02:37:06,409 - INFO - epoch 1, step 10320, training loss = 2.172703, validation loss = 2.803903
2018-12-05 02:37:10,036 - INFO - epoch 1, step 10330, training loss = 2.329973, validation loss = 3.120728
2018-12-05 02:37:14,075 - INFO - epoch 1, step 10340, training loss = 2.246710, validation loss = 3.029653
2018-12-05 02:37:18,371 - INFO - epoch 1, step 10350, training loss = 2.292005, validation loss = 3.065329
2018-12-05 02:37:22,657 - INFO - epoch 1, step 10360, training loss = 2.059476, validation loss = 3.344432
2018-12-05 02:37:27,133 - INFO - epoch 1, step 10370, training loss = 2.516633, validation loss = 2.419042
2018-12-05 02:37:31,363 - INFO - epoch 1, step 10380, training loss = 2.406389, validation loss = 2.357748
2018-12-05 02:37:35,450 - INFO - epoch 1, step 10390, training loss = 2.293281, validation loss = 2.881725
2018-12-05 02:37:39,418 - INFO - epoch 1, step 10400, training loss = 2.545718, validation loss = 2.708919
2018-12-05 02:37:44,343 - INFO - epoch 1, step 10410, training loss = 2.041568, validation loss = 2.352565
2018-12-05 02:37:49,096 - INFO - epoch 1, step 10420, training loss = 2.315910, validation loss = 3.315760
2018-12-05 02:37:53,443 - INFO - epoch 1, step 10430, training loss = 1.865510, validation loss = 3.147045
2018-12-05 02:37:57,501 - INFO - epoch 1, step 10440, training loss = 2.036563, validation loss = 2.326125
2018-12-05 02:38:01,745 - INFO - epoch 1, step 10450, training loss = 2.053706, validation loss = 2.230461
2018-12-05 02:38:05,910 - INFO - epoch 1, step 10460, training loss = 2.176833, validation loss = 1.938158
2018-12-05 02:38:10,236 - INFO - epoch 1, step 10470, training loss = 2.052648, validation loss = 1.744875
2018-12-05 02:38:14,293 - INFO - epoch 1, step 10480, training loss = 2.257929, validation loss = 2.528760
2018-12-05 02:38:18,584 - INFO - epoch 1, step 10490, training loss = 1.864522, validation loss = 2.195585
2018-12-05 02:38:23,071 - INFO - epoch 1, step 10500, training loss = 1.992889, validation loss = 2.031101
2018-12-05 02:38:27,237 - INFO - epoch 1, step 10510, training loss = 2.280339, validation loss = 2.524453
2018-12-05 02:38:31,453 - INFO - epoch 1, step 10520, training loss = 2.380939, validation loss = 2.359958
2018-12-05 02:38:35,432 - INFO - epoch 1, step 10530, training loss = 1.918114, validation loss = 2.484403
2018-12-05 02:38:39,469 - INFO - epoch 1, step 10540, training loss = 2.161491, validation loss = 2.746795
2018-12-05 02:38:43,619 - INFO - epoch 1, step 10550, training loss = 2.108300, validation loss = 2.240155
2018-12-05 02:38:47,426 - INFO - epoch 1, step 10560, training loss = 1.971820, validation loss = 2.248807
2018-12-05 02:38:51,413 - INFO - epoch 1, step 10570, training loss = 2.207312, validation loss = 2.097587
2018-12-05 02:38:55,460 - INFO - epoch 1, step 10580, training loss = 2.022327, validation loss = 2.267691
2018-12-05 02:38:59,345 - INFO - epoch 1, step 10590, training loss = 2.373448, validation loss = 3.153861
2018-12-05 02:39:03,075 - INFO - epoch 1, step 10600, training loss = 1.912073, validation loss = 2.606977
2018-12-05 02:39:06,815 - INFO - epoch 1, step 10610, training loss = 2.271919, validation loss = 2.705034
2018-12-05 02:39:10,623 - INFO - epoch 1, step 10620, training loss = 1.728624, validation loss = 2.675576
2018-12-05 02:39:14,562 - INFO - epoch 1, step 10630, training loss = 1.830666, validation loss = 2.062987
2018-12-05 02:39:18,590 - INFO - epoch 1, step 10640, training loss = 2.100401, validation loss = 1.985375
2018-12-05 02:39:22,580 - INFO - epoch 1, step 10650, training loss = 2.148078, validation loss = 2.465255
2018-12-05 02:39:26,420 - INFO - epoch 1, step 10660, training loss = 1.910501, validation loss = 2.469316
2018-12-05 02:39:30,378 - INFO - epoch 1, step 10670, training loss = 1.919898, validation loss = 2.181876
2018-12-05 02:39:34,213 - INFO - epoch 1, step 10680, training loss = 1.675177, validation loss = 2.328793
2018-12-05 02:39:38,110 - INFO - epoch 1, step 10690, training loss = 2.041426, validation loss = 2.809446
2018-12-05 02:39:41,626 - INFO - epoch 1, step 10700, training loss = 2.833133, validation loss = 2.220204
2018-12-05 02:39:45,481 - INFO - epoch 1, step 10710, training loss = 2.352658, validation loss = 2.258326
2018-12-05 02:39:49,293 - INFO - epoch 1, step 10720, training loss = 2.068845, validation loss = 1.970445
2018-12-05 02:39:53,224 - INFO - epoch 1, step 10730, training loss = 2.276644, validation loss = 2.799412
2018-12-05 02:39:57,124 - INFO - epoch 1, step 10740, training loss = 1.677019, validation loss = 2.186913
2018-12-05 02:40:01,030 - INFO - epoch 1, step 10750, training loss = 1.818150, validation loss = 2.698431
2018-12-05 02:40:04,766 - INFO - epoch 1, step 10760, training loss = 2.259756, validation loss = 2.414685
2018-12-05 02:40:08,760 - INFO - epoch 1, step 10770, training loss = 2.325559, validation loss = 2.051837
2018-12-05 02:40:12,606 - INFO - epoch 1, step 10780, training loss = 1.884562, validation loss = 2.281419
2018-12-05 02:40:16,572 - INFO - epoch 1, step 10790, training loss = 2.169547, validation loss = 2.650895
2018-12-05 02:40:20,554 - INFO - epoch 1, step 10800, training loss = 2.234422, validation loss = 2.747472
2018-12-05 02:40:24,559 - INFO - epoch 1, step 10810, training loss = 2.115305, validation loss = 2.584023
2018-12-05 02:40:28,423 - INFO - epoch 1, step 10820, training loss = 2.331137, validation loss = 2.069021
2018-12-05 02:40:32,115 - INFO - epoch 1, step 10830, training loss = 2.097855, validation loss = 2.293460
2018-12-05 02:40:35,927 - INFO - epoch 1, step 10840, training loss = 2.346023, validation loss = 2.380390
2018-12-05 02:40:39,724 - INFO - epoch 1, step 10850, training loss = 2.156294, validation loss = 2.703484
2018-12-05 02:40:43,784 - INFO - epoch 1, step 10860, training loss = 2.036944, validation loss = 2.709021
2018-12-05 02:40:47,372 - INFO - epoch 1, step 10870, training loss = 1.518656, validation loss = 2.732088
2018-12-05 02:40:51,016 - INFO - epoch 1, step 10880, training loss = 2.084409, validation loss = 2.724937
2018-12-05 02:40:54,516 - INFO - epoch 1, step 10890, training loss = 1.974829, validation loss = 2.271119
2018-12-05 02:40:58,251 - INFO - epoch 1, step 10900, training loss = 2.097674, validation loss = 2.709325
2018-12-05 02:41:01,823 - INFO - epoch 1, step 10910, training loss = 1.978900, validation loss = 3.039064
2018-12-05 02:41:05,211 - INFO - epoch 1, step 10920, training loss = 1.428642, validation loss = 2.780879
2018-12-05 02:41:08,617 - INFO - epoch 1, step 10930, training loss = 2.289968, validation loss = 2.928693
2018-12-05 02:41:12,186 - INFO - epoch 1, step 10940, training loss = 2.541989, validation loss = 2.587768
2018-12-05 02:41:15,657 - INFO - epoch 1, step 10950, training loss = 1.868568, validation loss = 2.717420
2018-12-05 02:41:19,211 - INFO - epoch 1, step 10960, training loss = 2.036305, validation loss = 2.166382
2018-12-05 02:41:22,755 - INFO - epoch 1, step 10970, training loss = 2.183676, validation loss = 2.287651
2018-12-05 02:41:26,153 - INFO - epoch 1, step 10980, training loss = 2.293870, validation loss = 2.382186
2018-12-05 02:41:29,738 - INFO - epoch 1, step 10990, training loss = 1.848075, validation loss = 2.649606
2018-12-05 02:41:33,008 - INFO - epoch 1, step 11000, training loss = 2.531838, validation loss = 2.529655
2018-12-05 02:41:36,268 - INFO - epoch 1, step 11010, training loss = 2.184778, validation loss = 2.728727
2018-12-05 02:41:39,482 - INFO - epoch 1, step 11020, training loss = 2.382292, validation loss = 2.669158
2018-12-05 02:41:43,137 - INFO - epoch 1, step 11030, training loss = 2.134663, validation loss = 2.460891
2018-12-05 02:41:47,071 - INFO - epoch 1, step 11040, training loss = 2.137679, validation loss = 2.573769
2018-12-05 02:41:51,289 - INFO - epoch 1, step 11050, training loss = 1.980246, validation loss = 1.940126
2018-12-05 02:41:55,211 - INFO - epoch 1, step 11060, training loss = 2.147913, validation loss = 2.630499
2018-12-05 02:41:59,327 - INFO - epoch 1, step 11070, training loss = 2.151008, validation loss = 2.641167
2018-12-05 02:42:03,146 - INFO - epoch 1, step 11080, training loss = 2.071788, validation loss = 2.779431
2018-12-05 02:42:07,310 - INFO - epoch 1, step 11090, training loss = 1.930344, validation loss = 2.208536
2018-12-05 02:42:11,160 - INFO - epoch 1, step 11100, training loss = 2.149737, validation loss = 2.677087
2018-12-05 02:42:15,190 - INFO - epoch 1, step 11110, training loss = 2.140477, validation loss = 2.680048
2018-12-05 02:42:19,245 - INFO - epoch 1, step 11120, training loss = 2.007146, validation loss = 3.301183
2018-12-05 02:42:23,059 - INFO - epoch 1, step 11130, training loss = 2.190961, validation loss = 1.834201
2018-12-05 02:42:26,512 - INFO - epoch 1, step 11140, training loss = 1.861030, validation loss = 2.546455
2018-12-05 02:42:30,110 - INFO - epoch 1, step 11150, training loss = 1.556752, validation loss = 2.297165
2018-12-05 02:42:33,779 - INFO - epoch 1, step 11160, training loss = 1.656637, validation loss = 2.127320
2018-12-05 02:42:37,697 - INFO - epoch 1, step 11170, training loss = 1.612627, validation loss = 2.879931
2018-12-05 02:42:41,370 - INFO - epoch 1, step 11180, training loss = 1.751621, validation loss = 2.578783
2018-12-05 02:42:45,139 - INFO - epoch 1, step 11190, training loss = 1.709236, validation loss = 2.831804
2018-12-05 02:42:48,882 - INFO - epoch 1, step 11200, training loss = 2.497817, validation loss = 3.125979
2018-12-05 02:42:52,559 - INFO - epoch 1, step 11210, training loss = 2.315015, validation loss = 2.393934
2018-12-05 02:42:56,213 - INFO - epoch 1, step 11220, training loss = 1.877820, validation loss = 2.313259
2018-12-05 02:42:59,982 - INFO - epoch 1, step 11230, training loss = 2.147074, validation loss = 2.620551
2018-12-05 02:43:03,818 - INFO - epoch 1, step 11240, training loss = 2.011554, validation loss = 2.530634
2018-12-05 02:43:07,522 - INFO - epoch 1, step 11250, training loss = 1.905005, validation loss = 2.621030
2018-12-05 02:43:10,855 - INFO - epoch 1, step 11260, training loss = 2.176728, validation loss = 2.454144
2018-12-05 02:43:14,250 - INFO - epoch 1, step 11270, training loss = 2.012460, validation loss = 2.866411
2018-12-05 02:43:17,716 - INFO - epoch 1, step 11280, training loss = 1.955366, validation loss = 3.010685
2018-12-05 02:43:21,186 - INFO - epoch 1, step 11290, training loss = 1.981078, validation loss = 2.262250
2018-12-05 02:43:24,849 - INFO - epoch 1, step 11300, training loss = 2.045214, validation loss = 2.464494
2018-12-05 02:43:28,373 - INFO - epoch 1, step 11310, training loss = 2.181690, validation loss = 2.369626
2018-12-05 02:43:31,983 - INFO - epoch 1, step 11320, training loss = 2.220270, validation loss = 2.408664
2018-12-05 02:43:35,588 - INFO - epoch 1, step 11330, training loss = 2.401590, validation loss = 2.834473
2018-12-05 02:43:39,254 - INFO - epoch 1, step 11340, training loss = 1.822831, validation loss = 3.014108
2018-12-05 02:43:42,934 - INFO - epoch 1, step 11350, training loss = 2.132895, validation loss = 2.508764
2018-12-05 02:43:46,743 - INFO - epoch 1, step 11360, training loss = 2.076145, validation loss = 2.363871
2018-12-05 02:43:50,268 - INFO - epoch 1, step 11370, training loss = 2.607759, validation loss = 2.681176
2018-12-05 02:43:53,931 - INFO - epoch 1, step 11380, training loss = 2.005553, validation loss = 2.594236
2018-12-05 02:43:57,538 - INFO - epoch 1, step 11390, training loss = 1.715329, validation loss = 2.350397
2018-12-05 02:44:01,151 - INFO - epoch 1, step 11400, training loss = 2.119734, validation loss = 3.033570
2018-12-05 02:44:04,802 - INFO - epoch 1, step 11410, training loss = 1.881094, validation loss = 3.022295
2018-12-05 02:44:08,265 - INFO - epoch 1, step 11420, training loss = 2.241207, validation loss = 2.851437
2018-12-05 02:44:11,845 - INFO - epoch 1, step 11430, training loss = 2.456170, validation loss = 2.357515
2018-12-05 02:44:15,653 - INFO - epoch 1, step 11440, training loss = 1.524169, validation loss = 2.583761
2018-12-05 02:44:19,427 - INFO - epoch 1, step 11450, training loss = 2.279478, validation loss = 2.220700
2018-12-05 02:44:23,100 - INFO - epoch 1, step 11460, training loss = 1.723812, validation loss = 3.059587
2018-12-05 02:44:27,140 - INFO - epoch 1, step 11470, training loss = 2.418389, validation loss = 2.893811
2018-12-05 02:44:31,128 - INFO - epoch 1, step 11480, training loss = 1.919212, validation loss = 2.807174
2018-12-05 02:44:35,437 - INFO - epoch 1, step 11490, training loss = 2.267597, validation loss = 2.894865
2018-12-05 02:44:39,582 - INFO - epoch 1, step 11500, training loss = 2.383409, validation loss = 2.543175
2018-12-05 02:44:43,591 - INFO - epoch 1, step 11510, training loss = 2.090849, validation loss = 2.575532
2018-12-05 02:44:47,483 - INFO - epoch 1, step 11520, training loss = 2.241153, validation loss = 3.111952
2018-12-05 02:44:51,132 - INFO - epoch 1, step 11530, training loss = 2.225964, validation loss = 3.265404
2018-12-05 02:44:55,039 - INFO - epoch 1, step 11540, training loss = 2.257510, validation loss = 2.749918
2018-12-05 02:44:59,316 - INFO - epoch 1, step 11550, training loss = 1.686714, validation loss = 2.932703
2018-12-05 02:45:03,444 - INFO - epoch 1, step 11560, training loss = 1.586389, validation loss = 2.524092
2018-12-05 02:45:07,928 - INFO - epoch 1, step 11570, training loss = 1.857130, validation loss = 2.756476
2018-12-05 02:45:12,145 - INFO - epoch 1, step 11580, training loss = 2.571684, validation loss = 2.492440
2018-12-05 02:45:16,469 - INFO - epoch 1, step 11590, training loss = 1.801831, validation loss = 2.234243
2018-12-05 02:45:20,798 - INFO - epoch 1, step 11600, training loss = 1.926178, validation loss = 2.461731
2018-12-05 02:45:25,038 - INFO - epoch 1, step 11610, training loss = 1.937808, validation loss = 2.832167
2018-12-05 02:45:29,097 - INFO - epoch 1, step 11620, training loss = 1.434425, validation loss = 2.352174
2018-12-05 02:45:33,338 - INFO - epoch 1, step 11630, training loss = 2.411686, validation loss = 2.968075
2018-12-05 02:45:37,511 - INFO - epoch 1, step 11640, training loss = 2.171904, validation loss = 2.112410
2018-12-05 02:45:41,450 - INFO - epoch 1, step 11650, training loss = 1.804153, validation loss = 2.465843
2018-12-05 02:45:45,232 - INFO - epoch 1, step 11660, training loss = 1.870829, validation loss = 2.704977
2018-12-05 02:45:48,720 - INFO - epoch 1, step 11670, training loss = 2.309041, validation loss = 2.708228
2018-12-05 02:45:52,316 - INFO - epoch 1, step 11680, training loss = 2.104353, validation loss = 2.500191
2018-12-05 02:45:56,042 - INFO - epoch 1, step 11690, training loss = 1.860264, validation loss = 2.348290
2018-12-05 02:45:59,642 - INFO - epoch 1, step 11700, training loss = 2.176464, validation loss = 2.746048
2018-12-05 02:46:03,215 - INFO - epoch 1, step 11710, training loss = 1.931133, validation loss = 2.574865
2018-12-05 02:46:06,602 - INFO - epoch 1, step 11720, training loss = 1.823319, validation loss = 2.688381
2018-12-05 02:46:10,473 - INFO - epoch 1, step 11730, training loss = 1.943117, validation loss = 2.271317
2018-12-05 02:46:13,975 - INFO - epoch 1, step 11740, training loss = 2.215685, validation loss = 2.567976
2018-12-05 02:46:17,723 - INFO - epoch 1, step 11750, training loss = 1.623746, validation loss = 2.660893
2018-12-05 02:46:21,246 - INFO - epoch 1, step 11760, training loss = 2.226597, validation loss = 2.877181
2018-12-05 02:46:24,855 - INFO - epoch 1, step 11770, training loss = 2.145198, validation loss = 2.258243
2018-12-05 02:46:28,679 - INFO - epoch 1, step 11780, training loss = 2.467836, validation loss = 2.643268
2018-12-05 02:46:33,106 - INFO - epoch 1, step 11790, training loss = 2.206345, validation loss = 2.176980
2018-12-05 02:46:37,088 - INFO - epoch 1, step 11800, training loss = 2.178657, validation loss = 2.885633
2018-12-05 02:46:41,079 - INFO - epoch 1, step 11810, training loss = 1.979083, validation loss = 2.482511
2018-12-05 02:46:45,198 - INFO - epoch 1, step 11820, training loss = 2.263256, validation loss = 2.986331
2018-12-05 02:46:49,088 - INFO - epoch 1, step 11830, training loss = 2.243567, validation loss = 2.567993
2018-12-05 02:46:53,140 - INFO - epoch 1, step 11840, training loss = 1.793169, validation loss = 2.805192
2018-12-05 02:46:57,065 - INFO - epoch 1, step 11850, training loss = 1.940338, validation loss = 2.510220
2018-12-05 02:47:01,243 - INFO - epoch 1, step 11860, training loss = 2.165467, validation loss = 2.195737
2018-12-05 02:47:05,133 - INFO - epoch 1, step 11870, training loss = 1.813118, validation loss = 2.337908
2018-12-05 02:47:09,132 - INFO - epoch 1, step 11880, training loss = 2.056031, validation loss = 2.041962
2018-12-05 02:47:13,031 - INFO - epoch 1, step 11890, training loss = 2.155903, validation loss = 2.416921
2018-12-05 02:47:16,975 - INFO - epoch 1, step 11900, training loss = 2.126977, validation loss = 2.608557
2018-12-05 02:47:20,829 - INFO - epoch 1, step 11910, training loss = 2.099056, validation loss = 2.455990
2018-12-05 02:47:24,698 - INFO - epoch 1, step 11920, training loss = 1.984983, validation loss = 2.251920
2018-12-05 02:47:28,420 - INFO - epoch 1, step 11930, training loss = 1.601615, validation loss = 2.653963
2018-12-05 02:47:32,100 - INFO - epoch 1, step 11940, training loss = 2.715752, validation loss = 2.470020
2018-12-05 02:47:35,788 - INFO - epoch 1, step 11950, training loss = 1.695045, validation loss = 2.440975
2018-12-05 02:47:39,553 - INFO - epoch 1, step 11960, training loss = 1.916743, validation loss = 2.774565
2018-12-05 02:47:43,178 - INFO - epoch 1, step 11970, training loss = 2.032254, validation loss = 2.390482
2018-12-05 02:47:46,817 - INFO - epoch 1, step 11980, training loss = 1.704670, validation loss = 2.526299
2018-12-05 02:47:50,430 - INFO - epoch 1, step 11990, training loss = 2.202289, validation loss = 3.219914
2018-12-05 02:47:54,133 - INFO - epoch 1, step 12000, training loss = 1.992930, validation loss = 2.856751
2018-12-05 02:47:57,846 - INFO - epoch 1, step 12010, training loss = 2.100781, validation loss = 2.319391
2018-12-05 02:48:01,372 - INFO - epoch 1, step 12020, training loss = 1.958358, validation loss = 2.163922
2018-12-05 02:48:04,961 - INFO - epoch 1, step 12030, training loss = 2.070650, validation loss = 2.796425
2018-12-05 02:48:08,720 - INFO - epoch 1, step 12040, training loss = 1.469534, validation loss = 2.970664
2018-12-05 02:48:12,691 - INFO - epoch 1, step 12050, training loss = 2.415452, validation loss = 2.418986
2018-12-05 02:48:17,009 - INFO - epoch 1, step 12060, training loss = 2.282699, validation loss = 2.038323
2018-12-05 02:48:21,272 - INFO - epoch 1, step 12070, training loss = 2.290528, validation loss = 2.431274
2018-12-05 02:48:25,709 - INFO - epoch 1, step 12080, training loss = 2.235942, validation loss = 2.641318
2018-12-05 02:48:30,074 - INFO - epoch 1, step 12090, training loss = 2.007067, validation loss = 2.573881
2018-12-05 02:48:34,274 - INFO - epoch 1, step 12100, training loss = 2.211273, validation loss = 2.149670
2018-12-05 02:48:38,565 - INFO - epoch 1, step 12110, training loss = 2.180496, validation loss = 1.806359
2018-12-05 02:48:42,905 - INFO - epoch 1, step 12120, training loss = 1.902581, validation loss = 2.028360
2018-12-05 02:48:47,131 - INFO - epoch 1, step 12130, training loss = 2.242944, validation loss = 2.589613
2018-12-05 02:48:51,216 - INFO - epoch 1, step 12140, training loss = 1.884664, validation loss = 1.927385
2018-12-05 02:48:55,557 - INFO - epoch 1, step 12150, training loss = 2.278208, validation loss = 2.781288
2018-12-05 02:48:59,738 - INFO - epoch 1, step 12160, training loss = 1.681716, validation loss = 2.534437
2018-12-05 02:49:03,996 - INFO - epoch 1, step 12170, training loss = 2.442707, validation loss = 2.547688
2018-12-05 02:49:08,065 - INFO - epoch 1, step 12180, training loss = 2.477787, validation loss = 2.470452
2018-12-05 02:49:12,501 - INFO - epoch 1, step 12190, training loss = 1.764651, validation loss = 2.781319
2018-12-05 02:49:16,700 - INFO - epoch 1, step 12200, training loss = 2.121114, validation loss = 2.725326
2018-12-05 02:49:20,896 - INFO - epoch 1, step 12210, training loss = 2.137125, validation loss = 2.403378
2018-12-05 02:49:25,242 - INFO - epoch 1, step 12220, training loss = 1.783832, validation loss = 2.313043
2018-12-05 02:49:29,630 - INFO - epoch 1, step 12230, training loss = 2.157689, validation loss = 2.601889
2018-12-05 02:49:33,651 - INFO - epoch 1, step 12240, training loss = 2.494849, validation loss = 2.683807
2018-12-05 02:49:37,785 - INFO - epoch 1, step 12250, training loss = 2.207566, validation loss = 2.460797
2018-12-05 02:49:42,017 - INFO - epoch 1, step 12260, training loss = 1.997195, validation loss = 2.169530
2018-12-05 02:49:46,164 - INFO - epoch 1, step 12270, training loss = 2.389179, validation loss = 2.398415
2018-12-05 02:49:50,222 - INFO - epoch 1, step 12280, training loss = 2.147976, validation loss = 2.598353
2018-12-05 02:49:54,458 - INFO - epoch 1, step 12290, training loss = 2.150071, validation loss = 3.109283
2018-12-05 02:49:58,701 - INFO - epoch 1, step 12300, training loss = 2.413534, validation loss = 2.809799
2018-12-05 02:50:02,746 - INFO - epoch 1, step 12310, training loss = 2.129422, validation loss = 3.151323
2018-12-05 02:50:06,630 - INFO - epoch 1, step 12320, training loss = 2.021890, validation loss = 2.669490
2018-12-05 02:50:10,357 - INFO - epoch 1, step 12330, training loss = 1.825614, validation loss = 3.086064
2018-12-05 02:50:13,929 - INFO - epoch 1, step 12340, training loss = 1.820091, validation loss = 2.656617
2018-12-05 02:50:17,470 - INFO - epoch 1, step 12350, training loss = 2.122448, validation loss = 3.232179
2018-12-05 02:50:21,002 - INFO - epoch 1, step 12360, training loss = 2.219157, validation loss = 2.799359
2018-12-05 02:50:24,858 - INFO - epoch 1, step 12370, training loss = 2.016849, validation loss = 2.525090
2018-12-05 02:50:28,489 - INFO - epoch 1, step 12380, training loss = 2.071647, validation loss = 2.899266
2018-12-05 02:50:32,118 - INFO - epoch 1, step 12390, training loss = 2.444584, validation loss = 3.104339
2018-12-05 02:50:35,937 - INFO - epoch 1, step 12400, training loss = 2.136078, validation loss = 2.485128
2018-12-05 02:50:40,124 - INFO - epoch 1, step 12410, training loss = 2.034748, validation loss = 2.413071
2018-12-05 02:50:44,311 - INFO - epoch 1, step 12420, training loss = 1.985107, validation loss = 3.002863
2018-12-05 02:50:48,370 - INFO - epoch 1, step 12430, training loss = 2.792954, validation loss = 2.533853
2018-12-05 02:50:52,559 - INFO - epoch 1, step 12440, training loss = 2.219117, validation loss = 2.639904
2018-12-05 02:50:56,597 - INFO - epoch 1, step 12450, training loss = 1.939057, validation loss = 2.874850
2018-12-05 02:51:00,602 - INFO - epoch 1, step 12460, training loss = 2.396806, validation loss = 3.180889
2018-12-05 02:51:04,765 - INFO - epoch 1, step 12470, training loss = 1.704735, validation loss = 2.892315
2018-12-05 02:51:08,806 - INFO - epoch 1, step 12480, training loss = 2.369906, validation loss = 2.918070
2018-12-05 02:51:12,758 - INFO - epoch 1, step 12490, training loss = 2.053824, validation loss = 2.600563
2018-12-05 02:51:16,778 - INFO - epoch 1, step 12500, training loss = 1.892483, validation loss = 2.504324
2018-12-05 02:51:20,944 - INFO - epoch 1, step 12510, training loss = 1.896733, validation loss = 3.252575
2018-12-05 02:51:25,170 - INFO - epoch 1, step 12520, training loss = 2.165800, validation loss = 2.719169
2018-12-05 02:51:29,117 - INFO - epoch 1, step 12530, training loss = 2.219345, validation loss = 2.779642
2018-12-05 02:51:33,041 - INFO - epoch 1, step 12540, training loss = 2.314707, validation loss = 3.150696
2018-12-05 02:51:36,914 - INFO - epoch 1, step 12550, training loss = 2.137765, validation loss = 2.612448
2018-12-05 02:51:40,776 - INFO - epoch 1, step 12560, training loss = 2.229704, validation loss = 2.487577
2018-12-05 02:51:44,485 - INFO - epoch 1, step 12570, training loss = 2.639910, validation loss = 2.290014
2018-12-05 02:51:48,313 - INFO - epoch 1, step 12580, training loss = 2.501826, validation loss = 3.072995
2018-12-05 02:51:51,884 - INFO - epoch 1, step 12590, training loss = 1.963858, validation loss = 2.878840
2018-12-05 02:51:55,627 - INFO - epoch 1, step 12600, training loss = 1.955036, validation loss = 3.286608
2018-12-05 02:51:59,472 - INFO - epoch 1, step 12610, training loss = 1.928480, validation loss = 3.498506
2018-12-05 02:52:03,215 - INFO - epoch 1, step 12620, training loss = 2.086841, validation loss = 2.886576
2018-12-05 02:52:07,104 - INFO - epoch 1, step 12630, training loss = 2.017590, validation loss = 3.205209
2018-12-05 02:52:10,802 - INFO - epoch 1, step 12640, training loss = 1.966277, validation loss = 2.555678
2018-12-05 02:52:14,515 - INFO - epoch 1, step 12650, training loss = 1.791546, validation loss = 2.841897
2018-12-05 02:52:18,136 - INFO - epoch 1, step 12660, training loss = 1.716073, validation loss = 2.339682
2018-12-05 02:52:21,857 - INFO - epoch 1, step 12670, training loss = 2.170476, validation loss = 2.605800
2018-12-05 02:52:25,397 - INFO - epoch 1, step 12680, training loss = 2.121608, validation loss = 2.745392
2018-12-05 02:52:28,887 - INFO - epoch 1, step 12690, training loss = 1.753237, validation loss = 3.304592
2018-12-05 02:52:32,363 - INFO - epoch 1, step 12700, training loss = 2.292356, validation loss = 3.188428
2018-12-05 02:52:35,619 - INFO - epoch 1, step 12710, training loss = 2.344681, validation loss = 2.901869
2018-12-05 02:52:38,993 - INFO - epoch 1, step 12720, training loss = 2.246557, validation loss = 2.681883
2018-12-05 02:52:42,497 - INFO - epoch 1, step 12730, training loss = 2.232828, validation loss = 3.742298
2018-12-05 02:52:45,982 - INFO - epoch 1, step 12740, training loss = 2.183977, validation loss = 3.131431
2018-12-05 02:52:49,452 - INFO - epoch 1, step 12750, training loss = 2.369529, validation loss = 2.923974
2018-12-05 02:52:53,006 - INFO - epoch 1, step 12760, training loss = 2.081948, validation loss = 2.922067
2018-12-05 02:52:56,408 - INFO - epoch 1, step 12770, training loss = 2.185658, validation loss = 2.690023
2018-12-05 02:53:00,082 - INFO - epoch 1, step 12780, training loss = 2.454293, validation loss = 2.796456
2018-12-05 02:53:03,648 - INFO - epoch 1, step 12790, training loss = 1.941787, validation loss = 2.679452
2018-12-05 02:53:07,094 - INFO - epoch 1, step 12800, training loss = 2.075533, validation loss = 2.709194
2018-12-05 02:53:11,164 - INFO - epoch 1, step 12810, training loss = 2.131553, validation loss = 3.054847
2018-12-05 02:53:14,992 - INFO - epoch 1, step 12820, training loss = 1.859521, validation loss = 2.436578
2018-12-05 02:53:19,099 - INFO - epoch 1, step 12830, training loss = 2.052889, validation loss = 2.395399
2018-12-05 02:53:22,816 - INFO - epoch 1, step 12840, training loss = 2.056380, validation loss = 2.390774
2018-12-05 02:53:26,828 - INFO - epoch 1, step 12850, training loss = 2.206854, validation loss = 3.367304
2018-12-05 02:53:30,679 - INFO - epoch 1, step 12860, training loss = 1.927275, validation loss = 3.564946
2018-12-05 02:53:34,354 - INFO - epoch 1, step 12870, training loss = 2.534441, validation loss = 3.215380
2018-12-05 02:53:38,379 - INFO - epoch 1, step 12880, training loss = 2.070833, validation loss = 2.850968
2018-12-05 02:53:42,377 - INFO - epoch 1, step 12890, training loss = 1.854686, validation loss = 3.139466
2018-12-05 02:53:45,942 - INFO - epoch 1, step 12900, training loss = 2.110324, validation loss = 2.802535
2018-12-05 02:53:49,500 - INFO - epoch 1, step 12910, training loss = 2.281901, validation loss = 2.810196
2018-12-05 02:53:53,067 - INFO - epoch 1, step 12920, training loss = 2.233221, validation loss = 2.907209
2018-12-05 02:53:56,590 - INFO - epoch 1, step 12930, training loss = 2.370594, validation loss = 3.123190
2018-12-05 02:54:00,109 - INFO - epoch 1, step 12940, training loss = 2.088802, validation loss = 2.899052
2018-12-05 02:54:03,505 - INFO - epoch 1, step 12950, training loss = 2.586291, validation loss = 2.865806
2018-12-05 02:54:06,954 - INFO - epoch 1, step 12960, training loss = 2.136388, validation loss = 2.656738
2018-12-05 02:54:10,361 - INFO - epoch 1, step 12970, training loss = 2.104172, validation loss = 2.947771
2018-12-05 02:54:13,781 - INFO - epoch 1, step 12980, training loss = 2.267371, validation loss = 3.493725
2018-12-05 02:54:17,200 - INFO - epoch 1, step 12990, training loss = 2.344320, validation loss = 2.895363
2018-12-05 02:54:20,512 - INFO - epoch 1, step 13000, training loss = 2.420492, validation loss = 2.820910
2018-12-05 02:54:24,025 - INFO - epoch 1, step 13010, training loss = 1.893658, validation loss = 3.040806
2018-12-05 02:54:27,414 - INFO - epoch 1, step 13020, training loss = 2.140784, validation loss = 3.096270
2018-12-05 02:54:30,726 - INFO - epoch 1, step 13030, training loss = 2.604523, validation loss = 3.299735
2018-12-05 02:54:34,078 - INFO - epoch 1, step 13040, training loss = 2.450137, validation loss = 2.860603
2018-12-05 02:54:37,503 - INFO - epoch 1, step 13050, training loss = 2.245469, validation loss = 3.115021
2018-12-05 02:54:41,083 - INFO - epoch 1, step 13060, training loss = 2.211954, validation loss = 3.192189
2018-12-05 02:54:45,063 - INFO - epoch 1, step 13070, training loss = 1.925696, validation loss = 2.615376
2018-12-05 02:54:49,282 - INFO - epoch 1, step 13080, training loss = 2.178642, validation loss = 3.018529
2018-12-05 02:54:53,501 - INFO - epoch 1, step 13090, training loss = 2.115161, validation loss = 2.855228
2018-12-05 02:54:58,078 - INFO - epoch 1, step 13100, training loss = 2.176999, validation loss = 3.075222
2018-12-05 02:55:02,511 - INFO - epoch 1, step 13110, training loss = 2.124092, validation loss = 3.160597
2018-12-05 02:55:06,436 - INFO - epoch 1, step 13120, training loss = 2.484332, validation loss = 2.241655
2018-12-05 02:55:10,342 - INFO - epoch 1, step 13130, training loss = 2.008822, validation loss = 2.652137
2018-12-05 02:55:14,357 - INFO - epoch 1, step 13140, training loss = 1.970572, validation loss = 3.110149
2018-12-05 02:55:18,309 - INFO - epoch 1, step 13150, training loss = 2.183412, validation loss = 2.362571
2018-12-05 02:55:22,307 - INFO - epoch 1, step 13160, training loss = 2.143120, validation loss = 2.995245
2018-12-05 02:55:26,317 - INFO - epoch 1, step 13170, training loss = 2.101109, validation loss = 2.467555
2018-12-05 02:55:30,449 - INFO - epoch 1, step 13180, training loss = 2.063298, validation loss = 3.253459
2018-12-05 02:55:34,195 - INFO - epoch 1, step 13190, training loss = 2.136140, validation loss = 2.682905
2018-12-05 02:55:38,035 - INFO - epoch 1, step 13200, training loss = 2.382509, validation loss = 3.079543
2018-12-05 02:55:41,516 - INFO - epoch 1, step 13210, training loss = 2.569566, validation loss = 2.778249
2018-12-05 02:55:44,912 - INFO - epoch 1, step 13220, training loss = 2.410016, validation loss = 3.064773
2018-12-05 02:55:48,417 - INFO - epoch 1, step 13230, training loss = 2.312900, validation loss = 3.054679
2018-12-05 02:55:51,775 - INFO - epoch 1, step 13240, training loss = 2.463554, validation loss = 3.822938
2018-12-05 02:55:55,119 - INFO - epoch 1, step 13250, training loss = 2.225499, validation loss = 3.446465
2018-12-05 02:55:58,432 - INFO - epoch 1, step 13260, training loss = 1.952072, validation loss = 2.967801
2018-12-05 02:56:02,026 - INFO - epoch 1, step 13270, training loss = 2.236759, validation loss = 2.750034
2018-12-05 02:56:05,499 - INFO - epoch 1, step 13280, training loss = 1.993672, validation loss = 2.997370
2018-12-05 02:56:09,046 - INFO - epoch 1, step 13290, training loss = 1.957742, validation loss = 2.935453
2018-12-05 02:56:12,583 - INFO - epoch 1, step 13300, training loss = 2.073606, validation loss = 3.118989
2018-12-05 02:56:16,195 - INFO - epoch 1, step 13310, training loss = 2.178770, validation loss = 3.129342
2018-12-05 02:56:19,622 - INFO - epoch 1, step 13320, training loss = 2.363626, validation loss = 2.434821
2018-12-05 02:56:23,025 - INFO - epoch 1, step 13330, training loss = 1.978770, validation loss = 2.404519
2018-12-05 02:56:26,616 - INFO - epoch 1, step 13340, training loss = 2.378679, validation loss = 2.933074
2018-12-05 02:56:30,278 - INFO - epoch 1, step 13350, training loss = 1.903584, validation loss = 2.917700
2018-12-05 02:56:33,845 - INFO - epoch 1, step 13360, training loss = 1.884016, validation loss = 2.845012
2018-12-05 02:56:37,399 - INFO - epoch 1, step 13370, training loss = 2.041380, validation loss = 2.497937
2018-12-05 02:56:41,191 - INFO - epoch 1, step 13380, training loss = 1.754946, validation loss = 2.979633
2018-12-05 02:56:44,736 - INFO - epoch 1, step 13390, training loss = 1.722985, validation loss = 3.065153
2018-12-05 02:56:48,411 - INFO - epoch 1, step 13400, training loss = 1.628822, validation loss = 2.200463
2018-12-05 02:56:51,946 - INFO - epoch 1, step 13410, training loss = 1.921415, validation loss = 2.996780
2018-12-05 02:56:55,747 - INFO - epoch 1, step 13420, training loss = 1.793521, validation loss = 3.378815
2018-12-05 02:56:59,243 - INFO - epoch 1, step 13430, training loss = 2.102044, validation loss = 3.271766
2018-12-05 02:57:02,774 - INFO - epoch 1, step 13440, training loss = 2.098032, validation loss = 2.532528
2018-12-05 02:57:06,315 - INFO - epoch 1, step 13450, training loss = 2.020450, validation loss = 2.643565
2018-12-05 02:57:09,986 - INFO - epoch 1, step 13460, training loss = 1.751499, validation loss = 3.048791
2018-12-05 02:57:13,975 - INFO - epoch 1, step 13470, training loss = 2.008428, validation loss = 3.625201
2018-12-05 02:57:18,085 - INFO - epoch 1, step 13480, training loss = 2.205006, validation loss = 2.924101
2018-12-05 02:57:22,253 - INFO - epoch 1, step 13490, training loss = 2.209823, validation loss = 3.068895
2018-12-05 02:57:26,459 - INFO - epoch 1, step 13500, training loss = 2.436956, validation loss = 2.608166
2018-12-05 02:57:30,569 - INFO - epoch 1, step 13510, training loss = 1.846685, validation loss = 2.444273
2018-12-05 02:57:34,940 - INFO - epoch 1, step 13520, training loss = 1.985527, validation loss = 2.944810
2018-12-05 02:57:39,270 - INFO - epoch 1, step 13530, training loss = 1.958693, validation loss = 2.999515
2018-12-05 02:57:43,416 - INFO - epoch 1, step 13540, training loss = 1.859500, validation loss = 3.333740
2018-12-05 02:57:47,658 - INFO - epoch 1, step 13550, training loss = 2.326537, validation loss = 2.015716
2018-12-05 02:57:51,782 - INFO - epoch 1, step 13560, training loss = 2.108326, validation loss = 3.172810
2018-12-05 02:57:55,980 - INFO - epoch 1, step 13570, training loss = 2.179732, validation loss = 2.838099
2018-12-05 02:58:00,199 - INFO - epoch 1, step 13580, training loss = 2.033974, validation loss = 2.987405
2018-12-05 02:58:04,538 - INFO - epoch 1, step 13590, training loss = 1.839132, validation loss = 2.667600
2018-12-05 02:58:08,721 - INFO - epoch 1, step 13600, training loss = 2.418976, validation loss = 2.150379
2018-12-05 02:58:12,582 - INFO - epoch 1, step 13610, training loss = 2.082410, validation loss = 2.639228
2018-12-05 02:58:15,878 - INFO - epoch 1, step 13620, training loss = 2.230664, validation loss = 2.697712
2018-12-05 02:58:19,168 - INFO - epoch 1, step 13630, training loss = 2.361660, validation loss = 2.588347
2018-12-05 02:58:22,608 - INFO - epoch 1, step 13640, training loss = 2.486286, validation loss = 2.228479
2018-12-05 02:58:26,024 - INFO - epoch 1, step 13650, training loss = 1.906630, validation loss = 3.072841
2018-12-05 02:58:29,487 - INFO - epoch 1, step 13660, training loss = 1.942803, validation loss = 2.535931
2018-12-05 02:58:33,120 - INFO - epoch 1, step 13670, training loss = 2.136712, validation loss = 1.919354
2018-12-05 02:58:36,721 - INFO - epoch 1, step 13680, training loss = 1.688972, validation loss = 2.310281
2018-12-05 02:58:40,340 - INFO - epoch 1, step 13690, training loss = 2.421912, validation loss = 1.953539
2018-12-05 02:58:43,915 - INFO - epoch 1, step 13700, training loss = 1.443196, validation loss = 2.578110
2018-12-05 02:58:47,258 - INFO - epoch 1, step 13710, training loss = 2.044282, validation loss = 2.840000
2018-12-05 02:58:50,680 - INFO - epoch 1, step 13720, training loss = 2.106528, validation loss = 2.777911
2018-12-05 02:58:54,494 - INFO - epoch 1, step 13730, training loss = 2.150602, validation loss = 2.375965
2018-12-05 02:58:58,535 - INFO - epoch 1, step 13740, training loss = 1.930186, validation loss = 2.129316
2018-12-05 02:59:02,642 - INFO - epoch 1, step 13750, training loss = 1.850513, validation loss = 2.276796
2018-12-05 02:59:06,523 - INFO - epoch 1, step 13760, training loss = 1.742309, validation loss = 2.242243
2018-12-05 02:59:10,573 - INFO - epoch 1, step 13770, training loss = 1.911711, validation loss = 2.458957
2018-12-05 02:59:14,622 - INFO - epoch 1, step 13780, training loss = 1.844662, validation loss = 3.014224
2018-12-05 02:59:18,556 - INFO - epoch 1, step 13790, training loss = 2.131217, validation loss = 3.257905
2018-12-05 02:59:22,284 - INFO - epoch 1, step 13800, training loss = 2.010615, validation loss = 3.319729
2018-12-05 02:59:26,000 - INFO - epoch 1, step 13810, training loss = 1.773697, validation loss = 2.520376
2018-12-05 02:59:29,472 - INFO - epoch 1, step 13820, training loss = 1.516747, validation loss = 3.028967
2018-12-05 02:59:33,038 - INFO - epoch 1, step 13830, training loss = 2.039373, validation loss = 2.594523
2018-12-05 02:59:36,535 - INFO - epoch 1, step 13840, training loss = 1.723731, validation loss = 2.250363
2018-12-05 02:59:40,105 - INFO - epoch 1, step 13850, training loss = 2.063175, validation loss = 2.773713
2018-12-05 02:59:43,706 - INFO - epoch 1, step 13860, training loss = 1.443099, validation loss = 2.494831
2018-12-05 02:59:47,343 - INFO - epoch 1, step 13870, training loss = 1.552502, validation loss = 3.011380
2018-12-05 02:59:50,752 - INFO - epoch 1, step 13880, training loss = 2.491913, validation loss = 2.807856
2018-12-05 02:59:55,015 - INFO - epoch 1, step 13890, training loss = 2.335811, validation loss = 2.834804
2018-12-05 02:59:59,333 - INFO - epoch 1, step 13900, training loss = 1.807125, validation loss = 2.804838
2018-12-05 03:00:03,709 - INFO - epoch 1, step 13910, training loss = 2.130090, validation loss = 2.134853
2018-12-05 03:00:07,723 - INFO - epoch 1, step 13920, training loss = 1.796856, validation loss = 2.393879
2018-12-05 03:00:12,087 - INFO - epoch 1, step 13930, training loss = 1.958521, validation loss = 2.389828
2018-12-05 03:00:16,380 - INFO - epoch 1, step 13940, training loss = 2.241669, validation loss = 2.336430
2018-12-05 03:00:20,562 - INFO - epoch 1, step 13950, training loss = 2.589741, validation loss = 2.422672
2018-12-05 03:00:25,003 - INFO - epoch 1, step 13960, training loss = 2.386588, validation loss = 2.462873
2018-12-05 03:00:29,324 - INFO - epoch 1, step 13970, training loss = 1.747804, validation loss = 2.397303
2018-12-05 03:00:33,925 - INFO - epoch 1, step 13980, training loss = 1.903797, validation loss = 2.338096
2018-12-05 03:00:38,275 - INFO - epoch 1, step 13990, training loss = 1.556002, validation loss = 2.408745
2018-12-05 03:00:42,603 - INFO - epoch 1, step 14000, training loss = 1.651995, validation loss = 2.192114
2018-12-05 03:00:46,898 - INFO - epoch 1, step 14010, training loss = 2.183441, validation loss = 2.680201
2018-12-05 03:00:50,743 - INFO - epoch 1, step 14020, training loss = 2.034390, validation loss = 2.507604
2018-12-05 03:00:54,333 - INFO - epoch 1, step 14030, training loss = 2.065614, validation loss = 2.761063
2018-12-05 03:00:58,735 - INFO - epoch 1, step 14040, training loss = 2.190789, validation loss = 2.334430
2018-12-05 03:01:03,060 - INFO - epoch 1, step 14050, training loss = 2.228504, validation loss = 2.099009
2018-12-05 03:01:06,838 - INFO - epoch 1, step 14060, training loss = 2.210919, validation loss = 2.119911
2018-12-05 03:01:10,414 - INFO - epoch 1, step 14070, training loss = 1.990866, validation loss = 2.961517
2018-12-05 03:01:13,995 - INFO - epoch 1, step 14080, training loss = 2.182596, validation loss = 2.718223
2018-12-05 03:01:17,761 - INFO - epoch 1, step 14090, training loss = 2.009153, validation loss = 2.345490
2018-12-05 03:01:21,512 - INFO - epoch 1, step 14100, training loss = 2.435989, validation loss = 2.730054
2018-12-05 03:01:25,240 - INFO - epoch 1, step 14110, training loss = 1.884652, validation loss = 2.714054
2018-12-05 03:01:29,403 - INFO - epoch 1, step 14120, training loss = 2.079196, validation loss = 2.973091
2018-12-05 03:01:33,153 - INFO - epoch 1, step 14130, training loss = 2.108932, validation loss = 2.677320
2018-12-05 03:01:37,003 - INFO - epoch 1, step 14140, training loss = 2.424704, validation loss = 3.140107
2018-12-05 03:01:40,926 - INFO - epoch 1, step 14150, training loss = 2.237903, validation loss = 2.868884
2018-12-05 03:01:44,631 - INFO - epoch 1, step 14160, training loss = 2.034999, validation loss = 2.294125
2018-12-05 03:01:48,417 - INFO - epoch 1, step 14170, training loss = 2.280508, validation loss = 2.478771
2018-12-05 03:01:52,279 - INFO - epoch 1, step 14180, training loss = 2.028358, validation loss = 1.991280
2018-12-05 03:01:56,159 - INFO - epoch 1, step 14190, training loss = 2.432670, validation loss = 2.877339
2018-12-05 03:01:59,827 - INFO - epoch 1, step 14200, training loss = 2.093126, validation loss = 2.999757
2018-12-05 03:02:03,557 - INFO - epoch 1, step 14210, training loss = 2.086399, validation loss = 2.841341
2018-12-05 03:02:07,504 - INFO - epoch 1, step 14220, training loss = 2.178020, validation loss = 2.727496
2018-12-05 03:02:11,531 - INFO - epoch 1, step 14230, training loss = 1.981422, validation loss = 2.681178
2018-12-05 03:02:15,777 - INFO - epoch 1, step 14240, training loss = 1.953954, validation loss = 2.505988
2018-12-05 03:02:20,018 - INFO - epoch 1, step 14250, training loss = 2.140484, validation loss = 2.192273
2018-12-05 03:02:24,344 - INFO - epoch 1, step 14260, training loss = 2.234513, validation loss = 2.508786
2018-12-05 03:02:28,503 - INFO - epoch 1, step 14270, training loss = 1.344195, validation loss = 2.500262
2018-12-05 03:02:32,744 - INFO - epoch 1, step 14280, training loss = 2.135979, validation loss = 2.829333
2018-12-05 03:02:36,989 - INFO - epoch 1, step 14290, training loss = 2.017809, validation loss = 2.910169
2018-12-05 03:02:41,095 - INFO - epoch 1, step 14300, training loss = 2.210024, validation loss = 2.363008
2018-12-05 03:02:45,229 - INFO - epoch 1, step 14310, training loss = 1.846271, validation loss = 2.679346
2018-12-05 03:02:49,380 - INFO - epoch 1, step 14320, training loss = 2.082680, validation loss = 2.684004
2018-12-05 03:02:53,664 - INFO - epoch 1, step 14330, training loss = 2.167855, validation loss = 2.210123
2018-12-05 03:02:57,961 - INFO - epoch 1, step 14340, training loss = 2.409277, validation loss = 2.714571
2018-12-05 03:03:01,981 - INFO - epoch 1, step 14350, training loss = 2.530517, validation loss = 2.713809
2018-12-05 03:03:05,176 - INFO - epoch 1, step 14360, training loss = 2.874772, validation loss = 2.360343
2018-12-05 03:03:08,259 - INFO - epoch 1, step 14370, training loss = 2.674589, validation loss = 2.764276
2018-12-05 03:03:11,461 - INFO - epoch 1, step 14380, training loss = 2.557379, validation loss = 2.842042
2018-12-05 03:03:14,643 - INFO - epoch 1, step 14390, training loss = 2.328227, validation loss = 2.409259
2018-12-05 03:03:17,854 - INFO - epoch 1, step 14400, training loss = 2.426642, validation loss = 2.729143
2018-12-05 03:03:21,087 - INFO - epoch 1, step 14410, training loss = 2.344482, validation loss = 2.483964
2018-12-05 03:03:24,408 - INFO - epoch 1, step 14420, training loss = 2.571426, validation loss = 2.329805
2018-12-05 03:03:27,345 - INFO - epoch 1, step 14430, training loss = 3.186054, validation loss = 2.994936
2018-12-05 03:03:30,428 - INFO - epoch 1, step 14440, training loss = 2.317451, validation loss = 3.015865
2018-12-05 03:03:33,758 - INFO - epoch 1, step 14450, training loss = 2.468115, validation loss = 2.290155
2018-12-05 03:03:36,928 - INFO - epoch 1, step 14460, training loss = 2.806749, validation loss = 2.781621
2018-12-05 03:03:40,182 - INFO - epoch 1, step 14470, training loss = 2.525806, validation loss = 2.863647
2018-12-05 03:03:43,479 - INFO - epoch 1, step 14480, training loss = 2.163009, validation loss = 2.851431
2018-12-05 03:03:46,763 - INFO - epoch 1, step 14490, training loss = 2.474203, validation loss = 3.208903
2018-12-05 03:03:50,167 - INFO - epoch 1, step 14500, training loss = 2.589596, validation loss = 2.553976
2018-12-05 03:03:53,475 - INFO - epoch 1, step 14510, training loss = 2.943333, validation loss = 2.358937
2018-12-05 03:03:56,910 - INFO - epoch 1, step 14520, training loss = 2.886851, validation loss = 2.136650
2018-12-05 03:04:00,551 - INFO - epoch 1, step 14530, training loss = 2.803417, validation loss = 2.493750
2018-12-05 03:04:04,117 - INFO - epoch 1, step 14540, training loss = 2.277312, validation loss = 2.383349
2018-12-05 03:04:07,945 - INFO - epoch 1, step 14550, training loss = 2.833270, validation loss = 1.919719
2018-12-05 03:04:11,654 - INFO - epoch 1, step 14560, training loss = 2.655162, validation loss = 2.546401
2018-12-05 03:04:15,327 - INFO - epoch 1, step 14570, training loss = 2.620065, validation loss = 2.238248
2018-12-05 03:04:18,914 - INFO - epoch 1, step 14580, training loss = 2.770405, validation loss = 2.262683
2018-12-05 03:04:22,619 - INFO - epoch 1, step 14590, training loss = 2.939672, validation loss = 2.334589
2018-12-05 03:04:26,219 - INFO - epoch 1, step 14600, training loss = 2.515013, validation loss = 2.631865
2018-12-05 03:04:29,721 - INFO - epoch 1, step 14610, training loss = 2.869632, validation loss = 2.371027
2018-12-05 03:04:33,293 - INFO - epoch 1, step 14620, training loss = 3.157964, validation loss = 1.962532
2018-12-05 03:04:38,315 - INFO - epoch 1, step 14630, training loss = 2.205543, validation loss = 2.409263
2018-12-05 03:04:44,164 - INFO - epoch 1, step 14640, training loss = 2.196198, validation loss = 2.121884
2018-12-05 03:04:49,670 - INFO - epoch 1, step 14650, training loss = 2.604505, validation loss = 2.281299
2018-12-05 03:04:54,818 - INFO - epoch 1, step 14660, training loss = 1.960997, validation loss = 2.810467
2018-12-05 03:05:00,771 - INFO - epoch 1, step 14670, training loss = 2.124201, validation loss = 2.242100
2018-12-05 03:05:06,618 - INFO - epoch 1, step 14680, training loss = 2.207429, validation loss = 2.326038
2018-12-05 03:05:10,669 - INFO - epoch 1, step 14690, training loss = 2.685724, validation loss = 2.161341
2018-12-05 03:05:13,968 - INFO - epoch 1, step 14700, training loss = 2.103936, validation loss = 2.523350
2018-12-05 03:05:17,491 - INFO - epoch 1, step 14710, training loss = 1.896404, validation loss = 2.611119
2018-12-05 03:05:20,764 - INFO - epoch 1, step 14720, training loss = 2.439835, validation loss = 3.155010
2018-12-05 03:05:24,051 - INFO - epoch 1, step 14730, training loss = 2.511001, validation loss = 2.517516
2018-12-05 03:05:27,418 - INFO - epoch 1, step 14740, training loss = 2.088693, validation loss = 2.704682
2018-12-05 03:05:30,691 - INFO - epoch 1, step 14750, training loss = 2.350537, validation loss = 2.135146
2018-12-05 03:05:33,891 - INFO - epoch 1, step 14760, training loss = 2.102854, validation loss = 2.654466
2018-12-05 03:05:37,055 - INFO - epoch 1, step 14770, training loss = 2.530461, validation loss = 2.709068
2018-12-05 03:05:40,162 - INFO - epoch 1, step 14780, training loss = 2.402048, validation loss = 2.887757
2018-12-05 03:05:43,361 - INFO - epoch 1, step 14790, training loss = 2.219525, validation loss = 2.499348
2018-12-05 03:05:46,484 - INFO - epoch 1, step 14800, training loss = 2.387000, validation loss = 2.832956
2018-12-05 03:05:49,620 - INFO - epoch 1, step 14810, training loss = 2.262236, validation loss = 2.571299
2018-12-05 03:05:52,757 - INFO - epoch 1, step 14820, training loss = 2.982708, validation loss = 1.850154
2018-12-05 03:05:56,024 - INFO - epoch 1, step 14830, training loss = 2.173186, validation loss = 2.528447
2018-12-05 03:05:59,198 - INFO - epoch 1, step 14840, training loss = 2.155367, validation loss = 3.004315
2018-12-05 03:06:02,747 - INFO - epoch 1, step 14850, training loss = 2.237425, validation loss = 2.907193
2018-12-05 03:06:06,285 - INFO - epoch 1, step 14860, training loss = 2.472592, validation loss = 2.653973
2018-12-05 03:06:12,619 - INFO - epoch 1, step 14870, training loss = 2.197994, validation loss = 2.792212
2018-12-05 03:06:18,793 - INFO - epoch 1, step 14880, training loss = 2.320692, validation loss = 2.305772
2018-12-05 03:06:24,846 - INFO - epoch 1, step 14890, training loss = 2.183958, validation loss = 2.073325
2018-12-05 03:06:30,317 - INFO - epoch 1, step 14900, training loss = 1.727463, validation loss = 2.203454
2018-12-05 03:06:35,857 - INFO - epoch 1, step 14910, training loss = 2.347065, validation loss = 2.634929
2018-12-05 03:06:41,470 - INFO - epoch 1, step 14920, training loss = 2.261541, validation loss = 2.529131
2018-12-05 03:06:46,822 - INFO - epoch 1, step 14930, training loss = 2.242446, validation loss = 2.025414
2018-12-05 03:06:52,175 - INFO - epoch 1, step 14940, training loss = 2.286830, validation loss = 2.607715
2018-12-05 03:06:58,032 - INFO - epoch 1, step 14950, training loss = 2.202389, validation loss = 2.014373
2018-12-05 03:07:03,773 - INFO - epoch 1, step 14960, training loss = 1.984425, validation loss = 1.714102
2018-12-05 03:07:09,692 - INFO - epoch 1, step 14970, training loss = 2.119720, validation loss = 1.757879
2018-12-05 03:07:15,802 - INFO - epoch 1, step 14980, training loss = 1.565092, validation loss = 2.166432
2018-12-05 03:07:21,773 - INFO - epoch 1, step 14990, training loss = 2.094166, validation loss = 2.566256
2018-12-05 03:07:27,573 - INFO - epoch 1, step 15000, training loss = 2.182620, validation loss = 2.769906
2018-12-05 03:07:32,795 - INFO - epoch 1, step 15010, training loss = 1.944403, validation loss = 2.776366
2018-12-05 03:07:38,447 - INFO - epoch 1, step 15020, training loss = 1.640751, validation loss = 2.453481
2018-12-05 03:07:44,420 - INFO - epoch 1, step 15030, training loss = 2.008342, validation loss = 2.037441
2018-12-05 03:07:50,015 - INFO - epoch 1, step 15040, training loss = 1.914143, validation loss = 2.269320
2018-12-05 03:07:55,678 - INFO - epoch 1, step 15050, training loss = 2.190064, validation loss = 2.490407
2018-12-05 03:08:01,513 - INFO - epoch 1, step 15060, training loss = 2.162862, validation loss = 2.341795
2018-12-05 03:08:07,757 - INFO - epoch 1, step 15070, training loss = 1.771194, validation loss = 2.113571
2018-12-05 03:08:14,527 - INFO - epoch 1, step 15080, training loss = 2.051937, validation loss = 2.369667
2018-12-05 03:08:20,379 - INFO - epoch 1, step 15090, training loss = 2.419017, validation loss = 2.044517
2018-12-05 03:08:25,608 - INFO - epoch 1, step 15100, training loss = 2.354033, validation loss = 2.237812
2018-12-05 03:08:32,541 - INFO - epoch 1, step 15110, training loss = 1.411973, validation loss = 2.046157
2018-12-05 03:08:38,709 - INFO - epoch 1, step 15120, training loss = 1.547291, validation loss = 2.303015
2018-12-05 03:08:45,061 - INFO - epoch 1, step 15130, training loss = 2.456661, validation loss = 2.632479
2018-12-05 03:08:51,685 - INFO - epoch 1, step 15140, training loss = 2.047591, validation loss = 2.502403
2018-12-05 03:08:57,587 - INFO - epoch 1, step 15150, training loss = 2.300781, validation loss = 2.478623
2018-12-05 03:09:04,223 - INFO - epoch 1, step 15160, training loss = 1.885415, validation loss = 2.091622
2018-12-05 03:09:11,202 - INFO - epoch 1, step 15170, training loss = 1.594513, validation loss = 2.365611
2018-12-05 03:09:17,013 - INFO - epoch 1, step 15180, training loss = 2.057021, validation loss = 2.380137
2018-12-05 03:09:23,597 - INFO - epoch 1, step 15190, training loss = 1.512220, validation loss = 2.191041
2018-12-05 03:09:28,978 - INFO - epoch 1, step 15200, training loss = 2.184511, validation loss = 2.442383
2018-12-05 03:09:34,918 - INFO - epoch 1, step 15210, training loss = 2.288694, validation loss = 2.661938
2018-12-05 03:09:40,756 - INFO - epoch 1, step 15220, training loss = 2.247713, validation loss = 2.220259
2018-12-05 03:09:46,431 - INFO - epoch 1, step 15230, training loss = 2.217869, validation loss = 2.165880
2018-12-05 03:09:52,201 - INFO - epoch 1, step 15240, training loss = 2.640991, validation loss = 2.340766
2018-12-05 03:09:58,585 - INFO - epoch 1, step 15250, training loss = 1.937053, validation loss = 2.528356
2018-12-05 03:10:05,752 - INFO - epoch 1, step 15260, training loss = 1.970236, validation loss = 1.690452
2018-12-05 03:10:11,197 - INFO - epoch 1, step 15270, training loss = 2.097391, validation loss = 2.468266
2018-12-05 03:10:17,128 - INFO - epoch 1, step 15280, training loss = 2.111196, validation loss = 2.289031
2018-12-05 03:10:22,734 - INFO - epoch 1, step 15290, training loss = 2.022597, validation loss = 2.325886
2018-12-05 03:10:28,636 - INFO - epoch 1, step 15300, training loss = 1.708964, validation loss = 2.331243
2018-12-05 03:10:34,058 - INFO - epoch 1, step 15310, training loss = 2.186914, validation loss = 2.576527
2018-12-05 03:10:39,296 - INFO - epoch 1, step 15320, training loss = 2.237176, validation loss = 2.796055
2018-12-05 03:10:44,689 - INFO - epoch 1, step 15330, training loss = 1.802396, validation loss = 2.157592
2018-12-05 03:10:50,527 - INFO - epoch 1, step 15340, training loss = 1.843195, validation loss = 2.182148
2018-12-05 03:10:55,665 - INFO - epoch 1, step 15350, training loss = 2.136026, validation loss = 2.634158
2018-12-05 03:11:01,247 - INFO - epoch 1, step 15360, training loss = 2.216457, validation loss = 2.304440
2018-12-05 03:11:06,594 - INFO - epoch 1, step 15370, training loss = 2.040165, validation loss = 2.496794
2018-12-05 03:11:12,468 - INFO - epoch 1, step 15380, training loss = 2.083937, validation loss = 2.298923
2018-12-05 03:11:17,809 - INFO - epoch 1, step 15390, training loss = 3.021887, validation loss = 2.292341
2018-12-05 03:11:20,985 - INFO - epoch 1, step 15400, training loss = 2.854687, validation loss = 2.821131
2018-12-05 03:11:24,230 - INFO - epoch 1, step 15410, training loss = 2.444401, validation loss = 2.948126
2018-12-05 03:11:27,499 - INFO - epoch 1, step 15420, training loss = 1.965179, validation loss = 2.719701
2018-12-05 03:11:30,652 - INFO - epoch 1, step 15430, training loss = 2.236094, validation loss = 2.700250
2018-12-05 03:11:33,937 - INFO - epoch 1, step 15440, training loss = 2.041190, validation loss = 2.650690
2018-12-05 03:11:37,155 - INFO - epoch 1, step 15450, training loss = 2.438221, validation loss = 2.810340
2018-12-05 03:11:40,390 - INFO - epoch 1, step 15460, training loss = 2.788721, validation loss = 2.387504
2018-12-05 03:11:43,842 - INFO - epoch 1, step 15470, training loss = 1.723935, validation loss = 2.306067
2018-12-05 03:11:47,204 - INFO - epoch 1, step 15480, training loss = 2.038133, validation loss = 2.327307
2018-12-05 03:11:50,376 - INFO - epoch 1, step 15490, training loss = 2.362013, validation loss = 2.547385
2018-12-05 03:11:53,510 - INFO - epoch 1, step 15500, training loss = 2.426622, validation loss = 2.984215
2018-12-05 03:11:56,723 - INFO - epoch 1, step 15510, training loss = 2.177956, validation loss = 2.944345
2018-12-05 03:11:59,823 - INFO - epoch 1, step 15520, training loss = 2.207646, validation loss = 2.284043
2018-12-05 03:12:02,902 - INFO - epoch 1, step 15530, training loss = 2.529375, validation loss = 2.655981
2018-12-05 03:12:06,033 - INFO - epoch 1, step 15540, training loss = 2.495964, validation loss = 2.726350
2018-12-05 03:12:09,233 - INFO - epoch 1, step 15550, training loss = 2.258911, validation loss = 3.528733
2018-12-05 03:12:12,463 - INFO - epoch 1, step 15560, training loss = 2.252715, validation loss = 2.485388
2018-12-05 03:12:15,945 - INFO - epoch 1, step 15570, training loss = 1.931741, validation loss = 2.563815
2018-12-05 03:12:19,118 - INFO - epoch 1, step 15580, training loss = 2.628895, validation loss = 2.615320
2018-12-05 03:12:22,377 - INFO - epoch 1, step 15590, training loss = 2.411496, validation loss = 2.823769
2018-12-05 03:12:27,473 - INFO - epoch 1, step 15600, training loss = 2.169268, validation loss = 2.506085
2018-12-05 03:12:32,437 - INFO - epoch 1, step 15610, training loss = 2.817775, validation loss = 2.751237
2018-12-05 03:12:37,268 - INFO - epoch 1, step 15620, training loss = 2.734408, validation loss = 2.316801
2018-12-05 03:12:42,106 - INFO - epoch 1, step 15630, training loss = 2.725879, validation loss = 2.293195
2018-12-05 03:12:47,060 - INFO - epoch 1, step 15640, training loss = 2.002337, validation loss = 2.656350
2018-12-05 03:12:51,773 - INFO - epoch 1, step 15650, training loss = 2.280361, validation loss = 2.434680
2018-12-05 03:12:56,192 - INFO - epoch 1, step 15660, training loss = 2.912489, validation loss = 2.843625
2018-12-05 03:13:01,005 - INFO - epoch 1, step 15670, training loss = 2.327589, validation loss = 2.498264
2018-12-05 03:13:05,667 - INFO - epoch 1, step 15680, training loss = 2.404904, validation loss = 2.322892
2018-12-05 03:13:10,311 - INFO - epoch 1, step 15690, training loss = 2.817195, validation loss = 2.095134
2018-12-05 03:13:15,055 - INFO - epoch 1, step 15700, training loss = 2.617396, validation loss = 2.461453
2018-12-05 03:13:19,736 - INFO - epoch 1, step 15710, training loss = 2.441706, validation loss = 2.927507
2018-12-05 03:13:25,472 - INFO - epoch 1, step 15720, training loss = 2.108601, validation loss = 2.430143
2018-12-05 03:13:31,168 - INFO - epoch 1, step 15730, training loss = 2.643096, validation loss = 2.679117
2018-12-05 03:13:37,186 - INFO - epoch 1, step 15740, training loss = 2.159403, validation loss = 2.755465
2018-12-05 03:13:42,766 - INFO - epoch 1, step 15750, training loss = 2.085782, validation loss = 2.121515
2018-12-05 03:13:48,537 - INFO - epoch 1, step 15760, training loss = 1.935228, validation loss = 2.444874
2018-12-05 03:13:54,215 - INFO - epoch 1, step 15770, training loss = 1.962490, validation loss = 2.536350
2018-12-05 03:14:00,127 - INFO - epoch 1, step 15780, training loss = 2.139648, validation loss = 2.847730
2018-12-05 03:14:05,285 - INFO - epoch 1, step 15790, training loss = 2.532992, validation loss = 2.221735
2018-12-05 03:14:10,486 - INFO - epoch 1, step 15800, training loss = 2.245506, validation loss = 2.538803
2018-12-05 03:14:15,824 - INFO - epoch 1, step 15810, training loss = 2.190725, validation loss = 2.631644
2018-12-05 03:14:21,226 - INFO - epoch 1, step 15820, training loss = 2.982034, validation loss = 2.213042
2018-12-05 03:14:26,926 - INFO - epoch 1, step 15830, training loss = 2.144743, validation loss = 2.106236
2018-12-05 03:14:32,673 - INFO - epoch 1, step 15840, training loss = 2.594408, validation loss = 2.053776
2018-12-05 03:14:38,226 - INFO - epoch 1, step 15850, training loss = 2.383625, validation loss = 3.038039
2018-12-05 03:14:43,632 - INFO - epoch 1, step 15860, training loss = 2.053420, validation loss = 2.306245
2018-12-05 03:14:49,546 - INFO - epoch 1, step 15870, training loss = 2.069844, validation loss = 1.906637
2018-12-05 03:14:55,082 - INFO - epoch 1, step 15880, training loss = 2.201493, validation loss = 2.610984
2018-12-05 03:15:00,733 - INFO - epoch 1, step 15890, training loss = 2.041630, validation loss = 2.547483
2018-12-05 03:15:06,654 - INFO - epoch 1, step 15900, training loss = 1.886022, validation loss = 2.574141
2018-12-05 03:15:12,105 - INFO - epoch 1, step 15910, training loss = 1.933974, validation loss = 2.781317
2018-12-05 03:15:17,214 - INFO - epoch 1, step 15920, training loss = 1.994294, validation loss = 2.459387
2018-12-05 03:15:21,741 - INFO - epoch 1, step 15930, training loss = 2.393034, validation loss = 2.489531
2018-12-05 03:15:26,032 - INFO - epoch 1, step 15940, training loss = 2.568464, validation loss = 2.728113
2018-12-05 03:15:30,207 - INFO - epoch 1, step 15950, training loss = 2.331011, validation loss = 2.326580
2018-12-05 03:15:34,630 - INFO - epoch 1, step 15960, training loss = 2.194750, validation loss = 2.286710
2018-12-05 03:15:38,866 - INFO - epoch 1, step 15970, training loss = 2.183995, validation loss = 2.225070
2018-12-05 03:15:42,970 - INFO - epoch 1, step 15980, training loss = 1.905386, validation loss = 2.382710
2018-12-05 03:15:47,677 - INFO - epoch 1, step 15990, training loss = 2.040213, validation loss = 2.394952
2018-12-05 03:15:52,182 - INFO - epoch 1, step 16000, training loss = 2.340759, validation loss = 2.565995
2018-12-05 03:15:56,512 - INFO - epoch 1, step 16010, training loss = 2.415371, validation loss = 2.380371
2018-12-05 03:16:00,435 - INFO - epoch 1, step 16020, training loss = 2.336671, validation loss = 2.395887
2018-12-05 03:16:03,898 - INFO - epoch 1, step 16030, training loss = 2.450602, validation loss = 1.985992
2018-12-05 03:16:06,210 - INFO - epoch 1, step 16040, training loss = 2.544370, validation loss = 2.934952
2018-12-05 03:16:08,593 - INFO - epoch 1, step 16050, training loss = 2.500479, validation loss = 3.173688
2018-12-05 03:16:10,985 - INFO - epoch 1, step 16060, training loss = 2.875742, validation loss = 3.151058
2018-12-05 03:16:13,287 - INFO - epoch 1, step 16070, training loss = 2.724677, validation loss = 3.423441
2018-12-05 03:16:15,716 - INFO - epoch 1, step 16080, training loss = 1.918703, validation loss = 2.568488
2018-12-05 03:16:18,119 - INFO - epoch 1, step 16090, training loss = 2.470756, validation loss = 3.463963
2018-12-05 03:16:20,562 - INFO - epoch 1, step 16100, training loss = 2.342859, validation loss = 3.204789
2018-12-05 03:16:23,031 - INFO - epoch 1, step 16110, training loss = 2.795386, validation loss = 3.063803
2018-12-05 03:16:25,396 - INFO - epoch 1, step 16120, training loss = 2.095642, validation loss = 2.756901
2018-12-05 03:16:27,839 - INFO - epoch 1, step 16130, training loss = 2.681630, validation loss = 3.217834
2018-12-05 03:16:30,253 - INFO - epoch 1, step 16140, training loss = 2.109468, validation loss = 2.926188
2018-12-05 03:16:32,757 - INFO - epoch 1, step 16150, training loss = 2.247516, validation loss = 3.014158
2018-12-05 03:16:35,191 - INFO - epoch 1, step 16160, training loss = 2.283308, validation loss = 3.432992
2018-12-05 03:16:37,535 - INFO - epoch 1, step 16170, training loss = 2.047297, validation loss = 3.609454
2018-12-05 03:16:40,069 - INFO - epoch 1, step 16180, training loss = 2.797832, validation loss = 2.449641
2018-12-05 03:16:43,143 - INFO - epoch 1, step 16190, training loss = 2.690608, validation loss = 3.019842
2018-12-05 03:16:46,877 - INFO - epoch 1, step 16200, training loss = 2.683839, validation loss = 2.818756
2018-12-05 03:16:50,510 - INFO - epoch 1, step 16210, training loss = 3.155084, validation loss = 3.029684
2018-12-05 03:16:54,182 - INFO - epoch 1, step 16220, training loss = 2.339079, validation loss = 2.412171
2018-12-05 03:16:57,642 - INFO - epoch 1, step 16230, training loss = 2.747118, validation loss = 2.376791
2018-12-05 03:17:01,166 - INFO - epoch 1, step 16240, training loss = 2.754677, validation loss = 2.670925
2018-12-05 03:17:04,756 - INFO - epoch 1, step 16250, training loss = 2.490769, validation loss = 2.962883
2018-12-05 03:17:08,571 - INFO - epoch 1, step 16260, training loss = 2.831116, validation loss = 2.336685
2018-12-05 03:17:12,229 - INFO - epoch 1, step 16270, training loss = 2.752207, validation loss = 2.707069
2018-12-05 03:17:15,994 - INFO - epoch 1, step 16280, training loss = 2.799259, validation loss = 2.664964
2018-12-05 03:17:19,691 - INFO - epoch 1, step 16290, training loss = 2.676364, validation loss = 2.879977
2018-12-05 03:17:23,346 - INFO - epoch 1, step 16300, training loss = 2.393800, validation loss = 2.693344
2018-12-05 03:17:27,159 - INFO - epoch 1, step 16310, training loss = 2.329500, validation loss = 2.465447
2018-12-05 03:17:29,694 - INFO - epoch 1, step 16320, training loss = 2.502839, validation loss = 2.690947
2018-12-05 03:17:32,060 - INFO - epoch 1, step 16330, training loss = 2.425658, validation loss = 2.436135
2018-12-05 03:17:34,590 - INFO - epoch 1, step 16340, training loss = 2.552448, validation loss = 3.058171
2018-12-05 03:17:36,999 - INFO - epoch 1, step 16350, training loss = 2.489131, validation loss = 2.761589
2018-12-05 03:17:39,500 - INFO - epoch 1, step 16360, training loss = 2.243863, validation loss = 3.596921
2018-12-05 03:17:41,922 - INFO - epoch 1, step 16370, training loss = 2.409841, validation loss = 2.831270
2018-12-05 03:17:44,421 - INFO - epoch 1, step 16380, training loss = 2.721287, validation loss = 2.698010
2018-12-05 03:17:46,771 - INFO - epoch 1, step 16390, training loss = 2.508563, validation loss = 3.239394
2018-12-05 03:17:49,271 - INFO - epoch 1, step 16400, training loss = 2.308647, validation loss = 3.019929
2018-12-05 03:17:51,725 - INFO - epoch 1, step 16410, training loss = 2.235778, validation loss = 3.038801
2018-12-05 03:17:54,087 - INFO - epoch 1, step 16420, training loss = 2.434054, validation loss = 3.172807
2018-12-05 03:17:59,237 - INFO - epoch 1, step 16430, training loss = 2.808448, validation loss = 2.838186
2018-12-05 03:18:04,688 - INFO - epoch 1, step 16440, training loss = 2.412480, validation loss = 2.965691
2018-12-05 03:18:09,773 - INFO - epoch 1, step 16450, training loss = 2.332461, validation loss = 2.681859
2018-12-05 03:18:14,871 - INFO - epoch 1, step 16460, training loss = 2.324667, validation loss = 3.219492
2018-12-05 03:18:19,956 - INFO - epoch 1, step 16470, training loss = 2.413846, validation loss = 2.151853
2018-12-05 03:18:25,255 - INFO - epoch 1, step 16480, training loss = 2.814471, validation loss = 2.424413
2018-12-05 03:18:30,221 - INFO - epoch 1, step 16490, training loss = 2.462749, validation loss = 2.534188
2018-12-05 03:18:35,359 - INFO - epoch 1, step 16500, training loss = 2.703399, validation loss = 2.728321
2018-12-05 03:18:40,473 - INFO - epoch 1, step 16510, training loss = 2.412936, validation loss = 2.849368
2018-12-05 03:18:45,647 - INFO - epoch 1, step 16520, training loss = 2.279314, validation loss = 3.205678
2018-12-05 03:18:50,952 - INFO - epoch 1, step 16530, training loss = 2.583687, validation loss = 2.662907
2018-12-05 03:18:56,145 - INFO - epoch 1, step 16540, training loss = 2.103175, validation loss = 2.383803
2018-12-05 03:19:01,240 - INFO - epoch 1, step 16550, training loss = 2.648484, validation loss = 2.262135
2018-12-05 03:19:06,309 - INFO - epoch 1, step 16560, training loss = 2.840513, validation loss = 2.576848
2018-12-05 03:19:11,629 - INFO - epoch 1, step 16570, training loss = 2.404800, validation loss = 2.921705
2018-12-05 03:19:16,645 - INFO - epoch 1, step 16580, training loss = 2.235172, validation loss = 2.527820
2018-12-05 03:19:21,936 - INFO - epoch 1, step 16590, training loss = 2.261382, validation loss = 2.586843
2018-12-05 03:19:27,154 - INFO - epoch 1, step 16600, training loss = 2.928726, validation loss = 2.447751
2018-12-05 03:19:32,273 - INFO - epoch 1, step 16610, training loss = 2.549570, validation loss = 2.643049
2018-12-05 03:19:37,516 - INFO - epoch 1, step 16620, training loss = 2.446389, validation loss = 2.540676
2018-12-05 03:19:42,787 - INFO - epoch 1, step 16630, training loss = 2.349640, validation loss = 2.487639
2018-12-05 03:19:47,609 - INFO - epoch 1, step 16640, training loss = 2.028897, validation loss = 2.255073
2018-12-05 03:19:51,450 - INFO - epoch 1, step 16650, training loss = 2.361385, validation loss = 2.800691
2018-12-05 03:19:55,299 - INFO - epoch 1, step 16660, training loss = 2.194988, validation loss = 2.690608
2018-12-05 03:19:59,033 - INFO - epoch 1, step 16670, training loss = 1.972627, validation loss = 2.583257
2018-12-05 03:20:02,772 - INFO - epoch 1, step 16680, training loss = 2.108214, validation loss = 2.904669
2018-12-05 03:20:06,413 - INFO - epoch 1, step 16690, training loss = 2.677550, validation loss = 3.362914
2018-12-05 03:20:10,963 - INFO - epoch 1, step 16700, training loss = 2.337379, validation loss = 3.522845
2018-12-05 03:20:15,307 - INFO - epoch 1, step 16710, training loss = 2.448911, validation loss = 3.139328
2018-12-05 03:20:19,861 - INFO - epoch 1, step 16720, training loss = 2.591886, validation loss = 3.160595
2018-12-05 03:20:24,336 - INFO - epoch 1, step 16730, training loss = 2.688100, validation loss = 3.165301
2018-12-05 03:20:28,600 - INFO - epoch 1, step 16740, training loss = 2.204841, validation loss = 3.192844
2018-12-05 03:20:32,835 - INFO - epoch 1, step 16750, training loss = 2.495038, validation loss = 3.367381
2018-12-05 03:20:36,983 - INFO - epoch 1, step 16760, training loss = 2.219408, validation loss = 2.975326
2018-12-05 03:20:40,090 - INFO - epoch 1, step 16770, training loss = 2.283304, validation loss = 2.980641
2018-12-05 03:20:43,249 - INFO - epoch 1, step 16780, training loss = 2.227776, validation loss = 2.624048
2018-12-05 03:20:46,398 - INFO - epoch 1, step 16790, training loss = 2.276450, validation loss = 3.562737
2018-12-05 03:20:49,572 - INFO - epoch 1, step 16800, training loss = 2.678321, validation loss = 3.410365
2018-12-05 03:20:52,853 - INFO - epoch 1, step 16810, training loss = 2.060990, validation loss = 3.097107
2018-12-05 03:20:56,083 - INFO - epoch 1, step 16820, training loss = 2.671342, validation loss = 2.759781
2018-12-05 03:20:59,221 - INFO - epoch 1, step 16830, training loss = 2.614891, validation loss = 2.923795
2018-12-05 03:21:02,385 - INFO - epoch 1, step 16840, training loss = 2.347639, validation loss = 3.595779
2018-12-05 03:21:05,644 - INFO - epoch 1, step 16850, training loss = 2.544126, validation loss = 3.912739
2018-12-05 03:21:08,976 - INFO - epoch 1, step 16860, training loss = 2.163033, validation loss = 3.271294
2018-12-05 03:21:12,124 - INFO - epoch 1, step 16870, training loss = 1.917743, validation loss = 3.652074
2018-12-05 03:21:15,755 - INFO - epoch 1, step 16880, training loss = 2.641443, validation loss = 3.166781
2018-12-05 03:21:19,086 - INFO - epoch 1, step 16890, training loss = 2.141695, validation loss = 3.506501
2018-12-05 03:21:22,356 - INFO - epoch 1, step 16900, training loss = 2.591166, validation loss = 2.826062
2018-12-05 03:21:25,583 - INFO - epoch 1, step 16910, training loss = 2.353180, validation loss = 3.287175
2018-12-05 03:21:28,686 - INFO - epoch 1, step 16920, training loss = 2.669677, validation loss = 2.880827
2018-12-05 03:21:31,962 - INFO - epoch 1, step 16930, training loss = 2.632585, validation loss = 3.486206
2018-12-05 03:21:35,064 - INFO - epoch 1, step 16940, training loss = 2.050791, validation loss = 3.232306
2018-12-05 03:21:38,710 - INFO - epoch 1, step 16950, training loss = 2.367232, validation loss = 3.372561
2018-12-05 03:21:43,748 - INFO - epoch 1, step 16960, training loss = 2.327799, validation loss = 3.600424
2018-12-05 03:21:48,339 - INFO - epoch 1, step 16970, training loss = 2.930390, validation loss = 2.977642
2018-12-05 03:21:53,350 - INFO - epoch 1, step 16980, training loss = 2.185482, validation loss = 3.169554
2018-12-05 03:21:58,085 - INFO - epoch 1, step 16990, training loss = 2.610818, validation loss = 2.706744
2018-12-05 03:22:02,765 - INFO - epoch 1, step 17000, training loss = 2.787214, validation loss = 3.277822
2018-12-05 03:22:07,521 - INFO - epoch 1, step 17010, training loss = 2.383698, validation loss = 3.211692
2018-12-05 03:22:12,122 - INFO - epoch 1, step 17020, training loss = 2.393582, validation loss = 2.979225
2018-12-05 03:22:16,976 - INFO - epoch 1, step 17030, training loss = 2.155262, validation loss = 2.894636
2018-12-05 03:22:21,780 - INFO - epoch 1, step 17040, training loss = 1.953022, validation loss = 2.887381
2018-12-05 03:22:26,393 - INFO - epoch 1, step 17050, training loss = 2.129624, validation loss = 3.018796
2018-12-05 03:22:30,972 - INFO - epoch 1, step 17060, training loss = 2.771244, validation loss = 3.359517
2018-12-05 03:22:35,976 - INFO - epoch 1, step 17070, training loss = 2.655276, validation loss = 3.085826
2018-12-05 03:22:41,329 - INFO - epoch 1, step 17080, training loss = 2.456770, validation loss = 3.066584
2018-12-05 03:22:46,407 - INFO - epoch 1, step 17090, training loss = 2.068460, validation loss = 2.792030
2018-12-05 03:22:51,520 - INFO - epoch 1, step 17100, training loss = 2.084998, validation loss = 2.860590
2018-12-05 03:22:56,765 - INFO - epoch 1, step 17110, training loss = 2.493541, validation loss = 3.406668
2018-12-05 03:23:01,956 - INFO - epoch 1, step 17120, training loss = 2.368029, validation loss = 2.930686
2018-12-05 03:23:06,950 - INFO - epoch 1, step 17130, training loss = 2.319470, validation loss = 3.235964
2018-12-05 03:23:12,088 - INFO - epoch 1, step 17140, training loss = 2.391443, validation loss = 3.630933
2018-12-05 03:23:17,269 - INFO - epoch 1, step 17150, training loss = 2.105235, validation loss = 3.202720
2018-12-05 03:23:22,366 - INFO - epoch 1, step 17160, training loss = 2.084274, validation loss = 3.242377
2018-12-05 03:23:27,386 - INFO - epoch 1, step 17170, training loss = 2.622386, validation loss = 3.561416
2018-12-05 03:23:32,286 - INFO - epoch 1, step 17180, training loss = 2.094872, validation loss = 3.375014
2018-12-05 03:23:37,515 - INFO - epoch 1, step 17190, training loss = 2.064560, validation loss = 3.338891
2018-12-05 03:23:42,745 - INFO - epoch 1, step 17200, training loss = 2.320777, validation loss = 3.073985
2018-12-05 03:23:47,998 - INFO - epoch 1, step 17210, training loss = 2.192974, validation loss = 2.646800
2018-12-05 03:23:53,067 - INFO - epoch 1, step 17220, training loss = 2.553653, validation loss = 3.400095
2018-12-05 03:23:58,421 - INFO - epoch 1, step 17230, training loss = 2.655323, validation loss = 3.128286
2018-12-05 03:24:03,391 - INFO - epoch 1, step 17240, training loss = 2.561318, validation loss = 3.083695
2018-12-05 03:24:08,607 - INFO - epoch 1, step 17250, training loss = 2.346317, validation loss = 3.243295
2018-12-05 03:24:13,636 - INFO - epoch 1, step 17260, training loss = 2.061166, validation loss = 3.014882
2018-12-05 03:24:18,770 - INFO - epoch 1, step 17270, training loss = 2.290325, validation loss = 3.652633
2018-12-05 03:24:23,853 - INFO - epoch 1, step 17280, training loss = 2.422747, validation loss = 3.387726
2018-12-05 03:24:28,758 - INFO - epoch 1, step 17290, training loss = 2.320668, validation loss = 2.793700
2018-12-05 03:24:34,011 - INFO - epoch 1, step 17300, training loss = 1.889946, validation loss = 3.548365
2018-12-05 03:24:39,060 - INFO - epoch 1, step 17310, training loss = 1.980899, validation loss = 3.484719
2018-12-05 03:24:44,159 - INFO - epoch 1, step 17320, training loss = 1.937887, validation loss = 2.976573
2018-12-05 03:24:49,054 - INFO - epoch 1, step 17330, training loss = 2.715087, validation loss = 3.816874
2018-12-05 03:24:54,075 - INFO - epoch 1, step 17340, training loss = 2.089215, validation loss = 3.792761
2018-12-05 03:24:59,497 - INFO - epoch 1, step 17350, training loss = 2.495642, validation loss = 3.461936
2018-12-05 03:25:04,785 - INFO - epoch 1, step 17360, training loss = 2.395021, validation loss = 3.431429
2018-12-05 03:25:09,728 - INFO - epoch 1, step 17370, training loss = 2.280857, validation loss = 3.110500
2018-12-05 03:25:13,918 - INFO - epoch 1, step 17380, training loss = 2.291568, validation loss = 3.529658
2018-12-05 03:25:17,985 - INFO - epoch 1, step 17390, training loss = 2.143149, validation loss = 3.954874
2018-12-05 03:25:22,344 - INFO - epoch 1, step 17400, training loss = 1.726229, validation loss = 3.458931
2018-12-05 03:25:26,815 - INFO - epoch 1, step 17410, training loss = 2.449276, validation loss = 3.770701
2018-12-05 03:25:30,344 - INFO - epoch 1, step 17420, training loss = 3.016524, validation loss = 3.807889
2018-12-05 03:25:32,792 - INFO - epoch 1, step 17430, training loss = 2.677224, validation loss = 4.225384
2018-12-05 03:25:35,228 - INFO - epoch 1, step 17440, training loss = 2.791620, validation loss = 3.558770
2018-12-05 03:25:37,642 - INFO - epoch 1, step 17450, training loss = 2.567755, validation loss = 3.651740
2018-12-05 03:25:40,328 - INFO - epoch 1, step 17460, training loss = 2.508616, validation loss = 3.883376
2018-12-05 03:25:43,056 - INFO - epoch 1, step 17470, training loss = 2.257387, validation loss = 3.478134
2018-12-05 03:25:45,612 - INFO - epoch 1, step 17480, training loss = 2.240576, validation loss = 3.564874
2018-12-05 03:25:48,360 - INFO - epoch 1, step 17490, training loss = 2.414001, validation loss = 3.419003
2018-12-05 03:25:52,269 - INFO - epoch 1, step 17500, training loss = 2.975470, validation loss = 3.153624
2018-12-05 03:25:56,270 - INFO - epoch 1, step 17510, training loss = 2.288289, validation loss = 3.453660
2018-12-05 03:26:00,324 - INFO - epoch 1, step 17520, training loss = 2.720278, validation loss = 3.192479
2018-12-05 03:26:04,410 - INFO - epoch 1, step 17530, training loss = 2.170240, validation loss = 3.223600
2018-12-05 03:26:08,598 - INFO - epoch 1, step 17540, training loss = 2.331969, validation loss = 2.814480
2018-12-05 03:26:13,542 - INFO - epoch 1, step 17550, training loss = 2.646526, validation loss = 3.808902
2018-12-05 03:26:18,820 - INFO - epoch 1, step 17560, training loss = 2.740536, validation loss = 3.616186
2018-12-05 03:26:23,995 - INFO - epoch 1, step 17570, training loss = 2.555266, validation loss = 3.265182
2018-12-05 03:26:29,446 - INFO - epoch 1, step 17580, training loss = 2.768100, validation loss = 3.328177
2018-12-05 03:26:34,675 - INFO - epoch 1, step 17590, training loss = 2.003127, validation loss = 3.772046
2018-12-05 03:26:39,997 - INFO - epoch 1, step 17600, training loss = 2.461771, validation loss = 3.884145
2018-12-05 03:26:45,271 - INFO - epoch 1, step 17610, training loss = 2.255265, validation loss = 3.631506
2018-12-05 03:26:50,459 - INFO - epoch 1, step 17620, training loss = 2.968252, validation loss = 3.341621
2018-12-05 03:26:55,854 - INFO - epoch 1, step 17630, training loss = 2.301502, validation loss = 3.732049
2018-12-05 03:27:01,081 - INFO - epoch 1, step 17640, training loss = 2.206659, validation loss = 3.484615
2018-12-05 03:27:06,215 - INFO - epoch 1, step 17650, training loss = 2.748351, validation loss = 3.297157
2018-12-05 03:27:11,224 - INFO - epoch 1, step 17660, training loss = 2.453116, validation loss = 3.463282
2018-12-05 03:27:16,345 - INFO - epoch 1, step 17670, training loss = 2.606038, validation loss = 3.872294
2018-12-05 03:27:21,704 - INFO - epoch 1, step 17680, training loss = 2.199594, validation loss = 3.545766
2018-12-05 03:27:27,062 - INFO - epoch 1, step 17690, training loss = 2.366872, validation loss = 3.692855
2018-12-05 03:27:32,365 - INFO - epoch 1, step 17700, training loss = 2.360298, validation loss = 3.152845
2018-12-05 03:27:37,697 - INFO - epoch 1, step 17710, training loss = 2.525738, validation loss = 4.193922
2018-12-05 03:27:43,168 - INFO - epoch 1, step 17720, training loss = 2.308173, validation loss = 3.537739
2018-12-05 03:27:48,368 - INFO - epoch 1, step 17730, training loss = 2.456680, validation loss = 3.736860
2018-12-05 03:27:53,606 - INFO - epoch 1, step 17740, training loss = 2.395708, validation loss = 3.587304
2018-12-05 03:27:58,955 - INFO - epoch 1, step 17750, training loss = 2.602942, validation loss = 4.120958
2018-12-05 03:28:03,823 - INFO - epoch 1, step 17760, training loss = 1.978141, validation loss = 3.405054
2018-12-05 03:28:07,980 - INFO - epoch 1, step 17770, training loss = 2.113827, validation loss = 3.224585
2018-12-05 03:28:12,207 - INFO - epoch 1, step 17780, training loss = 2.009046, validation loss = 3.220062
2018-12-05 03:28:16,258 - INFO - epoch 1, step 17790, training loss = 2.232064, validation loss = 3.104384
2018-12-05 03:28:20,528 - INFO - epoch 1, step 17800, training loss = 2.520329, validation loss = 3.178328
2018-12-05 03:28:24,954 - INFO - epoch 1, step 17810, training loss = 2.174751, validation loss = 3.200310
2018-12-05 03:28:28,936 - INFO - epoch 1, step 17820, training loss = 2.208045, validation loss = 3.638678
2018-12-05 03:28:32,189 - INFO - epoch 1, step 17830, training loss = 2.446230, validation loss = 3.078193
2018-12-05 03:28:35,497 - INFO - epoch 1, step 17840, training loss = 2.204036, validation loss = 3.481616
2018-12-05 03:28:38,824 - INFO - epoch 1, step 17850, training loss = 2.091647, validation loss = 3.905138
2018-12-05 03:28:42,023 - INFO - epoch 1, step 17860, training loss = 2.254991, validation loss = 3.310308
2018-12-05 03:28:45,027 - INFO - epoch 1, step 17870, training loss = 2.251715, validation loss = 3.065964
2018-12-05 03:28:48,234 - INFO - epoch 1, step 17880, training loss = 2.548069, validation loss = 3.262081
2018-12-05 03:28:51,458 - INFO - epoch 1, step 17890, training loss = 2.297148, validation loss = 3.302362
2018-12-05 03:28:54,611 - INFO - epoch 1, step 17900, training loss = 2.583986, validation loss = 3.852118
2018-12-05 03:28:57,615 - INFO - epoch 1, step 17910, training loss = 2.613608, validation loss = 3.567349
2018-12-05 03:29:00,777 - INFO - epoch 1, step 17920, training loss = 2.839999, validation loss = 3.645094
2018-12-05 03:29:03,747 - INFO - epoch 1, step 17930, training loss = 2.945522, validation loss = 4.121004
2018-12-05 03:29:06,876 - INFO - epoch 1, step 17940, training loss = 2.793865, validation loss = 3.785520
2018-12-05 03:29:09,950 - INFO - epoch 1, step 17950, training loss = 2.450377, validation loss = 4.129491
2018-12-05 03:29:13,069 - INFO - epoch 1, step 17960, training loss = 2.354209, validation loss = 3.413041
2018-12-05 03:29:16,227 - INFO - epoch 1, step 17970, training loss = 2.067624, validation loss = 3.541329
2018-12-05 03:29:19,417 - INFO - epoch 1, step 17980, training loss = 2.396868, validation loss = 3.508047
2018-12-05 03:29:22,468 - INFO - epoch 1, step 17990, training loss = 2.349555, validation loss = 3.305536
2018-12-05 03:29:25,629 - INFO - epoch 1, step 18000, training loss = 2.354117, validation loss = 4.029126
2018-12-05 03:29:28,893 - INFO - epoch 1, step 18010, training loss = 2.620785, validation loss = 4.120154
2018-12-05 03:29:31,981 - INFO - epoch 1, step 18020, training loss = 2.207642, validation loss = 3.524561
2018-12-05 03:29:34,328 - INFO - epoch 1, step 18030, training loss = 2.539886, validation loss = 4.064351
2018-12-05 03:29:36,798 - INFO - epoch 1, step 18040, training loss = 2.180285, validation loss = 3.494504
2018-12-05 03:29:39,232 - INFO - epoch 1, step 18050, training loss = 2.272562, validation loss = 3.385171
2018-12-05 03:29:41,621 - INFO - epoch 1, step 18060, training loss = 2.574396, validation loss = 3.435323
2018-12-05 03:29:43,926 - INFO - epoch 1, step 18070, training loss = 2.735508, validation loss = 4.233015
2018-12-05 03:29:46,496 - INFO - epoch 1, step 18080, training loss = 2.136672, validation loss = 4.277242
2018-12-05 03:29:48,860 - INFO - epoch 1, step 18090, training loss = 2.059395, validation loss = 3.820776
2018-12-05 03:29:51,262 - INFO - epoch 1, step 18100, training loss = 2.354488, validation loss = 3.611842
2018-12-05 03:29:55,070 - INFO - epoch 1, step 18110, training loss = 2.652170, validation loss = 3.423691
2018-12-05 03:30:00,480 - INFO - epoch 1, step 18120, training loss = 2.252149, validation loss = 3.789135
2018-12-05 03:30:05,688 - INFO - epoch 1, step 18130, training loss = 2.068821, validation loss = 3.812341
2018-12-05 03:30:10,976 - INFO - epoch 1, step 18140, training loss = 2.153579, validation loss = 3.150688
2018-12-05 03:30:17,049 - INFO - epoch 1, step 18150, training loss = 2.360463, validation loss = 3.454802
2018-12-05 03:30:22,446 - INFO - epoch 1, step 18160, training loss = 1.962488, validation loss = 3.817361
2018-12-05 03:30:27,707 - INFO - epoch 1, step 18170, training loss = 1.989499, validation loss = 3.489245
2018-12-05 03:30:32,829 - INFO - epoch 1, step 18180, training loss = 2.280191, validation loss = 3.574705
2018-12-05 03:30:37,874 - INFO - epoch 1, step 18190, training loss = 2.378011, validation loss = 3.575370
2018-12-05 03:30:43,239 - INFO - epoch 1, step 18200, training loss = 2.100260, validation loss = 3.806238
2018-12-05 03:30:48,383 - INFO - epoch 1, step 18210, training loss = 2.280652, validation loss = 3.620627
2018-12-05 03:30:53,348 - INFO - epoch 1, step 18220, training loss = 2.299914, validation loss = 3.379673
2018-12-05 03:30:58,408 - INFO - epoch 1, step 18230, training loss = 2.023918, validation loss = 3.796665
2018-12-05 03:31:03,511 - INFO - epoch 1, step 18240, training loss = 2.239987, validation loss = 3.533878
2018-12-05 03:31:08,705 - INFO - epoch 1, step 18250, training loss = 2.572466, validation loss = 3.537995
2018-12-05 03:31:13,804 - INFO - epoch 1, step 18260, training loss = 2.351471, validation loss = 3.717695
2018-12-05 03:31:18,853 - INFO - epoch 1, step 18270, training loss = 2.156645, validation loss = 3.872279
2018-12-05 03:31:24,121 - INFO - epoch 1, step 18280, training loss = 2.137544, validation loss = 3.697160
2018-12-05 03:31:29,035 - INFO - epoch 1, step 18290, training loss = 2.656906, validation loss = 3.649122
2018-12-05 03:31:33,997 - INFO - epoch 1, step 18300, training loss = 2.692807, validation loss = 3.749401
2018-12-05 03:31:39,009 - INFO - epoch 1, step 18310, training loss = 1.917526, validation loss = 3.538165
2018-12-05 03:31:44,572 - INFO - epoch 1, step 18320, training loss = 2.282598, validation loss = 3.430732
2018-12-05 03:31:49,794 - INFO - epoch 1, step 18330, training loss = 2.241616, validation loss = 3.491132
2018-12-05 03:31:55,078 - INFO - epoch 1, step 18340, training loss = 1.905711, validation loss = 3.335182
2018-12-05 03:32:00,140 - INFO - epoch 1, step 18350, training loss = 2.294029, validation loss = 3.941187
2018-12-05 03:32:05,013 - INFO - epoch 1, step 18360, training loss = 2.602249, validation loss = 4.107039
2018-12-05 03:32:08,294 - INFO - epoch 1, step 18370, training loss = 2.478041, validation loss = 3.420453
2018-12-05 03:32:11,313 - INFO - epoch 1, step 18380, training loss = 2.333040, validation loss = 3.886616
2018-12-05 03:32:14,417 - INFO - epoch 1, step 18390, training loss = 2.018469, validation loss = 4.010379
2018-12-05 03:32:17,495 - INFO - epoch 1, step 18400, training loss = 2.544826, validation loss = 3.527812
2018-12-05 03:32:20,627 - INFO - epoch 1, step 18410, training loss = 2.389968, validation loss = 3.356278
2018-12-05 03:32:23,738 - INFO - epoch 1, step 18420, training loss = 1.920227, validation loss = 3.131339
2018-12-05 03:32:26,840 - INFO - epoch 1, step 18430, training loss = 2.482814, validation loss = 2.763348
2018-12-05 03:32:29,883 - INFO - epoch 1, step 18440, training loss = 2.355942, validation loss = 4.003177
2018-12-05 03:32:32,909 - INFO - epoch 1, step 18450, training loss = 2.723840, validation loss = 3.488601
2018-12-05 03:32:36,256 - INFO - epoch 1, step 18460, training loss = 1.599915, validation loss = 3.378347
2018-12-05 03:32:39,480 - INFO - epoch 1, step 18470, training loss = 2.321966, validation loss = 3.042838
2018-12-05 03:32:42,728 - INFO - epoch 1, step 18480, training loss = 2.240612, validation loss = 3.882120
2018-12-05 03:32:46,174 - INFO - epoch 1, step 18490, training loss = 2.029001, validation loss = 3.955587
2018-12-05 03:32:49,496 - INFO - epoch 1, step 18500, training loss = 2.171218, validation loss = 3.404511
2018-12-05 03:32:52,734 - INFO - epoch 1, step 18510, training loss = 2.168244, validation loss = 3.497977
2018-12-05 03:32:55,845 - INFO - epoch 1, step 18520, training loss = 3.031439, validation loss = 3.520039
2018-12-05 03:32:59,364 - INFO - epoch 1, step 18530, training loss = 2.152965, validation loss = 3.515420
2018-12-05 03:33:02,714 - INFO - epoch 1, step 18540, training loss = 2.058431, validation loss = 3.658758
2018-12-05 03:33:06,032 - INFO - epoch 1, step 18550, training loss = 1.797335, validation loss = 3.100472
2018-12-05 03:33:09,327 - INFO - epoch 1, step 18560, training loss = 1.932645, validation loss = 3.610512
2018-12-05 03:33:12,901 - INFO - epoch 1, step 18570, training loss = 1.724387, validation loss = 3.446768
2018-12-05 03:33:16,181 - INFO - epoch 1, step 18580, training loss = 1.903545, validation loss = 4.022924
2018-12-05 03:33:19,763 - INFO - epoch 1, step 18590, training loss = 2.685756, validation loss = 3.538814
2018-12-05 03:33:23,510 - INFO - epoch 1, step 18600, training loss = 2.336785, validation loss = 3.464963
2018-12-05 03:33:27,064 - INFO - epoch 1, step 18610, training loss = 2.401509, validation loss = 3.790549
2018-12-05 03:33:31,338 - INFO - epoch 1, step 18620, training loss = 2.227050, validation loss = 3.728698
2018-12-05 03:33:36,358 - INFO - epoch 1, step 18630, training loss = 2.519264, validation loss = 3.855019
2018-12-05 03:33:41,590 - INFO - epoch 1, step 18640, training loss = 2.271707, validation loss = 3.477687
2018-12-05 03:33:46,761 - INFO - epoch 1, step 18650, training loss = 2.604774, validation loss = 3.471418
2018-12-05 03:33:51,625 - INFO - epoch 1, step 18660, training loss = 2.226773, validation loss = 3.497671
2018-12-05 03:33:56,956 - INFO - epoch 1, step 18670, training loss = 2.362123, validation loss = 3.444127
2018-12-05 03:34:02,086 - INFO - epoch 1, step 18680, training loss = 2.433399, validation loss = 3.216525
2018-12-05 03:34:06,985 - INFO - epoch 1, step 18690, training loss = 2.335197, validation loss = 3.208966
2018-12-05 03:34:12,048 - INFO - epoch 1, step 18700, training loss = 2.304954, validation loss = 3.593982
2018-12-05 03:34:16,960 - INFO - epoch 1, step 18710, training loss = 2.527086, validation loss = 3.095910
2018-12-05 03:34:22,241 - INFO - epoch 1, step 18720, training loss = 2.193798, validation loss = 4.114403
2018-12-05 03:34:27,618 - INFO - epoch 1, step 18730, training loss = 2.272523, validation loss = 3.744383
2018-12-05 03:34:32,806 - INFO - epoch 1, step 18740, training loss = 1.569497, validation loss = 3.209859
2018-12-05 03:34:37,199 - INFO - epoch 1, step 18750, training loss = 3.001021, validation loss = 3.527436
2018-12-05 03:34:40,304 - INFO - epoch 1, step 18760, training loss = 2.792211, validation loss = 3.319717
2018-12-05 03:34:43,417 - INFO - epoch 1, step 18770, training loss = 2.391973, validation loss = 3.468482
2018-12-05 03:34:46,637 - INFO - epoch 1, step 18780, training loss = 1.799123, validation loss = 3.752825
2018-12-05 03:34:50,309 - INFO - epoch 1, step 18790, training loss = 2.084277, validation loss = 3.441691
2018-12-05 03:34:53,512 - INFO - epoch 1, step 18800, training loss = 2.689831, validation loss = 3.475059
2018-12-05 03:34:56,566 - INFO - epoch 1, step 18810, training loss = 2.543424, validation loss = 3.472172
2018-12-05 03:34:59,604 - INFO - epoch 1, step 18820, training loss = 2.091572, validation loss = 3.242699
2018-12-05 03:35:02,624 - INFO - epoch 1, step 18830, training loss = 2.298816, validation loss = 3.483278
2018-12-05 03:35:05,822 - INFO - epoch 1, step 18840, training loss = 2.524082, validation loss = 3.266647
2018-12-05 03:35:08,990 - INFO - epoch 1, step 18850, training loss = 1.949077, validation loss = 3.506353
2018-12-05 03:35:12,140 - INFO - epoch 1, step 18860, training loss = 2.425727, validation loss = 3.345770
2018-12-05 03:35:15,169 - INFO - epoch 1, step 18870, training loss = 1.869305, validation loss = 3.495321
2018-12-05 03:35:18,257 - INFO - epoch 1, step 18880, training loss = 2.322742, validation loss = 3.434086
2018-12-05 03:35:21,294 - INFO - epoch 1, step 18890, training loss = 2.452317, validation loss = 3.763320
2018-12-05 03:35:24,476 - INFO - epoch 1, step 18900, training loss = 2.208142, validation loss = 3.520275
2018-12-05 03:35:27,864 - INFO - epoch 1, step 18910, training loss = 1.800581, validation loss = 3.590079
2018-12-05 03:35:30,902 - INFO - epoch 1, step 18920, training loss = 2.179418, validation loss = 3.512069
2018-12-05 03:35:34,008 - INFO - epoch 1, step 18930, training loss = 2.416333, validation loss = 3.863243
2018-12-05 03:35:37,131 - INFO - epoch 1, step 18940, training loss = 2.018744, validation loss = 3.498438
2018-12-05 03:35:40,318 - INFO - epoch 1, step 18950, training loss = 1.582343, validation loss = 3.537548
2018-12-05 03:35:43,569 - INFO - epoch 1, step 18960, training loss = 2.098882, validation loss = 3.628161
2018-12-05 03:35:48,035 - INFO - epoch 1, step 18970, training loss = 2.112814, validation loss = 3.393434
2018-12-05 03:35:52,269 - INFO - epoch 1, step 18980, training loss = 2.435520, validation loss = 3.429998
2018-12-05 03:35:56,203 - INFO - epoch 1, step 18990, training loss = 2.316282, validation loss = 3.243693
2018-12-05 03:36:00,642 - INFO - epoch 1, step 19000, training loss = 2.127135, validation loss = 3.590942
2018-12-05 03:36:04,984 - INFO - epoch 1, step 19010, training loss = 2.414449, validation loss = 3.177589
2018-12-05 03:36:08,954 - INFO - epoch 1, step 19020, training loss = 2.701226, validation loss = 3.734428
2018-12-05 03:36:12,537 - INFO - epoch 1, step 19030, training loss = 2.712940, validation loss = 3.608069
2018-12-05 03:36:15,653 - INFO - epoch 1, step 19040, training loss = 2.124760, validation loss = 3.159614
2018-12-05 03:36:18,888 - INFO - epoch 1, step 19050, training loss = 2.190425, validation loss = 3.738231
2018-12-05 03:36:22,055 - INFO - epoch 1, step 19060, training loss = 2.388096, validation loss = 3.315907
2018-12-05 03:36:25,118 - INFO - epoch 1, step 19070, training loss = 2.019203, validation loss = 3.043609
2018-12-05 03:36:28,259 - INFO - epoch 1, step 19080, training loss = 2.813837, validation loss = 3.610805
2018-12-05 03:36:31,307 - INFO - epoch 1, step 19090, training loss = 2.436422, validation loss = 3.738100
2018-12-05 03:36:34,482 - INFO - epoch 1, step 19100, training loss = 2.055563, validation loss = 3.325486
2018-12-05 03:36:37,466 - INFO - epoch 1, step 19110, training loss = 2.337981, validation loss = 3.175660
2018-12-05 03:36:40,496 - INFO - epoch 1, step 19120, training loss = 2.584850, validation loss = 3.183189
2018-12-05 03:36:43,525 - INFO - epoch 1, step 19130, training loss = 2.183447, validation loss = 3.483517
2018-12-05 03:36:46,688 - INFO - epoch 1, step 19140, training loss = 2.022475, validation loss = 3.164234
2018-12-05 03:36:49,830 - INFO - epoch 1, step 19150, training loss = 2.049697, validation loss = 3.806882
2018-12-05 03:36:52,992 - INFO - epoch 1, step 19160, training loss = 2.322975, validation loss = 3.226534
2018-12-05 03:36:56,148 - INFO - epoch 1, step 19170, training loss = 2.145262, validation loss = 3.399130
2018-12-05 03:36:59,120 - INFO - epoch 1, step 19180, training loss = 2.241468, validation loss = 3.564993
2018-12-05 03:37:02,308 - INFO - epoch 1, step 19190, training loss = 1.888008, validation loss = 3.610830
2018-12-05 03:37:05,534 - INFO - epoch 1, step 19200, training loss = 2.577788, validation loss = 2.903577
2018-12-05 03:37:08,641 - INFO - epoch 1, step 19210, training loss = 2.794361, validation loss = 3.548234
2018-12-05 03:37:11,591 - INFO - epoch 1, step 19220, training loss = 2.686980, validation loss = 3.802210
2018-12-05 03:37:15,969 - INFO - epoch 1, step 19230, training loss = 3.117393, validation loss = 3.521702
2018-12-05 03:37:20,935 - INFO - epoch 1, step 19240, training loss = 2.501975, validation loss = 3.759583
2018-12-05 03:37:26,479 - INFO - epoch 1, step 19250, training loss = 2.396411, validation loss = 3.597591
2018-12-05 03:37:31,476 - INFO - epoch 1, step 19260, training loss = 2.243322, validation loss = 3.686550
2018-12-05 03:37:36,589 - INFO - epoch 1, step 19270, training loss = 2.331343, validation loss = 3.847091
2018-12-05 03:37:41,548 - INFO - epoch 1, step 19280, training loss = 2.021637, validation loss = 3.767253
2018-12-05 03:37:46,447 - INFO - epoch 1, step 19290, training loss = 2.622535, validation loss = 3.575541
2018-12-05 03:37:51,656 - INFO - epoch 1, step 19300, training loss = 2.723305, validation loss = 3.753996
2018-12-05 03:37:56,788 - INFO - epoch 1, step 19310, training loss = 2.162740, validation loss = 3.741107
2018-12-05 03:38:01,959 - INFO - epoch 1, step 19320, training loss = 2.024418, validation loss = 2.977251
2018-12-05 03:38:06,989 - INFO - epoch 1, step 19330, training loss = 1.982389, validation loss = 3.119643
2018-12-05 03:38:11,910 - INFO - epoch 1, step 19340, training loss = 2.516009, validation loss = 3.537913
2018-12-05 03:38:16,954 - INFO - epoch 1, step 19350, training loss = 1.813609, validation loss = 3.348874
2018-12-05 03:38:22,582 - INFO - epoch 1, step 19360, training loss = 2.008647, validation loss = 3.277432
2018-12-05 03:38:28,644 - INFO - epoch 1, step 19370, training loss = 1.736537, validation loss = 3.358692
2018-12-05 03:38:34,488 - INFO - epoch 1, step 19380, training loss = 1.747320, validation loss = 3.214002
2018-12-05 03:38:40,325 - INFO - epoch 1, step 19390, training loss = 1.986057, validation loss = 3.636127
2018-12-05 03:38:45,791 - INFO - epoch 1, step 19400, training loss = 1.820448, validation loss = 3.440811
2018-12-05 03:38:51,572 - INFO - epoch 1, step 19410, training loss = 1.946371, validation loss = 3.391239
2018-12-05 03:38:57,698 - INFO - epoch 1, step 19420, training loss = 2.095908, validation loss = 3.453173
2018-12-05 03:39:03,186 - INFO - epoch 1, step 19430, training loss = 1.992780, validation loss = 3.868368
2018-12-05 03:39:08,591 - INFO - epoch 1, step 19440, training loss = 2.300452, validation loss = 3.203971
2018-12-05 03:39:13,822 - INFO - epoch 1, step 19450, training loss = 1.961595, validation loss = 3.763124
2018-12-05 03:39:19,075 - INFO - epoch 1, step 19460, training loss = 2.282329, validation loss = 3.876917
2018-12-05 03:39:25,187 - INFO - epoch 1, step 19470, training loss = 2.135393, validation loss = 3.861236
2018-12-05 03:39:30,646 - INFO - epoch 1, step 19480, training loss = 2.247688, validation loss = 3.514628
2018-12-05 03:39:36,471 - INFO - epoch 1, step 19490, training loss = 2.017604, validation loss = 3.429194
2018-12-05 03:39:42,509 - INFO - epoch 1, step 19500, training loss = 2.083763, validation loss = 3.498720
2018-12-05 03:39:48,414 - INFO - epoch 1, step 19510, training loss = 1.594977, validation loss = 3.861421
2018-12-05 03:39:54,377 - INFO - epoch 1, step 19520, training loss = 1.506069, validation loss = 3.327899
2018-12-05 03:40:00,653 - INFO - epoch 1, step 19530, training loss = 2.162719, validation loss = 3.499527
2018-12-05 03:40:04,689 - INFO - epoch 1, step 19540, training loss = 2.331782, validation loss = 3.305355
2018-12-05 03:40:09,108 - INFO - epoch 1, step 19550, training loss = 2.102813, validation loss = 2.922770
2018-12-05 03:40:13,311 - INFO - epoch 1, step 19560, training loss = 2.542284, validation loss = 3.511540
2018-12-05 03:40:17,340 - INFO - epoch 1, step 19570, training loss = 2.116578, validation loss = 3.544336
2018-12-05 03:40:21,724 - INFO - epoch 1, step 19580, training loss = 2.481663, validation loss = 3.214718
2018-12-05 03:40:25,899 - INFO - epoch 1, step 19590, training loss = 2.270555, validation loss = 3.344803
2018-12-05 03:40:29,957 - INFO - epoch 1, step 19600, training loss = 2.688504, validation loss = 3.525361
2018-12-05 03:40:33,925 - INFO - epoch 1, step 19610, training loss = 2.372399, validation loss = 3.282455
2018-12-05 03:40:38,085 - INFO - epoch 1, step 19620, training loss = 2.629820, validation loss = 3.785840
2018-12-05 03:40:42,245 - INFO - epoch 1, step 19630, training loss = 2.059422, validation loss = 3.388486
2018-12-05 03:40:46,395 - INFO - epoch 1, step 19640, training loss = 2.256031, validation loss = 3.521407
2018-12-05 03:40:50,755 - INFO - epoch 1, step 19650, training loss = 2.417854, validation loss = 3.685774
2018-12-05 03:40:56,061 - INFO - epoch 1, step 19660, training loss = 2.047259, validation loss = 3.422385
2018-12-05 03:41:01,690 - INFO - epoch 1, step 19670, training loss = 2.042023, validation loss = 3.410766
2018-12-05 03:41:06,879 - INFO - epoch 1, step 19680, training loss = 1.984565, validation loss = 3.825909
2018-12-05 03:41:11,839 - INFO - epoch 1, step 19690, training loss = 1.958834, validation loss = 3.217335
2018-12-05 03:41:17,591 - INFO - epoch 1, step 19700, training loss = 1.730271, validation loss = 3.296189
2018-12-05 03:41:23,409 - INFO - epoch 1, step 19710, training loss = 1.821182, validation loss = 3.639313
2018-12-05 03:41:28,674 - INFO - epoch 1, step 19720, training loss = 2.171611, validation loss = 3.592356
2018-12-05 03:41:34,726 - INFO - epoch 1, step 19730, training loss = 1.953987, validation loss = 3.375180
2018-12-05 03:41:40,435 - INFO - epoch 1, step 19740, training loss = 2.081122, validation loss = 3.086725
2018-12-05 03:41:45,669 - INFO - epoch 1, step 19750, training loss = 2.539467, validation loss = 2.986455
2018-12-05 03:41:50,868 - INFO - epoch 1, step 19760, training loss = 1.855740, validation loss = 2.732522
2018-12-05 03:41:56,416 - INFO - epoch 1, step 19770, training loss = 2.101220, validation loss = 3.376913
2018-12-05 03:42:02,028 - INFO - epoch 1, step 19780, training loss = 1.983709, validation loss = 3.487598
2018-12-05 03:42:07,711 - INFO - epoch 1, step 19790, training loss = 2.270232, validation loss = 3.437519
2018-12-05 03:42:12,983 - INFO - epoch 1, step 19800, training loss = 2.243519, validation loss = 2.986999
2018-12-05 03:42:18,607 - INFO - epoch 1, step 19810, training loss = 2.418878, validation loss = 3.170766
2018-12-05 03:42:23,981 - INFO - epoch 1, step 19820, training loss = 2.321600, validation loss = 3.614321
2018-12-05 03:42:29,454 - INFO - epoch 1, step 19830, training loss = 2.098555, validation loss = 3.091809
2018-12-05 03:42:34,854 - INFO - epoch 1, step 19840, training loss = 1.923264, validation loss = 3.863451
2018-12-05 03:42:40,449 - INFO - epoch 1, step 19850, training loss = 2.008783, validation loss = 3.675017
2018-12-05 03:42:45,924 - INFO - epoch 1, step 19860, training loss = 2.184576, validation loss = 3.423244
2018-12-05 03:42:51,578 - INFO - epoch 1, step 19870, training loss = 1.890270, validation loss = 4.144792
2018-12-05 03:42:56,451 - INFO - epoch 1, step 19880, training loss = 2.646622, validation loss = 3.220968
2018-12-05 03:42:59,520 - INFO - epoch 1, step 19890, training loss = 2.462290, validation loss = 3.423394
2018-12-05 03:43:03,671 - INFO - epoch 1, step 19900, training loss = 2.098052, validation loss = 3.374293
2018-12-05 03:43:06,971 - INFO - epoch 1, step 19910, training loss = 2.325835, validation loss = 3.573784
2018-12-05 03:43:10,230 - INFO - epoch 1, step 19920, training loss = 2.505106, validation loss = 3.385988
2018-12-05 03:43:13,547 - INFO - epoch 1, step 19930, training loss = 2.670580, validation loss = 3.701519
2018-12-05 03:43:16,689 - INFO - epoch 1, step 19940, training loss = 2.265866, validation loss = 3.714389
2018-12-05 03:43:19,839 - INFO - epoch 1, step 19950, training loss = 2.169487, validation loss = 3.537508
2018-12-05 03:43:22,976 - INFO - epoch 1, step 19960, training loss = 2.210162, validation loss = 3.343929
2018-12-05 03:43:26,297 - INFO - epoch 1, step 19970, training loss = 2.409910, validation loss = 3.580067
2018-12-05 03:43:29,430 - INFO - epoch 1, step 19980, training loss = 2.762724, validation loss = 4.467892
2018-12-05 03:43:32,678 - INFO - epoch 1, step 19990, training loss = 2.603379, validation loss = 2.895773
2018-12-05 03:43:35,990 - INFO - epoch 1, step 20000, training loss = 2.331594, validation loss = 3.563489
2018-12-05 03:43:39,139 - INFO - epoch 1, step 20010, training loss = 1.993313, validation loss = 3.318434
2018-12-05 03:43:42,418 - INFO - epoch 1, step 20020, training loss = 2.341201, validation loss = 2.971138
2018-12-05 03:43:45,571 - INFO - epoch 1, step 20030, training loss = 2.427710, validation loss = 3.333062
2018-12-05 03:43:48,630 - INFO - epoch 1, step 20040, training loss = 2.253157, validation loss = 3.705194
2018-12-05 03:43:51,767 - INFO - epoch 1, step 20050, training loss = 2.721864, validation loss = 3.469776
2018-12-05 03:43:54,901 - INFO - epoch 1, step 20060, training loss = 2.648975, validation loss = 3.393836
2018-12-05 03:43:58,056 - INFO - epoch 1, step 20070, training loss = 2.183329, validation loss = 3.035465
2018-12-05 03:44:01,254 - INFO - epoch 1, step 20080, training loss = 2.411292, validation loss = 3.879349
2018-12-05 03:44:04,500 - INFO - epoch 1, step 20090, training loss = 2.712446, validation loss = 3.191177
2018-12-05 03:44:07,763 - INFO - epoch 1, step 20100, training loss = 2.403604, validation loss = 3.532157
2018-12-05 03:44:10,905 - INFO - epoch 1, step 20110, training loss = 2.128692, validation loss = 4.165894
2018-12-05 03:44:14,267 - INFO - epoch 1, step 20120, training loss = 2.413765, validation loss = 3.125290
2018-12-05 03:44:17,521 - INFO - epoch 1, step 20130, training loss = 2.214134, validation loss = 3.471537
2018-12-05 03:44:20,578 - INFO - epoch 1, step 20140, training loss = 2.077962, validation loss = 3.120898
2018-12-05 03:44:23,890 - INFO - epoch 1, step 20150, training loss = 1.872671, validation loss = 3.353109
2018-12-05 03:44:27,171 - INFO - epoch 1, step 20160, training loss = 2.428741, validation loss = 3.436377
2018-12-05 03:44:30,252 - INFO - epoch 1, step 20170, training loss = 2.816117, validation loss = 3.220713
2018-12-05 03:44:33,354 - INFO - epoch 1, step 20180, training loss = 2.228106, validation loss = 3.627914
2018-12-05 03:44:36,329 - INFO - epoch 1, step 20190, training loss = 2.370412, validation loss = 3.823418
2018-12-05 03:44:39,453 - INFO - epoch 1, step 20200, training loss = 1.879169, validation loss = 3.521437
2018-12-05 03:44:42,575 - INFO - epoch 1, step 20210, training loss = 2.533292, validation loss = 3.390922
2018-12-05 03:44:45,907 - INFO - epoch 1, step 20220, training loss = 2.101745, validation loss = 3.542137
2018-12-05 03:44:50,014 - INFO - epoch 1, step 20230, training loss = 2.446671, validation loss = 3.500238
2018-12-05 03:44:54,545 - INFO - epoch 1, step 20240, training loss = 2.651867, validation loss = 3.665838
2018-12-05 03:44:58,936 - INFO - epoch 1, step 20250, training loss = 2.099738, validation loss = 3.013044
2018-12-05 03:45:03,054 - INFO - epoch 1, step 20260, training loss = 2.385148, validation loss = 3.632837
2018-12-05 03:45:07,395 - INFO - epoch 1, step 20270, training loss = 2.351949, validation loss = 3.616451
2018-12-05 03:45:11,787 - INFO - epoch 1, step 20280, training loss = 2.248931, validation loss = 3.923140
2018-12-05 03:45:15,945 - INFO - epoch 1, step 20290, training loss = 2.222816, validation loss = 4.194267
2018-12-05 03:45:20,442 - INFO - epoch 1, step 20300, training loss = 2.490181, validation loss = 3.194932
2018-12-05 03:45:24,760 - INFO - epoch 1, step 20310, training loss = 2.596434, validation loss = 3.313537
2018-12-05 03:45:29,029 - INFO - epoch 1, step 20320, training loss = 1.958167, validation loss = 3.013389
2018-12-05 03:45:33,252 - INFO - epoch 1, step 20330, training loss = 2.105906, validation loss = 3.429832
2018-12-05 03:45:37,370 - INFO - epoch 1, step 20340, training loss = 2.266393, validation loss = 3.340229
2018-12-05 03:45:41,714 - INFO - epoch 1, step 20350, training loss = 2.337725, validation loss = 2.819107
2018-12-05 03:45:45,732 - INFO - epoch 1, step 20360, training loss = 2.416221, validation loss = 3.327088
2018-12-05 03:45:49,757 - INFO - epoch 1, step 20370, training loss = 1.962605, validation loss = 3.709729
2018-12-05 03:45:53,884 - INFO - epoch 1, step 20380, training loss = 2.211982, validation loss = 3.531449
2018-12-05 03:45:57,869 - INFO - epoch 1, step 20390, training loss = 1.982184, validation loss = 3.405958
2018-12-05 03:46:02,503 - INFO - epoch 1, step 20400, training loss = 2.082379, validation loss = 3.083485
2018-12-05 03:46:07,062 - INFO - epoch 1, step 20410, training loss = 1.570477, validation loss = 3.340953
2018-12-05 03:46:11,634 - INFO - epoch 1, step 20420, training loss = 2.121346, validation loss = 3.602111
2018-12-05 03:46:16,205 - INFO - epoch 1, step 20430, training loss = 2.282941, validation loss = 2.805503
2018-12-05 03:46:20,459 - INFO - epoch 1, step 20440, training loss = 2.469613, validation loss = 3.201337
2018-12-05 03:46:24,890 - INFO - epoch 1, step 20450, training loss = 2.388196, validation loss = 3.197524
2018-12-05 03:46:29,195 - INFO - epoch 1, step 20460, training loss = 2.016320, validation loss = 3.319821
2018-12-05 03:46:33,232 - INFO - epoch 1, step 20470, training loss = 2.617842, validation loss = 3.104991
2018-12-05 03:46:38,376 - INFO - epoch 1, step 20480, training loss = 2.376432, validation loss = 3.502060
2018-12-05 03:46:43,248 - INFO - epoch 1, step 20490, training loss = 2.655524, validation loss = 3.157576
2018-12-05 03:46:48,383 - INFO - epoch 1, step 20500, training loss = 2.023227, validation loss = 3.497480
2018-12-05 03:46:53,326 - INFO - epoch 1, step 20510, training loss = 2.289437, validation loss = 3.489242
2018-12-05 03:46:58,293 - INFO - epoch 1, step 20520, training loss = 2.353128, validation loss = 3.591393
2018-12-05 03:47:03,352 - INFO - epoch 1, step 20530, training loss = 2.450074, validation loss = 3.152065
2018-12-05 03:47:08,376 - INFO - epoch 1, step 20540, training loss = 2.926585, validation loss = 3.819767
2018-12-05 03:47:13,388 - INFO - epoch 1, step 20550, training loss = 2.181834, validation loss = 3.379201
2018-12-05 03:47:18,393 - INFO - epoch 1, step 20560, training loss = 2.151791, validation loss = 3.123391
2018-12-05 03:47:23,298 - INFO - epoch 1, step 20570, training loss = 2.252296, validation loss = 3.559242
2018-12-05 03:47:28,196 - INFO - epoch 1, step 20580, training loss = 2.647737, validation loss = 3.756876
2018-12-05 03:47:33,424 - INFO - epoch 1, step 20590, training loss = 2.457335, validation loss = 3.139731
2018-12-05 03:47:38,406 - INFO - epoch 1, step 20600, training loss = 2.246555, validation loss = 3.418632
2018-12-05 03:47:43,444 - INFO - epoch 1, step 20610, training loss = 2.043587, validation loss = 3.629918
2018-12-05 03:47:48,031 - INFO - epoch 1, step 20620, training loss = 2.715870, validation loss = 3.451511
2018-12-05 03:47:51,636 - INFO - epoch 1, step 20630, training loss = 2.532314, validation loss = 3.218074
2018-12-05 03:47:55,210 - INFO - epoch 1, step 20640, training loss = 2.698060, validation loss = 3.062625
2018-12-05 03:47:58,890 - INFO - epoch 1, step 20650, training loss = 2.289944, validation loss = 3.188381
2018-12-05 03:48:02,572 - INFO - epoch 1, step 20660, training loss = 2.237676, validation loss = 3.471781
2018-12-05 03:48:06,162 - INFO - epoch 1, step 20670, training loss = 2.514078, validation loss = 3.435297
2018-12-05 03:48:09,753 - INFO - epoch 1, step 20680, training loss = 2.765751, validation loss = 3.132943
2018-12-05 03:48:13,422 - INFO - epoch 1, step 20690, training loss = 2.565728, validation loss = 3.450893
2018-12-05 03:48:17,071 - INFO - epoch 1, step 20700, training loss = 2.197014, validation loss = 2.987018
2018-12-05 03:48:20,613 - INFO - epoch 1, step 20710, training loss = 2.239682, validation loss = 3.155448
2018-12-05 03:48:24,390 - INFO - epoch 1, step 20720, training loss = 1.963742, validation loss = 3.566664
2018-12-05 03:48:28,746 - INFO - epoch 1, step 20730, training loss = 2.188158, validation loss = 2.918565
2018-12-05 03:48:33,238 - INFO - epoch 1, step 20740, training loss = 2.125977, validation loss = 3.278152
2018-12-05 03:48:37,658 - INFO - epoch 1, step 20750, training loss = 1.638180, validation loss = 3.829824
2018-12-05 03:48:41,791 - INFO - epoch 1, step 20760, training loss = 2.146114, validation loss = 3.145348
2018-12-05 03:48:45,874 - INFO - epoch 1, step 20770, training loss = 2.250185, validation loss = 3.429440
2018-12-05 03:48:50,526 - INFO - epoch 1, step 20780, training loss = 2.405580, validation loss = 3.245800
2018-12-05 03:48:55,404 - INFO - epoch 1, step 20790, training loss = 2.431885, validation loss = 3.346874
2018-12-05 03:48:58,466 - INFO - epoch 1, step 20800, training loss = 2.515073, validation loss = 3.630628
2018-12-05 03:49:01,462 - INFO - epoch 1, step 20810, training loss = 1.757907, validation loss = 3.371614
2018-12-05 03:49:04,809 - INFO - epoch 1, step 20820, training loss = 2.503499, validation loss = 2.956012
2018-12-05 03:49:07,937 - INFO - epoch 1, step 20830, training loss = 2.062385, validation loss = 3.951028
2018-12-05 03:49:11,090 - INFO - epoch 1, step 20840, training loss = 2.246174, validation loss = 3.541147
2018-12-05 03:49:14,221 - INFO - epoch 1, step 20850, training loss = 1.759226, validation loss = 3.899267
2018-12-05 03:49:17,445 - INFO - epoch 1, step 20860, training loss = 2.213221, validation loss = 3.714820
2018-12-05 03:49:20,694 - INFO - epoch 1, step 20870, training loss = 2.587579, validation loss = 3.518894
2018-12-05 03:49:23,751 - INFO - epoch 1, step 20880, training loss = 2.620374, validation loss = 3.405076
2018-12-05 03:49:26,844 - INFO - epoch 1, step 20890, training loss = 2.466667, validation loss = 3.556585
2018-12-05 03:49:30,100 - INFO - epoch 1, step 20900, training loss = 2.518480, validation loss = 3.777945
2018-12-05 03:49:33,229 - INFO - epoch 1, step 20910, training loss = 1.819138, validation loss = 3.748958
2018-12-05 03:49:36,449 - INFO - epoch 1, step 20920, training loss = 2.524188, validation loss = 3.854167
2018-12-05 03:49:39,494 - INFO - epoch 1, step 20930, training loss = 2.605409, validation loss = 3.480576
2018-12-05 03:49:42,618 - INFO - epoch 1, step 20940, training loss = 1.982957, validation loss = 3.780869
2018-12-05 03:49:45,806 - INFO - epoch 1, step 20950, training loss = 2.240068, validation loss = 2.952734
2018-12-05 03:49:51,417 - INFO - epoch 1, step 20960, training loss = 2.137792, validation loss = 3.677516
2018-12-05 03:49:57,604 - INFO - epoch 1, step 20970, training loss = 1.899692, validation loss = 3.933660
2018-12-05 03:50:03,306 - INFO - epoch 1, step 20980, training loss = 2.260547, validation loss = 3.458757
2018-12-05 03:50:08,996 - INFO - epoch 1, step 20990, training loss = 2.270422, validation loss = 3.520329
2018-12-05 03:50:14,614 - INFO - epoch 1, step 21000, training loss = 2.102078, validation loss = 3.242052
2018-12-05 03:50:20,578 - INFO - epoch 1, step 21010, training loss = 2.294000, validation loss = 3.165817
2018-12-05 03:50:26,559 - INFO - epoch 1, step 21020, training loss = 2.376611, validation loss = 3.674471
2018-12-05 03:50:32,016 - INFO - epoch 1, step 21030, training loss = 2.075663, validation loss = 2.968324
2018-12-05 03:50:38,462 - INFO - epoch 1, step 21040, training loss = 1.754812, validation loss = 3.558147
2018-12-05 03:50:43,741 - INFO - epoch 1, step 21050, training loss = 1.785651, validation loss = 3.595479
2018-12-05 03:50:48,841 - INFO - epoch 1, step 21060, training loss = 2.229227, validation loss = 3.487537
2018-12-05 03:50:54,223 - INFO - epoch 1, step 21070, training loss = 2.268767, validation loss = 3.272751
2018-12-05 03:50:59,355 - INFO - epoch 1, step 21080, training loss = 2.013257, validation loss = 3.143449
2018-12-05 03:51:04,232 - INFO - epoch 1, step 21090, training loss = 2.135960, validation loss = 3.783563
2018-12-05 03:51:09,030 - INFO - epoch 1, step 21100, training loss = 2.487176, validation loss = 2.892648
2018-12-05 03:51:14,071 - INFO - epoch 1, step 21110, training loss = 1.948605, validation loss = 3.700947
2018-12-05 03:51:19,017 - INFO - epoch 1, step 21120, training loss = 2.325072, validation loss = 3.401266
2018-12-05 03:51:24,068 - INFO - epoch 1, step 21130, training loss = 2.290123, validation loss = 3.180070
2018-12-05 03:51:28,874 - INFO - epoch 1, step 21140, training loss = 2.481647, validation loss = 3.498885
2018-12-05 03:51:33,705 - INFO - epoch 1, step 21150, training loss = 2.469291, validation loss = 3.465191
2018-12-05 03:51:38,686 - INFO - epoch 1, step 21160, training loss = 2.259904, validation loss = 3.218829
2018-12-05 03:51:43,694 - INFO - epoch 1, step 21170, training loss = 2.373279, validation loss = 3.487638
2018-12-05 03:51:48,569 - INFO - epoch 1, step 21180, training loss = 2.091892, validation loss = 3.177974
2018-12-05 03:51:53,652 - INFO - epoch 1, step 21190, training loss = 2.330009, validation loss = 3.541381
2018-12-05 03:51:58,613 - INFO - epoch 1, step 21200, training loss = 2.565768, validation loss = 3.865572
2018-12-05 03:52:03,563 - INFO - epoch 1, step 21210, training loss = 2.270308, validation loss = 3.868742
2018-12-05 03:52:08,404 - INFO - epoch 1, step 21220, training loss = 2.335000, validation loss = 3.934448
2018-12-05 03:52:13,552 - INFO - epoch 1, step 21230, training loss = 2.463099, validation loss = 3.048089
2018-12-05 03:52:18,475 - INFO - epoch 1, step 21240, training loss = 2.352864, validation loss = 3.591501
2018-12-05 03:52:23,372 - INFO - epoch 1, step 21250, training loss = 1.871592, validation loss = 3.655948
2018-12-05 03:52:28,278 - INFO - epoch 1, step 21260, training loss = 2.532791, validation loss = 3.320437
2018-12-05 03:52:33,260 - INFO - epoch 1, step 21270, training loss = 2.185928, validation loss = 3.569054
2018-12-05 03:52:38,798 - INFO - epoch 1, step 21280, training loss = 2.582916, validation loss = 2.995906
2018-12-05 03:52:43,968 - INFO - epoch 1, step 21290, training loss = 2.109941, validation loss = 3.089751
2018-12-05 03:52:48,928 - INFO - epoch 1, step 21300, training loss = 2.607572, validation loss = 3.296350
2018-12-05 03:52:53,852 - INFO - epoch 1, step 21310, training loss = 2.529475, validation loss = 3.683807
2018-12-05 03:52:58,748 - INFO - epoch 1, step 21320, training loss = 2.377236, validation loss = 3.206727
2018-12-05 03:53:03,872 - INFO - epoch 1, step 21330, training loss = 2.222257, validation loss = 4.006700
2018-12-05 03:53:09,096 - INFO - epoch 1, step 21340, training loss = 2.139447, validation loss = 3.019069
2018-12-05 03:53:14,149 - INFO - epoch 1, step 21350, training loss = 2.217088, validation loss = 3.714567
2018-12-05 03:53:19,370 - INFO - epoch 1, step 21360, training loss = 2.253160, validation loss = 3.915277
2018-12-05 03:53:24,334 - INFO - epoch 1, step 21370, training loss = 2.449617, validation loss = 3.511535
2018-12-05 03:53:30,012 - INFO - epoch 1, step 21380, training loss = 2.025633, validation loss = 3.209638
2018-12-05 03:53:35,310 - INFO - epoch 1, step 21390, training loss = 2.101946, validation loss = 3.719328
2018-12-05 03:53:40,247 - INFO - epoch 1, step 21400, training loss = 2.214363, validation loss = 3.257013
2018-12-05 03:53:45,222 - INFO - epoch 1, step 21410, training loss = 2.815032, validation loss = 3.902248
2018-12-05 03:53:50,371 - INFO - epoch 1, step 21420, training loss = 2.314132, validation loss = 4.272185
2018-12-05 03:53:55,729 - INFO - epoch 1, step 21430, training loss = 2.011369, validation loss = 3.279350
2018-12-05 03:54:01,181 - INFO - epoch 1, step 21440, training loss = 2.459344, validation loss = 3.743618
2018-12-05 03:54:06,502 - INFO - epoch 1, step 21450, training loss = 2.485193, validation loss = 3.542038
2018-12-05 03:54:11,426 - INFO - epoch 1, step 21460, training loss = 1.991558, validation loss = 3.721035
2018-12-05 03:54:16,647 - INFO - epoch 1, step 21470, training loss = 2.717947, validation loss = 3.682216
2018-12-05 03:54:22,468 - INFO - epoch 1, step 21480, training loss = 1.890249, validation loss = 3.244173
2018-12-05 03:54:28,123 - INFO - epoch 1, step 21490, training loss = 2.122308, validation loss = 3.425207
2018-12-05 03:54:33,245 - INFO - epoch 1, step 21500, training loss = 2.385767, validation loss = 3.120168
2018-12-05 03:54:37,218 - INFO - epoch 1, step 21510, training loss = 2.772112, validation loss = 4.067860
2018-12-05 03:54:40,427 - INFO - epoch 1, step 21520, training loss = 2.466107, validation loss = 3.377142
2018-12-05 03:54:43,608 - INFO - epoch 1, step 21530, training loss = 2.131875, validation loss = 3.537675
2018-12-05 03:54:46,782 - INFO - epoch 1, step 21540, training loss = 2.680490, validation loss = 3.685011
2018-12-05 03:54:50,126 - INFO - epoch 1, step 21550, training loss = 2.555354, validation loss = 3.660801
2018-12-05 03:54:53,346 - INFO - epoch 1, step 21560, training loss = 2.772837, validation loss = 3.489818
2018-12-05 03:54:56,498 - INFO - epoch 1, step 21570, training loss = 2.528850, validation loss = 3.412228
2018-12-05 03:54:59,717 - INFO - epoch 1, step 21580, training loss = 2.529460, validation loss = 3.483043
2018-12-05 03:55:02,945 - INFO - epoch 1, step 21590, training loss = 2.455246, validation loss = 3.351274
2018-12-05 03:55:06,138 - INFO - epoch 1, step 21600, training loss = 2.889349, validation loss = 4.073703
2018-12-05 03:55:09,375 - INFO - epoch 1, step 21610, training loss = 2.296443, validation loss = 3.613718
2018-12-05 03:55:12,582 - INFO - epoch 1, step 21620, training loss = 2.545129, validation loss = 3.261166
2018-12-05 03:55:15,603 - INFO - epoch 1, step 21630, training loss = 2.529447, validation loss = 3.669262
2018-12-05 03:55:19,265 - INFO - epoch 1, step 21640, training loss = 2.652195, validation loss = 3.482636
2018-12-05 03:55:23,867 - INFO - epoch 1, step 21650, training loss = 2.296596, validation loss = 3.415901
2018-12-05 03:55:28,757 - INFO - epoch 1, step 21660, training loss = 2.324917, validation loss = 3.616937
2018-12-05 03:55:33,505 - INFO - epoch 1, step 21670, training loss = 2.494148, validation loss = 3.404807
2018-12-05 03:55:38,129 - INFO - epoch 1, step 21680, training loss = 2.158499, validation loss = 3.080586
2018-12-05 03:55:42,838 - INFO - epoch 1, step 21690, training loss = 2.565007, validation loss = 3.485354
2018-12-05 03:55:47,721 - INFO - epoch 1, step 21700, training loss = 2.188235, validation loss = 3.317687
2018-12-05 03:55:52,476 - INFO - epoch 1, step 21710, training loss = 2.485677, validation loss = 3.639507
2018-12-05 03:55:57,118 - INFO - epoch 1, step 21720, training loss = 2.527024, validation loss = 3.045614
2018-12-05 03:56:01,588 - INFO - epoch 1, step 21730, training loss = 2.734826, validation loss = 3.800292
2018-12-05 03:56:06,398 - INFO - epoch 1, step 21740, training loss = 2.602257, validation loss = 3.001142
2018-12-05 03:56:10,900 - INFO - epoch 1, step 21750, training loss = 2.461837, validation loss = 3.421452
2018-12-05 03:56:15,504 - INFO - epoch 1, step 21760, training loss = 2.802917, validation loss = 3.578632
2018-12-05 03:56:20,448 - INFO - epoch 1, step 21770, training loss = 1.927025, validation loss = 3.117510
2018-12-05 03:56:25,102 - INFO - epoch 1, step 21780, training loss = 2.074424, validation loss = 3.525577
2018-12-05 03:56:30,093 - INFO - epoch 1, step 21790, training loss = 2.418356, validation loss = 2.967891
2018-12-05 03:56:35,085 - INFO - epoch 1, step 21800, training loss = 2.664612, validation loss = 3.442145
2018-12-05 03:56:39,840 - INFO - epoch 1, step 21810, training loss = 2.318927, validation loss = 3.523357
2018-12-05 03:56:44,874 - INFO - epoch 1, step 21820, training loss = 2.461411, validation loss = 3.671324
2018-12-05 03:56:49,906 - INFO - epoch 1, step 21830, training loss = 2.272833, validation loss = 3.446424
2018-12-05 03:56:55,215 - INFO - epoch 1, step 21840, training loss = 2.730681, validation loss = 3.604717
2018-12-05 03:56:59,450 - INFO - epoch 1, step 21850, training loss = 2.655533, validation loss = 3.483876
2018-12-05 03:57:04,424 - INFO - epoch 1, step 21860, training loss = 2.545529, validation loss = 3.766891
2018-12-05 03:57:09,181 - INFO - epoch 1, step 21870, training loss = 2.658798, validation loss = 3.322341
2018-12-05 03:57:14,230 - INFO - epoch 1, step 21880, training loss = 1.985270, validation loss = 3.422583
2018-12-05 03:57:17,435 - INFO - epoch 1, step 21890, training loss = 2.669540, validation loss = 2.918785
2018-12-05 03:57:19,870 - INFO - epoch 1, step 21900, training loss = 1.649944, validation loss = 4.216380
2018-12-05 03:57:22,302 - INFO - epoch 1, step 21910, training loss = 2.833257, validation loss = 3.648564
2018-12-05 03:57:24,696 - INFO - epoch 1, step 21920, training loss = 1.938576, validation loss = 3.457776
2018-12-05 03:57:27,105 - INFO - epoch 1, step 21930, training loss = 2.368499, validation loss = 3.680687
2018-12-05 03:57:29,397 - INFO - epoch 1, step 21940, training loss = 2.047123, validation loss = 3.574523
2018-12-05 03:57:31,744 - INFO - epoch 1, step 21950, training loss = 2.185170, validation loss = 3.184578
2018-12-05 03:57:34,090 - INFO - epoch 1, step 21960, training loss = 2.567509, validation loss = 3.122267
2018-12-05 03:57:36,376 - INFO - epoch 1, step 21970, training loss = 2.422886, validation loss = 3.451094
2018-12-05 03:57:38,592 - INFO - epoch 1, step 21980, training loss = 2.811465, validation loss = 3.689377
2018-12-05 03:57:40,915 - INFO - epoch 1, step 21990, training loss = 2.544139, validation loss = 3.656662
2018-12-05 03:57:43,309 - INFO - epoch 1, step 22000, training loss = 2.468078, validation loss = 3.058686
2018-12-05 03:57:45,786 - INFO - epoch 1, step 22010, training loss = 1.938926, validation loss = 3.038949
2018-12-05 03:57:48,182 - INFO - epoch 1, step 22020, training loss = 1.705527, validation loss = 3.489003
2018-12-05 03:57:50,822 - INFO - epoch 1, step 22030, training loss = 2.303478, validation loss = 3.433420
2018-12-05 03:57:53,242 - INFO - epoch 1, step 22040, training loss = 2.656506, validation loss = 2.601251
2018-12-05 03:57:56,514 - INFO - epoch 1, step 22050, training loss = 2.607254, validation loss = 3.815567
2018-12-05 03:58:00,713 - INFO - epoch 1, step 22060, training loss = 2.538269, validation loss = 3.002503
2018-12-05 03:58:05,336 - INFO - epoch 1, step 22070, training loss = 2.392231, validation loss = 2.847880
2018-12-05 03:58:09,776 - INFO - epoch 1, step 22080, training loss = 2.265252, validation loss = 3.488567
2018-12-05 03:58:14,443 - INFO - epoch 1, step 22090, training loss = 1.633438, validation loss = 2.139358
2018-12-05 03:58:18,971 - INFO - epoch 1, step 22100, training loss = 2.148170, validation loss = 2.939001
2018-12-05 03:58:23,601 - INFO - epoch 1, step 22110, training loss = 2.347456, validation loss = 2.828688
2018-12-05 03:58:27,785 - INFO - epoch 1, step 22120, training loss = 1.938023, validation loss = 3.032684
2018-12-05 03:58:32,095 - INFO - epoch 1, step 22130, training loss = 2.008036, validation loss = 2.967844
2018-12-05 03:58:36,652 - INFO - epoch 1, step 22140, training loss = 2.356324, validation loss = 3.070186
2018-12-05 03:58:40,907 - INFO - epoch 1, step 22150, training loss = 2.140998, validation loss = 2.712808
2018-12-05 03:58:45,663 - INFO - epoch 1, step 22160, training loss = 1.672044, validation loss = 2.663296
2018-12-05 03:58:49,934 - INFO - epoch 1, step 22170, training loss = 1.927333, validation loss = 2.399864
2018-12-05 03:58:54,366 - INFO - epoch 1, step 22180, training loss = 2.484375, validation loss = 2.338420
2018-12-05 03:58:58,524 - INFO - epoch 1, step 22190, training loss = 3.062753, validation loss = 2.953492
2018-12-05 03:59:02,684 - INFO - epoch 1, step 22200, training loss = 2.337968, validation loss = 2.945798
2018-12-05 03:59:06,902 - INFO - epoch 1, step 22210, training loss = 2.373598, validation loss = 2.220258
2018-12-05 03:59:11,524 - INFO - epoch 1, step 22220, training loss = 1.943580, validation loss = 3.241334
2018-12-05 03:59:17,269 - INFO - epoch 1, step 22230, training loss = 1.789293, validation loss = 3.028569
2018-12-05 03:59:23,090 - INFO - epoch 1, step 22240, training loss = 2.285791, validation loss = 2.516797
2018-12-05 03:59:28,978 - INFO - epoch 1, step 22250, training loss = 2.345772, validation loss = 3.281816
2018-12-05 03:59:34,391 - INFO - epoch 1, step 22260, training loss = 2.022145, validation loss = 3.306940
2018-12-05 03:59:39,718 - INFO - epoch 1, step 22270, training loss = 2.252982, validation loss = 3.286404
2018-12-05 03:59:45,651 - INFO - epoch 1, step 22280, training loss = 2.408615, validation loss = 2.806248
2018-12-05 03:59:52,470 - INFO - epoch 1, step 22290, training loss = 1.597577, validation loss = 2.785661
2018-12-05 03:59:58,336 - INFO - epoch 1, step 22300, training loss = 1.798497, validation loss = 3.315872
2018-12-05 04:00:04,349 - INFO - epoch 1, step 22310, training loss = 1.667094, validation loss = 2.559523
2018-12-05 04:00:10,158 - INFO - epoch 1, step 22320, training loss = 2.190526, validation loss = 3.158438
2018-12-05 04:00:15,899 - INFO - epoch 1, step 22330, training loss = 1.774859, validation loss = 2.507751
2018-12-05 04:00:22,025 - INFO - epoch 1, step 22340, training loss = 2.301025, validation loss = 2.947351
2018-12-05 04:00:27,855 - INFO - epoch 1, step 22350, training loss = 1.926248, validation loss = 2.762284
2018-12-05 04:00:33,822 - INFO - epoch 1, step 22360, training loss = 2.227987, validation loss = 2.426390
2018-12-05 04:00:39,741 - INFO - epoch 1, step 22370, training loss = 1.874457, validation loss = 2.632598
2018-12-05 04:00:45,219 - INFO - epoch 1, step 22380, training loss = 2.098794, validation loss = 2.956964
2018-12-05 04:00:50,319 - INFO - epoch 1, step 22390, training loss = 1.918123, validation loss = 3.374423
2018-12-05 04:00:55,813 - INFO - epoch 1, step 22400, training loss = 2.415936, validation loss = 3.221233
2018-12-05 04:01:01,867 - INFO - epoch 1, step 22410, training loss = 2.469192, validation loss = 3.180528
2018-12-05 04:01:07,241 - INFO - epoch 1, step 22420, training loss = 1.973919, validation loss = 3.611479
2018-12-05 04:01:13,075 - INFO - epoch 1, step 22430, training loss = 2.321348, validation loss = 3.463326
2018-12-05 04:01:18,898 - INFO - epoch 1, step 22440, training loss = 1.689586, validation loss = 3.568909
2018-12-05 04:01:24,626 - INFO - epoch 1, step 22450, training loss = 2.162807, validation loss = 3.770089
2018-12-05 04:01:29,832 - INFO - epoch 1, step 22460, training loss = 2.629256, validation loss = 3.282088
2018-12-05 04:01:35,302 - INFO - epoch 1, step 22470, training loss = 2.227870, validation loss = 3.929211
2018-12-05 04:01:40,670 - INFO - epoch 1, step 22480, training loss = 2.274077, validation loss = 3.787924
2018-12-05 04:01:46,271 - INFO - epoch 1, step 22490, training loss = 2.206090, validation loss = 3.329905
2018-12-05 04:01:51,524 - INFO - epoch 1, step 22500, training loss = 2.490762, validation loss = 3.420312
2018-12-05 04:01:56,739 - INFO - epoch 1, step 22510, training loss = 2.379110, validation loss = 3.251273
2018-12-05 04:02:02,755 - INFO - epoch 1, step 22520, training loss = 2.267502, validation loss = 3.990976
2018-12-05 04:02:08,302 - INFO - epoch 1, step 22530, training loss = 2.128383, validation loss = 3.269768
2018-12-05 04:02:14,081 - INFO - epoch 1, step 22540, training loss = 2.292964, validation loss = 3.983085
2018-12-05 04:02:19,668 - INFO - epoch 1, step 22550, training loss = 2.144838, validation loss = 3.425389
2018-12-05 04:02:25,451 - INFO - epoch 1, step 22560, training loss = 1.787336, validation loss = 3.574513
2018-12-05 04:02:31,029 - INFO - epoch 1, step 22570, training loss = 1.944613, validation loss = 4.295825
2018-12-05 04:02:37,247 - INFO - epoch 1, step 22580, training loss = 1.983214, validation loss = 3.252153
2018-12-05 04:02:42,695 - INFO - epoch 1, step 22590, training loss = 2.434097, validation loss = 3.478310
2018-12-05 04:02:47,990 - INFO - epoch 1, step 22600, training loss = 1.840978, validation loss = 3.928338
2018-12-05 04:02:53,042 - INFO - epoch 1, step 22610, training loss = 2.512442, validation loss = 3.170232
2018-12-05 04:02:57,697 - INFO - epoch 1, step 22620, training loss = 2.447585, validation loss = 2.996487
2018-12-05 04:03:02,130 - INFO - epoch 1, step 22630, training loss = 2.485642, validation loss = 3.242133
2018-12-05 04:03:06,275 - INFO - epoch 1, step 22640, training loss = 2.312125, validation loss = 3.694925
2018-12-05 04:03:10,211 - INFO - epoch 1, step 22650, training loss = 2.237802, validation loss = 3.347237
2018-12-05 04:03:14,421 - INFO - epoch 1, step 22660, training loss = 2.434624, validation loss = 3.221236
2018-12-05 04:03:18,617 - INFO - epoch 1, step 22670, training loss = 2.430796, validation loss = 3.821214
2018-12-05 04:03:22,599 - INFO - epoch 1, step 22680, training loss = 2.812295, validation loss = 2.983157
2018-12-05 04:03:26,118 - INFO - epoch 1, step 22690, training loss = 2.467708, validation loss = 3.141201
2018-12-05 04:03:29,509 - INFO - epoch 1, step 22700, training loss = 2.278537, validation loss = 3.855048
2018-12-05 04:03:32,991 - INFO - epoch 1, step 22710, training loss = 2.418380, validation loss = 3.522593
2018-12-05 04:03:36,518 - INFO - epoch 1, step 22720, training loss = 2.655511, validation loss = 3.174194
2018-12-05 04:03:39,991 - INFO - epoch 1, step 22730, training loss = 2.404047, validation loss = 2.920183
2018-12-05 04:03:43,506 - INFO - epoch 1, step 22740, training loss = 2.193469, validation loss = 3.619135
2018-12-05 04:03:47,037 - INFO - epoch 1, step 22750, training loss = 2.395970, validation loss = 3.274198
2018-12-05 04:03:50,569 - INFO - epoch 1, step 22760, training loss = 2.441706, validation loss = 3.438286
2018-12-05 04:03:54,108 - INFO - epoch 1, step 22770, training loss = 2.342253, validation loss = 3.567904
2018-12-05 04:03:57,389 - INFO - epoch 1, step 22780, training loss = 2.012106, validation loss = 3.791191
2018-12-05 04:04:01,316 - INFO - epoch 1, step 22790, training loss = 2.086168, validation loss = 3.655422
2018-12-05 04:04:04,490 - INFO - epoch 1, step 22800, training loss = 1.945339, validation loss = 3.410039
2018-12-05 04:04:07,632 - INFO - epoch 1, step 22810, training loss = 2.213767, validation loss = 3.129789
2018-12-05 04:04:11,724 - INFO - epoch 1, step 22820, training loss = 1.762936, validation loss = 3.678110
2018-12-05 04:04:14,942 - INFO - epoch 1, step 22830, training loss = 2.245553, validation loss = 3.437042
2018-12-05 04:04:18,081 - INFO - epoch 1, step 22840, training loss = 2.282896, validation loss = 3.113938
2018-12-05 04:04:21,275 - INFO - epoch 1, step 22850, training loss = 1.812870, validation loss = 3.230742
2018-12-05 04:04:24,592 - INFO - epoch 1, step 22860, training loss = 2.268832, validation loss = 3.080332
2018-12-05 04:04:27,944 - INFO - epoch 1, step 22870, training loss = 1.903283, validation loss = 3.824665
2018-12-05 04:04:31,101 - INFO - epoch 1, step 22880, training loss = 2.599582, validation loss = 3.121457
2018-12-05 04:04:34,165 - INFO - epoch 1, step 22890, training loss = 2.190966, validation loss = 3.520550
2018-12-05 04:04:37,417 - INFO - epoch 1, step 22900, training loss = 2.295588, validation loss = 3.645155
2018-12-05 04:04:40,545 - INFO - epoch 1, step 22910, training loss = 2.258035, validation loss = 3.576692
2018-12-05 04:04:43,871 - INFO - epoch 1, step 22920, training loss = 2.321129, validation loss = 2.732373
2018-12-05 04:04:47,061 - INFO - epoch 1, step 22930, training loss = 1.765759, validation loss = 3.661252
2018-12-05 04:04:50,235 - INFO - epoch 1, step 22940, training loss = 2.017687, validation loss = 3.578524
2018-12-05 04:04:53,534 - INFO - epoch 1, step 22950, training loss = 2.210882, validation loss = 2.958491
2018-12-05 04:04:56,783 - INFO - epoch 1, step 22960, training loss = 2.703991, validation loss = 3.736902
2018-12-05 04:04:59,980 - INFO - epoch 1, step 22970, training loss = 2.841902, validation loss = 3.106289
2018-12-05 04:05:03,325 - INFO - epoch 1, step 22980, training loss = 2.385550, validation loss = 3.437261
2018-12-05 04:05:06,313 - INFO - epoch 1, step 22990, training loss = 2.226113, validation loss = 2.388968
2018-12-05 04:05:09,491 - INFO - epoch 1, step 23000, training loss = 2.441847, validation loss = 2.196493
2018-12-05 04:05:13,634 - INFO - epoch 1, step 23010, training loss = 2.336437, validation loss = 2.466971
2018-12-05 04:05:17,894 - INFO - epoch 1, step 23020, training loss = 2.558801, validation loss = 2.357698
2018-12-05 04:05:22,090 - INFO - epoch 1, step 23030, training loss = 2.407300, validation loss = 2.430753
2018-12-05 04:05:26,401 - INFO - epoch 1, step 23040, training loss = 2.775022, validation loss = 2.453714
2018-12-05 04:05:31,134 - INFO - epoch 1, step 23050, training loss = 2.116278, validation loss = 2.331203
2018-12-05 04:05:35,391 - INFO - epoch 1, step 23060, training loss = 2.095892, validation loss = 2.287726
2018-12-05 04:05:39,997 - INFO - epoch 1, step 23070, training loss = 1.556402, validation loss = 1.720652
2018-12-05 04:05:44,197 - INFO - epoch 1, step 23080, training loss = 2.205609, validation loss = 1.739056
2018-12-05 04:05:48,323 - INFO - epoch 1, step 23090, training loss = 2.488384, validation loss = 2.216451
2018-12-05 04:05:52,343 - INFO - epoch 1, step 23100, training loss = 2.435082, validation loss = 2.017158
2018-12-05 04:05:56,345 - INFO - epoch 1, step 23110, training loss = 2.686254, validation loss = 2.664751
2018-12-05 04:06:00,356 - INFO - epoch 1, step 23120, training loss = 2.108404, validation loss = 1.981479
2018-12-05 04:06:03,772 - INFO - epoch 1, step 23130, training loss = 2.570169, validation loss = 2.317432
2018-12-05 04:06:06,077 - INFO - epoch 1, step 23140, training loss = 2.775285, validation loss = 2.233038
2018-12-05 04:06:08,401 - INFO - epoch 1, step 23150, training loss = 1.938016, validation loss = 2.485142
2018-12-05 04:06:10,737 - INFO - epoch 1, step 23160, training loss = 2.091910, validation loss = 2.428520
2018-12-05 04:06:13,025 - INFO - epoch 1, step 23170, training loss = 2.220561, validation loss = 2.343024
2018-12-05 04:06:15,349 - INFO - epoch 1, step 23180, training loss = 1.815829, validation loss = 1.732729
2018-12-05 04:06:17,559 - INFO - epoch 1, step 23190, training loss = 2.698639, validation loss = 2.283772
2018-12-05 04:06:19,856 - INFO - epoch 1, step 23200, training loss = 2.123711, validation loss = 1.920728
2018-12-05 04:06:22,158 - INFO - epoch 1, step 23210, training loss = 2.182704, validation loss = 2.620302
2018-12-05 04:06:24,451 - INFO - epoch 1, step 23220, training loss = 1.980775, validation loss = 2.398491
2018-12-05 04:06:26,752 - INFO - epoch 1, step 23230, training loss = 2.255147, validation loss = 2.565744
2018-12-05 04:06:29,058 - INFO - epoch 1, step 23240, training loss = 2.278153, validation loss = 2.695626
2018-12-05 04:06:31,359 - INFO - epoch 1, step 23250, training loss = 2.284807, validation loss = 2.745656
2018-12-05 04:06:33,612 - INFO - epoch 1, step 23260, training loss = 1.998636, validation loss = 2.308249
2018-12-05 04:06:35,891 - INFO - epoch 1, step 23270, training loss = 2.492686, validation loss = 2.889469
2018-12-05 04:06:38,220 - INFO - epoch 1, step 23280, training loss = 2.530396, validation loss = 2.677413
2018-12-05 04:06:41,295 - INFO - epoch 1, step 23290, training loss = 2.542035, validation loss = 2.440893
2018-12-05 04:06:44,596 - INFO - epoch 1, step 23300, training loss = 2.383494, validation loss = 2.525798
2018-12-05 04:06:47,996 - INFO - epoch 1, step 23310, training loss = 2.317565, validation loss = 2.217454
2018-12-05 04:06:51,132 - INFO - epoch 1, step 23320, training loss = 2.311404, validation loss = 2.535913
2018-12-05 04:06:54,205 - INFO - epoch 1, step 23330, training loss = 2.612718, validation loss = 2.542844
2018-12-05 04:06:57,432 - INFO - epoch 1, step 23340, training loss = 2.264740, validation loss = 2.243808
2018-12-05 04:07:00,676 - INFO - epoch 1, step 23350, training loss = 1.999292, validation loss = 2.447554
2018-12-05 04:07:03,754 - INFO - epoch 1, step 23360, training loss = 2.980198, validation loss = 2.345861
2018-12-05 04:07:06,978 - INFO - epoch 1, step 23370, training loss = 2.163964, validation loss = 2.365721
2018-12-05 04:07:10,152 - INFO - epoch 1, step 23380, training loss = 2.252853, validation loss = 2.463914
2018-12-05 04:07:13,178 - INFO - epoch 1, step 23390, training loss = 2.361116, validation loss = 2.333386
2018-12-05 04:07:16,203 - INFO - epoch 1, step 23400, training loss = 2.123615, validation loss = 2.501694
2018-12-05 04:07:19,474 - INFO - epoch 1, step 23410, training loss = 2.330754, validation loss = 2.525194
2018-12-05 04:07:22,744 - INFO - epoch 1, step 23420, training loss = 2.436394, validation loss = 2.587209
2018-12-05 04:07:26,252 - INFO - epoch 1, step 23430, training loss = 2.062949, validation loss = 2.489219
2018-12-05 04:07:29,885 - INFO - epoch 1, step 23440, training loss = 2.117317, validation loss = 2.261622
2018-12-05 04:07:33,305 - INFO - epoch 1, step 23450, training loss = 2.014360, validation loss = 2.613122
2018-12-05 04:07:36,754 - INFO - epoch 1, step 23460, training loss = 1.967690, validation loss = 2.386699
2018-12-05 04:07:41,354 - INFO - epoch 1, step 23470, training loss = 2.418296, validation loss = 2.507758
2018-12-05 04:07:47,704 - INFO - epoch 1, step 23480, training loss = 2.246515, validation loss = 2.471931
2018-12-05 04:07:53,067 - INFO - epoch 1, step 23490, training loss = 2.404608, validation loss = 2.281727
2018-12-05 04:07:58,521 - INFO - epoch 1, step 23500, training loss = 1.909263, validation loss = 2.434387
2018-12-05 04:08:03,972 - INFO - epoch 1, step 23510, training loss = 2.799239, validation loss = 2.349156
2018-12-05 04:08:08,509 - INFO - epoch 1, step 23520, training loss = 2.172364, validation loss = 1.904468
2018-12-05 04:08:12,555 - INFO - epoch 1, step 23530, training loss = 2.215642, validation loss = 2.245513
2018-12-05 04:08:16,912 - INFO - epoch 1, step 23540, training loss = 2.222757, validation loss = 2.402642
2018-12-05 04:08:21,543 - INFO - epoch 1, step 23550, training loss = 2.446075, validation loss = 2.561117
2018-12-05 04:08:25,675 - INFO - epoch 1, step 23560, training loss = 2.435717, validation loss = 2.203909
2018-12-05 04:08:29,956 - INFO - epoch 1, step 23570, training loss = 2.260007, validation loss = 2.084974
2018-12-05 04:08:34,011 - INFO - epoch 1, step 23580, training loss = 2.204392, validation loss = 2.149784
2018-12-05 04:08:38,453 - INFO - epoch 1, step 23590, training loss = 1.973436, validation loss = 1.706059
2018-12-05 04:08:42,777 - INFO - epoch 1, step 23600, training loss = 2.308899, validation loss = 1.482256
2018-12-05 04:08:46,668 - INFO - epoch 1, step 23610, training loss = 2.224267, validation loss = 2.267866
2018-12-05 04:08:50,756 - INFO - epoch 1, step 23620, training loss = 2.064492, validation loss = 2.450522
2018-12-05 04:08:54,870 - INFO - epoch 1, step 23630, training loss = 2.492065, validation loss = 2.265381
2018-12-05 04:08:59,346 - INFO - epoch 1, step 23640, training loss = 2.175489, validation loss = 2.122404
2018-12-05 04:09:03,450 - INFO - epoch 1, step 23650, training loss = 1.963082, validation loss = 2.163835
2018-12-05 04:09:07,889 - INFO - epoch 1, step 23660, training loss = 2.351331, validation loss = 2.418829
2018-12-05 04:09:12,226 - INFO - epoch 1, step 23670, training loss = 2.178359, validation loss = 2.065053
2018-12-05 04:09:16,222 - INFO - epoch 1, step 23680, training loss = 2.190215, validation loss = 1.870356
2018-12-05 04:09:20,387 - INFO - epoch 1, step 23690, training loss = 2.450178, validation loss = 2.394492
2018-12-05 04:09:24,855 - INFO - epoch 1, step 23700, training loss = 1.963319, validation loss = 2.243038
2018-12-05 04:09:29,648 - INFO - epoch 1, step 23710, training loss = 2.400690, validation loss = 1.967971
2018-12-05 04:09:34,583 - INFO - epoch 1, step 23720, training loss = 2.090580, validation loss = 2.328721
2018-12-05 04:09:39,170 - INFO - epoch 1, step 23730, training loss = 2.563367, validation loss = 1.978841
2018-12-05 04:09:43,892 - INFO - epoch 1, step 23740, training loss = 2.473742, validation loss = 1.815784
2018-12-05 04:09:48,907 - INFO - epoch 1, step 23750, training loss = 2.525463, validation loss = 2.160102
2018-12-05 04:09:53,803 - INFO - epoch 1, step 23760, training loss = 2.314910, validation loss = 2.186826
2018-12-05 04:09:58,634 - INFO - epoch 1, step 23770, training loss = 2.284889, validation loss = 2.058475
2018-12-05 04:10:03,290 - INFO - epoch 1, step 23780, training loss = 2.402518, validation loss = 2.288120
2018-12-05 04:10:07,932 - INFO - epoch 1, step 23790, training loss = 1.895314, validation loss = 2.059285
2018-12-05 04:10:13,130 - INFO - epoch 1, step 23800, training loss = 2.790183, validation loss = 1.598482
2018-12-05 04:10:18,022 - INFO - epoch 1, step 23810, training loss = 2.619447, validation loss = 2.131081
2018-12-05 04:10:23,183 - INFO - epoch 1, step 23820, training loss = 2.462827, validation loss = 1.826638
2018-12-05 04:10:28,120 - INFO - epoch 1, step 23830, training loss = 2.363757, validation loss = 2.182408
2018-12-05 04:10:32,993 - INFO - epoch 1, step 23840, training loss = 2.770352, validation loss = 2.138314
2018-12-05 04:10:37,922 - INFO - epoch 1, step 23850, training loss = 2.608090, validation loss = 1.982656
2018-12-05 04:10:42,804 - INFO - epoch 1, step 23860, training loss = 2.046079, validation loss = 1.947348
2018-12-05 04:10:47,786 - INFO - epoch 1, step 23870, training loss = 2.341587, validation loss = 1.971188
2018-12-05 04:10:52,734 - INFO - epoch 1, step 23880, training loss = 2.182796, validation loss = 2.389435
2018-12-05 04:10:57,678 - INFO - epoch 1, step 23890, training loss = 2.298905, validation loss = 2.032593
2018-12-05 04:11:03,235 - INFO - epoch 1, step 23900, training loss = 2.551366, validation loss = 1.819064
2018-12-05 04:11:08,128 - INFO - epoch 1, step 23910, training loss = 2.585563, validation loss = 2.107420
2018-12-05 04:11:13,194 - INFO - epoch 1, step 23920, training loss = 2.154367, validation loss = 2.458255
2018-12-05 04:11:17,986 - INFO - epoch 1, step 23930, training loss = 2.367182, validation loss = 1.827052
2018-12-05 04:11:22,835 - INFO - epoch 1, step 23940, training loss = 2.666458, validation loss = 1.846382
2018-12-05 04:11:27,829 - INFO - epoch 1, step 23950, training loss = 2.272389, validation loss = 2.231113
2018-12-05 04:11:32,385 - INFO - epoch 1, step 23960, training loss = 2.179553, validation loss = 2.156831
2018-12-05 04:11:37,160 - INFO - epoch 1, step 23970, training loss = 1.963780, validation loss = 2.067449
2018-12-05 04:11:41,879 - INFO - epoch 1, step 23980, training loss = 1.984576, validation loss = 2.029597
2018-12-05 04:11:46,607 - INFO - epoch 1, step 23990, training loss = 2.742502, validation loss = 1.929879
2018-12-05 04:11:51,202 - INFO - epoch 1, step 24000, training loss = 2.134593, validation loss = 1.789589
2018-12-05 04:11:55,857 - INFO - epoch 1, step 24010, training loss = 2.095268, validation loss = 2.402298
2018-12-05 04:12:00,764 - INFO - epoch 1, step 24020, training loss = 1.826054, validation loss = 1.931790
2018-12-05 04:12:06,774 - INFO - epoch 1, step 24030, training loss = 1.716746, validation loss = 2.186332
2018-12-05 04:12:12,423 - INFO - epoch 1, step 24040, training loss = 1.924791, validation loss = 2.058807
2018-12-05 04:12:17,998 - INFO - epoch 1, step 24050, training loss = 1.622397, validation loss = 1.974125
2018-12-05 04:12:23,866 - INFO - epoch 1, step 24060, training loss = 1.736659, validation loss = 2.413157
2018-12-05 04:12:29,980 - INFO - epoch 1, step 24070, training loss = 1.744419, validation loss = 2.193138
2018-12-05 04:12:36,039 - INFO - epoch 1, step 24080, training loss = 1.982345, validation loss = 2.195031
2018-12-05 04:12:41,721 - INFO - epoch 1, step 24090, training loss = 2.203131, validation loss = 2.222292
2018-12-05 04:12:48,353 - INFO - epoch 1, step 24100, training loss = 2.195659, validation loss = 2.072235
2018-12-05 04:12:54,370 - INFO - epoch 1, step 24110, training loss = 2.083104, validation loss = 1.810791
2018-12-05 04:12:59,992 - INFO - epoch 1, step 24120, training loss = 1.782590, validation loss = 2.444339
2018-12-05 04:13:05,814 - INFO - epoch 1, step 24130, training loss = 2.055265, validation loss = 1.900661
2018-12-05 04:13:12,055 - INFO - epoch 1, step 24140, training loss = 1.668855, validation loss = 2.310208
2018-12-05 04:13:17,838 - INFO - epoch 1, step 24150, training loss = 1.889985, validation loss = 2.329354
2018-12-05 04:13:23,397 - INFO - epoch 1, step 24160, training loss = 2.436255, validation loss = 2.010967
2018-12-05 04:13:29,297 - INFO - epoch 1, step 24170, training loss = 1.838693, validation loss = 1.781778
2018-12-05 04:13:34,806 - INFO - epoch 1, step 24180, training loss = 1.856120, validation loss = 1.838736
2018-12-05 04:13:40,500 - INFO - epoch 1, step 24190, training loss = 2.056458, validation loss = 2.350681
2018-12-05 04:13:46,122 - INFO - epoch 1, step 24200, training loss = 1.837233, validation loss = 1.680055
2018-12-05 04:13:51,560 - INFO - epoch 1, step 24210, training loss = 2.058159, validation loss = 2.107777
2018-12-05 04:13:58,220 - INFO - epoch 1, step 24220, training loss = 1.501959, validation loss = 2.342208
2018-12-05 04:14:04,268 - INFO - epoch 1, step 24230, training loss = 2.098413, validation loss = 1.885706
2018-12-05 04:14:09,282 - INFO - epoch 1, step 24240, training loss = 2.974257, validation loss = 2.010080
2018-12-05 04:14:12,451 - INFO - epoch 1, step 24250, training loss = 2.216329, validation loss = 2.105873
2018-12-05 04:14:15,585 - INFO - epoch 1, step 24260, training loss = 2.362607, validation loss = 1.952393
2018-12-05 04:14:18,760 - INFO - epoch 1, step 24270, training loss = 2.606228, validation loss = 2.033040
2018-12-05 04:14:22,269 - INFO - epoch 1, step 24280, training loss = 1.865719, validation loss = 1.875954
2018-12-05 04:14:25,345 - INFO - epoch 1, step 24290, training loss = 1.715473, validation loss = 2.151678
2018-12-05 04:14:28,543 - INFO - epoch 1, step 24300, training loss = 2.296971, validation loss = 2.096429
2018-12-05 04:14:31,838 - INFO - epoch 1, step 24310, training loss = 1.990104, validation loss = 2.342843
2018-12-05 04:14:34,942 - INFO - epoch 1, step 24320, training loss = 2.462085, validation loss = 2.193907
2018-12-05 04:14:38,265 - INFO - epoch 1, step 24330, training loss = 2.907953, validation loss = 2.408629
2018-12-05 04:14:41,372 - INFO - epoch 1, step 24340, training loss = 2.503973, validation loss = 1.955447
2018-12-05 04:14:44,527 - INFO - epoch 1, step 24350, training loss = 2.033235, validation loss = 2.432951
2018-12-05 04:14:47,759 - INFO - epoch 1, step 24360, training loss = 2.050965, validation loss = 2.070974
2018-12-05 04:14:51,213 - INFO - epoch 1, step 24370, training loss = 2.223027, validation loss = 1.749371
2018-12-05 04:14:54,390 - INFO - epoch 1, step 24380, training loss = 2.316682, validation loss = 2.376132
2018-12-05 04:14:57,568 - INFO - epoch 1, step 24390, training loss = 2.547443, validation loss = 2.144742
2018-12-05 04:15:00,970 - INFO - epoch 1, step 24400, training loss = 2.071223, validation loss = 2.693943
2018-12-05 04:15:04,201 - INFO - epoch 1, step 24410, training loss = 2.454824, validation loss = 2.378722
2018-12-05 04:15:07,508 - INFO - epoch 1, step 24420, training loss = 2.299687, validation loss = 2.063980
2018-12-05 04:15:10,510 - INFO - epoch 1, step 24430, training loss = 2.213417, validation loss = 2.005301
2018-12-05 04:15:13,811 - INFO - epoch 1, step 24440, training loss = 2.370617, validation loss = 2.156915
2018-12-05 04:15:16,994 - INFO - epoch 1, step 24450, training loss = 2.661138, validation loss = 2.104866
2018-12-05 04:15:20,039 - INFO - epoch 1, step 24460, training loss = 3.048139, validation loss = 2.037567
2018-12-05 04:15:23,211 - INFO - epoch 1, step 24470, training loss = 2.443703, validation loss = 1.794250
2018-12-05 04:15:26,158 - INFO - epoch 1, step 24480, training loss = 2.177041, validation loss = 1.996982
2018-12-05 04:15:29,592 - INFO - epoch 1, step 24490, training loss = 2.634067, validation loss = 2.347497
2018-12-05 04:15:33,014 - INFO - epoch 1, step 24500, training loss = 2.241738, validation loss = 2.060733
2018-12-05 04:15:36,160 - INFO - epoch 1, step 24510, training loss = 2.486080, validation loss = 2.419887
2018-12-05 04:15:39,387 - INFO - epoch 1, step 24520, training loss = 2.634642, validation loss = 1.901376
2018-12-05 04:15:42,516 - INFO - epoch 1, step 24530, training loss = 2.706491, validation loss = 2.406600
2018-12-05 04:15:45,686 - INFO - epoch 1, step 24540, training loss = 2.040354, validation loss = 2.013589
2018-12-05 04:15:48,822 - INFO - epoch 1, step 24550, training loss = 2.233964, validation loss = 2.580581
2018-12-05 04:15:52,097 - INFO - epoch 1, step 24560, training loss = 2.143024, validation loss = 2.284247
2018-12-05 04:15:55,176 - INFO - epoch 1, step 24570, training loss = 2.374665, validation loss = 2.434384
2018-12-05 04:15:58,490 - INFO - epoch 1, step 24580, training loss = 1.947030, validation loss = 2.339140
2018-12-05 04:16:01,623 - INFO - epoch 1, step 24590, training loss = 2.297678, validation loss = 2.166603
2018-12-05 04:16:04,680 - INFO - epoch 1, step 24600, training loss = 3.221809, validation loss = 2.713510
2018-12-05 04:16:07,881 - INFO - epoch 1, step 24610, training loss = 2.805255, validation loss = 2.331361
2018-12-05 04:16:11,130 - INFO - epoch 1, step 24620, training loss = 3.035899, validation loss = 2.348735
2018-12-05 04:16:14,552 - INFO - epoch 1, step 24630, training loss = 2.102835, validation loss = 2.192279
2018-12-05 04:16:17,696 - INFO - epoch 1, step 24640, training loss = 2.290764, validation loss = 1.941056
2018-12-05 04:16:21,379 - INFO - epoch 1, step 24650, training loss = 0.979161, validation loss = 2.285343
2018-12-05 04:16:24,427 - INFO - epoch 1, step 24660, training loss = 2.121562, validation loss = 2.264796
2018-12-05 04:16:27,589 - INFO - epoch 1, step 24670, training loss = 1.959542, validation loss = 2.154492
2018-12-05 04:16:30,767 - INFO - epoch 1, step 24680, training loss = 2.646221, validation loss = 2.560249
2018-12-05 04:16:33,935 - INFO - epoch 1, step 24690, training loss = 2.194195, validation loss = 2.229805
2018-12-05 04:16:36,979 - INFO - epoch 1, step 24700, training loss = 2.476389, validation loss = 2.455626
2018-12-05 04:16:39,949 - INFO - epoch 1, step 24710, training loss = 2.345012, validation loss = 2.276083
2018-12-05 04:16:43,187 - INFO - epoch 1, step 24720, training loss = 2.125221, validation loss = 2.295275
2018-12-05 04:16:46,485 - INFO - epoch 1, step 24730, training loss = 1.837815, validation loss = 2.155364
2018-12-05 04:16:49,602 - INFO - epoch 1, step 24740, training loss = 2.070354, validation loss = 2.192910
2018-12-05 04:16:52,766 - INFO - epoch 1, step 24750, training loss = 2.553671, validation loss = 1.941691
2018-12-05 04:16:55,969 - INFO - epoch 1, step 24760, training loss = 2.854613, validation loss = 1.723830
2018-12-05 04:16:59,187 - INFO - epoch 1, step 24770, training loss = 2.150891, validation loss = 2.327570
2018-12-05 04:17:02,366 - INFO - epoch 1, step 24780, training loss = 2.619129, validation loss = 2.348937
2018-12-05 04:17:05,747 - INFO - epoch 1, step 24790, training loss = 2.146099, validation loss = 2.003232
2018-12-05 04:17:08,965 - INFO - epoch 1, step 24800, training loss = 1.843772, validation loss = 2.445218
2018-12-05 04:17:12,800 - INFO - epoch 1, step 24810, training loss = 2.257966, validation loss = 2.464485
2018-12-05 04:17:15,994 - INFO - epoch 1, step 24820, training loss = 2.342650, validation loss = 2.074892
2018-12-05 04:17:19,093 - INFO - epoch 1, step 24830, training loss = 2.158385, validation loss = 2.490935
2018-12-05 04:17:22,129 - INFO - epoch 1, step 24840, training loss = 2.974659, validation loss = 2.546304
2018-12-05 04:17:25,550 - INFO - epoch 1, step 24850, training loss = 1.732002, validation loss = 2.442944
2018-12-05 04:17:28,888 - INFO - epoch 1, step 24860, training loss = 1.878371, validation loss = 2.455187
2018-12-05 04:17:32,090 - INFO - epoch 1, step 24870, training loss = 2.131584, validation loss = 2.231738
2018-12-05 04:17:35,300 - INFO - epoch 1, step 24880, training loss = 2.214478, validation loss = 2.172896
2018-12-05 04:17:39,534 - INFO - epoch 1, step 24890, training loss = 2.604696, validation loss = 2.030536
2018-12-05 04:17:43,908 - INFO - epoch 1, step 24900, training loss = 2.166858, validation loss = 1.979751
2018-12-05 04:17:48,204 - INFO - epoch 1, step 24910, training loss = 2.869428, validation loss = 1.545477
2018-12-05 04:17:52,703 - INFO - epoch 1, step 24920, training loss = 2.250981, validation loss = 2.005172
2018-12-05 04:17:57,200 - INFO - epoch 1, step 24930, training loss = 2.100935, validation loss = 1.921070
2018-12-05 04:18:01,345 - INFO - epoch 1, step 24940, training loss = 2.156621, validation loss = 2.181839
2018-12-05 04:18:05,930 - INFO - epoch 1, step 24950, training loss = 2.551116, validation loss = 1.971902
2018-12-05 04:18:11,254 - INFO - epoch 1, step 24960, training loss = 2.835332, validation loss = 2.223335
2018-12-05 04:18:16,732 - INFO - epoch 1, step 24970, training loss = 2.525307, validation loss = 2.392565
2018-12-05 04:18:22,109 - INFO - epoch 1, step 24980, training loss = 2.075196, validation loss = 2.291046
2018-12-05 04:18:27,147 - INFO - epoch 1, step 24990, training loss = 2.385075, validation loss = 2.664942
2018-12-05 04:18:32,772 - INFO - epoch 1, step 25000, training loss = 2.443081, validation loss = 2.193498
2018-12-05 04:18:38,295 - INFO - epoch 1, step 25010, training loss = 2.618567, validation loss = 2.049901
2018-12-05 04:18:43,537 - INFO - epoch 1, step 25020, training loss = 2.905267, validation loss = 2.203323
2018-12-05 04:18:48,992 - INFO - epoch 1, step 25030, training loss = 2.615927, validation loss = 2.675617
2018-12-05 04:18:54,504 - INFO - epoch 1, step 25040, training loss = 2.551659, validation loss = 1.961557
2018-12-05 04:18:59,488 - INFO - epoch 1, step 25050, training loss = 2.459336, validation loss = 2.174975
2018-12-05 04:19:04,642 - INFO - epoch 1, step 25060, training loss = 2.119408, validation loss = 2.260902
2018-12-05 04:19:09,823 - INFO - epoch 1, step 25070, training loss = 2.242388, validation loss = 2.266546
2018-12-05 04:19:15,064 - INFO - epoch 1, step 25080, training loss = 2.541800, validation loss = 2.393081
2018-12-05 04:19:20,627 - INFO - epoch 1, step 25090, training loss = 2.672974, validation loss = 2.013151
2018-12-05 04:19:25,618 - INFO - epoch 1, step 25100, training loss = 2.722491, validation loss = 2.233902
2018-12-05 04:19:30,980 - INFO - epoch 1, step 25110, training loss = 2.825011, validation loss = 2.175781
2018-12-05 04:19:36,204 - INFO - epoch 1, step 25120, training loss = 2.577360, validation loss = 2.193333
2018-12-05 04:19:41,303 - INFO - epoch 1, step 25130, training loss = 2.394678, validation loss = 2.109764
2018-12-05 04:19:46,868 - INFO - epoch 1, step 25140, training loss = 2.550739, validation loss = 2.131177
2018-12-05 04:19:52,274 - INFO - epoch 1, step 25150, training loss = 2.473314, validation loss = 2.207116
2018-12-05 04:19:56,913 - INFO - epoch 1, step 25160, training loss = 2.563272, validation loss = 1.940053
2018-12-05 04:20:00,797 - INFO - epoch 1, step 25170, training loss = 2.665018, validation loss = 2.048188
2018-12-05 04:20:04,284 - INFO - epoch 1, step 25180, training loss = 2.812247, validation loss = 2.522358
2018-12-05 04:20:07,768 - INFO - epoch 1, step 25190, training loss = 2.673258, validation loss = 2.619503
2018-12-05 04:20:11,340 - INFO - epoch 1, step 25200, training loss = 2.299122, validation loss = 2.395771
2018-12-05 04:20:14,853 - INFO - epoch 1, step 25210, training loss = 2.292239, validation loss = 2.080911
2018-12-05 04:20:18,221 - INFO - epoch 1, step 25220, training loss = 2.333008, validation loss = 2.424967
2018-12-05 04:20:21,973 - INFO - epoch 1, step 25230, training loss = 2.129029, validation loss = 2.223083
2018-12-05 04:20:25,737 - INFO - epoch 1, step 25240, training loss = 2.052757, validation loss = 1.949768
2018-12-05 04:20:29,141 - INFO - epoch 1, step 25250, training loss = 2.403104, validation loss = 2.303995
2018-12-05 04:20:32,461 - INFO - epoch 1, step 25260, training loss = 2.511810, validation loss = 2.382097
2018-12-05 04:20:36,338 - INFO - epoch 1, step 25270, training loss = 1.978749, validation loss = 2.205735
2018-12-05 04:20:42,140 - INFO - epoch 1, step 25280, training loss = 2.239560, validation loss = 1.997060
2018-12-05 04:20:47,489 - INFO - epoch 1, step 25290, training loss = 1.970638, validation loss = 2.333752
2018-12-05 04:20:52,738 - INFO - epoch 1, step 25300, training loss = 2.366615, validation loss = 2.634830
2018-12-05 04:20:57,959 - INFO - epoch 1, step 25310, training loss = 1.822496, validation loss = 2.515307
2018-12-05 04:21:03,616 - INFO - epoch 1, step 25320, training loss = 2.076419, validation loss = 2.295356
2018-12-05 04:21:08,822 - INFO - epoch 1, step 25330, training loss = 2.348909, validation loss = 2.228723
2018-12-05 04:21:13,793 - INFO - epoch 1, step 25340, training loss = 2.099038, validation loss = 2.295243
2018-12-05 04:21:19,602 - INFO - epoch 1, step 25350, training loss = 2.754015, validation loss = 2.183999
2018-12-05 04:21:25,955 - INFO - epoch 1, step 25360, training loss = 1.960570, validation loss = 2.510139
2018-12-05 04:21:31,313 - INFO - epoch 1, step 25370, training loss = 2.005698, validation loss = 2.341720
2018-12-05 04:21:36,479 - INFO - epoch 1, step 25380, training loss = 2.475940, validation loss = 2.628680
2018-12-05 04:21:41,719 - INFO - epoch 1, step 25390, training loss = 2.556505, validation loss = 2.432046
2018-12-05 04:21:46,869 - INFO - epoch 1, step 25400, training loss = 2.103586, validation loss = 2.222670
2018-12-05 04:21:52,159 - INFO - epoch 1, step 25410, training loss = 2.048904, validation loss = 2.434309
2018-12-05 04:21:57,623 - INFO - epoch 1, step 25420, training loss = 2.244952, validation loss = 2.055715
2018-12-05 04:22:02,734 - INFO - epoch 1, step 25430, training loss = 1.939155, validation loss = 2.158056
2018-12-05 04:22:07,874 - INFO - epoch 1, step 25440, training loss = 2.164728, validation loss = 2.356524
2018-12-05 04:22:13,301 - INFO - epoch 1, step 25450, training loss = 1.541591, validation loss = 2.091853
2018-12-05 04:22:18,620 - INFO - epoch 1, step 25460, training loss = 2.758269, validation loss = 2.162240
2018-12-05 04:22:21,719 - INFO - epoch 1, step 25470, training loss = 2.722216, validation loss = 1.979959
2018-12-05 04:22:24,894 - INFO - epoch 1, step 25480, training loss = 1.612129, validation loss = 2.372395
2018-12-05 04:22:28,011 - INFO - epoch 1, step 25490, training loss = 2.185037, validation loss = 2.134342
2018-12-05 04:22:31,364 - INFO - epoch 1, step 25500, training loss = 2.551150, validation loss = 2.440414
2018-12-05 04:22:34,549 - INFO - epoch 1, step 25510, training loss = 2.312918, validation loss = 2.470747
2018-12-05 04:22:37,675 - INFO - epoch 1, step 25520, training loss = 2.206872, validation loss = 2.510117
2018-12-05 04:22:40,843 - INFO - epoch 1, step 25530, training loss = 2.569202, validation loss = 1.985829
2018-12-05 04:22:43,931 - INFO - epoch 1, step 25540, training loss = 2.300776, validation loss = 2.256336
2018-12-05 04:22:47,120 - INFO - epoch 1, step 25550, training loss = 2.386335, validation loss = 2.279011
2018-12-05 04:22:50,282 - INFO - epoch 1, step 25560, training loss = 2.408794, validation loss = 2.269009
2018-12-05 04:22:53,453 - INFO - epoch 1, step 25570, training loss = 2.117533, validation loss = 2.305156
2018-12-05 04:22:56,701 - INFO - epoch 1, step 25580, training loss = 2.407162, validation loss = 2.255828
2018-12-05 04:23:02,023 - INFO - epoch 1, step 25590, training loss = 2.585686, validation loss = 2.695015
2018-12-05 04:23:07,749 - INFO - epoch 1, step 25600, training loss = 1.952950, validation loss = 2.631053
2018-12-05 04:23:13,499 - INFO - epoch 1, step 25610, training loss = 2.242673, validation loss = 2.488004
2018-12-05 04:23:18,771 - INFO - epoch 1, step 25620, training loss = 2.131844, validation loss = 2.505248
2018-12-05 04:23:24,227 - INFO - epoch 1, step 25630, training loss = 2.327522, validation loss = 2.093756
2018-12-05 04:23:29,643 - INFO - epoch 1, step 25640, training loss = 2.283550, validation loss = 2.243489
2018-12-05 04:23:34,680 - INFO - epoch 1, step 25650, training loss = 2.251445, validation loss = 2.153670
2018-12-05 04:23:40,146 - INFO - epoch 1, step 25660, training loss = 1.864643, validation loss = 2.445600
2018-12-05 04:23:45,738 - INFO - epoch 1, step 25670, training loss = 2.344868, validation loss = 2.318488
2018-12-05 04:23:51,531 - INFO - epoch 1, step 25680, training loss = 1.747388, validation loss = 2.374641
2018-12-05 04:23:56,893 - INFO - epoch 1, step 25690, training loss = 2.374896, validation loss = 2.302722
2018-12-05 04:24:03,395 - INFO - epoch 1, step 25700, training loss = 1.863483, validation loss = 1.611025
2018-12-05 04:24:08,840 - INFO - epoch 1, step 25710, training loss = 2.489762, validation loss = 2.233906
2018-12-05 04:24:14,240 - INFO - epoch 1, step 25720, training loss = 2.062404, validation loss = 2.706930
2018-12-05 04:24:19,963 - INFO - epoch 1, step 25730, training loss = 2.161456, validation loss = 2.220601
2018-12-05 04:24:25,846 - INFO - epoch 1, step 25740, training loss = 1.602646, validation loss = 2.720886
2018-12-05 04:24:30,997 - INFO - epoch 1, step 25750, training loss = 2.366204, validation loss = 2.365673
2018-12-05 04:24:35,388 - INFO - epoch 1, step 25760, training loss = 2.651446, validation loss = 2.589305
2018-12-05 04:24:39,347 - INFO - epoch 1, step 25770, training loss = 2.194679, validation loss = 2.329170
2018-12-05 04:24:43,467 - INFO - epoch 1, step 25780, training loss = 2.292164, validation loss = 2.196782
2018-12-05 04:24:47,785 - INFO - epoch 1, step 25790, training loss = 2.461044, validation loss = 2.358838
2018-12-05 04:24:51,897 - INFO - epoch 1, step 25800, training loss = 2.132928, validation loss = 2.435033
2018-12-05 04:24:56,015 - INFO - epoch 1, step 25810, training loss = 2.447038, validation loss = 2.397928
2018-12-05 04:24:59,285 - INFO - epoch 1, step 25820, training loss = 2.055435, validation loss = 1.941491
2018-12-05 04:25:02,695 - INFO - epoch 1, step 25830, training loss = 1.940434, validation loss = 2.128063
2018-12-05 04:25:05,833 - INFO - epoch 1, step 25840, training loss = 2.535673, validation loss = 2.024764
2018-12-05 04:25:09,138 - INFO - epoch 1, step 25850, training loss = 2.189267, validation loss = 2.457716
2018-12-05 04:25:12,251 - INFO - epoch 1, step 25860, training loss = 2.205169, validation loss = 2.632264
2018-12-05 04:25:15,415 - INFO - epoch 1, step 25870, training loss = 2.349133, validation loss = 2.533812
2018-12-05 04:25:18,562 - INFO - epoch 1, step 25880, training loss = 1.864093, validation loss = 2.145117
2018-12-05 04:25:21,557 - INFO - epoch 1, step 25890, training loss = 2.188652, validation loss = 2.617806
2018-12-05 04:25:24,674 - INFO - epoch 1, step 25900, training loss = 2.163909, validation loss = 2.135871
2018-12-05 04:25:27,718 - INFO - epoch 1, step 25910, training loss = 2.625230, validation loss = 2.641138
2018-12-05 04:25:30,682 - INFO - epoch 1, step 25920, training loss = 2.269016, validation loss = 1.790485
2018-12-05 04:25:33,880 - INFO - epoch 1, step 25930, training loss = 2.065037, validation loss = 2.633691
2018-12-05 04:25:37,074 - INFO - epoch 1, step 25940, training loss = 2.511659, validation loss = 2.091273
2018-12-05 04:25:40,400 - INFO - epoch 1, step 25950, training loss = 2.372329, validation loss = 2.812263
2018-12-05 04:25:45,455 - INFO - epoch 1, step 25960, training loss = 2.382044, validation loss = 2.134284
2018-12-05 04:25:50,612 - INFO - epoch 1, step 25970, training loss = 2.420678, validation loss = 1.775077
2018-12-05 04:25:55,796 - INFO - epoch 1, step 25980, training loss = 2.207591, validation loss = 2.412632
2018-12-05 04:26:01,345 - INFO - epoch 1, step 25990, training loss = 2.442995, validation loss = 2.024041
2018-12-05 04:26:06,461 - INFO - epoch 1, step 26000, training loss = 2.143299, validation loss = 2.174943
2018-12-05 04:26:11,511 - INFO - epoch 1, step 26010, training loss = 2.528106, validation loss = 2.528982
2018-12-05 04:26:16,968 - INFO - epoch 1, step 26020, training loss = 2.605123, validation loss = 2.246637
2018-12-05 04:26:21,937 - INFO - epoch 1, step 26030, training loss = 2.547840, validation loss = 2.120304
2018-12-05 04:26:27,589 - INFO - epoch 1, step 26040, training loss = 2.361251, validation loss = 2.307414
2018-12-05 04:26:32,607 - INFO - epoch 1, step 26050, training loss = 2.010676, validation loss = 2.218234
2018-12-05 04:26:37,901 - INFO - epoch 1, step 26060, training loss = 2.479088, validation loss = 2.642494
2018-12-05 04:26:42,903 - INFO - epoch 1, step 26070, training loss = 2.194788, validation loss = 2.553031
2018-12-05 04:26:47,865 - INFO - epoch 1, step 26080, training loss = 2.668784, validation loss = 2.292539
2018-12-05 04:26:53,117 - INFO - epoch 1, step 26090, training loss = 2.516508, validation loss = 2.471916
2018-12-05 04:26:58,042 - INFO - epoch 1, step 26100, training loss = 1.919720, validation loss = 2.432120
2018-12-05 04:27:02,990 - INFO - epoch 1, step 26110, training loss = 2.020800, validation loss = 2.071510
2018-12-05 04:27:07,849 - INFO - epoch 1, step 26120, training loss = 2.315630, validation loss = 2.231570
2018-12-05 04:27:12,898 - INFO - epoch 1, step 26130, training loss = 2.491679, validation loss = 2.236028
2018-12-05 04:27:18,249 - INFO - epoch 1, step 26140, training loss = 2.418203, validation loss = 2.197505
2018-12-05 04:27:23,272 - INFO - epoch 1, step 26150, training loss = 2.375943, validation loss = 2.367663
2018-12-05 04:27:28,876 - INFO - epoch 1, step 26160, training loss = 1.940083, validation loss = 2.273414
2018-12-05 04:27:34,384 - INFO - epoch 1, step 26170, training loss = 2.416941, validation loss = 1.781566
2018-12-05 04:27:40,196 - INFO - epoch 1, step 26180, training loss = 2.012436, validation loss = 2.320911
2018-12-05 04:27:45,447 - INFO - epoch 1, step 26190, training loss = 1.963840, validation loss = 2.315155
2018-12-05 04:27:51,582 - INFO - epoch 1, step 26200, training loss = 2.586946, validation loss = 2.065591
2018-12-05 04:27:57,364 - INFO - epoch 1, step 26210, training loss = 2.440999, validation loss = 2.054238
2018-12-05 04:28:02,622 - INFO - epoch 1, step 26220, training loss = 2.299361, validation loss = 2.182326
2018-12-05 04:28:08,086 - INFO - epoch 1, step 26230, training loss = 1.881357, validation loss = 1.974714
2018-12-05 04:28:13,292 - INFO - epoch 1, step 26240, training loss = 1.964282, validation loss = 2.132612
2018-12-05 04:28:18,621 - INFO - epoch 1, step 26250, training loss = 2.455731, validation loss = 2.713062
2018-12-05 04:28:24,002 - INFO - epoch 1, step 26260, training loss = 2.024732, validation loss = 2.332594
2018-12-05 04:28:29,705 - INFO - epoch 1, step 26270, training loss = 2.262706, validation loss = 2.503443
2018-12-05 04:28:35,227 - INFO - epoch 1, step 26280, training loss = 2.084518, validation loss = 2.358155
2018-12-05 04:28:41,447 - INFO - epoch 1, step 26290, training loss = 2.076186, validation loss = 2.078622
2018-12-05 04:28:46,933 - INFO - epoch 1, step 26300, training loss = 1.810169, validation loss = 2.057889
2018-12-05 04:28:52,061 - INFO - epoch 1, step 26310, training loss = 2.394469, validation loss = 1.752359
2018-12-05 04:28:57,360 - INFO - epoch 1, step 26320, training loss = 2.248816, validation loss = 1.812517
2018-12-05 04:29:02,495 - INFO - epoch 1, step 26330, training loss = 2.496781, validation loss = 2.280088
2018-12-05 04:29:07,610 - INFO - epoch 1, step 26340, training loss = 2.806054, validation loss = 2.344140
2018-12-05 04:29:12,719 - INFO - epoch 1, step 26350, training loss = 2.994445, validation loss = 2.236691
2018-12-05 04:29:17,880 - INFO - epoch 1, step 26360, training loss = 2.337530, validation loss = 1.859295
2018-12-05 04:29:23,108 - INFO - epoch 1, step 26370, training loss = 1.968692, validation loss = 1.985758
2018-12-05 04:29:28,341 - INFO - epoch 1, step 26380, training loss = 2.604909, validation loss = 2.189652
2018-12-05 04:29:33,606 - INFO - epoch 1, step 26390, training loss = 2.249379, validation loss = 2.337763
2018-12-05 04:29:38,839 - INFO - epoch 1, step 26400, training loss = 2.271920, validation loss = 2.429368
2018-12-05 04:29:44,167 - INFO - epoch 1, step 26410, training loss = 2.334301, validation loss = 2.044945
2018-12-05 04:29:49,851 - INFO - epoch 1, step 26420, training loss = 1.979384, validation loss = 2.147162
2018-12-05 04:29:55,283 - INFO - epoch 1, step 26430, training loss = 2.399744, validation loss = 2.089190
2018-12-05 04:30:00,374 - INFO - epoch 1, step 26440, training loss = 2.157415, validation loss = 2.153431
2018-12-05 04:30:05,419 - INFO - epoch 1, step 26450, training loss = 2.327797, validation loss = 2.258591
2018-12-05 04:30:10,799 - INFO - epoch 1, step 26460, training loss = 2.645959, validation loss = 2.001200
2018-12-05 04:30:15,413 - INFO - epoch 1, step 26470, training loss = 2.632218, validation loss = 1.843903
2018-12-05 04:30:18,963 - INFO - epoch 1, step 26480, training loss = 2.884807, validation loss = 2.202613
2018-12-05 04:30:22,124 - INFO - epoch 1, step 26490, training loss = 2.207812, validation loss = 2.231025
2018-12-05 04:30:25,287 - INFO - epoch 1, step 26500, training loss = 1.983485, validation loss = 2.444943
2018-12-05 04:30:28,651 - INFO - epoch 1, step 26510, training loss = 2.139756, validation loss = 2.472858
2018-12-05 04:30:32,127 - INFO - epoch 1, step 26520, training loss = 2.112393, validation loss = 1.997063
2018-12-05 04:30:35,491 - INFO - epoch 1, step 26530, training loss = 2.289866, validation loss = 1.925319
2018-12-05 04:30:38,826 - INFO - epoch 1, step 26540, training loss = 2.198741, validation loss = 2.428169
2018-12-05 04:30:42,147 - INFO - epoch 1, step 26550, training loss = 2.697913, validation loss = 2.168273
2018-12-05 04:30:45,376 - INFO - epoch 1, step 26560, training loss = 2.472646, validation loss = 2.422337
2018-12-05 04:30:48,536 - INFO - epoch 1, step 26570, training loss = 2.542675, validation loss = 1.830075
2018-12-05 04:30:51,593 - INFO - epoch 1, step 26580, training loss = 2.672189, validation loss = 2.391702
2018-12-05 04:30:54,651 - INFO - epoch 1, step 26590, training loss = 2.774611, validation loss = 2.201216
2018-12-05 04:30:57,694 - INFO - epoch 1, step 26600, training loss = 2.541419, validation loss = 2.417251
2018-12-05 04:31:00,955 - INFO - epoch 1, step 26610, training loss = 2.376362, validation loss = 2.183222
2018-12-05 04:31:03,970 - INFO - epoch 1, step 26620, training loss = 2.547627, validation loss = 2.298602
2018-12-05 04:31:07,139 - INFO - epoch 1, step 26630, training loss = 2.335860, validation loss = 2.886246
2018-12-05 04:31:10,292 - INFO - epoch 1, step 26640, training loss = 2.643630, validation loss = 2.610099
2018-12-05 04:31:13,548 - INFO - epoch 1, step 26650, training loss = 2.300360, validation loss = 2.325348
2018-12-05 04:31:16,778 - INFO - epoch 1, step 26660, training loss = 2.130106, validation loss = 1.779513
2018-12-05 04:31:19,897 - INFO - epoch 1, step 26670, training loss = 2.263649, validation loss = 2.207968
2018-12-05 04:31:23,025 - INFO - epoch 1, step 26680, training loss = 2.400177, validation loss = 2.543300
2018-12-05 04:31:26,144 - INFO - epoch 1, step 26690, training loss = 2.075240, validation loss = 2.331955
2018-12-05 04:31:29,311 - INFO - epoch 1, step 26700, training loss = 2.264106, validation loss = 2.159935
2018-12-05 04:31:32,417 - INFO - epoch 1, step 26710, training loss = 2.480646, validation loss = 2.397853
2018-12-05 04:31:37,245 - INFO - epoch 1, step 26720, training loss = 2.191708, validation loss = 2.173725
2018-12-05 04:31:42,920 - INFO - epoch 1, step 26730, training loss = 2.657593, validation loss = 2.393880
2018-12-05 04:31:48,878 - INFO - epoch 1, step 26740, training loss = 2.076653, validation loss = 2.290365
2018-12-05 04:31:54,794 - INFO - epoch 1, step 26750, training loss = 2.244200, validation loss = 2.687216
2018-12-05 04:32:00,981 - INFO - epoch 1, step 26760, training loss = 2.066866, validation loss = 2.171909
2018-12-05 04:32:06,779 - INFO - epoch 1, step 26770, training loss = 1.854510, validation loss = 2.230610
2018-12-05 04:32:12,077 - INFO - epoch 1, step 26780, training loss = 2.138541, validation loss = 1.980156
2018-12-05 04:32:17,522 - INFO - epoch 1, step 26790, training loss = 2.434705, validation loss = 2.039675
2018-12-05 04:32:22,836 - INFO - epoch 1, step 26800, training loss = 2.293798, validation loss = 2.195771
2018-12-05 04:32:28,049 - INFO - epoch 1, step 26810, training loss = 1.627081, validation loss = 2.568538
2018-12-05 04:32:33,782 - INFO - epoch 1, step 26820, training loss = 1.863378, validation loss = 2.622232
2018-12-05 04:32:39,247 - INFO - epoch 1, step 26830, training loss = 2.093557, validation loss = 1.708542
2018-12-05 04:32:45,120 - INFO - epoch 1, step 26840, training loss = 1.780688, validation loss = 2.133249
2018-12-05 04:32:50,564 - INFO - epoch 1, step 26850, training loss = 2.193640, validation loss = 2.279037
2018-12-05 04:32:55,549 - INFO - epoch 1, step 26860, training loss = 2.487553, validation loss = 2.508842
2018-12-05 04:33:00,640 - INFO - epoch 1, step 26870, training loss = 2.652154, validation loss = 2.045732
2018-12-05 04:33:05,750 - INFO - epoch 1, step 26880, training loss = 2.542410, validation loss = 1.954985
2018-12-05 04:33:10,742 - INFO - epoch 1, step 26890, training loss = 2.583512, validation loss = 2.431853
2018-12-05 04:33:16,388 - INFO - epoch 1, step 26900, training loss = 2.236446, validation loss = 2.046079
2018-12-05 04:33:21,561 - INFO - epoch 1, step 26910, training loss = 2.392138, validation loss = 2.490529
2018-12-05 04:33:26,942 - INFO - epoch 1, step 26920, training loss = 2.510795, validation loss = 2.639775
2018-12-05 04:33:32,362 - INFO - epoch 1, step 26930, training loss = 2.516983, validation loss = 2.379596
2018-12-05 04:33:37,370 - INFO - epoch 1, step 26940, training loss = 2.484052, validation loss = 1.891686
2018-12-05 04:33:42,489 - INFO - epoch 1, step 26950, training loss = 2.744652, validation loss = 2.551535
2018-12-05 04:33:47,689 - INFO - epoch 1, step 26960, training loss = 2.299603, validation loss = 2.272813
2018-12-05 04:33:53,041 - INFO - epoch 1, step 26970, training loss = 2.587629, validation loss = 2.216736
2018-12-05 04:33:58,607 - INFO - epoch 1, step 26980, training loss = 2.496721, validation loss = 2.170997
2018-12-05 04:34:03,925 - INFO - epoch 1, step 26990, training loss = 2.584941, validation loss = 1.995078
2018-12-05 04:34:09,165 - INFO - epoch 1, step 27000, training loss = 2.732332, validation loss = 2.497313
2018-12-05 04:34:14,310 - INFO - epoch 1, step 27010, training loss = 2.802718, validation loss = 2.125956
2018-12-05 04:34:19,463 - INFO - epoch 1, step 27020, training loss = 2.013564, validation loss = 2.127699
2018-12-05 04:34:24,526 - INFO - epoch 1, step 27030, training loss = 2.337516, validation loss = 2.313663
2018-12-05 04:34:29,589 - INFO - epoch 1, step 27040, training loss = 2.707184, validation loss = 2.377145
2018-12-05 04:34:34,843 - INFO - epoch 1, step 27050, training loss = 2.502427, validation loss = 2.309003
2018-12-05 04:34:39,497 - INFO - epoch 1, step 27060, training loss = 2.541595, validation loss = 2.176457
2018-12-05 04:34:43,679 - INFO - epoch 1, step 27070, training loss = 2.429610, validation loss = 2.316049
2018-12-05 04:34:47,846 - INFO - epoch 1, step 27080, training loss = 2.381502, validation loss = 2.279801
2018-12-05 04:34:51,980 - INFO - epoch 1, step 27090, training loss = 2.240856, validation loss = 2.047444
2018-12-05 04:34:56,152 - INFO - epoch 1, step 27100, training loss = 1.950395, validation loss = 1.919254
2018-12-05 04:35:00,234 - INFO - epoch 1, step 27110, training loss = 1.917657, validation loss = 2.151222
2018-12-05 04:35:03,810 - INFO - epoch 1, step 27120, training loss = 2.200006, validation loss = 1.937891
2018-12-05 04:35:07,610 - INFO - epoch 1, step 27130, training loss = 1.898504, validation loss = 2.537050
2018-12-05 04:35:11,500 - INFO - epoch 1, step 27140, training loss = 2.095431, validation loss = 2.190487
2018-12-05 04:35:14,942 - INFO - epoch 1, step 27150, training loss = 2.352916, validation loss = 2.141109
2018-12-05 04:35:18,556 - INFO - epoch 1, step 27160, training loss = 2.139528, validation loss = 2.366165
2018-12-05 04:35:23,617 - INFO - epoch 1, step 27170, training loss = 2.096000, validation loss = 1.767419
2018-12-05 04:35:28,519 - INFO - epoch 1, step 27180, training loss = 2.305334, validation loss = 2.073569
2018-12-05 04:35:33,439 - INFO - epoch 1, step 27190, training loss = 2.262532, validation loss = 2.501826
2018-12-05 04:35:38,473 - INFO - epoch 1, step 27200, training loss = 2.365595, validation loss = 2.141812
2018-12-05 04:35:43,589 - INFO - epoch 1, step 27210, training loss = 2.285350, validation loss = 2.496559
2018-12-05 04:35:48,708 - INFO - epoch 1, step 27220, training loss = 2.308223, validation loss = 2.216277
2018-12-05 04:35:53,847 - INFO - epoch 1, step 27230, training loss = 2.098718, validation loss = 1.745487
2018-12-05 04:35:59,017 - INFO - epoch 1, step 27240, training loss = 2.248485, validation loss = 2.191686
2018-12-05 04:36:04,149 - INFO - epoch 1, step 27250, training loss = 2.189611, validation loss = 2.204237
2018-12-05 04:36:09,656 - INFO - epoch 1, step 27260, training loss = 1.637412, validation loss = 1.823801
2018-12-05 04:36:14,708 - INFO - epoch 1, step 27270, training loss = 2.538626, validation loss = 2.141061
2018-12-05 04:36:19,726 - INFO - epoch 1, step 27280, training loss = 2.398182, validation loss = 2.234473
2018-12-05 04:36:24,699 - INFO - epoch 1, step 27290, training loss = 2.423411, validation loss = 1.953530
2018-12-05 04:36:29,091 - INFO - epoch 1, step 27300, training loss = 2.325093, validation loss = 2.018273
2018-12-05 04:36:33,189 - INFO - epoch 1, step 27310, training loss = 2.250754, validation loss = 2.194865
2018-12-05 04:36:37,932 - INFO - epoch 1, step 27320, training loss = 2.030029, validation loss = 2.375359
2018-12-05 04:36:42,591 - INFO - epoch 1, step 27330, training loss = 2.437911, validation loss = 1.663283
2018-12-05 04:36:47,019 - INFO - epoch 1, step 27340, training loss = 2.119009, validation loss = 2.150377
2018-12-05 04:36:51,033 - INFO - epoch 1, step 27350, training loss = 1.901873, validation loss = 2.228749
2018-12-05 04:36:55,273 - INFO - epoch 1, step 27360, training loss = 2.289575, validation loss = 2.213762
2018-12-05 04:36:59,357 - INFO - epoch 1, step 27370, training loss = 2.437598, validation loss = 1.850712
2018-12-05 04:37:03,993 - INFO - epoch 1, step 27380, training loss = 2.235468, validation loss = 2.259053
2018-12-05 04:37:08,459 - INFO - epoch 1, step 27390, training loss = 2.116042, validation loss = 2.134323
2018-12-05 04:37:12,012 - INFO - epoch 1, step 27400, training loss = 2.347023, validation loss = 2.381408
2018-12-05 04:37:15,115 - INFO - epoch 1, step 27410, training loss = 2.476733, validation loss = 2.132176
2018-12-05 04:37:18,112 - INFO - epoch 1, step 27420, training loss = 2.262116, validation loss = 2.324784
2018-12-05 04:37:21,164 - INFO - epoch 1, step 27430, training loss = 2.256904, validation loss = 2.105846
2018-12-05 04:37:24,614 - INFO - epoch 1, step 27440, training loss = 2.496987, validation loss = 2.045968
2018-12-05 04:37:27,751 - INFO - epoch 1, step 27450, training loss = 2.364890, validation loss = 2.125887
2018-12-05 04:37:31,082 - INFO - epoch 1, step 27460, training loss = 2.458038, validation loss = 1.698574
2018-12-05 04:37:34,254 - INFO - epoch 1, step 27470, training loss = 2.621688, validation loss = 2.349476
2018-12-05 04:37:37,370 - INFO - epoch 1, step 27480, training loss = 2.432583, validation loss = 2.327676
2018-12-05 04:37:40,538 - INFO - epoch 1, step 27490, training loss = 2.317339, validation loss = 2.850418
2018-12-05 04:37:43,641 - INFO - epoch 1, step 27500, training loss = 2.320897, validation loss = 2.261288
2018-12-05 04:37:46,873 - INFO - epoch 1, step 27510, training loss = 2.029947, validation loss = 2.555185
2018-12-05 04:37:50,042 - INFO - epoch 1, step 27520, training loss = 2.086983, validation loss = 2.580407
2018-12-05 04:37:53,231 - INFO - epoch 1, step 27530, training loss = 2.306964, validation loss = 2.306947
2018-12-05 04:37:56,506 - INFO - epoch 1, step 27540, training loss = 1.915262, validation loss = 2.446483
2018-12-05 04:37:59,747 - INFO - epoch 1, step 27550, training loss = 1.693856, validation loss = 1.689830
2018-12-05 04:38:03,002 - INFO - epoch 1, step 27560, training loss = 2.331380, validation loss = 2.106510
2018-12-05 04:38:06,415 - INFO - epoch 1, step 27570, training loss = 2.393263, validation loss = 2.502996
2018-12-05 04:38:10,411 - INFO - epoch 1, step 27580, training loss = 2.179591, validation loss = 1.949414
2018-12-05 04:38:14,544 - INFO - epoch 1, step 27590, training loss = 2.572600, validation loss = 2.219878
2018-12-05 04:38:18,594 - INFO - epoch 1, step 27600, training loss = 2.423403, validation loss = 2.421624
2018-12-05 04:38:23,013 - INFO - epoch 1, step 27610, training loss = 1.804265, validation loss = 2.212195
2018-12-05 04:38:27,334 - INFO - epoch 1, step 27620, training loss = 2.444834, validation loss = 2.292509
2018-12-05 04:38:32,270 - INFO - epoch 1, step 27630, training loss = 2.029496, validation loss = 2.323785
2018-12-05 04:38:38,226 - INFO - epoch 1, step 27640, training loss = 2.005268, validation loss = 2.226900
2018-12-05 04:38:43,658 - INFO - epoch 1, step 27650, training loss = 1.665272, validation loss = 2.419137
2018-12-05 04:38:49,138 - INFO - epoch 1, step 27660, training loss = 2.354640, validation loss = 2.955706
2018-12-05 04:38:55,119 - INFO - epoch 1, step 27670, training loss = 1.798196, validation loss = 2.254602
2018-12-05 04:39:00,903 - INFO - epoch 1, step 27680, training loss = 2.040247, validation loss = 3.090432
2018-12-05 04:39:06,474 - INFO - epoch 1, step 27690, training loss = 2.075204, validation loss = 1.791509
2018-12-05 04:39:11,937 - INFO - epoch 1, step 27700, training loss = 1.869933, validation loss = 2.636858
2018-12-05 04:39:18,355 - INFO - epoch 1, step 27710, training loss = 2.038393, validation loss = 2.574312
2018-12-05 04:39:23,934 - INFO - epoch 1, step 27720, training loss = 2.165567, validation loss = 2.275188
2018-12-05 04:39:29,858 - INFO - epoch 1, step 27730, training loss = 1.899665, validation loss = 2.076902
2018-12-05 04:39:35,384 - INFO - epoch 1, step 27740, training loss = 2.346651, validation loss = 2.396752
2018-12-05 04:39:40,769 - INFO - epoch 1, step 27750, training loss = 2.110700, validation loss = 2.476936
2018-12-05 04:39:45,929 - INFO - epoch 1, step 27760, training loss = 2.160461, validation loss = 2.800658
2018-12-05 04:39:51,324 - INFO - epoch 1, step 27770, training loss = 2.030622, validation loss = 2.370322
2018-12-05 04:39:56,566 - INFO - epoch 1, step 27780, training loss = 1.930743, validation loss = 2.582144
2018-12-05 04:40:01,924 - INFO - epoch 1, step 27790, training loss = 2.322224, validation loss = 2.519740
2018-12-05 04:40:06,823 - INFO - epoch 1, step 27800, training loss = 2.223874, validation loss = 2.439133
2018-12-05 04:40:11,752 - INFO - epoch 1, step 27810, training loss = 2.529953, validation loss = 2.200759
2018-12-05 04:40:16,534 - INFO - epoch 1, step 27820, training loss = 2.246754, validation loss = 2.341192
2018-12-05 04:40:21,414 - INFO - epoch 1, step 27830, training loss = 2.290264, validation loss = 2.545184
2018-12-05 04:40:26,835 - INFO - epoch 1, step 27840, training loss = 1.817196, validation loss = 2.421598
2018-12-05 04:40:31,803 - INFO - epoch 1, step 27850, training loss = 1.968120, validation loss = 2.688472
2018-12-05 04:40:36,751 - INFO - epoch 1, step 27860, training loss = 2.199025, validation loss = 2.639670
2018-12-05 04:40:42,186 - INFO - epoch 1, step 27870, training loss = 1.601771, validation loss = 2.312012
2018-12-05 04:40:47,430 - INFO - epoch 1, step 27880, training loss = 1.843297, validation loss = 2.442123
2018-12-05 04:40:52,342 - INFO - epoch 1, step 27890, training loss = 2.288567, validation loss = 2.677626
2018-12-05 04:40:57,414 - INFO - epoch 1, step 27900, training loss = 2.350153, validation loss = 2.617234
2018-12-05 04:41:02,245 - INFO - epoch 1, step 27910, training loss = 2.146892, validation loss = 3.308849
2018-12-05 04:41:07,298 - INFO - epoch 1, step 27920, training loss = 2.346308, validation loss = 2.958219
2018-12-05 04:41:12,386 - INFO - epoch 1, step 27930, training loss = 2.537972, validation loss = 2.493516
2018-12-05 04:41:17,667 - INFO - epoch 1, step 27940, training loss = 1.765425, validation loss = 2.583969
2018-12-05 04:41:22,812 - INFO - epoch 1, step 27950, training loss = 2.067283, validation loss = 2.155293
2018-12-05 04:41:28,189 - INFO - epoch 1, step 27960, training loss = 1.478229, validation loss = 2.565819
2018-12-05 04:41:33,411 - INFO - epoch 1, step 27970, training loss = 2.110847, validation loss = 2.419378
2018-12-05 04:41:38,492 - INFO - epoch 1, step 27980, training loss = 1.864304, validation loss = 2.439595
2018-12-05 04:41:43,622 - INFO - epoch 1, step 27990, training loss = 2.191496, validation loss = 2.377168
2018-12-05 04:41:48,763 - INFO - epoch 1, step 28000, training loss = 2.186345, validation loss = 2.081942
2018-12-05 04:41:54,152 - INFO - epoch 1, step 28010, training loss = 2.159638, validation loss = 2.352237
2018-12-05 04:41:59,396 - INFO - epoch 1, step 28020, training loss = 2.138457, validation loss = 2.732423
2018-12-05 04:42:04,630 - INFO - epoch 1, step 28030, training loss = 2.409558, validation loss = 3.010531
2018-12-05 04:42:09,765 - INFO - epoch 1, step 28040, training loss = 2.108316, validation loss = 2.331225
2018-12-05 04:42:14,925 - INFO - epoch 1, step 28050, training loss = 1.961562, validation loss = 2.710006
2018-12-05 04:42:20,126 - INFO - epoch 1, step 28060, training loss = 1.787012, validation loss = 2.505371
2018-12-05 04:42:26,456 - INFO - epoch 1, step 28070, training loss = 1.718748, validation loss = 2.590159
2018-12-05 04:42:31,731 - INFO - epoch 1, step 28080, training loss = 2.187324, validation loss = 2.407797
2018-12-05 04:42:36,969 - INFO - epoch 1, step 28090, training loss = 1.795033, validation loss = 2.756788
2018-12-05 04:42:42,028 - INFO - epoch 1, step 28100, training loss = 2.090012, validation loss = 2.469327
2018-12-05 04:42:47,261 - INFO - epoch 1, step 28110, training loss = 2.105693, validation loss = 2.463923
2018-12-05 04:42:52,385 - INFO - epoch 1, step 28120, training loss = 2.243314, validation loss = 2.562457
2018-12-05 04:42:57,300 - INFO - epoch 1, step 28130, training loss = 2.071690, validation loss = 2.380390
2018-12-05 04:43:02,375 - INFO - epoch 1, step 28140, training loss = 2.034252, validation loss = 2.852397
2018-12-05 04:43:07,624 - INFO - epoch 1, step 28150, training loss = 2.624672, validation loss = 2.139086
2018-12-05 04:43:12,864 - INFO - epoch 1, step 28160, training loss = 2.129933, validation loss = 2.093025
2018-12-05 04:43:18,109 - INFO - epoch 1, step 28170, training loss = 2.218881, validation loss = 2.415538
2018-12-05 04:43:23,075 - INFO - epoch 1, step 28180, training loss = 2.007398, validation loss = 2.622234
2018-12-05 04:43:28,075 - INFO - epoch 1, step 28190, training loss = 2.159135, validation loss = 2.437660
2018-12-05 04:43:33,379 - INFO - epoch 1, step 28200, training loss = 2.112157, validation loss = 2.797438
2018-12-05 04:43:38,437 - INFO - epoch 1, step 28210, training loss = 2.290430, validation loss = 2.356584
2018-12-05 04:43:43,681 - INFO - epoch 1, step 28220, training loss = 2.596153, validation loss = 2.160806
2018-12-05 04:43:48,820 - INFO - epoch 1, step 28230, training loss = 2.277526, validation loss = 2.276208
2018-12-05 04:43:53,842 - INFO - epoch 1, step 28240, training loss = 2.278405, validation loss = 2.545684
2018-12-05 04:43:58,794 - INFO - epoch 1, step 28250, training loss = 1.983437, validation loss = 2.239545
2018-12-05 04:44:03,903 - INFO - epoch 1, step 28260, training loss = 1.900347, validation loss = 2.306591
2018-12-05 04:44:09,267 - INFO - epoch 1, step 28270, training loss = 2.090699, validation loss = 2.468551
2018-12-05 04:44:14,396 - INFO - epoch 1, step 28280, training loss = 2.140203, validation loss = 2.275053
2018-12-05 04:44:19,433 - INFO - epoch 1, step 28290, training loss = 2.364337, validation loss = 2.407451
2018-12-05 04:44:24,404 - INFO - epoch 1, step 28300, training loss = 2.450502, validation loss = 2.404728
2018-12-05 04:44:29,498 - INFO - epoch 1, step 28310, training loss = 2.112534, validation loss = 2.207712
2018-12-05 04:44:34,509 - INFO - epoch 1, step 28320, training loss = 2.513981, validation loss = 2.253106
2018-12-05 04:44:39,824 - INFO - epoch 1, step 28330, training loss = 2.461195, validation loss = 2.742011
2018-12-05 04:44:44,782 - INFO - epoch 1, step 28340, training loss = 2.460806, validation loss = 2.373273
2018-12-05 04:44:49,815 - INFO - epoch 1, step 28350, training loss = 2.311431, validation loss = 2.516448
2018-12-05 04:44:54,707 - INFO - epoch 1, step 28360, training loss = 2.707021, validation loss = 2.614001
2018-12-05 04:44:58,930 - INFO - epoch 1, step 28370, training loss = 2.377052, validation loss = 2.609197
2018-12-05 04:45:03,103 - INFO - epoch 1, step 28380, training loss = 2.641673, validation loss = 2.078496
2018-12-05 04:45:07,431 - INFO - epoch 1, step 28390, training loss = 2.403540, validation loss = 2.079458
2018-12-05 04:45:11,944 - INFO - epoch 1, step 28400, training loss = 1.642555, validation loss = 2.105784
2018-12-05 04:45:16,459 - INFO - epoch 1, step 28410, training loss = 1.830050, validation loss = 2.400728
2018-12-05 04:45:21,826 - INFO - epoch 1, step 28420, training loss = 2.144031, validation loss = 2.191525
2018-12-05 04:45:27,526 - INFO - epoch 1, step 28430, training loss = 2.001970, validation loss = 2.729177
2018-12-05 04:45:32,981 - INFO - epoch 1, step 28440, training loss = 1.676499, validation loss = 2.673051
2018-12-05 04:45:38,518 - INFO - epoch 1, step 28450, training loss = 1.983681, validation loss = 2.229337
2018-12-05 04:45:44,492 - INFO - epoch 1, step 28460, training loss = 2.080536, validation loss = 2.236857
2018-12-05 04:45:50,310 - INFO - epoch 1, step 28470, training loss = 1.745317, validation loss = 2.250449
2018-12-05 04:45:56,136 - INFO - epoch 1, step 28480, training loss = 2.313708, validation loss = 2.606726
2018-12-05 04:46:01,560 - INFO - epoch 1, step 28490, training loss = 2.480984, validation loss = 2.404223
2018-12-05 04:46:07,812 - INFO - epoch 1, step 28500, training loss = 1.913768, validation loss = 2.457726
2018-12-05 04:46:13,667 - INFO - epoch 1, step 28510, training loss = 1.646144, validation loss = 2.141177
2018-12-05 04:46:16,897 - INFO - epoch 1, step 28520, training loss = 2.197399, validation loss = 2.466211
2018-12-05 04:46:19,922 - INFO - epoch 1, step 28530, training loss = 1.948640, validation loss = 2.561805
2018-12-05 04:46:23,091 - INFO - epoch 1, step 28540, training loss = 3.351912, validation loss = 2.670319
2018-12-05 04:46:26,243 - INFO - epoch 1, step 28550, training loss = 2.758887, validation loss = 2.140143
2018-12-05 04:46:29,381 - INFO - epoch 1, step 28560, training loss = 2.130775, validation loss = 2.145582
2018-12-05 04:46:32,669 - INFO - epoch 1, step 28570, training loss = 2.150661, validation loss = 2.501803
2018-12-05 04:46:35,895 - INFO - epoch 1, step 28580, training loss = 2.575504, validation loss = 2.082094
2018-12-05 04:46:39,149 - INFO - epoch 1, step 28590, training loss = 2.059870, validation loss = 2.142131
2018-12-05 04:46:42,197 - INFO - epoch 1, step 28600, training loss = 2.692626, validation loss = 2.248537
2018-12-05 04:46:45,174 - INFO - epoch 1, step 28610, training loss = 2.260619, validation loss = 2.024623
2018-12-05 04:46:48,292 - INFO - epoch 1, step 28620, training loss = 1.956621, validation loss = 2.050303
2018-12-05 04:46:51,385 - INFO - epoch 1, step 28630, training loss = 1.955395, validation loss = 2.344029
2018-12-05 04:46:54,472 - INFO - epoch 1, step 28640, training loss = 2.055254, validation loss = 2.269556
2018-12-05 04:46:57,856 - INFO - epoch 1, step 28650, training loss = 2.348842, validation loss = 1.859442
2018-12-05 04:47:02,075 - INFO - epoch 1, step 28660, training loss = 1.847045, validation loss = 2.341242
2018-12-05 04:47:06,526 - INFO - epoch 1, step 28670, training loss = 2.214988, validation loss = 2.375592
2018-12-05 04:47:10,554 - INFO - epoch 1, step 28680, training loss = 2.368662, validation loss = 2.249705
2018-12-05 04:47:14,764 - INFO - epoch 1, step 28690, training loss = 2.345208, validation loss = 2.396663
2018-12-05 04:47:18,942 - INFO - epoch 1, step 28700, training loss = 2.527935, validation loss = 2.277663
2018-12-05 04:47:23,684 - INFO - epoch 1, step 28710, training loss = 2.873980, validation loss = 2.297048
2018-12-05 04:47:28,844 - INFO - epoch 1, step 28720, training loss = 2.391848, validation loss = 2.371381
2018-12-05 04:47:34,178 - INFO - epoch 1, step 28730, training loss = 2.236597, validation loss = 1.998509
2018-12-05 04:47:39,055 - INFO - epoch 1, step 28740, training loss = 2.270810, validation loss = 2.427131
2018-12-05 04:47:43,963 - INFO - epoch 1, step 28750, training loss = 2.388566, validation loss = 2.363967
2018-12-05 04:47:49,028 - INFO - epoch 1, step 28760, training loss = 2.336706, validation loss = 2.355943
2018-12-05 04:47:53,910 - INFO - epoch 1, step 28770, training loss = 2.461612, validation loss = 2.211240
2018-12-05 04:47:58,989 - INFO - epoch 1, step 28780, training loss = 2.613976, validation loss = 1.924150
2018-12-05 04:48:03,766 - INFO - epoch 1, step 28790, training loss = 2.306131, validation loss = 2.271790
2018-12-05 04:48:08,875 - INFO - epoch 1, step 28800, training loss = 2.320116, validation loss = 2.546419
2018-12-05 04:48:14,021 - INFO - epoch 1, step 28810, training loss = 2.176635, validation loss = 2.157221
2018-12-05 04:48:19,029 - INFO - epoch 1, step 28820, training loss = 2.334107, validation loss = 2.389019
2018-12-05 04:48:23,999 - INFO - epoch 1, step 28830, training loss = 1.746846, validation loss = 2.212593
2018-12-05 04:48:29,145 - INFO - epoch 1, step 28840, training loss = 2.452339, validation loss = 2.247857
2018-12-05 04:48:34,388 - INFO - epoch 1, step 28850, training loss = 1.893977, validation loss = 2.474581
2018-12-05 04:48:39,703 - INFO - epoch 1, step 28860, training loss = 2.587314, validation loss = 2.414258
2018-12-05 04:48:44,742 - INFO - epoch 1, step 28870, training loss = 2.774289, validation loss = 2.803770
2018-12-05 04:48:49,807 - INFO - epoch 1, step 28880, training loss = 2.204210, validation loss = 2.685784
2018-12-05 04:48:54,836 - INFO - epoch 1, step 28890, training loss = 2.022969, validation loss = 2.382196
2018-12-05 04:48:59,848 - INFO - epoch 1, step 28900, training loss = 2.075452, validation loss = 2.499734
2018-12-05 04:49:05,296 - INFO - epoch 1, step 28910, training loss = 2.518868, validation loss = 2.530663
2018-12-05 04:49:10,468 - INFO - epoch 1, step 28920, training loss = 2.513570, validation loss = 2.109090
2018-12-05 04:49:15,483 - INFO - epoch 1, step 28930, training loss = 2.227407, validation loss = 2.254215
2018-12-05 04:49:20,597 - INFO - epoch 1, step 28940, training loss = 2.456319, validation loss = 2.264880
2018-12-05 04:49:25,819 - INFO - epoch 1, step 28950, training loss = 2.366962, validation loss = 2.186594
2018-12-05 04:49:31,154 - INFO - epoch 1, step 28960, training loss = 2.472081, validation loss = 2.141914
2018-12-05 04:49:36,492 - INFO - epoch 1, step 28970, training loss = 2.522381, validation loss = 2.081160
2018-12-05 04:49:41,687 - INFO - epoch 1, step 28980, training loss = 2.560291, validation loss = 2.320580
2018-12-05 04:49:46,871 - INFO - epoch 1, step 28990, training loss = 2.232887, validation loss = 2.376260
2018-12-05 04:49:52,335 - INFO - epoch 1, step 29000, training loss = 2.335660, validation loss = 2.252642
2018-12-05 04:49:57,291 - INFO - epoch 1, step 29010, training loss = 2.414505, validation loss = 2.095452
2018-12-05 04:50:02,585 - INFO - epoch 1, step 29020, training loss = 2.213601, validation loss = 2.502792
2018-12-05 04:50:07,850 - INFO - epoch 1, step 29030, training loss = 2.611310, validation loss = 2.392345
2018-12-05 04:50:12,810 - INFO - epoch 1, step 29040, training loss = 2.662285, validation loss = 2.274936
2018-12-05 04:50:17,918 - INFO - epoch 1, step 29050, training loss = 2.308864, validation loss = 2.553703
2018-12-05 04:50:22,380 - INFO - epoch 1, step 29060, training loss = 1.899822, validation loss = 2.209728
2018-12-05 04:50:26,813 - INFO - epoch 1, step 29070, training loss = 2.359555, validation loss = 2.136966
2018-12-05 04:50:31,116 - INFO - epoch 1, step 29080, training loss = 2.106704, validation loss = 2.316927
2018-12-05 04:50:35,303 - INFO - epoch 1, step 29090, training loss = 2.352343, validation loss = 2.357811
2018-12-05 04:50:39,467 - INFO - epoch 1, step 29100, training loss = 2.010026, validation loss = 2.239809
2018-12-05 04:50:43,638 - INFO - epoch 1, step 29110, training loss = 2.310450, validation loss = 1.993236
2018-12-05 04:50:49,132 - INFO - epoch 1, step 29120, training loss = 2.044128, validation loss = 2.087584
2018-12-05 04:50:54,983 - INFO - epoch 1, step 29130, training loss = 2.435146, validation loss = 2.404707
2018-12-05 04:51:00,538 - INFO - epoch 1, step 29140, training loss = 2.297801, validation loss = 2.193876
2018-12-05 04:51:05,957 - INFO - epoch 1, step 29150, training loss = 2.265903, validation loss = 2.331622
2018-12-05 04:51:11,486 - INFO - epoch 1, step 29160, training loss = 1.838467, validation loss = 1.858366
2018-12-05 04:51:17,130 - INFO - epoch 1, step 29170, training loss = 2.308158, validation loss = 2.397763
2018-12-05 04:51:22,738 - INFO - epoch 1, step 29180, training loss = 1.789392, validation loss = 2.468218
2018-12-05 04:51:28,724 - INFO - epoch 1, step 29190, training loss = 1.725830, validation loss = 2.282975
2018-12-05 04:51:34,206 - INFO - epoch 1, step 29200, training loss = 1.895251, validation loss = 2.184444
2018-12-05 04:51:40,230 - INFO - epoch 1, step 29210, training loss = 2.166064, validation loss = 2.288411
2018-12-05 04:51:45,547 - INFO - epoch 1, step 29220, training loss = 2.474957, validation loss = 2.220676
2018-12-05 04:51:50,696 - INFO - epoch 1, step 29230, training loss = 2.223794, validation loss = 2.276412
2018-12-05 04:51:56,310 - INFO - epoch 1, step 29240, training loss = 1.980208, validation loss = 2.360161
2018-12-05 04:52:01,233 - INFO - epoch 1, step 29250, training loss = 2.222051, validation loss = 2.069403
2018-12-05 04:52:06,529 - INFO - epoch 1, step 29260, training loss = 2.332422, validation loss = 2.256682
2018-12-05 04:52:11,867 - INFO - epoch 1, step 29270, training loss = 2.427462, validation loss = 2.040401
2018-12-05 04:52:17,279 - INFO - epoch 1, step 29280, training loss = 2.296033, validation loss = 2.193449
2018-12-05 04:52:22,401 - INFO - epoch 1, step 29290, training loss = 2.418093, validation loss = 2.090800
2018-12-05 04:52:27,500 - INFO - epoch 1, step 29300, training loss = 2.473609, validation loss = 1.958648
2018-12-05 04:52:32,521 - INFO - epoch 1, step 29310, training loss = 2.607114, validation loss = 2.439609
2018-12-05 04:52:37,595 - INFO - epoch 1, step 29320, training loss = 2.411463, validation loss = 2.173774
2018-12-05 04:52:42,627 - INFO - epoch 1, step 29330, training loss = 2.648163, validation loss = 2.184064
2018-12-05 04:52:47,658 - INFO - epoch 1, step 29340, training loss = 2.370326, validation loss = 2.360653
2018-12-05 04:52:53,225 - INFO - epoch 1, step 29350, training loss = 1.806107, validation loss = 2.049714
2018-12-05 04:52:58,588 - INFO - epoch 1, step 29360, training loss = 2.012433, validation loss = 2.029932
2018-12-05 04:53:03,585 - INFO - epoch 1, step 29370, training loss = 1.884322, validation loss = 2.032878
2018-12-05 04:53:09,172 - INFO - epoch 1, step 29380, training loss = 2.033595, validation loss = 2.237075
2018-12-05 04:53:14,535 - INFO - epoch 1, step 29390, training loss = 2.055984, validation loss = 2.030644
2018-12-05 04:53:20,088 - INFO - epoch 1, step 29400, training loss = 2.157567, validation loss = 2.221182
2018-12-05 04:53:25,361 - INFO - epoch 1, step 29410, training loss = 2.561174, validation loss = 2.469586
2018-12-05 04:53:30,429 - INFO - epoch 1, step 29420, training loss = 2.276340, validation loss = 2.276999
2018-12-05 04:53:35,996 - INFO - epoch 1, step 29430, training loss = 2.162756, validation loss = 2.317658
2018-12-05 04:53:41,175 - INFO - epoch 1, step 29440, training loss = 2.286539, validation loss = 2.312736
2018-12-05 04:53:46,456 - INFO - epoch 1, step 29450, training loss = 2.369827, validation loss = 2.158351
2018-12-05 04:53:51,782 - INFO - epoch 1, step 29460, training loss = 2.208547, validation loss = 2.190968
2018-12-05 04:53:56,896 - INFO - epoch 1, step 29470, training loss = 2.497593, validation loss = 2.418945
2018-12-05 04:54:02,127 - INFO - epoch 1, step 29480, training loss = 2.282832, validation loss = 2.096410
2018-12-05 04:54:07,358 - INFO - epoch 1, step 29490, training loss = 2.325354, validation loss = 2.334738
2018-12-05 04:54:12,293 - INFO - epoch 1, step 29500, training loss = 2.567441, validation loss = 2.668716
2018-12-05 04:54:18,042 - INFO - epoch 1, step 29510, training loss = 2.003062, validation loss = 2.587956
2018-12-05 04:54:23,206 - INFO - epoch 1, step 29520, training loss = 2.009271, validation loss = 2.244475
2018-12-05 04:54:28,464 - INFO - epoch 1, step 29530, training loss = 2.351271, validation loss = 2.406161
2018-12-05 04:54:34,239 - INFO - epoch 1, step 29540, training loss = 2.453670, validation loss = 2.518273
2018-12-05 04:54:39,323 - INFO - epoch 1, step 29550, training loss = 2.459082, validation loss = 2.382352
2018-12-05 04:54:44,765 - INFO - epoch 1, step 29560, training loss = 2.010381, validation loss = 2.234134
2018-12-05 04:54:50,261 - INFO - epoch 1, step 29570, training loss = 2.123670, validation loss = 2.265640
2018-12-05 04:54:55,341 - INFO - epoch 1, step 29580, training loss = 2.357063, validation loss = 2.056762
2018-12-05 04:55:00,513 - INFO - epoch 1, step 29590, training loss = 2.543916, validation loss = 2.315961
2018-12-05 04:55:05,505 - INFO - epoch 1, step 29600, training loss = 2.125597, validation loss = 2.300260
2018-12-05 04:55:10,747 - INFO - epoch 1, step 29610, training loss = 2.157757, validation loss = 2.484239
2018-12-05 04:55:16,195 - INFO - epoch 1, step 29620, training loss = 2.068218, validation loss = 2.250208
2018-12-05 04:55:21,560 - INFO - epoch 1, step 29630, training loss = 2.005202, validation loss = 2.334297
2018-12-05 04:55:27,197 - INFO - epoch 1, step 29640, training loss = 2.423369, validation loss = 2.516847
2018-12-05 04:55:32,568 - INFO - epoch 1, step 29650, training loss = 2.356453, validation loss = 2.581197
2018-12-05 04:55:37,882 - INFO - epoch 1, step 29660, training loss = 1.902880, validation loss = 2.666889
2018-12-05 04:55:42,821 - INFO - epoch 1, step 29670, training loss = 2.527853, validation loss = 2.788508
2018-12-05 04:55:47,974 - INFO - epoch 1, step 29680, training loss = 2.256875, validation loss = 2.695651
2018-12-05 04:55:53,125 - INFO - epoch 1, step 29690, training loss = 2.483629, validation loss = 2.767277
2018-12-05 04:55:57,715 - INFO - epoch 1, step 29700, training loss = 2.411903, validation loss = 2.725009
2018-12-05 04:56:01,636 - INFO - epoch 1, step 29710, training loss = 2.104133, validation loss = 2.296574
2018-12-05 04:56:05,951 - INFO - epoch 1, step 29720, training loss = 2.387156, validation loss = 2.374747
2018-12-05 04:56:10,717 - INFO - epoch 1, step 29730, training loss = 2.156152, validation loss = 2.362998
2018-12-05 04:56:14,815 - INFO - epoch 1, step 29740, training loss = 2.192231, validation loss = 2.717546
2018-12-05 04:56:18,963 - INFO - epoch 1, step 29750, training loss = 2.174829, validation loss = 2.158612
2018-12-05 04:56:23,475 - INFO - epoch 1, step 29760, training loss = 2.075564, validation loss = 2.641391
2018-12-05 04:56:28,605 - INFO - epoch 1, step 29770, training loss = 2.270008, validation loss = 2.574814
2018-12-05 04:56:33,543 - INFO - epoch 1, step 29780, training loss = 2.303062, validation loss = 2.428620
2018-12-05 04:56:38,408 - INFO - epoch 1, step 29790, training loss = 2.261866, validation loss = 2.408124
2018-12-05 04:56:43,448 - INFO - epoch 1, step 29800, training loss = 2.117460, validation loss = 2.694158
2018-12-05 04:56:48,693 - INFO - epoch 1, step 29810, training loss = 2.058417, validation loss = 2.453918
2018-12-05 04:56:53,737 - INFO - epoch 1, step 29820, training loss = 2.196664, validation loss = 2.304135
2018-12-05 04:56:58,723 - INFO - epoch 1, step 29830, training loss = 2.395125, validation loss = 2.253888
2018-12-05 04:57:04,420 - INFO - epoch 1, step 29840, training loss = 2.291289, validation loss = 2.225237
2018-12-05 04:57:09,608 - INFO - epoch 1, step 29850, training loss = 2.001128, validation loss = 2.403293
2018-12-05 04:57:15,011 - INFO - epoch 1, step 29860, training loss = 2.558346, validation loss = 2.337284
2018-12-05 04:57:20,137 - INFO - epoch 1, step 29870, training loss = 2.319176, validation loss = 2.733871
2018-12-05 04:57:25,770 - INFO - epoch 1, step 29880, training loss = 2.459484, validation loss = 2.862045
2018-12-05 04:57:31,027 - INFO - epoch 1, step 29890, training loss = 2.321845, validation loss = 2.448757
2018-12-05 04:57:36,240 - INFO - epoch 1, step 29900, training loss = 2.401827, validation loss = 2.033759
2018-12-05 04:57:41,430 - INFO - epoch 1, step 29910, training loss = 2.340196, validation loss = 2.565882
2018-12-05 04:57:46,585 - INFO - epoch 1, step 29920, training loss = 2.327532, validation loss = 2.552874
2018-12-05 04:57:51,712 - INFO - epoch 1, step 29930, training loss = 2.097879, validation loss = 2.421468
2018-12-05 04:57:56,980 - INFO - epoch 1, step 29940, training loss = 2.097149, validation loss = 2.508480
2018-12-05 04:58:02,261 - INFO - epoch 1, step 29950, training loss = 2.442235, validation loss = 2.107129
2018-12-05 04:58:07,438 - INFO - epoch 1, step 29960, training loss = 2.784992, validation loss = 2.134541
2018-12-05 04:58:12,475 - INFO - epoch 1, step 29970, training loss = 2.168451, validation loss = 2.251889
2018-12-05 04:58:17,755 - INFO - epoch 1, step 29980, training loss = 2.135332, validation loss = 2.452472
2018-12-05 04:58:22,923 - INFO - epoch 1, step 29990, training loss = 2.205938, validation loss = 2.263696
2018-12-05 04:58:28,325 - INFO - epoch 1, step 30000, training loss = 2.095874, validation loss = 2.452011
2018-12-05 04:58:33,562 - INFO - epoch 1, step 30010, training loss = 2.442999, validation loss = 2.016902
2018-12-05 04:58:38,695 - INFO - epoch 1, step 30020, training loss = 2.410662, validation loss = 2.480292
2018-12-05 04:58:43,932 - INFO - epoch 1, step 30030, training loss = 2.279902, validation loss = 2.502435
2018-12-05 04:58:49,071 - INFO - epoch 1, step 30040, training loss = 2.321334, validation loss = 2.189392
2018-12-05 04:58:54,154 - INFO - epoch 1, step 30050, training loss = 2.030005, validation loss = 2.420825
2018-12-05 04:58:59,003 - INFO - epoch 1, step 30060, training loss = 2.244819, validation loss = 2.525406
2018-12-05 04:59:03,401 - INFO - epoch 1, step 30070, training loss = 1.992393, validation loss = 2.664522
2018-12-05 04:59:07,679 - INFO - epoch 1, step 30080, training loss = 2.238507, validation loss = 2.382447
2018-12-05 04:59:11,774 - INFO - epoch 1, step 30090, training loss = 2.294132, validation loss = 2.098750
2018-12-05 04:59:15,889 - INFO - epoch 1, step 30100, training loss = 2.688257, validation loss = 2.252143
2018-12-05 04:59:19,568 - INFO - epoch 1, step 30110, training loss = 2.351814, validation loss = 2.152049
2018-12-05 04:59:22,704 - INFO - epoch 1, step 30120, training loss = 2.273029, validation loss = 2.240431
2018-12-05 04:59:25,794 - INFO - epoch 1, step 30130, training loss = 2.405943, validation loss = 2.756037
2018-12-05 04:59:28,904 - INFO - epoch 1, step 30140, training loss = 2.137072, validation loss = 2.729546
2018-12-05 04:59:32,050 - INFO - epoch 1, step 30150, training loss = 2.005862, validation loss = 2.587673
2018-12-05 04:59:35,260 - INFO - epoch 1, step 30160, training loss = 2.241536, validation loss = 2.261201
2018-12-05 04:59:38,334 - INFO - epoch 1, step 30170, training loss = 2.273834, validation loss = 2.641131
2018-12-05 04:59:41,478 - INFO - epoch 1, step 30180, training loss = 1.921409, validation loss = 2.501594
2018-12-05 04:59:44,707 - INFO - epoch 1, step 30190, training loss = 2.019505, validation loss = 2.482582
2018-12-05 04:59:47,937 - INFO - epoch 1, step 30200, training loss = 2.538028, validation loss = 2.747840
2018-12-05 04:59:51,140 - INFO - epoch 1, step 30210, training loss = 2.621955, validation loss = 2.610725
2018-12-05 04:59:55,913 - INFO - epoch 1, step 30220, training loss = 2.260225, validation loss = 2.168008
2018-12-05 05:00:00,978 - INFO - epoch 1, step 30230, training loss = 2.651742, validation loss = 2.308542
2018-12-05 05:00:06,580 - INFO - epoch 1, step 30240, training loss = 2.595048, validation loss = 2.393951
2018-12-05 05:00:11,432 - INFO - epoch 1, step 30250, training loss = 2.349267, validation loss = 2.204601
2018-12-05 05:00:16,255 - INFO - epoch 1, step 30260, training loss = 1.940964, validation loss = 3.141645
2018-12-05 05:00:21,277 - INFO - epoch 1, step 30270, training loss = 2.220715, validation loss = 2.430149
2018-12-05 05:00:26,476 - INFO - epoch 1, step 30280, training loss = 2.583961, validation loss = 2.470083
2018-12-05 05:00:31,505 - INFO - epoch 1, step 30290, training loss = 1.979994, validation loss = 2.448139
2018-12-05 05:00:36,546 - INFO - epoch 1, step 30300, training loss = 2.123419, validation loss = 2.728052
2018-12-05 05:00:41,622 - INFO - epoch 1, step 30310, training loss = 2.249921, validation loss = 2.632252
2018-12-05 05:00:46,509 - INFO - epoch 1, step 30320, training loss = 2.484151, validation loss = 2.613240
2018-12-05 05:00:51,480 - INFO - epoch 1, step 30330, training loss = 1.970101, validation loss = 2.386765
2018-12-05 05:00:56,647 - INFO - epoch 1, step 30340, training loss = 2.169241, validation loss = 1.861185
2018-12-05 05:01:01,564 - INFO - epoch 1, step 30350, training loss = 2.331031, validation loss = 2.233363
2018-12-05 05:01:07,068 - INFO - epoch 1, step 30360, training loss = 2.323171, validation loss = 2.389272
2018-12-05 05:01:12,744 - INFO - epoch 1, step 30370, training loss = 2.263441, validation loss = 2.170611
2018-12-05 05:01:17,910 - INFO - epoch 1, step 30380, training loss = 2.196110, validation loss = 2.799026
2018-12-05 05:01:23,429 - INFO - epoch 1, step 30390, training loss = 2.184165, validation loss = 2.349322
2018-12-05 05:01:29,621 - INFO - epoch 1, step 30400, training loss = 1.502124, validation loss = 2.145667
2018-12-05 05:01:35,634 - INFO - epoch 1, step 30410, training loss = 1.375759, validation loss = 2.577800
2018-12-05 05:01:40,960 - INFO - epoch 1, step 30420, training loss = 1.846349, validation loss = 2.095358
2018-12-05 05:01:46,867 - INFO - epoch 1, step 30430, training loss = 1.794156, validation loss = 2.314336
2018-12-05 05:01:52,304 - INFO - epoch 1, step 30440, training loss = 2.089638, validation loss = 2.486913
2018-12-05 05:01:57,459 - INFO - epoch 1, step 30450, training loss = 2.043439, validation loss = 2.254211
2018-12-05 05:02:03,245 - INFO - epoch 1, step 30460, training loss = 1.624130, validation loss = 2.446177
2018-12-05 05:02:08,703 - INFO - epoch 1, step 30470, training loss = 2.119742, validation loss = 2.822005
2018-12-05 05:02:14,187 - INFO - epoch 1, step 30480, training loss = 1.795288, validation loss = 2.769656
2018-12-05 05:02:19,355 - INFO - epoch 1, step 30490, training loss = 2.408951, validation loss = 2.479734
2018-12-05 05:02:24,550 - INFO - epoch 1, step 30500, training loss = 2.206417, validation loss = 2.500550
2018-12-05 05:02:30,436 - INFO - epoch 1, step 30510, training loss = 1.729333, validation loss = 2.011339
2018-12-05 05:02:35,858 - INFO - epoch 1, step 30520, training loss = 2.456486, validation loss = 2.772497
2018-12-05 05:02:40,801 - INFO - epoch 1, step 30530, training loss = 2.289060, validation loss = 2.367172
2018-12-05 05:02:46,292 - INFO - epoch 1, step 30540, training loss = 1.970510, validation loss = 2.755890
2018-12-05 05:02:51,756 - INFO - epoch 1, step 30550, training loss = 2.197760, validation loss = 2.269717
2018-12-05 05:02:57,244 - INFO - epoch 1, step 30560, training loss = 2.133384, validation loss = 2.319135
2018-12-05 05:03:02,816 - INFO - epoch 1, step 30570, training loss = 2.457149, validation loss = 2.507654
2018-12-05 05:03:08,393 - INFO - epoch 1, step 30580, training loss = 1.939553, validation loss = 2.235378
2018-12-05 05:03:13,861 - INFO - epoch 1, step 30590, training loss = 1.841560, validation loss = 2.488270
2018-12-05 05:03:19,055 - INFO - epoch 1, step 30600, training loss = 2.184886, validation loss = 2.868326
2018-12-05 05:03:25,067 - INFO - epoch 1, step 30610, training loss = 2.033213, validation loss = 2.431974
2018-12-05 05:03:30,367 - INFO - epoch 1, step 30620, training loss = 1.941000, validation loss = 2.833141
2018-12-05 05:03:36,673 - INFO - epoch 1, step 30630, training loss = 2.000316, validation loss = 2.606305
2018-12-05 05:03:42,502 - INFO - epoch 1, step 30640, training loss = 1.953164, validation loss = 2.427055
2018-12-05 05:03:47,673 - INFO - epoch 1, step 30650, training loss = 2.007701, validation loss = 2.261409
2018-12-05 05:03:53,482 - INFO - epoch 1, step 30660, training loss = 1.921006, validation loss = 2.238782
2018-12-05 05:03:59,023 - INFO - epoch 1, step 30670, training loss = 2.138893, validation loss = 2.872137
2018-12-05 05:04:04,469 - INFO - epoch 1, step 30680, training loss = 2.193562, validation loss = 2.495569
2018-12-05 05:04:10,072 - INFO - epoch 1, step 30690, training loss = 2.020082, validation loss = 2.745868
2018-12-05 05:04:15,948 - INFO - epoch 1, step 30700, training loss = 1.688753, validation loss = 2.095065
2018-12-05 05:04:21,483 - INFO - epoch 1, step 30710, training loss = 1.984306, validation loss = 2.309786
2018-12-05 05:04:27,070 - INFO - epoch 1, step 30720, training loss = 2.388648, validation loss = 2.406076
2018-12-05 05:04:32,199 - INFO - epoch 1, step 30730, training loss = 1.976985, validation loss = 2.445550
2018-12-05 05:04:37,816 - INFO - epoch 1, step 30740, training loss = 2.051122, validation loss = 2.166829
2018-12-05 05:04:42,238 - INFO - epoch 1, step 30750, training loss = 3.701481, validation loss = 2.237241
2018-12-05 05:04:44,903 - INFO - epoch 1, step 30760, training loss = 2.145569, validation loss = 2.270208
2018-12-05 05:04:47,604 - INFO - epoch 1, step 30770, training loss = 3.131034, validation loss = 2.269268
2018-12-05 05:04:50,415 - INFO - epoch 1, step 30780, training loss = 2.211462, validation loss = 2.359632
2018-12-05 05:04:53,143 - INFO - epoch 1, step 30790, training loss = 2.932010, validation loss = 2.715401
2018-12-05 05:04:55,870 - INFO - epoch 1, step 30800, training loss = 2.042352, validation loss = 2.792355
2018-12-05 05:04:58,622 - INFO - epoch 1, step 30810, training loss = 2.731048, validation loss = 2.699049
2018-12-05 05:05:01,400 - INFO - epoch 1, step 30820, training loss = 2.343174, validation loss = 2.562534
2018-12-05 05:05:04,159 - INFO - epoch 1, step 30830, training loss = 2.482767, validation loss = 2.363858
2018-12-05 05:05:07,118 - INFO - epoch 1, step 30840, training loss = 2.144418, validation loss = 2.559369
2018-12-05 05:05:10,606 - INFO - epoch 1, step 30850, training loss = 1.752167, validation loss = 2.388312
2018-12-05 05:05:13,984 - INFO - epoch 1, step 30860, training loss = 2.591944, validation loss = 2.364670
2018-12-05 05:05:17,274 - INFO - epoch 1, step 30870, training loss = 2.736758, validation loss = 2.777272
2018-12-05 05:05:20,427 - INFO - epoch 1, step 30880, training loss = 2.097770, validation loss = 2.288326
2018-12-05 05:05:25,801 - INFO - epoch 1, step 30890, training loss = 2.108278, validation loss = 1.799919
2018-12-05 05:05:31,434 - INFO - epoch 1, step 30900, training loss = 2.119732, validation loss = 2.417465
2018-12-05 05:05:36,587 - INFO - epoch 1, step 30910, training loss = 2.346606, validation loss = 2.340623
2018-12-05 05:05:41,929 - INFO - epoch 1, step 30920, training loss = 2.489877, validation loss = 2.713637
2018-12-05 05:05:46,998 - INFO - epoch 1, step 30930, training loss = 2.189963, validation loss = 2.640600
2018-12-05 05:05:52,112 - INFO - epoch 1, step 30940, training loss = 2.025026, validation loss = 2.645442
2018-12-05 05:05:57,529 - INFO - epoch 1, step 30950, training loss = 2.252159, validation loss = 2.428665
2018-12-05 05:06:03,635 - INFO - epoch 1, step 30960, training loss = 2.106829, validation loss = 2.367093
2018-12-05 05:06:09,553 - INFO - epoch 1, step 30970, training loss = 2.538790, validation loss = 2.868348
2018-12-05 05:06:14,993 - INFO - epoch 1, step 30980, training loss = 1.888501, validation loss = 2.227144
2018-12-05 05:06:20,798 - INFO - epoch 1, step 30990, training loss = 2.113599, validation loss = 2.175332
2018-12-05 05:06:26,752 - INFO - epoch 1, step 31000, training loss = 1.845168, validation loss = 2.551265
2018-12-05 05:06:32,714 - INFO - epoch 1, step 31010, training loss = 2.258131, validation loss = 2.970347
2018-12-05 05:06:38,203 - INFO - epoch 1, step 31020, training loss = 1.979844, validation loss = 2.251771
2018-12-05 05:06:43,958 - INFO - epoch 1, step 31030, training loss = 2.272334, validation loss = 2.708999
2018-12-05 05:06:49,351 - INFO - epoch 1, step 31040, training loss = 2.603261, validation loss = 2.228478
2018-12-05 05:06:55,373 - INFO - epoch 1, step 31050, training loss = 1.754287, validation loss = 2.177946
2018-12-05 05:07:00,717 - INFO - epoch 1, step 31060, training loss = 2.772560, validation loss = 2.591347
2018-12-05 05:07:03,783 - INFO - epoch 1, step 31070, training loss = 2.211534, validation loss = 2.516270
2018-12-05 05:07:06,986 - INFO - epoch 1, step 31080, training loss = 2.259822, validation loss = 2.530733
2018-12-05 05:07:10,249 - INFO - epoch 1, step 31090, training loss = 2.571394, validation loss = 2.516636
2018-12-05 05:07:13,481 - INFO - epoch 1, step 31100, training loss = 2.309702, validation loss = 2.409338
2018-12-05 05:07:16,596 - INFO - epoch 1, step 31110, training loss = 2.372072, validation loss = 2.018261
2018-12-05 05:07:19,806 - INFO - epoch 1, step 31120, training loss = 3.023064, validation loss = 2.333990
2018-12-05 05:07:22,954 - INFO - epoch 1, step 31130, training loss = 2.219546, validation loss = 2.655374
2018-12-05 05:07:26,057 - INFO - epoch 1, step 31140, training loss = 2.248671, validation loss = 2.180532
2018-12-05 05:07:29,335 - INFO - epoch 1, step 31150, training loss = 2.288822, validation loss = 2.336928
2018-12-05 05:07:32,361 - INFO - epoch 1, step 31160, training loss = 2.171341, validation loss = 2.619065
2018-12-05 05:07:35,675 - INFO - epoch 1, step 31170, training loss = 2.558336, validation loss = 2.413224
2018-12-05 05:07:39,042 - INFO - epoch 1, step 31180, training loss = 2.455199, validation loss = 2.209985
2018-12-05 05:07:42,141 - INFO - epoch 1, step 31190, training loss = 2.433726, validation loss = 2.132022
2018-12-05 05:07:46,110 - INFO - epoch 1, step 31200, training loss = 2.459226, validation loss = 2.358377
2018-12-05 05:07:50,120 - INFO - epoch 1, step 31210, training loss = 2.139624, validation loss = 2.169193
2018-12-05 05:07:54,194 - INFO - epoch 1, step 31220, training loss = 2.266493, validation loss = 2.661511
2018-12-05 05:07:58,282 - INFO - epoch 1, step 31230, training loss = 2.517009, validation loss = 2.467747
2018-12-05 05:08:02,342 - INFO - epoch 1, step 31240, training loss = 2.345829, validation loss = 2.186040
2018-12-05 05:08:06,645 - INFO - epoch 1, step 31250, training loss = 2.401418, validation loss = 2.160131
2018-12-05 05:08:10,206 - INFO - epoch 1, step 31260, training loss = 1.945027, validation loss = 2.648116
2018-12-05 05:08:13,884 - INFO - epoch 1, step 31270, training loss = 1.937059, validation loss = 2.394048
2018-12-05 05:08:17,470 - INFO - epoch 1, step 31280, training loss = 2.057396, validation loss = 2.653707
2018-12-05 05:08:21,432 - INFO - epoch 1, step 31290, training loss = 1.970274, validation loss = 2.528149
2018-12-05 05:08:24,874 - INFO - epoch 1, step 31300, training loss = 2.549984, validation loss = 2.471612
2018-12-05 05:08:27,257 - INFO - epoch 1, step 31310, training loss = 1.811288, validation loss = 2.735512
2018-12-05 05:08:29,736 - INFO - epoch 1, step 31320, training loss = 2.080309, validation loss = 2.575597
2018-12-05 05:08:32,120 - INFO - epoch 1, step 31330, training loss = 2.865516, validation loss = 2.566081
2018-12-05 05:08:34,371 - INFO - epoch 1, step 31340, training loss = 1.855224, validation loss = 2.330154
2018-12-05 05:08:36,778 - INFO - epoch 1, step 31350, training loss = 1.758235, validation loss = 2.590723
2018-12-05 05:08:39,234 - INFO - epoch 1, step 31360, training loss = 2.440828, validation loss = 2.437948
2018-12-05 05:08:41,622 - INFO - epoch 1, step 31370, training loss = 2.405509, validation loss = 2.258962
2018-12-05 05:08:44,020 - INFO - epoch 1, step 31380, training loss = 2.514001, validation loss = 2.314752
2018-12-05 05:08:46,581 - INFO - epoch 1, step 31390, training loss = 2.613232, validation loss = 2.486991
2018-12-05 05:08:49,056 - INFO - epoch 1, step 31400, training loss = 2.159605, validation loss = 2.644842
2018-12-05 05:08:51,499 - INFO - epoch 1, step 31410, training loss = 2.961840, validation loss = 2.599270
2018-12-05 05:08:53,869 - INFO - epoch 1, step 31420, training loss = 1.927302, validation loss = 2.208801
2018-12-05 05:08:56,218 - INFO - epoch 1, step 31430, training loss = 2.359391, validation loss = 2.448847
2018-12-05 05:08:58,543 - INFO - epoch 1, step 31440, training loss = 2.667188, validation loss = 2.640960
2018-12-05 05:09:01,352 - INFO - epoch 1, step 31450, training loss = 2.524548, validation loss = 2.412432
2018-12-05 05:09:04,661 - INFO - epoch 1, step 31460, training loss = 2.382002, validation loss = 2.330173
2018-12-05 05:09:07,936 - INFO - epoch 1, step 31470, training loss = 2.434071, validation loss = 2.303363
2018-12-05 05:09:11,043 - INFO - epoch 1, step 31480, training loss = 2.731784, validation loss = 2.112423
2018-12-05 05:09:14,111 - INFO - epoch 1, step 31490, training loss = 2.080087, validation loss = 2.488033
2018-12-05 05:09:17,343 - INFO - epoch 1, step 31500, training loss = 2.251678, validation loss = 2.532446
2018-12-05 05:09:20,453 - INFO - epoch 1, step 31510, training loss = 2.422993, validation loss = 2.413763
2018-12-05 05:09:23,539 - INFO - epoch 1, step 31520, training loss = 2.433503, validation loss = 2.642253
2018-12-05 05:09:26,743 - INFO - epoch 1, step 31530, training loss = 1.998006, validation loss = 2.128653
2018-12-05 05:09:30,124 - INFO - epoch 1, step 31540, training loss = 2.576221, validation loss = 2.043569
2018-12-05 05:09:33,377 - INFO - epoch 1, step 31550, training loss = 2.485189, validation loss = 2.286026
2018-12-05 05:09:36,695 - INFO - epoch 1, step 31560, training loss = 2.452215, validation loss = 2.275995
2018-12-05 05:09:40,420 - INFO - epoch 1, step 31570, training loss = 2.669684, validation loss = 2.700272
2018-12-05 05:09:45,731 - INFO - epoch 1, step 31580, training loss = 2.674056, validation loss = 2.198848
2018-12-05 05:09:50,859 - INFO - epoch 1, step 31590, training loss = 2.445800, validation loss = 2.659106
2018-12-05 05:09:55,910 - INFO - epoch 1, step 31600, training loss = 2.533354, validation loss = 1.959139
2018-12-05 05:10:00,915 - INFO - epoch 1, step 31610, training loss = 2.417744, validation loss = 2.288617
2018-12-05 05:10:06,026 - INFO - epoch 1, step 31620, training loss = 2.059288, validation loss = 2.229951
2018-12-05 05:10:11,057 - INFO - epoch 1, step 31630, training loss = 2.595890, validation loss = 2.666566
2018-12-05 05:10:16,152 - INFO - epoch 1, step 31640, training loss = 2.266114, validation loss = 2.788078
2018-12-05 05:10:21,148 - INFO - epoch 1, step 31650, training loss = 1.956846, validation loss = 2.219303
2018-12-05 05:10:26,155 - INFO - epoch 1, step 31660, training loss = 2.192217, validation loss = 2.421949
2018-12-05 05:10:31,708 - INFO - epoch 1, step 31670, training loss = 2.485755, validation loss = 2.390110
2018-12-05 05:10:36,837 - INFO - epoch 1, step 31680, training loss = 2.320087, validation loss = 2.900439
2018-12-05 05:10:41,963 - INFO - epoch 1, step 31690, training loss = 2.071255, validation loss = 2.856367
2018-12-05 05:10:47,167 - INFO - epoch 1, step 31700, training loss = 2.555585, validation loss = 2.025396
2018-12-05 05:10:52,291 - INFO - epoch 1, step 31710, training loss = 2.353895, validation loss = 2.078888
2018-12-05 05:10:57,512 - INFO - epoch 1, step 31720, training loss = 2.368841, validation loss = 2.346875
2018-12-05 05:11:02,485 - INFO - epoch 1, step 31730, training loss = 2.116663, validation loss = 2.818162
2018-12-05 05:11:07,495 - INFO - epoch 1, step 31740, training loss = 2.338508, validation loss = 2.319783
2018-12-05 05:11:12,572 - INFO - epoch 1, step 31750, training loss = 2.921537, validation loss = 2.198169
2018-12-05 05:11:17,909 - INFO - epoch 1, step 31760, training loss = 2.312271, validation loss = 2.279055
2018-12-05 05:11:23,017 - INFO - epoch 1, step 31770, training loss = 2.167927, validation loss = 2.501465
2018-12-05 05:11:28,551 - INFO - epoch 1, step 31780, training loss = 2.521511, validation loss = 2.529309
2018-12-05 05:11:32,425 - INFO - epoch 1, step 31790, training loss = 3.014058, validation loss = 2.627705
2018-12-05 05:11:34,742 - INFO - epoch 1, step 31800, training loss = 2.380092, validation loss = 2.596491
2018-12-05 05:11:37,097 - INFO - epoch 1, step 31810, training loss = 2.440351, validation loss = 2.948161
2018-12-05 05:11:39,398 - INFO - epoch 1, step 31820, training loss = 2.213530, validation loss = 2.071533
2018-12-05 05:11:41,739 - INFO - epoch 1, step 31830, training loss = 1.903738, validation loss = 2.605346
2018-12-05 05:11:44,036 - INFO - epoch 1, step 31840, training loss = 2.391860, validation loss = 2.564044
2018-12-05 05:11:46,393 - INFO - epoch 1, step 31850, training loss = 2.086572, validation loss = 2.701474
2018-12-05 05:11:48,680 - INFO - epoch 1, step 31860, training loss = 2.466585, validation loss = 2.708933
2018-12-05 05:11:51,017 - INFO - epoch 1, step 31870, training loss = 1.975360, validation loss = 2.582054
2018-12-05 05:11:53,277 - INFO - epoch 1, step 31880, training loss = 2.366387, validation loss = 2.457644
2018-12-05 05:11:55,576 - INFO - epoch 1, step 31890, training loss = 2.178697, validation loss = 2.761318
2018-12-05 05:11:58,015 - INFO - epoch 1, step 31900, training loss = 2.575755, validation loss = 2.687751
2018-12-05 05:12:00,462 - INFO - epoch 1, step 31910, training loss = 2.310616, validation loss = 2.512527
2018-12-05 05:12:02,817 - INFO - epoch 1, step 31920, training loss = 2.214139, validation loss = 2.651424
2018-12-05 05:12:05,154 - INFO - epoch 1, step 31930, training loss = 2.386531, validation loss = 2.356390
2018-12-05 05:12:10,668 - INFO - epoch 1, step 31940, training loss = 2.379906, validation loss = 2.638167
2018-12-05 05:12:16,319 - INFO - epoch 1, step 31950, training loss = 2.197888, validation loss = 2.729003
2018-12-05 05:12:22,173 - INFO - epoch 1, step 31960, training loss = 1.758191, validation loss = 1.801692
2018-12-05 05:12:27,870 - INFO - epoch 1, step 31970, training loss = 2.177575, validation loss = 2.175109
2018-12-05 05:12:33,191 - INFO - epoch 1, step 31980, training loss = 1.891172, validation loss = 2.584886
2018-12-05 05:12:39,270 - INFO - epoch 1, step 31990, training loss = 2.205892, validation loss = 2.525230
2018-12-05 05:12:45,652 - INFO - epoch 1, step 32000, training loss = 2.144567, validation loss = 2.811596
2018-12-05 05:12:51,655 - INFO - epoch 1, step 32010, training loss = 1.485216, validation loss = 2.112034
2018-12-05 05:12:57,540 - INFO - epoch 1, step 32020, training loss = 1.771493, validation loss = 2.009202
2018-12-05 05:13:03,080 - INFO - epoch 1, step 32030, training loss = 2.037920, validation loss = 2.313402
2018-12-05 05:13:08,366 - INFO - epoch 1, step 32040, training loss = 2.086634, validation loss = 2.116188
2018-12-05 05:13:14,193 - INFO - epoch 1, step 32050, training loss = 2.594590, validation loss = 2.620214
2018-12-05 05:13:19,921 - INFO - epoch 1, step 32060, training loss = 2.024707, validation loss = 2.745714
2018-12-05 05:13:26,180 - INFO - epoch 1, step 32070, training loss = 1.841220, validation loss = 2.298282
2018-12-05 05:13:32,106 - INFO - epoch 1, step 32080, training loss = 1.858770, validation loss = 2.261201
2018-12-05 05:13:37,537 - INFO - epoch 1, step 32090, training loss = 1.967662, validation loss = 2.326320
2018-12-05 05:13:43,382 - INFO - epoch 1, step 32100, training loss = 1.555887, validation loss = 2.162089
2018-12-05 05:13:48,990 - INFO - epoch 1, step 32110, training loss = 2.237701, validation loss = 2.497292
2018-12-05 05:13:54,194 - INFO - epoch 1, step 32120, training loss = 3.143214, validation loss = 2.119506
2018-12-05 05:13:56,712 - INFO - epoch 1, step 32130, training loss = 2.378689, validation loss = 2.523408
2018-12-05 05:13:59,111 - INFO - epoch 1, step 32140, training loss = 2.221623, validation loss = 2.202483
2018-12-05 05:14:01,542 - INFO - epoch 1, step 32150, training loss = 1.959297, validation loss = 2.305340
2018-12-05 05:14:03,914 - INFO - epoch 1, step 32160, training loss = 2.247030, validation loss = 2.260335
2018-12-05 05:14:06,322 - INFO - epoch 1, step 32170, training loss = 1.926493, validation loss = 2.755162
2018-12-05 05:14:08,624 - INFO - epoch 1, step 32180, training loss = 2.017146, validation loss = 2.484451
2018-12-05 05:14:11,007 - INFO - epoch 1, step 32190, training loss = 1.830165, validation loss = 2.236468
2018-12-05 05:14:13,390 - INFO - epoch 1, step 32200, training loss = 2.227277, validation loss = 2.192925
2018-12-05 05:14:15,871 - INFO - epoch 1, step 32210, training loss = 1.698922, validation loss = 2.456109
2018-12-05 05:14:18,303 - INFO - epoch 1, step 32220, training loss = 1.876983, validation loss = 2.962947
2018-12-05 05:14:20,674 - INFO - epoch 1, step 32230, training loss = 2.713748, validation loss = 2.661904
2018-12-05 05:14:23,102 - INFO - epoch 1, step 32240, training loss = 1.375514, validation loss = 2.475729
2018-12-05 05:14:25,418 - INFO - epoch 1, step 32250, training loss = 2.359708, validation loss = 2.726779
2018-12-05 05:14:27,818 - INFO - epoch 1, step 32260, training loss = 2.056003, validation loss = 2.555778
2018-12-05 05:14:30,105 - INFO - epoch 1, step 32270, training loss = 2.552585, validation loss = 3.125171
2018-12-05 05:14:35,031 - INFO - epoch 1, step 32280, training loss = 2.081420, validation loss = 2.174363
2018-12-05 05:14:40,481 - INFO - epoch 1, step 32290, training loss = 2.222518, validation loss = 2.198138
2018-12-05 05:14:46,219 - INFO - epoch 1, step 32300, training loss = 2.662782, validation loss = 2.222638
2018-12-05 05:14:51,420 - INFO - epoch 1, step 32310, training loss = 2.277047, validation loss = 2.485609
2018-12-05 05:14:56,478 - INFO - epoch 1, step 32320, training loss = 2.310587, validation loss = 2.540306
2018-12-05 05:15:01,603 - INFO - epoch 1, step 32330, training loss = 2.304264, validation loss = 2.459705
2018-12-05 05:15:06,588 - INFO - epoch 1, step 32340, training loss = 2.197932, validation loss = 2.275631
2018-12-05 05:15:11,690 - INFO - epoch 1, step 32350, training loss = 2.412984, validation loss = 1.885521
2018-12-05 05:15:16,820 - INFO - epoch 1, step 32360, training loss = 2.432128, validation loss = 1.994082
2018-12-05 05:15:22,491 - INFO - epoch 1, step 32370, training loss = 2.574877, validation loss = 2.100275
2018-12-05 05:15:27,507 - INFO - epoch 1, step 32380, training loss = 2.595249, validation loss = 2.266763
2018-12-05 05:15:32,227 - INFO - epoch 1, step 32390, training loss = 2.347015, validation loss = 2.276624
2018-12-05 05:15:37,340 - INFO - epoch 1, step 32400, training loss = 2.553924, validation loss = 2.075018
2018-12-05 05:15:42,346 - INFO - epoch 1, step 32410, training loss = 2.121594, validation loss = 1.974930
2018-12-05 05:15:47,282 - INFO - epoch 1, step 32420, training loss = 2.476180, validation loss = 2.287669
2018-12-05 05:15:52,457 - INFO - epoch 1, step 32430, training loss = 2.401734, validation loss = 2.484228
2018-12-05 05:15:57,598 - INFO - epoch 1, step 32440, training loss = 2.104075, validation loss = 2.390305
2018-12-05 05:16:02,509 - INFO - epoch 1, step 32450, training loss = 2.052643, validation loss = 2.264523
2018-12-05 05:16:07,817 - INFO - epoch 1, step 32460, training loss = 2.503011, validation loss = 2.168921
2018-12-05 05:16:12,813 - INFO - epoch 1, step 32470, training loss = 2.400745, validation loss = 2.472120
2018-12-05 05:16:17,998 - INFO - epoch 1, step 32480, training loss = 1.679672, validation loss = 2.535940
2018-12-05 05:16:22,955 - INFO - epoch 1, step 32490, training loss = 2.249347, validation loss = 2.511130
2018-12-05 05:16:28,011 - INFO - epoch 1, step 32500, training loss = 2.624657, validation loss = 2.051603
2018-12-05 05:16:32,986 - INFO - epoch 1, step 32510, training loss = 2.288690, validation loss = 2.277291
2018-12-05 05:16:37,796 - INFO - epoch 1, step 32520, training loss = 2.407531, validation loss = 2.424172
2018-12-05 05:16:41,913 - INFO - epoch 1, step 32530, training loss = 2.268572, validation loss = 2.278890
2018-12-05 05:16:46,185 - INFO - epoch 1, step 32540, training loss = 2.654828, validation loss = 1.954517
2018-12-05 05:16:50,440 - INFO - epoch 1, step 32550, training loss = 2.260897, validation loss = 1.985733
2018-12-05 05:16:54,549 - INFO - epoch 1, step 32560, training loss = 2.186130, validation loss = 2.530696
2018-12-05 05:16:58,534 - INFO - epoch 1, step 32570, training loss = 2.083631, validation loss = 2.854475
2018-12-05 05:17:02,882 - INFO - epoch 1, step 32580, training loss = 2.119264, validation loss = 2.516308
2018-12-05 05:17:07,192 - INFO - epoch 1, step 32590, training loss = 1.899060, validation loss = 2.293154
2018-12-05 05:17:10,308 - INFO - epoch 1, step 32600, training loss = 2.033634, validation loss = 2.682962
2018-12-05 05:17:13,607 - INFO - epoch 1, step 32610, training loss = 2.547093, validation loss = 2.590811
2018-12-05 05:17:17,112 - INFO - epoch 1, step 32620, training loss = 1.946230, validation loss = 2.406798
2018-12-05 05:17:20,329 - INFO - epoch 1, step 32630, training loss = 2.119527, validation loss = 2.251205
2018-12-05 05:17:23,578 - INFO - epoch 1, step 32640, training loss = 2.308292, validation loss = 2.511756
2018-12-05 05:17:26,811 - INFO - epoch 1, step 32650, training loss = 1.963875, validation loss = 2.612616
2018-12-05 05:17:30,076 - INFO - epoch 1, step 32660, training loss = 2.078737, validation loss = 2.161873
2018-12-05 05:17:35,142 - INFO - epoch 1, step 32670, training loss = 2.304551, validation loss = 1.908438
2018-12-05 05:17:40,832 - INFO - epoch 1, step 32680, training loss = 1.996925, validation loss = 2.153028
2018-12-05 05:17:46,411 - INFO - epoch 1, step 32690, training loss = 2.079191, validation loss = 2.418283
2018-12-05 05:17:52,293 - INFO - epoch 1, step 32700, training loss = 2.185786, validation loss = 2.842994
2018-12-05 05:17:57,496 - INFO - epoch 1, step 32710, training loss = 2.023320, validation loss = 2.123195
2018-12-05 05:18:02,684 - INFO - epoch 1, step 32720, training loss = 2.109004, validation loss = 2.138413
2018-12-05 05:18:07,920 - INFO - epoch 1, step 32730, training loss = 2.261485, validation loss = 2.524118
2018-12-05 05:18:12,887 - INFO - epoch 1, step 32740, training loss = 2.305772, validation loss = 2.640959
2018-12-05 05:18:18,071 - INFO - epoch 1, step 32750, training loss = 2.056237, validation loss = 2.645008
2018-12-05 05:18:22,990 - INFO - epoch 1, step 32760, training loss = 2.114168, validation loss = 2.389522
2018-12-05 05:18:28,023 - INFO - epoch 1, step 32770, training loss = 2.103085, validation loss = 1.911247
2018-12-05 05:18:32,894 - INFO - epoch 1, step 32780, training loss = 2.562895, validation loss = 2.318656
2018-12-05 05:18:37,920 - INFO - epoch 1, step 32790, training loss = 2.064305, validation loss = 2.664447
2018-12-05 05:18:42,933 - INFO - epoch 1, step 32800, training loss = 2.276139, validation loss = 2.383215
2018-12-05 05:18:48,163 - INFO - epoch 1, step 32810, training loss = 2.145545, validation loss = 2.042173
2018-12-05 05:18:53,273 - INFO - epoch 1, step 32820, training loss = 2.769323, validation loss = 1.988257
2018-12-05 05:18:58,336 - INFO - epoch 1, step 32830, training loss = 2.220327, validation loss = 2.638771
2018-12-05 05:19:03,568 - INFO - epoch 1, step 32840, training loss = 2.626368, validation loss = 2.481550
2018-12-05 05:19:08,833 - INFO - epoch 1, step 32850, training loss = 1.957393, validation loss = 2.676890
2018-12-05 05:19:13,708 - INFO - epoch 1, step 32860, training loss = 2.492703, validation loss = 2.547185
2018-12-05 05:19:19,001 - INFO - epoch 1, step 32870, training loss = 2.416660, validation loss = 2.549745
2018-12-05 05:19:24,227 - INFO - epoch 1, step 32880, training loss = 2.114476, validation loss = 2.172843
2018-12-05 05:19:29,752 - INFO - epoch 1, step 32890, training loss = 1.994834, validation loss = 2.431375
2018-12-05 05:19:35,118 - INFO - epoch 1, step 32900, training loss = 2.147759, validation loss = 2.510868
2018-12-05 05:19:40,738 - INFO - epoch 1, step 32910, training loss = 1.772511, validation loss = 2.405759
2018-12-05 05:19:46,327 - INFO - epoch 1, step 32920, training loss = 2.160506, validation loss = 2.177437
2018-12-05 05:19:51,928 - INFO - epoch 1, step 32930, training loss = 1.987219, validation loss = 2.234245
2018-12-05 05:19:57,241 - INFO - epoch 1, step 32940, training loss = 2.196310, validation loss = 2.398473
2018-12-05 05:20:03,311 - INFO - epoch 1, step 32950, training loss = 1.636998, validation loss = 2.534593
2018-12-05 05:20:09,040 - INFO - epoch 1, step 32960, training loss = 1.694395, validation loss = 2.471886
2018-12-05 05:20:14,785 - INFO - epoch 1, step 32970, training loss = 1.695748, validation loss = 2.109612
2018-12-05 05:20:20,943 - INFO - epoch 1, step 32980, training loss = 2.431326, validation loss = 2.157067
2018-12-05 05:20:26,282 - INFO - epoch 1, step 32990, training loss = 2.172516, validation loss = 2.328707
2018-12-05 05:20:31,116 - INFO - epoch 1, step 33000, training loss = 2.031697, validation loss = 1.918674
2018-12-05 05:20:35,181 - INFO - epoch 1, step 33010, training loss = 2.327462, validation loss = 2.473613
2018-12-05 05:20:39,834 - INFO - epoch 1, step 33020, training loss = 2.053805, validation loss = 2.209601
2018-12-05 05:20:44,020 - INFO - epoch 1, step 33030, training loss = 2.268764, validation loss = 2.126492
2018-12-05 05:20:48,142 - INFO - epoch 1, step 33040, training loss = 1.777108, validation loss = 2.568966
2018-12-05 05:20:52,506 - INFO - epoch 1, step 33050, training loss = 1.912268, validation loss = 2.293679
2018-12-05 05:20:57,093 - INFO - epoch 1, step 33060, training loss = 2.058422, validation loss = 2.202075
2018-12-05 05:21:00,622 - INFO - epoch 1, step 33070, training loss = 2.183644, validation loss = 2.253851
2018-12-05 05:21:04,264 - INFO - epoch 1, step 33080, training loss = 3.098891, validation loss = 1.720446
2018-12-05 05:21:07,736 - INFO - epoch 1, step 33090, training loss = 2.109018, validation loss = 2.058342
2018-12-05 05:21:11,396 - INFO - epoch 1, step 33100, training loss = 2.424373, validation loss = 2.763352
2018-12-05 05:21:14,985 - INFO - epoch 1, step 33110, training loss = 2.503826, validation loss = 2.042392
2018-12-05 05:21:18,672 - INFO - epoch 1, step 33120, training loss = 2.391112, validation loss = 1.875043
2018-12-05 05:21:22,006 - INFO - epoch 1, step 33130, training loss = 2.558673, validation loss = 2.061811
2018-12-05 05:21:25,840 - INFO - epoch 1, step 33140, training loss = 2.253577, validation loss = 2.297939
2018-12-05 05:21:29,581 - INFO - epoch 1, step 33150, training loss = 2.839910, validation loss = 2.264286
2018-12-05 05:21:32,939 - INFO - epoch 1, step 33160, training loss = 2.416594, validation loss = 2.187187
2018-12-05 05:21:36,604 - INFO - epoch 1, step 33170, training loss = 2.749980, validation loss = 1.952036
2018-12-05 05:21:42,125 - INFO - epoch 1, step 33180, training loss = 1.834500, validation loss = 2.655169
2018-12-05 05:21:47,599 - INFO - epoch 1, step 33190, training loss = 2.107520, validation loss = 2.303143
2018-12-05 05:21:53,284 - INFO - epoch 1, step 33200, training loss = 1.832689, validation loss = 2.514418
2018-12-05 05:21:59,448 - INFO - epoch 1, step 33210, training loss = 2.100049, validation loss = 2.123298
2018-12-05 05:22:04,814 - INFO - epoch 1, step 33220, training loss = 2.284956, validation loss = 2.122598
2018-12-05 05:22:09,955 - INFO - epoch 1, step 33230, training loss = 2.408991, validation loss = 1.888872
2018-12-05 05:22:15,382 - INFO - epoch 1, step 33240, training loss = 1.716891, validation loss = 1.981821
2018-12-05 05:22:20,854 - INFO - epoch 1, step 33250, training loss = 1.787276, validation loss = 2.256387
2018-12-05 05:22:26,278 - INFO - epoch 1, step 33260, training loss = 2.151772, validation loss = 2.042327
2018-12-05 05:22:31,347 - INFO - epoch 1, step 33270, training loss = 2.015364, validation loss = 2.105220
2018-12-05 05:22:37,151 - INFO - epoch 1, step 33280, training loss = 2.010306, validation loss = 2.059609
2018-12-05 05:22:42,688 - INFO - epoch 1, step 33290, training loss = 2.087507, validation loss = 1.937626
2018-12-05 05:22:47,788 - INFO - epoch 1, step 33300, training loss = 2.135886, validation loss = 2.339146
2018-12-05 05:22:54,156 - INFO - epoch 1, step 33310, training loss = 2.371927, validation loss = 2.316710
2018-12-05 05:22:59,568 - INFO - epoch 1, step 33320, training loss = 2.084292, validation loss = 2.107403
2018-12-05 05:23:05,065 - INFO - epoch 1, step 33330, training loss = 1.848666, validation loss = 2.328132
2018-12-05 05:23:10,787 - INFO - epoch 1, step 33340, training loss = 1.969981, validation loss = 2.378575
2018-12-05 05:23:16,560 - INFO - epoch 1, step 33350, training loss = 1.642083, validation loss = 2.170531
2018-12-05 05:23:21,974 - INFO - epoch 1, step 33360, training loss = 2.806999, validation loss = 1.826130
2018-12-05 05:23:26,820 - INFO - epoch 1, step 33370, training loss = 2.771626, validation loss = 2.036805
2018-12-05 05:23:31,719 - INFO - epoch 1, step 33380, training loss = 2.731721, validation loss = 2.369030
2018-12-05 05:23:36,565 - INFO - epoch 1, step 33390, training loss = 2.265993, validation loss = 2.206025
2018-12-05 05:23:41,429 - INFO - epoch 1, step 33400, training loss = 1.794007, validation loss = 1.852275
2018-12-05 05:23:46,410 - INFO - epoch 1, step 33410, training loss = 2.095438, validation loss = 2.458438
2018-12-05 05:23:51,303 - INFO - epoch 1, step 33420, training loss = 2.405531, validation loss = 2.632536
2018-12-05 05:23:55,915 - INFO - epoch 1, step 33430, training loss = 2.416827, validation loss = 2.308520
2018-12-05 05:24:00,468 - INFO - epoch 1, step 33440, training loss = 2.182991, validation loss = 1.881894
2018-12-05 05:24:05,201 - INFO - epoch 1, step 33450, training loss = 2.519304, validation loss = 2.293182
2018-12-05 05:24:09,741 - INFO - epoch 1, step 33460, training loss = 2.092914, validation loss = 2.372573
2018-12-05 05:24:14,442 - INFO - epoch 1, step 33470, training loss = 2.366174, validation loss = 2.380483
2018-12-05 05:24:19,202 - INFO - epoch 1, step 33480, training loss = 2.031885, validation loss = 2.215542
2018-12-05 05:24:24,544 - INFO - epoch 1, step 33490, training loss = 2.198430, validation loss = 2.256085
2018-12-05 05:24:29,603 - INFO - epoch 1, step 33500, training loss = 2.265950, validation loss = 2.150117
2018-12-05 05:24:34,528 - INFO - epoch 1, step 33510, training loss = 1.911375, validation loss = 2.757244
2018-12-05 05:24:39,486 - INFO - epoch 1, step 33520, training loss = 2.237962, validation loss = 2.437676
2018-12-05 05:24:44,962 - INFO - epoch 1, step 33530, training loss = 1.928359, validation loss = 2.048493
2018-12-05 05:24:50,382 - INFO - epoch 1, step 33540, training loss = 2.104589, validation loss = 2.507786
2018-12-05 05:24:55,354 - INFO - epoch 1, step 33550, training loss = 2.490293, validation loss = 2.686167
2018-12-05 05:25:00,362 - INFO - epoch 1, step 33560, training loss = 2.197474, validation loss = 2.711090
2018-12-05 05:25:05,410 - INFO - epoch 1, step 33570, training loss = 2.108494, validation loss = 2.146271
2018-12-05 05:25:10,408 - INFO - epoch 1, step 33580, training loss = 2.291720, validation loss = 2.526403
2018-12-05 05:25:16,080 - INFO - epoch 1, step 33590, training loss = 1.547589, validation loss = 2.245397
2018-12-05 05:25:21,418 - INFO - epoch 1, step 33600, training loss = 1.860535, validation loss = 2.208425
2018-12-05 05:25:27,748 - INFO - epoch 1, step 33610, training loss = 2.315439, validation loss = 2.274254
2018-12-05 05:25:33,107 - INFO - epoch 1, step 33620, training loss = 1.629313, validation loss = 2.633821
2018-12-05 05:25:38,076 - INFO - epoch 1, step 33630, training loss = 2.423130, validation loss = 2.214113
2018-12-05 05:25:43,552 - INFO - epoch 1, step 33640, training loss = 2.179316, validation loss = 2.209436
2018-12-05 05:25:48,545 - INFO - epoch 1, step 33650, training loss = 2.425304, validation loss = 2.345300
2018-12-05 05:25:53,771 - INFO - epoch 1, step 33660, training loss = 2.080179, validation loss = 2.443133
2018-12-05 05:25:59,194 - INFO - epoch 1, step 33670, training loss = 2.186806, validation loss = 2.165475
2018-12-05 05:26:04,279 - INFO - epoch 1, step 33680, training loss = 2.248400, validation loss = 2.179315
2018-12-05 05:26:09,288 - INFO - epoch 1, step 33690, training loss = 1.973396, validation loss = 2.265593
2018-12-05 05:26:14,346 - INFO - epoch 1, step 33700, training loss = 2.061358, validation loss = 2.626343
2018-12-05 05:26:19,317 - INFO - epoch 1, step 33710, training loss = 1.982545, validation loss = 2.547371
2018-12-05 05:26:24,540 - INFO - epoch 1, step 33720, training loss = 1.914928, validation loss = 2.232762
2018-12-05 05:26:29,597 - INFO - epoch 1, step 33730, training loss = 2.165667, validation loss = 2.023113
2018-12-05 05:26:34,588 - INFO - epoch 1, step 33740, training loss = 2.344160, validation loss = 2.438417
2018-12-05 05:26:39,840 - INFO - epoch 1, step 33750, training loss = 2.602690, validation loss = 2.525585
2018-12-05 05:26:44,776 - INFO - epoch 1, step 33760, training loss = 1.807862, validation loss = 2.296768
2018-12-05 05:26:49,931 - INFO - epoch 1, step 33770, training loss = 2.382250, validation loss = 2.137216
2018-12-05 05:26:55,292 - INFO - epoch 1, step 33780, training loss = 2.713207, validation loss = 2.240516
2018-12-05 05:27:00,452 - INFO - epoch 1, step 33790, training loss = 2.080165, validation loss = 2.771406
2018-12-05 05:27:05,545 - INFO - epoch 1, step 33800, training loss = 2.178144, validation loss = 2.094032
2018-12-05 05:27:10,814 - INFO - epoch 1, step 33810, training loss = 1.987080, validation loss = 2.187518
2018-12-05 05:27:16,079 - INFO - epoch 1, step 33820, training loss = 2.319882, validation loss = 2.604339
2018-12-05 05:27:21,445 - INFO - epoch 1, step 33830, training loss = 2.269274, validation loss = 2.429454
2018-12-05 05:27:26,338 - INFO - epoch 1, step 33840, training loss = 2.115993, validation loss = 1.930892
2018-12-05 05:27:31,488 - INFO - epoch 1, step 33850, training loss = 2.386942, validation loss = 2.598796
2018-12-05 05:27:36,674 - INFO - epoch 1, step 33860, training loss = 2.331865, validation loss = 2.557757
2018-12-05 05:27:41,874 - INFO - epoch 1, step 33870, training loss = 2.001452, validation loss = 2.368644
2018-12-05 05:27:46,957 - INFO - epoch 1, step 33880, training loss = 2.300222, validation loss = 2.700904
2018-12-05 05:27:51,927 - INFO - epoch 1, step 33890, training loss = 2.585840, validation loss = 2.515644
2018-12-05 05:27:56,993 - INFO - epoch 1, step 33900, training loss = 2.502061, validation loss = 2.433969
2018-12-05 05:28:02,176 - INFO - epoch 1, step 33910, training loss = 2.463873, validation loss = 2.793241
2018-12-05 05:28:07,305 - INFO - epoch 1, step 33920, training loss = 2.146818, validation loss = 2.050247
2018-12-05 05:28:12,664 - INFO - epoch 1, step 33930, training loss = 2.332898, validation loss = 2.940845
2018-12-05 05:28:17,918 - INFO - epoch 1, step 33940, training loss = 2.055141, validation loss = 2.710713
2018-12-05 05:28:23,207 - INFO - epoch 1, step 33950, training loss = 2.317965, validation loss = 2.671541
2018-12-05 05:28:28,145 - INFO - epoch 1, step 33960, training loss = 2.397909, validation loss = 2.469012
2018-12-05 05:28:33,263 - INFO - epoch 1, step 33970, training loss = 2.237591, validation loss = 2.219358
2018-12-05 05:28:39,249 - INFO - epoch 1, step 33980, training loss = 2.243994, validation loss = 2.281031
2018-12-05 05:28:44,223 - INFO - epoch 1, step 33990, training loss = 2.484137, validation loss = 2.572241
2018-12-05 05:28:49,277 - INFO - epoch 1, step 34000, training loss = 2.420119, validation loss = 2.440291
2018-12-05 05:28:54,332 - INFO - epoch 1, step 34010, training loss = 2.196520, validation loss = 2.454885
2018-12-05 05:28:59,335 - INFO - epoch 1, step 34020, training loss = 2.293281, validation loss = 2.870106
2018-12-05 05:29:04,279 - INFO - epoch 1, step 34030, training loss = 2.418110, validation loss = 2.003392
2018-12-05 05:29:09,294 - INFO - epoch 1, step 34040, training loss = 2.392291, validation loss = 2.381404
2018-12-05 05:29:14,563 - INFO - epoch 1, step 34050, training loss = 1.808077, validation loss = 2.807955
2018-12-05 05:29:19,791 - INFO - epoch 1, step 34060, training loss = 2.275448, validation loss = 2.552145
2018-12-05 05:29:24,661 - INFO - epoch 1, step 34070, training loss = 2.248717, validation loss = 2.666656
2018-12-05 05:29:29,541 - INFO - epoch 1, step 34080, training loss = 2.435165, validation loss = 2.389129
2018-12-05 05:29:33,423 - INFO - epoch 1, step 34090, training loss = 2.465764, validation loss = 2.099413
2018-12-05 05:29:35,988 - INFO - epoch 1, step 34100, training loss = 1.866661, validation loss = 2.444522
2018-12-05 05:29:38,345 - INFO - epoch 1, step 34110, training loss = 2.852990, validation loss = 2.438897
2018-12-05 05:29:40,860 - INFO - epoch 1, step 34120, training loss = 2.049489, validation loss = 2.543461
2018-12-05 05:29:43,218 - INFO - epoch 1, step 34130, training loss = 2.105866, validation loss = 2.621753
2018-12-05 05:29:45,584 - INFO - epoch 1, step 34140, training loss = 2.078202, validation loss = 2.412150
2018-12-05 05:29:47,812 - INFO - epoch 1, step 34150, training loss = 2.597323, validation loss = 2.678846
2018-12-05 05:29:50,199 - INFO - epoch 1, step 34160, training loss = 1.713522, validation loss = 2.702493
2018-12-05 05:29:52,729 - INFO - epoch 1, step 34170, training loss = 1.938593, validation loss = 2.469665
2018-12-05 05:29:55,246 - INFO - epoch 1, step 34180, training loss = 2.366070, validation loss = 2.740781
2018-12-05 05:29:57,594 - INFO - epoch 1, step 34190, training loss = 2.421514, validation loss = 3.104458
2018-12-05 05:30:00,051 - INFO - epoch 1, step 34200, training loss = 1.604382, validation loss = 2.814223
2018-12-05 05:30:02,542 - INFO - epoch 1, step 34210, training loss = 1.779549, validation loss = 2.277370
2018-12-05 05:30:04,916 - INFO - epoch 1, step 34220, training loss = 2.410050, validation loss = 2.971585
2018-12-05 05:30:09,625 - INFO - epoch 1, step 34230, training loss = 2.394461, validation loss = 2.474822
2018-12-05 05:30:14,787 - INFO - epoch 1, step 34240, training loss = 1.987992, validation loss = 2.506857
2018-12-05 05:30:20,154 - INFO - epoch 1, step 34250, training loss = 2.205428, validation loss = 2.634533
2018-12-05 05:30:25,076 - INFO - epoch 1, step 34260, training loss = 2.149338, validation loss = 2.886008
2018-12-05 05:30:30,153 - INFO - epoch 1, step 34270, training loss = 2.195938, validation loss = 1.838607
2018-12-05 05:30:35,615 - INFO - epoch 1, step 34280, training loss = 2.547503, validation loss = 2.749462
2018-12-05 05:30:40,871 - INFO - epoch 1, step 34290, training loss = 2.279005, validation loss = 2.332088
2018-12-05 05:30:46,103 - INFO - epoch 1, step 34300, training loss = 2.769511, validation loss = 2.572366
2018-12-05 05:30:51,121 - INFO - epoch 1, step 34310, training loss = 2.310970, validation loss = 2.377364
2018-12-05 05:30:56,121 - INFO - epoch 1, step 34320, training loss = 1.997882, validation loss = 2.483960
2018-12-05 05:31:01,608 - INFO - epoch 1, step 34330, training loss = 2.029863, validation loss = 2.787518
2018-12-05 05:31:06,795 - INFO - epoch 1, step 34340, training loss = 2.195982, validation loss = 2.180433
2018-12-05 05:31:12,344 - INFO - epoch 1, step 34350, training loss = 2.198615, validation loss = 2.333486
2018-12-05 05:31:17,577 - INFO - epoch 1, step 34360, training loss = 1.959108, validation loss = 2.502870
2018-12-05 05:31:22,571 - INFO - epoch 1, step 34370, training loss = 2.149672, validation loss = 2.516285
2018-12-05 05:31:27,698 - INFO - epoch 1, step 34380, training loss = 2.277733, validation loss = 2.808743
2018-12-05 05:31:33,074 - INFO - epoch 1, step 34390, training loss = 2.525163, validation loss = 2.580800
2018-12-05 05:31:38,204 - INFO - epoch 1, step 34400, training loss = 2.257319, validation loss = 2.364650
2018-12-05 05:31:43,239 - INFO - epoch 1, step 34410, training loss = 2.352907, validation loss = 2.672783
2018-12-05 05:31:48,453 - INFO - epoch 1, step 34420, training loss = 2.441536, validation loss = 2.225567
2018-12-05 05:31:53,574 - INFO - epoch 1, step 34430, training loss = 2.257571, validation loss = 2.762217
2018-12-05 05:31:58,615 - INFO - epoch 1, step 34440, training loss = 2.144413, validation loss = 2.264713
2018-12-05 05:32:03,733 - INFO - epoch 1, step 34450, training loss = 2.362857, validation loss = 2.133822
2018-12-05 05:32:08,924 - INFO - epoch 1, step 34460, training loss = 2.189187, validation loss = 2.617814
2018-12-05 05:32:13,026 - INFO - epoch 1, step 34470, training loss = 2.012657, validation loss = 2.637969
2018-12-05 05:32:16,108 - INFO - epoch 1, step 34480, training loss = 2.976361, validation loss = 2.413770
2018-12-05 05:32:19,445 - INFO - epoch 1, step 34490, training loss = 1.801367, validation loss = 2.658440
2018-12-05 05:32:22,904 - INFO - epoch 1, step 34500, training loss = 2.442820, validation loss = 2.627179
2018-12-05 05:32:25,935 - INFO - epoch 1, step 34510, training loss = 2.457658, validation loss = 2.498260
2018-12-05 05:32:29,040 - INFO - epoch 1, step 34520, training loss = 2.336829, validation loss = 2.696375
2018-12-05 05:32:32,262 - INFO - epoch 1, step 34530, training loss = 2.279209, validation loss = 2.512149
2018-12-05 05:32:35,474 - INFO - epoch 1, step 34540, training loss = 2.405157, validation loss = 2.715343
2018-12-05 05:32:38,709 - INFO - epoch 1, step 34550, training loss = 2.307010, validation loss = 2.638736
2018-12-05 05:32:42,081 - INFO - epoch 1, step 34560, training loss = 2.431216, validation loss = 2.194725
2018-12-05 05:32:45,355 - INFO - epoch 1, step 34570, training loss = 2.266703, validation loss = 2.927237
2018-12-05 05:32:48,527 - INFO - epoch 1, step 34580, training loss = 2.476444, validation loss = 2.746639
2018-12-05 05:32:51,664 - INFO - epoch 1, step 34590, training loss = 2.255225, validation loss = 2.710044
2018-12-05 05:32:55,048 - INFO - epoch 1, step 34600, training loss = 1.870080, validation loss = 2.668978
2018-12-05 05:32:58,260 - INFO - epoch 1, step 34610, training loss = 2.506616, validation loss = 2.586710
2018-12-05 05:33:01,406 - INFO - epoch 1, step 34620, training loss = 2.407192, validation loss = 2.418606
2018-12-05 05:33:04,530 - INFO - epoch 1, step 34630, training loss = 2.104798, validation loss = 2.529039
2018-12-05 05:33:07,644 - INFO - epoch 1, step 34640, training loss = 2.257155, validation loss = 2.891422
2018-12-05 05:33:12,947 - INFO - epoch 1, step 34650, training loss = 2.581715, validation loss = 2.733084
2018-12-05 05:33:18,086 - INFO - epoch 1, step 34660, training loss = 2.133626, validation loss = 2.515847
2018-12-05 05:33:23,329 - INFO - epoch 1, step 34670, training loss = 2.682342, validation loss = 2.624952
2018-12-05 05:33:28,508 - INFO - epoch 1, step 34680, training loss = 2.515191, validation loss = 2.540739
2018-12-05 05:33:34,016 - INFO - epoch 1, step 34690, training loss = 2.623594, validation loss = 2.568584
2018-12-05 05:33:39,406 - INFO - epoch 1, step 34700, training loss = 1.914118, validation loss = 2.385802
2018-12-05 05:33:44,857 - INFO - epoch 1, step 34710, training loss = 2.242124, validation loss = 2.628621
2018-12-05 05:33:50,177 - INFO - epoch 1, step 34720, training loss = 2.251518, validation loss = 2.751478
2018-12-05 05:33:55,640 - INFO - epoch 1, step 34730, training loss = 2.277622, validation loss = 2.694407
2018-12-05 05:34:00,843 - INFO - epoch 1, step 34740, training loss = 2.670781, validation loss = 2.693886
2018-12-05 05:34:06,207 - INFO - epoch 1, step 34750, training loss = 2.170612, validation loss = 2.493121
2018-12-05 05:34:11,790 - INFO - epoch 1, step 34760, training loss = 2.407096, validation loss = 2.624033
2018-12-05 05:34:17,245 - INFO - epoch 1, step 34770, training loss = 2.695073, validation loss = 2.546210
2018-12-05 05:34:22,930 - INFO - epoch 1, step 34780, training loss = 2.430940, validation loss = 2.454580
2018-12-05 05:34:28,558 - INFO - epoch 1, step 34790, training loss = 2.286533, validation loss = 2.389217
2018-12-05 05:34:33,964 - INFO - epoch 1, step 34800, training loss = 2.675570, validation loss = 2.845210
2018-12-05 05:34:39,076 - INFO - epoch 1, step 34810, training loss = 2.384650, validation loss = 2.536469
2018-12-05 05:34:44,111 - INFO - epoch 1, step 34820, training loss = 2.144847, validation loss = 2.483783
2018-12-05 05:34:47,709 - INFO - epoch 1, step 34830, training loss = 2.554120, validation loss = 2.365111
2018-12-05 05:34:51,719 - INFO - epoch 1, step 34840, training loss = 2.158275, validation loss = 2.337015
2018-12-05 05:34:57,808 - INFO - epoch 1, step 34850, training loss = 2.088022, validation loss = 2.489315
2018-12-05 05:35:03,161 - INFO - epoch 1, step 34860, training loss = 2.100402, validation loss = 2.513044
2018-12-05 05:35:09,336 - INFO - epoch 1, step 34870, training loss = 2.129828, validation loss = 2.537554
2018-12-05 05:35:15,549 - INFO - epoch 1, step 34880, training loss = 2.287336, validation loss = 2.303554
2018-12-05 05:35:21,651 - INFO - epoch 1, step 34890, training loss = 2.331640, validation loss = 2.699162
2018-12-05 05:35:27,972 - INFO - epoch 1, step 34900, training loss = 1.757260, validation loss = 2.575624
2018-12-05 05:35:33,056 - INFO - epoch 1, step 34910, training loss = 2.339060, validation loss = 2.502899
2018-12-05 05:35:38,547 - INFO - epoch 1, step 34920, training loss = 1.711483, validation loss = 2.730874
2018-12-05 05:35:44,257 - INFO - epoch 1, step 34930, training loss = 2.074996, validation loss = 2.367089
2018-12-05 05:35:49,016 - INFO - epoch 1, step 34940, training loss = 2.561200, validation loss = 2.532017
2018-12-05 05:35:53,830 - INFO - epoch 1, step 34950, training loss = 2.440436, validation loss = 2.632868
2018-12-05 05:35:58,458 - INFO - epoch 1, step 34960, training loss = 2.213637, validation loss = 2.513266
2018-12-05 05:36:03,552 - INFO - epoch 1, step 34970, training loss = 2.164769, validation loss = 2.360906
2018-12-05 05:36:09,018 - INFO - epoch 1, step 34980, training loss = 2.513630, validation loss = 2.637622
2018-12-05 05:36:13,701 - INFO - epoch 1, step 34990, training loss = 2.019119, validation loss = 2.431339
2018-12-05 05:36:18,327 - INFO - epoch 1, step 35000, training loss = 2.080394, validation loss = 2.615300
2018-12-05 05:36:23,422 - INFO - epoch 1, step 35010, training loss = 2.163009, validation loss = 2.205614
2018-12-05 05:36:28,147 - INFO - epoch 1, step 35020, training loss = 2.340691, validation loss = 2.638441
2018-12-05 05:36:33,088 - INFO - epoch 1, step 35030, training loss = 2.438439, validation loss = 2.420664
2018-12-05 05:36:37,819 - INFO - epoch 1, step 35040, training loss = 1.930350, validation loss = 2.639799
2018-12-05 05:36:42,517 - INFO - epoch 1, step 35050, training loss = 2.358558, validation loss = 2.552493
2018-12-05 05:36:47,309 - INFO - epoch 1, step 35060, training loss = 1.708966, validation loss = 2.134629
2018-12-05 05:36:49,750 - INFO - epoch 1, step 35070, training loss = 2.637515, validation loss = 2.489296
2018-12-05 05:36:52,106 - INFO - epoch 1, step 35080, training loss = 2.551323, validation loss = 2.727964
2018-12-05 05:36:54,388 - INFO - epoch 1, step 35090, training loss = 2.586221, validation loss = 2.541628
2018-12-05 05:36:56,895 - INFO - epoch 1, step 35100, training loss = 2.298177, validation loss = 2.560383
2018-12-05 05:36:59,354 - INFO - epoch 1, step 35110, training loss = 2.734441, validation loss = 2.552348
2018-12-05 05:37:01,781 - INFO - epoch 1, step 35120, training loss = 2.450830, validation loss = 2.835529
2018-12-05 05:37:04,081 - INFO - epoch 1, step 35130, training loss = 2.044829, validation loss = 2.673265
2018-12-05 05:37:06,364 - INFO - epoch 1, step 35140, training loss = 2.339260, validation loss = 2.647973
2018-12-05 05:37:08,722 - INFO - epoch 1, step 35150, training loss = 1.827017, validation loss = 2.952228
2018-12-05 05:37:11,094 - INFO - epoch 1, step 35160, training loss = 2.650593, validation loss = 3.142023
2018-12-05 05:37:13,332 - INFO - epoch 1, step 35170, training loss = 2.144858, validation loss = 2.738578
2018-12-05 05:37:15,588 - INFO - epoch 1, step 35180, training loss = 2.293633, validation loss = 2.863537
2018-12-05 05:37:17,791 - INFO - epoch 1, step 35190, training loss = 2.330268, validation loss = 2.835189
2018-12-05 05:37:20,091 - INFO - epoch 1, step 35200, training loss = 2.300832, validation loss = 2.547534
2018-12-05 05:37:22,358 - INFO - epoch 1, step 35210, training loss = 1.534040, validation loss = 2.516302
2018-12-05 05:37:24,656 - INFO - epoch 1, step 35220, training loss = 2.208310, validation loss = 2.403679
2018-12-05 05:37:28,282 - INFO - epoch 1, step 35230, training loss = 2.154584, validation loss = 2.392721
2018-12-05 05:37:32,490 - INFO - epoch 1, step 35240, training loss = 2.097863, validation loss = 2.286294
2018-12-05 05:37:36,883 - INFO - epoch 1, step 35250, training loss = 1.676220, validation loss = 2.544888
2018-12-05 05:37:41,149 - INFO - epoch 1, step 35260, training loss = 2.650772, validation loss = 1.985910
2018-12-05 05:37:45,461 - INFO - epoch 1, step 35270, training loss = 2.438785, validation loss = 2.566463
2018-12-05 05:37:49,777 - INFO - epoch 1, step 35280, training loss = 1.834291, validation loss = 2.389957
2018-12-05 05:37:54,019 - INFO - epoch 1, step 35290, training loss = 2.076745, validation loss = 2.655563
2018-12-05 05:37:58,198 - INFO - epoch 1, step 35300, training loss = 2.020283, validation loss = 2.436568
2018-12-05 05:38:02,437 - INFO - epoch 1, step 35310, training loss = 2.293115, validation loss = 2.343642
2018-12-05 05:38:06,707 - INFO - epoch 1, step 35320, training loss = 2.305603, validation loss = 1.980052
2018-12-05 05:38:11,247 - INFO - epoch 1, step 35330, training loss = 2.562690, validation loss = 1.934774
2018-12-05 05:38:15,818 - INFO - epoch 1, step 35340, training loss = 2.529344, validation loss = 2.925291
2018-12-05 05:38:20,347 - INFO - epoch 1, step 35350, training loss = 2.105676, validation loss = 2.590383
2018-12-05 05:38:24,801 - INFO - epoch 1, step 35360, training loss = 2.371527, validation loss = 1.857374
2018-12-05 05:38:29,321 - INFO - epoch 1, step 35370, training loss = 2.675490, validation loss = 2.473990
2018-12-05 05:38:33,717 - INFO - epoch 1, step 35380, training loss = 2.478945, validation loss = 1.973167
2018-12-05 05:38:38,201 - INFO - epoch 1, step 35390, training loss = 2.766230, validation loss = 2.608956
2018-12-05 05:38:43,127 - INFO - epoch 1, step 35400, training loss = 2.554173, validation loss = 2.874767
2018-12-05 05:38:47,533 - INFO - epoch 1, step 35410, training loss = 2.463351, validation loss = 1.997449
2018-12-05 05:38:51,954 - INFO - epoch 1, step 35420, training loss = 2.409542, validation loss = 2.497717
2018-12-05 05:38:56,445 - INFO - epoch 1, step 35430, training loss = 2.357670, validation loss = 2.556585
2018-12-05 05:39:00,966 - INFO - epoch 1, step 35440, training loss = 2.597738, validation loss = 2.631555
2018-12-05 05:39:05,361 - INFO - epoch 1, step 35450, training loss = 2.153699, validation loss = 2.191935
2018-12-05 05:39:09,847 - INFO - epoch 1, step 35460, training loss = 2.171890, validation loss = 2.692194
2018-12-05 05:39:14,153 - INFO - epoch 1, step 35470, training loss = 2.443673, validation loss = 2.092982
2018-12-05 05:39:18,467 - INFO - epoch 1, step 35480, training loss = 1.495503, validation loss = 2.418942
2018-12-05 05:39:22,742 - INFO - epoch 1, step 35490, training loss = 1.884969, validation loss = 2.138769
2018-12-05 05:39:26,992 - INFO - epoch 1, step 35500, training loss = 2.192856, validation loss = 2.780113
2018-12-05 05:39:31,126 - INFO - epoch 1, step 35510, training loss = 2.308402, validation loss = 2.463139
2018-12-05 05:39:35,176 - INFO - epoch 1, step 35520, training loss = 2.543032, validation loss = 2.618698
2018-12-05 05:39:39,522 - INFO - epoch 1, step 35530, training loss = 2.144654, validation loss = 2.558936
2018-12-05 05:39:43,683 - INFO - epoch 1, step 35540, training loss = 2.692448, validation loss = 2.493557
2018-12-05 05:39:48,292 - INFO - epoch 1, step 35550, training loss = 2.144214, validation loss = 2.263258
2018-12-05 05:39:52,590 - INFO - epoch 1, step 35560, training loss = 2.394712, validation loss = 2.020573
2018-12-05 05:39:57,008 - INFO - epoch 1, step 35570, training loss = 1.856020, validation loss = 2.646774
2018-12-05 05:40:01,325 - INFO - epoch 1, step 35580, training loss = 2.586979, validation loss = 2.408291
2018-12-05 05:40:07,378 - INFO - epoch 1, step 35590, training loss = 2.323233, validation loss = 2.532860
2018-12-05 05:40:12,774 - INFO - epoch 1, step 35600, training loss = 2.028545, validation loss = 2.294816
2018-12-05 05:40:18,691 - INFO - epoch 1, step 35610, training loss = 2.088427, validation loss = 2.462152
2018-12-05 05:40:24,068 - INFO - epoch 1, step 35620, training loss = 2.067133, validation loss = 2.545377
2018-12-05 05:40:29,650 - INFO - epoch 1, step 35630, training loss = 2.388889, validation loss = 2.013572
2018-12-05 05:40:35,201 - INFO - epoch 1, step 35640, training loss = 1.779047, validation loss = 2.015488
2018-12-05 05:40:40,973 - INFO - epoch 1, step 35650, training loss = 2.071429, validation loss = 2.463272
2018-12-05 05:40:46,431 - INFO - epoch 1, step 35660, training loss = 1.964257, validation loss = 2.053696
2018-12-05 05:40:52,237 - INFO - epoch 1, step 35670, training loss = 1.894468, validation loss = 2.593366
2018-12-05 05:40:57,863 - INFO - epoch 1, step 35680, training loss = 2.414607, validation loss = 2.501152
2018-12-05 05:41:01,943 - INFO - epoch 1, step 35690, training loss = 1.793749, validation loss = 2.174024
2018-12-05 05:41:06,408 - INFO - epoch 1, step 35700, training loss = 2.275828, validation loss = 2.397690
2018-12-05 05:41:10,536 - INFO - epoch 1, step 35710, training loss = 2.210701, validation loss = 2.352047
2018-12-05 05:41:14,817 - INFO - epoch 1, step 35720, training loss = 2.256304, validation loss = 1.857842
2018-12-05 05:41:18,813 - INFO - epoch 1, step 35730, training loss = 2.509945, validation loss = 2.633129
2018-12-05 05:41:23,271 - INFO - epoch 1, step 35740, training loss = 2.271117, validation loss = 2.187976
2018-12-05 05:41:27,420 - INFO - epoch 1, step 35750, training loss = 2.841924, validation loss = 2.571883
2018-12-05 05:41:31,336 - INFO - epoch 1, step 35760, training loss = 2.744081, validation loss = 1.996924
2018-12-05 05:41:35,173 - INFO - epoch 1, step 35770, training loss = 2.580261, validation loss = 1.890642
2018-12-05 05:41:38,858 - INFO - epoch 1, step 35780, training loss = 2.375901, validation loss = 2.048900
2018-12-05 05:41:42,891 - INFO - epoch 1, step 35790, training loss = 2.297668, validation loss = 2.200594
2018-12-05 05:41:46,856 - INFO - epoch 1, step 35800, training loss = 2.338677, validation loss = 2.198178
2018-12-05 05:41:50,709 - INFO - epoch 1, step 35810, training loss = 2.690366, validation loss = 2.805516
2018-12-05 05:41:54,495 - INFO - epoch 1, step 35820, training loss = 2.326977, validation loss = 2.289802
2018-12-05 05:41:58,418 - INFO - epoch 1, step 35830, training loss = 2.533563, validation loss = 1.964022
2018-12-05 05:42:02,249 - INFO - epoch 1, step 35840, training loss = 2.606030, validation loss = 1.828521
2018-12-05 05:42:05,947 - INFO - epoch 1, step 35850, training loss = 2.517658, validation loss = 2.252046
2018-12-05 05:42:09,872 - INFO - epoch 1, step 35860, training loss = 2.583045, validation loss = 1.761216
2018-12-05 05:42:13,621 - INFO - epoch 1, step 35870, training loss = 2.219737, validation loss = 2.392362
2018-12-05 05:42:17,409 - INFO - epoch 1, step 35880, training loss = 2.500151, validation loss = 2.638275
2018-12-05 05:42:21,115 - INFO - epoch 1, step 35890, training loss = 2.256691, validation loss = 2.038731
2018-12-05 05:42:24,973 - INFO - epoch 1, step 35900, training loss = 2.300387, validation loss = 2.488602
2018-12-05 05:42:28,834 - INFO - epoch 1, step 35910, training loss = 2.061134, validation loss = 2.482867
2018-12-05 05:42:32,974 - INFO - epoch 1, step 35920, training loss = 2.169108, validation loss = 2.436140
2018-12-05 05:42:37,105 - INFO - epoch 1, step 35930, training loss = 2.197546, validation loss = 1.876990
2018-12-05 05:42:40,761 - INFO - epoch 1, step 35940, training loss = 2.233830, validation loss = 2.500347
2018-12-05 05:42:44,545 - INFO - epoch 1, step 35950, training loss = 2.210248, validation loss = 2.602488
2018-12-05 05:42:48,485 - INFO - epoch 1, step 35960, training loss = 2.516474, validation loss = 2.398879
2018-12-05 05:42:52,316 - INFO - epoch 1, step 35970, training loss = 2.593566, validation loss = 2.045846
2018-12-05 05:42:56,086 - INFO - epoch 1, step 35980, training loss = 2.216998, validation loss = 2.184903
2018-12-05 05:42:59,935 - INFO - epoch 1, step 35990, training loss = 1.969449, validation loss = 2.637418
2018-12-05 05:43:03,800 - INFO - epoch 1, step 36000, training loss = 2.328294, validation loss = 2.488975
2018-12-05 05:43:07,607 - INFO - epoch 1, step 36010, training loss = 2.237986, validation loss = 2.312174
2018-12-05 05:43:11,402 - INFO - epoch 1, step 36020, training loss = 1.837637, validation loss = 2.035823
2018-12-05 05:43:15,117 - INFO - epoch 1, step 36030, training loss = 2.213164, validation loss = 2.721873
2018-12-05 05:43:18,829 - INFO - epoch 1, step 36040, training loss = 2.059798, validation loss = 2.715014
2018-12-05 05:43:22,471 - INFO - epoch 1, step 36050, training loss = 2.300621, validation loss = 1.995496
2018-12-05 05:43:26,347 - INFO - epoch 1, step 36060, training loss = 2.508077, validation loss = 2.244964
2018-12-05 05:43:30,423 - INFO - epoch 1, step 36070, training loss = 2.030617, validation loss = 2.826638
2018-12-05 05:43:34,251 - INFO - epoch 1, step 36080, training loss = 2.186291, validation loss = 2.519978
2018-12-05 05:43:37,826 - INFO - epoch 1, step 36090, training loss = 2.004140, validation loss = 2.513330
2018-12-05 05:43:41,434 - INFO - epoch 1, step 36100, training loss = 2.198823, validation loss = 2.670900
2018-12-05 05:43:45,236 - INFO - epoch 1, step 36110, training loss = 2.347348, validation loss = 2.587454
2018-12-05 05:43:49,152 - INFO - epoch 1, step 36120, training loss = 2.385481, validation loss = 3.060415
2018-12-05 05:43:53,059 - INFO - epoch 1, step 36130, training loss = 2.357741, validation loss = 2.361957
2018-12-05 05:43:56,930 - INFO - epoch 1, step 36140, training loss = 2.269067, validation loss = 2.229448
2018-12-05 05:44:00,716 - INFO - epoch 1, step 36150, training loss = 2.005673, validation loss = 2.146551
2018-12-05 05:44:04,576 - INFO - epoch 1, step 36160, training loss = 2.356422, validation loss = 2.393823
2018-12-05 05:44:08,278 - INFO - epoch 1, step 36170, training loss = 1.988428, validation loss = 2.718892
2018-12-05 05:44:12,257 - INFO - epoch 1, step 36180, training loss = 2.227515, validation loss = 2.619527
2018-12-05 05:44:15,999 - INFO - epoch 1, step 36190, training loss = 2.434194, validation loss = 2.381518
2018-12-05 05:44:19,965 - INFO - epoch 1, step 36200, training loss = 1.913825, validation loss = 1.723327
2018-12-05 05:44:23,739 - INFO - epoch 1, step 36210, training loss = 2.437668, validation loss = 3.072537
2018-12-05 05:44:27,492 - INFO - epoch 1, step 36220, training loss = 2.189893, validation loss = 2.290309
2018-12-05 05:44:31,093 - INFO - epoch 1, step 36230, training loss = 2.053054, validation loss = 2.780298
2018-12-05 05:44:34,961 - INFO - epoch 1, step 36240, training loss = 2.147331, validation loss = 2.418191
2018-12-05 05:44:38,592 - INFO - epoch 1, step 36250, training loss = 2.433059, validation loss = 2.741633
2018-12-05 05:44:42,310 - INFO - epoch 1, step 36260, training loss = 2.199271, validation loss = 2.511764
2018-12-05 05:44:46,067 - INFO - epoch 1, step 36270, training loss = 2.516135, validation loss = 2.666832
2018-12-05 05:44:49,699 - INFO - epoch 1, step 36280, training loss = 2.149210, validation loss = 2.745039
2018-12-05 05:44:53,352 - INFO - epoch 1, step 36290, training loss = 2.118748, validation loss = 2.266317
2018-12-05 05:44:57,198 - INFO - epoch 1, step 36300, training loss = 2.195153, validation loss = 2.373624
2018-12-05 05:45:00,983 - INFO - epoch 1, step 36310, training loss = 2.210009, validation loss = 2.292684
2018-12-05 05:45:04,720 - INFO - epoch 1, step 36320, training loss = 2.151606, validation loss = 2.397511
2018-12-05 05:45:08,531 - INFO - epoch 1, step 36330, training loss = 2.149861, validation loss = 2.807738
2018-12-05 05:45:12,369 - INFO - epoch 1, step 36340, training loss = 2.090060, validation loss = 2.298867
2018-12-05 05:45:16,295 - INFO - epoch 1, step 36350, training loss = 2.016481, validation loss = 2.212695
2018-12-05 05:45:19,864 - INFO - epoch 1, step 36360, training loss = 1.977590, validation loss = 2.832992
2018-12-05 05:45:23,601 - INFO - epoch 1, step 36370, training loss = 2.249561, validation loss = 2.810313
2018-12-05 05:45:27,405 - INFO - epoch 1, step 36380, training loss = 2.005252, validation loss = 2.936705
2018-12-05 05:45:31,191 - INFO - epoch 1, step 36390, training loss = 2.373428, validation loss = 2.287319
2018-12-05 05:45:35,012 - INFO - epoch 1, step 36400, training loss = 2.380135, validation loss = 2.270803
2018-12-05 05:45:38,721 - INFO - epoch 1, step 36410, training loss = 2.214970, validation loss = 2.652707
2018-12-05 05:45:42,291 - INFO - epoch 1, step 36420, training loss = 2.230653, validation loss = 2.389935
2018-12-05 05:45:45,955 - INFO - epoch 1, step 36430, training loss = 2.332392, validation loss = 2.472759
2018-12-05 05:45:49,752 - INFO - epoch 1, step 36440, training loss = 2.475847, validation loss = 2.202571
2018-12-05 05:45:53,564 - INFO - epoch 1, step 36450, training loss = 2.286625, validation loss = 2.488166
2018-12-05 05:45:57,298 - INFO - epoch 1, step 36460, training loss = 1.907700, validation loss = 2.711211
2018-12-05 05:46:01,074 - INFO - epoch 1, step 36470, training loss = 2.385033, validation loss = 2.490432
2018-12-05 05:46:05,078 - INFO - epoch 1, step 36480, training loss = 2.284300, validation loss = 2.453406
2018-12-05 05:46:08,821 - INFO - epoch 1, step 36490, training loss = 2.278289, validation loss = 2.901176
2018-12-05 05:46:12,604 - INFO - epoch 1, step 36500, training loss = 2.255495, validation loss = 2.410477
2018-12-05 05:46:16,627 - INFO - epoch 1, step 36510, training loss = 2.071679, validation loss = 2.422009
2018-12-05 05:46:20,700 - INFO - epoch 1, step 36520, training loss = 2.266862, validation loss = 2.467204
2018-12-05 05:46:24,460 - INFO - epoch 1, step 36530, training loss = 2.152977, validation loss = 2.555197
2018-12-05 05:46:28,475 - INFO - epoch 1, step 36540, training loss = 2.098328, validation loss = 2.681508
2018-12-05 05:46:32,094 - INFO - epoch 1, step 36550, training loss = 2.176603, validation loss = 2.372576
2018-12-05 05:46:35,869 - INFO - epoch 1, step 36560, training loss = 1.956381, validation loss = 2.425862
2018-12-05 05:46:39,828 - INFO - epoch 1, step 36570, training loss = 2.308189, validation loss = 2.746285
2018-12-05 05:46:43,623 - INFO - epoch 1, step 36580, training loss = 2.340761, validation loss = 2.276605
2018-12-05 05:46:47,504 - INFO - epoch 1, step 36590, training loss = 2.273003, validation loss = 2.707214
2018-12-05 05:46:51,185 - INFO - epoch 1, step 36600, training loss = 1.980647, validation loss = 2.286606
2018-12-05 05:46:55,080 - INFO - epoch 1, step 36610, training loss = 2.505119, validation loss = 2.531353
2018-12-05 05:46:58,941 - INFO - epoch 1, step 36620, training loss = 2.332302, validation loss = 2.547254
2018-12-05 05:47:02,793 - INFO - epoch 1, step 36630, training loss = 2.110972, validation loss = 2.341066
2018-12-05 05:47:06,184 - INFO - epoch 1, step 36640, training loss = 2.395794, validation loss = 2.689373
2018-12-05 05:47:10,090 - INFO - epoch 1, step 36650, training loss = 2.423578, validation loss = 2.520070
2018-12-05 05:47:14,015 - INFO - epoch 1, step 36660, training loss = 1.910033, validation loss = 2.840001
2018-12-05 05:47:17,828 - INFO - epoch 1, step 36670, training loss = 2.005836, validation loss = 2.783518
2018-12-05 05:47:21,636 - INFO - epoch 1, step 36680, training loss = 2.063244, validation loss = 2.776485
2018-12-05 05:47:25,409 - INFO - epoch 1, step 36690, training loss = 1.965358, validation loss = 2.404214
2018-12-05 05:47:29,048 - INFO - epoch 1, step 36700, training loss = 1.969672, validation loss = 2.632136
2018-12-05 05:47:32,778 - INFO - epoch 1, step 36710, training loss = 2.377164, validation loss = 2.018471
2018-12-05 05:47:36,682 - INFO - epoch 1, step 36720, training loss = 1.861120, validation loss = 2.227746
2018-12-05 05:47:40,516 - INFO - epoch 1, step 36730, training loss = 2.191142, validation loss = 2.515879
2018-12-05 05:47:44,441 - INFO - epoch 1, step 36740, training loss = 2.406746, validation loss = 2.584021
2018-12-05 05:47:48,317 - INFO - epoch 1, step 36750, training loss = 2.020128, validation loss = 2.312611
2018-12-05 05:47:52,108 - INFO - epoch 1, step 36760, training loss = 2.536173, validation loss = 2.492974
2018-12-05 05:47:55,743 - INFO - epoch 1, step 36770, training loss = 2.387576, validation loss = 2.696397
2018-12-05 05:47:59,337 - INFO - epoch 1, step 36780, training loss = 2.869866, validation loss = 2.242354
2018-12-05 05:48:02,862 - INFO - epoch 1, step 36790, training loss = 3.277092, validation loss = 2.437716
2018-12-05 05:48:06,471 - INFO - epoch 1, step 36800, training loss = 3.550846, validation loss = 2.348932
2018-12-05 05:48:10,102 - INFO - epoch 1, step 36810, training loss = 3.110461, validation loss = 2.813220
2018-12-05 05:48:13,621 - INFO - epoch 1, step 36820, training loss = 2.991752, validation loss = 2.915192
2018-12-05 05:48:17,248 - INFO - epoch 1, step 36830, training loss = 2.828136, validation loss = 2.912297
2018-12-05 05:48:21,300 - INFO - epoch 1, step 36840, training loss = 2.716968, validation loss = 2.771210
2018-12-05 05:48:24,873 - INFO - epoch 1, step 36850, training loss = 3.076924, validation loss = 3.163626
2018-12-05 05:48:28,660 - INFO - epoch 1, step 36860, training loss = 2.708722, validation loss = 2.576735
2018-12-05 05:48:31,936 - INFO - epoch 1, step 36870, training loss = 2.939478, validation loss = 2.476707
2018-12-05 05:48:35,600 - INFO - epoch 1, step 36880, training loss = 2.478241, validation loss = 2.946476
2018-12-05 05:48:39,410 - INFO - epoch 1, step 36890, training loss = 3.297126, validation loss = 2.873775
2018-12-05 05:48:42,969 - INFO - epoch 1, step 36900, training loss = 3.339807, validation loss = 2.174747
2018-12-05 05:48:46,479 - INFO - epoch 1, step 36910, training loss = 2.971859, validation loss = 2.787105
2018-12-05 05:48:49,978 - INFO - epoch 1, step 36920, training loss = 2.682026, validation loss = 2.489164
2018-12-05 05:48:53,606 - INFO - epoch 1, step 36930, training loss = 2.991324, validation loss = 2.727101
2018-12-05 05:48:57,210 - INFO - epoch 1, step 36940, training loss = 2.730807, validation loss = 2.437604
2018-12-05 05:49:00,961 - INFO - epoch 1, step 36950, training loss = 3.050317, validation loss = 2.525858
2018-12-05 05:49:04,834 - INFO - epoch 1, step 36960, training loss = 2.963276, validation loss = 2.762663
2018-12-05 05:49:08,846 - INFO - epoch 1, step 36970, training loss = 3.453529, validation loss = 2.141232
2018-12-05 05:49:12,498 - INFO - epoch 1, step 36980, training loss = 2.691861, validation loss = 2.530672
2018-12-05 05:49:15,958 - INFO - epoch 1, step 36990, training loss = 3.153201, validation loss = 3.127778
2018-12-05 05:49:19,379 - INFO - epoch 1, step 37000, training loss = 2.909748, validation loss = 2.226749
2018-12-05 05:49:22,851 - INFO - epoch 1, step 37010, training loss = 2.576693, validation loss = 2.383008
2018-12-05 05:49:26,610 - INFO - epoch 1, step 37020, training loss = 2.762026, validation loss = 3.085973
2018-12-05 05:49:30,291 - INFO - epoch 1, step 37030, training loss = 2.831545, validation loss = 2.370060
2018-12-05 05:49:34,163 - INFO - epoch 1, step 37040, training loss = 3.111769, validation loss = 2.792499
2018-12-05 05:49:37,636 - INFO - epoch 1, step 37050, training loss = 2.868821, validation loss = 2.541688
2018-12-05 05:49:41,149 - INFO - epoch 1, step 37060, training loss = 2.684947, validation loss = 2.712157
2018-12-05 05:49:44,911 - INFO - epoch 1, step 37070, training loss = 2.952051, validation loss = 2.772898
2018-12-05 05:49:48,489 - INFO - epoch 1, step 37080, training loss = 2.900270, validation loss = 2.984061
2018-12-05 05:49:52,246 - INFO - epoch 1, step 37090, training loss = 3.345676, validation loss = 2.980089
2018-12-05 05:49:55,961 - INFO - epoch 1, step 37100, training loss = 3.034498, validation loss = 3.020757
2018-12-05 05:49:59,414 - INFO - epoch 1, step 37110, training loss = 2.658916, validation loss = 2.779297
2018-12-05 05:50:03,278 - INFO - epoch 1, step 37120, training loss = 2.691852, validation loss = 2.340939
2018-12-05 05:50:06,660 - INFO - epoch 1, step 37130, training loss = 2.838498, validation loss = 2.580064
2018-12-05 05:50:10,159 - INFO - epoch 1, step 37140, training loss = 2.517138, validation loss = 3.456005
2018-12-05 05:50:13,574 - INFO - epoch 1, step 37150, training loss = 2.754304, validation loss = 2.557976
2018-12-05 05:50:17,161 - INFO - epoch 1, step 37160, training loss = 3.235439, validation loss = 2.886265
2018-12-05 05:50:20,499 - INFO - epoch 1, step 37170, training loss = 2.797528, validation loss = 2.025968
2018-12-05 05:50:24,331 - INFO - epoch 1, step 37180, training loss = 3.073131, validation loss = 2.820189
2018-12-05 05:50:27,940 - INFO - epoch 1, step 37190, training loss = 3.493469, validation loss = 2.693372
2018-12-05 05:50:31,379 - INFO - epoch 1, step 37200, training loss = 2.920386, validation loss = 2.960141
2018-12-05 05:50:34,995 - INFO - epoch 1, step 37210, training loss = 3.021383, validation loss = 2.350657
2018-12-05 05:50:38,478 - INFO - epoch 1, step 37220, training loss = 3.119673, validation loss = 2.747900
2018-12-05 05:50:42,231 - INFO - epoch 1, step 37230, training loss = 2.981268, validation loss = 2.903744
2018-12-05 05:50:46,132 - INFO - epoch 1, step 37240, training loss = 2.568206, validation loss = 2.748746
2018-12-05 05:50:49,933 - INFO - epoch 1, step 37250, training loss = 2.264006, validation loss = 3.129535
2018-12-05 05:50:53,455 - INFO - epoch 1, step 37260, training loss = 3.176579, validation loss = 3.084777
2018-12-05 05:50:57,284 - INFO - epoch 1, step 37270, training loss = 2.674840, validation loss = 2.371839
2018-12-05 05:51:00,695 - INFO - epoch 1, step 37280, training loss = 2.724135, validation loss = 2.785529
2018-12-05 05:51:04,208 - INFO - epoch 1, step 37290, training loss = 3.218735, validation loss = 2.873108
2018-12-05 05:51:07,922 - INFO - epoch 1, step 37300, training loss = 2.944162, validation loss = 2.797411
2018-12-05 05:51:11,319 - INFO - epoch 1, step 37310, training loss = 2.831706, validation loss = 3.072734
2018-12-05 05:51:14,870 - INFO - epoch 1, step 37320, training loss = 3.400500, validation loss = 3.093940
2018-12-05 05:51:18,217 - INFO - epoch 1, step 37330, training loss = 2.716694, validation loss = 2.954049
2018-12-05 05:51:21,454 - INFO - epoch 1, step 37340, training loss = 3.012204, validation loss = 2.522980
2018-12-05 05:51:24,886 - INFO - epoch 1, step 37350, training loss = 3.010333, validation loss = 2.832760
2018-12-05 05:51:28,356 - INFO - epoch 1, step 37360, training loss = 2.913602, validation loss = 2.940652
2018-12-05 05:51:31,766 - INFO - epoch 1, step 37370, training loss = 3.212911, validation loss = 2.981775
2018-12-05 05:51:35,265 - INFO - epoch 1, step 37380, training loss = 3.102019, validation loss = 2.816246
2018-12-05 05:51:38,843 - INFO - epoch 1, step 37390, training loss = 2.786906, validation loss = 2.734068
2018-12-05 05:51:42,433 - INFO - epoch 1, step 37400, training loss = 3.005085, validation loss = 3.195538
2018-12-05 05:51:45,918 - INFO - epoch 1, step 37410, training loss = 2.842009, validation loss = 2.968192
2018-12-05 05:51:49,559 - INFO - epoch 1, step 37420, training loss = 3.422144, validation loss = 2.625875
2018-12-05 05:51:53,321 - INFO - epoch 1, step 37430, training loss = 3.425447, validation loss = 3.034088
2018-12-05 05:51:56,845 - INFO - epoch 1, step 37440, training loss = 2.665498, validation loss = 2.785467
2018-12-05 05:52:00,170 - INFO - epoch 1, step 37450, training loss = 2.873824, validation loss = 3.096902
2018-12-05 05:52:03,729 - INFO - epoch 1, step 37460, training loss = 3.041639, validation loss = 2.448445
2018-12-05 05:52:07,561 - INFO - epoch 1, step 37470, training loss = 3.217419, validation loss = 2.850634
2018-12-05 05:52:11,324 - INFO - epoch 1, step 37480, training loss = 2.605969, validation loss = 2.984226
2018-12-05 05:52:14,730 - INFO - epoch 1, step 37490, training loss = 2.778682, validation loss = 3.242194
2018-12-05 05:52:18,072 - INFO - epoch 1, step 37500, training loss = 3.171394, validation loss = 2.511805
2018-12-05 05:52:21,467 - INFO - epoch 1, step 37510, training loss = 2.648907, validation loss = 2.632543
2018-12-05 05:52:24,848 - INFO - epoch 1, step 37520, training loss = 2.756337, validation loss = 2.331724
2018-12-05 05:52:28,901 - INFO - epoch 1, step 37530, training loss = 3.163494, validation loss = 2.247743
2018-12-05 05:52:32,513 - INFO - epoch 1, step 37540, training loss = 2.893229, validation loss = 3.032820
2018-12-05 05:52:36,211 - INFO - epoch 1, step 37550, training loss = 2.632407, validation loss = 2.548822
2018-12-05 05:52:39,685 - INFO - epoch 1, step 37560, training loss = 2.454654, validation loss = 2.583738
2018-12-05 05:52:43,161 - INFO - epoch 1, step 37570, training loss = 3.412421, validation loss = 2.565900
2018-12-05 05:52:46,870 - INFO - epoch 1, step 37580, training loss = 3.023397, validation loss = 3.119420
2018-12-05 05:52:50,642 - INFO - epoch 1, step 37590, training loss = 2.650031, validation loss = 3.232070
2018-12-05 05:52:54,134 - INFO - epoch 1, step 37600, training loss = 2.756378, validation loss = 3.169375
2018-12-05 05:52:57,586 - INFO - epoch 1, step 37610, training loss = 2.903039, validation loss = 2.786999
2018-12-05 05:53:01,213 - INFO - epoch 1, step 37620, training loss = 2.840353, validation loss = 2.911762
2018-12-05 05:53:04,946 - INFO - epoch 1, step 37630, training loss = 3.141842, validation loss = 2.869585
2018-12-05 05:53:08,853 - INFO - epoch 1, step 37640, training loss = 3.282952, validation loss = 2.488270
2018-12-05 05:53:12,448 - INFO - epoch 1, step 37650, training loss = 2.763124, validation loss = 2.965232
2018-12-05 05:53:16,236 - INFO - epoch 1, step 37660, training loss = 3.336710, validation loss = 3.047260
2018-12-05 05:53:20,108 - INFO - epoch 1, step 37670, training loss = 2.455906, validation loss = 2.475758
2018-12-05 05:53:23,686 - INFO - epoch 1, step 37680, training loss = 3.278351, validation loss = 2.845411
2018-12-05 05:53:27,561 - INFO - epoch 1, step 37690, training loss = 2.359493, validation loss = 2.577277
2018-12-05 05:53:31,377 - INFO - epoch 1, step 37700, training loss = 3.136838, validation loss = 2.636968
2018-12-05 05:53:34,992 - INFO - epoch 1, step 37710, training loss = 2.603651, validation loss = 2.932380
2018-12-05 05:53:38,628 - INFO - epoch 1, step 37720, training loss = 3.335770, validation loss = 3.221786
2018-12-05 05:53:42,475 - INFO - epoch 1, step 37730, training loss = 2.627911, validation loss = 2.944379
2018-12-05 05:53:46,118 - INFO - epoch 1, step 37740, training loss = 3.361430, validation loss = 2.883837
2018-12-05 05:53:49,913 - INFO - epoch 1, step 37750, training loss = 3.228007, validation loss = 2.651538
2018-12-05 05:53:53,563 - INFO - epoch 1, step 37760, training loss = 3.042528, validation loss = 2.927447
2018-12-05 05:53:57,098 - INFO - epoch 1, step 37770, training loss = 2.601565, validation loss = 2.841782
2018-12-05 05:54:00,682 - INFO - epoch 1, step 37780, training loss = 3.039013, validation loss = 2.471874
2018-12-05 05:54:04,172 - INFO - epoch 1, step 37790, training loss = 3.134480, validation loss = 2.927956
2018-12-05 05:54:07,450 - INFO - epoch 1, step 37800, training loss = 3.090300, validation loss = 3.333615
2018-12-05 05:54:11,370 - INFO - epoch 1, step 37810, training loss = 3.027555, validation loss = 3.041539
2018-12-05 05:54:15,237 - INFO - epoch 1, step 37820, training loss = 2.817563, validation loss = 3.199636
2018-12-05 05:54:19,151 - INFO - epoch 1, step 37830, training loss = 3.326802, validation loss = 2.472816
2018-12-05 05:54:22,936 - INFO - epoch 1, step 37840, training loss = 2.986755, validation loss = 3.068658
2018-12-05 05:54:26,562 - INFO - epoch 1, step 37850, training loss = 2.761801, validation loss = 2.981349
2018-12-05 05:54:30,438 - INFO - epoch 1, step 37860, training loss = 2.516130, validation loss = 2.345251
2018-12-05 05:54:34,368 - INFO - epoch 1, step 37870, training loss = 3.591676, validation loss = 2.935958
2018-12-05 05:54:38,325 - INFO - epoch 1, step 37880, training loss = 2.693922, validation loss = 2.676834
2018-12-05 05:54:42,209 - INFO - epoch 1, step 37890, training loss = 3.004045, validation loss = 2.663602
2018-12-05 05:54:45,935 - INFO - epoch 1, step 37900, training loss = 2.945540, validation loss = 3.130894
2018-12-05 05:54:49,288 - INFO - epoch 1, step 37910, training loss = 2.730348, validation loss = 2.636032
2018-12-05 05:54:52,697 - INFO - epoch 1, step 37920, training loss = 2.679970, validation loss = 3.385662
2018-12-05 05:54:56,227 - INFO - epoch 1, step 37930, training loss = 2.745580, validation loss = 2.958472
2018-12-05 05:54:59,662 - INFO - epoch 1, step 37940, training loss = 2.802964, validation loss = 2.318749
2018-12-05 05:55:03,473 - INFO - epoch 1, step 37950, training loss = 3.069603, validation loss = 3.038908
2018-12-05 05:55:07,325 - INFO - epoch 1, step 37960, training loss = 2.799585, validation loss = 2.940514
2018-12-05 05:55:10,846 - INFO - epoch 1, step 37970, training loss = 2.648760, validation loss = 2.539152
2018-12-05 05:55:14,201 - INFO - epoch 1, step 37980, training loss = 3.214352, validation loss = 2.792267
2018-12-05 05:55:17,752 - INFO - epoch 1, step 37990, training loss = 2.736790, validation loss = 2.609866
2018-12-05 05:55:21,104 - INFO - epoch 1, step 38000, training loss = 2.829500, validation loss = 3.048530
2018-12-05 05:55:24,627 - INFO - epoch 1, step 38010, training loss = 2.830898, validation loss = 2.995645
2018-12-05 05:55:28,203 - INFO - epoch 1, step 38020, training loss = 2.623492, validation loss = 3.035365
2018-12-05 05:55:31,960 - INFO - epoch 1, step 38030, training loss = 2.820068, validation loss = 2.567098
2018-12-05 05:55:35,846 - INFO - epoch 1, step 38040, training loss = 2.884651, validation loss = 3.181132
2018-12-05 05:55:39,661 - INFO - epoch 1, step 38050, training loss = 3.185684, validation loss = 2.492563
2018-12-05 05:55:43,263 - INFO - epoch 1, step 38060, training loss = 2.221186, validation loss = 3.191105
2018-12-05 05:55:46,948 - INFO - epoch 1, step 38070, training loss = 2.745975, validation loss = 2.221442
2018-12-05 05:55:50,510 - INFO - epoch 1, step 38080, training loss = 2.712969, validation loss = 2.889824
2018-12-05 05:55:54,182 - INFO - epoch 1, step 38090, training loss = 3.086909, validation loss = 2.643749
2018-12-05 05:55:57,613 - INFO - epoch 1, step 38100, training loss = 3.317300, validation loss = 2.435254
2018-12-05 05:56:00,978 - INFO - epoch 1, step 38110, training loss = 3.033959, validation loss = 2.676677
2018-12-05 05:56:04,446 - INFO - epoch 1, step 38120, training loss = 3.128985, validation loss = 2.642103
2018-12-05 05:56:07,863 - INFO - epoch 1, step 38130, training loss = 3.083187, validation loss = 2.897500
2018-12-05 05:56:11,474 - INFO - epoch 1, step 38140, training loss = 2.983610, validation loss = 2.744835
2018-12-05 05:56:15,051 - INFO - epoch 1, step 38150, training loss = 2.699444, validation loss = 2.654929
2018-12-05 05:56:18,507 - INFO - epoch 1, step 38160, training loss = 2.949473, validation loss = 2.337502
2018-12-05 05:56:22,196 - INFO - epoch 1, step 38170, training loss = 3.188633, validation loss = 2.791949
2018-12-05 05:56:25,942 - INFO - epoch 1, step 38180, training loss = 2.924791, validation loss = 2.864342
2018-12-05 05:56:29,769 - INFO - epoch 1, step 38190, training loss = 2.794686, validation loss = 2.515841
2018-12-05 05:56:33,278 - INFO - epoch 1, step 38200, training loss = 2.644239, validation loss = 2.204166
2018-12-05 05:56:36,597 - INFO - epoch 1, step 38210, training loss = 2.930272, validation loss = 2.680070
2018-12-05 05:56:40,453 - INFO - epoch 1, step 38220, training loss = 2.429980, validation loss = 2.910170
2018-12-05 05:56:44,339 - INFO - epoch 1, step 38230, training loss = 3.375035, validation loss = 2.684902
2018-12-05 05:56:48,238 - INFO - epoch 1, step 38240, training loss = 2.997902, validation loss = 1.867608
2018-12-05 05:56:52,060 - INFO - epoch 1, step 38250, training loss = 2.889474, validation loss = 2.216676
2018-12-05 05:56:55,946 - INFO - epoch 1, step 38260, training loss = 2.904524, validation loss = 2.289779
2018-12-05 05:56:59,703 - INFO - epoch 1, step 38270, training loss = 3.103071, validation loss = 2.697116
2018-12-05 05:57:03,973 - INFO - epoch 1, step 38280, training loss = 2.897346, validation loss = 2.012910
2018-12-05 05:57:09,027 - INFO - epoch 1, step 38290, training loss = 2.181917, validation loss = 2.614240
2018-12-05 05:57:14,124 - INFO - epoch 1, step 38300, training loss = 2.833710, validation loss = 2.467242
2018-12-05 05:57:18,978 - INFO - epoch 1, step 38310, training loss = 2.196400, validation loss = 2.229133
2018-12-05 05:57:24,410 - INFO - epoch 1, step 38320, training loss = 2.375844, validation loss = 2.602272
2018-12-05 05:57:29,585 - INFO - epoch 1, step 38330, training loss = 2.277999, validation loss = 3.361652
2018-12-05 05:57:34,682 - INFO - epoch 1, step 38340, training loss = 3.460430, validation loss = 2.498179
2018-12-05 05:57:40,040 - INFO - epoch 1, step 38350, training loss = 3.387243, validation loss = 2.660250
2018-12-05 05:57:45,654 - INFO - epoch 1, step 38360, training loss = 2.733350, validation loss = 2.465229
2018-12-05 05:57:51,070 - INFO - epoch 1, step 38370, training loss = 2.698131, validation loss = 2.407360
2018-12-05 05:57:57,102 - INFO - epoch 1, step 38380, training loss = 2.988103, validation loss = 2.215335
2018-12-05 05:58:03,648 - INFO - epoch 1, step 38390, training loss = 1.590479, validation loss = 1.834697
2018-12-05 05:58:07,790 - INFO - epoch 1, step 38400, training loss = 3.135977, validation loss = 2.121904
2018-12-05 05:58:11,542 - INFO - epoch 1, step 38410, training loss = 3.188552, validation loss = 2.605811
2018-12-05 05:58:15,436 - INFO - epoch 1, step 38420, training loss = 3.115469, validation loss = 2.478325
2018-12-05 05:58:19,464 - INFO - epoch 1, step 38430, training loss = 3.281336, validation loss = 2.547669
2018-12-05 05:58:23,369 - INFO - epoch 1, step 38440, training loss = 2.567666, validation loss = 2.524016
2018-12-05 05:58:27,176 - INFO - epoch 1, step 38450, training loss = 3.385767, validation loss = 2.802845
2018-12-05 05:58:31,765 - INFO - epoch 1, step 38460, training loss = 2.349817, validation loss = 2.687563
2018-12-05 05:58:36,804 - INFO - epoch 1, step 38470, training loss = 2.169458, validation loss = 2.661524
2018-12-05 05:58:41,730 - INFO - epoch 1, step 38480, training loss = 2.760516, validation loss = 2.824193
2018-12-05 05:58:46,519 - INFO - epoch 1, step 38490, training loss = 2.905953, validation loss = 2.867423
2018-12-05 05:58:51,510 - INFO - epoch 1, step 38500, training loss = 2.869395, validation loss = 2.570332
2018-12-05 05:58:57,021 - INFO - epoch 1, step 38510, training loss = 2.308618, validation loss = 2.602494
2018-12-05 05:59:01,855 - INFO - epoch 1, step 38520, training loss = 2.207736, validation loss = 2.045980
2018-12-05 05:59:07,252 - INFO - epoch 1, step 38530, training loss = 2.377150, validation loss = 2.811703
2018-12-05 05:59:12,328 - INFO - epoch 1, step 38540, training loss = 2.518199, validation loss = 2.329260
2018-12-05 05:59:16,357 - INFO - epoch 1, step 38550, training loss = 2.775021, validation loss = 2.193345
2018-12-05 05:59:20,067 - INFO - epoch 1, step 38560, training loss = 2.427300, validation loss = 2.525781
2018-12-05 05:59:23,916 - INFO - epoch 1, step 38570, training loss = 2.826048, validation loss = 2.472431
2018-12-05 05:59:27,596 - INFO - epoch 1, step 38580, training loss = 3.065122, validation loss = 2.908894
2018-12-05 05:59:31,326 - INFO - epoch 1, step 38590, training loss = 3.102016, validation loss = 2.087611
2018-12-05 05:59:35,233 - INFO - epoch 1, step 38600, training loss = 2.780095, validation loss = 2.513106
2018-12-05 05:59:39,400 - INFO - epoch 1, step 38610, training loss = 2.149503, validation loss = 2.448752
2018-12-05 05:59:43,391 - INFO - epoch 1, step 38620, training loss = 2.632939, validation loss = 2.662870
2018-12-05 05:59:47,469 - INFO - epoch 1, step 38630, training loss = 2.504511, validation loss = 2.524800
2018-12-05 05:59:51,468 - INFO - epoch 1, step 38640, training loss = 2.384647, validation loss = 2.027249
2018-12-05 05:59:55,420 - INFO - epoch 1, step 38650, training loss = 2.401320, validation loss = 2.556041
2018-12-05 05:59:59,468 - INFO - epoch 1, step 38660, training loss = 3.014483, validation loss = 2.523850
2018-12-05 06:00:03,692 - INFO - epoch 1, step 38670, training loss = 2.571836, validation loss = 2.490608
2018-12-05 06:00:07,668 - INFO - epoch 1, step 38680, training loss = 3.138029, validation loss = 2.060020
2018-12-05 06:00:11,496 - INFO - epoch 1, step 38690, training loss = 3.036721, validation loss = 2.109799
2018-12-05 06:00:15,666 - INFO - epoch 1, step 38700, training loss = 3.051368, validation loss = 2.166090
2018-12-05 06:00:19,736 - INFO - epoch 1, step 38710, training loss = 2.695289, validation loss = 2.620400
2018-12-05 06:00:24,058 - INFO - epoch 1, step 38720, training loss = 2.674196, validation loss = 2.871988
2018-12-05 06:00:28,253 - INFO - epoch 1, step 38730, training loss = 2.003292, validation loss = 2.523626
2018-12-05 06:00:34,230 - INFO - epoch 1, step 38740, training loss = 2.768752, validation loss = 2.662008
2018-12-05 06:00:40,446 - INFO - epoch 1, step 38750, training loss = 1.716761, validation loss = 3.198923
2018-12-05 06:00:45,701 - INFO - epoch 1, step 38760, training loss = 1.949141, validation loss = 1.609547
2018-12-05 06:00:51,517 - INFO - epoch 1, step 38770, training loss = 2.147176, validation loss = 2.772852
2018-12-05 06:00:56,889 - INFO - epoch 1, step 38780, training loss = 2.474993, validation loss = 2.582788
2018-12-05 06:01:02,283 - INFO - epoch 1, step 38790, training loss = 2.320282, validation loss = 2.653991
2018-12-05 06:01:07,419 - INFO - epoch 1, step 38800, training loss = 2.254457, validation loss = 2.946640
2018-12-05 06:01:12,440 - INFO - epoch 1, step 38810, training loss = 2.502937, validation loss = 2.462254
2018-12-05 06:01:17,518 - INFO - epoch 1, step 38820, training loss = 3.425746, validation loss = 3.039103
2018-12-05 06:01:22,846 - INFO - epoch 1, step 38830, training loss = 2.203196, validation loss = 2.788281
2018-12-05 06:01:28,771 - INFO - epoch 1, step 38840, training loss = 2.021630, validation loss = 3.429861
2018-12-05 06:01:34,284 - INFO - epoch 1, step 38850, training loss = 2.478294, validation loss = 3.131895
2018-12-05 06:01:39,757 - INFO - epoch 1, step 38860, training loss = 1.998294, validation loss = 2.835791
2018-12-05 06:01:44,999 - INFO - epoch 1, step 38870, training loss = 2.207740, validation loss = 2.691896
2018-12-05 06:01:50,141 - INFO - epoch 1, step 38880, training loss = 2.614680, validation loss = 2.666177
2018-12-05 06:01:55,372 - INFO - epoch 1, step 38890, training loss = 3.388962, validation loss = 3.629254
2018-12-05 06:02:00,887 - INFO - epoch 1, step 38900, training loss = 2.178365, validation loss = 2.711041
2018-12-05 06:02:06,428 - INFO - epoch 1, step 38910, training loss = 1.927146, validation loss = 2.200015
2018-12-05 06:02:11,709 - INFO - epoch 1, step 38920, training loss = 2.322394, validation loss = 2.457502
2018-12-05 06:02:16,726 - INFO - epoch 1, step 38930, training loss = 2.813006, validation loss = 2.714215
2018-12-05 06:02:22,408 - INFO - epoch 1, step 38940, training loss = 2.543204, validation loss = 2.889898
2018-12-05 06:02:27,735 - INFO - epoch 1, step 38950, training loss = 2.467942, validation loss = 3.203873
2018-12-05 06:02:33,126 - INFO - epoch 1, step 38960, training loss = 1.794037, validation loss = 3.074359
2018-12-05 06:02:38,373 - INFO - epoch 1, step 38970, training loss = 2.865826, validation loss = 3.336924
2018-12-05 06:02:42,481 - INFO - epoch 1, step 38980, training loss = 3.392562, validation loss = 2.857380
2018-12-05 06:02:46,429 - INFO - epoch 1, step 38990, training loss = 3.240450, validation loss = 2.825790
2018-12-05 06:02:50,600 - INFO - epoch 1, step 39000, training loss = 2.595000, validation loss = 2.534874
2018-12-05 06:02:54,582 - INFO - epoch 1, step 39010, training loss = 2.643411, validation loss = 2.935112
2018-12-05 06:02:59,268 - INFO - epoch 1, step 39020, training loss = 2.733840, validation loss = 3.065696
2018-12-05 06:03:05,326 - INFO - epoch 1, step 39030, training loss = 2.463495, validation loss = 2.988378
2018-12-05 06:03:10,851 - INFO - epoch 1, step 39040, training loss = 2.305348, validation loss = 3.630257
2018-12-05 06:03:16,085 - INFO - epoch 1, step 39050, training loss = 2.209939, validation loss = 2.894341
2018-12-05 06:03:21,540 - INFO - epoch 1, step 39060, training loss = 2.116225, validation loss = 2.608286
2018-12-05 06:03:26,773 - INFO - epoch 1, step 39070, training loss = 2.149840, validation loss = 2.767335
2018-12-05 06:03:31,923 - INFO - epoch 1, step 39080, training loss = 2.374685, validation loss = 2.772167
2018-12-05 06:03:36,805 - INFO - epoch 1, step 39090, training loss = 2.072529, validation loss = 2.684122
2018-12-05 06:03:41,886 - INFO - epoch 1, step 39100, training loss = 2.618458, validation loss = 2.362526
2018-12-05 06:03:46,050 - INFO - epoch 1, step 39110, training loss = 3.056591, validation loss = 2.654674
2018-12-05 06:03:49,982 - INFO - epoch 1, step 39120, training loss = 2.976028, validation loss = 3.049542
2018-12-05 06:03:54,154 - INFO - epoch 1, step 39130, training loss = 3.062447, validation loss = 2.781960
2018-12-05 06:03:58,525 - INFO - epoch 1, step 39140, training loss = 2.840212, validation loss = 3.524228
2018-12-05 06:04:02,942 - INFO - epoch 1, step 39150, training loss = 3.041697, validation loss = 2.340578
2018-12-05 06:04:07,059 - INFO - epoch 1, step 39160, training loss = 2.805046, validation loss = 2.522199
2018-12-05 06:04:11,102 - INFO - epoch 1, step 39170, training loss = 3.125311, validation loss = 2.579145
2018-12-05 06:04:15,344 - INFO - epoch 1, step 39180, training loss = 2.388522, validation loss = 2.956096
2018-12-05 06:04:19,327 - INFO - epoch 1, step 39190, training loss = 2.926019, validation loss = 2.678782
2018-12-05 06:04:23,672 - INFO - epoch 1, step 39200, training loss = 2.678196, validation loss = 3.522769
2018-12-05 06:04:28,936 - INFO - epoch 1, step 39210, training loss = 2.327657, validation loss = 3.339107
2018-12-05 06:04:33,647 - INFO - epoch 1, step 39220, training loss = 2.691350, validation loss = 3.039301
2018-12-05 06:04:39,049 - INFO - epoch 1, step 39230, training loss = 2.625282, validation loss = 2.775908
2018-12-05 06:04:44,564 - INFO - epoch 1, step 39240, training loss = 2.169828, validation loss = 2.653543
2018-12-05 06:04:49,839 - INFO - epoch 1, step 39250, training loss = 2.135609, validation loss = 3.028784
2018-12-05 06:04:54,935 - INFO - epoch 1, step 39260, training loss = 2.204950, validation loss = 2.975257
2018-12-05 06:05:00,264 - INFO - epoch 1, step 39270, training loss = 2.194393, validation loss = 2.550485
2018-12-05 06:05:05,124 - INFO - epoch 1, step 39280, training loss = 2.881898, validation loss = 2.780349
2018-12-05 06:05:10,486 - INFO - epoch 1, step 39290, training loss = 2.413218, validation loss = 3.047889
2018-12-05 06:05:15,606 - INFO - epoch 1, step 39300, training loss = 1.913783, validation loss = 2.579209
2018-12-05 06:05:20,408 - INFO - epoch 1, step 39310, training loss = 2.851657, validation loss = 2.671541
2018-12-05 06:05:24,845 - INFO - epoch 1, step 39320, training loss = 2.176012, validation loss = 2.824053
2018-12-05 06:05:30,013 - INFO - epoch 1, step 39330, training loss = 2.232643, validation loss = 2.829036
2018-12-05 06:05:34,061 - INFO - epoch 1, step 39340, training loss = 2.843535, validation loss = 2.893823
2018-12-05 06:05:37,638 - INFO - epoch 1, step 39350, training loss = 2.903726, validation loss = 2.850673
2018-12-05 06:05:41,354 - INFO - epoch 1, step 39360, training loss = 2.798310, validation loss = 3.260851
2018-12-05 06:05:45,212 - INFO - epoch 1, step 39370, training loss = 2.536154, validation loss = 2.878937
2018-12-05 06:05:48,852 - INFO - epoch 1, step 39380, training loss = 3.276415, validation loss = 2.430902
2018-12-05 06:05:52,462 - INFO - epoch 1, step 39390, training loss = 2.581266, validation loss = 2.384196
2018-12-05 06:05:57,033 - INFO - epoch 1, step 39400, training loss = 2.530951, validation loss = 2.620817
2018-12-05 06:06:02,633 - INFO - epoch 1, step 39410, training loss = 2.497458, validation loss = 2.972008
2018-12-05 06:06:08,095 - INFO - epoch 1, step 39420, training loss = 2.099388, validation loss = 2.779255
2018-12-05 06:06:13,327 - INFO - epoch 1, step 39430, training loss = 3.024158, validation loss = 2.819404
2018-12-05 06:06:18,914 - INFO - epoch 1, step 39440, training loss = 2.287565, validation loss = 2.661319
2018-12-05 06:06:24,145 - INFO - epoch 1, step 39450, training loss = 2.167674, validation loss = 2.563179
2018-12-05 06:06:29,654 - INFO - epoch 1, step 39460, training loss = 1.760557, validation loss = 2.518815
2018-12-05 06:06:35,000 - INFO - epoch 1, step 39470, training loss = 2.518523, validation loss = 2.774285
2018-12-05 06:06:39,250 - INFO - epoch 1, step 39480, training loss = 2.479671, validation loss = 3.002771
2018-12-05 06:06:42,887 - INFO - epoch 1, step 39490, training loss = 2.800525, validation loss = 2.801968
2018-12-05 06:06:46,609 - INFO - epoch 1, step 39500, training loss = 3.065777, validation loss = 3.149998
2018-12-05 06:06:50,595 - INFO - epoch 1, step 39510, training loss = 2.996927, validation loss = 2.634334
2018-12-05 06:06:54,625 - INFO - epoch 1, step 39520, training loss = 2.855630, validation loss = 2.521008
2018-12-05 06:06:58,660 - INFO - epoch 1, step 39530, training loss = 2.935785, validation loss = 3.128868
2018-12-05 06:07:03,858 - INFO - epoch 1, step 39540, training loss = 2.233980, validation loss = 2.895955
2018-12-05 06:07:09,076 - INFO - epoch 1, step 39550, training loss = 2.024683, validation loss = 3.021722
2018-12-05 06:07:13,903 - INFO - epoch 1, step 39560, training loss = 2.362217, validation loss = 3.177065
2018-12-05 06:07:18,803 - INFO - epoch 1, step 39570, training loss = 2.629676, validation loss = 2.970311
2018-12-05 06:07:23,932 - INFO - epoch 1, step 39580, training loss = 2.039572, validation loss = 2.954907
2018-12-05 06:07:29,501 - INFO - epoch 1, step 39590, training loss = 2.211049, validation loss = 2.950901
2018-12-05 06:07:34,786 - INFO - epoch 1, step 39600, training loss = 2.390123, validation loss = 3.198065
2018-12-05 06:07:40,250 - INFO - epoch 1, step 39610, training loss = 2.049561, validation loss = 3.334093
2018-12-05 06:07:45,086 - INFO - epoch 1, step 39620, training loss = 2.617289, validation loss = 2.937514
2018-12-05 06:07:50,537 - INFO - epoch 1, step 39630, training loss = 1.688618, validation loss = 2.393137
2018-12-05 06:07:55,369 - INFO - epoch 1, step 39640, training loss = 2.417446, validation loss = 2.694759
2018-12-05 06:08:01,141 - INFO - epoch 1, step 39650, training loss = 2.331430, validation loss = 2.915852
2018-12-05 06:08:06,889 - INFO - epoch 1, step 39660, training loss = 1.751867, validation loss = 2.816159
2018-12-05 06:08:12,282 - INFO - epoch 1, step 39670, training loss = 2.462788, validation loss = 3.370319
2018-12-05 06:08:17,729 - INFO - epoch 1, step 39680, training loss = 2.710735, validation loss = 3.345426
2018-12-05 06:08:23,600 - INFO - epoch 1, step 39690, training loss = 1.761249, validation loss = 2.867462
2018-12-05 06:08:28,424 - INFO - epoch 1, step 39700, training loss = 2.780972, validation loss = 2.545998
2018-12-05 06:08:33,850 - INFO - epoch 1, step 39710, training loss = 2.645548, validation loss = 2.911454
2018-12-05 06:08:39,115 - INFO - epoch 1, step 39720, training loss = 2.196555, validation loss = 2.718181
2018-12-05 06:08:44,673 - INFO - epoch 1, step 39730, training loss = 2.799745, validation loss = 3.137802
2018-12-05 06:08:48,424 - INFO - epoch 1, step 39740, training loss = 3.008203, validation loss = 3.107986
2018-12-05 06:08:52,361 - INFO - epoch 1, step 39750, training loss = 2.916319, validation loss = 2.800044
2018-12-05 06:08:56,286 - INFO - epoch 1, step 39760, training loss = 2.785719, validation loss = 3.047471
2018-12-05 06:09:00,273 - INFO - epoch 1, step 39770, training loss = 2.901273, validation loss = 2.957182
2018-12-05 06:09:03,930 - INFO - epoch 1, step 39780, training loss = 2.918190, validation loss = 2.307551
2018-12-05 06:09:07,869 - INFO - epoch 1, step 39790, training loss = 3.138526, validation loss = 2.480298
2018-12-05 06:09:11,797 - INFO - epoch 1, step 39800, training loss = 2.791431, validation loss = 2.723027
2018-12-05 06:09:16,059 - INFO - epoch 1, step 39810, training loss = 2.971161, validation loss = 2.925825
2018-12-05 06:09:20,001 - INFO - epoch 1, step 39820, training loss = 2.919449, validation loss = 3.244868
2018-12-05 06:09:24,134 - INFO - epoch 1, step 39830, training loss = 3.159008, validation loss = 3.174200
2018-12-05 06:09:28,288 - INFO - epoch 1, step 39840, training loss = 2.799841, validation loss = 3.252622
2018-12-05 06:09:32,173 - INFO - epoch 1, step 39850, training loss = 3.038017, validation loss = 2.838286
2018-12-05 06:09:36,197 - INFO - epoch 1, step 39860, training loss = 3.113003, validation loss = 3.002191
2018-12-05 06:09:40,244 - INFO - epoch 1, step 39870, training loss = 2.713632, validation loss = 3.117061
2018-12-05 06:09:45,289 - INFO - epoch 1, step 39880, training loss = 3.066799, validation loss = 3.044162
2018-12-05 06:09:50,411 - INFO - epoch 1, step 39890, training loss = 2.685257, validation loss = 3.074951
2018-12-05 06:09:55,913 - INFO - epoch 1, step 39900, training loss = 2.259906, validation loss = 3.078855
2018-12-05 06:10:00,736 - INFO - epoch 1, step 39910, training loss = 2.386783, validation loss = 3.121320
2018-12-05 06:10:06,224 - INFO - epoch 1, step 39920, training loss = 2.015085, validation loss = 2.407070
2018-12-05 06:10:11,555 - INFO - epoch 1, step 39930, training loss = 1.879320, validation loss = 2.602190
2018-12-05 06:10:16,624 - INFO - epoch 1, step 39940, training loss = 1.940520, validation loss = 2.262581
2018-12-05 06:10:22,091 - INFO - epoch 1, step 39950, training loss = 2.413151, validation loss = 2.753428
2018-12-05 06:10:27,484 - INFO - epoch 1, step 39960, training loss = 2.035613, validation loss = 2.925324
2018-12-05 06:10:32,874 - INFO - epoch 1, step 39970, training loss = 2.760172, validation loss = 2.785386
2018-12-05 06:10:37,265 - INFO - epoch 1, step 39980, training loss = 2.838179, validation loss = 2.798652
2018-12-05 06:10:41,148 - INFO - epoch 1, step 39990, training loss = 3.228828, validation loss = 2.977706
2018-12-05 06:10:44,995 - INFO - epoch 1, step 40000, training loss = 2.786812, validation loss = 2.120838
2018-12-05 06:10:48,692 - INFO - epoch 1, step 40010, training loss = 3.130431, validation loss = 2.178957
2018-12-05 06:10:52,455 - INFO - epoch 1, step 40020, training loss = 3.054512, validation loss = 2.557804
2018-12-05 06:10:56,532 - INFO - epoch 1, step 40030, training loss = 3.227401, validation loss = 2.471175
2018-12-05 06:11:00,571 - INFO - epoch 1, step 40040, training loss = 2.669167, validation loss = 2.311298
2018-12-05 06:11:04,653 - INFO - epoch 1, step 40050, training loss = 3.278916, validation loss = 3.049606
2018-12-05 06:11:08,802 - INFO - epoch 1, step 40060, training loss = 3.069660, validation loss = 2.943711
2018-12-05 06:11:12,759 - INFO - epoch 1, step 40070, training loss = 2.520501, validation loss = 2.204788
2018-12-05 06:11:16,880 - INFO - epoch 1, step 40080, training loss = 2.782734, validation loss = 2.142575
2018-12-05 06:11:20,987 - INFO - epoch 1, step 40090, training loss = 3.126051, validation loss = 1.902761
2018-12-05 06:11:25,306 - INFO - epoch 1, step 40100, training loss = 3.088288, validation loss = 1.715791
2018-12-05 06:11:28,976 - INFO - epoch 1, step 40110, training loss = 2.741886, validation loss = 2.440518
2018-12-05 06:11:32,793 - INFO - epoch 1, step 40120, training loss = 3.012610, validation loss = 2.172210
2018-12-05 06:11:36,691 - INFO - epoch 1, step 40130, training loss = 2.744847, validation loss = 1.997827
2018-12-05 06:11:40,656 - INFO - epoch 1, step 40140, training loss = 2.865374, validation loss = 2.433033
2018-12-05 06:11:44,470 - INFO - epoch 1, step 40150, training loss = 3.153630, validation loss = 2.307257
2018-12-05 06:11:48,445 - INFO - epoch 1, step 40160, training loss = 2.594167, validation loss = 2.468018
2018-12-05 06:11:52,291 - INFO - epoch 1, step 40170, training loss = 2.998132, validation loss = 2.537268
2018-12-05 06:11:56,489 - INFO - epoch 1, step 40180, training loss = 2.739469, validation loss = 1.970099
2018-12-05 06:12:00,536 - INFO - epoch 1, step 40190, training loss = 3.068458, validation loss = 2.112004
2018-12-05 06:12:04,265 - INFO - epoch 1, step 40200, training loss = 2.804432, validation loss = 2.047364
2018-12-05 06:12:08,226 - INFO - epoch 1, step 40210, training loss = 2.693428, validation loss = 2.237410
2018-12-05 06:12:11,903 - INFO - epoch 1, step 40220, training loss = 2.960881, validation loss = 2.972691
2018-12-05 06:12:15,934 - INFO - epoch 1, step 40230, training loss = 3.047765, validation loss = 2.445020
2018-12-05 06:12:19,956 - INFO - epoch 1, step 40240, training loss = 2.925564, validation loss = 2.508249
2018-12-05 06:12:24,058 - INFO - epoch 1, step 40250, training loss = 2.401858, validation loss = 2.585149
2018-12-05 06:12:28,225 - INFO - epoch 1, step 40260, training loss = 2.376781, validation loss = 1.954662
2018-12-05 06:12:32,368 - INFO - epoch 1, step 40270, training loss = 2.109347, validation loss = 1.921393
2018-12-05 06:12:36,695 - INFO - epoch 1, step 40280, training loss = 2.721993, validation loss = 2.306837
2018-12-05 06:12:41,253 - INFO - epoch 1, step 40290, training loss = 2.539445, validation loss = 2.314820
2018-12-05 06:12:45,518 - INFO - epoch 1, step 40300, training loss = 2.840371, validation loss = 2.028633
2018-12-05 06:12:49,901 - INFO - epoch 1, step 40310, training loss = 2.716271, validation loss = 2.185009
2018-12-05 06:12:53,706 - INFO - epoch 1, step 40320, training loss = 2.992641, validation loss = 2.515348
2018-12-05 06:12:57,427 - INFO - epoch 1, step 40330, training loss = 2.800812, validation loss = 2.138523
2018-12-05 06:13:01,683 - INFO - epoch 1, step 40340, training loss = 2.695755, validation loss = 2.170280
2018-12-05 06:13:05,577 - INFO - epoch 1, step 40350, training loss = 2.956539, validation loss = 1.915135
2018-12-05 06:13:09,523 - INFO - epoch 1, step 40360, training loss = 3.449424, validation loss = 2.720181
2018-12-05 06:13:13,370 - INFO - epoch 1, step 40370, training loss = 2.957976, validation loss = 2.164651
2018-12-05 06:13:17,464 - INFO - epoch 1, step 40380, training loss = 2.282762, validation loss = 2.524946
2018-12-05 06:13:21,336 - INFO - epoch 1, step 40390, training loss = 2.941684, validation loss = 2.294830
2018-12-05 06:13:25,194 - INFO - epoch 1, step 40400, training loss = 2.809657, validation loss = 1.896358
2018-12-05 06:13:29,288 - INFO - epoch 1, step 40410, training loss = 3.375923, validation loss = 2.188964
2018-12-05 06:13:33,395 - INFO - epoch 1, step 40420, training loss = 2.503863, validation loss = 2.535643
2018-12-05 06:13:38,787 - INFO - epoch 1, step 40430, training loss = 2.439350, validation loss = 2.502120
2018-12-05 06:13:44,263 - INFO - epoch 1, step 40440, training loss = 2.593951, validation loss = 2.539839
2018-12-05 06:13:49,660 - INFO - epoch 1, step 40450, training loss = 2.377209, validation loss = 1.995402
2018-12-05 06:13:53,833 - INFO - epoch 1, step 40460, training loss = 2.836717, validation loss = 2.330205
2018-12-05 06:13:57,596 - INFO - epoch 1, step 40470, training loss = 2.829459, validation loss = 2.363926
2018-12-05 06:14:01,469 - INFO - epoch 1, step 40480, training loss = 3.548282, validation loss = 2.530141
2018-12-05 06:14:05,192 - INFO - epoch 1, step 40490, training loss = 2.581087, validation loss = 2.478403
2018-12-05 06:14:08,853 - INFO - epoch 1, step 40500, training loss = 2.481808, validation loss = 2.538155
2018-12-05 06:14:12,684 - INFO - epoch 1, step 40510, training loss = 2.422668, validation loss = 2.586808
2018-12-05 06:14:16,636 - INFO - epoch 1, step 40520, training loss = 2.739524, validation loss = 2.158258
2018-12-05 06:14:20,503 - INFO - epoch 1, step 40530, training loss = 2.313534, validation loss = 2.613333
2018-12-05 06:14:24,297 - INFO - epoch 1, step 40540, training loss = 2.760537, validation loss = 2.814452
2018-12-05 06:14:28,359 - INFO - epoch 1, step 40550, training loss = 3.065468, validation loss = 2.666907
2018-12-05 06:14:32,304 - INFO - epoch 1, step 40560, training loss = 2.609551, validation loss = 2.685856
2018-12-05 06:14:36,582 - INFO - epoch 1, step 40570, training loss = 2.338142, validation loss = 2.309667
2018-12-05 06:14:41,790 - INFO - epoch 1, step 40580, training loss = 1.931318, validation loss = 2.471899
2018-12-05 06:14:47,020 - INFO - epoch 1, step 40590, training loss = 3.008466, validation loss = 1.977492
2018-12-05 06:14:52,201 - INFO - epoch 1, step 40600, training loss = 2.392376, validation loss = 2.156116
2018-12-05 06:14:57,307 - INFO - epoch 1, step 40610, training loss = 1.919480, validation loss = 2.261372
2018-12-05 06:15:02,593 - INFO - epoch 1, step 40620, training loss = 2.336432, validation loss = 2.440982
2018-12-05 06:15:07,715 - INFO - epoch 1, step 40630, training loss = 2.000401, validation loss = 2.422601
2018-12-05 06:15:12,885 - INFO - epoch 1, step 40640, training loss = 2.586890, validation loss = 2.518420
2018-12-05 06:15:18,201 - INFO - epoch 1, step 40650, training loss = 2.701313, validation loss = 2.370744
2018-12-05 06:15:23,737 - INFO - epoch 1, step 40660, training loss = 2.451175, validation loss = 2.216528
2018-12-05 06:15:29,266 - INFO - epoch 1, step 40670, training loss = 2.454969, validation loss = 2.456677
2018-12-05 06:15:34,658 - INFO - epoch 1, step 40680, training loss = 2.551217, validation loss = 1.777106
2018-12-05 06:15:40,297 - INFO - epoch 1, step 40690, training loss = 2.486575, validation loss = 2.548420
2018-12-05 06:15:44,686 - INFO - epoch 1, step 40700, training loss = 2.524403, validation loss = 2.550882
2018-12-05 06:15:49,016 - INFO - epoch 1, step 40710, training loss = 2.301643, validation loss = 2.655314
2018-12-05 06:15:53,370 - INFO - epoch 1, step 40720, training loss = 3.077234, validation loss = 2.149115
2018-12-05 06:15:57,638 - INFO - epoch 1, step 40730, training loss = 2.704392, validation loss = 2.465903
2018-12-05 06:16:01,978 - INFO - epoch 1, step 40740, training loss = 2.578760, validation loss = 2.489967
2018-12-05 06:16:06,074 - INFO - epoch 1, step 40750, training loss = 3.059068, validation loss = 3.032596
2018-12-05 06:16:10,544 - INFO - epoch 1, step 40760, training loss = 2.075650, validation loss = 1.685692
2018-12-05 06:16:14,811 - INFO - epoch 1, step 40770, training loss = 2.816043, validation loss = 2.475598
2018-12-05 06:16:18,817 - INFO - epoch 1, step 40780, training loss = 2.858597, validation loss = 2.190251
2018-12-05 06:16:22,950 - INFO - epoch 1, step 40790, training loss = 2.708128, validation loss = 1.961853
2018-12-05 06:16:26,814 - INFO - epoch 1, step 40800, training loss = 2.772619, validation loss = 2.637118
2018-12-05 06:16:31,066 - INFO - epoch 1, step 40810, training loss = 2.919333, validation loss = 2.415894
2018-12-05 06:16:35,241 - INFO - epoch 1, step 40820, training loss = 3.021928, validation loss = 2.583358
2018-12-05 06:16:39,695 - INFO - epoch 1, step 40830, training loss = 2.525561, validation loss = 2.852485
2018-12-05 06:16:43,790 - INFO - epoch 1, step 40840, training loss = 2.849147, validation loss = 2.273431
2018-12-05 06:16:48,106 - INFO - epoch 1, step 40850, training loss = 2.341723, validation loss = 2.209552
2018-12-05 06:16:51,943 - INFO - epoch 1, step 40860, training loss = 2.554383, validation loss = 2.480108
2018-12-05 06:16:55,851 - INFO - epoch 1, step 40870, training loss = 3.255261, validation loss = 2.352498
2018-12-05 06:16:59,772 - INFO - epoch 1, step 40880, training loss = 2.797953, validation loss = 2.505762
2018-12-05 06:17:03,829 - INFO - epoch 1, step 40890, training loss = 2.755402, validation loss = 2.310161
2018-12-05 06:17:07,823 - INFO - epoch 1, step 40900, training loss = 2.815891, validation loss = 2.710562
2018-12-05 06:17:11,834 - INFO - epoch 1, step 40910, training loss = 2.957912, validation loss = 2.872360
2018-12-05 06:17:15,700 - INFO - epoch 1, step 40920, training loss = 2.187957, validation loss = 2.097416
2018-12-05 06:17:19,612 - INFO - epoch 1, step 40930, training loss = 3.068439, validation loss = 2.295151
2018-12-05 06:17:23,464 - INFO - epoch 1, step 40940, training loss = 3.148038, validation loss = 2.262119
2018-12-05 06:17:27,413 - INFO - epoch 1, step 40950, training loss = 3.077605, validation loss = 2.244584
2018-12-05 06:17:31,644 - INFO - epoch 1, step 40960, training loss = 1.981817, validation loss = 2.523788
2018-12-05 06:17:35,491 - INFO - epoch 1, step 40970, training loss = 2.657850, validation loss = 2.644162
2018-12-05 06:17:39,493 - INFO - epoch 1, step 40980, training loss = 2.933604, validation loss = 2.347617
2018-12-05 06:17:43,668 - INFO - epoch 1, step 40990, training loss = 2.579960, validation loss = 2.268477
2018-12-05 06:17:47,761 - INFO - epoch 1, step 41000, training loss = 2.587592, validation loss = 2.612527
2018-12-05 06:17:52,077 - INFO - epoch 1, step 41010, training loss = 2.570029, validation loss = 2.526788
2018-12-05 06:17:56,390 - INFO - epoch 1, step 41020, training loss = 2.517190, validation loss = 2.144497
2018-12-05 06:18:00,568 - INFO - epoch 1, step 41030, training loss = 2.733419, validation loss = 2.815052
2018-12-05 06:18:04,563 - INFO - epoch 1, step 41040, training loss = 2.841805, validation loss = 2.736966
2018-12-05 06:18:08,719 - INFO - epoch 1, step 41050, training loss = 2.465992, validation loss = 2.595776
2018-12-05 06:18:12,636 - INFO - epoch 1, step 41060, training loss = 2.527981, validation loss = 2.127008
2018-12-05 06:18:16,807 - INFO - epoch 1, step 41070, training loss = 2.584976, validation loss = 2.425413
2018-12-05 06:18:20,792 - INFO - epoch 1, step 41080, training loss = 2.548606, validation loss = 2.059199
2018-12-05 06:18:25,041 - INFO - epoch 1, step 41090, training loss = 2.754640, validation loss = 2.772046
2018-12-05 06:18:28,945 - INFO - epoch 1, step 41100, training loss = 3.317303, validation loss = 2.679332
2018-12-05 06:18:33,002 - INFO - epoch 1, step 41110, training loss = 2.502819, validation loss = 2.552229
2018-12-05 06:18:36,826 - INFO - epoch 1, step 41120, training loss = 2.618833, validation loss = 2.756042
2018-12-05 06:18:40,896 - INFO - epoch 1, step 41130, training loss = 3.290698, validation loss = 2.486797
2018-12-05 06:18:44,918 - INFO - epoch 1, step 41140, training loss = 2.929744, validation loss = 2.446008
2018-12-05 06:18:48,781 - INFO - epoch 1, step 41150, training loss = 2.737312, validation loss = 3.060486
2018-12-05 06:18:52,788 - INFO - epoch 1, step 41160, training loss = 2.862036, validation loss = 3.084657
2018-12-05 06:18:57,002 - INFO - epoch 1, step 41170, training loss = 2.598139, validation loss = 2.632710
2018-12-05 06:19:00,920 - INFO - epoch 1, step 41180, training loss = 2.286907, validation loss = 2.731096
2018-12-05 06:19:04,975 - INFO - epoch 1, step 41190, training loss = 2.594380, validation loss = 2.334565
2018-12-05 06:19:08,911 - INFO - epoch 1, step 41200, training loss = 2.825708, validation loss = 2.640192
2018-12-05 06:19:13,307 - INFO - epoch 1, step 41210, training loss = 2.846908, validation loss = 2.433011
2018-12-05 06:19:17,371 - INFO - epoch 1, step 41220, training loss = 2.936897, validation loss = 2.181079
2018-12-05 06:19:21,344 - INFO - epoch 1, step 41230, training loss = 2.628684, validation loss = 2.366875
2018-12-05 06:19:25,297 - INFO - epoch 1, step 41240, training loss = 2.434169, validation loss = 2.717028
2018-12-05 06:19:29,431 - INFO - epoch 1, step 41250, training loss = 2.854071, validation loss = 2.190226
2018-12-05 06:19:33,467 - INFO - epoch 1, step 41260, training loss = 2.554506, validation loss = 2.792934
2018-12-05 06:19:37,771 - INFO - epoch 1, step 41270, training loss = 2.703956, validation loss = 1.998381
2018-12-05 06:19:41,529 - INFO - epoch 1, step 41280, training loss = 3.248919, validation loss = 2.386945
2018-12-05 06:19:45,424 - INFO - epoch 1, step 41290, training loss = 3.349299, validation loss = 2.515332
2018-12-05 06:19:49,543 - INFO - epoch 1, step 41300, training loss = 2.662673, validation loss = 2.626878
2018-12-05 06:19:53,525 - INFO - epoch 1, step 41310, training loss = 2.965760, validation loss = 2.293126
2018-12-05 06:19:57,506 - INFO - epoch 1, step 41320, training loss = 2.600631, validation loss = 2.234728
2018-12-05 06:20:01,467 - INFO - epoch 1, step 41330, training loss = 2.737478, validation loss = 2.561182
2018-12-05 06:20:05,432 - INFO - epoch 1, step 41340, training loss = 3.186268, validation loss = 2.491010
2018-12-05 06:20:09,363 - INFO - epoch 1, step 41350, training loss = 2.548450, validation loss = 2.535141
2018-12-05 06:20:13,155 - INFO - epoch 1, step 41360, training loss = 2.789592, validation loss = 2.186280
2018-12-05 06:20:16,995 - INFO - epoch 1, step 41370, training loss = 2.588006, validation loss = 2.362273
2018-12-05 06:20:22,239 - INFO - epoch 1, step 41380, training loss = 2.305272, validation loss = 2.528256
2018-12-05 06:20:27,516 - INFO - epoch 1, step 41390, training loss = 2.807006, validation loss = 2.672494
2018-12-05 06:20:32,774 - INFO - epoch 1, step 41400, training loss = 2.530874, validation loss = 2.090981
2018-12-05 06:20:38,025 - INFO - epoch 1, step 41410, training loss = 2.742160, validation loss = 2.507022
2018-12-05 06:20:43,925 - INFO - epoch 1, step 41420, training loss = 2.004829, validation loss = 2.103282
2018-12-05 06:20:50,016 - INFO - epoch 1, step 41430, training loss = 2.021104, validation loss = 2.781904
2018-12-05 06:20:54,972 - INFO - epoch 1, step 41440, training loss = 2.224592, validation loss = 2.356565
2018-12-05 06:21:00,486 - INFO - epoch 1, step 41450, training loss = 2.663588, validation loss = 2.806252
2018-12-05 06:21:06,001 - INFO - epoch 1, step 41460, training loss = 2.201468, validation loss = 2.437589
2018-12-05 06:21:11,273 - INFO - epoch 1, step 41470, training loss = 2.584323, validation loss = 2.684599
2018-12-05 06:21:16,836 - INFO - epoch 1, step 41480, training loss = 2.373190, validation loss = 2.390113
2018-12-05 06:21:21,626 - INFO - epoch 1, step 41490, training loss = 2.925265, validation loss = 2.104417
2018-12-05 06:21:25,791 - INFO - epoch 1, step 41500, training loss = 2.728966, validation loss = 2.338660
2018-12-05 06:21:30,064 - INFO - epoch 1, step 41510, training loss = 2.632458, validation loss = 2.010852
2018-12-05 06:21:34,197 - INFO - epoch 1, step 41520, training loss = 2.916834, validation loss = 2.398071
2018-12-05 06:21:38,510 - INFO - epoch 1, step 41530, training loss = 2.845515, validation loss = 2.468796
2018-12-05 06:21:42,865 - INFO - epoch 1, step 41540, training loss = 2.997682, validation loss = 2.219553
2018-12-05 06:21:46,914 - INFO - epoch 1, step 41550, training loss = 3.152980, validation loss = 2.055404
2018-12-05 06:21:51,588 - INFO - epoch 1, step 41560, training loss = 2.706651, validation loss = 2.444397
2018-12-05 06:21:57,522 - INFO - epoch 1, step 41570, training loss = 2.438298, validation loss = 2.323195
2018-12-05 06:22:02,711 - INFO - epoch 1, step 41580, training loss = 2.319496, validation loss = 2.331641
2018-12-05 06:22:08,108 - INFO - epoch 1, step 41590, training loss = 1.609217, validation loss = 2.665746
2018-12-05 06:22:13,401 - INFO - epoch 1, step 41600, training loss = 2.325935, validation loss = 2.287153
2018-12-05 06:22:18,597 - INFO - epoch 1, step 41610, training loss = 1.651224, validation loss = 2.343940
2018-12-05 06:22:23,776 - INFO - epoch 1, step 41620, training loss = 2.426031, validation loss = 2.968417
2018-12-05 06:22:29,509 - INFO - epoch 1, step 41630, training loss = 1.793386, validation loss = 2.634526
2018-12-05 06:22:34,463 - INFO - epoch 1, step 41640, training loss = 2.589277, validation loss = 2.179899
2018-12-05 06:22:38,637 - INFO - epoch 1, step 41650, training loss = 2.588259, validation loss = 2.090816
2018-12-05 06:22:42,670 - INFO - epoch 1, step 41660, training loss = 2.785799, validation loss = 2.676925
2018-12-05 06:22:46,786 - INFO - epoch 1, step 41670, training loss = 2.933279, validation loss = 2.861722
2018-12-05 06:22:51,023 - INFO - epoch 1, step 41680, training loss = 2.461985, validation loss = 2.129539
2018-12-05 06:22:55,216 - INFO - epoch 1, step 41690, training loss = 2.985655, validation loss = 1.961647
2018-12-05 06:22:59,284 - INFO - epoch 1, step 41700, training loss = 2.228417, validation loss = 2.354890
2018-12-05 06:23:03,483 - INFO - epoch 1, step 41710, training loss = 2.900299, validation loss = 2.518357
2018-12-05 06:23:07,545 - INFO - epoch 1, step 41720, training loss = 2.634476, validation loss = 2.467941
2018-12-05 06:23:12,156 - INFO - epoch 1, step 41730, training loss = 2.372479, validation loss = 2.196539
2018-12-05 06:23:17,780 - INFO - epoch 1, step 41740, training loss = 1.892792, validation loss = 1.785164
2018-12-05 06:23:23,060 - INFO - epoch 1, step 41750, training loss = 2.164714, validation loss = 1.980558
2018-12-05 06:23:28,451 - INFO - epoch 1, step 41760, training loss = 2.481685, validation loss = 2.449398
2018-12-05 06:23:32,407 - INFO - epoch 1, step 41770, training loss = 2.811935, validation loss = 1.921322
2018-12-05 06:23:36,427 - INFO - epoch 1, step 41780, training loss = 3.082854, validation loss = 2.775450
2018-12-05 06:23:40,485 - INFO - epoch 1, step 41790, training loss = 2.949125, validation loss = 2.515867
2018-12-05 06:23:44,438 - INFO - epoch 1, step 41800, training loss = 3.079970, validation loss = 2.430316
2018-12-05 06:23:48,482 - INFO - epoch 1, step 41810, training loss = 2.882387, validation loss = 2.430971
2018-12-05 06:23:52,367 - INFO - epoch 1, step 41820, training loss = 2.575886, validation loss = 2.718785
2018-12-05 06:23:56,533 - INFO - epoch 1, step 41830, training loss = 2.879850, validation loss = 2.660303
2018-12-05 06:24:00,457 - INFO - epoch 1, step 41840, training loss = 2.705693, validation loss = 2.343720
2018-12-05 06:24:04,549 - INFO - epoch 1, step 41850, training loss = 2.829857, validation loss = 2.325063
2018-12-05 06:24:08,436 - INFO - epoch 1, step 41860, training loss = 2.973473, validation loss = 2.577875
2018-12-05 06:24:12,338 - INFO - epoch 1, step 41870, training loss = 2.955590, validation loss = 2.638158
2018-12-05 06:24:16,151 - INFO - epoch 1, step 41880, training loss = 2.700467, validation loss = 2.388864
2018-12-05 06:24:20,054 - INFO - epoch 1, step 41890, training loss = 3.009613, validation loss = 2.112769
2018-12-05 06:24:24,857 - INFO - epoch 1, step 41900, training loss = 2.184761, validation loss = 2.262148
2018-12-05 06:24:30,653 - INFO - epoch 1, step 41910, training loss = 2.130819, validation loss = 2.401054
2018-12-05 06:24:35,891 - INFO - epoch 1, step 41920, training loss = 2.555010, validation loss = 3.023500
2018-12-05 06:24:40,968 - INFO - epoch 1, step 41930, training loss = 2.408477, validation loss = 2.772822
2018-12-05 06:24:46,060 - INFO - epoch 1, step 41940, training loss = 2.612757, validation loss = 3.090684
2018-12-05 06:24:51,391 - INFO - epoch 1, step 41950, training loss = 2.149017, validation loss = 2.520646
2018-12-05 06:24:56,726 - INFO - epoch 1, step 41960, training loss = 2.026612, validation loss = 2.885527
2018-12-05 06:25:02,153 - INFO - epoch 1, step 41970, training loss = 2.767856, validation loss = 2.556067
2018-12-05 06:25:07,608 - INFO - epoch 1, step 41980, training loss = 2.258473, validation loss = 3.128690
2018-12-05 06:25:13,325 - INFO - epoch 1, step 41990, training loss = 1.811110, validation loss = 2.655915
2018-12-05 06:25:17,299 - INFO - epoch 1, step 42000, training loss = 2.501691, validation loss = 2.423069
2018-12-05 06:25:21,174 - INFO - epoch 1, step 42010, training loss = 2.876472, validation loss = 2.717166
2018-12-05 06:25:25,135 - INFO - epoch 1, step 42020, training loss = 2.868962, validation loss = 3.007746
2018-12-05 06:25:29,289 - INFO - epoch 1, step 42030, training loss = 2.619067, validation loss = 2.405617
2018-12-05 06:25:33,007 - INFO - epoch 1, step 42040, training loss = 2.928505, validation loss = 2.321856
2018-12-05 06:25:36,971 - INFO - epoch 1, step 42050, training loss = 3.094362, validation loss = 2.789121
2018-12-05 06:25:41,199 - INFO - epoch 1, step 42060, training loss = 2.991901, validation loss = 2.395488
2018-12-05 06:25:45,386 - INFO - epoch 1, step 42070, training loss = 2.661421, validation loss = 2.660961
2018-12-05 06:25:49,420 - INFO - epoch 1, step 42080, training loss = 3.197532, validation loss = 2.825063
2018-12-05 06:25:53,360 - INFO - epoch 1, step 42090, training loss = 2.676288, validation loss = 3.061084
2018-12-05 06:25:57,461 - INFO - epoch 1, step 42100, training loss = 2.762955, validation loss = 2.862503
2018-12-05 06:26:01,500 - INFO - epoch 1, step 42110, training loss = 2.981094, validation loss = 2.747119
2018-12-05 06:26:05,766 - INFO - epoch 1, step 42120, training loss = 3.059631, validation loss = 2.562239
2018-12-05 06:26:10,035 - INFO - epoch 1, step 42130, training loss = 2.535357, validation loss = 2.352380
2018-12-05 06:26:15,266 - INFO - epoch 1, step 42140, training loss = 2.353892, validation loss = 3.142846
2018-12-05 06:26:20,972 - INFO - epoch 1, step 42150, training loss = 2.143613, validation loss = 2.595919
2018-12-05 06:26:26,358 - INFO - epoch 1, step 42160, training loss = 3.014974, validation loss = 2.709790
2018-12-05 06:26:31,972 - INFO - epoch 1, step 42170, training loss = 2.197993, validation loss = 3.057409
2018-12-05 06:26:37,613 - INFO - epoch 1, step 42180, training loss = 1.944103, validation loss = 2.509506
2018-12-05 06:26:42,286 - INFO - epoch 1, step 42190, training loss = 2.984118, validation loss = 2.319460
2018-12-05 06:26:46,491 - INFO - epoch 1, step 42200, training loss = 3.107853, validation loss = 2.128328
2018-12-05 06:26:50,610 - INFO - epoch 1, step 42210, training loss = 3.016319, validation loss = 2.833993
2018-12-05 06:26:54,457 - INFO - epoch 1, step 42220, training loss = 2.889229, validation loss = 2.775887
2018-12-05 06:26:58,603 - INFO - epoch 1, step 42230, training loss = 2.911010, validation loss = 3.134534
2018-12-05 06:27:02,648 - INFO - epoch 1, step 42240, training loss = 2.858008, validation loss = 3.307034
2018-12-05 06:27:06,701 - INFO - epoch 1, step 42250, training loss = 3.294127, validation loss = 2.768296
2018-12-05 06:27:10,917 - INFO - epoch 1, step 42260, training loss = 2.188094, validation loss = 2.902162
2018-12-05 06:27:14,710 - INFO - epoch 1, step 42270, training loss = 2.809904, validation loss = 2.454135
2018-12-05 06:27:18,655 - INFO - epoch 1, step 42280, training loss = 3.084246, validation loss = 2.751604
2018-12-05 06:27:22,524 - INFO - epoch 1, step 42290, training loss = 3.194819, validation loss = 2.265822
2018-12-05 06:27:26,344 - INFO - epoch 1, step 42300, training loss = 2.441889, validation loss = 2.492188
2018-12-05 06:27:30,301 - INFO - epoch 1, step 42310, training loss = 2.709899, validation loss = 2.657891
2018-12-05 06:27:34,065 - INFO - epoch 1, step 42320, training loss = 2.671774, validation loss = 2.963456
2018-12-05 06:27:38,119 - INFO - epoch 1, step 42330, training loss = 2.532827, validation loss = 2.946227
2018-12-05 06:27:42,069 - INFO - epoch 1, step 42340, training loss = 3.340141, validation loss = 2.738232
2018-12-05 06:27:46,170 - INFO - epoch 1, step 42350, training loss = 2.593016, validation loss = 2.467221
2018-12-05 06:27:50,632 - INFO - epoch 1, step 42360, training loss = 1.992998, validation loss = 3.365311
2018-12-05 06:27:54,765 - INFO - epoch 1, step 42370, training loss = 2.579719, validation loss = 2.850293
2018-12-05 06:27:59,011 - INFO - epoch 1, step 42380, training loss = 2.887560, validation loss = 2.844646
2018-12-05 06:28:02,837 - INFO - epoch 1, step 42390, training loss = 2.436292, validation loss = 2.781950
2018-12-05 06:28:06,925 - INFO - epoch 1, step 42400, training loss = 2.480978, validation loss = 2.592726
2018-12-05 06:28:11,289 - INFO - epoch 1, step 42410, training loss = 2.332149, validation loss = 2.578344
2018-12-05 06:28:16,160 - INFO - epoch 1, step 42420, training loss = 2.742337, validation loss = 2.524791
2018-12-05 06:28:21,607 - INFO - epoch 1, step 42430, training loss = 2.003357, validation loss = 2.649005
2018-12-05 06:28:26,727 - INFO - epoch 1, step 42440, training loss = 2.276042, validation loss = 2.983811
2018-12-05 06:28:32,523 - INFO - epoch 1, step 42450, training loss = 2.105764, validation loss = 2.315240
2018-12-05 06:28:38,419 - INFO - epoch 1, step 42460, training loss = 1.829489, validation loss = 2.228030
2018-12-05 06:28:44,054 - INFO - epoch 1, step 42470, training loss = 2.233860, validation loss = 2.309743
2018-12-05 06:28:49,178 - INFO - epoch 1, step 42480, training loss = 2.727555, validation loss = 3.171416
2018-12-05 06:28:54,236 - INFO - epoch 1, step 42490, training loss = 2.435644, validation loss = 3.503592
2018-12-05 06:28:59,273 - INFO - epoch 1, step 42500, training loss = 2.579005, validation loss = 2.955909
2018-12-05 06:29:04,371 - INFO - epoch 1, step 42510, training loss = 2.346573, validation loss = 2.757097
2018-12-05 06:29:09,453 - INFO - epoch 1, step 42520, training loss = 2.146640, validation loss = 3.130116
2018-12-05 06:29:14,590 - INFO - epoch 1, step 42530, training loss = 2.082569, validation loss = 2.733104
2018-12-05 06:29:20,497 - INFO - epoch 1, step 42540, training loss = 1.607151, validation loss = 2.749626
2018-12-05 06:29:24,314 - INFO - epoch 1, step 42550, training loss = 3.250201, validation loss = 2.782068
2018-12-05 06:29:28,178 - INFO - epoch 1, step 42560, training loss = 2.844651, validation loss = 2.918187
2018-12-05 06:29:32,020 - INFO - epoch 1, step 42570, training loss = 2.773256, validation loss = 2.792935
2018-12-05 06:29:35,873 - INFO - epoch 1, step 42580, training loss = 3.069851, validation loss = 2.809170
2018-12-05 06:29:39,659 - INFO - epoch 1, step 42590, training loss = 2.544375, validation loss = 2.546046
2018-12-05 06:29:43,940 - INFO - epoch 1, step 42600, training loss = 2.728609, validation loss = 2.704696
2018-12-05 06:29:47,898 - INFO - epoch 1, step 42610, training loss = 2.731203, validation loss = 3.199516
2018-12-05 06:29:51,915 - INFO - epoch 1, step 42620, training loss = 2.667394, validation loss = 2.816599
2018-12-05 06:29:55,795 - INFO - epoch 1, step 42630, training loss = 2.505694, validation loss = 2.726716
2018-12-05 06:29:59,857 - INFO - epoch 1, step 42640, training loss = 3.470473, validation loss = 2.819309
2018-12-05 06:30:03,815 - INFO - epoch 1, step 42650, training loss = 3.093138, validation loss = 3.014909
2018-12-05 06:30:08,031 - INFO - epoch 1, step 42660, training loss = 2.418656, validation loss = 2.930565
2018-12-05 06:30:12,017 - INFO - epoch 1, step 42670, training loss = 3.108885, validation loss = 2.746076
2018-12-05 06:30:16,065 - INFO - epoch 1, step 42680, training loss = 2.706103, validation loss = 2.859609
2018-12-05 06:30:20,346 - INFO - epoch 1, step 42690, training loss = 2.584158, validation loss = 2.958127
2018-12-05 06:30:24,460 - INFO - epoch 1, step 42700, training loss = 2.431725, validation loss = 2.542873
2018-12-05 06:30:28,471 - INFO - epoch 1, step 42710, training loss = 2.609978, validation loss = 2.733440
2018-12-05 06:30:32,812 - INFO - epoch 1, step 42720, training loss = 2.542986, validation loss = 2.833213
2018-12-05 06:30:37,013 - INFO - epoch 1, step 42730, training loss = 3.017298, validation loss = 2.955621
2018-12-05 06:30:41,221 - INFO - epoch 1, step 42740, training loss = 2.446845, validation loss = 2.878033
2018-12-05 06:30:45,585 - INFO - epoch 1, step 42750, training loss = 2.122604, validation loss = 2.117218
2018-12-05 06:30:51,646 - INFO - epoch 1, step 42760, training loss = 2.036431, validation loss = 2.599139
2018-12-05 06:30:57,846 - INFO - epoch 1, step 42770, training loss = 3.054811, validation loss = 2.900557
2018-12-05 06:31:03,643 - INFO - epoch 1, step 42780, training loss = 2.737010, validation loss = 2.174574
2018-12-05 06:31:08,924 - INFO - epoch 1, step 42790, training loss = 2.479795, validation loss = 2.843255
2018-12-05 06:31:14,748 - INFO - epoch 1, step 42800, training loss = 2.561694, validation loss = 2.410489
2018-12-05 06:31:20,416 - INFO - epoch 1, step 42810, training loss = 2.284146, validation loss = 3.101851
2018-12-05 06:31:25,896 - INFO - epoch 1, step 42820, training loss = 2.247905, validation loss = 2.602196
2018-12-05 06:31:31,408 - INFO - epoch 1, step 42830, training loss = 2.524829, validation loss = 2.837988
2018-12-05 06:31:35,658 - INFO - epoch 1, step 42840, training loss = 3.107173, validation loss = 2.651851
2018-12-05 06:31:39,280 - INFO - epoch 1, step 42850, training loss = 3.060782, validation loss = 2.904667
2018-12-05 06:31:43,037 - INFO - epoch 1, step 42860, training loss = 3.001529, validation loss = 2.876253
2018-12-05 06:31:46,676 - INFO - epoch 1, step 42870, training loss = 2.490705, validation loss = 3.577090
2018-12-05 06:31:50,615 - INFO - epoch 1, step 42880, training loss = 2.521145, validation loss = 3.228575
2018-12-05 06:31:54,400 - INFO - epoch 1, step 42890, training loss = 3.524225, validation loss = 2.859021
2018-12-05 06:31:58,292 - INFO - epoch 1, step 42900, training loss = 3.064780, validation loss = 2.624649
2018-12-05 06:32:02,144 - INFO - epoch 1, step 42910, training loss = 3.324421, validation loss = 2.834090
2018-12-05 06:32:05,982 - INFO - epoch 1, step 42920, training loss = 2.883220, validation loss = 2.778360
2018-12-05 06:32:09,862 - INFO - epoch 1, step 42930, training loss = 2.670287, validation loss = 2.986627
2018-12-05 06:32:13,603 - INFO - epoch 1, step 42940, training loss = 2.842861, validation loss = 2.977223
2018-12-05 06:32:17,376 - INFO - epoch 1, step 42950, training loss = 3.099298, validation loss = 2.269109
2018-12-05 06:32:21,340 - INFO - epoch 1, step 42960, training loss = 2.621671, validation loss = 2.233581
2018-12-05 06:32:25,239 - INFO - epoch 1, step 42970, training loss = 2.902782, validation loss = 2.637607
2018-12-05 06:32:29,131 - INFO - epoch 1, step 42980, training loss = 2.519315, validation loss = 2.722070
2018-12-05 06:32:32,835 - INFO - epoch 1, step 42990, training loss = 2.766016, validation loss = 2.737388
2018-12-05 06:32:37,818 - INFO - epoch 1, step 43000, training loss = 2.624617, validation loss = 2.427641
2018-12-05 06:32:42,931 - INFO - epoch 1, step 43010, training loss = 2.342737, validation loss = 2.784125
2018-12-05 06:32:48,088 - INFO - epoch 1, step 43020, training loss = 2.400043, validation loss = 2.892849
2018-12-05 06:32:52,944 - INFO - epoch 1, step 43030, training loss = 2.623776, validation loss = 2.064398
2018-12-05 06:32:57,470 - INFO - epoch 1, step 43040, training loss = 2.191196, validation loss = 2.859240
2018-12-05 06:33:02,336 - INFO - epoch 1, step 43050, training loss = 2.593737, validation loss = 3.158522
2018-12-05 06:33:08,041 - INFO - epoch 1, step 43060, training loss = 1.855267, validation loss = 2.920169
2018-12-05 06:33:13,474 - INFO - epoch 1, step 43070, training loss = 2.970131, validation loss = 2.240965
2018-12-05 06:33:19,185 - INFO - epoch 1, step 43080, training loss = 1.549467, validation loss = 2.497311
2018-12-05 06:33:23,427 - INFO - epoch 1, step 43090, training loss = 2.574495, validation loss = 2.819154
2018-12-05 06:33:27,520 - INFO - epoch 1, step 43100, training loss = 2.860835, validation loss = 3.403404
2018-12-05 06:33:31,348 - INFO - epoch 1, step 43110, training loss = 2.804768, validation loss = 2.701425
2018-12-05 06:33:35,679 - INFO - epoch 1, step 43120, training loss = 2.972687, validation loss = 2.900892
2018-12-05 06:33:40,096 - INFO - epoch 1, step 43130, training loss = 2.407923, validation loss = 2.489173
2018-12-05 06:33:43,996 - INFO - epoch 1, step 43140, training loss = 3.030222, validation loss = 2.363014
2018-12-05 06:33:47,884 - INFO - epoch 1, step 43150, training loss = 2.922244, validation loss = 2.764041
2018-12-05 06:33:51,867 - INFO - epoch 1, step 43160, training loss = 2.737799, validation loss = 2.784654
2018-12-05 06:33:56,262 - INFO - epoch 1, step 43170, training loss = 2.533331, validation loss = 3.227103
2018-12-05 06:34:00,374 - INFO - epoch 1, step 43180, training loss = 2.689679, validation loss = 2.051418
2018-12-05 06:34:04,363 - INFO - epoch 1, step 43190, training loss = 2.711931, validation loss = 3.113733
2018-12-05 06:34:08,527 - INFO - epoch 1, step 43200, training loss = 2.564267, validation loss = 2.768771
2018-12-05 06:34:12,478 - INFO - epoch 1, step 43210, training loss = 3.007730, validation loss = 2.920855
2018-12-05 06:34:16,546 - INFO - epoch 1, step 43220, training loss = 2.526820, validation loss = 2.538069
2018-12-05 06:34:20,420 - INFO - epoch 1, step 43230, training loss = 2.413379, validation loss = 2.191941
2018-12-05 06:34:24,178 - INFO - epoch 1, step 43240, training loss = 2.591362, validation loss = 2.626945
2018-12-05 06:34:28,458 - INFO - epoch 1, step 43250, training loss = 2.982103, validation loss = 2.538681
2018-12-05 06:34:33,558 - INFO - epoch 1, step 43260, training loss = 2.500429, validation loss = 2.469243
2018-12-05 06:34:39,128 - INFO - epoch 1, step 43270, training loss = 2.526862, validation loss = 2.130014
2018-12-05 06:34:44,710 - INFO - epoch 1, step 43280, training loss = 2.929400, validation loss = 2.744204
2018-12-05 06:34:50,213 - INFO - epoch 1, step 43290, training loss = 2.400126, validation loss = 2.298042
2018-12-05 06:34:55,910 - INFO - epoch 1, step 43300, training loss = 2.784807, validation loss = 1.778841
2018-12-05 06:35:01,295 - INFO - epoch 1, step 43310, training loss = 3.024952, validation loss = 2.174322
2018-12-05 06:35:05,429 - INFO - epoch 1, step 43320, training loss = 3.273403, validation loss = 1.811913
2018-12-05 06:35:09,814 - INFO - epoch 1, step 43330, training loss = 2.843434, validation loss = 2.400642
2018-12-05 06:35:14,190 - INFO - epoch 1, step 43340, training loss = 3.151525, validation loss = 2.560373
2018-12-05 06:35:18,400 - INFO - epoch 1, step 43350, training loss = 3.007035, validation loss = 2.538405
2018-12-05 06:35:22,503 - INFO - epoch 1, step 43360, training loss = 2.665576, validation loss = 2.181059
2018-12-05 06:35:26,647 - INFO - epoch 1, step 43370, training loss = 2.732579, validation loss = 1.964521
2018-12-05 06:35:31,052 - INFO - epoch 1, step 43380, training loss = 2.765617, validation loss = 2.226212
2018-12-05 06:35:35,559 - INFO - epoch 1, step 43390, training loss = 1.650305, validation loss = 2.177897
2018-12-05 06:35:39,382 - INFO - epoch 1, step 43400, training loss = 2.600897, validation loss = 2.365299
2018-12-05 06:35:43,716 - INFO - epoch 1, step 43410, training loss = 2.908971, validation loss = 2.856293
2018-12-05 06:35:48,046 - INFO - epoch 1, step 43420, training loss = 2.847607, validation loss = 3.053303
2018-12-05 06:35:52,099 - INFO - epoch 1, step 43430, training loss = 3.214176, validation loss = 3.065466
2018-12-05 06:35:56,408 - INFO - epoch 1, step 43440, training loss = 2.249226, validation loss = 2.353390
2018-12-05 06:36:00,639 - INFO - epoch 1, step 43450, training loss = 2.993356, validation loss = 2.862889
2018-12-05 06:36:04,666 - INFO - epoch 1, step 43460, training loss = 2.633705, validation loss = 2.560344
2018-12-05 06:36:08,745 - INFO - epoch 1, step 43470, training loss = 2.823166, validation loss = 2.189632
2018-12-05 06:36:12,692 - INFO - epoch 1, step 43480, training loss = 2.667017, validation loss = 2.578352
2018-12-05 06:36:16,864 - INFO - epoch 1, step 43490, training loss = 2.690652, validation loss = 2.286753
2018-12-05 06:36:21,036 - INFO - epoch 1, step 43500, training loss = 2.709416, validation loss = 2.789477
2018-12-05 06:36:25,274 - INFO - epoch 1, step 43510, training loss = 2.650416, validation loss = 2.700869
2018-12-05 06:36:29,371 - INFO - epoch 1, step 43520, training loss = 2.403503, validation loss = 2.815672
2018-12-05 06:36:34,288 - INFO - epoch 1, step 43530, training loss = 2.029667, validation loss = 2.699951
2018-12-05 06:36:39,800 - INFO - epoch 1, step 43540, training loss = 2.211623, validation loss = 2.197281
2018-12-05 06:36:44,854 - INFO - epoch 1, step 43550, training loss = 2.087890, validation loss = 2.394962
2018-12-05 06:36:50,057 - INFO - epoch 1, step 43560, training loss = 2.154048, validation loss = 2.295006
2018-12-05 06:36:54,244 - INFO - epoch 1, step 43570, training loss = 2.797674, validation loss = 2.350639
2018-12-05 06:36:58,307 - INFO - epoch 1, step 43580, training loss = 2.855137, validation loss = 2.365224
2018-12-05 06:37:02,331 - INFO - epoch 1, step 43590, training loss = 2.874941, validation loss = 2.431758
2018-12-05 06:37:06,395 - INFO - epoch 1, step 43600, training loss = 2.756899, validation loss = 2.367660
2018-12-05 06:37:10,397 - INFO - epoch 1, step 43610, training loss = 2.599937, validation loss = 2.243860
2018-12-05 06:37:14,444 - INFO - epoch 1, step 43620, training loss = 2.976707, validation loss = 2.271358
2018-12-05 06:37:18,491 - INFO - epoch 1, step 43630, training loss = 2.770139, validation loss = 2.068559
2018-12-05 06:37:22,871 - INFO - epoch 1, step 43640, training loss = 2.098381, validation loss = 2.658312
2018-12-05 06:37:28,094 - INFO - epoch 1, step 43650, training loss = 2.141978, validation loss = 2.484469
2018-12-05 06:37:33,781 - INFO - epoch 1, step 43660, training loss = 2.447903, validation loss = 2.703686
2018-12-05 06:37:39,107 - INFO - epoch 1, step 43670, training loss = 2.082319, validation loss = 2.222798
2018-12-05 06:37:43,530 - INFO - epoch 1, step 43680, training loss = 2.966360, validation loss = 2.102737
2018-12-05 06:37:47,570 - INFO - epoch 1, step 43690, training loss = 2.737191, validation loss = 2.041396
2018-12-05 06:37:51,722 - INFO - epoch 1, step 43700, training loss = 2.378642, validation loss = 2.739720
2018-12-05 06:37:55,680 - INFO - epoch 1, step 43710, training loss = 2.562096, validation loss = 2.656474
2018-12-05 06:37:59,646 - INFO - epoch 1, step 43720, training loss = 2.811646, validation loss = 2.278736
2018-12-05 06:38:03,613 - INFO - epoch 1, step 43730, training loss = 2.384807, validation loss = 2.650215
2018-12-05 06:38:07,495 - INFO - epoch 1, step 43740, training loss = 2.883280, validation loss = 2.695368
2018-12-05 06:38:11,699 - INFO - epoch 1, step 43750, training loss = 2.892184, validation loss = 2.911857
2018-12-05 06:38:15,770 - INFO - epoch 1, step 43760, training loss = 2.916265, validation loss = 2.549388
2018-12-05 06:38:19,754 - INFO - epoch 1, step 43770, training loss = 2.524747, validation loss = 2.945487
2018-12-05 06:38:23,742 - INFO - epoch 1, step 43780, training loss = 3.320282, validation loss = 2.618830
2018-12-05 06:38:29,743 - INFO - epoch 1, step 43790, training loss = 1.977701, validation loss = 2.352060
2018-12-05 06:38:35,084 - INFO - epoch 1, step 43800, training loss = 1.938099, validation loss = 2.391188
2018-12-05 06:38:40,569 - INFO - epoch 1, step 43810, training loss = 1.982173, validation loss = 1.986739
2018-12-05 06:38:45,225 - INFO - epoch 1, step 43820, training loss = 3.299217, validation loss = 2.876161
2018-12-05 06:38:49,136 - INFO - epoch 1, step 43830, training loss = 2.898935, validation loss = 3.007037
2018-12-05 06:38:53,079 - INFO - epoch 1, step 43840, training loss = 2.619857, validation loss = 2.717055
2018-12-05 06:38:57,212 - INFO - epoch 1, step 43850, training loss = 2.772005, validation loss = 2.589515
2018-12-05 06:39:00,926 - INFO - epoch 1, step 43860, training loss = 2.913986, validation loss = 2.540090
2018-12-05 06:39:05,025 - INFO - epoch 1, step 43870, training loss = 2.769278, validation loss = 2.548501
2018-12-05 06:39:09,139 - INFO - epoch 1, step 43880, training loss = 3.212711, validation loss = 2.189169
2018-12-05 06:39:13,479 - INFO - epoch 1, step 43890, training loss = 2.743199, validation loss = 2.512342
2018-12-05 06:39:17,701 - INFO - epoch 1, step 43900, training loss = 3.027015, validation loss = 2.516102
2018-12-05 06:39:21,638 - INFO - epoch 1, step 43910, training loss = 3.044127, validation loss = 2.781049
2018-12-05 06:39:25,655 - INFO - epoch 1, step 43920, training loss = 2.935492, validation loss = 2.766694
2018-12-05 06:39:29,593 - INFO - epoch 1, step 43930, training loss = 3.181160, validation loss = 2.287198
2018-12-05 06:39:33,811 - INFO - epoch 1, step 43940, training loss = 2.896663, validation loss = 2.610475
2018-12-05 06:39:37,912 - INFO - epoch 1, step 43950, training loss = 2.718208, validation loss = 2.669630
2018-12-05 06:39:42,072 - INFO - epoch 1, step 43960, training loss = 2.755917, validation loss = 2.135884
2018-12-05 06:39:46,250 - INFO - epoch 1, step 43970, training loss = 3.044415, validation loss = 2.458934
2018-12-05 06:39:50,490 - INFO - epoch 1, step 43980, training loss = 3.048641, validation loss = 2.792915
2018-12-05 06:39:54,572 - INFO - epoch 1, step 43990, training loss = 2.829275, validation loss = 2.340157
2018-12-05 06:39:59,054 - INFO - epoch 1, step 44000, training loss = 2.945309, validation loss = 2.613233
2018-12-05 06:40:03,159 - INFO - epoch 1, step 44010, training loss = 2.797189, validation loss = 2.661676
2018-12-05 06:40:07,250 - INFO - epoch 1, step 44020, training loss = 2.486854, validation loss = 2.379890
2018-12-05 06:40:11,347 - INFO - epoch 1, step 44030, training loss = 2.631813, validation loss = 2.638058
2018-12-05 06:40:15,301 - INFO - epoch 1, step 44040, training loss = 3.123951, validation loss = 2.429593
2018-12-05 06:40:19,341 - INFO - epoch 1, step 44050, training loss = 2.395453, validation loss = 2.209797
2018-12-05 06:40:23,323 - INFO - epoch 1, step 44060, training loss = 2.564008, validation loss = 2.852164
2018-12-05 06:40:27,537 - INFO - epoch 1, step 44070, training loss = 2.751974, validation loss = 2.799885
2018-12-05 06:40:31,866 - INFO - epoch 1, step 44080, training loss = 2.556570, validation loss = 2.122218
2018-12-05 06:40:36,001 - INFO - epoch 1, step 44090, training loss = 2.841218, validation loss = 2.623698
2018-12-05 06:40:40,226 - INFO - epoch 1, step 44100, training loss = 2.557478, validation loss = 2.620020
2018-12-05 06:40:44,433 - INFO - epoch 1, step 44110, training loss = 2.532897, validation loss = 2.652256
2018-12-05 06:40:48,541 - INFO - epoch 1, step 44120, training loss = 2.859169, validation loss = 2.944936
2018-12-05 06:40:52,871 - INFO - epoch 1, step 44130, training loss = 2.665051, validation loss = 2.307718
2018-12-05 06:40:57,222 - INFO - epoch 1, step 44140, training loss = 2.432730, validation loss = 2.117671
2018-12-05 06:41:01,687 - INFO - epoch 1, step 44150, training loss = 2.525979, validation loss = 1.909199
2018-12-05 06:41:05,863 - INFO - epoch 1, step 44160, training loss = 2.702321, validation loss = 2.353326
2018-12-05 06:41:10,097 - INFO - epoch 1, step 44170, training loss = 2.763467, validation loss = 2.337269
2018-12-05 06:41:14,274 - INFO - epoch 1, step 44180, training loss = 2.861937, validation loss = 1.844544
2018-12-05 06:41:18,316 - INFO - epoch 1, step 44190, training loss = 2.726613, validation loss = 2.481640
2018-12-05 06:41:22,252 - INFO - epoch 1, step 44200, training loss = 3.134703, validation loss = 2.188292
2018-12-05 06:41:26,486 - INFO - epoch 1, step 44210, training loss = 2.678903, validation loss = 2.234051
2018-12-05 06:41:30,613 - INFO - epoch 1, step 44220, training loss = 2.967598, validation loss = 2.158731
2018-12-05 06:41:34,481 - INFO - epoch 1, step 44230, training loss = 2.862109, validation loss = 2.517287
2018-12-05 06:41:38,507 - INFO - epoch 1, step 44240, training loss = 2.432829, validation loss = 2.317560
2018-12-05 06:41:42,580 - INFO - epoch 1, step 44250, training loss = 2.671823, validation loss = 1.922459
2018-12-05 06:41:46,646 - INFO - epoch 1, step 44260, training loss = 2.791241, validation loss = 2.428594
2018-12-05 06:41:50,746 - INFO - epoch 1, step 44270, training loss = 2.506469, validation loss = 2.138196
2018-12-05 06:41:54,999 - INFO - epoch 1, step 44280, training loss = 2.614914, validation loss = 2.323014
2018-12-05 06:41:58,962 - INFO - epoch 1, step 44290, training loss = 2.739250, validation loss = 2.905970
2018-12-05 06:42:03,581 - INFO - epoch 1, step 44300, training loss = 2.889121, validation loss = 2.298615
2018-12-05 06:42:07,899 - INFO - epoch 1, step 44310, training loss = 2.635216, validation loss = 2.457190
2018-12-05 06:42:12,175 - INFO - epoch 1, step 44320, training loss = 3.105079, validation loss = 2.247979
2018-12-05 06:42:16,321 - INFO - epoch 1, step 44330, training loss = 2.372764, validation loss = 2.616102
2018-12-05 06:42:20,221 - INFO - epoch 1, step 44340, training loss = 2.806075, validation loss = 2.558808
2018-12-05 06:42:24,459 - INFO - epoch 1, step 44350, training loss = 3.143429, validation loss = 3.006468
2018-12-05 06:42:28,542 - INFO - epoch 1, step 44360, training loss = 3.180735, validation loss = 2.424073
2018-12-05 06:42:32,718 - INFO - epoch 1, step 44370, training loss = 2.579921, validation loss = 2.614130
2018-12-05 06:42:36,398 - INFO - epoch 1, step 44380, training loss = 2.900814, validation loss = 2.084528
2018-12-05 06:42:40,205 - INFO - epoch 1, step 44390, training loss = 2.959403, validation loss = 2.518007
2018-12-05 06:42:44,168 - INFO - epoch 1, step 44400, training loss = 2.661599, validation loss = 2.587478
2018-12-05 06:42:48,079 - INFO - epoch 1, step 44410, training loss = 2.458067, validation loss = 2.843945
2018-12-05 06:42:52,029 - INFO - epoch 1, step 44420, training loss = 2.751177, validation loss = 2.460914
2018-12-05 06:42:55,790 - INFO - epoch 1, step 44430, training loss = 3.106290, validation loss = 2.606543
2018-12-05 06:42:59,539 - INFO - epoch 1, step 44440, training loss = 2.947477, validation loss = 2.444338
2018-12-05 06:43:03,405 - INFO - epoch 1, step 44450, training loss = 2.571097, validation loss = 1.707304
2018-12-05 06:43:07,403 - INFO - epoch 1, step 44460, training loss = 2.700435, validation loss = 2.438773
2018-12-05 06:43:11,267 - INFO - epoch 1, step 44470, training loss = 3.338910, validation loss = 2.878359
2018-12-05 06:43:15,268 - INFO - epoch 1, step 44480, training loss = 3.389385, validation loss = 2.692781
2018-12-05 06:43:19,233 - INFO - epoch 1, step 44490, training loss = 2.589919, validation loss = 2.524804
2018-12-05 06:43:24,771 - INFO - epoch 1, step 44500, training loss = 1.624720, validation loss = 2.704378
2018-12-05 06:43:30,111 - INFO - epoch 1, step 44510, training loss = 1.935073, validation loss = 2.254243
2018-12-05 06:43:35,258 - INFO - epoch 1, step 44520, training loss = 2.509897, validation loss = 2.129050
2018-12-05 06:43:39,993 - INFO - epoch 1, step 44530, training loss = 2.586347, validation loss = 2.329500
2018-12-05 06:43:44,272 - INFO - epoch 1, step 44540, training loss = 2.493880, validation loss = 2.720721
2018-12-05 06:43:48,223 - INFO - epoch 1, step 44550, training loss = 2.997420, validation loss = 2.574809
2018-12-05 06:43:52,341 - INFO - epoch 1, step 44560, training loss = 3.059629, validation loss = 2.018752
2018-12-05 06:43:56,593 - INFO - epoch 1, step 44570, training loss = 3.063705, validation loss = 2.673985
2018-12-05 06:44:00,717 - INFO - epoch 1, step 44580, training loss = 2.848441, validation loss = 2.049744
2018-12-05 06:44:04,999 - INFO - epoch 1, step 44590, training loss = 2.642166, validation loss = 1.810981
2018-12-05 06:44:09,207 - INFO - epoch 1, step 44600, training loss = 2.736963, validation loss = 1.888839
2018-12-05 06:44:13,574 - INFO - epoch 1, step 44610, training loss = 2.411006, validation loss = 2.227194
2018-12-05 06:44:17,612 - INFO - epoch 1, step 44620, training loss = 2.778897, validation loss = 2.697495
2018-12-05 06:44:22,029 - INFO - epoch 1, step 44630, training loss = 2.126235, validation loss = 2.849767
2018-12-05 06:44:27,576 - INFO - epoch 1, step 44640, training loss = 1.907423, validation loss = 2.730801
2018-12-05 06:44:33,088 - INFO - epoch 1, step 44650, training loss = 2.225339, validation loss = 2.463797
2018-12-05 06:44:38,014 - INFO - epoch 1, step 44660, training loss = 2.092155, validation loss = 2.171820
2018-12-05 06:44:43,697 - INFO - epoch 1, step 44670, training loss = 2.134586, validation loss = 2.442935
2018-12-05 06:44:49,100 - INFO - epoch 1, step 44680, training loss = 1.749467, validation loss = 2.583618
2018-12-05 06:44:54,685 - INFO - epoch 1, step 44690, training loss = 2.670155, validation loss = 2.457299
2018-12-05 06:44:59,926 - INFO - epoch 1, step 44700, training loss = 2.550205, validation loss = 2.173602
2018-12-05 06:45:05,037 - INFO - epoch 1, step 44710, training loss = 2.370363, validation loss = 2.324972
2018-12-05 06:45:09,968 - INFO - epoch 1, step 44720, training loss = 2.564790, validation loss = 2.065226
2018-12-05 06:45:14,724 - INFO - epoch 1, step 44730, training loss = 2.860436, validation loss = 2.325045
2018-12-05 06:45:18,418 - INFO - epoch 1, step 44740, training loss = 2.800862, validation loss = 2.190067
2018-12-05 06:45:22,610 - INFO - epoch 1, step 44750, training loss = 2.800074, validation loss = 2.384480
2018-12-05 06:45:26,658 - INFO - epoch 1, step 44760, training loss = 2.930120, validation loss = 2.737748
2018-12-05 06:45:30,740 - INFO - epoch 1, step 44770, training loss = 2.740673, validation loss = 2.549486
2018-12-05 06:45:34,784 - INFO - epoch 1, step 44780, training loss = 2.356959, validation loss = 2.401650
2018-12-05 06:45:39,688 - INFO - epoch 1, step 44790, training loss = 1.996054, validation loss = 2.140882
2018-12-05 06:45:45,267 - INFO - epoch 1, step 44800, training loss = 2.169991, validation loss = 2.484251
2018-12-05 06:45:49,986 - INFO - epoch 1, step 44810, training loss = 3.148958, validation loss = 2.522345
2018-12-05 06:45:54,664 - INFO - epoch 1, step 44820, training loss = 3.266730, validation loss = 2.158597
2018-12-05 06:45:59,176 - INFO - epoch 1, step 44830, training loss = 2.841089, validation loss = 2.636933
2018-12-05 06:46:03,110 - INFO - epoch 1, step 44840, training loss = 2.603721, validation loss = 2.872861
2018-12-05 06:46:07,070 - INFO - epoch 1, step 44850, training loss = 3.148658, validation loss = 2.284796
2018-12-05 06:46:10,985 - INFO - epoch 1, step 44860, training loss = 3.079136, validation loss = 2.206283
2018-12-05 06:46:14,766 - INFO - epoch 1, step 44870, training loss = 2.670117, validation loss = 2.458144
2018-12-05 06:46:18,702 - INFO - epoch 1, step 44880, training loss = 2.760839, validation loss = 2.712801
2018-12-05 06:46:22,445 - INFO - epoch 1, step 44890, training loss = 2.705133, validation loss = 1.766899
2018-12-05 06:46:26,241 - INFO - epoch 1, step 44900, training loss = 3.199976, validation loss = 2.557219
2018-12-05 06:46:30,082 - INFO - epoch 1, step 44910, training loss = 2.678815, validation loss = 2.366841
2018-12-05 06:46:33,852 - INFO - epoch 1, step 44920, training loss = 2.682974, validation loss = 2.447678
2018-12-05 06:46:37,563 - INFO - epoch 1, step 44930, training loss = 2.864145, validation loss = 2.469866
2018-12-05 06:46:41,646 - INFO - epoch 1, step 44940, training loss = 2.321558, validation loss = 2.683009
2018-12-05 06:46:46,576 - INFO - epoch 1, step 44950, training loss = 2.480023, validation loss = 2.884911
2018-12-05 06:46:51,875 - INFO - epoch 1, step 44960, training loss = 2.051042, validation loss = 2.240984
2018-12-05 06:46:56,974 - INFO - epoch 1, step 44970, training loss = 2.407770, validation loss = 2.256269
2018-12-05 06:47:01,419 - INFO - epoch 1, step 44980, training loss = 2.534773, validation loss = 2.709281
2018-12-05 06:47:05,552 - INFO - epoch 1, step 44990, training loss = 2.744891, validation loss = 2.438650
2018-12-05 06:47:09,861 - INFO - epoch 1, step 45000, training loss = 2.863491, validation loss = 2.754320
2018-12-05 06:47:14,097 - INFO - epoch 1, step 45010, training loss = 2.782801, validation loss = 2.440697
2018-12-05 06:47:18,822 - INFO - epoch 1, step 45020, training loss = 2.130106, validation loss = 2.434130
2018-12-05 06:47:23,737 - INFO - epoch 1, step 45030, training loss = 2.944243, validation loss = 2.949461
2018-12-05 06:47:29,171 - INFO - epoch 1, step 45040, training loss = 1.852853, validation loss = 2.859614
2018-12-05 06:47:34,335 - INFO - epoch 1, step 45050, training loss = 2.937949, validation loss = 2.540277
2018-12-05 06:47:39,349 - INFO - epoch 1, step 45060, training loss = 2.213363, validation loss = 2.635278
2018-12-05 06:47:44,580 - INFO - epoch 1, step 45070, training loss = 3.279139, validation loss = 2.621074
2018-12-05 06:47:49,509 - INFO - epoch 1, step 45080, training loss = 3.019262, validation loss = 2.648079
2018-12-05 06:47:53,808 - INFO - epoch 1, step 45090, training loss = 2.798458, validation loss = 2.342876
2018-12-05 06:47:58,103 - INFO - epoch 1, step 45100, training loss = 2.640741, validation loss = 2.228639
2018-12-05 06:48:02,319 - INFO - epoch 1, step 45110, training loss = 2.788394, validation loss = 2.211574
2018-12-05 06:48:06,721 - INFO - epoch 1, step 45120, training loss = 3.025373, validation loss = 2.435750
2018-12-05 06:48:11,182 - INFO - epoch 1, step 45130, training loss = 2.433934, validation loss = 2.832525
2018-12-05 06:48:14,980 - INFO - epoch 1, step 45140, training loss = 3.179476, validation loss = 2.824796
2018-12-05 06:48:18,873 - INFO - epoch 1, step 45150, training loss = 2.834405, validation loss = 2.238006
2018-12-05 06:48:22,834 - INFO - epoch 1, step 45160, training loss = 2.214735, validation loss = 2.632183
2018-12-05 06:48:26,951 - INFO - epoch 1, step 45170, training loss = 2.938352, validation loss = 2.582724
2018-12-05 06:48:31,807 - INFO - epoch 1, step 45180, training loss = 2.985102, validation loss = 3.347691
2018-12-05 06:48:37,760 - INFO - epoch 1, step 45190, training loss = 2.132295, validation loss = 2.294421
2018-12-05 06:48:43,503 - INFO - epoch 1, step 45200, training loss = 2.974705, validation loss = 2.480512
2018-12-05 06:48:48,759 - INFO - epoch 1, step 45210, training loss = 2.226979, validation loss = 2.468745
2018-12-05 06:48:53,909 - INFO - epoch 1, step 45220, training loss = 2.677909, validation loss = 2.677969
2018-12-05 06:48:57,576 - INFO - epoch 1, step 45230, training loss = 3.206769, validation loss = 2.481322
2018-12-05 06:49:01,473 - INFO - epoch 1, step 45240, training loss = 2.804289, validation loss = 2.836430
2018-12-05 06:49:05,115 - INFO - epoch 1, step 45250, training loss = 3.172316, validation loss = 2.493813
2018-12-05 06:49:09,080 - INFO - epoch 1, step 45260, training loss = 2.729638, validation loss = 2.372525
2018-12-05 06:49:12,839 - INFO - epoch 1, step 45270, training loss = 2.494820, validation loss = 2.664175
2018-12-05 06:49:17,414 - INFO - epoch 1, step 45280, training loss = 2.590552, validation loss = 2.399393
2018-12-05 06:49:22,748 - INFO - epoch 1, step 45290, training loss = 2.365819, validation loss = 2.795528
2018-12-05 06:49:27,802 - INFO - epoch 1, step 45300, training loss = 2.162464, validation loss = 2.544205
2018-12-05 06:49:33,161 - INFO - epoch 1, step 45310, training loss = 2.324434, validation loss = 2.407956
2018-12-05 06:49:38,095 - INFO - epoch 1, step 45320, training loss = 2.515739, validation loss = 2.209913
2018-12-05 06:49:43,553 - INFO - epoch 1, step 45330, training loss = 2.227315, validation loss = 2.533033
2018-12-05 06:49:48,890 - INFO - epoch 1, step 45340, training loss = 2.409417, validation loss = 2.897979
2018-12-05 06:49:54,578 - INFO - epoch 1, step 45350, training loss = 2.403354, validation loss = 2.602337
2018-12-05 06:49:59,533 - INFO - epoch 1, step 45360, training loss = 2.557922, validation loss = 2.802012
2018-12-05 06:50:04,752 - INFO - epoch 1, step 45370, training loss = 2.439482, validation loss = 2.832092
2018-12-05 06:50:09,733 - INFO - epoch 1, step 45380, training loss = 2.504006, validation loss = 2.230488
2018-12-05 06:50:14,716 - INFO - epoch 1, step 45390, training loss = 2.459086, validation loss = 2.546050
2018-12-05 06:50:20,505 - INFO - epoch 1, step 45400, training loss = 2.186143, validation loss = 2.691496
2018-12-05 06:50:25,505 - INFO - epoch 1, step 45410, training loss = 2.656605, validation loss = 3.023897
2018-12-05 06:50:30,660 - INFO - epoch 1, step 45420, training loss = 2.193699, validation loss = 2.333280
2018-12-05 06:50:35,937 - INFO - epoch 1, step 45430, training loss = 2.378318, validation loss = 2.566342
2018-12-05 06:50:41,777 - INFO - epoch 1, step 45440, training loss = 2.248446, validation loss = 2.660403
2018-12-05 06:50:46,439 - INFO - epoch 1, step 45450, training loss = 2.709088, validation loss = 2.361157
2018-12-05 06:50:50,583 - INFO - epoch 1, step 45460, training loss = 2.863826, validation loss = 2.260270
2018-12-05 06:50:54,720 - INFO - epoch 1, step 45470, training loss = 3.020812, validation loss = 2.083736
2018-12-05 06:50:58,328 - INFO - epoch 1, step 45480, training loss = 3.104877, validation loss = 3.080734
2018-12-05 06:51:02,203 - INFO - epoch 1, step 45490, training loss = 2.976411, validation loss = 2.350431
2018-12-05 06:51:06,587 - INFO - epoch 1, step 45500, training loss = 1.919730, validation loss = 2.042593
2018-12-05 06:51:12,359 - INFO - epoch 1, step 45510, training loss = 1.662554, validation loss = 2.748986
2018-12-05 06:51:17,610 - INFO - epoch 1, step 45520, training loss = 2.116005, validation loss = 2.649419
2018-12-05 06:51:22,709 - INFO - epoch 1, step 45530, training loss = 2.903613, validation loss = 2.637910
2018-12-05 06:51:26,575 - INFO - epoch 1, step 45540, training loss = 2.731394, validation loss = 2.784384
2018-12-05 06:51:30,285 - INFO - epoch 1, step 45550, training loss = 3.163007, validation loss = 2.625019
2018-12-05 06:51:34,229 - INFO - epoch 1, step 45560, training loss = 3.029678, validation loss = 2.601853
2018-12-05 06:51:38,132 - INFO - epoch 1, step 45570, training loss = 3.048465, validation loss = 2.842691
2018-12-05 06:51:41,968 - INFO - epoch 1, step 45580, training loss = 2.740009, validation loss = 2.392490
2018-12-05 06:51:45,869 - INFO - epoch 1, step 45590, training loss = 2.679376, validation loss = 2.244620
2018-12-05 06:51:49,677 - INFO - epoch 1, step 45600, training loss = 3.008885, validation loss = 2.250409
2018-12-05 06:51:53,435 - INFO - epoch 1, step 45610, training loss = 3.192812, validation loss = 2.492203
2018-12-05 06:51:57,254 - INFO - epoch 1, step 45620, training loss = 3.100301, validation loss = 2.519943
2018-12-05 06:52:01,128 - INFO - epoch 1, step 45630, training loss = 2.876947, validation loss = 2.604425
2018-12-05 06:52:04,996 - INFO - epoch 1, step 45640, training loss = 3.005824, validation loss = 2.351465
2018-12-05 06:52:08,688 - INFO - epoch 1, step 45650, training loss = 2.894006, validation loss = 2.469816
2018-12-05 06:52:12,652 - INFO - epoch 1, step 45660, training loss = 2.827801, validation loss = 1.955028
2018-12-05 06:52:16,689 - INFO - epoch 1, step 45670, training loss = 2.220684, validation loss = 2.580774
2018-12-05 06:52:20,351 - INFO - epoch 1, step 45680, training loss = 2.877813, validation loss = 2.768911
2018-12-05 06:52:24,399 - INFO - epoch 1, step 45690, training loss = 2.666040, validation loss = 2.857822
2018-12-05 06:52:28,263 - INFO - epoch 1, step 45700, training loss = 3.094675, validation loss = 3.075996
2018-12-05 06:52:32,224 - INFO - epoch 1, step 45710, training loss = 2.745804, validation loss = 2.203979
2018-12-05 06:52:36,270 - INFO - epoch 1, step 45720, training loss = 2.519115, validation loss = 2.923705
2018-12-05 06:52:40,116 - INFO - epoch 1, step 45730, training loss = 2.930125, validation loss = 2.691724
2018-12-05 06:52:43,893 - INFO - epoch 1, step 45740, training loss = 3.224476, validation loss = 2.601639
2018-12-05 06:52:47,606 - INFO - epoch 1, step 45750, training loss = 2.904114, validation loss = 2.427579
2018-12-05 06:52:51,426 - INFO - epoch 1, step 45760, training loss = 2.643461, validation loss = 2.752563
2018-12-05 06:52:55,203 - INFO - epoch 1, step 45770, training loss = 2.698130, validation loss = 2.494562
2018-12-05 06:52:58,972 - INFO - epoch 1, step 45780, training loss = 3.034830, validation loss = 2.507423
2018-12-05 06:53:02,864 - INFO - epoch 1, step 45790, training loss = 2.832899, validation loss = 2.834252
2018-12-05 06:53:06,806 - INFO - epoch 1, step 45800, training loss = 2.857689, validation loss = 2.990551
2018-12-05 06:53:11,629 - INFO - epoch 1, step 45810, training loss = 2.582628, validation loss = 2.084195
2018-12-05 06:53:16,936 - INFO - epoch 1, step 45820, training loss = 2.605540, validation loss = 2.627564
2018-12-05 06:53:22,033 - INFO - epoch 1, step 45830, training loss = 2.768889, validation loss = 2.696332
2018-12-05 06:53:27,169 - INFO - epoch 1, step 45840, training loss = 2.370057, validation loss = 2.952695
2018-12-05 06:53:32,463 - INFO - epoch 1, step 45850, training loss = 2.428678, validation loss = 2.476518
2018-12-05 06:53:37,806 - INFO - epoch 1, step 45860, training loss = 2.345413, validation loss = 2.393519
2018-12-05 06:53:43,061 - INFO - epoch 1, step 45870, training loss = 2.507805, validation loss = 2.636533
2018-12-05 06:53:48,434 - INFO - epoch 1, step 45880, training loss = 2.029593, validation loss = 2.907547
2018-12-05 06:53:54,394 - INFO - epoch 1, step 45890, training loss = 2.216385, validation loss = 2.209092
2018-12-05 06:54:00,030 - INFO - epoch 1, step 45900, training loss = 1.862396, validation loss = 2.662488
2018-12-05 06:54:05,812 - INFO - epoch 1, step 45910, training loss = 1.690843, validation loss = 2.778904
2018-12-05 06:54:11,261 - INFO - epoch 1, step 45920, training loss = 3.049891, validation loss = 2.892638
2018-12-05 06:54:17,381 - INFO - epoch 1, step 45930, training loss = 1.815739, validation loss = 2.570457
2018-12-05 06:54:22,610 - INFO - epoch 1, step 45940, training loss = 2.341340, validation loss = 2.368256
2018-12-05 06:54:28,080 - INFO - epoch 1, step 45950, training loss = 2.298991, validation loss = 2.569791
2018-12-05 06:54:33,570 - INFO - epoch 1, step 45960, training loss = 2.538468, validation loss = 2.131319
2018-12-05 06:54:39,038 - INFO - epoch 1, step 45970, training loss = 2.210712, validation loss = 2.645346
2018-12-05 06:54:45,354 - INFO - epoch 1, step 45980, training loss = 1.845579, validation loss = 2.538443
2018-12-05 06:54:50,350 - INFO - epoch 1, step 45990, training loss = 2.532059, validation loss = 3.169885
2018-12-05 06:54:55,706 - INFO - epoch 1, step 46000, training loss = 2.020055, validation loss = 2.532413
2018-12-05 06:55:01,505 - INFO - epoch 1, step 46010, training loss = 2.489943, validation loss = 2.365716
2018-12-05 06:55:05,937 - INFO - epoch 1, step 46020, training loss = 2.828046, validation loss = 2.723616
2018-12-05 06:55:09,936 - INFO - epoch 1, step 46030, training loss = 3.083111, validation loss = 2.549956
2018-12-05 06:55:13,917 - INFO - epoch 1, step 46040, training loss = 2.947850, validation loss = 2.588949
2018-12-05 06:55:18,010 - INFO - epoch 1, step 46050, training loss = 3.162607, validation loss = 2.649049
2018-12-05 06:55:21,964 - INFO - epoch 1, step 46060, training loss = 3.071976, validation loss = 2.710903
2018-12-05 06:55:25,980 - INFO - epoch 1, step 46070, training loss = 3.151819, validation loss = 2.951536
2018-12-05 06:55:30,251 - INFO - epoch 1, step 46080, training loss = 2.900822, validation loss = 2.654960
2018-12-05 06:55:34,548 - INFO - epoch 1, step 46090, training loss = 2.520584, validation loss = 3.105802
2018-12-05 06:55:38,834 - INFO - epoch 1, step 46100, training loss = 2.681659, validation loss = 2.195915
2018-12-05 06:55:43,108 - INFO - epoch 1, step 46110, training loss = 2.395570, validation loss = 2.535139
2018-12-05 06:55:47,305 - INFO - epoch 1, step 46120, training loss = 2.816528, validation loss = 2.715623
2018-12-05 06:55:51,584 - INFO - epoch 1, step 46130, training loss = 3.113114, validation loss = 2.775054
2018-12-05 06:55:55,956 - INFO - epoch 1, step 46140, training loss = 2.666566, validation loss = 2.800945
2018-12-05 06:56:00,015 - INFO - epoch 1, step 46150, training loss = 2.437519, validation loss = 3.137173
2018-12-05 06:56:04,042 - INFO - epoch 1, step 46160, training loss = 2.835401, validation loss = 2.802739
2018-12-05 06:56:08,111 - INFO - epoch 1, step 46170, training loss = 2.933551, validation loss = 2.467383
2018-12-05 06:56:11,950 - INFO - epoch 1, step 46180, training loss = 2.976753, validation loss = 2.324307
2018-12-05 06:56:15,700 - INFO - epoch 1, step 46190, training loss = 2.690835, validation loss = 2.639329
2018-12-05 06:56:19,578 - INFO - epoch 1, step 46200, training loss = 2.710268, validation loss = 2.883721
2018-12-05 06:56:23,873 - INFO - epoch 1, step 46210, training loss = 2.145143, validation loss = 2.650554
2018-12-05 06:56:27,715 - INFO - epoch 1, step 46220, training loss = 3.095848, validation loss = 2.751950
2018-12-05 06:56:31,531 - INFO - epoch 1, step 46230, training loss = 2.579971, validation loss = 2.489699
2018-12-05 06:56:35,587 - INFO - epoch 1, step 46240, training loss = 2.572977, validation loss = 2.696605
2018-12-05 06:56:39,889 - INFO - epoch 1, step 46250, training loss = 2.801812, validation loss = 2.600623
2018-12-05 06:56:44,273 - INFO - epoch 1, step 46260, training loss = 2.849417, validation loss = 2.598713
2018-12-05 06:56:48,472 - INFO - epoch 1, step 46270, training loss = 2.216932, validation loss = 2.301599
2018-12-05 06:56:52,506 - INFO - epoch 1, step 46280, training loss = 2.792181, validation loss = 2.776766
2018-12-05 06:56:56,855 - INFO - epoch 1, step 46290, training loss = 2.417449, validation loss = 2.678530
2018-12-05 06:57:01,184 - INFO - epoch 1, step 46300, training loss = 2.541727, validation loss = 2.418163
2018-12-05 06:57:05,247 - INFO - epoch 1, step 46310, training loss = 2.754745, validation loss = 2.651041
2018-12-05 06:57:09,298 - INFO - epoch 1, step 46320, training loss = 2.819623, validation loss = 3.008163
2018-12-05 06:57:13,221 - INFO - epoch 1, step 46330, training loss = 2.952574, validation loss = 3.123688
2018-12-05 06:57:17,212 - INFO - epoch 1, step 46340, training loss = 2.804983, validation loss = 2.811468
2018-12-05 06:57:21,259 - INFO - epoch 1, step 46350, training loss = 2.909069, validation loss = 2.915148
2018-12-05 06:57:25,164 - INFO - epoch 1, step 46360, training loss = 2.438624, validation loss = 2.913383
2018-12-05 06:57:28,938 - INFO - epoch 1, step 46370, training loss = 3.015142, validation loss = 2.973169
2018-12-05 06:57:32,562 - INFO - epoch 1, step 46380, training loss = 2.842722, validation loss = 3.126055
2018-12-05 06:57:36,471 - INFO - epoch 1, step 46390, training loss = 2.999313, validation loss = 2.705767
2018-12-05 06:57:40,412 - INFO - epoch 1, step 46400, training loss = 2.805635, validation loss = 2.807680
2018-12-05 06:57:44,374 - INFO - epoch 1, step 46410, training loss = 2.797765, validation loss = 2.466609
2018-12-05 06:57:48,051 - INFO - epoch 1, step 46420, training loss = 3.039561, validation loss = 3.201714
2018-12-05 06:57:51,834 - INFO - epoch 1, step 46430, training loss = 2.463952, validation loss = 3.126746
2018-12-05 06:57:55,516 - INFO - epoch 1, step 46440, training loss = 2.912767, validation loss = 2.854662
2018-12-05 06:57:59,161 - INFO - epoch 1, step 46450, training loss = 2.621202, validation loss = 2.515093
2018-12-05 06:58:02,860 - INFO - epoch 1, step 46460, training loss = 2.833876, validation loss = 2.652826
2018-12-05 06:58:06,806 - INFO - epoch 1, step 46470, training loss = 2.375247, validation loss = 3.249902
2018-12-05 06:58:12,274 - INFO - epoch 1, step 46480, training loss = 1.715378, validation loss = 3.490154
2018-12-05 06:58:17,161 - INFO - epoch 1, step 46490, training loss = 2.539198, validation loss = 2.921092
2018-12-05 06:58:22,572 - INFO - epoch 1, step 46500, training loss = 1.935644, validation loss = 3.261777
2018-12-05 06:58:27,675 - INFO - epoch 1, step 46510, training loss = 2.641997, validation loss = 2.799227
2018-12-05 06:58:33,253 - INFO - epoch 1, step 46520, training loss = 2.365209, validation loss = 3.011802
2018-12-05 06:58:37,495 - INFO - epoch 1, step 46530, training loss = 2.840863, validation loss = 2.468818
2018-12-05 06:58:41,363 - INFO - epoch 1, step 46540, training loss = 2.554375, validation loss = 2.857485
2018-12-05 06:58:45,515 - INFO - epoch 1, step 46550, training loss = 2.696961, validation loss = 2.521116
2018-12-05 06:58:49,298 - INFO - epoch 1, step 46560, training loss = 2.696527, validation loss = 2.909792
2018-12-05 06:58:53,281 - INFO - epoch 1, step 46570, training loss = 2.812562, validation loss = 2.664753
2018-12-05 06:58:57,327 - INFO - epoch 1, step 46580, training loss = 2.466675, validation loss = 2.911525
2018-12-05 06:59:01,489 - INFO - epoch 1, step 46590, training loss = 1.984294, validation loss = 3.284685
2018-12-05 06:59:06,744 - INFO - epoch 1, step 46600, training loss = 2.394182, validation loss = 2.704051
2018-12-05 06:59:12,272 - INFO - epoch 1, step 46610, training loss = 2.094709, validation loss = 2.827992
2018-12-05 06:59:18,096 - INFO - epoch 1, step 46620, training loss = 3.528783, validation loss = 2.416197
2018-12-05 06:59:22,740 - INFO - epoch 1, step 46630, training loss = 2.579401, validation loss = 2.962432
2018-12-05 06:59:28,235 - INFO - epoch 1, step 46640, training loss = 1.947236, validation loss = 2.801419
2018-12-05 06:59:33,741 - INFO - epoch 1, step 46650, training loss = 2.679348, validation loss = 2.805061
2018-12-05 06:59:37,697 - INFO - epoch 1, step 46660, training loss = 3.067124, validation loss = 2.630268
2018-12-05 06:59:41,822 - INFO - epoch 1, step 46670, training loss = 2.621428, validation loss = 2.630923
2018-12-05 06:59:45,631 - INFO - epoch 1, step 46680, training loss = 2.853288, validation loss = 2.754610
2018-12-05 06:59:49,343 - INFO - epoch 1, step 46690, training loss = 2.867209, validation loss = 2.992000
2018-12-05 06:59:53,233 - INFO - epoch 1, step 46700, training loss = 2.864370, validation loss = 2.778418
2018-12-05 06:59:57,401 - INFO - epoch 1, step 46710, training loss = 2.344257, validation loss = 2.770603
2018-12-05 07:00:01,412 - INFO - epoch 1, step 46720, training loss = 2.746401, validation loss = 2.539472
2018-12-05 07:00:05,544 - INFO - epoch 1, step 46730, training loss = 3.112123, validation loss = 2.544665
2018-12-05 07:00:09,460 - INFO - epoch 1, step 46740, training loss = 2.801021, validation loss = 3.034281
2018-12-05 07:00:13,809 - INFO - epoch 1, step 46750, training loss = 2.356555, validation loss = 2.617592
2018-12-05 07:00:18,023 - INFO - epoch 1, step 46760, training loss = 2.339088, validation loss = 2.904721
2018-12-05 07:00:22,131 - INFO - epoch 1, step 46770, training loss = 2.771526, validation loss = 3.244202
2018-12-05 07:00:26,080 - INFO - epoch 1, step 46780, training loss = 2.260169, validation loss = 2.785736
2018-12-05 07:00:30,095 - INFO - epoch 1, step 46790, training loss = 2.779932, validation loss = 2.971943
2018-12-05 07:00:34,266 - INFO - epoch 1, step 46800, training loss = 2.995567, validation loss = 3.043700
2018-12-05 07:00:38,029 - INFO - epoch 1, step 46810, training loss = 2.876192, validation loss = 3.114479
2018-12-05 07:00:41,906 - INFO - epoch 1, step 46820, training loss = 2.805992, validation loss = 2.881496
2018-12-05 07:00:45,794 - INFO - epoch 1, step 46830, training loss = 3.158909, validation loss = 2.720982
2018-12-05 07:00:49,676 - INFO - epoch 1, step 46840, training loss = 2.830610, validation loss = 2.360936
2018-12-05 07:00:53,408 - INFO - epoch 1, step 46850, training loss = 3.097095, validation loss = 3.146938
2018-12-05 07:00:57,362 - INFO - epoch 1, step 46860, training loss = 2.516766, validation loss = 2.883295
2018-12-05 07:01:01,276 - INFO - epoch 1, step 46870, training loss = 2.473963, validation loss = 2.804107
2018-12-05 07:01:05,182 - INFO - epoch 1, step 46880, training loss = 2.433867, validation loss = 3.099140
2018-12-05 07:01:09,060 - INFO - epoch 1, step 46890, training loss = 2.965891, validation loss = 2.837173
2018-12-05 07:01:12,706 - INFO - epoch 1, step 46900, training loss = 2.554128, validation loss = 3.300764
2018-12-05 07:01:16,927 - INFO - epoch 1, step 46910, training loss = 2.573558, validation loss = 3.154198
2018-12-05 07:01:21,930 - INFO - epoch 1, step 46920, training loss = 2.266992, validation loss = 2.630790
2018-12-05 07:01:27,377 - INFO - epoch 1, step 46930, training loss = 2.545093, validation loss = 3.334040
2018-12-05 07:01:32,841 - INFO - epoch 1, step 46940, training loss = 1.930947, validation loss = 3.335105
2018-12-05 07:01:38,497 - INFO - epoch 1, step 46950, training loss = 2.618246, validation loss = 2.846452
2018-12-05 07:01:43,924 - INFO - epoch 1, step 46960, training loss = 2.238472, validation loss = 3.590967
2018-12-05 07:01:49,346 - INFO - epoch 1, step 46970, training loss = 2.422802, validation loss = 3.252980
2018-12-05 07:01:55,337 - INFO - epoch 1, step 46980, training loss = 2.254959, validation loss = 3.010148
2018-12-05 07:02:00,912 - INFO - epoch 1, step 46990, training loss = 2.486567, validation loss = 2.968815
2018-12-05 07:02:06,198 - INFO - epoch 1, step 47000, training loss = 3.053024, validation loss = 2.665171
2018-12-05 07:02:11,691 - INFO - epoch 1, step 47010, training loss = 2.452104, validation loss = 3.081344
2018-12-05 07:02:16,792 - INFO - epoch 1, step 47020, training loss = 1.968083, validation loss = 3.595010
2018-12-05 07:02:22,044 - INFO - epoch 1, step 47030, training loss = 1.957167, validation loss = 3.011285
2018-12-05 07:02:26,852 - INFO - epoch 1, step 47040, training loss = 3.105179, validation loss = 3.341567
2018-12-05 07:02:31,631 - INFO - epoch 1, step 47050, training loss = 2.374369, validation loss = 3.394479
2018-12-05 07:02:35,876 - INFO - epoch 1, step 47060, training loss = 2.794937, validation loss = 3.829420
2018-12-05 07:02:40,292 - INFO - epoch 1, step 47070, training loss = 2.487421, validation loss = 3.213106
2018-12-05 07:02:45,133 - INFO - epoch 1, step 47080, training loss = 2.161630, validation loss = 3.234194
2018-12-05 07:02:49,501 - INFO - epoch 1, step 47090, training loss = 2.426867, validation loss = 3.472094
2018-12-05 07:02:54,058 - INFO - epoch 1, step 47100, training loss = 2.408391, validation loss = 3.056345
2018-12-05 07:02:58,175 - INFO - epoch 1, step 47110, training loss = 2.881584, validation loss = 3.065637
2018-12-05 07:03:02,394 - INFO - epoch 1, step 47120, training loss = 2.652575, validation loss = 3.073690
2018-12-05 07:03:07,112 - INFO - epoch 1, step 47130, training loss = 2.692297, validation loss = 2.899086
2018-12-05 07:03:11,327 - INFO - epoch 1, step 47140, training loss = 2.931358, validation loss = 2.989865
2018-12-05 07:03:15,645 - INFO - epoch 1, step 47150, training loss = 2.572022, validation loss = 2.907618
2018-12-05 07:03:19,773 - INFO - epoch 1, step 47160, training loss = 2.651862, validation loss = 2.857715
2018-12-05 07:03:23,931 - INFO - epoch 1, step 47170, training loss = 2.463421, validation loss = 2.500316
2018-12-05 07:03:28,169 - INFO - epoch 1, step 47180, training loss = 2.794637, validation loss = 3.391585
2018-12-05 07:03:32,437 - INFO - epoch 1, step 47190, training loss = 2.721904, validation loss = 3.169384
2018-12-05 07:03:36,115 - INFO - epoch 1, step 47200, training loss = 2.140696, validation loss = 2.806306
2018-12-05 07:03:39,332 - INFO - epoch 1, step 47210, training loss = 2.304242, validation loss = 2.818365
2018-12-05 07:03:42,393 - INFO - epoch 1, step 47220, training loss = 2.105307, validation loss = 3.380304
2018-12-05 07:03:45,643 - INFO - epoch 1, step 47230, training loss = 1.834433, validation loss = 3.382595
2018-12-05 07:03:48,722 - INFO - epoch 1, step 47240, training loss = 2.156525, validation loss = 3.218603
2018-12-05 07:03:52,188 - INFO - epoch 1, step 47250, training loss = 1.923134, validation loss = 3.001049
2018-12-05 07:03:55,409 - INFO - epoch 1, step 47260, training loss = 1.823032, validation loss = 3.406267
2018-12-05 07:03:59,329 - INFO - epoch 1, step 47270, training loss = 1.785783, validation loss = 3.088971
2018-12-05 07:04:03,155 - INFO - epoch 1, step 47280, training loss = 1.795113, validation loss = 2.992434
2018-12-05 07:04:07,194 - INFO - epoch 1, step 47290, training loss = 1.899242, validation loss = 3.072590
2018-12-05 07:04:11,031 - INFO - epoch 1, step 47300, training loss = 2.128367, validation loss = 3.506397
2018-12-05 07:04:14,623 - INFO - epoch 1, step 47310, training loss = 2.349184, validation loss = 3.161477
2018-12-05 07:04:18,472 - INFO - epoch 1, step 47320, training loss = 1.702138, validation loss = 3.216774
2018-12-05 07:04:22,292 - INFO - epoch 1, step 47330, training loss = 2.016274, validation loss = 2.823406
2018-12-05 07:04:26,421 - INFO - epoch 1, step 47340, training loss = 1.775015, validation loss = 3.789753
2018-12-05 07:04:30,337 - INFO - epoch 1, step 47350, training loss = 1.921560, validation loss = 3.179515
2018-12-05 07:04:33,748 - INFO - epoch 1, step 47360, training loss = 1.729448, validation loss = 3.357877
2018-12-05 07:04:36,921 - INFO - epoch 1, step 47370, training loss = 1.706651, validation loss = 3.163237
2018-12-05 07:04:40,160 - INFO - epoch 1, step 47380, training loss = 2.039118, validation loss = 3.488963
2018-12-05 07:04:43,488 - INFO - epoch 1, step 47390, training loss = 2.128826, validation loss = 3.122239
2018-12-05 07:04:46,613 - INFO - epoch 1, step 47400, training loss = 2.175919, validation loss = 3.044886
2018-12-05 07:04:49,760 - INFO - epoch 1, step 47410, training loss = 1.913704, validation loss = 3.077349
2018-12-05 07:04:52,860 - INFO - epoch 1, step 47420, training loss = 1.905188, validation loss = 2.951128
2018-12-05 07:04:56,429 - INFO - epoch 1, step 47430, training loss = 1.738599, validation loss = 3.001132
2018-12-05 07:05:00,198 - INFO - epoch 1, step 47440, training loss = 1.978463, validation loss = 3.084016
2018-12-05 07:05:04,057 - INFO - epoch 1, step 47450, training loss = 1.903816, validation loss = 3.449939
2018-12-05 07:05:07,739 - INFO - epoch 1, step 47460, training loss = 2.012480, validation loss = 2.881845
2018-12-05 07:05:11,577 - INFO - epoch 1, step 47470, training loss = 1.572294, validation loss = 3.337464
2018-12-05 07:05:15,243 - INFO - epoch 1, step 47480, training loss = 2.167064, validation loss = 3.679942
2018-12-05 07:05:19,189 - INFO - epoch 1, step 47490, training loss = 1.547329, validation loss = 3.151609
2018-12-05 07:05:22,808 - INFO - epoch 1, step 47500, training loss = 1.724481, validation loss = 2.801285
2018-12-05 07:05:26,596 - INFO - epoch 1, step 47510, training loss = 1.784645, validation loss = 2.947148
2018-12-05 07:05:30,276 - INFO - epoch 1, step 47520, training loss = 1.841340, validation loss = 3.115041
2018-12-05 07:05:33,829 - INFO - epoch 1, step 47530, training loss = 1.998513, validation loss = 3.660386
2018-12-05 07:05:37,541 - INFO - epoch 1, step 47540, training loss = 1.965810, validation loss = 3.344113
2018-12-05 07:05:41,170 - INFO - epoch 1, step 47550, training loss = 1.931420, validation loss = 3.317091
2018-12-05 07:05:44,859 - INFO - epoch 1, step 47560, training loss = 1.900844, validation loss = 3.805969
2018-12-05 07:05:48,330 - INFO - epoch 1, step 47570, training loss = 1.727360, validation loss = 3.392629
2018-12-05 07:05:51,904 - INFO - epoch 1, step 47580, training loss = 2.120127, validation loss = 3.784911
2018-12-05 07:05:55,453 - INFO - epoch 1, step 47590, training loss = 1.800773, validation loss = 3.119024
2018-12-05 07:05:58,974 - INFO - epoch 1, step 47600, training loss = 1.828465, validation loss = 3.184851
2018-12-05 07:06:02,458 - INFO - epoch 1, step 47610, training loss = 2.191896, validation loss = 3.151607
2018-12-05 07:06:06,046 - INFO - epoch 1, step 47620, training loss = 2.089211, validation loss = 3.062441
2018-12-05 07:06:09,687 - INFO - epoch 1, step 47630, training loss = 2.244498, validation loss = 3.771825
2018-12-05 07:06:12,931 - INFO - epoch 1, step 47640, training loss = 2.027375, validation loss = 3.784923
2018-12-05 07:06:15,951 - INFO - epoch 1, step 47650, training loss = 2.102875, validation loss = 3.135042
2018-12-05 07:06:19,140 - INFO - epoch 1, step 47660, training loss = 1.711218, validation loss = 3.670029
2018-12-05 07:06:22,280 - INFO - epoch 1, step 47670, training loss = 1.822511, validation loss = 3.098568
2018-12-05 07:06:25,353 - INFO - epoch 1, step 47680, training loss = 1.964062, validation loss = 3.012093
2018-12-05 07:06:28,671 - INFO - epoch 1, step 47690, training loss = 1.687943, validation loss = 3.016111
2018-12-05 07:06:31,675 - INFO - epoch 1, step 47700, training loss = 2.060457, validation loss = 3.721082
2018-12-05 07:06:34,652 - INFO - epoch 1, step 47710, training loss = 1.806905, validation loss = 3.767877
2018-12-05 07:06:38,020 - INFO - epoch 1, step 47720, training loss = 1.497061, validation loss = 3.438240
2018-12-05 07:06:41,422 - INFO - epoch 1, step 47730, training loss = 1.900052, validation loss = 3.218568
2018-12-05 07:06:44,671 - INFO - epoch 1, step 47740, training loss = 1.888167, validation loss = 3.216953
2018-12-05 07:06:48,261 - INFO - epoch 1, step 47750, training loss = 1.623891, validation loss = 3.572662
2018-12-05 07:06:51,741 - INFO - epoch 1, step 47760, training loss = 1.689042, validation loss = 3.477093
2018-12-05 07:06:55,191 - INFO - epoch 1, step 47770, training loss = 1.656330, validation loss = 3.038215
2018-12-05 07:06:58,649 - INFO - epoch 1, step 47780, training loss = 2.186538, validation loss = 3.089855
2018-12-05 07:07:02,387 - INFO - epoch 1, step 47790, training loss = 1.952589, validation loss = 3.610713
2018-12-05 07:07:06,159 - INFO - epoch 1, step 47800, training loss = 1.572505, validation loss = 3.160948
2018-12-05 07:07:10,149 - INFO - epoch 1, step 47810, training loss = 1.650482, validation loss = 3.289028
2018-12-05 07:07:13,908 - INFO - epoch 1, step 47820, training loss = 1.754849, validation loss = 3.272057
2018-12-05 07:07:17,641 - INFO - epoch 1, step 47830, training loss = 1.495587, validation loss = 3.529617
2018-12-05 07:07:21,989 - INFO - epoch 1, step 47840, training loss = 1.866875, validation loss = 3.389747
2018-12-05 07:07:25,854 - INFO - epoch 1, step 47850, training loss = 1.887569, validation loss = 3.202596
2018-12-05 07:07:30,300 - INFO - epoch 1, step 47860, training loss = 2.003531, validation loss = 3.585411
2018-12-05 07:07:34,524 - INFO - epoch 1, step 47870, training loss = 2.031165, validation loss = 3.284549
2018-12-05 07:07:39,136 - INFO - epoch 1, step 47880, training loss = 1.834908, validation loss = 3.351434
2018-12-05 07:07:43,539 - INFO - epoch 1, step 47890, training loss = 2.165611, validation loss = 3.442783
2018-12-05 07:07:47,735 - INFO - epoch 1, step 47900, training loss = 2.020450, validation loss = 3.712704
2018-12-05 07:07:52,061 - INFO - epoch 1, step 47910, training loss = 2.202294, validation loss = 3.343875
2018-12-05 07:07:56,550 - INFO - epoch 1, step 47920, training loss = 1.640500, validation loss = 3.419430
2018-12-05 07:08:01,098 - INFO - epoch 1, step 47930, training loss = 1.825847, validation loss = 3.399741
2018-12-05 07:08:05,444 - INFO - epoch 1, step 47940, training loss = 1.646214, validation loss = 3.305918
2018-12-05 07:08:09,601 - INFO - epoch 1, step 47950, training loss = 2.091174, validation loss = 3.254439
2018-12-05 07:08:13,867 - INFO - epoch 1, step 47960, training loss = 1.787660, validation loss = 3.217630
2018-12-05 07:08:18,221 - INFO - epoch 1, step 47970, training loss = 1.581757, validation loss = 3.081742
2018-12-05 07:08:22,230 - INFO - epoch 1, step 47980, training loss = 2.056299, validation loss = 3.666391
2018-12-05 07:08:26,134 - INFO - epoch 1, step 47990, training loss = 1.944651, validation loss = 3.786594
2018-12-05 07:08:30,379 - INFO - epoch 1, step 48000, training loss = 1.860144, validation loss = 3.319021
2018-12-05 07:08:34,426 - INFO - epoch 1, step 48010, training loss = 1.967254, validation loss = 3.613597
2018-12-05 07:08:38,304 - INFO - epoch 1, step 48020, training loss = 2.151381, validation loss = 3.679278
2018-12-05 07:08:41,379 - INFO - epoch 1, step 48030, training loss = 2.217451, validation loss = 3.251834
2018-12-05 07:08:44,597 - INFO - epoch 1, step 48040, training loss = 1.973196, validation loss = 3.149987
2018-12-05 07:08:47,886 - INFO - epoch 1, step 48050, training loss = 1.849107, validation loss = 2.950525
2018-12-05 07:08:50,971 - INFO - epoch 1, step 48060, training loss = 2.088890, validation loss = 2.533136
2018-12-05 07:08:54,259 - INFO - epoch 1, step 48070, training loss = 1.891540, validation loss = 3.781120
2018-12-05 07:08:57,595 - INFO - epoch 1, step 48080, training loss = 2.124332, validation loss = 3.238132
2018-12-05 07:09:01,031 - INFO - epoch 1, step 48090, training loss = 1.741545, validation loss = 3.176844
2018-12-05 07:09:04,502 - INFO - epoch 1, step 48100, training loss = 1.880781, validation loss = 2.837452
2018-12-05 07:09:07,818 - INFO - epoch 1, step 48110, training loss = 1.692528, validation loss = 3.587496
2018-12-05 07:09:11,418 - INFO - epoch 1, step 48120, training loss = 1.870725, validation loss = 3.704447
2018-12-05 07:09:15,282 - INFO - epoch 1, step 48130, training loss = 1.709756, validation loss = 3.288420
2018-12-05 07:09:18,860 - INFO - epoch 1, step 48140, training loss = 1.808222, validation loss = 3.316157
2018-12-05 07:09:22,396 - INFO - epoch 1, step 48150, training loss = 1.709111, validation loss = 3.299211
2018-12-05 07:09:26,081 - INFO - epoch 1, step 48160, training loss = 1.768651, validation loss = 3.247549
2018-12-05 07:09:30,479 - INFO - epoch 1, step 48170, training loss = 1.911675, validation loss = 3.527206
2018-12-05 07:09:34,812 - INFO - epoch 1, step 48180, training loss = 1.789658, validation loss = 2.919302
2018-12-05 07:09:39,101 - INFO - epoch 1, step 48190, training loss = 1.830866, validation loss = 3.528995
2018-12-05 07:09:43,108 - INFO - epoch 1, step 48200, training loss = 1.326151, validation loss = 3.253937
2018-12-05 07:09:47,555 - INFO - epoch 1, step 48210, training loss = 1.470328, validation loss = 3.897773
2018-12-05 07:09:51,801 - INFO - epoch 1, step 48220, training loss = 1.720055, validation loss = 3.353921
2018-12-05 07:09:55,754 - INFO - epoch 1, step 48230, training loss = 1.774128, validation loss = 3.324723
2018-12-05 07:09:59,831 - INFO - epoch 1, step 48240, training loss = 1.351501, validation loss = 3.589609
2018-12-05 07:10:03,797 - INFO - epoch 1, step 48250, training loss = 1.796022, validation loss = 3.498481
2018-12-05 07:10:07,893 - INFO - epoch 1, step 48260, training loss = 1.835011, validation loss = 3.677662
2018-12-05 07:10:11,725 - INFO - epoch 1, step 48270, training loss = 1.857381, validation loss = 3.302870
2018-12-05 07:10:15,527 - INFO - epoch 1, step 48280, training loss = 1.554945, validation loss = 3.185846
2018-12-05 07:10:19,335 - INFO - epoch 1, step 48290, training loss = 1.948524, validation loss = 3.267792
2018-12-05 07:10:23,325 - INFO - epoch 1, step 48300, training loss = 1.658497, validation loss = 3.288598
2018-12-05 07:10:27,469 - INFO - epoch 1, step 48310, training loss = 2.158912, validation loss = 3.053285
2018-12-05 07:10:31,922 - INFO - epoch 1, step 48320, training loss = 1.588222, validation loss = 2.986062
2018-12-05 07:10:36,448 - INFO - epoch 1, step 48330, training loss = 1.642341, validation loss = 3.478094
2018-12-05 07:10:40,567 - INFO - epoch 1, step 48340, training loss = 1.602625, validation loss = 2.929798
2018-12-05 07:10:44,867 - INFO - epoch 1, step 48350, training loss = 1.879018, validation loss = 3.871451
2018-12-05 07:10:49,274 - INFO - epoch 1, step 48360, training loss = 1.658172, validation loss = 3.619241
2018-12-05 07:10:53,708 - INFO - epoch 1, step 48370, training loss = 1.506357, validation loss = 2.921520
2018-12-05 07:10:58,270 - INFO - epoch 1, step 48380, training loss = 1.459757, validation loss = 3.409757
2018-12-05 07:11:02,427 - INFO - epoch 1, step 48390, training loss = 1.592102, validation loss = 3.093256
2018-12-05 07:11:06,948 - INFO - epoch 1, step 48400, training loss = 1.831166, validation loss = 3.308115
2018-12-05 07:11:11,125 - INFO - epoch 1, step 48410, training loss = 1.796201, validation loss = 3.555568
2018-12-05 07:11:15,347 - INFO - epoch 1, step 48420, training loss = 1.527373, validation loss = 3.293517
2018-12-05 07:11:19,685 - INFO - epoch 1, step 48430, training loss = 1.695368, validation loss = 3.293456
2018-12-05 07:11:23,841 - INFO - epoch 1, step 48440, training loss = 1.541066, validation loss = 3.254493
2018-12-05 07:11:28,080 - INFO - epoch 1, step 48450, training loss = 1.741195, validation loss = 3.125199
2018-12-05 07:11:32,106 - INFO - epoch 1, step 48460, training loss = 1.944935, validation loss = 3.292189
2018-12-05 07:11:36,289 - INFO - epoch 1, step 48470, training loss = 2.225442, validation loss = 3.079541
2018-12-05 07:11:39,495 - INFO - epoch 1, step 48480, training loss = 2.103557, validation loss = 3.349013
2018-12-05 07:11:42,754 - INFO - epoch 1, step 48490, training loss = 1.635348, validation loss = 3.220920
2018-12-05 07:11:45,854 - INFO - epoch 1, step 48500, training loss = 1.975468, validation loss = 3.296877
2018-12-05 07:11:48,969 - INFO - epoch 1, step 48510, training loss = 1.872645, validation loss = 3.231837
2018-12-05 07:11:52,151 - INFO - epoch 1, step 48520, training loss = 1.920034, validation loss = 3.543014
2018-12-05 07:11:55,372 - INFO - epoch 1, step 48530, training loss = 2.047370, validation loss = 3.330838
2018-12-05 07:11:58,574 - INFO - epoch 1, step 48540, training loss = 1.819867, validation loss = 3.297714
2018-12-05 07:12:01,867 - INFO - epoch 1, step 48550, training loss = 1.874236, validation loss = 3.253314
2018-12-05 07:12:05,086 - INFO - epoch 1, step 48560, training loss = 1.449760, validation loss = 3.624347
2018-12-05 07:12:08,353 - INFO - epoch 1, step 48570, training loss = 1.839318, validation loss = 3.328335
2018-12-05 07:12:11,780 - INFO - epoch 1, step 48580, training loss = 1.769519, validation loss = 3.475543
2018-12-05 07:12:15,240 - INFO - epoch 1, step 48590, training loss = 1.650700, validation loss = 3.285832
2018-12-05 07:12:18,611 - INFO - epoch 1, step 48600, training loss = 1.554813, validation loss = 3.223374
2018-12-05 07:12:22,097 - INFO - epoch 1, step 48610, training loss = 1.355161, validation loss = 3.341117
2018-12-05 07:12:25,303 - INFO - epoch 1, step 48620, training loss = 2.139279, validation loss = 3.010150
2018-12-05 07:12:29,290 - INFO - epoch 1, step 48630, training loss = 1.850397, validation loss = 3.446935
2018-12-05 07:12:33,250 - INFO - epoch 1, step 48640, training loss = 1.761195, validation loss = 2.926212
2018-12-05 07:12:37,023 - INFO - epoch 1, step 48650, training loss = 1.557937, validation loss = 3.592144
2018-12-05 07:12:41,027 - INFO - epoch 1, step 48660, training loss = 1.768553, validation loss = 3.527867
2018-12-05 07:12:44,973 - INFO - epoch 1, step 48670, training loss = 1.695686, validation loss = 2.937956
2018-12-05 07:12:49,005 - INFO - epoch 1, step 48680, training loss = 1.568109, validation loss = 3.591818
2018-12-05 07:12:53,258 - INFO - epoch 1, step 48690, training loss = 1.717057, validation loss = 3.169980
2018-12-05 07:12:57,294 - INFO - epoch 1, step 48700, training loss = 1.888794, validation loss = 2.764723
2018-12-05 07:13:01,493 - INFO - epoch 1, step 48710, training loss = 1.812762, validation loss = 3.487896
2018-12-05 07:13:05,560 - INFO - epoch 1, step 48720, training loss = 1.752207, validation loss = 3.573742
2018-12-05 07:13:09,728 - INFO - epoch 1, step 48730, training loss = 1.967142, validation loss = 3.172640
2018-12-05 07:13:13,959 - INFO - epoch 1, step 48740, training loss = 1.738771, validation loss = 2.989693
2018-12-05 07:13:18,088 - INFO - epoch 1, step 48750, training loss = 1.674258, validation loss = 2.930435
2018-12-05 07:13:22,431 - INFO - epoch 1, step 48760, training loss = 1.290730, validation loss = 3.193236
2018-12-05 07:13:26,310 - INFO - epoch 1, step 48770, training loss = 1.726346, validation loss = 3.083554
2018-12-05 07:13:30,419 - INFO - epoch 1, step 48780, training loss = 2.001469, validation loss = 3.651211
2018-12-05 07:13:34,807 - INFO - epoch 1, step 48790, training loss = 2.068353, validation loss = 2.977660
2018-12-05 07:13:39,262 - INFO - epoch 1, step 48800, training loss = 1.465513, validation loss = 3.246974
2018-12-05 07:13:43,414 - INFO - epoch 1, step 48810, training loss = 1.886628, validation loss = 3.350600
2018-12-05 07:13:47,674 - INFO - epoch 1, step 48820, training loss = 1.640730, validation loss = 3.528187
2018-12-05 07:13:51,988 - INFO - epoch 1, step 48830, training loss = 1.821714, validation loss = 2.826818
2018-12-05 07:13:56,220 - INFO - epoch 1, step 48840, training loss = 1.908497, validation loss = 3.378283
2018-12-05 07:14:00,623 - INFO - epoch 1, step 48850, training loss = 2.057569, validation loss = 3.682751
2018-12-05 07:14:04,666 - INFO - epoch 1, step 48860, training loss = 1.738570, validation loss = 3.334090
2018-12-05 07:14:08,569 - INFO - epoch 1, step 48870, training loss = 1.849722, validation loss = 3.452608
2018-12-05 07:14:12,366 - INFO - epoch 1, step 48880, training loss = 1.906000, validation loss = 3.280009
2018-12-05 07:14:16,397 - INFO - epoch 1, step 48890, training loss = 1.363936, validation loss = 3.429717
2018-12-05 07:14:20,394 - INFO - epoch 1, step 48900, training loss = 1.930915, validation loss = 3.642545
2018-12-05 07:14:24,275 - INFO - epoch 1, step 48910, training loss = 1.661696, validation loss = 3.543850
2018-12-05 07:14:28,120 - INFO - epoch 1, step 48920, training loss = 1.901908, validation loss = 3.330220
2018-12-05 07:14:31,782 - INFO - epoch 1, step 48930, training loss = 2.064983, validation loss = 3.497647
2018-12-05 07:14:35,457 - INFO - epoch 1, step 48940, training loss = 1.918895, validation loss = 3.484385
2018-12-05 07:14:39,430 - INFO - epoch 1, step 48950, training loss = 1.807737, validation loss = 2.761306
2018-12-05 07:14:43,047 - INFO - epoch 1, step 48960, training loss = 1.566434, validation loss = 2.876932
2018-12-05 07:14:46,639 - INFO - epoch 1, step 48970, training loss = 1.574399, validation loss = 3.261591
2018-12-05 07:14:50,527 - INFO - epoch 1, step 48980, training loss = 1.413208, validation loss = 3.206008
2018-12-05 07:14:54,088 - INFO - epoch 1, step 48990, training loss = 2.221965, validation loss = 3.058029
2018-12-05 07:14:57,333 - INFO - epoch 1, step 49000, training loss = 2.102996, validation loss = 3.135921
2018-12-05 07:15:00,642 - INFO - epoch 1, step 49010, training loss = 1.723394, validation loss = 3.011520
2018-12-05 07:15:03,859 - INFO - epoch 1, step 49020, training loss = 1.935975, validation loss = 3.538008
2018-12-05 07:15:06,985 - INFO - epoch 1, step 49030, training loss = 2.220515, validation loss = 3.288893
2018-12-05 07:15:10,120 - INFO - epoch 1, step 49040, training loss = 1.880191, validation loss = 3.244243
2018-12-05 07:15:13,740 - INFO - epoch 1, step 49050, training loss = 1.621831, validation loss = 3.267583
2018-12-05 07:15:17,772 - INFO - epoch 1, step 49060, training loss = 1.736795, validation loss = 3.625838
2018-12-05 07:15:21,602 - INFO - epoch 1, step 49070, training loss = 1.967845, validation loss = 2.948609
2018-12-05 07:15:25,569 - INFO - epoch 1, step 49080, training loss = 1.518605, validation loss = 3.494182
2018-12-05 07:15:29,279 - INFO - epoch 1, step 49090, training loss = 1.754990, validation loss = 3.693720
2018-12-05 07:15:33,045 - INFO - epoch 1, step 49100, training loss = 1.945971, validation loss = 3.668467
2018-12-05 07:15:36,714 - INFO - epoch 1, step 49110, training loss = 1.938487, validation loss = 3.383008
2018-12-05 07:15:40,517 - INFO - epoch 1, step 49120, training loss = 1.763667, validation loss = 3.314613
2018-12-05 07:15:44,111 - INFO - epoch 1, step 49130, training loss = 1.536410, validation loss = 3.273003
2018-12-05 07:15:47,678 - INFO - epoch 1, step 49140, training loss = 1.683787, validation loss = 3.557899
2018-12-05 07:15:51,302 - INFO - epoch 1, step 49150, training loss = 1.667744, validation loss = 3.122256
2018-12-05 07:15:54,758 - INFO - epoch 1, step 49160, training loss = 1.999895, validation loss = 3.267380
2018-12-05 07:15:58,117 - INFO - epoch 1, step 49170, training loss = 1.558921, validation loss = 3.116158
2018-12-05 07:16:01,624 - INFO - epoch 1, step 49180, training loss = 1.865289, validation loss = 2.736651
2018-12-05 07:16:05,238 - INFO - epoch 1, step 49190, training loss = 1.578198, validation loss = 3.388707
2018-12-05 07:16:09,504 - INFO - epoch 1, step 49200, training loss = 1.957328, validation loss = 3.373600
2018-12-05 07:16:13,589 - INFO - epoch 1, step 49210, training loss = 1.625149, validation loss = 3.084732
2018-12-05 07:16:17,713 - INFO - epoch 1, step 49220, training loss = 1.768319, validation loss = 3.191154
2018-12-05 07:16:21,846 - INFO - epoch 1, step 49230, training loss = 1.697585, validation loss = 3.479228
2018-12-05 07:16:25,864 - INFO - epoch 1, step 49240, training loss = 1.620526, validation loss = 3.106061
2018-12-05 07:16:29,884 - INFO - epoch 1, step 49250, training loss = 1.752346, validation loss = 3.549084
2018-12-05 07:16:34,051 - INFO - epoch 1, step 49260, training loss = 1.659843, validation loss = 3.339042
2018-12-05 07:16:38,179 - INFO - epoch 1, step 49270, training loss = 1.681461, validation loss = 3.430569
2018-12-05 07:16:41,633 - INFO - epoch 1, step 49280, training loss = 1.911900, validation loss = 3.446358
2018-12-05 07:16:45,223 - INFO - epoch 1, step 49290, training loss = 1.883680, validation loss = 3.296797
2018-12-05 07:16:48,763 - INFO - epoch 1, step 49300, training loss = 1.711698, validation loss = 3.166099
2018-12-05 07:16:52,050 - INFO - epoch 1, step 49310, training loss = 1.668554, validation loss = 3.662966
2018-12-05 07:16:55,655 - INFO - epoch 1, step 49320, training loss = 1.889779, validation loss = 3.145833
2018-12-05 07:16:59,163 - INFO - epoch 1, step 49330, training loss = 1.849784, validation loss = 3.179524
2018-12-05 07:17:02,740 - INFO - epoch 1, step 49340, training loss = 1.954883, validation loss = 3.527995
2018-12-05 07:17:05,983 - INFO - epoch 1, step 49350, training loss = 1.917215, validation loss = 3.466332
2018-12-05 07:17:09,233 - INFO - epoch 1, step 49360, training loss = 1.801122, validation loss = 3.176474
2018-12-05 07:17:12,574 - INFO - epoch 1, step 49370, training loss = 1.889457, validation loss = 2.998525
2018-12-05 07:17:15,851 - INFO - epoch 1, step 49380, training loss = 1.628680, validation loss = 2.799776
2018-12-05 07:17:19,247 - INFO - epoch 1, step 49390, training loss = 1.590999, validation loss = 2.558544
2018-12-05 07:17:22,883 - INFO - epoch 1, step 49400, training loss = 1.864755, validation loss = 3.183210
2018-12-05 07:17:25,961 - INFO - epoch 1, step 49410, training loss = 2.255905, validation loss = 3.419729
2018-12-05 07:17:28,922 - INFO - epoch 1, step 49420, training loss = 1.830049, validation loss = 3.296073
2018-12-05 07:17:32,098 - INFO - epoch 1, step 49430, training loss = 1.815751, validation loss = 2.842402
2018-12-05 07:17:35,206 - INFO - epoch 1, step 49440, training loss = 2.021771, validation loss = 3.050928
2018-12-05 07:17:38,392 - INFO - epoch 1, step 49450, training loss = 2.056169, validation loss = 3.471472
2018-12-05 07:17:41,711 - INFO - epoch 1, step 49460, training loss = 1.876702, validation loss = 2.771871
2018-12-05 07:17:44,866 - INFO - epoch 1, step 49470, training loss = 2.037011, validation loss = 3.679381
2018-12-05 07:17:48,023 - INFO - epoch 1, step 49480, training loss = 1.751566, validation loss = 3.572061
2018-12-05 07:17:52,008 - INFO - epoch 1, step 49490, training loss = 1.927019, validation loss = 3.297376
2018-12-05 07:17:55,409 - INFO - epoch 1, step 49500, training loss = 2.025939, validation loss = 3.993077
2018-12-05 07:17:58,639 - INFO - epoch 1, step 49510, training loss = 1.630757, validation loss = 3.126591
2018-12-05 07:18:01,729 - INFO - epoch 1, step 49520, training loss = 1.720631, validation loss = 3.281822
2018-12-05 07:18:04,713 - INFO - epoch 1, step 49530, training loss = 2.102694, validation loss = 3.300683
2018-12-05 07:18:07,862 - INFO - epoch 1, step 49540, training loss = 2.033931, validation loss = 3.463801
2018-12-05 07:18:11,027 - INFO - epoch 1, step 49550, training loss = 2.037632, validation loss = 3.140026
2018-12-05 07:18:14,020 - INFO - epoch 1, step 49560, training loss = 1.756246, validation loss = 3.472396
2018-12-05 07:18:17,418 - INFO - epoch 1, step 49570, training loss = 1.547898, validation loss = 3.310298
2018-12-05 07:18:21,006 - INFO - epoch 1, step 49580, training loss = 2.034327, validation loss = 3.240741
2018-12-05 07:18:24,417 - INFO - epoch 1, step 49590, training loss = 1.721764, validation loss = 3.184548
2018-12-05 07:18:27,945 - INFO - epoch 1, step 49600, training loss = 1.586972, validation loss = 3.359957
2018-12-05 07:18:31,379 - INFO - epoch 1, step 49610, training loss = 1.620880, validation loss = 4.134033
2018-12-05 07:18:34,806 - INFO - epoch 1, step 49620, training loss = 1.559393, validation loss = 2.689641
2018-12-05 07:18:38,673 - INFO - epoch 1, step 49630, training loss = 1.718322, validation loss = 3.363807
2018-12-05 07:18:42,973 - INFO - epoch 1, step 49640, training loss = 1.561096, validation loss = 3.133433
2018-12-05 07:18:47,441 - INFO - epoch 1, step 49650, training loss = 1.772321, validation loss = 2.827740
2018-12-05 07:18:51,611 - INFO - epoch 1, step 49660, training loss = 2.070144, validation loss = 3.161741
2018-12-05 07:18:55,948 - INFO - epoch 1, step 49670, training loss = 1.819862, validation loss = 3.555480
2018-12-05 07:19:00,306 - INFO - epoch 1, step 49680, training loss = 1.433767, validation loss = 3.311350
2018-12-05 07:19:04,733 - INFO - epoch 1, step 49690, training loss = 1.541278, validation loss = 3.182200
2018-12-05 07:19:09,125 - INFO - epoch 1, step 49700, training loss = 1.871178, validation loss = 2.790752
2018-12-05 07:19:13,492 - INFO - epoch 1, step 49710, training loss = 1.883699, validation loss = 3.669289
2018-12-05 07:19:17,796 - INFO - epoch 1, step 49720, training loss = 1.676065, validation loss = 2.997240
2018-12-05 07:19:21,921 - INFO - epoch 1, step 49730, training loss = 1.764686, validation loss = 3.326102
2018-12-05 07:19:26,468 - INFO - epoch 1, step 49740, training loss = 1.615145, validation loss = 3.951483
2018-12-05 07:19:30,935 - INFO - epoch 1, step 49750, training loss = 1.777804, validation loss = 2.792087
2018-12-05 07:19:35,129 - INFO - epoch 1, step 49760, training loss = 1.622405, validation loss = 3.144766
2018-12-05 07:19:39,498 - INFO - epoch 1, step 49770, training loss = 1.789201, validation loss = 2.949660
2018-12-05 07:19:44,052 - INFO - epoch 1, step 49780, training loss = 1.596762, validation loss = 3.136938
2018-12-05 07:19:48,254 - INFO - epoch 1, step 49790, training loss = 1.873946, validation loss = 3.051155
2018-12-05 07:19:51,538 - INFO - epoch 1, step 49800, training loss = 2.009601, validation loss = 2.984748
2018-12-05 07:19:54,732 - INFO - epoch 1, step 49810, training loss = 1.822806, validation loss = 3.314367
2018-12-05 07:19:57,844 - INFO - epoch 1, step 49820, training loss = 2.034680, validation loss = 3.572731
2018-12-05 07:20:01,359 - INFO - epoch 1, step 49830, training loss = 1.709067, validation loss = 3.367784
2018-12-05 07:20:04,607 - INFO - epoch 1, step 49840, training loss = 1.790345, validation loss = 3.056373
2018-12-05 07:20:07,971 - INFO - epoch 1, step 49850, training loss = 1.698649, validation loss = 3.337986
2018-12-05 07:20:11,480 - INFO - epoch 1, step 49860, training loss = 1.599035, validation loss = 3.340169
2018-12-05 07:20:14,975 - INFO - epoch 1, step 49870, training loss = 1.652582, validation loss = 3.505623
2018-12-05 07:20:18,676 - INFO - epoch 1, step 49880, training loss = 1.783948, validation loss = 2.868517
2018-12-05 07:20:22,239 - INFO - epoch 1, step 49890, training loss = 1.547950, validation loss = 3.389658
2018-12-05 07:20:25,807 - INFO - epoch 1, step 49900, training loss = 1.823942, validation loss = 3.491050
2018-12-05 07:20:29,501 - INFO - epoch 1, step 49910, training loss = 1.890795, validation loss = 3.810012
2018-12-05 07:20:32,927 - INFO - epoch 1, step 49920, training loss = 1.692611, validation loss = 4.144871
2018-12-05 07:20:36,932 - INFO - epoch 1, step 49930, training loss = 1.825814, validation loss = 3.084854
2018-12-05 07:20:41,140 - INFO - epoch 1, step 49940, training loss = 1.486379, validation loss = 3.186076
2018-12-05 07:20:45,365 - INFO - epoch 1, step 49950, training loss = 1.393165, validation loss = 2.879859
2018-12-05 07:20:49,598 - INFO - epoch 1, step 49960, training loss = 1.780195, validation loss = 3.284554
2018-12-05 07:20:53,466 - INFO - epoch 1, step 49970, training loss = 2.129360, validation loss = 3.239994
2018-12-05 07:20:57,626 - INFO - epoch 1, step 49980, training loss = 1.672657, validation loss = 2.720135
2018-12-05 07:21:01,907 - INFO - epoch 1, step 49990, training loss = 1.866132, validation loss = 3.137902
2018-12-05 07:21:06,021 - INFO - epoch 1, step 50000, training loss = 1.679382, validation loss = 3.560452
2018-12-05 07:21:10,111 - INFO - epoch 1, step 50010, training loss = 1.781515, validation loss = 3.436174
2018-12-05 07:21:14,333 - INFO - epoch 1, step 50020, training loss = 1.702536, validation loss = 3.348597
2018-12-05 07:21:18,590 - INFO - epoch 1, step 50030, training loss = 1.412394, validation loss = 2.950717
2018-12-05 07:21:22,551 - INFO - epoch 1, step 50040, training loss = 1.865427, validation loss = 3.263853
2018-12-05 07:21:26,754 - INFO - epoch 1, step 50050, training loss = 1.596293, validation loss = 3.392104
2018-12-05 07:21:31,167 - INFO - epoch 1, step 50060, training loss = 1.777283, validation loss = 2.754961
2018-12-05 07:21:35,549 - INFO - epoch 1, step 50070, training loss = 1.718228, validation loss = 3.092751
2018-12-05 07:21:40,099 - INFO - epoch 1, step 50080, training loss = 1.804481, validation loss = 3.008306
2018-12-05 07:21:43,328 - INFO - epoch 1, step 50090, training loss = 2.041519, validation loss = 3.083828
2018-12-05 07:21:46,714 - INFO - epoch 1, step 50100, training loss = 1.699513, validation loss = 3.089562
2018-12-05 07:21:49,986 - INFO - epoch 1, step 50110, training loss = 1.526756, validation loss = 3.342953
2018-12-05 07:21:53,234 - INFO - epoch 1, step 50120, training loss = 1.801734, validation loss = 2.995347
2018-12-05 07:21:56,666 - INFO - epoch 1, step 50130, training loss = 1.366367, validation loss = 3.334675
2018-12-05 07:21:59,890 - INFO - epoch 1, step 50140, training loss = 1.852234, validation loss = 3.293723
2018-12-05 07:22:03,753 - INFO - epoch 1, step 50150, training loss = 1.172949, validation loss = 3.479148
2018-12-05 07:22:07,865 - INFO - epoch 1, step 50160, training loss = 1.514070, validation loss = 3.073399
2018-12-05 07:22:11,955 - INFO - epoch 1, step 50170, training loss = 1.645576, validation loss = 3.728209
2018-12-05 07:22:16,232 - INFO - epoch 1, step 50180, training loss = 1.529402, validation loss = 3.295773
2018-12-05 07:22:20,565 - INFO - epoch 1, step 50190, training loss = 1.826761, validation loss = 3.064988
2018-12-05 07:22:24,785 - INFO - epoch 1, step 50200, training loss = 1.772828, validation loss = 3.342839
2018-12-05 07:22:28,830 - INFO - epoch 1, step 50210, training loss = 1.359136, validation loss = 3.522883
2018-12-05 07:22:32,774 - INFO - epoch 1, step 50220, training loss = 1.343382, validation loss = 2.910429
2018-12-05 07:22:36,847 - INFO - epoch 1, step 50230, training loss = 1.400867, validation loss = 3.241179
2018-12-05 07:22:41,279 - INFO - epoch 1, step 50240, training loss = 1.634390, validation loss = 3.437824
2018-12-05 07:22:45,357 - INFO - epoch 1, step 50250, training loss = 1.966674, validation loss = 3.307168
2018-12-05 07:22:49,664 - INFO - epoch 1, step 50260, training loss = 1.615556, validation loss = 3.130112
2018-12-05 07:22:53,698 - INFO - epoch 1, step 50270, training loss = 1.835332, validation loss = 2.950277
2018-12-05 07:22:57,866 - INFO - epoch 1, step 50280, training loss = 1.806543, validation loss = 2.954583
2018-12-05 07:23:02,305 - INFO - epoch 1, step 50290, training loss = 1.568430, validation loss = 3.386482
2018-12-05 07:23:06,536 - INFO - epoch 1, step 50300, training loss = 1.589230, validation loss = 3.315852
2018-12-05 07:23:10,849 - INFO - epoch 1, step 50310, training loss = 1.677819, validation loss = 2.962747
2018-12-05 07:23:14,995 - INFO - epoch 1, step 50320, training loss = 1.804514, validation loss = 3.362176
2018-12-05 07:23:19,451 - INFO - epoch 1, step 50330, training loss = 1.728016, validation loss = 2.925690
2018-12-05 07:23:23,622 - INFO - epoch 1, step 50340, training loss = 1.539796, validation loss = 2.970316
2018-12-05 07:23:28,072 - INFO - epoch 1, step 50350, training loss = 1.637266, validation loss = 3.444361
2018-12-05 07:23:32,681 - INFO - epoch 1, step 50360, training loss = 1.657809, validation loss = 2.762923
2018-12-05 07:23:36,834 - INFO - epoch 1, step 50370, training loss = 1.729819, validation loss = 3.220519
2018-12-05 07:23:40,825 - INFO - epoch 1, step 50380, training loss = 1.782952, validation loss = 3.757455
2018-12-05 07:23:44,944 - INFO - epoch 1, step 50390, training loss = 1.737021, validation loss = 3.135412
2018-12-05 07:23:49,258 - INFO - epoch 1, step 50400, training loss = 1.682282, validation loss = 3.311046
2018-12-05 07:23:53,059 - INFO - epoch 1, step 50410, training loss = 1.833604, validation loss = 3.113926
2018-12-05 07:23:56,933 - INFO - epoch 1, step 50420, training loss = 1.729762, validation loss = 3.242491
2018-12-05 07:24:00,581 - INFO - epoch 1, step 50430, training loss = 1.815678, validation loss = 3.453245
2018-12-05 07:24:04,299 - INFO - epoch 1, step 50440, training loss = 2.014649, validation loss = 3.181087
2018-12-05 07:24:08,062 - INFO - epoch 1, step 50450, training loss = 1.628499, validation loss = 2.629472
2018-12-05 07:24:11,845 - INFO - epoch 1, step 50460, training loss = 1.426882, validation loss = 3.744372
2018-12-05 07:24:15,690 - INFO - epoch 1, step 50470, training loss = 1.522939, validation loss = 3.290103
2018-12-05 07:24:18,942 - INFO - epoch 1, step 50480, training loss = 1.953469, validation loss = 3.648744
2018-12-05 07:24:22,100 - INFO - epoch 1, step 50490, training loss = 2.265776, validation loss = 3.448700
2018-12-05 07:24:25,123 - INFO - epoch 1, step 50500, training loss = 2.077957, validation loss = 3.327655
2018-12-05 07:24:28,309 - INFO - epoch 1, step 50510, training loss = 1.555894, validation loss = 3.233176
2018-12-05 07:24:31,487 - INFO - epoch 1, step 50520, training loss = 1.569633, validation loss = 3.279842
2018-12-05 07:24:34,810 - INFO - epoch 1, step 50530, training loss = 1.820358, validation loss = 3.533064
2018-12-05 07:24:38,062 - INFO - epoch 1, step 50540, training loss = 1.509744, validation loss = 3.627417
2018-12-05 07:24:41,221 - INFO - epoch 1, step 50550, training loss = 2.073995, validation loss = 3.678818
2018-12-05 07:24:45,228 - INFO - epoch 1, step 50560, training loss = 1.297111, validation loss = 3.207949
2018-12-05 07:24:49,480 - INFO - epoch 1, step 50570, training loss = 1.617328, validation loss = 3.470932
2018-12-05 07:24:53,360 - INFO - epoch 1, step 50580, training loss = 1.998285, validation loss = 2.774969
2018-12-05 07:24:57,392 - INFO - epoch 1, step 50590, training loss = 1.727585, validation loss = 3.551021
2018-12-05 07:25:01,563 - INFO - epoch 1, step 50600, training loss = 1.664444, validation loss = 3.805851
2018-12-05 07:25:05,588 - INFO - epoch 1, step 50610, training loss = 1.195430, validation loss = 3.258182
2018-12-05 07:25:09,649 - INFO - epoch 1, step 50620, training loss = 1.751935, validation loss = 3.298125
2018-12-05 07:25:13,750 - INFO - epoch 1, step 50630, training loss = 1.855761, validation loss = 3.058334
2018-12-05 07:25:18,000 - INFO - epoch 1, step 50640, training loss = 1.641611, validation loss = 2.967637
2018-12-05 07:25:22,293 - INFO - epoch 1, step 50650, training loss = 1.827289, validation loss = 3.582377
2018-12-05 07:25:26,658 - INFO - epoch 1, step 50660, training loss = 1.595669, validation loss = 2.783268
2018-12-05 07:25:31,027 - INFO - epoch 1, step 50670, training loss = 1.443709, validation loss = 3.342921
2018-12-05 07:25:35,383 - INFO - epoch 1, step 50680, training loss = 1.482682, validation loss = 3.459053
2018-12-05 07:25:39,593 - INFO - epoch 1, step 50690, training loss = 1.573001, validation loss = 3.421026
2018-12-05 07:25:43,229 - INFO - epoch 1, step 50700, training loss = 1.753555, validation loss = 3.079682
2018-12-05 07:25:47,085 - INFO - epoch 1, step 50710, training loss = 2.007527, validation loss = 3.005280
2018-12-05 07:25:50,649 - INFO - epoch 1, step 50720, training loss = 1.566078, validation loss = 3.675226
2018-12-05 07:25:54,089 - INFO - epoch 1, step 50730, training loss = 1.725900, validation loss = 2.783048
2018-12-05 07:25:57,632 - INFO - epoch 1, step 50740, training loss = 1.786856, validation loss = 3.667478
2018-12-05 07:26:01,180 - INFO - epoch 1, step 50750, training loss = 1.496829, validation loss = 3.319563
2018-12-05 07:26:04,639 - INFO - epoch 1, step 50760, training loss = 1.562039, validation loss = 3.084744
2018-12-05 07:26:07,971 - INFO - epoch 1, step 50770, training loss = 1.862243, validation loss = 3.441046
2018-12-05 07:26:11,170 - INFO - epoch 1, step 50780, training loss = 1.545552, validation loss = 3.391754
2018-12-05 07:26:14,547 - INFO - epoch 1, step 50790, training loss = 2.109581, validation loss = 3.169785
2018-12-05 07:26:18,064 - INFO - epoch 1, step 50800, training loss = 1.903412, validation loss = 3.394843
2018-12-05 07:26:21,498 - INFO - epoch 1, step 50810, training loss = 1.915387, validation loss = 3.126722
2018-12-05 07:26:25,012 - INFO - epoch 1, step 50820, training loss = 1.509488, validation loss = 3.339928
2018-12-05 07:26:28,632 - INFO - epoch 1, step 50830, training loss = 2.013841, validation loss = 3.808177
2018-12-05 07:26:32,078 - INFO - epoch 1, step 50840, training loss = 1.431288, validation loss = 3.852314
2018-12-05 07:26:35,532 - INFO - epoch 1, step 50850, training loss = 1.404938, validation loss = 3.783870
2018-12-05 07:26:39,090 - INFO - epoch 1, step 50860, training loss = 1.649321, validation loss = 2.930649
2018-12-05 07:26:42,821 - INFO - epoch 1, step 50870, training loss = 1.569971, validation loss = 3.544643
2018-12-05 07:26:46,458 - INFO - epoch 1, step 50880, training loss = 1.522743, validation loss = 3.514722
2018-12-05 07:26:49,935 - INFO - epoch 1, step 50890, training loss = 1.786151, validation loss = 3.168735
2018-12-05 07:26:54,004 - INFO - epoch 1, step 50900, training loss = 1.746063, validation loss = 3.459079
2018-12-05 07:26:57,659 - INFO - epoch 1, step 50910, training loss = 1.721584, validation loss = 2.928808
2018-12-05 07:27:01,237 - INFO - epoch 1, step 50920, training loss = 1.487802, validation loss = 2.992912
2018-12-05 07:27:04,796 - INFO - epoch 1, step 50930, training loss = 1.750797, validation loss = 3.174015
2018-12-05 07:27:08,353 - INFO - epoch 1, step 50940, training loss = 1.518511, validation loss = 3.634819
2018-12-05 07:27:11,864 - INFO - epoch 1, step 50950, training loss = 1.569424, validation loss = 3.033653
2018-12-05 07:27:15,413 - INFO - epoch 1, step 50960, training loss = 1.809205, validation loss = 3.812576
2018-12-05 07:27:18,827 - INFO - epoch 1, step 50970, training loss = 1.686209, validation loss = 2.865921
2018-12-05 07:27:22,259 - INFO - epoch 1, step 50980, training loss = 2.019631, validation loss = 3.540797
2018-12-05 07:27:25,686 - INFO - epoch 1, step 50990, training loss = 1.860645, validation loss = 3.773708
2018-12-05 07:27:28,997 - INFO - epoch 1, step 51000, training loss = 2.234249, validation loss = 3.251755
2018-12-05 07:27:32,444 - INFO - epoch 1, step 51010, training loss = 1.657016, validation loss = 3.014347
2018-12-05 07:27:35,993 - INFO - epoch 1, step 51020, training loss = 1.498528, validation loss = 3.512348
2018-12-05 07:27:39,071 - INFO - epoch 1, step 51030, training loss = 1.914927, validation loss = 3.122604
2018-12-05 07:27:42,396 - INFO - epoch 1, step 51040, training loss = 1.639135, validation loss = 3.707097
2018-12-05 07:27:46,189 - INFO - epoch 1, step 51050, training loss = 1.918744, validation loss = 3.967888
2018-12-05 07:27:50,058 - INFO - epoch 1, step 51060, training loss = 1.901493, validation loss = 3.146874
2018-12-05 07:27:53,937 - INFO - epoch 1, step 51070, training loss = 1.909777, validation loss = 3.499765
2018-12-05 07:27:57,842 - INFO - epoch 1, step 51080, training loss = 1.424076, validation loss = 3.406770
2018-12-05 07:28:01,921 - INFO - epoch 1, step 51090, training loss = 1.913146, validation loss = 3.527607
2018-12-05 07:28:05,891 - INFO - epoch 1, step 51100, training loss = 1.669865, validation loss = 3.486442
2018-12-05 07:28:09,829 - INFO - epoch 1, step 51110, training loss = 1.829568, validation loss = 2.908706
2018-12-05 07:28:13,899 - INFO - epoch 1, step 51120, training loss = 1.545945, validation loss = 3.116668
2018-12-05 07:28:17,788 - INFO - epoch 1, step 51130, training loss = 1.380551, validation loss = 2.889298
2018-12-05 07:28:21,471 - INFO - epoch 1, step 51140, training loss = 1.482888, validation loss = 3.838456
2018-12-05 07:28:25,438 - INFO - epoch 1, step 51150, training loss = 1.313227, validation loss = 3.146919
2018-12-05 07:28:29,303 - INFO - epoch 1, step 51160, training loss = 1.311796, validation loss = 3.241827
2018-12-05 07:28:33,195 - INFO - epoch 1, step 51170, training loss = 1.772770, validation loss = 3.394335
2018-12-05 07:28:36,871 - INFO - epoch 1, step 51180, training loss = 1.931894, validation loss = 3.473573
2018-12-05 07:28:40,420 - INFO - epoch 1, step 51190, training loss = 1.657301, validation loss = 3.252724
2018-12-05 07:28:44,060 - INFO - epoch 1, step 51200, training loss = 1.703672, validation loss = 3.104355
2018-12-05 07:28:47,579 - INFO - epoch 1, step 51210, training loss = 1.800966, validation loss = 3.287616
2018-12-05 07:28:50,943 - INFO - epoch 1, step 51220, training loss = 1.561522, validation loss = 3.122786
2018-12-05 07:28:54,517 - INFO - epoch 1, step 51230, training loss = 1.747537, validation loss = 3.809970
2018-12-05 07:28:57,962 - INFO - epoch 1, step 51240, training loss = 1.689135, validation loss = 3.470399
2018-12-05 07:29:01,490 - INFO - epoch 1, step 51250, training loss = 1.619078, validation loss = 3.025551
2018-12-05 07:29:05,008 - INFO - epoch 1, step 51260, training loss = 1.479768, validation loss = 3.546614
2018-12-05 07:29:08,303 - INFO - epoch 1, step 51270, training loss = 1.966267, validation loss = 3.377701
2018-12-05 07:29:11,677 - INFO - epoch 1, step 51280, training loss = 2.044227, validation loss = 3.298684
2018-12-05 07:29:14,992 - INFO - epoch 1, step 51290, training loss = 1.719295, validation loss = 3.494534
2018-12-05 07:29:18,470 - INFO - epoch 1, step 51300, training loss = 1.942160, validation loss = 3.331934
2018-12-05 07:29:21,601 - INFO - epoch 1, step 51310, training loss = 1.860734, validation loss = 3.089294
2018-12-05 07:29:24,737 - INFO - epoch 1, step 51320, training loss = 1.827769, validation loss = 3.431878
2018-12-05 07:29:27,882 - INFO - epoch 1, step 51330, training loss = 1.829031, validation loss = 3.265967
2018-12-05 07:29:31,015 - INFO - epoch 1, step 51340, training loss = 1.977905, validation loss = 3.597668
2018-12-05 07:29:34,026 - INFO - epoch 1, step 51350, training loss = 2.107555, validation loss = 2.939173
2018-12-05 07:29:37,028 - INFO - epoch 1, step 51360, training loss = 1.624833, validation loss = 3.747414
2018-12-05 07:29:40,223 - INFO - epoch 1, step 51370, training loss = 2.025488, validation loss = 2.917722
2018-12-05 07:29:43,410 - INFO - epoch 1, step 51380, training loss = 1.855950, validation loss = 3.423585
2018-12-05 07:29:46,574 - INFO - epoch 1, step 51390, training loss = 1.822991, validation loss = 3.477753
2018-12-05 07:29:49,646 - INFO - epoch 1, step 51400, training loss = 1.979932, validation loss = 3.111908
2018-12-05 07:29:52,857 - INFO - epoch 1, step 51410, training loss = 2.181714, validation loss = 3.404963
2018-12-05 07:29:56,204 - INFO - epoch 1, step 51420, training loss = 1.932857, validation loss = 2.921783
2018-12-05 07:30:00,318 - INFO - epoch 1, step 51430, training loss = 1.384424, validation loss = 3.294215
2018-12-05 07:30:04,012 - INFO - epoch 1, step 51440, training loss = 1.543129, validation loss = 3.396455
2018-12-05 07:30:08,063 - INFO - epoch 1, step 51450, training loss = 1.574448, validation loss = 3.555500
2018-12-05 07:30:12,326 - INFO - epoch 1, step 51460, training loss = 1.711807, validation loss = 3.331524
2018-12-05 07:30:16,235 - INFO - epoch 1, step 51470, training loss = 1.767256, validation loss = 3.481549
2018-12-05 07:30:20,515 - INFO - epoch 1, step 51480, training loss = 1.625231, validation loss = 3.431990
2018-12-05 07:30:24,390 - INFO - epoch 1, step 51490, training loss = 1.578967, validation loss = 3.674424
2018-12-05 07:30:28,449 - INFO - epoch 1, step 51500, training loss = 1.556043, validation loss = 3.269389
2018-12-05 07:30:32,502 - INFO - epoch 1, step 51510, training loss = 1.745836, validation loss = 3.309095
2018-12-05 07:30:36,566 - INFO - epoch 1, step 51520, training loss = 1.792163, validation loss = 2.841740
2018-12-05 07:30:40,529 - INFO - epoch 1, step 51530, training loss = 1.243699, validation loss = 3.767481
2018-12-05 07:30:44,779 - INFO - epoch 1, step 51540, training loss = 1.626121, validation loss = 3.188431
2018-12-05 07:30:48,955 - INFO - epoch 1, step 51550, training loss = 1.704430, validation loss = 3.112504
2018-12-05 07:30:52,656 - INFO - epoch 1, step 51560, training loss = 1.798964, validation loss = 3.220931
2018-12-05 07:30:56,235 - INFO - epoch 1, step 51570, training loss = 1.944018, validation loss = 3.293495
2018-12-05 07:31:00,196 - INFO - epoch 1, step 51580, training loss = 1.861127, validation loss = 2.801200
2018-12-05 07:31:04,100 - INFO - epoch 1, step 51590, training loss = 1.801868, validation loss = 2.636279
2018-12-05 07:31:08,166 - INFO - epoch 1, step 51600, training loss = 1.728793, validation loss = 3.073142
2018-12-05 07:31:12,149 - INFO - epoch 1, step 51610, training loss = 1.669695, validation loss = 3.269255
2018-12-05 07:31:16,211 - INFO - epoch 1, step 51620, training loss = 1.945237, validation loss = 3.348607
2018-12-05 07:31:20,150 - INFO - epoch 1, step 51630, training loss = 2.012113, validation loss = 2.929288
2018-12-05 07:31:23,961 - INFO - epoch 1, step 51640, training loss = 1.527578, validation loss = 2.674942
2018-12-05 07:31:27,888 - INFO - epoch 1, step 51650, training loss = 1.648132, validation loss = 3.158664
2018-12-05 07:31:31,659 - INFO - epoch 1, step 51660, training loss = 1.797341, validation loss = 3.268693
2018-12-05 07:31:35,494 - INFO - epoch 1, step 51670, training loss = 1.497512, validation loss = 2.448786
2018-12-05 07:31:39,257 - INFO - epoch 1, step 51680, training loss = 1.698916, validation loss = 3.464226
2018-12-05 07:31:43,081 - INFO - epoch 1, step 51690, training loss = 1.308838, validation loss = 2.890357
2018-12-05 07:31:46,772 - INFO - epoch 1, step 51700, training loss = 1.723519, validation loss = 2.777066
2018-12-05 07:31:50,824 - INFO - epoch 1, step 51710, training loss = 1.543997, validation loss = 3.516686
2018-12-05 07:31:54,992 - INFO - epoch 1, step 51720, training loss = 1.428969, validation loss = 2.121947
2018-12-05 07:31:59,350 - INFO - epoch 1, step 51730, training loss = 1.354978, validation loss = 2.932158
2018-12-05 07:32:03,629 - INFO - epoch 1, step 51740, training loss = 1.846387, validation loss = 2.862448
2018-12-05 07:32:07,856 - INFO - epoch 1, step 51750, training loss = 1.640740, validation loss = 3.009363
2018-12-05 07:32:11,998 - INFO - epoch 1, step 51760, training loss = 1.367849, validation loss = 2.894966
2018-12-05 07:32:16,158 - INFO - epoch 1, step 51770, training loss = 1.810593, validation loss = 3.108957
2018-12-05 07:32:20,609 - INFO - epoch 1, step 51780, training loss = 1.589644, validation loss = 2.625898
2018-12-05 07:32:25,120 - INFO - epoch 1, step 51790, training loss = 2.001684, validation loss = 2.704068
2018-12-05 07:32:29,676 - INFO - epoch 1, step 51800, training loss = 1.812377, validation loss = 2.375027
2018-12-05 07:32:34,022 - INFO - epoch 1, step 51810, training loss = 1.877094, validation loss = 2.311697
2018-12-05 07:32:38,355 - INFO - epoch 1, step 51820, training loss = 1.570106, validation loss = 2.920636
2018-12-05 07:32:42,496 - INFO - epoch 1, step 51830, training loss = 1.811213, validation loss = 2.931431
2018-12-05 07:32:46,895 - INFO - epoch 1, step 51840, training loss = 1.512650, validation loss = 2.218202
2018-12-05 07:32:50,857 - INFO - epoch 1, step 51850, training loss = 1.998542, validation loss = 3.121458
2018-12-05 07:32:54,001 - INFO - epoch 1, step 51860, training loss = 1.676422, validation loss = 3.078327
2018-12-05 07:32:57,342 - INFO - epoch 1, step 51870, training loss = 1.990310, validation loss = 2.564044
2018-12-05 07:33:00,521 - INFO - epoch 1, step 51880, training loss = 2.147413, validation loss = 3.345191
2018-12-05 07:33:03,799 - INFO - epoch 1, step 51890, training loss = 1.534079, validation loss = 3.409733
2018-12-05 07:33:06,976 - INFO - epoch 1, step 51900, training loss = 1.748707, validation loss = 3.294801
2018-12-05 07:33:10,196 - INFO - epoch 1, step 51910, training loss = 1.663078, validation loss = 2.818913
2018-12-05 07:33:13,372 - INFO - epoch 1, step 51920, training loss = 1.713681, validation loss = 2.756227
2018-12-05 07:33:16,400 - INFO - epoch 1, step 51930, training loss = 2.182223, validation loss = 3.379634
2018-12-05 07:33:19,805 - INFO - epoch 1, step 51940, training loss = 1.875221, validation loss = 2.531661
2018-12-05 07:33:23,125 - INFO - epoch 1, step 51950, training loss = 1.772858, validation loss = 3.141450
2018-12-05 07:33:26,697 - INFO - epoch 1, step 51960, training loss = 2.013948, validation loss = 2.494364
2018-12-05 07:33:29,959 - INFO - epoch 1, step 51970, training loss = 1.805443, validation loss = 2.982303
2018-12-05 07:33:33,389 - INFO - epoch 1, step 51980, training loss = 1.736908, validation loss = 2.643797
2018-12-05 07:33:36,604 - INFO - epoch 1, step 51990, training loss = 1.841412, validation loss = 2.419395
2018-12-05 07:33:40,754 - INFO - epoch 1, step 52000, training loss = 1.922688, validation loss = 2.578087
2018-12-05 07:33:44,816 - INFO - epoch 1, step 52010, training loss = 1.589477, validation loss = 2.817353
2018-12-05 07:33:48,751 - INFO - epoch 1, step 52020, training loss = 1.542396, validation loss = 3.312042
2018-12-05 07:33:52,984 - INFO - epoch 1, step 52030, training loss = 1.609299, validation loss = 3.112449
2018-12-05 07:33:56,880 - INFO - epoch 1, step 52040, training loss = 1.984227, validation loss = 3.032443
2018-12-05 07:34:00,989 - INFO - epoch 1, step 52050, training loss = 1.841325, validation loss = 3.581866
2018-12-05 07:34:05,234 - INFO - epoch 1, step 52060, training loss = 1.452022, validation loss = 3.379760
2018-12-05 07:34:09,413 - INFO - epoch 1, step 52070, training loss = 1.892708, validation loss = 3.455539
2018-12-05 07:34:13,622 - INFO - epoch 1, step 52080, training loss = 1.429393, validation loss = 3.746928
2018-12-05 07:34:17,767 - INFO - epoch 1, step 52090, training loss = 1.604195, validation loss = 3.234645
2018-12-05 07:34:21,780 - INFO - epoch 1, step 52100, training loss = 1.555791, validation loss = 3.819774
2018-12-05 07:34:26,156 - INFO - epoch 1, step 52110, training loss = 1.505247, validation loss = 3.668419
2018-12-05 07:34:30,402 - INFO - epoch 1, step 52120, training loss = 1.528690, validation loss = 3.264174
2018-12-05 07:34:34,580 - INFO - epoch 1, step 52130, training loss = 1.582817, validation loss = 3.319589
2018-12-05 07:34:38,825 - INFO - epoch 1, step 52140, training loss = 1.523378, validation loss = 3.160923
2018-12-05 07:34:42,221 - INFO - epoch 1, step 52150, training loss = 1.556978, validation loss = 3.873110
2018-12-05 07:34:45,344 - INFO - epoch 1, step 52160, training loss = 2.017708, validation loss = 3.176955
2018-12-05 07:34:48,570 - INFO - epoch 1, step 52170, training loss = 1.786957, validation loss = 4.008681
2018-12-05 07:34:51,702 - INFO - epoch 1, step 52180, training loss = 1.964588, validation loss = 3.212392
2018-12-05 07:34:54,993 - INFO - epoch 1, step 52190, training loss = 1.509481, validation loss = 3.540957
2018-12-05 07:34:58,629 - INFO - epoch 1, step 52200, training loss = 1.787254, validation loss = 4.219459
2018-12-05 07:35:01,918 - INFO - epoch 1, step 52210, training loss = 1.866139, validation loss = 3.238194
2018-12-05 07:35:05,157 - INFO - epoch 1, step 52220, training loss = 1.693151, validation loss = 3.446444
2018-12-05 07:35:08,375 - INFO - epoch 1, step 52230, training loss = 1.780490, validation loss = 3.694163
2018-12-05 07:35:11,568 - INFO - epoch 1, step 52240, training loss = 1.932277, validation loss = 3.073294
2018-12-05 07:35:14,737 - INFO - epoch 1, step 52250, training loss = 2.030699, validation loss = 2.974039
2018-12-05 07:35:17,867 - INFO - epoch 1, step 52260, training loss = 1.637387, validation loss = 3.229115
2018-12-05 07:35:21,150 - INFO - epoch 1, step 52270, training loss = 1.670581, validation loss = 3.656013
2018-12-05 07:35:24,459 - INFO - epoch 1, step 52280, training loss = 1.250772, validation loss = 3.317392
2018-12-05 07:35:27,957 - INFO - epoch 1, step 52290, training loss = 1.782684, validation loss = 3.133440
2018-12-05 07:35:31,244 - INFO - epoch 1, step 52300, training loss = 1.721012, validation loss = 3.790136
2018-12-05 07:35:35,855 - INFO - epoch 1, step 52310, training loss = 1.833448, validation loss = 2.940435
2018-12-05 07:35:40,165 - INFO - epoch 1, step 52320, training loss = 1.973908, validation loss = 3.204689
2018-12-05 07:35:44,539 - INFO - epoch 1, step 52330, training loss = 1.867480, validation loss = 3.900666
2018-12-05 07:35:48,995 - INFO - epoch 1, step 52340, training loss = 1.423464, validation loss = 3.496811
2018-12-05 07:35:53,277 - INFO - epoch 1, step 52350, training loss = 1.460354, validation loss = 3.129655
2018-12-05 07:35:57,974 - INFO - epoch 1, step 52360, training loss = 1.621791, validation loss = 2.961680
2018-12-05 07:36:02,473 - INFO - epoch 1, step 52370, training loss = 1.512271, validation loss = 3.534079
2018-12-05 07:36:06,148 - INFO - epoch 1, step 52380, training loss = 1.822871, validation loss = 3.274134
2018-12-05 07:36:09,235 - INFO - epoch 1, step 52390, training loss = 1.799480, validation loss = 3.336689
2018-12-05 07:36:12,338 - INFO - epoch 1, step 52400, training loss = 1.874326, validation loss = 3.368891
2018-12-05 07:36:15,679 - INFO - epoch 1, step 52410, training loss = 1.765576, validation loss = 3.751986
2018-12-05 07:36:18,912 - INFO - epoch 1, step 52420, training loss = 1.975022, validation loss = 3.626893
2018-12-05 07:36:22,041 - INFO - epoch 1, step 52430, training loss = 1.831707, validation loss = 3.318643
2018-12-05 07:36:25,202 - INFO - epoch 1, step 52440, training loss = 1.586805, validation loss = 3.099930
2018-12-05 07:36:28,348 - INFO - epoch 1, step 52450, training loss = 1.924965, validation loss = 3.573328
2018-12-05 07:36:31,616 - INFO - epoch 1, step 52460, training loss = 1.675392, validation loss = 3.388008
2018-12-05 07:36:34,967 - INFO - epoch 1, step 52470, training loss = 1.818714, validation loss = 2.984943
2018-12-05 07:36:38,114 - INFO - epoch 1, step 52480, training loss = 1.665431, validation loss = 3.167135
2018-12-05 07:36:41,441 - INFO - epoch 1, step 52490, training loss = 1.751955, validation loss = 2.958674
2018-12-05 07:36:44,586 - INFO - epoch 1, step 52500, training loss = 1.478594, validation loss = 3.723410
2018-12-05 07:36:47,864 - INFO - epoch 1, step 52510, training loss = 1.683680, validation loss = 2.972841
2018-12-05 07:36:51,349 - INFO - epoch 1, step 52520, training loss = 1.857057, validation loss = 3.580298
2018-12-05 07:36:55,239 - INFO - epoch 1, step 52530, training loss = 1.474692, validation loss = 3.549014
2018-12-05 07:36:59,138 - INFO - epoch 1, step 52540, training loss = 1.937689, validation loss = 3.537878
2018-12-05 07:37:03,290 - INFO - epoch 1, step 52550, training loss = 1.782316, validation loss = 2.665257
2018-12-05 07:37:07,351 - INFO - epoch 1, step 52560, training loss = 1.887549, validation loss = 3.578918
2018-12-05 07:37:11,386 - INFO - epoch 1, step 52570, training loss = 1.835459, validation loss = 3.492946
2018-12-05 07:37:15,534 - INFO - epoch 1, step 52580, training loss = 1.790883, validation loss = 2.894769
2018-12-05 07:37:19,359 - INFO - epoch 1, step 52590, training loss = 1.630478, validation loss = 3.550260
2018-12-05 07:37:23,107 - INFO - epoch 1, step 52600, training loss = 1.935039, validation loss = 3.091022
2018-12-05 07:37:26,517 - INFO - epoch 1, step 52610, training loss = 1.882887, validation loss = 3.219448
2018-12-05 07:37:29,815 - INFO - epoch 1, step 52620, training loss = 1.520113, validation loss = 1.855495
2018-12-05 07:37:33,497 - INFO - epoch 1, step 52630, training loss = 1.379867, validation loss = 1.834521
2018-12-05 07:37:36,917 - INFO - epoch 1, step 52640, training loss = 1.590250, validation loss = 1.993693
2018-12-05 07:37:40,227 - INFO - epoch 1, step 52650, training loss = 1.731896, validation loss = 1.848909
2018-12-05 07:37:43,413 - INFO - epoch 1, step 52660, training loss = 1.856746, validation loss = 2.026817
2018-12-05 07:37:47,363 - INFO - epoch 1, step 52670, training loss = 1.817979, validation loss = 2.127918
2018-12-05 07:37:51,529 - INFO - epoch 1, step 52680, training loss = 1.752730, validation loss = 1.855021
2018-12-05 07:37:55,681 - INFO - epoch 1, step 52690, training loss = 1.702959, validation loss = 2.047750
2018-12-05 07:37:59,822 - INFO - epoch 1, step 52700, training loss = 1.651226, validation loss = 1.427932
2018-12-05 07:38:03,886 - INFO - epoch 1, step 52710, training loss = 1.733339, validation loss = 1.492827
2018-12-05 07:38:08,219 - INFO - epoch 1, step 52720, training loss = 1.112059, validation loss = 1.942241
2018-12-05 07:38:12,344 - INFO - epoch 1, step 52730, training loss = 1.768884, validation loss = 1.696535
2018-12-05 07:38:16,548 - INFO - epoch 1, step 52740, training loss = 1.770987, validation loss = 2.354613
2018-12-05 07:38:20,724 - INFO - epoch 1, step 52750, training loss = 1.690402, validation loss = 1.652692
2018-12-05 07:38:25,031 - INFO - epoch 1, step 52760, training loss = 1.434018, validation loss = 1.987059
2018-12-05 07:38:29,170 - INFO - epoch 1, step 52770, training loss = 1.725331, validation loss = 1.993752
2018-12-05 07:38:33,470 - INFO - epoch 1, step 52780, training loss = 1.809179, validation loss = 1.796144
2018-12-05 07:38:37,616 - INFO - epoch 1, step 52790, training loss = 1.575956, validation loss = 2.060029
2018-12-05 07:38:41,823 - INFO - epoch 1, step 52800, training loss = 1.718803, validation loss = 1.851634
2018-12-05 07:38:46,211 - INFO - epoch 1, step 52810, training loss = 1.640876, validation loss = 1.449195
2018-12-05 07:38:50,641 - INFO - epoch 1, step 52820, training loss = 1.819679, validation loss = 1.988968
2018-12-05 07:38:55,248 - INFO - epoch 1, step 52830, training loss = 1.475242, validation loss = 1.564509
2018-12-05 07:38:59,460 - INFO - epoch 1, step 52840, training loss = 2.014509, validation loss = 2.194108
2018-12-05 07:39:03,699 - INFO - epoch 1, step 52850, training loss = 1.722630, validation loss = 2.002633
2018-12-05 07:39:07,984 - INFO - epoch 1, step 52860, training loss = 1.770352, validation loss = 2.074149
2018-12-05 07:39:11,937 - INFO - epoch 1, step 52870, training loss = 1.769068, validation loss = 2.241724
2018-12-05 07:39:15,320 - INFO - epoch 1, step 52880, training loss = 1.628164, validation loss = 2.278541
2018-12-05 07:39:18,553 - INFO - epoch 1, step 52890, training loss = 1.747793, validation loss = 1.861057
2018-12-05 07:39:21,721 - INFO - epoch 1, step 52900, training loss = 1.700513, validation loss = 2.261283
2018-12-05 07:39:24,833 - INFO - epoch 1, step 52910, training loss = 1.918781, validation loss = 2.012102
2018-12-05 07:39:27,927 - INFO - epoch 1, step 52920, training loss = 1.833840, validation loss = 1.983544
2018-12-05 07:39:31,040 - INFO - epoch 1, step 52930, training loss = 1.440805, validation loss = 1.960058
2018-12-05 07:39:34,027 - INFO - epoch 1, step 52940, training loss = 1.708587, validation loss = 1.773530
2018-12-05 07:39:37,314 - INFO - epoch 1, step 52950, training loss = 1.629605, validation loss = 2.117888
2018-12-05 07:39:40,420 - INFO - epoch 1, step 52960, training loss = 1.842356, validation loss = 2.169322
2018-12-05 07:39:43,443 - INFO - epoch 1, step 52970, training loss = 1.716357, validation loss = 1.875991
2018-12-05 07:39:46,605 - INFO - epoch 1, step 52980, training loss = 1.842938, validation loss = 2.098978
2018-12-05 07:39:49,717 - INFO - epoch 1, step 52990, training loss = 1.268693, validation loss = 1.862940
2018-12-05 07:39:52,962 - INFO - epoch 1, step 53000, training loss = 1.605278, validation loss = 1.822445
2018-12-05 07:39:56,056 - INFO - epoch 1, step 53010, training loss = 2.156602, validation loss = 2.047462
2018-12-05 07:39:59,601 - INFO - epoch 1, step 53020, training loss = 1.797681, validation loss = 1.833566
2018-12-05 07:40:02,895 - INFO - epoch 1, step 53030, training loss = 1.854126, validation loss = 2.173887
2018-12-05 07:40:06,329 - INFO - epoch 1, step 53040, training loss = 1.508260, validation loss = 2.134376
2018-12-05 07:40:09,898 - INFO - epoch 1, step 53050, training loss = 1.549369, validation loss = 2.050826
2018-12-05 07:40:13,466 - INFO - epoch 1, step 53060, training loss = 1.538399, validation loss = 2.048251
2018-12-05 07:40:17,085 - INFO - epoch 1, step 53070, training loss = 2.023551, validation loss = 1.875276
2018-12-05 07:40:20,622 - INFO - epoch 1, step 53080, training loss = 1.702764, validation loss = 2.004596
2018-12-05 07:40:24,251 - INFO - epoch 1, step 53090, training loss = 1.510545, validation loss = 1.981161
2018-12-05 07:40:27,967 - INFO - epoch 1, step 53100, training loss = 1.398222, validation loss = 2.163137
2018-12-05 07:40:31,719 - INFO - epoch 1, step 53110, training loss = 1.634359, validation loss = 2.011853
2018-12-05 07:40:35,430 - INFO - epoch 1, step 53120, training loss = 1.745685, validation loss = 1.818493
2018-12-05 07:40:39,288 - INFO - epoch 1, step 53130, training loss = 1.655928, validation loss = 2.023689
2018-12-05 07:40:43,184 - INFO - epoch 1, step 53140, training loss = 1.667781, validation loss = 1.983652
2018-12-05 07:40:46,886 - INFO - epoch 1, step 53150, training loss = 1.785643, validation loss = 1.657383
2018-12-05 07:40:50,450 - INFO - epoch 1, step 53160, training loss = 1.953674, validation loss = 1.866008
2018-12-05 07:40:53,405 - INFO - epoch 1, step 53170, training loss = 1.719362, validation loss = 1.880544
2018-12-05 07:40:56,663 - INFO - epoch 1, step 53180, training loss = 1.574785, validation loss = 2.016588
2018-12-05 07:40:59,783 - INFO - epoch 1, step 53190, training loss = 1.662489, validation loss = 1.833345
2018-12-05 07:41:02,983 - INFO - epoch 1, step 53200, training loss = 1.683596, validation loss = 1.700506
2018-12-05 07:41:06,104 - INFO - epoch 1, step 53210, training loss = 1.657275, validation loss = 1.772541
2018-12-05 07:41:09,183 - INFO - epoch 1, step 53220, training loss = 1.961551, validation loss = 1.482847
2018-12-05 07:41:12,364 - INFO - epoch 1, step 53230, training loss = 1.900574, validation loss = 1.253182
2018-12-05 07:41:15,952 - INFO - epoch 1, step 53240, training loss = 1.593775, validation loss = 1.888437
2018-12-05 07:41:19,649 - INFO - epoch 1, step 53250, training loss = 1.899932, validation loss = 2.015086
2018-12-05 07:41:23,643 - INFO - epoch 1, step 53260, training loss = 1.698061, validation loss = 2.003258
2018-12-05 07:41:27,585 - INFO - epoch 1, step 53270, training loss = 1.656342, validation loss = 1.697410
2018-12-05 07:41:31,153 - INFO - epoch 1, step 53280, training loss = 1.499525, validation loss = 1.821717
2018-12-05 07:41:34,812 - INFO - epoch 1, step 53290, training loss = 1.613360, validation loss = 1.921711
2018-12-05 07:41:38,959 - INFO - epoch 1, step 53300, training loss = 1.373928, validation loss = 1.683557
2018-12-05 07:41:42,625 - INFO - epoch 1, step 53310, training loss = 1.988251, validation loss = 1.565901
2018-12-05 07:41:46,497 - INFO - epoch 1, step 53320, training loss = 1.635555, validation loss = 2.115947
2018-12-05 07:41:50,874 - INFO - epoch 1, step 53330, training loss = 1.922663, validation loss = 1.803853
2018-12-05 07:41:55,143 - INFO - epoch 1, step 53340, training loss = 1.737965, validation loss = 1.574057
2018-12-05 07:41:59,624 - INFO - epoch 1, step 53350, training loss = 1.534080, validation loss = 1.980884
2018-12-05 07:42:03,782 - INFO - epoch 1, step 53360, training loss = 1.983329, validation loss = 1.693786
2018-12-05 07:42:08,170 - INFO - epoch 1, step 53370, training loss = 1.606926, validation loss = 1.488488
2018-12-05 07:42:12,276 - INFO - epoch 1, step 53380, training loss = 1.580525, validation loss = 1.725620
2018-12-05 07:42:16,421 - INFO - epoch 1, step 53390, training loss = 1.862350, validation loss = 1.777613
2018-12-05 07:42:20,956 - INFO - epoch 1, step 53400, training loss = 1.513176, validation loss = 1.739618
2018-12-05 07:42:25,504 - INFO - epoch 1, step 53410, training loss = 1.538503, validation loss = 1.880771
2018-12-05 07:42:30,040 - INFO - epoch 1, step 53420, training loss = 1.221514, validation loss = 1.779796
2018-12-05 07:42:34,373 - INFO - epoch 1, step 53430, training loss = 1.887829, validation loss = 1.246981
2018-12-05 07:42:38,864 - INFO - epoch 1, step 53440, training loss = 1.178060, validation loss = 1.724452
2018-12-05 07:42:43,228 - INFO - epoch 1, step 53450, training loss = 1.977593, validation loss = 1.432440
2018-12-05 07:42:47,741 - INFO - epoch 1, step 53460, training loss = 1.474075, validation loss = 1.785009
2018-12-05 07:42:52,102 - INFO - epoch 1, step 53470, training loss = 1.421822, validation loss = 1.724742
2018-12-05 07:42:55,944 - INFO - epoch 1, step 53480, training loss = 1.614992, validation loss = 1.573869
2018-12-05 07:42:59,669 - INFO - epoch 1, step 53490, training loss = 1.507066, validation loss = 1.667268
2018-12-05 07:43:03,304 - INFO - epoch 1, step 53500, training loss = 1.674423, validation loss = 1.632094
2018-12-05 07:43:06,801 - INFO - epoch 1, step 53510, training loss = 1.580330, validation loss = 2.033085
2018-12-05 07:43:10,279 - INFO - epoch 1, step 53520, training loss = 1.569958, validation loss = 1.806832
2018-12-05 07:43:13,920 - INFO - epoch 1, step 53530, training loss = 1.590340, validation loss = 1.575202
2018-12-05 07:43:17,314 - INFO - epoch 1, step 53540, training loss = 1.726096, validation loss = 1.748769
2018-12-05 07:43:20,794 - INFO - epoch 1, step 53550, training loss = 1.909740, validation loss = 2.058696
2018-12-05 07:43:24,000 - INFO - epoch 1, step 53560, training loss = 1.546121, validation loss = 1.575095
2018-12-05 07:43:27,288 - INFO - epoch 1, step 53570, training loss = 1.813039, validation loss = 1.583433
2018-12-05 07:43:30,487 - INFO - epoch 1, step 53580, training loss = 1.636853, validation loss = 1.918393
2018-12-05 07:43:33,826 - INFO - epoch 1, step 53590, training loss = 2.003533, validation loss = 1.927806
2018-12-05 07:43:37,037 - INFO - epoch 1, step 53600, training loss = 1.736075, validation loss = 1.841096
2018-12-05 07:43:40,350 - INFO - epoch 1, step 53610, training loss = 1.470150, validation loss = 1.806825
2018-12-05 07:43:43,694 - INFO - epoch 1, step 53620, training loss = 1.713020, validation loss = 1.736251
2018-12-05 07:43:47,995 - INFO - epoch 1, step 53630, training loss = 1.595566, validation loss = 1.479724
2018-12-05 07:43:52,048 - INFO - epoch 1, step 53640, training loss = 1.383563, validation loss = 2.007574
2018-12-05 07:43:55,843 - INFO - epoch 1, step 53650, training loss = 1.849304, validation loss = 1.658301
2018-12-05 07:43:59,586 - INFO - epoch 1, step 53660, training loss = 1.580700, validation loss = 1.839684
2018-12-05 07:44:03,429 - INFO - epoch 1, step 53670, training loss = 1.534611, validation loss = 1.662467
2018-12-05 07:44:06,971 - INFO - epoch 1, step 53680, training loss = 1.923960, validation loss = 1.643335
2018-12-05 07:44:10,768 - INFO - epoch 1, step 53690, training loss = 1.380333, validation loss = 2.019137
2018-12-05 07:44:14,876 - INFO - epoch 1, step 53700, training loss = 1.573244, validation loss = 1.752272
2018-12-05 07:44:19,071 - INFO - epoch 1, step 53710, training loss = 1.236029, validation loss = 1.779377
2018-12-05 07:44:23,060 - INFO - epoch 1, step 53720, training loss = 1.473112, validation loss = 1.817998
2018-12-05 07:44:27,303 - INFO - epoch 1, step 53730, training loss = 1.418185, validation loss = 1.649632
2018-12-05 07:44:31,282 - INFO - epoch 1, step 53740, training loss = 1.773421, validation loss = 1.530850
2018-12-05 07:44:35,576 - INFO - epoch 1, step 53750, training loss = 1.446982, validation loss = 2.009495
2018-12-05 07:44:39,962 - INFO - epoch 1, step 53760, training loss = 1.709643, validation loss = 1.519004
2018-12-05 07:44:44,387 - INFO - epoch 1, step 53770, training loss = 1.831776, validation loss = 1.953243
2018-12-05 07:44:48,427 - INFO - epoch 1, step 53780, training loss = 1.777326, validation loss = 1.925083
2018-12-05 07:44:51,763 - INFO - epoch 1, step 53790, training loss = 1.826280, validation loss = 1.770060
2018-12-05 07:44:55,049 - INFO - epoch 1, step 53800, training loss = 1.880516, validation loss = 1.593541
2018-12-05 07:44:58,458 - INFO - epoch 1, step 53810, training loss = 1.651631, validation loss = 1.566293
2018-12-05 07:45:01,954 - INFO - epoch 1, step 53820, training loss = 1.585224, validation loss = 2.062845
2018-12-05 07:45:05,184 - INFO - epoch 1, step 53830, training loss = 1.754816, validation loss = 1.401381
2018-12-05 07:45:08,512 - INFO - epoch 1, step 53840, training loss = 1.798892, validation loss = 1.760628
2018-12-05 07:45:11,888 - INFO - epoch 1, step 53850, training loss = 2.082717, validation loss = 1.983643
2018-12-05 07:45:15,026 - INFO - epoch 1, step 53860, training loss = 1.655021, validation loss = 1.556786
2018-12-05 07:45:18,122 - INFO - epoch 1, step 53870, training loss = 1.730854, validation loss = 1.716446
2018-12-05 07:45:21,220 - INFO - epoch 1, step 53880, training loss = 1.728335, validation loss = 1.810621
2018-12-05 07:45:24,324 - INFO - epoch 1, step 53890, training loss = 1.534037, validation loss = 1.605373
2018-12-05 07:45:27,397 - INFO - epoch 1, step 53900, training loss = 1.971020, validation loss = 1.714985
2018-12-05 07:45:30,570 - INFO - epoch 1, step 53910, training loss = 1.664279, validation loss = 1.566193
2018-12-05 07:45:33,644 - INFO - epoch 1, step 53920, training loss = 1.638842, validation loss = 1.740469
2018-12-05 07:45:36,820 - INFO - epoch 1, step 53930, training loss = 1.713321, validation loss = 1.827838
2018-12-05 07:45:39,868 - INFO - epoch 1, step 53940, training loss = 2.158267, validation loss = 1.931957
2018-12-05 07:45:43,505 - INFO - epoch 1, step 53950, training loss = 1.284583, validation loss = 1.795220
2018-12-05 07:45:46,955 - INFO - epoch 1, step 53960, training loss = 1.704581, validation loss = 1.993999
2018-12-05 07:45:50,125 - INFO - epoch 1, step 53970, training loss = 1.592569, validation loss = 1.516635
2018-12-05 07:45:53,508 - INFO - epoch 1, step 53980, training loss = 1.684540, validation loss = 1.986525
2018-12-05 07:45:56,799 - INFO - epoch 1, step 53990, training loss = 1.589907, validation loss = 1.661519
2018-12-05 07:46:01,358 - INFO - epoch 1, step 54000, training loss = 1.621714, validation loss = 1.319446
2018-12-05 07:46:05,848 - INFO - epoch 1, step 54010, training loss = 1.795023, validation loss = 1.828194
2018-12-05 07:46:10,387 - INFO - epoch 1, step 54020, training loss = 1.752509, validation loss = 1.718963
2018-12-05 07:46:14,938 - INFO - epoch 1, step 54030, training loss = 1.077582, validation loss = 2.237456
2018-12-05 07:46:19,364 - INFO - epoch 1, step 54040, training loss = 1.730283, validation loss = 1.868103
2018-12-05 07:46:23,877 - INFO - epoch 1, step 54050, training loss = 1.765151, validation loss = 1.669739
2018-12-05 07:46:28,369 - INFO - epoch 1, step 54060, training loss = 1.767733, validation loss = 1.564866
2018-12-05 07:46:32,473 - INFO - epoch 1, step 54070, training loss = 1.779254, validation loss = 1.699325
2018-12-05 07:46:35,957 - INFO - epoch 1, step 54080, training loss = 2.038830, validation loss = 1.661455
2018-12-05 07:46:39,192 - INFO - epoch 1, step 54090, training loss = 1.607422, validation loss = 1.748227
2018-12-05 07:46:42,285 - INFO - epoch 1, step 54100, training loss = 1.669919, validation loss = 1.458748
2018-12-05 07:46:45,438 - INFO - epoch 1, step 54110, training loss = 1.596266, validation loss = 1.543776
2018-12-05 07:46:48,652 - INFO - epoch 1, step 54120, training loss = 1.739924, validation loss = 1.897683
2018-12-05 07:46:51,857 - INFO - epoch 1, step 54130, training loss = 1.740834, validation loss = 1.657891
2018-12-05 07:46:54,978 - INFO - epoch 1, step 54140, training loss = 1.689503, validation loss = 1.998714
2018-12-05 07:46:58,138 - INFO - epoch 1, step 54150, training loss = 1.799286, validation loss = 1.620726
2018-12-05 07:47:01,416 - INFO - epoch 1, step 54160, training loss = 1.684021, validation loss = 1.904946
2018-12-05 07:47:04,717 - INFO - epoch 1, step 54170, training loss = 1.685336, validation loss = 1.667431
2018-12-05 07:47:07,912 - INFO - epoch 1, step 54180, training loss = 1.691676, validation loss = 2.191072
2018-12-05 07:47:11,237 - INFO - epoch 1, step 54190, training loss = 1.954598, validation loss = 1.785779
2018-12-05 07:47:14,326 - INFO - epoch 1, step 54200, training loss = 1.633042, validation loss = 2.017193
2018-12-05 07:47:17,861 - INFO - epoch 1, step 54210, training loss = 1.951050, validation loss = 2.007996
2018-12-05 07:47:21,356 - INFO - epoch 1, step 54220, training loss = 1.804113, validation loss = 1.669937
2018-12-05 07:47:24,665 - INFO - epoch 1, step 54230, training loss = 1.484598, validation loss = 2.192221
2018-12-05 07:47:28,661 - INFO - epoch 1, step 54240, training loss = 1.962270, validation loss = 1.939156
2018-12-05 07:47:32,704 - INFO - epoch 1, step 54250, training loss = 1.991649, validation loss = 1.830468
2018-12-05 07:47:36,871 - INFO - epoch 1, step 54260, training loss = 1.742539, validation loss = 1.717453
2018-12-05 07:47:40,918 - INFO - epoch 1, step 54270, training loss = 1.798608, validation loss = 1.574995
2018-12-05 07:47:44,991 - INFO - epoch 1, step 54280, training loss = 1.425339, validation loss = 1.813643
2018-12-05 07:47:49,448 - INFO - epoch 1, step 54290, training loss = 1.876420, validation loss = 1.820909
2018-12-05 07:47:53,628 - INFO - epoch 1, step 54300, training loss = 1.335469, validation loss = 1.780312
2018-12-05 07:47:57,072 - INFO - epoch 1, step 54310, training loss = 1.956679, validation loss = 2.087479
2018-12-05 07:48:00,459 - INFO - epoch 1, step 54320, training loss = 1.700467, validation loss = 1.752028
2018-12-05 07:48:03,950 - INFO - epoch 1, step 54330, training loss = 1.635299, validation loss = 2.041530
2018-12-05 07:48:07,349 - INFO - epoch 1, step 54340, training loss = 1.974551, validation loss = 1.799665
2018-12-05 07:48:10,636 - INFO - epoch 1, step 54350, training loss = 1.829480, validation loss = 1.947029
2018-12-05 07:48:14,139 - INFO - epoch 1, step 54360, training loss = 1.718417, validation loss = 1.859165
2018-12-05 07:48:17,717 - INFO - epoch 1, step 54370, training loss = 1.621188, validation loss = 1.619170
2018-12-05 07:48:20,872 - INFO - epoch 1, step 54380, training loss = 1.953656, validation loss = 1.614487
2018-12-05 07:48:23,990 - INFO - epoch 1, step 54390, training loss = 1.805143, validation loss = 1.433192
2018-12-05 07:48:27,364 - INFO - epoch 1, step 54400, training loss = 2.052951, validation loss = 1.891945
2018-12-05 07:48:30,398 - INFO - epoch 1, step 54410, training loss = 2.026880, validation loss = 1.991554
2018-12-05 07:48:33,673 - INFO - epoch 1, step 54420, training loss = 1.656928, validation loss = 1.634648
2018-12-05 07:48:37,158 - INFO - epoch 1, step 54430, training loss = 1.622726, validation loss = 2.026755
2018-12-05 07:48:40,208 - INFO - epoch 1, step 54440, training loss = 1.949399, validation loss = 2.080760
2018-12-05 07:48:44,151 - INFO - epoch 1, step 54450, training loss = 1.676124, validation loss = 1.655757
2018-12-05 07:48:48,551 - INFO - epoch 1, step 54460, training loss = 1.707744, validation loss = 2.106987
2018-12-05 07:48:52,646 - INFO - epoch 1, step 54470, training loss = 1.840656, validation loss = 1.983478
2018-12-05 07:48:57,271 - INFO - epoch 1, step 54480, training loss = 1.290502, validation loss = 1.967534
2018-12-05 07:49:01,611 - INFO - epoch 1, step 54490, training loss = 1.800086, validation loss = 1.904943
2018-12-05 07:49:05,809 - INFO - epoch 1, step 54500, training loss = 1.441293, validation loss = 1.871245
2018-12-05 07:49:09,911 - INFO - epoch 1, step 54510, training loss = 1.893740, validation loss = 1.725232
2018-12-05 07:49:13,881 - INFO - epoch 1, step 54520, training loss = 2.184915, validation loss = 1.670357
2018-12-05 07:49:17,736 - INFO - epoch 1, step 54530, training loss = 1.741125, validation loss = 1.608918
2018-12-05 07:49:21,279 - INFO - epoch 1, step 54540, training loss = 1.737790, validation loss = 1.259002
2018-12-05 07:49:24,861 - INFO - epoch 1, step 54550, training loss = 1.758778, validation loss = 1.677252
2018-12-05 07:49:28,353 - INFO - epoch 1, step 54560, training loss = 1.941487, validation loss = 1.651567
2018-12-05 07:49:31,832 - INFO - epoch 1, step 54570, training loss = 1.589844, validation loss = 1.759561
2018-12-05 07:49:35,516 - INFO - epoch 1, step 54580, training loss = 1.692344, validation loss = 1.619621
2018-12-05 07:49:38,971 - INFO - epoch 1, step 54590, training loss = 1.566793, validation loss = 1.925458
2018-12-05 07:49:42,776 - INFO - epoch 1, step 54600, training loss = 1.172156, validation loss = 1.796172
2018-12-05 07:49:46,498 - INFO - epoch 1, step 54610, training loss = 1.580108, validation loss = 1.917862
2018-12-05 07:49:50,266 - INFO - epoch 1, step 54620, training loss = 1.821310, validation loss = 2.175689
2018-12-05 07:49:54,102 - INFO - epoch 1, step 54630, training loss = 1.770915, validation loss = 1.781814
2018-12-05 07:49:57,978 - INFO - epoch 1, step 54640, training loss = 1.642174, validation loss = 1.684052
2018-12-05 07:50:02,339 - INFO - epoch 1, step 54650, training loss = 1.794262, validation loss = 1.715021
2018-12-05 07:50:06,301 - INFO - epoch 1, step 54660, training loss = 1.499587, validation loss = 2.189431
2018-12-05 07:50:10,267 - INFO - epoch 1, step 54670, training loss = 1.693556, validation loss = 1.533336
2018-12-05 07:50:14,095 - INFO - epoch 1, step 54680, training loss = 1.615633, validation loss = 1.697201
2018-12-05 07:50:18,113 - INFO - epoch 1, step 54690, training loss = 1.475234, validation loss = 1.898274
2018-12-05 07:50:22,551 - INFO - epoch 1, step 54700, training loss = 1.740488, validation loss = 1.829062
2018-12-05 07:50:26,569 - INFO - epoch 1, step 54710, training loss = 1.771166, validation loss = 1.913328
2018-12-05 07:50:30,730 - INFO - epoch 1, step 54720, training loss = 1.681406, validation loss = 1.559595
2018-12-05 07:50:35,046 - INFO - epoch 1, step 54730, training loss = 1.390154, validation loss = 1.651244
2018-12-05 07:50:39,101 - INFO - epoch 1, step 54740, training loss = 1.306748, validation loss = 1.655636
2018-12-05 07:50:42,370 - INFO - epoch 1, step 54750, training loss = 1.628996, validation loss = 1.827968
2018-12-05 07:50:45,511 - INFO - epoch 1, step 54760, training loss = 2.079193, validation loss = 1.627793
2018-12-05 07:50:48,791 - INFO - epoch 1, step 54770, training loss = 1.887508, validation loss = 1.788285
2018-12-05 07:50:52,105 - INFO - epoch 1, step 54780, training loss = 1.764419, validation loss = 1.863275
2018-12-05 07:50:55,311 - INFO - epoch 1, step 54790, training loss = 1.834256, validation loss = 1.562810
2018-12-05 07:50:58,513 - INFO - epoch 1, step 54800, training loss = 1.675663, validation loss = 1.795176
2018-12-05 07:51:01,823 - INFO - epoch 1, step 54810, training loss = 1.556146, validation loss = 2.177714
2018-12-05 07:51:04,713 - INFO - epoch 1, step 54820, training loss = 1.837009, validation loss = 2.126715
2018-12-05 07:51:08,929 - INFO - epoch 1, step 54830, training loss = 1.748117, validation loss = 1.958569
2018-12-05 07:51:13,265 - INFO - epoch 1, step 54840, training loss = 1.857125, validation loss = 1.762457
2018-12-05 07:51:17,959 - INFO - epoch 1, step 54850, training loss = 1.662784, validation loss = 1.947889
2018-12-05 07:51:22,443 - INFO - epoch 1, step 54860, training loss = 1.648505, validation loss = 1.786281
2018-12-05 07:51:26,911 - INFO - epoch 1, step 54870, training loss = 1.588900, validation loss = 1.608689
2018-12-05 07:51:31,520 - INFO - epoch 1, step 54880, training loss = 1.675002, validation loss = 1.953275
2018-12-05 07:51:35,981 - INFO - epoch 1, step 54890, training loss = 1.646680, validation loss = 2.028312
2018-12-05 07:51:40,252 - INFO - epoch 1, step 54900, training loss = 1.504963, validation loss = 1.915038
2018-12-05 07:51:44,823 - INFO - epoch 1, step 54910, training loss = 1.630928, validation loss = 1.627136
2018-12-05 07:51:49,039 - INFO - epoch 1, step 54920, training loss = 1.376181, validation loss = 1.740495
2018-12-05 07:51:53,011 - INFO - epoch 1, step 54930, training loss = 1.857176, validation loss = 2.032118
2018-12-05 07:51:57,317 - INFO - epoch 1, step 54940, training loss = 1.470320, validation loss = 1.914167
2018-12-05 07:52:01,502 - INFO - epoch 1, step 54950, training loss = 1.607201, validation loss = 1.950293
2018-12-05 07:52:05,772 - INFO - epoch 1, step 54960, training loss = 1.635203, validation loss = 1.755485
2018-12-05 07:52:09,885 - INFO - epoch 1, step 54970, training loss = 1.469778, validation loss = 1.810490
2018-12-05 07:52:14,010 - INFO - epoch 1, step 54980, training loss = 1.649391, validation loss = 1.794665
2018-12-05 07:52:18,030 - INFO - epoch 1, step 54990, training loss = 1.773359, validation loss = 2.000930
2018-12-05 07:52:22,155 - INFO - epoch 1, step 55000, training loss = 1.464619, validation loss = 1.776165
2018-12-05 07:52:26,474 - INFO - epoch 1, step 55010, training loss = 1.557925, validation loss = 2.171313
2018-12-05 07:52:30,604 - INFO - epoch 1, step 55020, training loss = 1.449275, validation loss = 1.930912
2018-12-05 07:52:34,672 - INFO - epoch 1, step 55030, training loss = 1.781277, validation loss = 1.758592
2018-12-05 07:52:38,801 - INFO - epoch 1, step 55040, training loss = 1.244678, validation loss = 2.054897
2018-12-05 07:52:42,950 - INFO - epoch 1, step 55050, training loss = 1.785091, validation loss = 1.667195
2018-12-05 07:52:47,094 - INFO - epoch 1, step 55060, training loss = 1.543285, validation loss = 1.750998
2018-12-05 07:52:51,001 - INFO - epoch 1, step 55070, training loss = 1.604853, validation loss = 1.790786
2018-12-05 07:52:54,924 - INFO - epoch 1, step 55080, training loss = 1.582706, validation loss = 1.726440
2018-12-05 07:52:58,797 - INFO - epoch 1, step 55090, training loss = 1.785452, validation loss = 1.678953
2018-12-05 07:53:03,026 - INFO - epoch 1, step 55100, training loss = 1.488688, validation loss = 1.613506
2018-12-05 07:53:07,038 - INFO - epoch 1, step 55110, training loss = 1.500591, validation loss = 1.980458
2018-12-05 07:53:10,748 - INFO - epoch 1, step 55120, training loss = 1.663823, validation loss = 1.715900
2018-12-05 07:53:14,842 - INFO - epoch 1, step 55130, training loss = 1.291687, validation loss = 1.994454
2018-12-05 07:53:18,735 - INFO - epoch 1, step 55140, training loss = 1.554468, validation loss = 1.943848
2018-12-05 07:53:22,475 - INFO - epoch 1, step 55150, training loss = 1.464738, validation loss = 1.973355
2018-12-05 07:53:26,017 - INFO - epoch 1, step 55160, training loss = 1.654415, validation loss = 1.626135
2018-12-05 07:53:29,374 - INFO - epoch 1, step 55170, training loss = 1.710035, validation loss = 1.792517
2018-12-05 07:53:32,980 - INFO - epoch 1, step 55180, training loss = 1.510122, validation loss = 1.742677
2018-12-05 07:53:36,427 - INFO - epoch 1, step 55190, training loss = 1.733457, validation loss = 1.931961
2018-12-05 07:53:40,120 - INFO - epoch 1, step 55200, training loss = 1.924680, validation loss = 1.859826
2018-12-05 07:53:43,541 - INFO - epoch 1, step 55210, training loss = 1.673261, validation loss = 1.745686
2018-12-05 07:53:47,692 - INFO - epoch 1, step 55220, training loss = 1.715433, validation loss = 2.213385
2018-12-05 07:53:51,805 - INFO - epoch 1, step 55230, training loss = 1.757671, validation loss = 2.160607
2018-12-05 07:53:56,088 - INFO - epoch 1, step 55240, training loss = 1.705019, validation loss = 2.044155
2018-12-05 07:54:00,323 - INFO - epoch 1, step 55250, training loss = 1.687912, validation loss = 2.049206
2018-12-05 07:54:04,485 - INFO - epoch 1, step 55260, training loss = 1.624782, validation loss = 1.699310
2018-12-05 07:54:08,859 - INFO - epoch 1, step 55270, training loss = 1.794731, validation loss = 1.810912
2018-12-05 07:54:12,993 - INFO - epoch 1, step 55280, training loss = 1.684341, validation loss = 1.840066
2018-12-05 07:54:17,476 - INFO - epoch 1, step 55290, training loss = 1.749747, validation loss = 1.861584
2018-12-05 07:54:21,847 - INFO - epoch 1, step 55300, training loss = 1.295553, validation loss = 1.844418
2018-12-05 07:54:26,277 - INFO - epoch 1, step 55310, training loss = 1.949027, validation loss = 1.962013
2018-12-05 07:54:30,827 - INFO - epoch 1, step 55320, training loss = 1.562088, validation loss = 1.803486
2018-12-05 07:54:35,465 - INFO - epoch 1, step 55330, training loss = 1.490774, validation loss = 1.282287
2018-12-05 07:54:39,670 - INFO - epoch 1, step 55340, training loss = 1.937278, validation loss = 1.801188
2018-12-05 07:54:44,225 - INFO - epoch 1, step 55350, training loss = 1.577829, validation loss = 2.232226
2018-12-05 07:54:48,715 - INFO - epoch 1, step 55360, training loss = 1.966018, validation loss = 1.812281
2018-12-05 07:54:53,032 - INFO - epoch 1, step 55370, training loss = 1.591472, validation loss = 2.295706
2018-12-05 07:54:56,901 - INFO - epoch 1, step 55380, training loss = 2.182153, validation loss = 1.921936
2018-12-05 07:54:59,908 - INFO - epoch 1, step 55390, training loss = 1.547683, validation loss = 2.058552
2018-12-05 07:55:03,166 - INFO - epoch 1, step 55400, training loss = 1.821747, validation loss = 1.819077
2018-12-05 07:55:06,369 - INFO - epoch 1, step 55410, training loss = 1.871662, validation loss = 1.851690
2018-12-05 07:55:09,454 - INFO - epoch 1, step 55420, training loss = 1.848628, validation loss = 1.949198
2018-12-05 07:55:12,473 - INFO - epoch 1, step 55430, training loss = 1.770694, validation loss = 2.065102
2018-12-05 07:55:15,583 - INFO - epoch 1, step 55440, training loss = 1.762574, validation loss = 1.967719
2018-12-05 07:55:18,913 - INFO - epoch 1, step 55450, training loss = 1.817468, validation loss = 1.601285
2018-12-05 07:55:22,779 - INFO - epoch 1, step 55460, training loss = 1.620496, validation loss = 1.675742
2018-12-05 07:55:26,655 - INFO - epoch 1, step 55470, training loss = 1.722333, validation loss = 1.705622
2018-12-05 07:55:30,306 - INFO - epoch 1, step 55480, training loss = 1.383972, validation loss = 1.999765
2018-12-05 07:55:34,044 - INFO - epoch 1, step 55490, training loss = 1.705526, validation loss = 2.141912
2018-12-05 07:55:37,883 - INFO - epoch 1, step 55500, training loss = 1.592577, validation loss = 2.073759
2018-12-05 07:55:41,774 - INFO - epoch 1, step 55510, training loss = 1.701547, validation loss = 1.749195
2018-12-05 07:55:46,080 - INFO - epoch 1, step 55520, training loss = 1.642248, validation loss = 2.067534
2018-12-05 07:55:49,854 - INFO - epoch 1, step 55530, training loss = 1.408363, validation loss = 1.760785
2018-12-05 07:55:53,233 - INFO - epoch 1, step 55540, training loss = 1.380710, validation loss = 2.151767
2018-12-05 07:55:56,823 - INFO - epoch 1, step 55550, training loss = 1.928816, validation loss = 1.379335
2018-12-05 07:56:00,032 - INFO - epoch 1, step 55560, training loss = 1.867486, validation loss = 2.198019
2018-12-05 07:56:03,279 - INFO - epoch 1, step 55570, training loss = 1.844099, validation loss = 1.659878
2018-12-05 07:56:06,763 - INFO - epoch 1, step 55580, training loss = 1.487977, validation loss = 2.154498
2018-12-05 07:56:10,001 - INFO - epoch 1, step 55590, training loss = 1.839211, validation loss = 1.625732
2018-12-05 07:56:14,277 - INFO - epoch 1, step 55600, training loss = 1.641192, validation loss = 1.309989
2018-12-05 07:56:18,614 - INFO - epoch 1, step 55610, training loss = 1.461592, validation loss = 1.956779
2018-12-05 07:56:22,953 - INFO - epoch 1, step 55620, training loss = 1.484991, validation loss = 1.587777
2018-12-05 07:56:27,098 - INFO - epoch 1, step 55630, training loss = 1.898299, validation loss = 1.786086
2018-12-05 07:56:31,524 - INFO - epoch 1, step 55640, training loss = 1.536969, validation loss = 2.066714
2018-12-05 07:56:36,098 - INFO - epoch 1, step 55650, training loss = 1.500871, validation loss = 1.853825
2018-12-05 07:56:40,345 - INFO - epoch 1, step 55660, training loss = 1.730736, validation loss = 1.551652
2018-12-05 07:56:44,474 - INFO - epoch 1, step 55670, training loss = 1.668442, validation loss = 1.857545
2018-12-05 07:56:48,737 - INFO - epoch 1, step 55680, training loss = 1.660519, validation loss = 1.890447
2018-12-05 07:56:52,757 - INFO - epoch 1, step 55690, training loss = 1.470505, validation loss = 2.160838
2018-12-05 07:56:56,713 - INFO - epoch 1, step 55700, training loss = 1.658574, validation loss = 2.109511
2018-12-05 07:57:00,805 - INFO - epoch 1, step 55710, training loss = 1.728983, validation loss = 1.898919
2018-12-05 07:57:04,830 - INFO - epoch 1, step 55720, training loss = 1.937292, validation loss = 1.994992
2018-12-05 07:57:08,741 - INFO - epoch 1, step 55730, training loss = 1.460537, validation loss = 1.847757
2018-12-05 07:57:12,929 - INFO - epoch 1, step 55740, training loss = 1.434695, validation loss = 1.554638
2018-12-05 07:57:17,003 - INFO - epoch 1, step 55750, training loss = 1.583418, validation loss = 1.807821
2018-12-05 07:57:20,585 - INFO - epoch 1, step 55760, training loss = 1.639107, validation loss = 1.708189
2018-12-05 07:57:24,195 - INFO - epoch 1, step 55770, training loss = 1.800110, validation loss = 1.660905
2018-12-05 07:57:27,940 - INFO - epoch 1, step 55780, training loss = 1.913952, validation loss = 1.988631
2018-12-05 07:57:31,599 - INFO - epoch 1, step 55790, training loss = 1.414682, validation loss = 1.774489
2018-12-05 07:57:35,234 - INFO - epoch 1, step 55800, training loss = 1.687808, validation loss = 1.382204
2018-12-05 07:57:38,774 - INFO - epoch 1, step 55810, training loss = 1.820101, validation loss = 1.855631
2018-12-05 07:57:42,174 - INFO - epoch 1, step 55820, training loss = 1.949130, validation loss = 1.966150
2018-12-05 07:57:45,957 - INFO - epoch 1, step 55830, training loss = 1.774506, validation loss = 1.729250
2018-12-05 07:57:50,168 - INFO - epoch 1, step 55840, training loss = 1.779659, validation loss = 1.631347
2018-12-05 07:57:54,532 - INFO - epoch 1, step 55850, training loss = 1.674766, validation loss = 1.792206
2018-12-05 07:57:58,977 - INFO - epoch 1, step 55860, training loss = 1.363178, validation loss = 1.551237
2018-12-05 07:58:03,347 - INFO - epoch 1, step 55870, training loss = 1.365920, validation loss = 1.800600
2018-12-05 07:58:07,583 - INFO - epoch 1, step 55880, training loss = 1.550301, validation loss = 2.136667
2018-12-05 07:58:12,078 - INFO - epoch 1, step 55890, training loss = 1.728253, validation loss = 1.946255
2018-12-05 07:58:16,338 - INFO - epoch 1, step 55900, training loss = 1.472000, validation loss = 2.110427
2018-12-05 07:58:20,401 - INFO - epoch 1, step 55910, training loss = 1.567538, validation loss = 2.041025
2018-12-05 07:58:24,606 - INFO - epoch 1, step 55920, training loss = 1.664231, validation loss = 1.641145
2018-12-05 07:58:28,910 - INFO - epoch 1, step 55930, training loss = 1.522243, validation loss = 1.689234
2018-12-05 07:58:32,977 - INFO - epoch 1, step 55940, training loss = 1.764562, validation loss = 1.522661
2018-12-05 07:58:36,878 - INFO - epoch 1, step 55950, training loss = 1.788142, validation loss = 1.466090
2018-12-05 07:58:41,247 - INFO - epoch 1, step 55960, training loss = 1.229123, validation loss = 1.815982
2018-12-05 07:58:45,075 - INFO - epoch 1, step 55970, training loss = 1.721826, validation loss = 2.000545
2018-12-05 07:58:49,231 - INFO - epoch 1, step 55980, training loss = 1.565007, validation loss = 1.947324
2018-12-05 07:58:53,167 - INFO - epoch 1, step 55990, training loss = 1.707179, validation loss = 1.541633
2018-12-05 07:58:57,056 - INFO - epoch 1, step 56000, training loss = 1.778603, validation loss = 1.568524
2018-12-05 07:59:01,111 - INFO - epoch 1, step 56010, training loss = 1.214683, validation loss = 1.778421
2018-12-05 07:59:04,881 - INFO - epoch 1, step 56020, training loss = 1.691909, validation loss = 1.879044
2018-12-05 07:59:08,620 - INFO - epoch 1, step 56030, training loss = 1.991987, validation loss = 1.719782
2018-12-05 07:59:12,562 - INFO - epoch 1, step 56040, training loss = 1.794018, validation loss = 1.641895
2018-12-05 07:59:16,348 - INFO - epoch 1, step 56050, training loss = 1.678589, validation loss = 1.728920
2018-12-05 07:59:19,996 - INFO - epoch 1, step 56060, training loss = 1.266364, validation loss = 1.818184
2018-12-05 07:59:23,657 - INFO - epoch 1, step 56070, training loss = 1.476050, validation loss = 1.762808
2018-12-05 07:59:27,156 - INFO - epoch 1, step 56080, training loss = 1.302489, validation loss = 1.854546
2018-12-05 07:59:30,779 - INFO - epoch 1, step 56090, training loss = 1.629855, validation loss = 1.514507
2018-12-05 07:59:34,560 - INFO - epoch 1, step 56100, training loss = 1.710598, validation loss = 1.454437
2018-12-05 07:59:38,709 - INFO - epoch 1, step 56110, training loss = 1.669189, validation loss = 1.749340
2018-12-05 07:59:42,964 - INFO - epoch 1, step 56120, training loss = 1.576483, validation loss = 1.766587
2018-12-05 07:59:47,381 - INFO - epoch 1, step 56130, training loss = 1.883565, validation loss = 1.898153
2018-12-05 07:59:51,569 - INFO - epoch 1, step 56140, training loss = 1.972293, validation loss = 1.858679
2018-12-05 07:59:56,006 - INFO - epoch 1, step 56150, training loss = 2.185166, validation loss = 1.616485
2018-12-05 08:00:00,525 - INFO - epoch 1, step 56160, training loss = 1.455138, validation loss = 1.501323
2018-12-05 08:00:04,825 - INFO - epoch 1, step 56170, training loss = 1.659906, validation loss = 1.870915
2018-12-05 08:00:09,123 - INFO - epoch 1, step 56180, training loss = 1.717131, validation loss = 1.774865
2018-12-05 08:00:13,028 - INFO - epoch 1, step 56190, training loss = 1.680460, validation loss = 1.929011
2018-12-05 08:00:16,515 - INFO - epoch 1, step 56200, training loss = 1.788610, validation loss = 1.438510
2018-12-05 08:00:19,695 - INFO - epoch 1, step 56210, training loss = 1.885798, validation loss = 2.085856
2018-12-05 08:00:22,861 - INFO - epoch 1, step 56220, training loss = 1.941005, validation loss = 1.730299
2018-12-05 08:00:26,012 - INFO - epoch 1, step 56230, training loss = 1.891258, validation loss = 2.131038
2018-12-05 08:00:29,315 - INFO - epoch 1, step 56240, training loss = 1.884360, validation loss = 1.676076
2018-12-05 08:00:32,332 - INFO - epoch 1, step 56250, training loss = 1.954253, validation loss = 1.927816
2018-12-05 08:00:35,426 - INFO - epoch 1, step 56260, training loss = 1.455339, validation loss = 2.351578
2018-12-05 08:00:38,734 - INFO - epoch 1, step 56270, training loss = 1.297651, validation loss = 2.104001
2018-12-05 08:00:41,897 - INFO - epoch 1, step 56280, training loss = 1.929610, validation loss = 1.799394
2018-12-05 08:00:45,054 - INFO - epoch 1, step 56290, training loss = 1.770582, validation loss = 1.355032
2018-12-05 08:00:48,182 - INFO - epoch 1, step 56300, training loss = 1.627862, validation loss = 1.821882
2018-12-05 08:00:51,263 - INFO - epoch 1, step 56310, training loss = 1.557065, validation loss = 2.113445
2018-12-05 08:00:54,757 - INFO - epoch 1, step 56320, training loss = 1.548687, validation loss = 1.864890
2018-12-05 08:00:58,113 - INFO - epoch 1, step 56330, training loss = 1.667030, validation loss = 1.690796
2018-12-05 08:01:01,494 - INFO - epoch 1, step 56340, training loss = 1.694490, validation loss = 1.961144
2018-12-05 08:01:05,232 - INFO - epoch 1, step 56350, training loss = 1.605062, validation loss = 1.688136
2018-12-05 08:01:09,400 - INFO - epoch 1, step 56360, training loss = 1.602257, validation loss = 1.932861
2018-12-05 08:01:13,500 - INFO - epoch 1, step 56370, training loss = 1.697662, validation loss = 1.902918
2018-12-05 08:01:17,421 - INFO - epoch 1, step 56380, training loss = 1.976490, validation loss = 2.191635
2018-12-05 08:01:21,588 - INFO - epoch 1, step 56390, training loss = 1.541479, validation loss = 1.745991
2018-12-05 08:01:25,875 - INFO - epoch 1, step 56400, training loss = 2.038167, validation loss = 1.785444
2018-12-05 08:01:30,225 - INFO - epoch 1, step 56410, training loss = 1.743269, validation loss = 1.650428
2018-12-05 08:01:34,479 - INFO - epoch 1, step 56420, training loss = 1.635142, validation loss = 1.674973
2018-12-05 08:01:38,613 - INFO - epoch 1, step 56430, training loss = 1.803809, validation loss = 1.741037
2018-12-05 08:01:42,734 - INFO - epoch 1, step 56440, training loss = 1.719653, validation loss = 2.080267
2018-12-05 08:01:46,882 - INFO - epoch 1, step 56450, training loss = 1.750547, validation loss = 2.269361
2018-12-05 08:01:51,420 - INFO - epoch 1, step 56460, training loss = 1.596076, validation loss = 1.433465
2018-12-05 08:01:55,729 - INFO - epoch 1, step 56470, training loss = 1.572097, validation loss = 1.824602
2018-12-05 08:02:00,149 - INFO - epoch 1, step 56480, training loss = 1.591091, validation loss = 1.871554
2018-12-05 08:02:04,622 - INFO - epoch 1, step 56490, training loss = 1.604687, validation loss = 1.950251
2018-12-05 08:02:08,909 - INFO - epoch 1, step 56500, training loss = 1.595715, validation loss = 1.612520
2018-12-05 08:02:13,246 - INFO - epoch 1, step 56510, training loss = 1.599136, validation loss = 1.541246
2018-12-05 08:02:17,487 - INFO - epoch 1, step 56520, training loss = 1.826978, validation loss = 1.846410
2018-12-05 08:02:21,723 - INFO - epoch 1, step 56530, training loss = 1.682788, validation loss = 1.598243
2018-12-05 08:02:26,091 - INFO - epoch 1, step 56540, training loss = 1.466542, validation loss = 2.002049
2018-12-05 08:02:30,017 - INFO - epoch 1, step 56550, training loss = 1.883554, validation loss = 2.046128
2018-12-05 08:02:33,469 - INFO - epoch 1, step 56560, training loss = 1.744310, validation loss = 1.969959
2018-12-05 08:02:36,965 - INFO - epoch 1, step 56570, training loss = 1.522421, validation loss = 1.582711
2018-12-05 08:02:40,649 - INFO - epoch 1, step 56580, training loss = 1.606811, validation loss = 1.995933
2018-12-05 08:02:44,231 - INFO - epoch 1, step 56590, training loss = 1.886646, validation loss = 1.879070
2018-12-05 08:02:47,704 - INFO - epoch 1, step 56600, training loss = 1.642479, validation loss = 1.791049
2018-12-05 08:02:51,303 - INFO - epoch 1, step 56610, training loss = 1.593855, validation loss = 1.617227
2018-12-05 08:02:54,690 - INFO - epoch 1, step 56620, training loss = 1.642216, validation loss = 1.590481
2018-12-05 08:02:58,272 - INFO - epoch 1, step 56630, training loss = 1.698757, validation loss = 1.957592
2018-12-05 08:03:01,574 - INFO - epoch 1, step 56640, training loss = 1.575083, validation loss = 1.549900
2018-12-05 08:03:05,135 - INFO - epoch 1, step 56650, training loss = 1.655356, validation loss = 1.761088
2018-12-05 08:03:08,570 - INFO - epoch 1, step 56660, training loss = 1.517655, validation loss = 1.893694
2018-12-05 08:03:11,861 - INFO - epoch 1, step 56670, training loss = 1.593318, validation loss = 1.833087
2018-12-05 08:03:15,059 - INFO - epoch 1, step 56680, training loss = 1.669134, validation loss = 1.881279
2018-12-05 08:03:18,372 - INFO - epoch 1, step 56690, training loss = 1.587650, validation loss = 1.783058
2018-12-05 08:03:22,110 - INFO - epoch 1, step 56700, training loss = 1.865518, validation loss = 1.757182
2018-12-05 08:03:26,406 - INFO - epoch 1, step 56710, training loss = 1.596847, validation loss = 1.837544
2018-12-05 08:03:30,399 - INFO - epoch 1, step 56720, training loss = 1.435123, validation loss = 1.716560
2018-12-05 08:03:34,443 - INFO - epoch 1, step 56730, training loss = 1.745368, validation loss = 1.505844
2018-12-05 08:03:38,446 - INFO - epoch 1, step 56740, training loss = 1.787056, validation loss = 1.734461
2018-12-05 08:03:42,710 - INFO - epoch 1, step 56750, training loss = 1.800300, validation loss = 1.545210
2018-12-05 08:03:46,682 - INFO - epoch 1, step 56760, training loss = 1.513253, validation loss = 2.041051
2018-12-05 08:03:50,421 - INFO - epoch 1, step 56770, training loss = 1.633714, validation loss = 1.816344
2018-12-05 08:03:54,409 - INFO - epoch 1, step 56780, training loss = 1.623011, validation loss = 1.684854
2018-12-05 08:03:58,041 - INFO - epoch 1, step 56790, training loss = 1.877720, validation loss = 1.859911
2018-12-05 08:04:01,526 - INFO - epoch 1, step 56800, training loss = 1.600753, validation loss = 1.460296
2018-12-05 08:04:05,199 - INFO - epoch 1, step 56810, training loss = 1.449947, validation loss = 1.601944
2018-12-05 08:04:09,139 - INFO - epoch 1, step 56820, training loss = 1.374596, validation loss = 1.910285
2018-12-05 08:04:12,829 - INFO - epoch 1, step 56830, training loss = 1.659617, validation loss = 1.732480
2018-12-05 08:04:16,585 - INFO - epoch 1, step 56840, training loss = 1.730755, validation loss = 1.961217
2018-12-05 08:04:19,816 - INFO - epoch 1, step 56850, training loss = 1.783869, validation loss = 1.672460
2018-12-05 08:04:23,208 - INFO - epoch 1, step 56860, training loss = 1.803850, validation loss = 1.499576
2018-12-05 08:04:26,574 - INFO - epoch 1, step 56870, training loss = 2.056700, validation loss = 1.731164
2018-12-05 08:04:29,622 - INFO - epoch 1, step 56880, training loss = 2.198891, validation loss = 1.691753
2018-12-05 08:04:32,898 - INFO - epoch 1, step 56890, training loss = 1.947204, validation loss = 1.409940
2018-12-05 08:04:36,310 - INFO - epoch 1, step 56900, training loss = 1.762176, validation loss = 1.728723
2018-12-05 08:04:39,555 - INFO - epoch 1, step 56910, training loss = 1.838336, validation loss = 1.854612
2018-12-05 08:04:42,741 - INFO - epoch 1, step 56920, training loss = 1.779541, validation loss = 1.568205
2018-12-05 08:04:46,273 - INFO - epoch 1, step 56930, training loss = 1.599330, validation loss = 1.511067
2018-12-05 08:04:49,712 - INFO - epoch 1, step 56940, training loss = 1.996933, validation loss = 1.808956
2018-12-05 08:04:53,325 - INFO - epoch 1, step 56950, training loss = 1.859234, validation loss = 1.913891
2018-12-05 08:04:56,721 - INFO - epoch 1, step 56960, training loss = 1.718850, validation loss = 1.262699
2018-12-05 08:05:00,226 - INFO - epoch 1, step 56970, training loss = 1.667400, validation loss = 1.855818
2018-12-05 08:05:03,704 - INFO - epoch 1, step 56980, training loss = 2.043279, validation loss = 1.755824
2018-12-05 08:05:07,370 - INFO - epoch 1, step 56990, training loss = 1.720389, validation loss = 1.764223
2018-12-05 08:05:11,766 - INFO - epoch 1, step 57000, training loss = 1.546212, validation loss = 1.550514
2018-12-05 08:05:16,174 - INFO - epoch 1, step 57010, training loss = 1.489386, validation loss = 1.859667
2018-12-05 08:05:20,454 - INFO - epoch 1, step 57020, training loss = 1.316954, validation loss = 1.650956
2018-12-05 08:05:24,755 - INFO - epoch 1, step 57030, training loss = 1.567107, validation loss = 1.980334
2018-12-05 08:05:29,182 - INFO - epoch 1, step 57040, training loss = 1.493396, validation loss = 1.706834
2018-12-05 08:05:33,354 - INFO - epoch 1, step 57050, training loss = 1.509189, validation loss = 1.765728
2018-12-05 08:05:37,495 - INFO - epoch 1, step 57060, training loss = 1.480324, validation loss = 1.707763
2018-12-05 08:05:41,842 - INFO - epoch 1, step 57070, training loss = 1.516107, validation loss = 1.671446
2018-12-05 08:05:45,821 - INFO - epoch 1, step 57080, training loss = 1.494374, validation loss = 1.658647
2018-12-05 08:05:49,965 - INFO - epoch 1, step 57090, training loss = 1.762827, validation loss = 1.258564
2018-12-05 08:05:53,627 - INFO - epoch 1, step 57100, training loss = 1.721147, validation loss = 1.791823
2018-12-05 08:05:57,563 - INFO - epoch 1, step 57110, training loss = 1.848541, validation loss = 1.901412
2018-12-05 08:06:01,344 - INFO - epoch 1, step 57120, training loss = 1.364979, validation loss = 2.202140
2018-12-05 08:06:05,099 - INFO - epoch 1, step 57130, training loss = 1.564860, validation loss = 1.789503
2018-12-05 08:06:09,100 - INFO - epoch 1, step 57140, training loss = 1.703795, validation loss = 2.087595
2018-12-05 08:06:13,307 - INFO - epoch 1, step 57150, training loss = 1.652821, validation loss = 2.091148
2018-12-05 08:06:17,447 - INFO - epoch 1, step 57160, training loss = 1.284654, validation loss = 1.906360
2018-12-05 08:06:21,747 - INFO - epoch 1, step 57170, training loss = 1.767535, validation loss = 1.955574
2018-12-05 08:06:25,958 - INFO - epoch 1, step 57180, training loss = 1.632582, validation loss = 1.317449
2018-12-05 08:06:30,291 - INFO - epoch 1, step 57190, training loss = 1.271841, validation loss = 1.754395
2018-12-05 08:06:34,469 - INFO - epoch 1, step 57200, training loss = 1.593948, validation loss = 1.798310
2018-12-05 08:06:38,819 - INFO - epoch 1, step 57210, training loss = 1.407698, validation loss = 1.588366
2018-12-05 08:06:42,917 - INFO - epoch 1, step 57220, training loss = 1.758709, validation loss = 1.679320
2018-12-05 08:06:47,096 - INFO - epoch 1, step 57230, training loss = 1.306753, validation loss = 1.948868
2018-12-05 08:06:51,282 - INFO - epoch 1, step 57240, training loss = 1.604821, validation loss = 1.822709
2018-12-05 08:06:55,605 - INFO - epoch 1, step 57250, training loss = 1.549104, validation loss = 1.861977
2018-12-05 08:06:59,734 - INFO - epoch 1, step 57260, training loss = 1.376366, validation loss = 1.927960
2018-12-05 08:07:04,024 - INFO - epoch 1, step 57270, training loss = 1.653276, validation loss = 1.716603
2018-12-05 08:07:08,347 - INFO - epoch 1, step 57280, training loss = 1.525676, validation loss = 1.978556
2018-12-05 08:07:11,953 - INFO - epoch 1, step 57290, training loss = 1.724534, validation loss = 2.304742
2018-12-05 08:07:15,577 - INFO - epoch 1, step 57300, training loss = 1.496298, validation loss = 1.571925
2018-12-05 08:07:19,018 - INFO - epoch 1, step 57310, training loss = 1.517634, validation loss = 2.351461
2018-12-05 08:07:22,531 - INFO - epoch 1, step 57320, training loss = 1.714684, validation loss = 1.386236
2018-12-05 08:07:26,217 - INFO - epoch 1, step 57330, training loss = 1.689472, validation loss = 2.010818
2018-12-05 08:07:29,628 - INFO - epoch 1, step 57340, training loss = 1.656335, validation loss = 1.979947
2018-12-05 08:07:33,491 - INFO - epoch 1, step 57350, training loss = 1.246593, validation loss = 1.822470
2018-12-05 08:07:37,115 - INFO - epoch 1, step 57360, training loss = 1.696898, validation loss = 1.550014
2018-12-05 08:07:40,543 - INFO - epoch 1, step 57370, training loss = 1.630436, validation loss = 1.782801
2018-12-05 08:07:43,735 - INFO - epoch 1, step 57380, training loss = 1.801428, validation loss = 1.864167
2018-12-05 08:07:47,156 - INFO - epoch 1, step 57390, training loss = 1.697290, validation loss = 2.090562
2018-12-05 08:07:50,311 - INFO - epoch 1, step 57400, training loss = 1.902684, validation loss = 1.853269
2018-12-05 08:07:53,622 - INFO - epoch 1, step 57410, training loss = 1.690756, validation loss = 2.005585
2018-12-05 08:07:56,652 - INFO - epoch 1, step 57420, training loss = 1.904197, validation loss = 2.004888
2018-12-05 08:07:59,862 - INFO - epoch 1, step 57430, training loss = 1.663969, validation loss = 1.782562
2018-12-05 08:08:03,100 - INFO - epoch 1, step 57440, training loss = 1.582690, validation loss = 1.825822
2018-12-05 08:08:06,236 - INFO - epoch 1, step 57450, training loss = 1.663810, validation loss = 1.810656
2018-12-05 08:08:09,325 - INFO - epoch 1, step 57460, training loss = 2.104129, validation loss = 1.748440
2018-12-05 08:08:12,507 - INFO - epoch 1, step 57470, training loss = 1.877000, validation loss = 1.887375
2018-12-05 08:08:15,562 - INFO - epoch 1, step 57480, training loss = 1.891559, validation loss = 2.057108
2018-12-05 08:08:18,981 - INFO - epoch 1, step 57490, training loss = 1.504220, validation loss = 1.966336
2018-12-05 08:08:22,169 - INFO - epoch 1, step 57500, training loss = 1.600560, validation loss = 1.717274
2018-12-05 08:08:25,205 - INFO - epoch 1, step 57510, training loss = 1.647588, validation loss = 1.811671
2018-12-05 08:08:28,435 - INFO - epoch 1, step 57520, training loss = 1.815187, validation loss = 1.916327
2018-12-05 08:08:31,693 - INFO - epoch 1, step 57530, training loss = 1.535592, validation loss = 2.031498
2018-12-05 08:08:35,002 - INFO - epoch 1, step 57540, training loss = 1.773991, validation loss = 2.451460
2018-12-05 08:08:38,437 - INFO - epoch 1, step 57550, training loss = 1.763546, validation loss = 2.023309
2018-12-05 08:08:41,903 - INFO - epoch 1, step 57560, training loss = 1.447537, validation loss = 2.033762
2018-12-05 08:08:45,204 - INFO - epoch 1, step 57570, training loss = 1.843155, validation loss = 1.784475
2018-12-05 08:08:48,331 - INFO - epoch 1, step 57580, training loss = 2.083455, validation loss = 1.668105
2018-12-05 08:08:51,376 - INFO - epoch 1, step 57590, training loss = 1.934657, validation loss = 1.826850
2018-12-05 08:08:54,466 - INFO - epoch 1, step 57600, training loss = 1.666580, validation loss = 1.838948
2018-12-05 08:08:57,607 - INFO - epoch 1, step 57610, training loss = 1.936802, validation loss = 1.757107
2018-12-05 08:09:00,750 - INFO - epoch 1, step 57620, training loss = 1.494118, validation loss = 1.785813
2018-12-05 08:09:03,886 - INFO - epoch 1, step 57630, training loss = 1.726415, validation loss = 1.466019
2018-12-05 08:09:07,136 - INFO - epoch 1, step 57640, training loss = 1.379494, validation loss = 1.793391
2018-12-05 08:09:10,446 - INFO - epoch 1, step 57650, training loss = 1.443852, validation loss = 1.925573
2018-12-05 08:09:14,592 - INFO - epoch 1, step 57660, training loss = 1.538761, validation loss = 2.332883
2018-12-05 08:09:18,777 - INFO - epoch 1, step 57670, training loss = 1.875412, validation loss = 1.705569
2018-12-05 08:09:23,018 - INFO - epoch 1, step 57680, training loss = 1.639444, validation loss = 1.943820
2018-12-05 08:09:27,189 - INFO - epoch 1, step 57690, training loss = 1.767305, validation loss = 1.923423
2018-12-05 08:09:31,236 - INFO - epoch 1, step 57700, training loss = 2.076792, validation loss = 1.874444
2018-12-05 08:09:35,619 - INFO - epoch 1, step 57710, training loss = 1.250805, validation loss = 1.839028
2018-12-05 08:09:39,229 - INFO - epoch 1, step 57720, training loss = 1.765490, validation loss = 2.127521
2018-12-05 08:09:42,936 - INFO - epoch 1, step 57730, training loss = 1.742503, validation loss = 1.801474
2018-12-05 08:09:46,723 - INFO - epoch 1, step 57740, training loss = 1.485696, validation loss = 1.875281
2018-12-05 08:09:50,907 - INFO - epoch 1, step 57750, training loss = 2.059911, validation loss = 1.979905
2018-12-05 08:09:54,745 - INFO - epoch 1, step 57760, training loss = 1.692950, validation loss = 1.824727
2018-12-05 08:09:58,784 - INFO - epoch 1, step 57770, training loss = 1.638307, validation loss = 2.163530
2018-12-05 08:10:02,565 - INFO - epoch 1, step 57780, training loss = 1.642359, validation loss = 1.619664
2018-12-05 08:10:06,270 - INFO - epoch 1, step 57790, training loss = 1.518326, validation loss = 1.365053
2018-12-05 08:10:09,903 - INFO - epoch 1, step 57800, training loss = 1.552706, validation loss = 1.831251
2018-12-05 08:10:13,972 - INFO - epoch 1, step 57810, training loss = 1.650051, validation loss = 1.993949
2018-12-05 08:10:17,886 - INFO - epoch 1, step 57820, training loss = 1.675574, validation loss = 1.656916
2018-12-05 08:10:21,616 - INFO - epoch 1, step 57830, training loss = 1.913541, validation loss = 2.158911
2018-12-05 08:10:25,268 - INFO - epoch 1, step 57840, training loss = 1.992070, validation loss = 1.791585
2018-12-05 08:10:29,357 - INFO - epoch 1, step 57850, training loss = 1.864048, validation loss = 1.714642
2018-12-05 08:10:33,808 - INFO - epoch 1, step 57860, training loss = 1.760668, validation loss = 1.731079
2018-12-05 08:10:38,243 - INFO - epoch 1, step 57870, training loss = 1.736614, validation loss = 2.051691
2018-12-05 08:10:42,559 - INFO - epoch 1, step 57880, training loss = 1.570176, validation loss = 1.675579
2018-12-05 08:10:46,298 - INFO - epoch 1, step 57890, training loss = 1.703120, validation loss = 1.804763
2018-12-05 08:10:50,084 - INFO - epoch 1, step 57900, training loss = 1.794164, validation loss = 1.842642
2018-12-05 08:10:54,097 - INFO - epoch 1, step 57910, training loss = 1.761338, validation loss = 1.727971
2018-12-05 08:10:58,259 - INFO - epoch 1, step 57920, training loss = 1.708472, validation loss = 1.926076
2018-12-05 08:11:02,385 - INFO - epoch 1, step 57930, training loss = 1.668516, validation loss = 1.830900
2018-12-05 08:11:06,604 - INFO - epoch 1, step 57940, training loss = 1.908551, validation loss = 1.630480
2018-12-05 08:11:10,845 - INFO - epoch 1, step 57950, training loss = 1.264652, validation loss = 1.736154
2018-12-05 08:11:14,689 - INFO - epoch 1, step 57960, training loss = 1.681796, validation loss = 2.091003
2018-12-05 08:11:18,876 - INFO - epoch 1, step 57970, training loss = 1.515791, validation loss = 1.761576
2018-12-05 08:11:22,789 - INFO - epoch 1, step 57980, training loss = 1.400906, validation loss = 1.890389
2018-12-05 08:11:27,137 - INFO - epoch 1, step 57990, training loss = 1.963810, validation loss = 1.936338
2018-12-05 08:11:31,453 - INFO - epoch 1, step 58000, training loss = 1.496921, validation loss = 2.182542
2018-12-05 08:11:35,762 - INFO - epoch 1, step 58010, training loss = 1.645683, validation loss = 1.620575
2018-12-05 08:11:40,059 - INFO - epoch 1, step 58020, training loss = 1.515110, validation loss = 1.725618
2018-12-05 08:11:44,309 - INFO - epoch 1, step 58030, training loss = 1.711196, validation loss = 1.702870
2018-12-05 08:11:48,294 - INFO - epoch 1, step 58040, training loss = 1.698597, validation loss = 1.977156
2018-12-05 08:11:52,367 - INFO - epoch 1, step 58050, training loss = 1.393419, validation loss = 1.658093
2018-12-05 08:11:56,338 - INFO - epoch 1, step 58060, training loss = 1.773676, validation loss = 2.264941
2018-12-05 08:12:00,523 - INFO - epoch 1, step 58070, training loss = 1.723237, validation loss = 2.048127
2018-12-05 08:12:04,823 - INFO - epoch 1, step 58080, training loss = 1.698550, validation loss = 1.781231
2018-12-05 08:12:08,507 - INFO - epoch 1, step 58090, training loss = 1.530522, validation loss = 1.732033
2018-12-05 08:12:12,030 - INFO - epoch 1, step 58100, training loss = 1.596591, validation loss = 1.772543
2018-12-05 08:12:15,734 - INFO - epoch 1, step 58110, training loss = 1.662146, validation loss = 2.045429
2018-12-05 08:12:19,339 - INFO - epoch 1, step 58120, training loss = 1.452931, validation loss = 1.977406
2018-12-05 08:12:22,929 - INFO - epoch 1, step 58130, training loss = 1.673030, validation loss = 1.979522
2018-12-05 08:12:26,041 - INFO - epoch 1, step 58140, training loss = 1.751457, validation loss = 1.673599
2018-12-05 08:12:29,221 - INFO - epoch 1, step 58150, training loss = 1.810360, validation loss = 1.947840
2018-12-05 08:12:32,279 - INFO - epoch 1, step 58160, training loss = 1.588941, validation loss = 2.084656
2018-12-05 08:12:35,326 - INFO - epoch 1, step 58170, training loss = 1.871287, validation loss = 2.119340
2018-12-05 08:12:38,533 - INFO - epoch 1, step 58180, training loss = 2.131035, validation loss = 1.576297
2018-12-05 08:12:41,513 - INFO - epoch 1, step 58190, training loss = 1.898513, validation loss = 1.651043
2018-12-05 08:12:44,590 - INFO - epoch 1, step 58200, training loss = 1.991559, validation loss = 1.985181
2018-12-05 08:12:47,627 - INFO - epoch 1, step 58210, training loss = 1.938020, validation loss = 1.594162
2018-12-05 08:12:51,489 - INFO - epoch 1, step 58220, training loss = 1.514883, validation loss = 1.693289
2018-12-05 08:12:55,692 - INFO - epoch 1, step 58230, training loss = 1.569709, validation loss = 1.797870
2018-12-05 08:12:59,870 - INFO - epoch 1, step 58240, training loss = 1.471882, validation loss = 1.518235
2018-12-05 08:13:03,811 - INFO - epoch 1, step 58250, training loss = 1.601979, validation loss = 1.596098
2018-12-05 08:13:07,824 - INFO - epoch 1, step 58260, training loss = 1.352228, validation loss = 1.783823
2018-12-05 08:13:11,822 - INFO - epoch 1, step 58270, training loss = 1.387737, validation loss = 1.741403
2018-12-05 08:13:16,209 - INFO - epoch 1, step 58280, training loss = 1.571268, validation loss = 1.495626
2018-12-05 08:13:20,440 - INFO - epoch 1, step 58290, training loss = 1.569947, validation loss = 1.978612
2018-12-05 08:13:24,561 - INFO - epoch 1, step 58300, training loss = 1.366260, validation loss = 1.924796
2018-12-05 08:13:28,614 - INFO - epoch 1, step 58310, training loss = 1.726155, validation loss = 1.837635
2018-12-05 08:13:32,806 - INFO - epoch 1, step 58320, training loss = 1.481156, validation loss = 1.981019
2018-12-05 08:13:36,941 - INFO - epoch 1, step 58330, training loss = 1.493075, validation loss = 1.884880
2018-12-05 08:13:41,134 - INFO - epoch 1, step 58340, training loss = 1.478094, validation loss = 1.946016
2018-12-05 08:13:45,205 - INFO - epoch 1, step 58350, training loss = 1.755580, validation loss = 1.820918
2018-12-05 08:13:49,294 - INFO - epoch 1, step 58360, training loss = 1.608238, validation loss = 1.464254
2018-12-05 08:13:53,531 - INFO - epoch 1, step 58370, training loss = 1.386418, validation loss = 1.954306
2018-12-05 08:13:57,703 - INFO - epoch 1, step 58380, training loss = 1.569769, validation loss = 1.809692
2018-12-05 08:14:02,003 - INFO - epoch 1, step 58390, training loss = 1.532671, validation loss = 1.853636
2018-12-05 08:14:05,876 - INFO - epoch 1, step 58400, training loss = 1.951036, validation loss = 1.783569
2018-12-05 08:14:09,509 - INFO - epoch 1, step 58410, training loss = 1.804345, validation loss = 1.515964
2018-12-05 08:14:13,384 - INFO - epoch 1, step 58420, training loss = 1.696589, validation loss = 1.570336
2018-12-05 08:14:17,231 - INFO - epoch 1, step 58430, training loss = 1.343089, validation loss = 1.952178
2018-12-05 08:14:20,645 - INFO - epoch 1, step 58440, training loss = 1.803037, validation loss = 1.712475
2018-12-05 08:14:24,212 - INFO - epoch 1, step 58450, training loss = 1.492311, validation loss = 1.695318
2018-12-05 08:14:28,024 - INFO - epoch 1, step 58460, training loss = 1.688985, validation loss = 1.727332
2018-12-05 08:14:31,903 - INFO - epoch 1, step 58470, training loss = 1.249577, validation loss = 1.890370
2018-12-05 08:14:35,479 - INFO - epoch 1, step 58480, training loss = 1.515869, validation loss = 1.755931
2018-12-05 08:14:39,128 - INFO - epoch 1, step 58490, training loss = 1.604211, validation loss = 1.796563
2018-12-05 08:14:42,623 - INFO - epoch 1, step 58500, training loss = 1.773725, validation loss = 2.059966
2018-12-05 08:14:46,131 - INFO - epoch 1, step 58510, training loss = 1.591799, validation loss = 2.028031
2018-12-05 08:14:49,867 - INFO - epoch 1, step 58520, training loss = 1.531150, validation loss = 1.746822
2018-12-05 08:14:53,289 - INFO - epoch 1, step 58530, training loss = 1.494240, validation loss = 1.810102
2018-12-05 08:14:57,026 - INFO - epoch 1, step 58540, training loss = 1.456679, validation loss = 1.904372
2018-12-05 08:15:00,829 - INFO - epoch 1, step 58550, training loss = 1.630620, validation loss = 1.342507
2018-12-05 08:15:04,656 - INFO - epoch 1, step 58560, training loss = 2.011332, validation loss = 1.708063
2018-12-05 08:15:08,878 - INFO - epoch 1, step 58570, training loss = 1.717924, validation loss = 1.726267
2018-12-05 08:15:13,002 - INFO - epoch 1, step 58580, training loss = 1.334327, validation loss = 1.503841
2018-12-05 08:15:17,038 - INFO - epoch 1, step 58590, training loss = 1.525392, validation loss = 1.719902
2018-12-05 08:15:21,198 - INFO - epoch 1, step 58600, training loss = 1.522933, validation loss = 1.381343
2018-12-05 08:15:25,190 - INFO - epoch 1, step 58610, training loss = 1.840659, validation loss = 1.753031
2018-12-05 08:15:29,253 - INFO - epoch 1, step 58620, training loss = 1.521606, validation loss = 1.943945
2018-12-05 08:15:32,672 - INFO - epoch 1, step 58630, training loss = 2.019229, validation loss = 1.756905
2018-12-05 08:15:35,751 - INFO - epoch 1, step 58640, training loss = 1.934341, validation loss = 1.609157
2018-12-05 08:15:39,040 - INFO - epoch 1, step 58650, training loss = 1.582929, validation loss = 1.968685
2018-12-05 08:15:42,501 - INFO - epoch 1, step 58660, training loss = 1.800023, validation loss = 1.805476
2018-12-05 08:15:45,513 - INFO - epoch 1, step 58670, training loss = 1.792947, validation loss = 1.847720
2018-12-05 08:15:48,797 - INFO - epoch 1, step 58680, training loss = 1.503176, validation loss = 1.900261
2018-12-05 08:15:52,381 - INFO - epoch 1, step 58690, training loss = 1.832044, validation loss = 1.851821
2018-12-05 08:15:55,649 - INFO - epoch 1, step 58700, training loss = 1.792344, validation loss = 1.706112
2018-12-05 08:15:59,378 - INFO - epoch 1, step 58710, training loss = 1.750548, validation loss = 1.868580
2018-12-05 08:16:03,489 - INFO - epoch 1, step 58720, training loss = 1.741156, validation loss = 1.871438
2018-12-05 08:16:07,772 - INFO - epoch 1, step 58730, training loss = 1.659840, validation loss = 1.839954
2018-12-05 08:16:11,778 - INFO - epoch 1, step 58740, training loss = 1.401882, validation loss = 1.579874
2018-12-05 08:16:16,005 - INFO - epoch 1, step 58750, training loss = 1.162474, validation loss = 1.748716
2018-12-05 08:16:20,265 - INFO - epoch 1, step 58760, training loss = 1.731216, validation loss = 1.865321
2018-12-05 08:16:24,603 - INFO - epoch 1, step 58770, training loss = 1.601160, validation loss = 1.773066
2018-12-05 08:16:28,875 - INFO - epoch 1, step 58780, training loss = 1.592480, validation loss = 1.955094
2018-12-05 08:16:33,061 - INFO - epoch 1, step 58790, training loss = 1.380394, validation loss = 1.412792
2018-12-05 08:16:37,139 - INFO - epoch 1, step 58800, training loss = 1.388583, validation loss = 2.012008
2018-12-05 08:16:41,044 - INFO - epoch 1, step 58810, training loss = 1.645449, validation loss = 2.073140
2018-12-05 08:16:45,216 - INFO - epoch 1, step 58820, training loss = 1.461674, validation loss = 1.761335
2018-12-05 08:16:49,485 - INFO - epoch 1, step 58830, training loss = 1.848622, validation loss = 1.732439
2018-12-05 08:16:53,421 - INFO - epoch 1, step 58840, training loss = 1.400870, validation loss = 1.818152
2018-12-05 08:16:57,228 - INFO - epoch 1, step 58850, training loss = 1.540931, validation loss = 1.732906
2018-12-05 08:17:01,356 - INFO - epoch 1, step 58860, training loss = 1.375572, validation loss = 1.760207
2018-12-05 08:17:05,379 - INFO - epoch 1, step 58870, training loss = 1.409855, validation loss = 1.832333
2018-12-05 08:17:09,648 - INFO - epoch 1, step 58880, training loss = 1.809090, validation loss = 1.586901
2018-12-05 08:17:13,713 - INFO - epoch 1, step 58890, training loss = 1.783181, validation loss = 1.684692
2018-12-05 08:17:18,016 - INFO - epoch 1, step 58900, training loss = 1.780591, validation loss = 1.593193
2018-12-05 08:17:22,063 - INFO - epoch 1, step 58910, training loss = 1.880318, validation loss = 1.705196
2018-12-05 08:17:26,577 - INFO - epoch 1, step 58920, training loss = 1.952000, validation loss = 1.598350
2018-12-05 08:17:30,961 - INFO - epoch 1, step 58930, training loss = 1.474941, validation loss = 1.552062
2018-12-05 08:17:34,205 - INFO - epoch 1, step 58940, training loss = 1.984881, validation loss = 1.872601
2018-12-05 08:17:37,347 - INFO - epoch 1, step 58950, training loss = 1.884388, validation loss = 1.701144
2018-12-05 08:17:40,755 - INFO - epoch 1, step 58960, training loss = 1.906934, validation loss = 1.694950
2018-12-05 08:17:43,908 - INFO - epoch 1, step 58970, training loss = 2.018130, validation loss = 1.949046
2018-12-05 08:17:47,240 - INFO - epoch 1, step 58980, training loss = 1.853183, validation loss = 1.551078
2018-12-05 08:17:50,498 - INFO - epoch 1, step 58990, training loss = 1.924908, validation loss = 1.602304
2018-12-05 08:17:53,969 - INFO - epoch 1, step 59000, training loss = 1.631906, validation loss = 1.494390
2018-12-05 08:17:57,235 - INFO - epoch 1, step 59010, training loss = 1.809178, validation loss = 1.788410
2018-12-05 08:18:01,396 - INFO - epoch 1, step 59020, training loss = 1.847571, validation loss = 1.532408
2018-12-05 08:18:05,537 - INFO - epoch 1, step 59030, training loss = 1.596491, validation loss = 1.797448
2018-12-05 08:18:09,606 - INFO - epoch 1, step 59040, training loss = 1.650878, validation loss = 1.909492
2018-12-05 08:18:13,751 - INFO - epoch 1, step 59050, training loss = 1.572910, validation loss = 1.839856
2018-12-05 08:18:18,003 - INFO - epoch 1, step 59060, training loss = 1.605319, validation loss = 1.828291
2018-12-05 08:18:21,626 - INFO - epoch 1, step 59070, training loss = 1.502902, validation loss = 1.739303
2018-12-05 08:18:25,353 - INFO - epoch 1, step 59080, training loss = 1.807870, validation loss = 1.673757
2018-12-05 08:18:29,086 - INFO - epoch 1, step 59090, training loss = 1.753826, validation loss = 1.731285
2018-12-05 08:18:32,736 - INFO - epoch 1, step 59100, training loss = 1.396689, validation loss = 2.330984
2018-12-05 08:18:36,112 - INFO - epoch 1, step 59110, training loss = 1.691125, validation loss = 2.027617
2018-12-05 08:18:39,659 - INFO - epoch 1, step 59120, training loss = 1.531591, validation loss = 2.243751
2018-12-05 08:18:43,351 - INFO - epoch 1, step 59130, training loss = 1.677489, validation loss = 2.523773
2018-12-05 08:18:46,845 - INFO - epoch 1, step 59140, training loss = 1.409433, validation loss = 2.583864
2018-12-05 08:18:50,460 - INFO - epoch 1, step 59150, training loss = 1.529316, validation loss = 2.168645
2018-12-05 08:18:54,165 - INFO - epoch 1, step 59160, training loss = 1.685362, validation loss = 2.329803
2018-12-05 08:18:57,983 - INFO - epoch 1, step 59170, training loss = 1.509745, validation loss = 2.496436
2018-12-05 08:19:01,754 - INFO - epoch 1, step 59180, training loss = 1.900812, validation loss = 2.317408
2018-12-05 08:19:05,490 - INFO - epoch 1, step 59190, training loss = 1.521541, validation loss = 2.252291
2018-12-05 08:19:09,272 - INFO - epoch 1, step 59200, training loss = 1.413190, validation loss = 2.156166
2018-12-05 08:19:13,608 - INFO - epoch 1, step 59210, training loss = 1.419933, validation loss = 2.064803
2018-12-05 08:19:17,582 - INFO - epoch 1, step 59220, training loss = 1.716175, validation loss = 2.254504
2018-12-05 08:19:21,678 - INFO - epoch 1, step 59230, training loss = 1.531011, validation loss = 2.264460
2018-12-05 08:19:26,061 - INFO - epoch 1, step 59240, training loss = 1.624738, validation loss = 2.412034
2018-12-05 08:19:30,110 - INFO - epoch 1, step 59250, training loss = 1.234982, validation loss = 2.217734
2018-12-05 08:19:34,322 - INFO - epoch 1, step 59260, training loss = 1.522413, validation loss = 2.215371
2018-12-05 08:19:38,710 - INFO - epoch 1, step 59270, training loss = 1.640412, validation loss = 2.510876
2018-12-05 08:19:42,962 - INFO - epoch 1, step 59280, training loss = 1.495070, validation loss = 2.523053
2018-12-05 08:19:47,225 - INFO - epoch 1, step 59290, training loss = 1.623504, validation loss = 2.635070
2018-12-05 08:19:51,401 - INFO - epoch 1, step 59300, training loss = 1.762730, validation loss = 2.749523
2018-12-05 08:19:55,852 - INFO - epoch 1, step 59310, training loss = 1.711319, validation loss = 2.586803
2018-12-05 08:20:00,147 - INFO - epoch 1, step 59320, training loss = 1.615527, validation loss = 2.684000
2018-12-05 08:20:04,520 - INFO - epoch 1, step 59330, training loss = 1.614956, validation loss = 2.696339
2018-12-05 08:20:09,016 - INFO - epoch 1, step 59340, training loss = 1.716356, validation loss = 2.304337
2018-12-05 08:20:13,349 - INFO - epoch 1, step 59350, training loss = 1.504688, validation loss = 2.323782
2018-12-05 08:20:17,832 - INFO - epoch 1, step 59360, training loss = 1.601324, validation loss = 2.370352
2018-12-05 08:20:21,048 - INFO - epoch 1, step 59370, training loss = 1.887305, validation loss = 2.756860
2018-12-05 08:20:24,203 - INFO - epoch 1, step 59380, training loss = 1.813277, validation loss = 2.173631
2018-12-05 08:20:27,365 - INFO - epoch 1, step 59390, training loss = 1.836974, validation loss = 2.657859
2018-12-05 08:20:30,509 - INFO - epoch 1, step 59400, training loss = 1.909720, validation loss = 2.631622
2018-12-05 08:20:33,610 - INFO - epoch 1, step 59410, training loss = 1.635519, validation loss = 2.371744
2018-12-05 08:20:36,729 - INFO - epoch 1, step 59420, training loss = 1.571152, validation loss = 2.393800
2018-12-05 08:20:39,763 - INFO - epoch 1, step 59430, training loss = 1.631716, validation loss = 2.731309
2018-12-05 08:20:41,897 - INFO - Model saved in dir ./models
2018-12-05 08:20:45,913 - INFO - epoch 2, step 10, training loss = 2.417910, validation loss = 2.433578
2018-12-05 08:20:49,592 - INFO - epoch 2, step 20, training loss = 1.608057, validation loss = 2.378349
2018-12-05 08:20:53,174 - INFO - epoch 2, step 30, training loss = 2.158149, validation loss = 2.186357
2018-12-05 08:20:56,682 - INFO - epoch 2, step 40, training loss = 2.418201, validation loss = 2.167491
2018-12-05 08:21:00,206 - INFO - epoch 2, step 50, training loss = 2.546981, validation loss = 2.397145
2018-12-05 08:21:03,916 - INFO - epoch 2, step 60, training loss = 2.018217, validation loss = 2.308277
2018-12-05 08:21:07,571 - INFO - epoch 2, step 70, training loss = 1.710647, validation loss = 2.599732
2018-12-05 08:21:11,094 - INFO - epoch 2, step 80, training loss = 2.110095, validation loss = 2.685387
2018-12-05 08:21:14,799 - INFO - epoch 2, step 90, training loss = 2.027546, validation loss = 2.429017
2018-12-05 08:21:18,494 - INFO - epoch 2, step 100, training loss = 1.721129, validation loss = 2.003962
2018-12-05 08:21:22,245 - INFO - epoch 2, step 110, training loss = 2.218818, validation loss = 2.433579
2018-12-05 08:21:25,964 - INFO - epoch 2, step 120, training loss = 1.948692, validation loss = 2.405927
2018-12-05 08:21:29,767 - INFO - epoch 2, step 130, training loss = 2.116827, validation loss = 2.297123
2018-12-05 08:21:33,563 - INFO - epoch 2, step 140, training loss = 2.300707, validation loss = 2.327561
2018-12-05 08:21:37,086 - INFO - epoch 2, step 150, training loss = 2.149652, validation loss = 2.068162
2018-12-05 08:21:41,020 - INFO - epoch 2, step 160, training loss = 1.821977, validation loss = 2.014937
2018-12-05 08:21:44,846 - INFO - epoch 2, step 170, training loss = 2.198501, validation loss = 2.109503
2018-12-05 08:21:48,983 - INFO - epoch 2, step 180, training loss = 1.971574, validation loss = 2.303153
2018-12-05 08:21:53,616 - INFO - epoch 2, step 190, training loss = 2.440939, validation loss = 2.096805
2018-12-05 08:21:57,507 - INFO - epoch 2, step 200, training loss = 1.908556, validation loss = 2.367677
2018-12-05 08:22:01,688 - INFO - epoch 2, step 210, training loss = 2.114551, validation loss = 1.887206
2018-12-05 08:22:05,752 - INFO - epoch 2, step 220, training loss = 2.222721, validation loss = 2.391653
2018-12-05 08:22:09,729 - INFO - epoch 2, step 230, training loss = 1.945940, validation loss = 2.417092
2018-12-05 08:22:13,799 - INFO - epoch 2, step 240, training loss = 2.091054, validation loss = 2.049608
2018-12-05 08:22:17,841 - INFO - epoch 2, step 250, training loss = 2.070682, validation loss = 2.287947
2018-12-05 08:22:22,016 - INFO - epoch 2, step 260, training loss = 2.058469, validation loss = 2.438547
2018-12-05 08:22:26,022 - INFO - epoch 2, step 270, training loss = 1.881160, validation loss = 2.546172
2018-12-05 08:22:29,896 - INFO - epoch 2, step 280, training loss = 2.383559, validation loss = 2.331129
2018-12-05 08:22:33,862 - INFO - epoch 2, step 290, training loss = 1.862846, validation loss = 2.044406
2018-12-05 08:22:38,102 - INFO - epoch 2, step 300, training loss = 1.641044, validation loss = 2.169982
2018-12-05 08:22:42,149 - INFO - epoch 2, step 310, training loss = 2.374508, validation loss = 2.037453
2018-12-05 08:22:46,055 - INFO - epoch 2, step 320, training loss = 2.097827, validation loss = 2.168288
2018-12-05 08:22:49,688 - INFO - epoch 2, step 330, training loss = 2.380658, validation loss = 2.633244
2018-12-05 08:22:53,480 - INFO - epoch 2, step 340, training loss = 2.016686, validation loss = 2.614475
2018-12-05 08:22:57,125 - INFO - epoch 2, step 350, training loss = 1.953505, validation loss = 2.466895
2018-12-05 08:23:00,990 - INFO - epoch 2, step 360, training loss = 1.983991, validation loss = 2.084609
2018-12-05 08:23:05,101 - INFO - epoch 2, step 370, training loss = 1.932770, validation loss = 2.398652
2018-12-05 08:23:08,816 - INFO - epoch 2, step 380, training loss = 1.919224, validation loss = 2.359909
2018-12-05 08:23:12,692 - INFO - epoch 2, step 390, training loss = 2.191261, validation loss = 2.347868
2018-12-05 08:23:16,569 - INFO - epoch 2, step 400, training loss = 1.950004, validation loss = 2.587851
2018-12-05 08:23:20,249 - INFO - epoch 2, step 410, training loss = 2.300359, validation loss = 2.500133
2018-12-05 08:23:24,043 - INFO - epoch 2, step 420, training loss = 1.858571, validation loss = 2.031172
2018-12-05 08:23:28,245 - INFO - epoch 2, step 430, training loss = 1.953190, validation loss = 2.176073
2018-12-05 08:23:32,355 - INFO - epoch 2, step 440, training loss = 1.742823, validation loss = 2.292132
2018-12-05 08:23:36,421 - INFO - epoch 2, step 450, training loss = 2.053671, validation loss = 2.069144
2018-12-05 08:23:40,429 - INFO - epoch 2, step 460, training loss = 1.819076, validation loss = 3.011518
2018-12-05 08:23:44,414 - INFO - epoch 2, step 470, training loss = 2.283903, validation loss = 2.297098
2018-12-05 08:23:48,648 - INFO - epoch 2, step 480, training loss = 1.585609, validation loss = 2.364145
2018-12-05 08:23:52,876 - INFO - epoch 2, step 490, training loss = 1.694808, validation loss = 2.235020
2018-12-05 08:23:57,030 - INFO - epoch 2, step 500, training loss = 2.479155, validation loss = 2.572083
2018-12-05 08:24:01,075 - INFO - epoch 2, step 510, training loss = 1.641954, validation loss = 2.483948
2018-12-05 08:24:05,162 - INFO - epoch 2, step 520, training loss = 1.840543, validation loss = 2.451446
2018-12-05 08:24:09,154 - INFO - epoch 2, step 530, training loss = 1.868720, validation loss = 2.177378
2018-12-05 08:24:13,028 - INFO - epoch 2, step 540, training loss = 2.049389, validation loss = 1.751361
2018-12-05 08:24:16,902 - INFO - epoch 2, step 550, training loss = 1.986767, validation loss = 2.000340
2018-12-05 08:24:20,776 - INFO - epoch 2, step 560, training loss = 2.027570, validation loss = 2.199195
2018-12-05 08:24:24,757 - INFO - epoch 2, step 570, training loss = 1.573629, validation loss = 1.909708
2018-12-05 08:24:28,680 - INFO - epoch 2, step 580, training loss = 2.238282, validation loss = 2.652205
2018-12-05 08:24:32,738 - INFO - epoch 2, step 590, training loss = 1.972963, validation loss = 2.118793
2018-12-05 08:24:36,827 - INFO - epoch 2, step 600, training loss = 1.949077, validation loss = 1.968557
2018-12-05 08:24:40,949 - INFO - epoch 2, step 610, training loss = 1.981299, validation loss = 2.437772
2018-12-05 08:24:44,999 - INFO - epoch 2, step 620, training loss = 2.487277, validation loss = 1.917880
2018-12-05 08:24:49,040 - INFO - epoch 2, step 630, training loss = 2.139900, validation loss = 2.198939
2018-12-05 08:24:53,301 - INFO - epoch 2, step 640, training loss = 1.857288, validation loss = 2.335671
2018-12-05 08:24:57,381 - INFO - epoch 2, step 650, training loss = 1.987860, validation loss = 2.096183
2018-12-05 08:25:01,049 - INFO - epoch 2, step 660, training loss = 1.918921, validation loss = 2.235108
2018-12-05 08:25:05,037 - INFO - epoch 2, step 670, training loss = 2.211224, validation loss = 2.540198
2018-12-05 08:25:08,980 - INFO - epoch 2, step 680, training loss = 2.087435, validation loss = 2.649361
2018-12-05 08:25:12,998 - INFO - epoch 2, step 690, training loss = 2.037457, validation loss = 2.263467
2018-12-05 08:25:17,102 - INFO - epoch 2, step 700, training loss = 2.001129, validation loss = 2.308783
2018-12-05 08:25:20,939 - INFO - epoch 2, step 710, training loss = 1.928944, validation loss = 1.829286
2018-12-05 08:25:25,019 - INFO - epoch 2, step 720, training loss = 2.004580, validation loss = 2.427979
2018-12-05 08:25:29,018 - INFO - epoch 2, step 730, training loss = 2.089654, validation loss = 2.289003
2018-12-05 08:25:33,018 - INFO - epoch 2, step 740, training loss = 1.577479, validation loss = 2.589972
2018-12-05 08:25:37,021 - INFO - epoch 2, step 750, training loss = 2.418395, validation loss = 1.980835
2018-12-05 08:25:40,953 - INFO - epoch 2, step 760, training loss = 1.314699, validation loss = 2.156915
2018-12-05 08:25:45,049 - INFO - epoch 2, step 770, training loss = 2.274681, validation loss = 2.360480
2018-12-05 08:25:49,374 - INFO - epoch 2, step 780, training loss = 2.068750, validation loss = 2.099022
2018-12-05 08:25:53,870 - INFO - epoch 2, step 790, training loss = 2.059615, validation loss = 2.344317
2018-12-05 08:25:58,100 - INFO - epoch 2, step 800, training loss = 2.401566, validation loss = 2.715437
2018-12-05 08:26:03,042 - INFO - epoch 2, step 810, training loss = 2.201105, validation loss = 2.271496
2018-12-05 08:26:07,138 - INFO - epoch 2, step 820, training loss = 2.022067, validation loss = 2.651567
2018-12-05 08:26:11,276 - INFO - epoch 2, step 830, training loss = 2.198776, validation loss = 2.395560
2018-12-05 08:26:15,431 - INFO - epoch 2, step 840, training loss = 1.957427, validation loss = 2.224041
2018-12-05 08:26:19,626 - INFO - epoch 2, step 850, training loss = 2.112666, validation loss = 2.030373
2018-12-05 08:26:23,888 - INFO - epoch 2, step 860, training loss = 1.853097, validation loss = 2.053225
2018-12-05 08:26:27,884 - INFO - epoch 2, step 870, training loss = 2.337106, validation loss = 2.661297
2018-12-05 08:26:31,893 - INFO - epoch 2, step 880, training loss = 2.447096, validation loss = 2.284914
2018-12-05 08:26:36,161 - INFO - epoch 2, step 890, training loss = 1.812955, validation loss = 2.536709
2018-12-05 08:26:40,261 - INFO - epoch 2, step 900, training loss = 2.399357, validation loss = 1.932004
2018-12-05 08:26:44,572 - INFO - epoch 2, step 910, training loss = 1.875199, validation loss = 2.116084
2018-12-05 08:26:48,777 - INFO - epoch 2, step 920, training loss = 2.060710, validation loss = 2.238365
2018-12-05 08:26:53,333 - INFO - epoch 2, step 930, training loss = 2.248195, validation loss = 2.221073
2018-12-05 08:26:57,741 - INFO - epoch 2, step 940, training loss = 1.996221, validation loss = 1.967841
2018-12-05 08:27:02,059 - INFO - epoch 2, step 950, training loss = 1.881617, validation loss = 2.057724
2018-12-05 08:27:06,382 - INFO - epoch 2, step 960, training loss = 2.328520, validation loss = 2.010095
2018-12-05 08:27:10,507 - INFO - epoch 2, step 970, training loss = 1.955708, validation loss = 1.971580
2018-12-05 08:27:14,950 - INFO - epoch 2, step 980, training loss = 1.957870, validation loss = 2.115544
2018-12-05 08:27:19,000 - INFO - epoch 2, step 990, training loss = 2.113627, validation loss = 2.455969
2018-12-05 08:27:23,219 - INFO - epoch 2, step 1000, training loss = 2.048643, validation loss = 2.475154
2018-12-05 08:27:27,410 - INFO - epoch 2, step 1010, training loss = 1.801259, validation loss = 2.400255
2018-12-05 08:27:31,265 - INFO - epoch 2, step 1020, training loss = 2.118759, validation loss = 2.328362
2018-12-05 08:27:35,290 - INFO - epoch 2, step 1030, training loss = 2.166988, validation loss = 2.097961
2018-12-05 08:27:39,313 - INFO - epoch 2, step 1040, training loss = 2.125467, validation loss = 2.312259
2018-12-05 08:27:43,482 - INFO - epoch 2, step 1050, training loss = 2.119802, validation loss = 2.118248
2018-12-05 08:27:47,478 - INFO - epoch 2, step 1060, training loss = 2.251585, validation loss = 2.207958
2018-12-05 08:27:51,442 - INFO - epoch 2, step 1070, training loss = 2.037828, validation loss = 2.504004
2018-12-05 08:27:55,549 - INFO - epoch 2, step 1080, training loss = 2.032677, validation loss = 2.004783
2018-12-05 08:27:59,907 - INFO - epoch 2, step 1090, training loss = 1.898712, validation loss = 1.576875
2018-12-05 08:28:03,903 - INFO - epoch 2, step 1100, training loss = 2.109697, validation loss = 2.280765
2018-12-05 08:28:08,173 - INFO - epoch 2, step 1110, training loss = 2.065866, validation loss = 2.154552
2018-12-05 08:28:12,087 - INFO - epoch 2, step 1120, training loss = 1.994860, validation loss = 2.532318
2018-12-05 08:28:16,183 - INFO - epoch 2, step 1130, training loss = 2.004553, validation loss = 2.479676
2018-12-05 08:28:20,341 - INFO - epoch 2, step 1140, training loss = 1.863898, validation loss = 2.460742
2018-12-05 08:28:24,501 - INFO - epoch 2, step 1150, training loss = 1.732503, validation loss = 2.212743
2018-12-05 08:28:28,735 - INFO - epoch 2, step 1160, training loss = 2.175313, validation loss = 2.108685
2018-12-05 08:28:32,833 - INFO - epoch 2, step 1170, training loss = 2.059797, validation loss = 2.604534
2018-12-05 08:28:36,863 - INFO - epoch 2, step 1180, training loss = 2.089736, validation loss = 2.050685
2018-12-05 08:28:40,798 - INFO - epoch 2, step 1190, training loss = 2.199884, validation loss = 1.989880
2018-12-05 08:28:44,760 - INFO - epoch 2, step 1200, training loss = 2.360027, validation loss = 2.416727
2018-12-05 08:28:49,013 - INFO - epoch 2, step 1210, training loss = 2.043830, validation loss = 2.783894
2018-12-05 08:28:53,355 - INFO - epoch 2, step 1220, training loss = 1.620657, validation loss = 2.085155
2018-12-05 08:28:57,375 - INFO - epoch 2, step 1230, training loss = 2.068118, validation loss = 2.502412
2018-12-05 08:29:01,642 - INFO - epoch 2, step 1240, training loss = 2.122816, validation loss = 2.003439
2018-12-05 08:29:05,691 - INFO - epoch 2, step 1250, training loss = 1.861150, validation loss = 1.973490
2018-12-05 08:29:09,624 - INFO - epoch 2, step 1260, training loss = 2.174244, validation loss = 2.364825
2018-12-05 08:29:13,639 - INFO - epoch 2, step 1270, training loss = 2.078506, validation loss = 2.290293
2018-12-05 08:29:17,520 - INFO - epoch 2, step 1280, training loss = 1.956006, validation loss = 2.424453
2018-12-05 08:29:21,648 - INFO - epoch 2, step 1290, training loss = 1.824096, validation loss = 2.382030
2018-12-05 08:29:25,715 - INFO - epoch 2, step 1300, training loss = 2.181424, validation loss = 2.160441
2018-12-05 08:29:29,305 - INFO - epoch 2, step 1310, training loss = 1.879486, validation loss = 1.771448
2018-12-05 08:29:33,274 - INFO - epoch 2, step 1320, training loss = 2.286493, validation loss = 2.046335
2018-12-05 08:29:36,977 - INFO - epoch 2, step 1330, training loss = 2.182343, validation loss = 2.361185
2018-12-05 08:29:40,480 - INFO - epoch 2, step 1340, training loss = 2.214241, validation loss = 1.995210
2018-12-05 08:29:44,224 - INFO - epoch 2, step 1350, training loss = 2.047539, validation loss = 2.036454
2018-12-05 08:29:48,067 - INFO - epoch 2, step 1360, training loss = 2.195235, validation loss = 2.341024
2018-12-05 08:29:51,688 - INFO - epoch 2, step 1370, training loss = 2.147799, validation loss = 2.101582
2018-12-05 08:29:55,375 - INFO - epoch 2, step 1380, training loss = 2.177691, validation loss = 1.851884
2018-12-05 08:29:58,912 - INFO - epoch 2, step 1390, training loss = 2.239693, validation loss = 1.901171
2018-12-05 08:30:02,568 - INFO - epoch 2, step 1400, training loss = 1.765396, validation loss = 2.112576
2018-12-05 08:30:06,479 - INFO - epoch 2, step 1410, training loss = 2.211655, validation loss = 2.014009
2018-12-05 08:30:10,002 - INFO - epoch 2, step 1420, training loss = 1.914557, validation loss = 2.504419
2018-12-05 08:30:13,909 - INFO - epoch 2, step 1430, training loss = 1.970674, validation loss = 2.321740
2018-12-05 08:30:17,893 - INFO - epoch 2, step 1440, training loss = 1.884342, validation loss = 1.983403
2018-12-05 08:30:21,718 - INFO - epoch 2, step 1450, training loss = 1.767027, validation loss = 2.033715
2018-12-05 08:30:25,621 - INFO - epoch 2, step 1460, training loss = 1.947937, validation loss = 2.423471
2018-12-05 08:30:29,424 - INFO - epoch 2, step 1470, training loss = 1.692710, validation loss = 2.233389
2018-12-05 08:30:32,946 - INFO - epoch 2, step 1480, training loss = 2.173992, validation loss = 2.457399
2018-12-05 08:30:36,697 - INFO - epoch 2, step 1490, training loss = 1.881699, validation loss = 2.284634
2018-12-05 08:30:42,894 - INFO - epoch 2, step 1500, training loss = 0.591868, validation loss = 2.200772
2018-12-05 08:30:46,782 - INFO - epoch 2, step 1510, training loss = 2.197713, validation loss = 2.469397
2018-12-05 08:30:50,676 - INFO - epoch 2, step 1520, training loss = 2.147399, validation loss = 2.237549
2018-12-05 08:30:54,477 - INFO - epoch 2, step 1530, training loss = 1.815235, validation loss = 2.163900
2018-12-05 08:30:58,331 - INFO - epoch 2, step 1540, training loss = 1.739024, validation loss = 1.987864
2018-12-05 08:31:02,145 - INFO - epoch 2, step 1550, training loss = 2.194239, validation loss = 2.092820
2018-12-05 08:31:05,991 - INFO - epoch 2, step 1560, training loss = 1.998783, validation loss = 1.930628
2018-12-05 08:31:10,212 - INFO - epoch 2, step 1570, training loss = 1.698642, validation loss = 1.933493
2018-12-05 08:31:13,895 - INFO - epoch 2, step 1580, training loss = 2.178337, validation loss = 1.876166
2018-12-05 08:31:17,588 - INFO - epoch 2, step 1590, training loss = 1.985777, validation loss = 2.102456
2018-12-05 08:31:21,151 - INFO - epoch 2, step 1600, training loss = 2.268876, validation loss = 2.280330
2018-12-05 08:31:24,860 - INFO - epoch 2, step 1610, training loss = 1.669516, validation loss = 2.302163
2018-12-05 08:31:28,667 - INFO - epoch 2, step 1620, training loss = 1.710274, validation loss = 1.778505
2018-12-05 08:31:32,345 - INFO - epoch 2, step 1630, training loss = 1.877263, validation loss = 1.982283
2018-12-05 08:31:35,950 - INFO - epoch 2, step 1640, training loss = 1.806447, validation loss = 2.230147
2018-12-05 08:31:39,752 - INFO - epoch 2, step 1650, training loss = 2.130412, validation loss = 2.070407
2018-12-05 08:31:44,688 - INFO - epoch 2, step 1660, training loss = 2.314160, validation loss = 2.089132
2018-12-05 08:31:49,819 - INFO - epoch 2, step 1670, training loss = 2.113542, validation loss = 1.996037
2018-12-05 08:31:53,482 - INFO - epoch 2, step 1680, training loss = 1.636243, validation loss = 1.685386
2018-12-05 08:31:57,171 - INFO - epoch 2, step 1690, training loss = 2.197921, validation loss = 2.083003
2018-12-05 08:32:00,730 - INFO - epoch 2, step 1700, training loss = 2.219448, validation loss = 2.170879
2018-12-05 08:32:04,235 - INFO - epoch 2, step 1710, training loss = 2.197365, validation loss = 2.208226
2018-12-05 08:32:07,968 - INFO - epoch 2, step 1720, training loss = 1.664482, validation loss = 2.375913
2018-12-05 08:32:11,556 - INFO - epoch 2, step 1730, training loss = 2.085579, validation loss = 1.790562
2018-12-05 08:32:14,922 - INFO - epoch 2, step 1740, training loss = 1.855386, validation loss = 1.734129
2018-12-05 08:32:18,267 - INFO - epoch 2, step 1750, training loss = 2.234488, validation loss = 2.013801
2018-12-05 08:32:21,706 - INFO - epoch 2, step 1760, training loss = 2.297306, validation loss = 2.027973
2018-12-05 08:32:25,149 - INFO - epoch 2, step 1770, training loss = 2.416190, validation loss = 2.439115
2018-12-05 08:32:28,540 - INFO - epoch 2, step 1780, training loss = 1.856450, validation loss = 2.014334
2018-12-05 08:32:31,836 - INFO - epoch 2, step 1790, training loss = 2.284736, validation loss = 2.336099
2018-12-05 08:32:35,192 - INFO - epoch 2, step 1800, training loss = 2.203432, validation loss = 1.741641
2018-12-05 08:32:38,528 - INFO - epoch 2, step 1810, training loss = 1.519744, validation loss = 1.990632
2018-12-05 08:32:41,978 - INFO - epoch 2, step 1820, training loss = 1.457686, validation loss = 1.963442
2018-12-05 08:32:45,354 - INFO - epoch 2, step 1830, training loss = 2.287038, validation loss = 2.444985
2018-12-05 08:32:48,989 - INFO - epoch 2, step 1840, training loss = 2.039079, validation loss = 2.562003
2018-12-05 08:32:52,505 - INFO - epoch 2, step 1850, training loss = 2.174004, validation loss = 1.968370
2018-12-05 08:32:56,800 - INFO - epoch 2, step 1860, training loss = 2.307726, validation loss = 2.253755
2018-12-05 08:33:00,795 - INFO - epoch 2, step 1870, training loss = 1.955753, validation loss = 2.270294
2018-12-05 08:33:05,031 - INFO - epoch 2, step 1880, training loss = 2.092358, validation loss = 2.647532
2018-12-05 08:33:09,236 - INFO - epoch 2, step 1890, training loss = 2.168453, validation loss = 2.651186
2018-12-05 08:33:13,623 - INFO - epoch 2, step 1900, training loss = 2.093780, validation loss = 1.816351
2018-12-05 08:33:18,000 - INFO - epoch 2, step 1910, training loss = 1.661979, validation loss = 1.943426
2018-12-05 08:33:22,066 - INFO - epoch 2, step 1920, training loss = 2.013631, validation loss = 2.152130
2018-12-05 08:33:26,270 - INFO - epoch 2, step 1930, training loss = 2.470228, validation loss = 2.509948
2018-12-05 08:33:30,849 - INFO - epoch 2, step 1940, training loss = 2.001394, validation loss = 2.154553
2018-12-05 08:33:35,135 - INFO - epoch 2, step 1950, training loss = 2.376297, validation loss = 1.945149
2018-12-05 08:33:38,464 - INFO - epoch 2, step 1960, training loss = 2.160891, validation loss = 2.046132
2018-12-05 08:33:41,776 - INFO - epoch 2, step 1970, training loss = 1.971556, validation loss = 2.313883
2018-12-05 08:33:45,106 - INFO - epoch 2, step 1980, training loss = 2.032941, validation loss = 2.340582
2018-12-05 08:33:48,767 - INFO - epoch 2, step 1990, training loss = 2.050833, validation loss = 2.517357
2018-12-05 08:33:52,257 - INFO - epoch 2, step 2000, training loss = 2.110000, validation loss = 2.444446
2018-12-05 08:33:55,576 - INFO - epoch 2, step 2010, training loss = 2.543645, validation loss = 2.557382
2018-12-05 08:33:58,879 - INFO - epoch 2, step 2020, training loss = 2.223143, validation loss = 1.788218
2018-12-05 08:34:02,219 - INFO - epoch 2, step 2030, training loss = 2.173047, validation loss = 2.197336
2018-12-05 08:34:05,475 - INFO - epoch 2, step 2040, training loss = 1.931246, validation loss = 2.109049
2018-12-05 08:34:09,017 - INFO - epoch 2, step 2050, training loss = 2.070197, validation loss = 2.341512
2018-12-05 08:34:12,560 - INFO - epoch 2, step 2060, training loss = 2.218114, validation loss = 2.329660
2018-12-05 08:34:16,110 - INFO - epoch 2, step 2070, training loss = 1.733603, validation loss = 2.131601
2018-12-05 08:34:19,662 - INFO - epoch 2, step 2080, training loss = 2.447737, validation loss = 2.069720
2018-12-05 08:34:22,968 - INFO - epoch 2, step 2090, training loss = 1.957449, validation loss = 2.324795
2018-12-05 08:34:26,464 - INFO - epoch 2, step 2100, training loss = 2.222090, validation loss = 2.188182
2018-12-05 08:34:29,940 - INFO - epoch 2, step 2110, training loss = 1.824428, validation loss = 2.111884
2018-12-05 08:34:33,317 - INFO - epoch 2, step 2120, training loss = 1.953792, validation loss = 2.136022
2018-12-05 08:34:36,980 - INFO - epoch 2, step 2130, training loss = 1.531125, validation loss = 2.026617
2018-12-05 08:34:40,314 - INFO - epoch 2, step 2140, training loss = 1.898326, validation loss = 2.311196
2018-12-05 08:34:43,727 - INFO - epoch 2, step 2150, training loss = 1.456614, validation loss = 2.526113
2018-12-05 08:34:47,296 - INFO - epoch 2, step 2160, training loss = 1.826837, validation loss = 1.670173
2018-12-05 08:34:50,769 - INFO - epoch 2, step 2170, training loss = 2.101445, validation loss = 2.044015
2018-12-05 08:34:54,141 - INFO - epoch 2, step 2180, training loss = 2.382803, validation loss = 2.439896
2018-12-05 08:34:57,800 - INFO - epoch 2, step 2190, training loss = 2.063186, validation loss = 2.405116
2018-12-05 08:35:01,397 - INFO - epoch 2, step 2200, training loss = 2.326845, validation loss = 2.584314
2018-12-05 08:35:05,208 - INFO - epoch 2, step 2210, training loss = 2.014023, validation loss = 1.968064
2018-12-05 08:35:08,933 - INFO - epoch 2, step 2220, training loss = 1.775687, validation loss = 1.820086
2018-12-05 08:35:12,570 - INFO - epoch 2, step 2230, training loss = 2.061268, validation loss = 2.075557
2018-12-05 08:35:16,265 - INFO - epoch 2, step 2240, training loss = 2.374134, validation loss = 1.945578
2018-12-05 08:35:19,940 - INFO - epoch 2, step 2250, training loss = 1.756475, validation loss = 2.433692
2018-12-05 08:35:23,467 - INFO - epoch 2, step 2260, training loss = 2.190600, validation loss = 2.684411
2018-12-05 08:35:27,226 - INFO - epoch 2, step 2270, training loss = 1.914315, validation loss = 2.149720
2018-12-05 08:35:31,026 - INFO - epoch 2, step 2280, training loss = 1.919256, validation loss = 2.095850
2018-12-05 08:35:35,160 - INFO - epoch 2, step 2290, training loss = 2.237876, validation loss = 2.158354
2018-12-05 08:35:39,394 - INFO - epoch 2, step 2300, training loss = 2.037924, validation loss = 1.952060
2018-12-05 08:35:43,531 - INFO - epoch 2, step 2310, training loss = 1.962575, validation loss = 2.308733
2018-12-05 08:35:47,676 - INFO - epoch 2, step 2320, training loss = 2.095400, validation loss = 1.865928
2018-12-05 08:35:52,063 - INFO - epoch 2, step 2330, training loss = 1.983817, validation loss = 2.331329
2018-12-05 08:35:56,047 - INFO - epoch 2, step 2340, training loss = 2.110648, validation loss = 1.812575
2018-12-05 08:36:00,051 - INFO - epoch 2, step 2350, training loss = 2.125087, validation loss = 1.913979
2018-12-05 08:36:04,145 - INFO - epoch 2, step 2360, training loss = 2.057163, validation loss = 1.937204
2018-12-05 08:36:08,061 - INFO - epoch 2, step 2370, training loss = 2.278264, validation loss = 2.431992
2018-12-05 08:36:12,185 - INFO - epoch 2, step 2380, training loss = 2.159687, validation loss = 2.181638
2018-12-05 08:36:16,404 - INFO - epoch 2, step 2390, training loss = 1.872460, validation loss = 1.879125
2018-12-05 08:36:20,632 - INFO - epoch 2, step 2400, training loss = 1.823972, validation loss = 1.865306
2018-12-05 08:36:24,659 - INFO - epoch 2, step 2410, training loss = 1.927133, validation loss = 2.138731
2018-12-05 08:36:29,341 - INFO - epoch 2, step 2420, training loss = 2.009996, validation loss = 2.591463
2018-12-05 08:36:33,258 - INFO - epoch 2, step 2430, training loss = 2.257454, validation loss = 2.269479
2018-12-05 08:36:36,971 - INFO - epoch 2, step 2440, training loss = 2.276721, validation loss = 2.004030
2018-12-05 08:36:40,692 - INFO - epoch 2, step 2450, training loss = 1.871443, validation loss = 2.274280
2018-12-05 08:36:44,403 - INFO - epoch 2, step 2460, training loss = 1.991040, validation loss = 2.127301
2018-12-05 08:36:48,051 - INFO - epoch 2, step 2470, training loss = 1.991688, validation loss = 2.749800
2018-12-05 08:36:51,763 - INFO - epoch 2, step 2480, training loss = 2.014536, validation loss = 1.910735
2018-12-05 08:36:55,547 - INFO - epoch 2, step 2490, training loss = 1.830481, validation loss = 2.025895
2018-12-05 08:36:59,179 - INFO - epoch 2, step 2500, training loss = 2.217300, validation loss = 2.015501
2018-12-05 08:37:02,806 - INFO - epoch 2, step 2510, training loss = 1.840740, validation loss = 2.268507
2018-12-05 08:37:06,300 - INFO - epoch 2, step 2520, training loss = 2.151490, validation loss = 2.333872
2018-12-05 08:37:09,838 - INFO - epoch 2, step 2530, training loss = 1.838611, validation loss = 2.202326
2018-12-05 08:37:13,469 - INFO - epoch 2, step 2540, training loss = 1.992841, validation loss = 2.090470
2018-12-05 08:37:17,108 - INFO - epoch 2, step 2550, training loss = 1.854318, validation loss = 1.693770
2018-12-05 08:37:20,744 - INFO - epoch 2, step 2560, training loss = 2.090556, validation loss = 1.772299
2018-12-05 08:37:24,346 - INFO - epoch 2, step 2570, training loss = 1.731147, validation loss = 1.937201
2018-12-05 08:37:27,903 - INFO - epoch 2, step 2580, training loss = 1.962627, validation loss = 2.094764
2018-12-05 08:37:31,572 - INFO - epoch 2, step 2590, training loss = 1.239893, validation loss = 2.039775
2018-12-05 08:37:35,326 - INFO - epoch 2, step 2600, training loss = 1.989329, validation loss = 1.915992
2018-12-05 08:37:39,057 - INFO - epoch 2, step 2610, training loss = 1.868124, validation loss = 1.806087
2018-12-05 08:37:42,709 - INFO - epoch 2, step 2620, training loss = 1.263158, validation loss = 2.209350
2018-12-05 08:37:46,333 - INFO - epoch 2, step 2630, training loss = 1.896599, validation loss = 2.379934
2018-12-05 08:37:49,881 - INFO - epoch 2, step 2640, training loss = 1.894946, validation loss = 2.172798
2018-12-05 08:37:54,009 - INFO - epoch 2, step 2650, training loss = 1.924704, validation loss = 2.143136
2018-12-05 08:37:58,283 - INFO - epoch 2, step 2660, training loss = 1.978530, validation loss = 2.097003
2018-12-05 08:38:02,377 - INFO - epoch 2, step 2670, training loss = 2.264649, validation loss = 2.263542
2018-12-05 08:38:06,500 - INFO - epoch 2, step 2680, training loss = 2.262207, validation loss = 2.359285
2018-12-05 08:38:10,875 - INFO - epoch 2, step 2690, training loss = 1.912388, validation loss = 2.241340
2018-12-05 08:38:15,053 - INFO - epoch 2, step 2700, training loss = 2.093314, validation loss = 1.870684
2018-12-05 08:38:19,338 - INFO - epoch 2, step 2710, training loss = 2.221626, validation loss = 2.148337
2018-12-05 08:38:23,419 - INFO - epoch 2, step 2720, training loss = 1.941791, validation loss = 2.226700
2018-12-05 08:38:27,602 - INFO - epoch 2, step 2730, training loss = 2.358064, validation loss = 2.171319
2018-12-05 08:38:31,944 - INFO - epoch 2, step 2740, training loss = 2.222473, validation loss = 1.763910
2018-12-05 08:38:36,182 - INFO - epoch 2, step 2750, training loss = 1.899626, validation loss = 1.872321
2018-12-05 08:38:40,388 - INFO - epoch 2, step 2760, training loss = 2.025849, validation loss = 2.263903
2018-12-05 08:38:44,685 - INFO - epoch 2, step 2770, training loss = 2.127473, validation loss = 2.612477
2018-12-05 08:38:48,962 - INFO - epoch 2, step 2780, training loss = 2.134423, validation loss = 2.300405
2018-12-05 08:38:53,001 - INFO - epoch 2, step 2790, training loss = 1.882305, validation loss = 2.054427
2018-12-05 08:38:57,186 - INFO - epoch 2, step 2800, training loss = 2.225193, validation loss = 2.473482
2018-12-05 08:39:01,179 - INFO - epoch 2, step 2810, training loss = 2.124632, validation loss = 2.258898
2018-12-05 08:39:05,024 - INFO - epoch 2, step 2820, training loss = 2.465328, validation loss = 2.100057
2018-12-05 08:39:08,698 - INFO - epoch 2, step 2830, training loss = 1.935821, validation loss = 2.002577
2018-12-05 08:39:12,312 - INFO - epoch 2, step 2840, training loss = 2.183486, validation loss = 2.198968
2018-12-05 08:39:15,744 - INFO - epoch 2, step 2850, training loss = 2.235986, validation loss = 2.260406
2018-12-05 08:39:19,412 - INFO - epoch 2, step 2860, training loss = 2.098292, validation loss = 1.901884
2018-12-05 08:39:22,981 - INFO - epoch 2, step 2870, training loss = 2.056555, validation loss = 1.651411
2018-12-05 08:39:26,658 - INFO - epoch 2, step 2880, training loss = 1.841065, validation loss = 1.977312
2018-12-05 08:39:30,472 - INFO - epoch 2, step 2890, training loss = 1.863652, validation loss = 2.174590
2018-12-05 08:39:34,109 - INFO - epoch 2, step 2900, training loss = 1.993538, validation loss = 2.718149
2018-12-05 08:39:37,865 - INFO - epoch 2, step 2910, training loss = 1.839238, validation loss = 1.931607
2018-12-05 08:39:41,608 - INFO - epoch 2, step 2920, training loss = 1.657792, validation loss = 2.001501
2018-12-05 08:39:45,278 - INFO - epoch 2, step 2930, training loss = 1.672353, validation loss = 2.275375
2018-12-05 08:39:48,916 - INFO - epoch 2, step 2940, training loss = 2.276228, validation loss = 2.467836
2018-12-05 08:39:53,124 - INFO - epoch 2, step 2950, training loss = 1.966568, validation loss = 2.436457
2018-12-05 08:39:57,533 - INFO - epoch 2, step 2960, training loss = 1.564432, validation loss = 2.209753
2018-12-05 08:40:01,834 - INFO - epoch 2, step 2970, training loss = 2.100249, validation loss = 1.743656
2018-12-05 08:40:06,231 - INFO - epoch 2, step 2980, training loss = 2.049487, validation loss = 2.199279
2018-12-05 08:40:10,621 - INFO - epoch 2, step 2990, training loss = 2.120807, validation loss = 2.515570
2018-12-05 08:40:14,958 - INFO - epoch 2, step 3000, training loss = 1.863544, validation loss = 2.303478
2018-12-05 08:40:19,442 - INFO - epoch 2, step 3010, training loss = 2.025787, validation loss = 1.814190
2018-12-05 08:40:23,721 - INFO - epoch 2, step 3020, training loss = 2.228434, validation loss = 1.736352
2018-12-05 08:40:28,035 - INFO - epoch 2, step 3030, training loss = 2.129086, validation loss = 2.414239
2018-12-05 08:40:32,056 - INFO - epoch 2, step 3040, training loss = 2.238296, validation loss = 2.364073
2018-12-05 08:40:36,213 - INFO - epoch 2, step 3050, training loss = 1.753299, validation loss = 2.472315
2018-12-05 08:40:40,376 - INFO - epoch 2, step 3060, training loss = 2.089118, validation loss = 2.367983
2018-12-05 08:40:44,668 - INFO - epoch 2, step 3070, training loss = 2.012184, validation loss = 2.396751
2018-12-05 08:40:48,731 - INFO - epoch 2, step 3080, training loss = 1.918824, validation loss = 2.015116
2018-12-05 08:40:53,022 - INFO - epoch 2, step 3090, training loss = 1.949970, validation loss = 2.224185
2018-12-05 08:40:57,177 - INFO - epoch 2, step 3100, training loss = 2.010396, validation loss = 2.279691
2018-12-05 08:41:01,346 - INFO - epoch 2, step 3110, training loss = 2.190857, validation loss = 2.284686
2018-12-05 08:41:05,415 - INFO - epoch 2, step 3120, training loss = 1.828540, validation loss = 1.865649
2018-12-05 08:41:09,557 - INFO - epoch 2, step 3130, training loss = 2.362017, validation loss = 2.064959
2018-12-05 08:41:13,702 - INFO - epoch 2, step 3140, training loss = 1.760693, validation loss = 2.147674
2018-12-05 08:41:17,946 - INFO - epoch 2, step 3150, training loss = 1.828528, validation loss = 2.357215
2018-12-05 08:41:22,172 - INFO - epoch 2, step 3160, training loss = 2.038209, validation loss = 2.322407
2018-12-05 08:41:26,344 - INFO - epoch 2, step 3170, training loss = 1.698594, validation loss = 1.939530
2018-12-05 08:41:30,534 - INFO - epoch 2, step 3180, training loss = 2.034648, validation loss = 1.918638
2018-12-05 08:41:34,719 - INFO - epoch 2, step 3190, training loss = 1.763286, validation loss = 2.083700
2018-12-05 08:41:38,869 - INFO - epoch 2, step 3200, training loss = 2.066226, validation loss = 1.636395
2018-12-05 08:41:43,204 - INFO - epoch 2, step 3210, training loss = 1.811807, validation loss = 2.260523
2018-12-05 08:41:47,493 - INFO - epoch 2, step 3220, training loss = 2.354546, validation loss = 2.015457
2018-12-05 08:41:51,795 - INFO - epoch 2, step 3230, training loss = 2.050982, validation loss = 1.934693
2018-12-05 08:41:56,065 - INFO - epoch 2, step 3240, training loss = 1.991138, validation loss = 2.333891
2018-12-05 08:42:00,540 - INFO - epoch 2, step 3250, training loss = 1.873171, validation loss = 2.095639
2018-12-05 08:42:04,520 - INFO - epoch 2, step 3260, training loss = 1.985199, validation loss = 2.027778
2018-12-05 08:42:08,649 - INFO - epoch 2, step 3270, training loss = 2.198032, validation loss = 2.084727
2018-12-05 08:42:12,645 - INFO - epoch 2, step 3280, training loss = 2.326545, validation loss = 1.531991
2018-12-05 08:42:16,338 - INFO - epoch 2, step 3290, training loss = 2.228069, validation loss = 1.889244
2018-12-05 08:42:20,129 - INFO - epoch 2, step 3300, training loss = 1.900772, validation loss = 2.551021
2018-12-05 08:42:23,860 - INFO - epoch 2, step 3310, training loss = 1.786284, validation loss = 1.861872
2018-12-05 08:42:27,824 - INFO - epoch 2, step 3320, training loss = 2.084307, validation loss = 1.654433
2018-12-05 08:42:31,480 - INFO - epoch 2, step 3330, training loss = 2.225310, validation loss = 1.920419
2018-12-05 08:42:35,119 - INFO - epoch 2, step 3340, training loss = 1.683048, validation loss = 2.144987
2018-12-05 08:42:39,029 - INFO - epoch 2, step 3350, training loss = 1.751525, validation loss = 2.078969
2018-12-05 08:42:42,586 - INFO - epoch 2, step 3360, training loss = 2.218273, validation loss = 2.006518
2018-12-05 08:42:46,487 - INFO - epoch 2, step 3370, training loss = 2.013650, validation loss = 1.827348
2018-12-05 08:42:50,522 - INFO - epoch 2, step 3380, training loss = 2.085325, validation loss = 2.456394
2018-12-05 08:42:54,184 - INFO - epoch 2, step 3390, training loss = 1.803841, validation loss = 2.099163
2018-12-05 08:42:58,118 - INFO - epoch 2, step 3400, training loss = 2.342775, validation loss = 2.292032
2018-12-05 08:43:02,205 - INFO - epoch 2, step 3410, training loss = 2.207946, validation loss = 1.899024
2018-12-05 08:43:06,178 - INFO - epoch 2, step 3420, training loss = 1.814531, validation loss = 1.935198
2018-12-05 08:43:10,468 - INFO - epoch 2, step 3430, training loss = 1.895055, validation loss = 1.687087
2018-12-05 08:43:14,354 - INFO - epoch 2, step 3440, training loss = 1.791422, validation loss = 1.737947
2018-12-05 08:43:18,295 - INFO - epoch 2, step 3450, training loss = 1.947254, validation loss = 1.999498
2018-12-05 08:43:22,447 - INFO - epoch 2, step 3460, training loss = 2.373085, validation loss = 1.836131
2018-12-05 08:43:26,643 - INFO - epoch 2, step 3470, training loss = 1.318579, validation loss = 1.934223
2018-12-05 08:43:30,389 - INFO - epoch 2, step 3480, training loss = 2.005401, validation loss = 1.811667
2018-12-05 08:43:34,217 - INFO - epoch 2, step 3490, training loss = 2.030406, validation loss = 1.766723
2018-12-05 08:43:37,941 - INFO - epoch 2, step 3500, training loss = 1.841658, validation loss = 2.101352
2018-12-05 08:43:41,739 - INFO - epoch 2, step 3510, training loss = 1.491095, validation loss = 2.039496
2018-12-05 08:43:45,454 - INFO - epoch 2, step 3520, training loss = 1.888668, validation loss = 1.872917
2018-12-05 08:43:49,382 - INFO - epoch 2, step 3530, training loss = 1.784327, validation loss = 2.028822
2018-12-05 08:43:52,954 - INFO - epoch 2, step 3540, training loss = 1.808915, validation loss = 2.061327
2018-12-05 08:43:56,686 - INFO - epoch 2, step 3550, training loss = 1.715582, validation loss = 1.951828
2018-12-05 08:44:00,359 - INFO - epoch 2, step 3560, training loss = 2.328130, validation loss = 1.669178
2018-12-05 08:44:04,084 - INFO - epoch 2, step 3570, training loss = 2.005524, validation loss = 1.854341
2018-12-05 08:44:07,855 - INFO - epoch 2, step 3580, training loss = 1.782565, validation loss = 2.186127
2018-12-05 08:44:11,763 - INFO - epoch 2, step 3590, training loss = 1.589629, validation loss = 1.991474
2018-12-05 08:44:15,559 - INFO - epoch 2, step 3600, training loss = 2.048969, validation loss = 1.640077
2018-12-05 08:44:19,489 - INFO - epoch 2, step 3610, training loss = 1.803450, validation loss = 2.243403
2018-12-05 08:44:23,114 - INFO - epoch 2, step 3620, training loss = 1.630655, validation loss = 2.348015
2018-12-05 08:44:26,854 - INFO - epoch 2, step 3630, training loss = 2.218565, validation loss = 2.107066
2018-12-05 08:44:30,811 - INFO - epoch 2, step 3640, training loss = 1.882704, validation loss = 1.718370
2018-12-05 08:44:34,469 - INFO - epoch 2, step 3650, training loss = 1.905192, validation loss = 2.048278
2018-12-05 08:44:38,508 - INFO - epoch 2, step 3660, training loss = 2.168442, validation loss = 2.179352
2018-12-05 08:44:42,503 - INFO - epoch 2, step 3670, training loss = 2.416852, validation loss = 2.118961
2018-12-05 08:44:46,116 - INFO - epoch 2, step 3680, training loss = 2.101454, validation loss = 1.961233
2018-12-05 08:44:49,595 - INFO - epoch 2, step 3690, training loss = 2.012868, validation loss = 2.028366
2018-12-05 08:44:53,868 - INFO - epoch 2, step 3700, training loss = 2.082704, validation loss = 1.894429
2018-12-05 08:44:57,530 - INFO - epoch 2, step 3710, training loss = 1.871063, validation loss = 2.401494
2018-12-05 08:45:01,001 - INFO - epoch 2, step 3720, training loss = 2.118428, validation loss = 2.151471
2018-12-05 08:45:04,593 - INFO - epoch 2, step 3730, training loss = 2.332997, validation loss = 1.861941
2018-12-05 08:45:08,432 - INFO - epoch 2, step 3740, training loss = 1.686655, validation loss = 2.293490
2018-12-05 08:45:11,696 - INFO - epoch 2, step 3750, training loss = 2.237978, validation loss = 2.447212
2018-12-05 08:45:15,083 - INFO - epoch 2, step 3760, training loss = 2.132020, validation loss = 2.459028
2018-12-05 08:45:18,500 - INFO - epoch 2, step 3770, training loss = 2.199505, validation loss = 1.942983
2018-12-05 08:45:21,784 - INFO - epoch 2, step 3780, training loss = 1.580070, validation loss = 2.296744
2018-12-05 08:45:24,953 - INFO - epoch 2, step 3790, training loss = 1.986336, validation loss = 2.016005
2018-12-05 08:45:28,124 - INFO - epoch 2, step 3800, training loss = 1.559492, validation loss = 1.943291
2018-12-05 08:45:31,532 - INFO - epoch 2, step 3810, training loss = 1.663095, validation loss = 2.029715
2018-12-05 08:45:34,910 - INFO - epoch 2, step 3820, training loss = 1.915697, validation loss = 2.382817
2018-12-05 08:45:38,393 - INFO - epoch 2, step 3830, training loss = 2.001419, validation loss = 1.980629
2018-12-05 08:45:41,773 - INFO - epoch 2, step 3840, training loss = 1.867228, validation loss = 1.880555
2018-12-05 08:45:45,054 - INFO - epoch 2, step 3850, training loss = 2.095936, validation loss = 2.039760
2018-12-05 08:45:48,486 - INFO - epoch 2, step 3860, training loss = 2.173873, validation loss = 2.123431
2018-12-05 08:45:51,778 - INFO - epoch 2, step 3870, training loss = 1.962660, validation loss = 1.942619
2018-12-05 08:45:55,311 - INFO - epoch 2, step 3880, training loss = 1.959430, validation loss = 1.950286
2018-12-05 08:45:59,365 - INFO - epoch 2, step 3890, training loss = 1.962313, validation loss = 1.916060
2018-12-05 08:46:03,372 - INFO - epoch 2, step 3900, training loss = 1.907551, validation loss = 2.327046
2018-12-05 08:46:07,582 - INFO - epoch 2, step 3910, training loss = 2.000927, validation loss = 2.263222
2018-12-05 08:46:11,721 - INFO - epoch 2, step 3920, training loss = 2.004625, validation loss = 1.997751
2018-12-05 08:46:15,705 - INFO - epoch 2, step 3930, training loss = 2.291688, validation loss = 1.749755
2018-12-05 08:46:19,831 - INFO - epoch 2, step 3940, training loss = 1.834290, validation loss = 2.115793
2018-12-05 08:46:23,791 - INFO - epoch 2, step 3950, training loss = 2.152073, validation loss = 2.289908
2018-12-05 08:46:27,563 - INFO - epoch 2, step 3960, training loss = 2.020443, validation loss = 2.050364
2018-12-05 08:46:31,375 - INFO - epoch 2, step 3970, training loss = 2.247461, validation loss = 1.931521
2018-12-05 08:46:35,516 - INFO - epoch 2, step 3980, training loss = 2.304685, validation loss = 1.969885
2018-12-05 08:46:39,458 - INFO - epoch 2, step 3990, training loss = 1.986724, validation loss = 2.498525
2018-12-05 08:46:43,601 - INFO - epoch 2, step 4000, training loss = 2.088203, validation loss = 1.840447
2018-12-05 08:46:47,892 - INFO - epoch 2, step 4010, training loss = 1.927298, validation loss = 1.966274
2018-12-05 08:46:51,485 - INFO - epoch 2, step 4020, training loss = 2.320284, validation loss = 2.249330
2018-12-05 08:46:54,912 - INFO - epoch 2, step 4030, training loss = 2.686454, validation loss = 2.176965
2018-12-05 08:46:58,204 - INFO - epoch 2, step 4040, training loss = 2.466709, validation loss = 1.746873
2018-12-05 08:47:01,841 - INFO - epoch 2, step 4050, training loss = 2.200935, validation loss = 2.336236
2018-12-05 08:47:05,303 - INFO - epoch 2, step 4060, training loss = 2.451077, validation loss = 2.291806
2018-12-05 08:47:08,617 - INFO - epoch 2, step 4070, training loss = 2.432099, validation loss = 2.113798
2018-12-05 08:47:12,043 - INFO - epoch 2, step 4080, training loss = 1.599335, validation loss = 2.365142
2018-12-05 08:47:15,862 - INFO - epoch 2, step 4090, training loss = 1.261563, validation loss = 2.199769
2018-12-05 08:47:19,431 - INFO - epoch 2, step 4100, training loss = 1.851142, validation loss = 2.072576
2018-12-05 08:47:23,097 - INFO - epoch 2, step 4110, training loss = 2.150024, validation loss = 2.437715
2018-12-05 08:47:26,760 - INFO - epoch 2, step 4120, training loss = 2.029202, validation loss = 1.792655
2018-12-05 08:47:30,437 - INFO - epoch 2, step 4130, training loss = 1.951271, validation loss = 2.519011
2018-12-05 08:47:33,931 - INFO - epoch 2, step 4140, training loss = 1.760833, validation loss = 2.380905
2018-12-05 08:47:37,548 - INFO - epoch 2, step 4150, training loss = 2.261768, validation loss = 2.369299
2018-12-05 08:47:41,001 - INFO - epoch 2, step 4160, training loss = 2.012849, validation loss = 2.149756
2018-12-05 08:47:44,504 - INFO - epoch 2, step 4170, training loss = 2.195183, validation loss = 1.938528
2018-12-05 08:47:48,188 - INFO - epoch 2, step 4180, training loss = 1.902709, validation loss = 2.111528
2018-12-05 08:47:51,720 - INFO - epoch 2, step 4190, training loss = 2.109594, validation loss = 2.296425
2018-12-05 08:47:55,112 - INFO - epoch 2, step 4200, training loss = 2.322001, validation loss = 2.183862
2018-12-05 08:47:58,622 - INFO - epoch 2, step 4210, training loss = 1.709211, validation loss = 2.131180
2018-12-05 08:48:02,172 - INFO - epoch 2, step 4220, training loss = 2.047564, validation loss = 2.526875
2018-12-05 08:48:05,912 - INFO - epoch 2, step 4230, training loss = 1.758189, validation loss = 1.799667
2018-12-05 08:48:09,889 - INFO - epoch 2, step 4240, training loss = 1.755668, validation loss = 2.108855
2018-12-05 08:48:13,924 - INFO - epoch 2, step 4250, training loss = 1.993798, validation loss = 2.550314
2018-12-05 08:48:17,823 - INFO - epoch 2, step 4260, training loss = 1.981899, validation loss = 2.289467
2018-12-05 08:48:21,429 - INFO - epoch 2, step 4270, training loss = 1.836124, validation loss = 2.396532
2018-12-05 08:48:25,266 - INFO - epoch 2, step 4280, training loss = 2.254465, validation loss = 2.112046
2018-12-05 08:48:28,877 - INFO - epoch 2, step 4290, training loss = 1.809812, validation loss = 1.898667
2018-12-05 08:48:32,508 - INFO - epoch 2, step 4300, training loss = 1.954851, validation loss = 2.212563
2018-12-05 08:48:35,983 - INFO - epoch 2, step 4310, training loss = 2.025550, validation loss = 2.044306
2018-12-05 08:48:39,571 - INFO - epoch 2, step 4320, training loss = 2.088986, validation loss = 2.133860
2018-12-05 08:48:43,403 - INFO - epoch 2, step 4330, training loss = 2.001432, validation loss = 2.325436
2018-12-05 08:48:47,240 - INFO - epoch 2, step 4340, training loss = 1.898733, validation loss = 2.043704
2018-12-05 08:48:51,061 - INFO - epoch 2, step 4350, training loss = 2.159488, validation loss = 2.252930
2018-12-05 08:48:54,691 - INFO - epoch 2, step 4360, training loss = 1.630180, validation loss = 2.301381
2018-12-05 08:48:58,384 - INFO - epoch 2, step 4370, training loss = 2.298830, validation loss = 2.112403
2018-12-05 08:49:02,102 - INFO - epoch 2, step 4380, training loss = 2.102169, validation loss = 2.337643
2018-12-05 08:49:05,613 - INFO - epoch 2, step 4390, training loss = 2.144441, validation loss = 2.563463
2018-12-05 08:49:09,238 - INFO - epoch 2, step 4400, training loss = 2.426584, validation loss = 2.367897
2018-12-05 08:49:12,833 - INFO - epoch 2, step 4410, training loss = 2.195400, validation loss = 1.936743
2018-12-05 08:49:16,676 - INFO - epoch 2, step 4420, training loss = 1.961800, validation loss = 2.455474
2018-12-05 08:49:20,386 - INFO - epoch 2, step 4430, training loss = 1.987940, validation loss = 2.120423
2018-12-05 08:49:24,276 - INFO - epoch 2, step 4440, training loss = 2.125033, validation loss = 2.123354
2018-12-05 08:49:27,877 - INFO - epoch 2, step 4450, training loss = 2.071361, validation loss = 2.182564
2018-12-05 08:49:31,449 - INFO - epoch 2, step 4460, training loss = 1.837046, validation loss = 2.564332
2018-12-05 08:49:35,287 - INFO - epoch 2, step 4470, training loss = 1.270375, validation loss = 1.615597
2018-12-05 08:49:38,949 - INFO - epoch 2, step 4480, training loss = 2.509224, validation loss = 2.382823
2018-12-05 08:49:42,382 - INFO - epoch 2, step 4490, training loss = 2.303539, validation loss = 1.972516
2018-12-05 08:49:46,009 - INFO - epoch 2, step 4500, training loss = 1.797157, validation loss = 2.184920
2018-12-05 08:49:49,714 - INFO - epoch 2, step 4510, training loss = 1.768639, validation loss = 2.090946
2018-12-05 08:49:53,219 - INFO - epoch 2, step 4520, training loss = 1.888772, validation loss = 2.089004
2018-12-05 08:49:56,795 - INFO - epoch 2, step 4530, training loss = 1.619649, validation loss = 2.513495
2018-12-05 08:50:00,470 - INFO - epoch 2, step 4540, training loss = 1.786304, validation loss = 1.917879
2018-12-05 08:50:03,980 - INFO - epoch 2, step 4550, training loss = 1.799748, validation loss = 1.956223
2018-12-05 08:50:07,638 - INFO - epoch 2, step 4560, training loss = 2.291413, validation loss = 2.133611
2018-12-05 08:50:11,268 - INFO - epoch 2, step 4570, training loss = 1.897250, validation loss = 2.227669
2018-12-05 08:50:14,678 - INFO - epoch 2, step 4580, training loss = 1.897277, validation loss = 2.516073
2018-12-05 08:50:18,185 - INFO - epoch 2, step 4590, training loss = 2.058172, validation loss = 2.264917
2018-12-05 08:50:21,787 - INFO - epoch 2, step 4600, training loss = 2.061541, validation loss = 2.057535
2018-12-05 08:50:25,610 - INFO - epoch 2, step 4610, training loss = 1.735814, validation loss = 2.360887
2018-12-05 08:50:29,242 - INFO - epoch 2, step 4620, training loss = 1.870556, validation loss = 1.882790
2018-12-05 08:50:32,873 - INFO - epoch 2, step 4630, training loss = 1.710416, validation loss = 2.459251
2018-12-05 08:50:36,489 - INFO - epoch 2, step 4640, training loss = 2.217055, validation loss = 1.976412
2018-12-05 08:50:40,077 - INFO - epoch 2, step 4650, training loss = 2.173608, validation loss = 1.837273
2018-12-05 08:50:44,120 - INFO - epoch 2, step 4660, training loss = 2.029340, validation loss = 2.335848
2018-12-05 08:50:48,407 - INFO - epoch 2, step 4670, training loss = 1.896728, validation loss = 2.416847
2018-12-05 08:50:52,788 - INFO - epoch 2, step 4680, training loss = 1.892863, validation loss = 2.241349
2018-12-05 08:50:56,805 - INFO - epoch 2, step 4690, training loss = 2.552027, validation loss = 2.372109
2018-12-05 08:51:01,140 - INFO - epoch 2, step 4700, training loss = 2.320021, validation loss = 2.360321
2018-12-05 08:51:05,186 - INFO - epoch 2, step 4710, training loss = 2.379538, validation loss = 2.177273
2018-12-05 08:51:09,323 - INFO - epoch 2, step 4720, training loss = 2.104653, validation loss = 2.443603
2018-12-05 08:51:13,569 - INFO - epoch 2, step 4730, training loss = 2.159246, validation loss = 2.224256
2018-12-05 08:51:17,654 - INFO - epoch 2, step 4740, training loss = 2.072107, validation loss = 2.473747
2018-12-05 08:51:21,943 - INFO - epoch 2, step 4750, training loss = 2.274616, validation loss = 2.338575
2018-12-05 08:51:26,207 - INFO - epoch 2, step 4760, training loss = 1.832306, validation loss = 1.925113
2018-12-05 08:51:30,336 - INFO - epoch 2, step 4770, training loss = 2.411073, validation loss = 2.604598
2018-12-05 08:51:34,731 - INFO - epoch 2, step 4780, training loss = 2.052341, validation loss = 2.408575
2018-12-05 08:51:38,601 - INFO - epoch 2, step 4790, training loss = 1.893548, validation loss = 2.435477
2018-12-05 08:51:42,335 - INFO - epoch 2, step 4800, training loss = 1.727467, validation loss = 2.295701
2018-12-05 08:51:46,121 - INFO - epoch 2, step 4810, training loss = 1.834375, validation loss = 2.287014
2018-12-05 08:51:50,032 - INFO - epoch 2, step 4820, training loss = 1.795407, validation loss = 2.058924
2018-12-05 08:51:53,747 - INFO - epoch 2, step 4830, training loss = 2.199972, validation loss = 2.190704
2018-12-05 08:51:57,700 - INFO - epoch 2, step 4840, training loss = 2.176638, validation loss = 2.477325
2018-12-05 08:52:01,609 - INFO - epoch 2, step 4850, training loss = 2.004573, validation loss = 2.415166
2018-12-05 08:52:05,516 - INFO - epoch 2, step 4860, training loss = 1.888829, validation loss = 2.037263
2018-12-05 08:52:09,475 - INFO - epoch 2, step 4870, training loss = 1.929882, validation loss = 2.117282
2018-12-05 08:52:13,311 - INFO - epoch 2, step 4880, training loss = 2.614188, validation loss = 2.131969
2018-12-05 08:52:16,739 - INFO - epoch 2, step 4890, training loss = 2.356014, validation loss = 2.328027
2018-12-05 08:52:20,176 - INFO - epoch 2, step 4900, training loss = 2.303103, validation loss = 2.085006
2018-12-05 08:52:23,454 - INFO - epoch 2, step 4910, training loss = 2.313242, validation loss = 2.184475
2018-12-05 08:52:26,770 - INFO - epoch 2, step 4920, training loss = 1.961035, validation loss = 2.359030
2018-12-05 08:52:30,004 - INFO - epoch 2, step 4930, training loss = 2.233002, validation loss = 2.211133
2018-12-05 08:52:33,300 - INFO - epoch 2, step 4940, training loss = 2.207180, validation loss = 2.341688
2018-12-05 08:52:36,612 - INFO - epoch 2, step 4950, training loss = 2.059345, validation loss = 2.101549
2018-12-05 08:52:40,160 - INFO - epoch 2, step 4960, training loss = 1.784097, validation loss = 2.293111
2018-12-05 08:52:43,762 - INFO - epoch 2, step 4970, training loss = 2.298902, validation loss = 2.245360
2018-12-05 08:52:47,219 - INFO - epoch 2, step 4980, training loss = 2.040954, validation loss = 2.129799
2018-12-05 08:52:50,553 - INFO - epoch 2, step 4990, training loss = 2.240749, validation loss = 1.995642
2018-12-05 08:52:54,039 - INFO - epoch 2, step 5000, training loss = 1.996014, validation loss = 2.423100
2018-12-05 08:52:58,499 - INFO - epoch 2, step 5010, training loss = 1.725154, validation loss = 2.169265
2018-12-05 08:53:02,705 - INFO - epoch 2, step 5020, training loss = 2.340206, validation loss = 2.207276
2018-12-05 08:53:06,806 - INFO - epoch 2, step 5030, training loss = 1.970624, validation loss = 2.104992
2018-12-05 08:53:10,934 - INFO - epoch 2, step 5040, training loss = 1.310754, validation loss = 2.132960
2018-12-05 08:53:14,805 - INFO - epoch 2, step 5050, training loss = 1.879249, validation loss = 2.274708
2018-12-05 08:53:18,847 - INFO - epoch 2, step 5060, training loss = 2.004739, validation loss = 2.278626
2018-12-05 08:53:23,193 - INFO - epoch 2, step 5070, training loss = 2.198997, validation loss = 2.137903
2018-12-05 08:53:27,481 - INFO - epoch 2, step 5080, training loss = 1.554927, validation loss = 2.086247
2018-12-05 08:53:31,627 - INFO - epoch 2, step 5090, training loss = 1.899049, validation loss = 2.425151
2018-12-05 08:53:35,711 - INFO - epoch 2, step 5100, training loss = 1.714833, validation loss = 2.253401
2018-12-05 08:53:39,773 - INFO - epoch 2, step 5110, training loss = 1.830108, validation loss = 2.376294
2018-12-05 08:53:43,596 - INFO - epoch 2, step 5120, training loss = 1.859356, validation loss = 2.477057
2018-12-05 08:53:47,439 - INFO - epoch 2, step 5130, training loss = 1.850695, validation loss = 2.173252
2018-12-05 08:53:51,025 - INFO - epoch 2, step 5140, training loss = 1.939120, validation loss = 2.401263
2018-12-05 08:53:54,763 - INFO - epoch 2, step 5150, training loss = 2.012593, validation loss = 2.396801
2018-12-05 08:53:58,374 - INFO - epoch 2, step 5160, training loss = 1.532988, validation loss = 2.243071
2018-12-05 08:54:01,964 - INFO - epoch 2, step 5170, training loss = 1.907857, validation loss = 2.122945
2018-12-05 08:54:05,601 - INFO - epoch 2, step 5180, training loss = 1.922605, validation loss = 2.346398
2018-12-05 08:54:09,300 - INFO - epoch 2, step 5190, training loss = 1.730452, validation loss = 2.181445
2018-12-05 08:54:12,898 - INFO - epoch 2, step 5200, training loss = 1.640276, validation loss = 2.326071
2018-12-05 08:54:17,134 - INFO - epoch 2, step 5210, training loss = 1.857101, validation loss = 1.965956
2018-12-05 08:54:20,923 - INFO - epoch 2, step 5220, training loss = 2.136142, validation loss = 2.325861
2018-12-05 08:54:24,912 - INFO - epoch 2, step 5230, training loss = 2.066524, validation loss = 2.210824
2018-12-05 08:54:29,038 - INFO - epoch 2, step 5240, training loss = 1.917705, validation loss = 2.344442
2018-12-05 08:54:33,027 - INFO - epoch 2, step 5250, training loss = 2.250333, validation loss = 2.274571
2018-12-05 08:54:37,042 - INFO - epoch 2, step 5260, training loss = 2.282922, validation loss = 1.988540
2018-12-05 08:54:41,012 - INFO - epoch 2, step 5270, training loss = 2.432372, validation loss = 2.258022
2018-12-05 08:54:45,113 - INFO - epoch 2, step 5280, training loss = 1.880834, validation loss = 2.326093
2018-12-05 08:54:49,326 - INFO - epoch 2, step 5290, training loss = 1.933010, validation loss = 2.157773
2018-12-05 08:54:53,255 - INFO - epoch 2, step 5300, training loss = 2.161297, validation loss = 2.078892
2018-12-05 08:54:57,440 - INFO - epoch 2, step 5310, training loss = 1.939946, validation loss = 2.215525
2018-12-05 08:55:01,110 - INFO - epoch 2, step 5320, training loss = 1.879296, validation loss = 2.452843
2018-12-05 08:55:04,658 - INFO - epoch 2, step 5330, training loss = 2.341304, validation loss = 2.308500
2018-12-05 08:55:08,425 - INFO - epoch 2, step 5340, training loss = 1.977499, validation loss = 2.229810
2018-12-05 08:55:12,175 - INFO - epoch 2, step 5350, training loss = 1.604116, validation loss = 2.552806
2018-12-05 08:55:15,973 - INFO - epoch 2, step 5360, training loss = 1.940680, validation loss = 2.648396
2018-12-05 08:55:19,826 - INFO - epoch 2, step 5370, training loss = 2.102242, validation loss = 2.316458
2018-12-05 08:55:23,638 - INFO - epoch 2, step 5380, training loss = 2.058872, validation loss = 2.457738
2018-12-05 08:55:27,348 - INFO - epoch 2, step 5390, training loss = 1.986023, validation loss = 2.448174
2018-12-05 08:55:31,188 - INFO - epoch 2, step 5400, training loss = 2.003837, validation loss = 2.080854
2018-12-05 08:55:35,040 - INFO - epoch 2, step 5410, training loss = 1.857723, validation loss = 1.919884
2018-12-05 08:55:38,777 - INFO - epoch 2, step 5420, training loss = 2.037308, validation loss = 1.993447
2018-12-05 08:55:42,582 - INFO - epoch 2, step 5430, training loss = 2.141372, validation loss = 2.025457
2018-12-05 08:55:46,315 - INFO - epoch 2, step 5440, training loss = 1.663771, validation loss = 1.986470
2018-12-05 08:55:49,884 - INFO - epoch 2, step 5450, training loss = 1.845812, validation loss = 2.168574
2018-12-05 08:55:53,440 - INFO - epoch 2, step 5460, training loss = 1.903580, validation loss = 1.743759
2018-12-05 08:55:57,143 - INFO - epoch 2, step 5470, training loss = 2.175735, validation loss = 2.375391
2018-12-05 08:56:00,840 - INFO - epoch 2, step 5480, training loss = 1.837312, validation loss = 2.119214
2018-12-05 08:56:04,432 - INFO - epoch 2, step 5490, training loss = 2.128515, validation loss = 2.417850
2018-12-05 08:56:08,164 - INFO - epoch 2, step 5500, training loss = 2.088130, validation loss = 2.175529
2018-12-05 08:56:11,830 - INFO - epoch 2, step 5510, training loss = 1.912451, validation loss = 2.072137
2018-12-05 08:56:15,475 - INFO - epoch 2, step 5520, training loss = 1.972440, validation loss = 1.826690
2018-12-05 08:56:19,156 - INFO - epoch 2, step 5530, training loss = 1.771587, validation loss = 1.757809
2018-12-05 08:56:23,245 - INFO - epoch 2, step 5540, training loss = 1.611120, validation loss = 2.594854
2018-12-05 08:56:27,229 - INFO - epoch 2, step 5550, training loss = 2.079602, validation loss = 2.300992
2018-12-05 08:56:31,192 - INFO - epoch 2, step 5560, training loss = 1.918892, validation loss = 1.669925
2018-12-05 08:56:35,107 - INFO - epoch 2, step 5570, training loss = 1.851476, validation loss = 2.183107
2018-12-05 08:56:38,984 - INFO - epoch 2, step 5580, training loss = 1.894006, validation loss = 1.821867
2018-12-05 08:56:42,962 - INFO - epoch 2, step 5590, training loss = 1.645208, validation loss = 2.273100
2018-12-05 08:56:46,850 - INFO - epoch 2, step 5600, training loss = 1.739750, validation loss = 2.557183
2018-12-05 08:56:50,926 - INFO - epoch 2, step 5610, training loss = 2.207832, validation loss = 1.753223
2018-12-05 08:56:54,832 - INFO - epoch 2, step 5620, training loss = 2.228917, validation loss = 2.202657
2018-12-05 08:56:59,103 - INFO - epoch 2, step 5630, training loss = 1.935357, validation loss = 2.314277
2018-12-05 08:57:03,448 - INFO - epoch 2, step 5640, training loss = 1.889154, validation loss = 2.369295
2018-12-05 08:57:07,664 - INFO - epoch 2, step 5650, training loss = 1.972621, validation loss = 1.984038
2018-12-05 08:57:11,815 - INFO - epoch 2, step 5660, training loss = 1.948985, validation loss = 2.452534
2018-12-05 08:57:15,995 - INFO - epoch 2, step 5670, training loss = 2.008041, validation loss = 1.896368
2018-12-05 08:57:20,178 - INFO - epoch 2, step 5680, training loss = 1.765635, validation loss = 2.231113
2018-12-05 08:57:24,521 - INFO - epoch 2, step 5690, training loss = 1.971746, validation loss = 1.953605
2018-12-05 08:57:28,583 - INFO - epoch 2, step 5700, training loss = 2.199556, validation loss = 2.521111
2018-12-05 08:57:32,798 - INFO - epoch 2, step 5710, training loss = 1.926979, validation loss = 2.334580
2018-12-05 08:57:36,817 - INFO - epoch 2, step 5720, training loss = 1.972916, validation loss = 2.386043
2018-12-05 08:57:41,022 - INFO - epoch 2, step 5730, training loss = 2.109982, validation loss = 2.345167
2018-12-05 08:57:45,147 - INFO - epoch 2, step 5740, training loss = 2.109057, validation loss = 2.285671
2018-12-05 08:57:49,395 - INFO - epoch 2, step 5750, training loss = 2.159720, validation loss = 2.098895
2018-12-05 08:57:53,877 - INFO - epoch 2, step 5760, training loss = 2.153526, validation loss = 1.843420
2018-12-05 08:57:58,010 - INFO - epoch 2, step 5770, training loss = 1.618990, validation loss = 2.421904
2018-12-05 08:58:01,956 - INFO - epoch 2, step 5780, training loss = 2.012928, validation loss = 2.197837
2018-12-05 08:58:06,167 - INFO - epoch 2, step 5790, training loss = 2.296941, validation loss = 2.250994
2018-12-05 08:58:10,407 - INFO - epoch 2, step 5800, training loss = 1.923086, validation loss = 1.946415
2018-12-05 08:58:14,647 - INFO - epoch 2, step 5810, training loss = 1.915419, validation loss = 2.191770
2018-12-05 08:58:18,932 - INFO - epoch 2, step 5820, training loss = 1.750158, validation loss = 2.254025
2018-12-05 08:58:23,367 - INFO - epoch 2, step 5830, training loss = 1.917200, validation loss = 1.787796
2018-12-05 08:58:27,623 - INFO - epoch 2, step 5840, training loss = 1.913802, validation loss = 1.786690
2018-12-05 08:58:31,007 - INFO - epoch 2, step 5850, training loss = 2.160460, validation loss = 2.236888
2018-12-05 08:58:34,360 - INFO - epoch 2, step 5860, training loss = 2.195264, validation loss = 1.779261
2018-12-05 08:58:37,708 - INFO - epoch 2, step 5870, training loss = 1.800459, validation loss = 2.360139
2018-12-05 08:58:41,171 - INFO - epoch 2, step 5880, training loss = 2.089356, validation loss = 2.248294
2018-12-05 08:58:44,393 - INFO - epoch 2, step 5890, training loss = 2.054940, validation loss = 2.152946
2018-12-05 08:58:47,702 - INFO - epoch 2, step 5900, training loss = 2.046266, validation loss = 2.620882
2018-12-05 08:58:51,187 - INFO - epoch 2, step 5910, training loss = 2.212584, validation loss = 2.536547
2018-12-05 08:58:54,487 - INFO - epoch 2, step 5920, training loss = 2.431973, validation loss = 2.023852
2018-12-05 08:58:57,791 - INFO - epoch 2, step 5930, training loss = 1.547929, validation loss = 2.749052
2018-12-05 08:59:01,211 - INFO - epoch 2, step 5940, training loss = 1.808990, validation loss = 2.412799
2018-12-05 08:59:04,430 - INFO - epoch 2, step 5950, training loss = 1.876240, validation loss = 2.830642
2018-12-05 08:59:07,759 - INFO - epoch 2, step 5960, training loss = 2.290081, validation loss = 2.147263
2018-12-05 08:59:11,848 - INFO - epoch 2, step 5970, training loss = 2.167268, validation loss = 1.957084
2018-12-05 08:59:16,121 - INFO - epoch 2, step 5980, training loss = 1.844851, validation loss = 2.044097
2018-12-05 08:59:20,556 - INFO - epoch 2, step 5990, training loss = 2.133574, validation loss = 2.217931
2018-12-05 08:59:24,783 - INFO - epoch 2, step 6000, training loss = 2.021907, validation loss = 2.255330
2018-12-05 08:59:28,871 - INFO - epoch 2, step 6010, training loss = 1.695491, validation loss = 2.773199
2018-12-05 08:59:33,179 - INFO - epoch 2, step 6020, training loss = 1.950801, validation loss = 2.386712
2018-12-05 08:59:37,446 - INFO - epoch 2, step 6030, training loss = 2.140799, validation loss = 2.020652
2018-12-05 08:59:41,729 - INFO - epoch 2, step 6040, training loss = 1.957638, validation loss = 1.867223
2018-12-05 08:59:46,210 - INFO - epoch 2, step 6050, training loss = 1.946671, validation loss = 2.237523
2018-12-05 08:59:50,477 - INFO - epoch 2, step 6060, training loss = 2.149419, validation loss = 1.790459
2018-12-05 08:59:54,673 - INFO - epoch 2, step 6070, training loss = 2.248300, validation loss = 2.418291
2018-12-05 08:59:58,966 - INFO - epoch 2, step 6080, training loss = 1.821627, validation loss = 2.619616
2018-12-05 09:00:03,184 - INFO - epoch 2, step 6090, training loss = 2.106262, validation loss = 2.109024
2018-12-05 09:00:07,247 - INFO - epoch 2, step 6100, training loss = 2.118197, validation loss = 2.488623
2018-12-05 09:00:11,417 - INFO - epoch 2, step 6110, training loss = 1.699304, validation loss = 2.596074
2018-12-05 09:00:16,305 - INFO - epoch 2, step 6120, training loss = 2.182916, validation loss = 2.440365
2018-12-05 09:00:20,614 - INFO - epoch 2, step 6130, training loss = 1.686359, validation loss = 1.930942
2018-12-05 09:00:24,708 - INFO - epoch 2, step 6140, training loss = 2.175167, validation loss = 2.477012
2018-12-05 09:00:28,879 - INFO - epoch 2, step 6150, training loss = 1.942091, validation loss = 2.614602
2018-12-05 09:00:33,119 - INFO - epoch 2, step 6160, training loss = 1.970545, validation loss = 2.407214
2018-12-05 09:00:37,374 - INFO - epoch 2, step 6170, training loss = 2.049574, validation loss = 2.051779
2018-12-05 09:00:41,624 - INFO - epoch 2, step 6180, training loss = 1.828642, validation loss = 2.246157
2018-12-05 09:00:45,783 - INFO - epoch 2, step 6190, training loss = 1.929688, validation loss = 2.683674
2018-12-05 09:00:50,074 - INFO - epoch 2, step 6200, training loss = 2.483401, validation loss = 2.544484
2018-12-05 09:00:54,202 - INFO - epoch 2, step 6210, training loss = 2.016765, validation loss = 2.344396
2018-12-05 09:00:58,716 - INFO - epoch 2, step 6220, training loss = 2.089013, validation loss = 2.107259
2018-12-05 09:01:02,853 - INFO - epoch 2, step 6230, training loss = 1.647495, validation loss = 2.674358
2018-12-05 09:01:06,936 - INFO - epoch 2, step 6240, training loss = 1.958353, validation loss = 2.747346
2018-12-05 09:01:11,118 - INFO - epoch 2, step 6250, training loss = 1.692397, validation loss = 2.019107
2018-12-05 09:01:15,267 - INFO - epoch 2, step 6260, training loss = 2.200777, validation loss = 2.247708
2018-12-05 09:01:19,432 - INFO - epoch 2, step 6270, training loss = 1.964366, validation loss = 2.765221
2018-12-05 09:01:23,215 - INFO - epoch 2, step 6280, training loss = 2.049167, validation loss = 2.704939
2018-12-05 09:01:27,237 - INFO - epoch 2, step 6290, training loss = 1.636322, validation loss = 2.466820
2018-12-05 09:01:30,895 - INFO - epoch 2, step 6300, training loss = 2.218199, validation loss = 2.660640
2018-12-05 09:01:34,774 - INFO - epoch 2, step 6310, training loss = 1.560776, validation loss = 2.582429
2018-12-05 09:01:38,632 - INFO - epoch 2, step 6320, training loss = 2.071687, validation loss = 3.232846
2018-12-05 09:01:42,403 - INFO - epoch 2, step 6330, training loss = 1.980613, validation loss = 2.346162
2018-12-05 09:01:46,239 - INFO - epoch 2, step 6340, training loss = 2.493187, validation loss = 2.285356
2018-12-05 09:01:49,980 - INFO - epoch 2, step 6350, training loss = 1.796976, validation loss = 2.157363
2018-12-05 09:01:53,499 - INFO - epoch 2, step 6360, training loss = 1.900568, validation loss = 2.372028
2018-12-05 09:01:57,182 - INFO - epoch 2, step 6370, training loss = 2.524983, validation loss = 2.788513
2018-12-05 09:02:00,920 - INFO - epoch 2, step 6380, training loss = 2.021532, validation loss = 2.640115
2018-12-05 09:02:04,756 - INFO - epoch 2, step 6390, training loss = 1.420376, validation loss = 2.383169
2018-12-05 09:02:08,481 - INFO - epoch 2, step 6400, training loss = 2.059967, validation loss = 1.724311
2018-12-05 09:02:12,014 - INFO - epoch 2, step 6410, training loss = 1.917542, validation loss = 2.995398
2018-12-05 09:02:15,772 - INFO - epoch 2, step 6420, training loss = 1.670068, validation loss = 2.311052
2018-12-05 09:02:19,533 - INFO - epoch 2, step 6430, training loss = 1.541886, validation loss = 2.779424
2018-12-05 09:02:23,279 - INFO - epoch 2, step 6440, training loss = 2.320965, validation loss = 2.389879
2018-12-05 09:02:27,015 - INFO - epoch 2, step 6450, training loss = 1.950912, validation loss = 2.599017
2018-12-05 09:02:30,644 - INFO - epoch 2, step 6460, training loss = 2.042464, validation loss = 2.445693
2018-12-05 09:02:34,317 - INFO - epoch 2, step 6470, training loss = 1.582026, validation loss = 2.635641
2018-12-05 09:02:37,828 - INFO - epoch 2, step 6480, training loss = 2.022080, validation loss = 2.667739
2018-12-05 09:02:41,623 - INFO - epoch 2, step 6490, training loss = 1.548994, validation loss = 2.200661
2018-12-05 09:02:45,400 - INFO - epoch 2, step 6500, training loss = 1.864438, validation loss = 2.440653
2018-12-05 09:02:49,082 - INFO - epoch 2, step 6510, training loss = 1.890125, validation loss = 2.332241
2018-12-05 09:02:52,850 - INFO - epoch 2, step 6520, training loss = 1.935672, validation loss = 2.378567
2018-12-05 09:02:56,461 - INFO - epoch 2, step 6530, training loss = 2.407598, validation loss = 2.839371
2018-12-05 09:03:00,009 - INFO - epoch 2, step 6540, training loss = 1.818151, validation loss = 2.293041
2018-12-05 09:03:03,785 - INFO - epoch 2, step 6550, training loss = 1.901853, validation loss = 2.188598
2018-12-05 09:03:07,331 - INFO - epoch 2, step 6560, training loss = 2.036941, validation loss = 2.837692
2018-12-05 09:03:10,782 - INFO - epoch 2, step 6570, training loss = 2.293464, validation loss = 2.889457
2018-12-05 09:03:14,317 - INFO - epoch 2, step 6580, training loss = 2.016837, validation loss = 2.859773
2018-12-05 09:03:18,096 - INFO - epoch 2, step 6590, training loss = 2.057318, validation loss = 2.319097
2018-12-05 09:03:21,615 - INFO - epoch 2, step 6600, training loss = 2.097102, validation loss = 2.219034
2018-12-05 09:03:25,262 - INFO - epoch 2, step 6610, training loss = 1.785440, validation loss = 2.600940
2018-12-05 09:03:28,952 - INFO - epoch 2, step 6620, training loss = 1.969301, validation loss = 2.397103
2018-12-05 09:03:32,771 - INFO - epoch 2, step 6630, training loss = 1.969607, validation loss = 2.479739
2018-12-05 09:03:36,441 - INFO - epoch 2, step 6640, training loss = 2.038773, validation loss = 2.154025
2018-12-05 09:03:40,186 - INFO - epoch 2, step 6650, training loss = 2.057909, validation loss = 2.486797
2018-12-05 09:03:44,165 - INFO - epoch 2, step 6660, training loss = 1.778588, validation loss = 2.616098
2018-12-05 09:03:48,077 - INFO - epoch 2, step 6670, training loss = 2.017450, validation loss = 2.420679
2018-12-05 09:03:51,762 - INFO - epoch 2, step 6680, training loss = 1.894171, validation loss = 2.425325
2018-12-05 09:03:55,845 - INFO - epoch 2, step 6690, training loss = 2.108234, validation loss = 2.918321
2018-12-05 09:03:59,434 - INFO - epoch 2, step 6700, training loss = 2.344653, validation loss = 2.434006
2018-12-05 09:04:03,129 - INFO - epoch 2, step 6710, training loss = 1.595520, validation loss = 2.421403
2018-12-05 09:04:06,818 - INFO - epoch 2, step 6720, training loss = 2.157309, validation loss = 2.484432
2018-12-05 09:04:10,668 - INFO - epoch 2, step 6730, training loss = 1.958336, validation loss = 2.531532
2018-12-05 09:04:14,408 - INFO - epoch 2, step 6740, training loss = 1.881420, validation loss = 2.682927
2018-12-05 09:04:18,398 - INFO - epoch 2, step 6750, training loss = 1.944812, validation loss = 2.409403
2018-12-05 09:04:22,132 - INFO - epoch 2, step 6760, training loss = 2.069985, validation loss = 2.364917
2018-12-05 09:04:25,881 - INFO - epoch 2, step 6770, training loss = 1.983757, validation loss = 2.789395
2018-12-05 09:04:29,633 - INFO - epoch 2, step 6780, training loss = 2.139692, validation loss = 2.294437
2018-12-05 09:04:33,327 - INFO - epoch 2, step 6790, training loss = 1.664147, validation loss = 2.687020
2018-12-05 09:04:36,848 - INFO - epoch 2, step 6800, training loss = 1.952355, validation loss = 2.308378
2018-12-05 09:04:40,503 - INFO - epoch 2, step 6810, training loss = 2.167658, validation loss = 2.551430
2018-12-05 09:04:44,154 - INFO - epoch 2, step 6820, training loss = 1.661018, validation loss = 2.639648
2018-12-05 09:04:48,048 - INFO - epoch 2, step 6830, training loss = 2.049178, validation loss = 2.386700
2018-12-05 09:04:51,527 - INFO - epoch 2, step 6840, training loss = 1.891334, validation loss = 2.618290
2018-12-05 09:04:55,092 - INFO - epoch 2, step 6850, training loss = 1.779358, validation loss = 2.551685
2018-12-05 09:04:58,653 - INFO - epoch 2, step 6860, training loss = 2.007759, validation loss = 2.879550
2018-12-05 09:05:02,137 - INFO - epoch 2, step 6870, training loss = 2.369973, validation loss = 2.858114
2018-12-05 09:05:05,805 - INFO - epoch 2, step 6880, training loss = 1.927165, validation loss = 2.914476
2018-12-05 09:05:09,306 - INFO - epoch 2, step 6890, training loss = 2.230793, validation loss = 2.337883
2018-12-05 09:05:12,942 - INFO - epoch 2, step 6900, training loss = 1.632025, validation loss = 2.606873
2018-12-05 09:05:17,000 - INFO - epoch 2, step 6910, training loss = 2.239454, validation loss = 2.044034
2018-12-05 09:05:20,902 - INFO - epoch 2, step 6920, training loss = 2.397058, validation loss = 2.237247
2018-12-05 09:05:24,929 - INFO - epoch 2, step 6930, training loss = 1.875060, validation loss = 2.512606
2018-12-05 09:05:28,590 - INFO - epoch 2, step 6940, training loss = 2.128160, validation loss = 2.518873
2018-12-05 09:05:32,530 - INFO - epoch 2, step 6950, training loss = 2.127438, validation loss = 2.233233
2018-12-05 09:05:36,597 - INFO - epoch 2, step 6960, training loss = 2.197784, validation loss = 2.430753
2018-12-05 09:05:40,622 - INFO - epoch 2, step 6970, training loss = 1.845326, validation loss = 2.623358
2018-12-05 09:05:44,777 - INFO - epoch 2, step 6980, training loss = 1.757364, validation loss = 2.204501
2018-12-05 09:05:49,102 - INFO - epoch 2, step 6990, training loss = 1.944679, validation loss = 2.353097
2018-12-05 09:05:53,215 - INFO - epoch 2, step 7000, training loss = 2.046638, validation loss = 2.329976
2018-12-05 09:05:57,682 - INFO - epoch 2, step 7010, training loss = 1.960967, validation loss = 2.697438
2018-12-05 09:06:01,800 - INFO - epoch 2, step 7020, training loss = 1.560352, validation loss = 2.960870
2018-12-05 09:06:06,081 - INFO - epoch 2, step 7030, training loss = 2.050648, validation loss = 2.852129
2018-12-05 09:06:10,488 - INFO - epoch 2, step 7040, training loss = 1.755684, validation loss = 2.696333
2018-12-05 09:06:14,938 - INFO - epoch 2, step 7050, training loss = 1.827067, validation loss = 3.168256
2018-12-05 09:06:19,222 - INFO - epoch 2, step 7060, training loss = 2.584639, validation loss = 2.575759
2018-12-05 09:06:23,302 - INFO - epoch 2, step 7070, training loss = 2.017600, validation loss = 2.522275
2018-12-05 09:06:27,591 - INFO - epoch 2, step 7080, training loss = 2.057201, validation loss = 2.869238
2018-12-05 09:06:31,825 - INFO - epoch 2, step 7090, training loss = 1.790898, validation loss = 2.865161
2018-12-05 09:06:36,041 - INFO - epoch 2, step 7100, training loss = 2.231173, validation loss = 2.231392
2018-12-05 09:06:40,189 - INFO - epoch 2, step 7110, training loss = 1.604919, validation loss = 2.646961
2018-12-05 09:06:44,418 - INFO - epoch 2, step 7120, training loss = 2.162401, validation loss = 2.312863
2018-12-05 09:06:48,740 - INFO - epoch 2, step 7130, training loss = 1.713717, validation loss = 2.552109
2018-12-05 09:06:52,959 - INFO - epoch 2, step 7140, training loss = 1.966187, validation loss = 2.393822
2018-12-05 09:06:57,177 - INFO - epoch 2, step 7150, training loss = 1.674521, validation loss = 2.525136
2018-12-05 09:07:01,053 - INFO - epoch 2, step 7160, training loss = 2.294270, validation loss = 2.709347
2018-12-05 09:07:05,148 - INFO - epoch 2, step 7170, training loss = 1.895236, validation loss = 2.099475
2018-12-05 09:07:09,249 - INFO - epoch 2, step 7180, training loss = 1.903555, validation loss = 2.522877
2018-12-05 09:07:13,627 - INFO - epoch 2, step 7190, training loss = 1.900078, validation loss = 3.088547
2018-12-05 09:07:17,738 - INFO - epoch 2, step 7200, training loss = 1.777856, validation loss = 2.215197
2018-12-05 09:07:22,316 - INFO - epoch 2, step 7210, training loss = 2.102837, validation loss = 2.413167
2018-12-05 09:07:26,673 - INFO - epoch 2, step 7220, training loss = 1.942964, validation loss = 3.089639
2018-12-05 09:07:30,315 - INFO - epoch 2, step 7230, training loss = 2.057091, validation loss = 2.302177
2018-12-05 09:07:33,964 - INFO - epoch 2, step 7240, training loss = 1.876395, validation loss = 2.775012
2018-12-05 09:07:37,650 - INFO - epoch 2, step 7250, training loss = 1.790408, validation loss = 2.484548
2018-12-05 09:07:41,191 - INFO - epoch 2, step 7260, training loss = 2.378163, validation loss = 2.813254
2018-12-05 09:07:44,960 - INFO - epoch 2, step 7270, training loss = 2.005421, validation loss = 2.809937
2018-12-05 09:07:48,517 - INFO - epoch 2, step 7280, training loss = 2.054146, validation loss = 3.153411
2018-12-05 09:07:52,214 - INFO - epoch 2, step 7290, training loss = 1.927281, validation loss = 3.016250
2018-12-05 09:07:56,030 - INFO - epoch 2, step 7300, training loss = 1.624525, validation loss = 3.129636
2018-12-05 09:07:59,906 - INFO - epoch 2, step 7310, training loss = 1.676334, validation loss = 2.873760
2018-12-05 09:08:03,673 - INFO - epoch 2, step 7320, training loss = 2.119987, validation loss = 2.293530
2018-12-05 09:08:07,323 - INFO - epoch 2, step 7330, training loss = 2.311338, validation loss = 2.539967
2018-12-05 09:08:11,018 - INFO - epoch 2, step 7340, training loss = 1.887948, validation loss = 3.249794
2018-12-05 09:08:14,815 - INFO - epoch 2, step 7350, training loss = 2.073863, validation loss = 2.450842
2018-12-05 09:08:18,475 - INFO - epoch 2, step 7360, training loss = 2.132108, validation loss = 2.965676
2018-12-05 09:08:21,839 - INFO - epoch 2, step 7370, training loss = 2.067499, validation loss = 1.952137
2018-12-05 09:08:25,698 - INFO - epoch 2, step 7380, training loss = 2.062507, validation loss = 2.749365
2018-12-05 09:08:29,384 - INFO - epoch 2, step 7390, training loss = 1.964170, validation loss = 2.639444
2018-12-05 09:08:33,168 - INFO - epoch 2, step 7400, training loss = 2.017141, validation loss = 2.913173
2018-12-05 09:08:36,853 - INFO - epoch 2, step 7410, training loss = 1.748470, validation loss = 2.433419
2018-12-05 09:08:40,377 - INFO - epoch 2, step 7420, training loss = 1.895603, validation loss = 2.764432
2018-12-05 09:08:43,496 - INFO - epoch 2, step 7430, training loss = 1.841740, validation loss = 2.957471
2018-12-05 09:08:46,965 - INFO - epoch 2, step 7440, training loss = 1.717369, validation loss = 2.837963
2018-12-05 09:08:50,316 - INFO - epoch 2, step 7450, training loss = 2.211189, validation loss = 3.115930
2018-12-05 09:08:53,609 - INFO - epoch 2, step 7460, training loss = 1.554124, validation loss = 3.169780
2018-12-05 09:08:56,965 - INFO - epoch 2, step 7470, training loss = 2.009016, validation loss = 2.624152
2018-12-05 09:09:00,347 - INFO - epoch 2, step 7480, training loss = 1.971286, validation loss = 2.911640
2018-12-05 09:09:03,600 - INFO - epoch 2, step 7490, training loss = 2.145569, validation loss = 2.896420
2018-12-05 09:09:06,956 - INFO - epoch 2, step 7500, training loss = 1.533045, validation loss = 2.936941
2018-12-05 09:09:10,558 - INFO - epoch 2, step 7510, training loss = 1.686295, validation loss = 3.175551
2018-12-05 09:09:13,907 - INFO - epoch 2, step 7520, training loss = 1.190762, validation loss = 3.252849
2018-12-05 09:09:17,371 - INFO - epoch 2, step 7530, training loss = 1.923889, validation loss = 3.072508
2018-12-05 09:09:20,599 - INFO - epoch 2, step 7540, training loss = 2.117852, validation loss = 2.601725
2018-12-05 09:09:23,821 - INFO - epoch 2, step 7550, training loss = 1.846491, validation loss = 2.839213
2018-12-05 09:09:27,512 - INFO - epoch 2, step 7560, training loss = 1.679163, validation loss = 3.056901
2018-12-05 09:09:31,109 - INFO - epoch 2, step 7570, training loss = 2.005038, validation loss = 3.008790
2018-12-05 09:09:34,608 - INFO - epoch 2, step 7580, training loss = 1.913508, validation loss = 3.012298
2018-12-05 09:09:38,207 - INFO - epoch 2, step 7590, training loss = 1.914535, validation loss = 2.807212
2018-12-05 09:09:41,794 - INFO - epoch 2, step 7600, training loss = 2.038208, validation loss = 3.089123
2018-12-05 09:09:45,342 - INFO - epoch 2, step 7610, training loss = 1.747196, validation loss = 2.964281
2018-12-05 09:09:49,121 - INFO - epoch 2, step 7620, training loss = 2.057050, validation loss = 2.524843
2018-12-05 09:09:52,958 - INFO - epoch 2, step 7630, training loss = 2.009712, validation loss = 2.975059
2018-12-05 09:09:56,632 - INFO - epoch 2, step 7640, training loss = 1.549328, validation loss = 2.823341
2018-12-05 09:10:00,228 - INFO - epoch 2, step 7650, training loss = 1.837460, validation loss = 3.124378
2018-12-05 09:10:03,919 - INFO - epoch 2, step 7660, training loss = 1.870831, validation loss = 2.614317
2018-12-05 09:10:07,757 - INFO - epoch 2, step 7670, training loss = 1.679056, validation loss = 2.851388
2018-12-05 09:10:11,528 - INFO - epoch 2, step 7680, training loss = 1.824179, validation loss = 2.975800
2018-12-05 09:10:15,374 - INFO - epoch 2, step 7690, training loss = 1.490860, validation loss = 3.284165
2018-12-05 09:10:19,070 - INFO - epoch 2, step 7700, training loss = 1.742450, validation loss = 2.560283
2018-12-05 09:10:22,747 - INFO - epoch 2, step 7710, training loss = 2.042056, validation loss = 2.650242
2018-12-05 09:10:26,543 - INFO - epoch 2, step 7720, training loss = 1.922792, validation loss = 2.302352
2018-12-05 09:10:30,154 - INFO - epoch 2, step 7730, training loss = 1.963775, validation loss = 2.236502
2018-12-05 09:10:33,760 - INFO - epoch 2, step 7740, training loss = 2.341430, validation loss = 3.194817
2018-12-05 09:10:37,434 - INFO - epoch 2, step 7750, training loss = 1.716862, validation loss = 2.563532
2018-12-05 09:10:41,087 - INFO - epoch 2, step 7760, training loss = 2.107613, validation loss = 2.527651
2018-12-05 09:10:44,657 - INFO - epoch 2, step 7770, training loss = 2.146565, validation loss = 2.530401
2018-12-05 09:10:48,396 - INFO - epoch 2, step 7780, training loss = 1.864600, validation loss = 3.111698
2018-12-05 09:10:52,262 - INFO - epoch 2, step 7790, training loss = 2.145530, validation loss = 3.343143
2018-12-05 09:10:55,915 - INFO - epoch 2, step 7800, training loss = 2.260415, validation loss = 3.217569
2018-12-05 09:10:59,692 - INFO - epoch 2, step 7810, training loss = 1.702505, validation loss = 2.758863
2018-12-05 09:11:03,368 - INFO - epoch 2, step 7820, training loss = 2.309030, validation loss = 2.866799
2018-12-05 09:11:07,354 - INFO - epoch 2, step 7830, training loss = 2.049588, validation loss = 2.845588
2018-12-05 09:11:11,097 - INFO - epoch 2, step 7840, training loss = 2.144732, validation loss = 2.463589
2018-12-05 09:11:15,171 - INFO - epoch 2, step 7850, training loss = 1.992933, validation loss = 2.943050
2018-12-05 09:11:19,044 - INFO - epoch 2, step 7860, training loss = 1.867535, validation loss = 3.047483
2018-12-05 09:11:22,989 - INFO - epoch 2, step 7870, training loss = 1.875803, validation loss = 2.493822
2018-12-05 09:11:26,964 - INFO - epoch 2, step 7880, training loss = 1.524045, validation loss = 2.736202
2018-12-05 09:11:30,966 - INFO - epoch 2, step 7890, training loss = 1.951290, validation loss = 2.570647
2018-12-05 09:11:35,028 - INFO - epoch 2, step 7900, training loss = 1.839976, validation loss = 2.604295
2018-12-05 09:11:38,924 - INFO - epoch 2, step 7910, training loss = 2.182670, validation loss = 2.974870
2018-12-05 09:11:43,271 - INFO - epoch 2, step 7920, training loss = 1.945357, validation loss = 3.260535
2018-12-05 09:11:47,067 - INFO - epoch 2, step 7930, training loss = 2.168998, validation loss = 3.006812
2018-12-05 09:11:50,946 - INFO - epoch 2, step 7940, training loss = 1.415893, validation loss = 2.878198
2018-12-05 09:11:54,870 - INFO - epoch 2, step 7950, training loss = 1.711567, validation loss = 2.684969
2018-12-05 09:11:59,052 - INFO - epoch 2, step 7960, training loss = 1.733793, validation loss = 2.846614
2018-12-05 09:12:03,275 - INFO - epoch 2, step 7970, training loss = 1.518989, validation loss = 2.836568
2018-12-05 09:12:07,448 - INFO - epoch 2, step 7980, training loss = 1.827483, validation loss = 2.361091
2018-12-05 09:12:11,526 - INFO - epoch 2, step 7990, training loss = 1.793890, validation loss = 2.861409
2018-12-05 09:12:15,401 - INFO - epoch 2, step 8000, training loss = 2.058842, validation loss = 3.283298
2018-12-05 09:12:19,595 - INFO - epoch 2, step 8010, training loss = 2.248945, validation loss = 3.110798
2018-12-05 09:12:23,662 - INFO - epoch 2, step 8020, training loss = 1.564018, validation loss = 3.316849
2018-12-05 09:12:27,943 - INFO - epoch 2, step 8030, training loss = 2.303800, validation loss = 2.488251
2018-12-05 09:12:32,311 - INFO - epoch 2, step 8040, training loss = 2.038396, validation loss = 3.102501
2018-12-05 09:12:36,519 - INFO - epoch 2, step 8050, training loss = 1.813583, validation loss = 2.972653
2018-12-05 09:12:40,891 - INFO - epoch 2, step 8060, training loss = 2.144977, validation loss = 2.362615
2018-12-05 09:12:45,217 - INFO - epoch 2, step 8070, training loss = 1.756961, validation loss = 2.916877
2018-12-05 09:12:49,372 - INFO - epoch 2, step 8080, training loss = 1.975580, validation loss = 2.586637
2018-12-05 09:12:53,397 - INFO - epoch 2, step 8090, training loss = 1.706794, validation loss = 2.546865
2018-12-05 09:12:57,750 - INFO - epoch 2, step 8100, training loss = 1.894804, validation loss = 3.082922
2018-12-05 09:13:01,981 - INFO - epoch 2, step 8110, training loss = 2.146779, validation loss = 2.614274
2018-12-05 09:13:06,188 - INFO - epoch 2, step 8120, training loss = 2.095087, validation loss = 3.291450
2018-12-05 09:13:10,578 - INFO - epoch 2, step 8130, training loss = 2.219019, validation loss = 2.893318
2018-12-05 09:13:14,854 - INFO - epoch 2, step 8140, training loss = 1.932757, validation loss = 2.231232
2018-12-05 09:13:19,291 - INFO - epoch 2, step 8150, training loss = 2.134282, validation loss = 2.909802
2018-12-05 09:13:23,430 - INFO - epoch 2, step 8160, training loss = 2.001706, validation loss = 2.984740
2018-12-05 09:13:27,582 - INFO - epoch 2, step 8170, training loss = 2.162137, validation loss = 2.585944
2018-12-05 09:13:31,885 - INFO - epoch 2, step 8180, training loss = 1.924887, validation loss = 2.740224
2018-12-05 09:13:36,184 - INFO - epoch 2, step 8190, training loss = 2.116982, validation loss = 2.508794
2018-12-05 09:13:40,455 - INFO - epoch 2, step 8200, training loss = 2.268790, validation loss = 2.949473
2018-12-05 09:13:44,556 - INFO - epoch 2, step 8210, training loss = 1.980498, validation loss = 2.944551
2018-12-05 09:13:48,762 - INFO - epoch 2, step 8220, training loss = 1.821186, validation loss = 3.070044
2018-12-05 09:13:52,984 - INFO - epoch 2, step 8230, training loss = 1.764822, validation loss = 2.540919
2018-12-05 09:13:57,021 - INFO - epoch 2, step 8240, training loss = 2.011422, validation loss = 3.330842
2018-12-05 09:14:00,999 - INFO - epoch 2, step 8250, training loss = 2.165117, validation loss = 2.356895
2018-12-05 09:14:04,677 - INFO - epoch 2, step 8260, training loss = 1.992584, validation loss = 3.113201
2018-12-05 09:14:08,600 - INFO - epoch 2, step 8270, training loss = 1.872236, validation loss = 2.227144
2018-12-05 09:14:12,476 - INFO - epoch 2, step 8280, training loss = 1.993432, validation loss = 2.807899
2018-12-05 09:14:16,215 - INFO - epoch 2, step 8290, training loss = 1.848013, validation loss = 2.499802
2018-12-05 09:14:19,877 - INFO - epoch 2, step 8300, training loss = 2.099663, validation loss = 2.319734
2018-12-05 09:14:23,358 - INFO - epoch 2, step 8310, training loss = 2.094628, validation loss = 2.625497
2018-12-05 09:14:26,810 - INFO - epoch 2, step 8320, training loss = 1.962162, validation loss = 2.722920
2018-12-05 09:14:30,253 - INFO - epoch 2, step 8330, training loss = 2.681066, validation loss = 2.956616
2018-12-05 09:14:33,747 - INFO - epoch 2, step 8340, training loss = 1.924011, validation loss = 2.724675
2018-12-05 09:14:37,208 - INFO - epoch 2, step 8350, training loss = 1.900611, validation loss = 2.691559
2018-12-05 09:14:40,563 - INFO - epoch 2, step 8360, training loss = 1.913795, validation loss = 2.375100
2018-12-05 09:14:43,787 - INFO - epoch 2, step 8370, training loss = 1.991873, validation loss = 2.847592
2018-12-05 09:14:47,256 - INFO - epoch 2, step 8380, training loss = 2.106812, validation loss = 3.026293
2018-12-05 09:14:50,680 - INFO - epoch 2, step 8390, training loss = 1.677255, validation loss = 2.520544
2018-12-05 09:14:54,147 - INFO - epoch 2, step 8400, training loss = 2.093261, validation loss = 2.295147
2018-12-05 09:14:57,551 - INFO - epoch 2, step 8410, training loss = 1.446564, validation loss = 2.770863
2018-12-05 09:15:01,422 - INFO - epoch 2, step 8420, training loss = 2.198267, validation loss = 2.930294
2018-12-05 09:15:05,642 - INFO - epoch 2, step 8430, training loss = 2.073884, validation loss = 2.729667
2018-12-05 09:15:09,859 - INFO - epoch 2, step 8440, training loss = 1.235542, validation loss = 1.837464
2018-12-05 09:15:13,841 - INFO - epoch 2, step 8450, training loss = 1.836907, validation loss = 2.180113
2018-12-05 09:15:18,005 - INFO - epoch 2, step 8460, training loss = 1.968932, validation loss = 2.219675
2018-12-05 09:15:22,024 - INFO - epoch 2, step 8470, training loss = 1.896813, validation loss = 2.649087
2018-12-05 09:15:26,076 - INFO - epoch 2, step 8480, training loss = 1.989674, validation loss = 2.033116
2018-12-05 09:15:30,091 - INFO - epoch 2, step 8490, training loss = 2.298613, validation loss = 2.715829
2018-12-05 09:15:34,143 - INFO - epoch 2, step 8500, training loss = 1.779039, validation loss = 2.469332
2018-12-05 09:15:38,268 - INFO - epoch 2, step 8510, training loss = 2.190611, validation loss = 2.126449
2018-12-05 09:15:42,324 - INFO - epoch 2, step 8520, training loss = 2.133132, validation loss = 2.587273
2018-12-05 09:15:45,480 - INFO - epoch 2, step 8530, training loss = 1.783857, validation loss = 3.435271
2018-12-05 09:15:48,731 - INFO - epoch 2, step 8540, training loss = 1.812581, validation loss = 2.475816
2018-12-05 09:15:52,239 - INFO - epoch 2, step 8550, training loss = 2.132382, validation loss = 2.607793
2018-12-05 09:15:55,754 - INFO - epoch 2, step 8560, training loss = 2.264865, validation loss = 2.547691
2018-12-05 09:15:59,320 - INFO - epoch 2, step 8570, training loss = 1.995200, validation loss = 2.328427
2018-12-05 09:16:02,816 - INFO - epoch 2, step 8580, training loss = 2.375957, validation loss = 2.237339
2018-12-05 09:16:06,479 - INFO - epoch 2, step 8590, training loss = 1.787829, validation loss = 1.818021
2018-12-05 09:16:09,958 - INFO - epoch 2, step 8600, training loss = 1.691864, validation loss = 2.174918
2018-12-05 09:16:13,470 - INFO - epoch 2, step 8610, training loss = 1.429596, validation loss = 2.625686
2018-12-05 09:16:17,007 - INFO - epoch 2, step 8620, training loss = 1.645011, validation loss = 2.592755
2018-12-05 09:16:20,635 - INFO - epoch 2, step 8630, training loss = 2.028881, validation loss = 2.529108
2018-12-05 09:16:24,017 - INFO - epoch 2, step 8640, training loss = 1.709391, validation loss = 2.554357
2018-12-05 09:16:27,353 - INFO - epoch 2, step 8650, training loss = 1.907859, validation loss = 2.805598
2018-12-05 09:16:30,865 - INFO - epoch 2, step 8660, training loss = 2.241623, validation loss = 2.810342
2018-12-05 09:16:34,563 - INFO - epoch 2, step 8670, training loss = 1.826945, validation loss = 2.636895
2018-12-05 09:16:38,119 - INFO - epoch 2, step 8680, training loss = 2.023994, validation loss = 2.808404
2018-12-05 09:16:41,671 - INFO - epoch 2, step 8690, training loss = 2.454560, validation loss = 2.776261
2018-12-05 09:16:45,432 - INFO - epoch 2, step 8700, training loss = 2.140806, validation loss = 2.538847
2018-12-05 09:16:49,364 - INFO - epoch 2, step 8710, training loss = 1.842819, validation loss = 2.578528
2018-12-05 09:16:53,220 - INFO - epoch 2, step 8720, training loss = 1.999533, validation loss = 1.941815
2018-12-05 09:16:56,794 - INFO - epoch 2, step 8730, training loss = 1.876106, validation loss = 2.803640
2018-12-05 09:17:00,434 - INFO - epoch 2, step 8740, training loss = 2.163015, validation loss = 2.432426
2018-12-05 09:17:04,138 - INFO - epoch 2, step 8750, training loss = 2.160999, validation loss = 2.192756
2018-12-05 09:17:08,609 - INFO - epoch 2, step 8760, training loss = 2.023717, validation loss = 2.594566
2018-12-05 09:17:12,118 - INFO - epoch 2, step 8770, training loss = 1.785127, validation loss = 2.457153
2018-12-05 09:17:15,425 - INFO - epoch 2, step 8780, training loss = 1.794473, validation loss = 2.932047
2018-12-05 09:17:18,859 - INFO - epoch 2, step 8790, training loss = 2.332457, validation loss = 2.164668
2018-12-05 09:17:22,107 - INFO - epoch 2, step 8800, training loss = 1.790786, validation loss = 2.457714
2018-12-05 09:17:25,613 - INFO - epoch 2, step 8810, training loss = 1.982057, validation loss = 2.550246
2018-12-05 09:17:29,214 - INFO - epoch 2, step 8820, training loss = 2.190732, validation loss = 2.691354
2018-12-05 09:17:32,624 - INFO - epoch 2, step 8830, training loss = 1.727276, validation loss = 2.602718
2018-12-05 09:17:36,150 - INFO - epoch 2, step 8840, training loss = 2.157178, validation loss = 2.050198
2018-12-05 09:17:39,589 - INFO - epoch 2, step 8850, training loss = 1.803102, validation loss = 2.817140
2018-12-05 09:17:42,992 - INFO - epoch 2, step 8860, training loss = 1.874818, validation loss = 2.565585
2018-12-05 09:17:46,529 - INFO - epoch 2, step 8870, training loss = 2.154261, validation loss = 2.537789
2018-12-05 09:17:50,143 - INFO - epoch 2, step 8880, training loss = 1.832730, validation loss = 2.046595
2018-12-05 09:17:53,832 - INFO - epoch 2, step 8890, training loss = 2.148163, validation loss = 2.125535
2018-12-05 09:17:57,729 - INFO - epoch 2, step 8900, training loss = 1.641855, validation loss = 2.158646
2018-12-05 09:18:01,651 - INFO - epoch 2, step 8910, training loss = 1.991069, validation loss = 2.561739
2018-12-05 09:18:05,166 - INFO - epoch 2, step 8920, training loss = 2.258598, validation loss = 2.836786
2018-12-05 09:18:08,725 - INFO - epoch 2, step 8930, training loss = 2.043784, validation loss = 2.430731
2018-12-05 09:18:12,421 - INFO - epoch 2, step 8940, training loss = 2.204036, validation loss = 2.564432
2018-12-05 09:18:16,073 - INFO - epoch 2, step 8950, training loss = 2.110681, validation loss = 3.302072
2018-12-05 09:18:19,954 - INFO - epoch 2, step 8960, training loss = 2.209288, validation loss = 1.656016
2018-12-05 09:18:23,363 - INFO - epoch 2, step 8970, training loss = 2.371286, validation loss = 2.771887
2018-12-05 09:18:26,624 - INFO - epoch 2, step 8980, training loss = 1.932858, validation loss = 2.457359
2018-12-05 09:18:30,040 - INFO - epoch 2, step 8990, training loss = 2.121406, validation loss = 2.603297
2018-12-05 09:18:33,325 - INFO - epoch 2, step 9000, training loss = 1.887857, validation loss = 2.798804
2018-12-05 09:18:36,800 - INFO - epoch 2, step 9010, training loss = 2.146579, validation loss = 2.412840
2018-12-05 09:18:40,168 - INFO - epoch 2, step 9020, training loss = 2.090541, validation loss = 3.036625
2018-12-05 09:18:43,573 - INFO - epoch 2, step 9030, training loss = 2.481029, validation loss = 2.833411
2018-12-05 09:18:47,229 - INFO - epoch 2, step 9040, training loss = 2.123351, validation loss = 3.420202
2018-12-05 09:18:50,641 - INFO - epoch 2, step 9050, training loss = 2.298213, validation loss = 3.078304
2018-12-05 09:18:54,117 - INFO - epoch 2, step 9060, training loss = 2.535878, validation loss = 2.779092
2018-12-05 09:18:57,491 - INFO - epoch 2, step 9070, training loss = 1.811326, validation loss = 2.553032
2018-12-05 09:19:00,884 - INFO - epoch 2, step 9080, training loss = 2.114547, validation loss = 2.587059
2018-12-05 09:19:04,818 - INFO - epoch 2, step 9090, training loss = 1.956292, validation loss = 3.568698
2018-12-05 09:19:08,901 - INFO - epoch 2, step 9100, training loss = 1.732629, validation loss = 2.800570
2018-12-05 09:19:13,143 - INFO - epoch 2, step 9110, training loss = 1.760860, validation loss = 2.285699
2018-12-05 09:19:17,430 - INFO - epoch 2, step 9120, training loss = 1.722789, validation loss = 2.552222
2018-12-05 09:19:21,021 - INFO - epoch 2, step 9130, training loss = 1.899419, validation loss = 2.799704
2018-12-05 09:19:24,405 - INFO - epoch 2, step 9140, training loss = 1.721583, validation loss = 2.818646
2018-12-05 09:19:27,898 - INFO - epoch 2, step 9150, training loss = 1.812438, validation loss = 3.233874
2018-12-05 09:19:31,195 - INFO - epoch 2, step 9160, training loss = 1.912754, validation loss = 3.101071
2018-12-05 09:19:34,329 - INFO - epoch 2, step 9170, training loss = 2.052180, validation loss = 3.219677
2018-12-05 09:19:37,399 - INFO - epoch 2, step 9180, training loss = 1.790037, validation loss = 2.904552
2018-12-05 09:19:40,954 - INFO - epoch 2, step 9190, training loss = 2.014112, validation loss = 2.825362
2018-12-05 09:19:44,223 - INFO - epoch 2, step 9200, training loss = 1.484581, validation loss = 2.453206
2018-12-05 09:19:47,650 - INFO - epoch 2, step 9210, training loss = 2.027010, validation loss = 2.787714
2018-12-05 09:19:50,914 - INFO - epoch 2, step 9220, training loss = 1.734177, validation loss = 2.926491
2018-12-05 09:19:54,138 - INFO - epoch 2, step 9230, training loss = 1.737821, validation loss = 2.945721
2018-12-05 09:19:57,542 - INFO - epoch 2, step 9240, training loss = 2.192943, validation loss = 3.517525
2018-12-05 09:20:00,828 - INFO - epoch 2, step 9250, training loss = 1.519128, validation loss = 2.940429
2018-12-05 09:20:04,319 - INFO - epoch 2, step 9260, training loss = 1.955534, validation loss = 2.681187
2018-12-05 09:20:07,915 - INFO - epoch 2, step 9270, training loss = 2.349330, validation loss = 2.702029
2018-12-05 09:20:11,605 - INFO - epoch 2, step 9280, training loss = 1.622516, validation loss = 2.716541
2018-12-05 09:20:15,019 - INFO - epoch 2, step 9290, training loss = 1.737903, validation loss = 2.712265
2018-12-05 09:20:18,533 - INFO - epoch 2, step 9300, training loss = 1.718003, validation loss = 2.393373
2018-12-05 09:20:21,927 - INFO - epoch 2, step 9310, training loss = 2.275075, validation loss = 2.682247
2018-12-05 09:20:25,386 - INFO - epoch 2, step 9320, training loss = 2.021986, validation loss = 3.163845
2018-12-05 09:20:28,992 - INFO - epoch 2, step 9330, training loss = 1.688827, validation loss = 2.865744
2018-12-05 09:20:32,803 - INFO - epoch 2, step 9340, training loss = 2.064876, validation loss = 3.668191
2018-12-05 09:20:36,506 - INFO - epoch 2, step 9350, training loss = 1.902871, validation loss = 2.285922
2018-12-05 09:20:40,254 - INFO - epoch 2, step 9360, training loss = 1.517752, validation loss = 2.476928
2018-12-05 09:20:43,991 - INFO - epoch 2, step 9370, training loss = 1.935510, validation loss = 2.487467
2018-12-05 09:20:48,210 - INFO - epoch 2, step 9380, training loss = 1.894329, validation loss = 2.955029
2018-12-05 09:20:52,406 - INFO - epoch 2, step 9390, training loss = 1.980583, validation loss = 2.646518
2018-12-05 09:20:56,430 - INFO - epoch 2, step 9400, training loss = 1.959669, validation loss = 3.635572
2018-12-05 09:21:00,548 - INFO - epoch 2, step 9410, training loss = 1.911427, validation loss = 3.366587
2018-12-05 09:21:04,540 - INFO - epoch 2, step 9420, training loss = 1.601217, validation loss = 2.995711
2018-12-05 09:21:08,622 - INFO - epoch 2, step 9430, training loss = 1.817077, validation loss = 2.750287
2018-12-05 09:21:12,960 - INFO - epoch 2, step 9440, training loss = 1.967053, validation loss = 2.561815
2018-12-05 09:21:16,904 - INFO - epoch 2, step 9450, training loss = 2.197897, validation loss = 3.169986
2018-12-05 09:21:20,984 - INFO - epoch 2, step 9460, training loss = 1.823794, validation loss = 2.929454
2018-12-05 09:21:25,280 - INFO - epoch 2, step 9470, training loss = 1.680140, validation loss = 2.513695
2018-12-05 09:21:28,889 - INFO - epoch 2, step 9480, training loss = 1.967979, validation loss = 2.746064
2018-12-05 09:21:32,323 - INFO - epoch 2, step 9490, training loss = 2.055175, validation loss = 2.974200
2018-12-05 09:21:35,858 - INFO - epoch 2, step 9500, training loss = 1.240556, validation loss = 2.593608
2018-12-05 09:21:39,250 - INFO - epoch 2, step 9510, training loss = 1.797426, validation loss = 2.548112
2018-12-05 09:21:42,611 - INFO - epoch 2, step 9520, training loss = 1.892678, validation loss = 2.690491
2018-12-05 09:21:45,853 - INFO - epoch 2, step 9530, training loss = 1.979797, validation loss = 2.851774
2018-12-05 09:21:49,167 - INFO - epoch 2, step 9540, training loss = 1.964918, validation loss = 2.924724
2018-12-05 09:21:52,568 - INFO - epoch 2, step 9550, training loss = 1.742171, validation loss = 2.868186
2018-12-05 09:21:56,059 - INFO - epoch 2, step 9560, training loss = 1.734365, validation loss = 3.348849
2018-12-05 09:21:59,435 - INFO - epoch 2, step 9570, training loss = 1.750801, validation loss = 2.795611
2018-12-05 09:22:02,582 - INFO - epoch 2, step 9580, training loss = 1.572535, validation loss = 2.312998
2018-12-05 09:22:05,925 - INFO - epoch 2, step 9590, training loss = 1.665167, validation loss = 2.334760
2018-12-05 09:22:09,502 - INFO - epoch 2, step 9600, training loss = 1.585531, validation loss = 2.532690
2018-12-05 09:22:13,018 - INFO - epoch 2, step 9610, training loss = 1.757960, validation loss = 2.935610
2018-12-05 09:22:16,571 - INFO - epoch 2, step 9620, training loss = 2.215515, validation loss = 2.845439
2018-12-05 09:22:20,211 - INFO - epoch 2, step 9630, training loss = 1.756451, validation loss = 2.942245
2018-12-05 09:22:23,838 - INFO - epoch 2, step 9640, training loss = 1.332136, validation loss = 2.807803
2018-12-05 09:22:27,480 - INFO - epoch 2, step 9650, training loss = 1.340166, validation loss = 2.623398
2018-12-05 09:22:31,062 - INFO - epoch 2, step 9660, training loss = 2.234798, validation loss = 2.429594
2018-12-05 09:22:34,648 - INFO - epoch 2, step 9670, training loss = 2.015522, validation loss = 2.789288
2018-12-05 09:22:38,278 - INFO - epoch 2, step 9680, training loss = 1.921767, validation loss = 2.966983
2018-12-05 09:22:41,782 - INFO - epoch 2, step 9690, training loss = 2.165292, validation loss = 2.808583
2018-12-05 09:22:45,403 - INFO - epoch 2, step 9700, training loss = 1.862411, validation loss = 3.164007
2018-12-05 09:22:49,829 - INFO - epoch 2, step 9710, training loss = 1.933094, validation loss = 2.622645
2018-12-05 09:22:54,282 - INFO - epoch 2, step 9720, training loss = 1.876688, validation loss = 2.478863
2018-12-05 09:22:58,459 - INFO - epoch 2, step 9730, training loss = 2.020098, validation loss = 3.088288
2018-12-05 09:23:02,798 - INFO - epoch 2, step 9740, training loss = 2.131114, validation loss = 2.923440
2018-12-05 09:23:07,034 - INFO - epoch 2, step 9750, training loss = 1.888522, validation loss = 2.974288
2018-12-05 09:23:11,110 - INFO - epoch 2, step 9760, training loss = 1.932459, validation loss = 3.209311
2018-12-05 09:23:15,262 - INFO - epoch 2, step 9770, training loss = 2.384649, validation loss = 3.088517
2018-12-05 09:23:19,887 - INFO - epoch 2, step 9780, training loss = 2.276131, validation loss = 2.822394
2018-12-05 09:23:24,169 - INFO - epoch 2, step 9790, training loss = 1.822078, validation loss = 3.025592
2018-12-05 09:23:28,632 - INFO - epoch 2, step 9800, training loss = 1.672284, validation loss = 3.315937
2018-12-05 09:23:32,916 - INFO - epoch 2, step 9810, training loss = 1.949545, validation loss = 3.685562
2018-12-05 09:23:37,269 - INFO - epoch 2, step 9820, training loss = 1.969009, validation loss = 2.966653
2018-12-05 09:23:41,382 - INFO - epoch 2, step 9830, training loss = 2.231922, validation loss = 2.384812
2018-12-05 09:23:45,172 - INFO - epoch 2, step 9840, training loss = 1.871911, validation loss = 2.715569
2018-12-05 09:23:48,983 - INFO - epoch 2, step 9850, training loss = 1.830776, validation loss = 3.014187
2018-12-05 09:23:52,491 - INFO - epoch 2, step 9860, training loss = 1.446847, validation loss = 2.811619
2018-12-05 09:23:55,936 - INFO - epoch 2, step 9870, training loss = 2.122371, validation loss = 3.504035
2018-12-05 09:23:59,376 - INFO - epoch 2, step 9880, training loss = 1.660234, validation loss = 3.505352
2018-12-05 09:24:02,891 - INFO - epoch 2, step 9890, training loss = 1.597528, validation loss = 3.005356
2018-12-05 09:24:06,446 - INFO - epoch 2, step 9900, training loss = 1.537975, validation loss = 2.682462
2018-12-05 09:24:10,009 - INFO - epoch 2, step 9910, training loss = 1.744793, validation loss = 2.821322
2018-12-05 09:24:13,480 - INFO - epoch 2, step 9920, training loss = 1.806822, validation loss = 2.691018
2018-12-05 09:24:17,325 - INFO - epoch 2, step 9930, training loss = 1.749636, validation loss = 3.110424
2018-12-05 09:24:20,764 - INFO - epoch 2, step 9940, training loss = 2.081270, validation loss = 3.045300
2018-12-05 09:24:24,452 - INFO - epoch 2, step 9950, training loss = 1.926504, validation loss = 2.890852
2018-12-05 09:24:27,842 - INFO - epoch 2, step 9960, training loss = 2.029425, validation loss = 3.201980
2018-12-05 09:24:31,604 - INFO - epoch 2, step 9970, training loss = 1.582312, validation loss = 3.125093
2018-12-05 09:24:35,178 - INFO - epoch 2, step 9980, training loss = 1.916089, validation loss = 2.220558
2018-12-05 09:24:38,845 - INFO - epoch 2, step 9990, training loss = 1.778343, validation loss = 2.385245
2018-12-05 09:24:42,442 - INFO - epoch 2, step 10000, training loss = 2.259795, validation loss = 2.699970
2018-12-05 09:24:46,167 - INFO - epoch 2, step 10010, training loss = 1.572829, validation loss = 2.832981
2018-12-05 09:24:49,649 - INFO - epoch 2, step 10020, training loss = 1.507700, validation loss = 3.091244
2018-12-05 09:24:53,024 - INFO - epoch 2, step 10030, training loss = 2.100820, validation loss = 3.088489
2018-12-05 09:24:56,525 - INFO - epoch 2, step 10040, training loss = 1.893651, validation loss = 3.326082
2018-12-05 09:24:59,876 - INFO - epoch 2, step 10050, training loss = 1.958278, validation loss = 2.799517
2018-12-05 09:25:03,316 - INFO - epoch 2, step 10060, training loss = 2.152275, validation loss = 2.929815
2018-12-05 09:25:06,738 - INFO - epoch 2, step 10070, training loss = 1.969797, validation loss = 3.157546
2018-12-05 09:25:10,044 - INFO - epoch 2, step 10080, training loss = 2.131573, validation loss = 3.121195
2018-12-05 09:25:13,613 - INFO - epoch 2, step 10090, training loss = 2.276570, validation loss = 2.993121
2018-12-05 09:25:16,849 - INFO - epoch 2, step 10100, training loss = 2.148064, validation loss = 3.113415
2018-12-05 09:25:20,308 - INFO - epoch 2, step 10110, training loss = 2.084934, validation loss = 3.315870
2018-12-05 09:25:23,653 - INFO - epoch 2, step 10120, training loss = 1.956675, validation loss = 2.393663
2018-12-05 09:25:27,019 - INFO - epoch 2, step 10130, training loss = 1.989449, validation loss = 2.583600
2018-12-05 09:25:30,368 - INFO - epoch 2, step 10140, training loss = 1.843326, validation loss = 2.275528
2018-12-05 09:25:33,736 - INFO - epoch 2, step 10150, training loss = 1.957496, validation loss = 2.683726
2018-12-05 09:25:37,427 - INFO - epoch 2, step 10160, training loss = 2.215091, validation loss = 3.008609
2018-12-05 09:25:41,100 - INFO - epoch 2, step 10170, training loss = 1.979840, validation loss = 2.871731
2018-12-05 09:25:44,738 - INFO - epoch 2, step 10180, training loss = 2.078753, validation loss = 2.911571
2018-12-05 09:25:48,548 - INFO - epoch 2, step 10190, training loss = 2.048674, validation loss = 3.141453
2018-12-05 09:25:52,324 - INFO - epoch 2, step 10200, training loss = 2.082802, validation loss = 2.260793
2018-12-05 09:25:55,968 - INFO - epoch 2, step 10210, training loss = 1.892746, validation loss = 2.200101
2018-12-05 09:25:59,717 - INFO - epoch 2, step 10220, training loss = 2.201191, validation loss = 2.724025
2018-12-05 09:26:03,495 - INFO - epoch 2, step 10230, training loss = 1.774930, validation loss = 2.565654
2018-12-05 09:26:06,958 - INFO - epoch 2, step 10240, training loss = 1.836256, validation loss = 2.240799
2018-12-05 09:26:10,446 - INFO - epoch 2, step 10250, training loss = 2.121671, validation loss = 3.100419
2018-12-05 09:26:13,872 - INFO - epoch 2, step 10260, training loss = 2.161897, validation loss = 2.965050
2018-12-05 09:26:17,490 - INFO - epoch 2, step 10270, training loss = 1.779481, validation loss = 2.273930
2018-12-05 09:26:21,015 - INFO - epoch 2, step 10280, training loss = 1.897889, validation loss = 2.238856
2018-12-05 09:26:24,562 - INFO - epoch 2, step 10290, training loss = 2.094071, validation loss = 1.913055
2018-12-05 09:26:28,045 - INFO - epoch 2, step 10300, training loss = 1.919882, validation loss = 1.720311
2018-12-05 09:26:31,426 - INFO - epoch 2, step 10310, training loss = 2.105798, validation loss = 2.524675
2018-12-05 09:26:35,044 - INFO - epoch 2, step 10320, training loss = 1.992272, validation loss = 2.196170
2018-12-05 09:26:38,657 - INFO - epoch 2, step 10330, training loss = 2.191621, validation loss = 2.015562
2018-12-05 09:26:42,776 - INFO - epoch 2, step 10340, training loss = 2.058782, validation loss = 2.448174
2018-12-05 09:26:47,115 - INFO - epoch 2, step 10350, training loss = 2.150687, validation loss = 2.232353
2018-12-05 09:26:51,434 - INFO - epoch 2, step 10360, training loss = 1.926150, validation loss = 2.448097
2018-12-05 09:26:55,803 - INFO - epoch 2, step 10370, training loss = 2.367034, validation loss = 2.572608
2018-12-05 09:26:59,952 - INFO - epoch 2, step 10380, training loss = 2.215515, validation loss = 2.101057
2018-12-05 09:27:04,131 - INFO - epoch 2, step 10390, training loss = 2.132519, validation loss = 2.131953
2018-12-05 09:27:08,271 - INFO - epoch 2, step 10400, training loss = 2.388457, validation loss = 1.983156
2018-12-05 09:27:13,204 - INFO - epoch 2, step 10410, training loss = 1.890386, validation loss = 2.113904
2018-12-05 09:27:18,099 - INFO - epoch 2, step 10420, training loss = 2.149341, validation loss = 2.964348
2018-12-05 09:27:22,450 - INFO - epoch 2, step 10430, training loss = 1.715483, validation loss = 2.437917
2018-12-05 09:27:26,373 - INFO - epoch 2, step 10440, training loss = 1.919760, validation loss = 2.612825
2018-12-05 09:27:30,608 - INFO - epoch 2, step 10450, training loss = 1.922736, validation loss = 2.559158
2018-12-05 09:27:34,830 - INFO - epoch 2, step 10460, training loss = 2.044181, validation loss = 1.968975
2018-12-05 09:27:39,067 - INFO - epoch 2, step 10470, training loss = 1.915566, validation loss = 1.899273
2018-12-05 09:27:43,168 - INFO - epoch 2, step 10480, training loss = 2.110405, validation loss = 2.376139
2018-12-05 09:27:47,370 - INFO - epoch 2, step 10490, training loss = 1.740446, validation loss = 2.336408
2018-12-05 09:27:51,814 - INFO - epoch 2, step 10500, training loss = 1.882718, validation loss = 2.104995
2018-12-05 09:27:55,999 - INFO - epoch 2, step 10510, training loss = 2.144665, validation loss = 2.229345
2018-12-05 09:28:00,111 - INFO - epoch 2, step 10520, training loss = 2.224855, validation loss = 2.698599
2018-12-05 09:28:04,090 - INFO - epoch 2, step 10530, training loss = 1.778899, validation loss = 2.117042
2018-12-05 09:28:08,074 - INFO - epoch 2, step 10540, training loss = 1.990579, validation loss = 2.181238
2018-12-05 09:28:12,192 - INFO - epoch 2, step 10550, training loss = 1.917624, validation loss = 1.914343
2018-12-05 09:28:16,039 - INFO - epoch 2, step 10560, training loss = 1.804552, validation loss = 2.713011
2018-12-05 09:28:19,963 - INFO - epoch 2, step 10570, training loss = 2.061750, validation loss = 2.094069
2018-12-05 09:28:23,890 - INFO - epoch 2, step 10580, training loss = 1.851375, validation loss = 2.609208
2018-12-05 09:28:27,835 - INFO - epoch 2, step 10590, training loss = 2.208830, validation loss = 2.372869
2018-12-05 09:28:31,632 - INFO - epoch 2, step 10600, training loss = 1.760774, validation loss = 2.018470
2018-12-05 09:28:35,484 - INFO - epoch 2, step 10610, training loss = 2.094212, validation loss = 2.229092
2018-12-05 09:28:39,237 - INFO - epoch 2, step 10620, training loss = 1.595818, validation loss = 2.532697
2018-12-05 09:28:42,974 - INFO - epoch 2, step 10630, training loss = 1.694800, validation loss = 2.684085
2018-12-05 09:28:46,744 - INFO - epoch 2, step 10640, training loss = 1.962020, validation loss = 2.479962
2018-12-05 09:28:50,598 - INFO - epoch 2, step 10650, training loss = 2.006228, validation loss = 2.002042
2018-12-05 09:28:54,401 - INFO - epoch 2, step 10660, training loss = 1.778329, validation loss = 2.152246
2018-12-05 09:28:58,348 - INFO - epoch 2, step 10670, training loss = 1.752677, validation loss = 2.277085
2018-12-05 09:29:02,115 - INFO - epoch 2, step 10680, training loss = 1.563975, validation loss = 2.572095
2018-12-05 09:29:06,063 - INFO - epoch 2, step 10690, training loss = 1.902144, validation loss = 2.590000
2018-12-05 09:29:09,631 - INFO - epoch 2, step 10700, training loss = 2.645810, validation loss = 2.625838
2018-12-05 09:29:13,597 - INFO - epoch 2, step 10710, training loss = 2.202808, validation loss = 2.553816
2018-12-05 09:29:17,315 - INFO - epoch 2, step 10720, training loss = 1.904911, validation loss = 2.146810
2018-12-05 09:29:21,296 - INFO - epoch 2, step 10730, training loss = 2.109710, validation loss = 2.568005
2018-12-05 09:29:25,076 - INFO - epoch 2, step 10740, training loss = 1.559755, validation loss = 2.871949
2018-12-05 09:29:29,021 - INFO - epoch 2, step 10750, training loss = 1.706634, validation loss = 2.632698
2018-12-05 09:29:32,665 - INFO - epoch 2, step 10760, training loss = 2.098248, validation loss = 2.741262
2018-12-05 09:29:36,636 - INFO - epoch 2, step 10770, training loss = 2.146642, validation loss = 2.392836
2018-12-05 09:29:40,422 - INFO - epoch 2, step 10780, training loss = 1.734435, validation loss = 2.576660
2018-12-05 09:29:44,327 - INFO - epoch 2, step 10790, training loss = 2.013009, validation loss = 1.988364
2018-12-05 09:29:48,148 - INFO - epoch 2, step 10800, training loss = 2.078556, validation loss = 2.129401
2018-12-05 09:29:52,140 - INFO - epoch 2, step 10810, training loss = 1.971275, validation loss = 2.232868
2018-12-05 09:29:55,863 - INFO - epoch 2, step 10820, training loss = 2.147602, validation loss = 2.443242
2018-12-05 09:29:59,481 - INFO - epoch 2, step 10830, training loss = 1.979411, validation loss = 2.341218
2018-12-05 09:30:03,291 - INFO - epoch 2, step 10840, training loss = 2.213852, validation loss = 2.579557
2018-12-05 09:30:07,138 - INFO - epoch 2, step 10850, training loss = 1.958755, validation loss = 2.489075
2018-12-05 09:30:11,205 - INFO - epoch 2, step 10860, training loss = 1.887163, validation loss = 2.326287
2018-12-05 09:30:14,812 - INFO - epoch 2, step 10870, training loss = 1.408444, validation loss = 2.479023
2018-12-05 09:30:18,650 - INFO - epoch 2, step 10880, training loss = 1.934701, validation loss = 1.897942
2018-12-05 09:30:22,104 - INFO - epoch 2, step 10890, training loss = 1.820513, validation loss = 2.522976
2018-12-05 09:30:25,784 - INFO - epoch 2, step 10900, training loss = 1.940565, validation loss = 2.557217
2018-12-05 09:30:29,370 - INFO - epoch 2, step 10910, training loss = 1.856781, validation loss = 2.700834
2018-12-05 09:30:32,728 - INFO - epoch 2, step 10920, training loss = 1.312805, validation loss = 2.195162
2018-12-05 09:30:36,054 - INFO - epoch 2, step 10930, training loss = 2.159674, validation loss = 2.689708
2018-12-05 09:30:39,535 - INFO - epoch 2, step 10940, training loss = 2.408873, validation loss = 2.659674
2018-12-05 09:30:43,114 - INFO - epoch 2, step 10950, training loss = 1.767509, validation loss = 3.290815
2018-12-05 09:30:46,806 - INFO - epoch 2, step 10960, training loss = 1.922907, validation loss = 1.816654
2018-12-05 09:30:50,333 - INFO - epoch 2, step 10970, training loss = 2.010556, validation loss = 2.439565
2018-12-05 09:30:53,718 - INFO - epoch 2, step 10980, training loss = 2.150719, validation loss = 2.224125
2018-12-05 09:30:57,325 - INFO - epoch 2, step 10990, training loss = 1.724210, validation loss = 2.086372
2018-12-05 09:31:00,612 - INFO - epoch 2, step 11000, training loss = 2.368981, validation loss = 2.800821
2018-12-05 09:31:03,964 - INFO - epoch 2, step 11010, training loss = 2.018806, validation loss = 2.525116
2018-12-05 09:31:07,207 - INFO - epoch 2, step 11020, training loss = 2.194408, validation loss = 2.788652
2018-12-05 09:31:10,787 - INFO - epoch 2, step 11030, training loss = 2.004735, validation loss = 3.045863
2018-12-05 09:31:14,699 - INFO - epoch 2, step 11040, training loss = 2.006226, validation loss = 2.246397
2018-12-05 09:31:18,833 - INFO - epoch 2, step 11050, training loss = 1.852832, validation loss = 2.159142
2018-12-05 09:31:22,770 - INFO - epoch 2, step 11060, training loss = 1.984622, validation loss = 2.480290
2018-12-05 09:31:26,853 - INFO - epoch 2, step 11070, training loss = 1.978808, validation loss = 2.407766
2018-12-05 09:31:30,719 - INFO - epoch 2, step 11080, training loss = 1.906558, validation loss = 2.463688
2018-12-05 09:31:34,988 - INFO - epoch 2, step 11090, training loss = 1.826752, validation loss = 2.279083
2018-12-05 09:31:39,014 - INFO - epoch 2, step 11100, training loss = 1.987982, validation loss = 2.700445
2018-12-05 09:31:42,997 - INFO - epoch 2, step 11110, training loss = 2.010058, validation loss = 2.871476
2018-12-05 09:31:47,053 - INFO - epoch 2, step 11120, training loss = 1.891005, validation loss = 2.075198
2018-12-05 09:31:50,755 - INFO - epoch 2, step 11130, training loss = 2.030524, validation loss = 2.353562
2018-12-05 09:31:54,278 - INFO - epoch 2, step 11140, training loss = 1.758650, validation loss = 2.263188
2018-12-05 09:31:57,899 - INFO - epoch 2, step 11150, training loss = 1.449063, validation loss = 2.245869
2018-12-05 09:32:01,556 - INFO - epoch 2, step 11160, training loss = 1.571721, validation loss = 2.730203
2018-12-05 09:32:05,455 - INFO - epoch 2, step 11170, training loss = 1.488748, validation loss = 2.865946
2018-12-05 09:32:09,106 - INFO - epoch 2, step 11180, training loss = 1.649715, validation loss = 2.379982
2018-12-05 09:32:12,890 - INFO - epoch 2, step 11190, training loss = 1.587939, validation loss = 2.240248
2018-12-05 09:32:16,549 - INFO - epoch 2, step 11200, training loss = 2.349001, validation loss = 2.590157
2018-12-05 09:32:20,130 - INFO - epoch 2, step 11210, training loss = 2.162613, validation loss = 2.499201
2018-12-05 09:32:23,799 - INFO - epoch 2, step 11220, training loss = 1.746388, validation loss = 2.228912
2018-12-05 09:32:27,476 - INFO - epoch 2, step 11230, training loss = 2.002940, validation loss = 2.871914
2018-12-05 09:32:31,216 - INFO - epoch 2, step 11240, training loss = 1.871290, validation loss = 2.929366
2018-12-05 09:32:34,875 - INFO - epoch 2, step 11250, training loss = 1.794928, validation loss = 2.733810
2018-12-05 09:32:38,350 - INFO - epoch 2, step 11260, training loss = 2.051422, validation loss = 2.258913
2018-12-05 09:32:41,763 - INFO - epoch 2, step 11270, training loss = 1.853791, validation loss = 2.475873
2018-12-05 09:32:45,251 - INFO - epoch 2, step 11280, training loss = 1.799268, validation loss = 2.163257
2018-12-05 09:32:48,726 - INFO - epoch 2, step 11290, training loss = 1.832725, validation loss = 2.962846
2018-12-05 09:32:52,507 - INFO - epoch 2, step 11300, training loss = 1.900470, validation loss = 2.788844
2018-12-05 09:32:56,085 - INFO - epoch 2, step 11310, training loss = 2.029589, validation loss = 2.768746
2018-12-05 09:32:59,785 - INFO - epoch 2, step 11320, training loss = 2.071580, validation loss = 2.786747
2018-12-05 09:33:03,441 - INFO - epoch 2, step 11330, training loss = 2.238415, validation loss = 2.436370
2018-12-05 09:33:07,154 - INFO - epoch 2, step 11340, training loss = 1.694112, validation loss = 2.536715
2018-12-05 09:33:10,924 - INFO - epoch 2, step 11350, training loss = 1.987144, validation loss = 3.069078
2018-12-05 09:33:14,745 - INFO - epoch 2, step 11360, training loss = 1.926431, validation loss = 3.188215
2018-12-05 09:33:18,414 - INFO - epoch 2, step 11370, training loss = 2.435630, validation loss = 2.705467
2018-12-05 09:33:22,106 - INFO - epoch 2, step 11380, training loss = 1.890926, validation loss = 2.855491
2018-12-05 09:33:25,690 - INFO - epoch 2, step 11390, training loss = 1.597577, validation loss = 2.486414
2018-12-05 09:33:29,317 - INFO - epoch 2, step 11400, training loss = 1.997440, validation loss = 2.724410
2018-12-05 09:33:32,988 - INFO - epoch 2, step 11410, training loss = 1.733531, validation loss = 2.481342
2018-12-05 09:33:36,516 - INFO - epoch 2, step 11420, training loss = 2.107592, validation loss = 2.266665
2018-12-05 09:33:40,148 - INFO - epoch 2, step 11430, training loss = 2.272498, validation loss = 2.440615
2018-12-05 09:33:43,933 - INFO - epoch 2, step 11440, training loss = 1.411743, validation loss = 2.787753
2018-12-05 09:33:47,659 - INFO - epoch 2, step 11450, training loss = 2.158544, validation loss = 2.324374
2018-12-05 09:33:51,414 - INFO - epoch 2, step 11460, training loss = 1.628942, validation loss = 2.965108
2018-12-05 09:33:55,558 - INFO - epoch 2, step 11470, training loss = 2.209912, validation loss = 2.105734
2018-12-05 09:33:59,676 - INFO - epoch 2, step 11480, training loss = 1.789686, validation loss = 2.409263
2018-12-05 09:34:04,012 - INFO - epoch 2, step 11490, training loss = 2.146365, validation loss = 2.590624
2018-12-05 09:34:08,105 - INFO - epoch 2, step 11500, training loss = 2.222206, validation loss = 2.508194
2018-12-05 09:34:12,083 - INFO - epoch 2, step 11510, training loss = 1.962882, validation loss = 2.351499
2018-12-05 09:34:16,031 - INFO - epoch 2, step 11520, training loss = 2.105494, validation loss = 2.258520
2018-12-05 09:34:19,781 - INFO - epoch 2, step 11530, training loss = 2.065042, validation loss = 2.631520
2018-12-05 09:34:23,732 - INFO - epoch 2, step 11540, training loss = 2.090387, validation loss = 2.417297
2018-12-05 09:34:27,938 - INFO - epoch 2, step 11550, training loss = 1.557766, validation loss = 2.435758
2018-12-05 09:34:32,091 - INFO - epoch 2, step 11560, training loss = 1.496613, validation loss = 2.135348
2018-12-05 09:34:36,423 - INFO - epoch 2, step 11570, training loss = 1.739149, validation loss = 2.383111
2018-12-05 09:34:40,636 - INFO - epoch 2, step 11580, training loss = 2.390785, validation loss = 2.471846
2018-12-05 09:34:44,965 - INFO - epoch 2, step 11590, training loss = 1.670244, validation loss = 2.671247
2018-12-05 09:34:49,259 - INFO - epoch 2, step 11600, training loss = 1.820744, validation loss = 2.108915
2018-12-05 09:34:53,384 - INFO - epoch 2, step 11610, training loss = 1.803755, validation loss = 2.499980
2018-12-05 09:34:57,493 - INFO - epoch 2, step 11620, training loss = 1.337285, validation loss = 2.065586
2018-12-05 09:35:01,681 - INFO - epoch 2, step 11630, training loss = 2.246044, validation loss = 2.747787
2018-12-05 09:35:05,867 - INFO - epoch 2, step 11640, training loss = 2.020920, validation loss = 2.357373
2018-12-05 09:35:09,772 - INFO - epoch 2, step 11650, training loss = 1.679167, validation loss = 2.868382
2018-12-05 09:35:13,505 - INFO - epoch 2, step 11660, training loss = 1.776962, validation loss = 2.509884
2018-12-05 09:35:16,953 - INFO - epoch 2, step 11670, training loss = 2.183631, validation loss = 2.791859
2018-12-05 09:35:20,586 - INFO - epoch 2, step 11680, training loss = 1.950591, validation loss = 2.523088
2018-12-05 09:35:24,305 - INFO - epoch 2, step 11690, training loss = 1.746105, validation loss = 2.167476
2018-12-05 09:35:27,878 - INFO - epoch 2, step 11700, training loss = 2.017811, validation loss = 2.323028
2018-12-05 09:35:31,568 - INFO - epoch 2, step 11710, training loss = 1.791700, validation loss = 2.017697
2018-12-05 09:35:34,995 - INFO - epoch 2, step 11720, training loss = 1.680245, validation loss = 2.405380
2018-12-05 09:35:38,864 - INFO - epoch 2, step 11730, training loss = 1.817178, validation loss = 2.612762
2018-12-05 09:35:42,362 - INFO - epoch 2, step 11740, training loss = 2.107785, validation loss = 2.427763
2018-12-05 09:35:46,110 - INFO - epoch 2, step 11750, training loss = 1.513916, validation loss = 2.214048
2018-12-05 09:35:49,686 - INFO - epoch 2, step 11760, training loss = 2.048062, validation loss = 2.594325
2018-12-05 09:35:53,343 - INFO - epoch 2, step 11770, training loss = 1.995312, validation loss = 2.388334
2018-12-05 09:35:57,189 - INFO - epoch 2, step 11780, training loss = 2.289525, validation loss = 2.300588
2018-12-05 09:36:01,589 - INFO - epoch 2, step 11790, training loss = 2.023998, validation loss = 2.587603
2018-12-05 09:36:05,640 - INFO - epoch 2, step 11800, training loss = 2.054118, validation loss = 2.264598
2018-12-05 09:36:09,624 - INFO - epoch 2, step 11810, training loss = 1.831406, validation loss = 2.402524
2018-12-05 09:36:13,734 - INFO - epoch 2, step 11820, training loss = 2.104508, validation loss = 3.073303
2018-12-05 09:36:17,651 - INFO - epoch 2, step 11830, training loss = 2.092770, validation loss = 2.696981
2018-12-05 09:36:21,757 - INFO - epoch 2, step 11840, training loss = 1.665728, validation loss = 2.192621
2018-12-05 09:36:25,737 - INFO - epoch 2, step 11850, training loss = 1.811789, validation loss = 2.049474
2018-12-05 09:36:29,908 - INFO - epoch 2, step 11860, training loss = 2.056639, validation loss = 2.666336
2018-12-05 09:36:33,798 - INFO - epoch 2, step 11870, training loss = 1.664924, validation loss = 2.772309
2018-12-05 09:36:37,804 - INFO - epoch 2, step 11880, training loss = 1.900624, validation loss = 2.290745
2018-12-05 09:36:41,695 - INFO - epoch 2, step 11890, training loss = 1.995713, validation loss = 1.965234
2018-12-05 09:36:45,806 - INFO - epoch 2, step 11900, training loss = 1.967969, validation loss = 2.365813
2018-12-05 09:36:49,744 - INFO - epoch 2, step 11910, training loss = 1.968285, validation loss = 2.559547
2018-12-05 09:36:53,646 - INFO - epoch 2, step 11920, training loss = 1.855486, validation loss = 2.474157
2018-12-05 09:36:57,393 - INFO - epoch 2, step 11930, training loss = 1.519250, validation loss = 2.068239
2018-12-05 09:37:01,272 - INFO - epoch 2, step 11940, training loss = 2.542804, validation loss = 1.772980
2018-12-05 09:37:05,093 - INFO - epoch 2, step 11950, training loss = 1.590365, validation loss = 1.986312
2018-12-05 09:37:08,985 - INFO - epoch 2, step 11960, training loss = 1.774184, validation loss = 2.532824
2018-12-05 09:37:12,566 - INFO - epoch 2, step 11970, training loss = 1.923542, validation loss = 1.955274
2018-12-05 09:37:16,174 - INFO - epoch 2, step 11980, training loss = 1.569563, validation loss = 2.791232
2018-12-05 09:37:19,759 - INFO - epoch 2, step 11990, training loss = 2.065444, validation loss = 2.562222
2018-12-05 09:37:23,606 - INFO - epoch 2, step 12000, training loss = 1.852412, validation loss = 2.588601
2018-12-05 09:37:27,330 - INFO - epoch 2, step 12010, training loss = 1.965526, validation loss = 2.487311
2018-12-05 09:37:30,943 - INFO - epoch 2, step 12020, training loss = 1.821976, validation loss = 2.779957
2018-12-05 09:37:34,535 - INFO - epoch 2, step 12030, training loss = 1.951140, validation loss = 2.687146
2018-12-05 09:37:38,295 - INFO - epoch 2, step 12040, training loss = 1.377940, validation loss = 2.355877
2018-12-05 09:37:42,242 - INFO - epoch 2, step 12050, training loss = 2.244339, validation loss = 2.256289
2018-12-05 09:37:46,567 - INFO - epoch 2, step 12060, training loss = 2.137551, validation loss = 2.529981
2018-12-05 09:37:50,835 - INFO - epoch 2, step 12070, training loss = 2.129496, validation loss = 2.576667
2018-12-05 09:37:55,269 - INFO - epoch 2, step 12080, training loss = 2.126484, validation loss = 2.338714
2018-12-05 09:37:59,606 - INFO - epoch 2, step 12090, training loss = 1.873673, validation loss = 2.099608
2018-12-05 09:38:03,902 - INFO - epoch 2, step 12100, training loss = 2.088839, validation loss = 2.312836
2018-12-05 09:38:07,998 - INFO - epoch 2, step 12110, training loss = 2.070534, validation loss = 2.497606
2018-12-05 09:38:12,289 - INFO - epoch 2, step 12120, training loss = 1.799022, validation loss = 2.999096
2018-12-05 09:38:16,644 - INFO - epoch 2, step 12130, training loss = 2.115094, validation loss = 2.710078
2018-12-05 09:38:20,709 - INFO - epoch 2, step 12140, training loss = 1.761679, validation loss = 3.058422
2018-12-05 09:38:25,093 - INFO - epoch 2, step 12150, training loss = 2.145267, validation loss = 2.521812
2018-12-05 09:38:29,373 - INFO - epoch 2, step 12160, training loss = 1.564014, validation loss = 2.936899
2018-12-05 09:38:33,693 - INFO - epoch 2, step 12170, training loss = 2.293844, validation loss = 2.467845
2018-12-05 09:38:37,746 - INFO - epoch 2, step 12180, training loss = 2.307699, validation loss = 3.072216
2018-12-05 09:38:42,241 - INFO - epoch 2, step 12190, training loss = 1.649659, validation loss = 2.633304
2018-12-05 09:38:46,560 - INFO - epoch 2, step 12200, training loss = 1.985018, validation loss = 2.427226
2018-12-05 09:38:50,843 - INFO - epoch 2, step 12210, training loss = 2.005103, validation loss = 2.810960
2018-12-05 09:38:55,258 - INFO - epoch 2, step 12220, training loss = 1.684277, validation loss = 3.002180
2018-12-05 09:38:59,652 - INFO - epoch 2, step 12230, training loss = 2.005915, validation loss = 2.356580
2018-12-05 09:39:03,738 - INFO - epoch 2, step 12240, training loss = 2.350516, validation loss = 2.339935
2018-12-05 09:39:07,936 - INFO - epoch 2, step 12250, training loss = 2.046788, validation loss = 2.908719
2018-12-05 09:39:12,175 - INFO - epoch 2, step 12260, training loss = 1.904917, validation loss = 2.462546
2018-12-05 09:39:16,446 - INFO - epoch 2, step 12270, training loss = 2.241582, validation loss = 2.528668
2018-12-05 09:39:20,552 - INFO - epoch 2, step 12280, training loss = 1.998804, validation loss = 2.769210
2018-12-05 09:39:24,793 - INFO - epoch 2, step 12290, training loss = 2.005618, validation loss = 3.048291
2018-12-05 09:39:28,993 - INFO - epoch 2, step 12300, training loss = 2.270922, validation loss = 2.794144
2018-12-05 09:39:33,110 - INFO - epoch 2, step 12310, training loss = 1.999343, validation loss = 2.784344
2018-12-05 09:39:37,024 - INFO - epoch 2, step 12320, training loss = 1.869337, validation loss = 2.526863
2018-12-05 09:39:40,769 - INFO - epoch 2, step 12330, training loss = 1.709648, validation loss = 2.412389
2018-12-05 09:39:44,250 - INFO - epoch 2, step 12340, training loss = 1.680130, validation loss = 3.238951
2018-12-05 09:39:47,802 - INFO - epoch 2, step 12350, training loss = 1.991670, validation loss = 2.676523
2018-12-05 09:39:51,310 - INFO - epoch 2, step 12360, training loss = 2.061576, validation loss = 2.697319
2018-12-05 09:39:55,093 - INFO - epoch 2, step 12370, training loss = 1.860569, validation loss = 3.052063
2018-12-05 09:39:58,768 - INFO - epoch 2, step 12380, training loss = 1.945586, validation loss = 2.556454
2018-12-05 09:40:02,442 - INFO - epoch 2, step 12390, training loss = 2.272206, validation loss = 2.426213
2018-12-05 09:40:06,256 - INFO - epoch 2, step 12400, training loss = 2.006441, validation loss = 2.191543
2018-12-05 09:40:10,423 - INFO - epoch 2, step 12410, training loss = 1.902951, validation loss = 2.950166
2018-12-05 09:40:14,722 - INFO - epoch 2, step 12420, training loss = 1.881679, validation loss = 2.779300
2018-12-05 09:40:18,724 - INFO - epoch 2, step 12430, training loss = 2.580844, validation loss = 3.202687
2018-12-05 09:40:22,940 - INFO - epoch 2, step 12440, training loss = 2.055276, validation loss = 3.332868
2018-12-05 09:40:27,053 - INFO - epoch 2, step 12450, training loss = 1.843419, validation loss = 2.742386
2018-12-05 09:40:31,004 - INFO - epoch 2, step 12460, training loss = 2.277302, validation loss = 3.102822
2018-12-05 09:40:35,214 - INFO - epoch 2, step 12470, training loss = 1.596212, validation loss = 2.417188
2018-12-05 09:40:39,212 - INFO - epoch 2, step 12480, training loss = 2.209546, validation loss = 2.685144
2018-12-05 09:40:43,194 - INFO - epoch 2, step 12490, training loss = 1.935290, validation loss = 2.235089
2018-12-05 09:40:47,263 - INFO - epoch 2, step 12500, training loss = 1.755963, validation loss = 2.499724
2018-12-05 09:40:51,396 - INFO - epoch 2, step 12510, training loss = 1.764392, validation loss = 2.620312
2018-12-05 09:40:55,494 - INFO - epoch 2, step 12520, training loss = 2.030490, validation loss = 3.112061
2018-12-05 09:40:59,530 - INFO - epoch 2, step 12530, training loss = 2.086232, validation loss = 2.913195
2018-12-05 09:41:03,473 - INFO - epoch 2, step 12540, training loss = 2.164727, validation loss = 2.685167
2018-12-05 09:41:07,348 - INFO - epoch 2, step 12550, training loss = 1.985163, validation loss = 2.504797
2018-12-05 09:41:11,234 - INFO - epoch 2, step 12560, training loss = 2.082976, validation loss = 3.507922
2018-12-05 09:41:14,967 - INFO - epoch 2, step 12570, training loss = 2.442569, validation loss = 2.850576
2018-12-05 09:41:18,772 - INFO - epoch 2, step 12580, training loss = 2.337432, validation loss = 2.783566
2018-12-05 09:41:22,327 - INFO - epoch 2, step 12590, training loss = 1.853678, validation loss = 2.718302
2018-12-05 09:41:26,182 - INFO - epoch 2, step 12600, training loss = 1.831586, validation loss = 2.543733
2018-12-05 09:41:30,049 - INFO - epoch 2, step 12610, training loss = 1.808117, validation loss = 2.647247
2018-12-05 09:41:33,791 - INFO - epoch 2, step 12620, training loss = 1.960782, validation loss = 2.501636
2018-12-05 09:41:37,623 - INFO - epoch 2, step 12630, training loss = 1.859721, validation loss = 2.537088
2018-12-05 09:41:41,309 - INFO - epoch 2, step 12640, training loss = 1.847210, validation loss = 2.945709
2018-12-05 09:41:45,074 - INFO - epoch 2, step 12650, training loss = 1.650895, validation loss = 2.329024
2018-12-05 09:41:48,724 - INFO - epoch 2, step 12660, training loss = 1.596934, validation loss = 2.318882
2018-12-05 09:41:52,453 - INFO - epoch 2, step 12670, training loss = 2.025183, validation loss = 2.310500
2018-12-05 09:41:55,980 - INFO - epoch 2, step 12680, training loss = 1.970969, validation loss = 3.219173
2018-12-05 09:41:59,535 - INFO - epoch 2, step 12690, training loss = 1.629145, validation loss = 3.483855
2018-12-05 09:42:03,080 - INFO - epoch 2, step 12700, training loss = 2.153620, validation loss = 3.137480
2018-12-05 09:42:06,441 - INFO - epoch 2, step 12710, training loss = 2.175698, validation loss = 2.813107
2018-12-05 09:42:09,845 - INFO - epoch 2, step 12720, training loss = 2.124092, validation loss = 3.062448
2018-12-05 09:42:13,337 - INFO - epoch 2, step 12730, training loss = 2.096399, validation loss = 2.755025
2018-12-05 09:42:16,805 - INFO - epoch 2, step 12740, training loss = 2.023143, validation loss = 2.759520
2018-12-05 09:42:20,223 - INFO - epoch 2, step 12750, training loss = 2.210646, validation loss = 2.838882
2018-12-05 09:42:23,734 - INFO - epoch 2, step 12760, training loss = 1.942655, validation loss = 3.019457
2018-12-05 09:42:27,102 - INFO - epoch 2, step 12770, training loss = 2.037754, validation loss = 2.770802
2018-12-05 09:42:30,829 - INFO - epoch 2, step 12780, training loss = 2.319319, validation loss = 2.751177
2018-12-05 09:42:34,450 - INFO - epoch 2, step 12790, training loss = 1.804252, validation loss = 2.592795
2018-12-05 09:42:38,002 - INFO - epoch 2, step 12800, training loss = 1.958600, validation loss = 2.886860
2018-12-05 09:42:42,244 - INFO - epoch 2, step 12810, training loss = 1.990528, validation loss = 3.341784
2018-12-05 09:42:46,085 - INFO - epoch 2, step 12820, training loss = 1.705908, validation loss = 2.719540
2018-12-05 09:42:50,105 - INFO - epoch 2, step 12830, training loss = 1.932382, validation loss = 2.658356
2018-12-05 09:42:53,881 - INFO - epoch 2, step 12840, training loss = 1.925400, validation loss = 2.837138
2018-12-05 09:42:58,039 - INFO - epoch 2, step 12850, training loss = 2.068399, validation loss = 2.922621
2018-12-05 09:43:01,785 - INFO - epoch 2, step 12860, training loss = 1.778010, validation loss = 3.065847
2018-12-05 09:43:05,413 - INFO - epoch 2, step 12870, training loss = 2.338903, validation loss = 2.720729
2018-12-05 09:43:09,425 - INFO - epoch 2, step 12880, training loss = 1.903622, validation loss = 2.948582
2018-12-05 09:43:13,360 - INFO - epoch 2, step 12890, training loss = 1.731069, validation loss = 2.930340
2018-12-05 09:43:16,884 - INFO - epoch 2, step 12900, training loss = 1.974957, validation loss = 2.445148
2018-12-05 09:43:20,339 - INFO - epoch 2, step 12910, training loss = 2.135683, validation loss = 2.911000
2018-12-05 09:43:23,911 - INFO - epoch 2, step 12920, training loss = 2.057456, validation loss = 2.798320
2018-12-05 09:43:27,319 - INFO - epoch 2, step 12930, training loss = 2.259078, validation loss = 3.052631
2018-12-05 09:43:30,785 - INFO - epoch 2, step 12940, training loss = 1.949262, validation loss = 3.140218
2018-12-05 09:43:34,249 - INFO - epoch 2, step 12950, training loss = 2.416377, validation loss = 2.216954
2018-12-05 09:43:37,782 - INFO - epoch 2, step 12960, training loss = 1.996106, validation loss = 2.580235
2018-12-05 09:43:41,206 - INFO - epoch 2, step 12970, training loss = 1.946935, validation loss = 3.002801
2018-12-05 09:43:44,712 - INFO - epoch 2, step 12980, training loss = 2.124167, validation loss = 2.328144
2018-12-05 09:43:48,184 - INFO - epoch 2, step 12990, training loss = 2.187549, validation loss = 2.956706
2018-12-05 09:43:51,508 - INFO - epoch 2, step 13000, training loss = 2.245917, validation loss = 2.429000
2018-12-05 09:43:55,093 - INFO - epoch 2, step 13010, training loss = 1.755314, validation loss = 3.234683
2018-12-05 09:43:58,590 - INFO - epoch 2, step 13020, training loss = 1.973147, validation loss = 2.650285
2018-12-05 09:44:01,923 - INFO - epoch 2, step 13030, training loss = 2.413303, validation loss = 3.036630
2018-12-05 09:44:05,194 - INFO - epoch 2, step 13040, training loss = 2.313101, validation loss = 2.720793
2018-12-05 09:44:08,651 - INFO - epoch 2, step 13050, training loss = 2.060589, validation loss = 2.973821
2018-12-05 09:44:12,265 - INFO - epoch 2, step 13060, training loss = 2.046325, validation loss = 2.930321
2018-12-05 09:44:16,185 - INFO - epoch 2, step 13070, training loss = 1.791773, validation loss = 3.656569
2018-12-05 09:44:20,403 - INFO - epoch 2, step 13080, training loss = 2.047976, validation loss = 3.262163
2018-12-05 09:44:24,657 - INFO - epoch 2, step 13090, training loss = 1.993519, validation loss = 2.801081
2018-12-05 09:44:29,096 - INFO - epoch 2, step 13100, training loss = 2.019901, validation loss = 2.603334
2018-12-05 09:44:33,441 - INFO - epoch 2, step 13110, training loss = 1.962467, validation loss = 2.873500
2018-12-05 09:44:37,402 - INFO - epoch 2, step 13120, training loss = 2.319469, validation loss = 2.795475
2018-12-05 09:44:41,282 - INFO - epoch 2, step 13130, training loss = 1.841926, validation loss = 2.964297
2018-12-05 09:44:45,278 - INFO - epoch 2, step 13140, training loss = 1.822901, validation loss = 2.955912
2018-12-05 09:44:49,223 - INFO - epoch 2, step 13150, training loss = 2.029376, validation loss = 2.297494
2018-12-05 09:44:53,221 - INFO - epoch 2, step 13160, training loss = 1.958120, validation loss = 2.268102
2018-12-05 09:44:57,289 - INFO - epoch 2, step 13170, training loss = 1.972087, validation loss = 2.741017
2018-12-05 09:45:01,544 - INFO - epoch 2, step 13180, training loss = 1.905624, validation loss = 2.794940
2018-12-05 09:45:05,366 - INFO - epoch 2, step 13190, training loss = 1.958586, validation loss = 2.708943
2018-12-05 09:45:09,178 - INFO - epoch 2, step 13200, training loss = 2.246972, validation loss = 2.364444
2018-12-05 09:45:12,500 - INFO - epoch 2, step 13210, training loss = 2.409877, validation loss = 2.865981
2018-12-05 09:45:15,988 - INFO - epoch 2, step 13220, training loss = 2.233902, validation loss = 2.985214
2018-12-05 09:45:19,631 - INFO - epoch 2, step 13230, training loss = 2.198845, validation loss = 2.173019
2018-12-05 09:45:22,962 - INFO - epoch 2, step 13240, training loss = 2.282626, validation loss = 2.864280
2018-12-05 09:45:26,387 - INFO - epoch 2, step 13250, training loss = 2.110606, validation loss = 3.278126
2018-12-05 09:45:29,717 - INFO - epoch 2, step 13260, training loss = 1.840852, validation loss = 3.100417
2018-12-05 09:45:33,414 - INFO - epoch 2, step 13270, training loss = 2.057299, validation loss = 2.413467
2018-12-05 09:45:36,885 - INFO - epoch 2, step 13280, training loss = 1.856955, validation loss = 2.534747
2018-12-05 09:45:40,485 - INFO - epoch 2, step 13290, training loss = 1.828997, validation loss = 2.901920
2018-12-05 09:45:44,006 - INFO - epoch 2, step 13300, training loss = 1.958104, validation loss = 3.453588
2018-12-05 09:45:47,687 - INFO - epoch 2, step 13310, training loss = 2.072301, validation loss = 2.838067
2018-12-05 09:45:51,188 - INFO - epoch 2, step 13320, training loss = 2.200791, validation loss = 3.072161
2018-12-05 09:45:54,614 - INFO - epoch 2, step 13330, training loss = 1.831772, validation loss = 2.577388
2018-12-05 09:45:58,332 - INFO - epoch 2, step 13340, training loss = 2.240475, validation loss = 2.451159
2018-12-05 09:46:01,970 - INFO - epoch 2, step 13350, training loss = 1.802170, validation loss = 2.914244
2018-12-05 09:46:05,604 - INFO - epoch 2, step 13360, training loss = 1.784329, validation loss = 2.947702
2018-12-05 09:46:09,250 - INFO - epoch 2, step 13370, training loss = 1.910279, validation loss = 3.285400
2018-12-05 09:46:13,120 - INFO - epoch 2, step 13380, training loss = 1.623496, validation loss = 1.976256
2018-12-05 09:46:16,785 - INFO - epoch 2, step 13390, training loss = 1.625621, validation loss = 3.159176
2018-12-05 09:46:20,479 - INFO - epoch 2, step 13400, training loss = 1.508648, validation loss = 2.828350
2018-12-05 09:46:24,108 - INFO - epoch 2, step 13410, training loss = 1.826205, validation loss = 2.959920
2018-12-05 09:46:28,016 - INFO - epoch 2, step 13420, training loss = 1.668039, validation loss = 2.660940
2018-12-05 09:46:31,530 - INFO - epoch 2, step 13430, training loss = 1.987336, validation loss = 2.155198
2018-12-05 09:46:35,092 - INFO - epoch 2, step 13440, training loss = 1.971847, validation loss = 2.620935
2018-12-05 09:46:38,653 - INFO - epoch 2, step 13450, training loss = 1.889739, validation loss = 2.580837
2018-12-05 09:46:42,443 - INFO - epoch 2, step 13460, training loss = 1.636961, validation loss = 2.442347
2018-12-05 09:46:46,446 - INFO - epoch 2, step 13470, training loss = 1.899227, validation loss = 2.121003
2018-12-05 09:46:50,532 - INFO - epoch 2, step 13480, training loss = 2.051614, validation loss = 2.894328
2018-12-05 09:46:54,927 - INFO - epoch 2, step 13490, training loss = 2.070138, validation loss = 2.336027
2018-12-05 09:46:59,135 - INFO - epoch 2, step 13500, training loss = 2.288763, validation loss = 1.784348
2018-12-05 09:47:03,223 - INFO - epoch 2, step 13510, training loss = 1.751779, validation loss = 2.122034
2018-12-05 09:47:07,747 - INFO - epoch 2, step 13520, training loss = 1.873506, validation loss = 1.817999
2018-12-05 09:47:12,053 - INFO - epoch 2, step 13530, training loss = 1.839937, validation loss = 2.341264
2018-12-05 09:47:16,208 - INFO - epoch 2, step 13540, training loss = 1.761747, validation loss = 2.626290
2018-12-05 09:47:20,528 - INFO - epoch 2, step 13550, training loss = 2.161021, validation loss = 2.578175
2018-12-05 09:47:24,780 - INFO - epoch 2, step 13560, training loss = 2.008343, validation loss = 2.203648
2018-12-05 09:47:28,970 - INFO - epoch 2, step 13570, training loss = 2.051799, validation loss = 2.013501
2018-12-05 09:47:33,226 - INFO - epoch 2, step 13580, training loss = 1.904143, validation loss = 2.162011
2018-12-05 09:47:37,533 - INFO - epoch 2, step 13590, training loss = 1.744836, validation loss = 2.099305
2018-12-05 09:47:41,789 - INFO - epoch 2, step 13600, training loss = 2.256225, validation loss = 2.319790
2018-12-05 09:47:45,700 - INFO - epoch 2, step 13610, training loss = 1.989255, validation loss = 2.883600
2018-12-05 09:47:48,934 - INFO - epoch 2, step 13620, training loss = 2.084355, validation loss = 3.226460
2018-12-05 09:47:52,238 - INFO - epoch 2, step 13630, training loss = 2.228399, validation loss = 3.235493
2018-12-05 09:47:55,574 - INFO - epoch 2, step 13640, training loss = 2.338561, validation loss = 2.472974
2018-12-05 09:47:59,142 - INFO - epoch 2, step 13650, training loss = 1.759368, validation loss = 3.000778
2018-12-05 09:48:02,710 - INFO - epoch 2, step 13660, training loss = 1.784200, validation loss = 2.524773
2018-12-05 09:48:06,327 - INFO - epoch 2, step 13670, training loss = 1.997276, validation loss = 2.202976
2018-12-05 09:48:09,791 - INFO - epoch 2, step 13680, training loss = 1.605412, validation loss = 2.672777
2018-12-05 09:48:13,359 - INFO - epoch 2, step 13690, training loss = 2.268673, validation loss = 2.440242
2018-12-05 09:48:16,948 - INFO - epoch 2, step 13700, training loss = 1.358515, validation loss = 2.952079
2018-12-05 09:48:20,264 - INFO - epoch 2, step 13710, training loss = 1.876506, validation loss = 2.783397
2018-12-05 09:48:23,620 - INFO - epoch 2, step 13720, training loss = 1.961945, validation loss = 2.850381
2018-12-05 09:48:27,258 - INFO - epoch 2, step 13730, training loss = 2.043460, validation loss = 2.749998
2018-12-05 09:48:31,341 - INFO - epoch 2, step 13740, training loss = 1.796745, validation loss = 2.120481
2018-12-05 09:48:35,512 - INFO - epoch 2, step 13750, training loss = 1.703818, validation loss = 2.310726
2018-12-05 09:48:39,530 - INFO - epoch 2, step 13760, training loss = 1.636965, validation loss = 2.291038
2018-12-05 09:48:43,567 - INFO - epoch 2, step 13770, training loss = 1.785065, validation loss = 2.277273
2018-12-05 09:48:47,584 - INFO - epoch 2, step 13780, training loss = 1.706598, validation loss = 2.357921
2018-12-05 09:48:51,530 - INFO - epoch 2, step 13790, training loss = 1.971364, validation loss = 2.387713
2018-12-05 09:48:55,268 - INFO - epoch 2, step 13800, training loss = 1.865402, validation loss = 2.342309
2018-12-05 09:48:59,068 - INFO - epoch 2, step 13810, training loss = 1.659991, validation loss = 2.358485
2018-12-05 09:49:02,642 - INFO - epoch 2, step 13820, training loss = 1.418994, validation loss = 2.399878
2018-12-05 09:49:06,212 - INFO - epoch 2, step 13830, training loss = 1.907556, validation loss = 2.197809
2018-12-05 09:49:09,646 - INFO - epoch 2, step 13840, training loss = 1.607730, validation loss = 2.656288
2018-12-05 09:49:13,130 - INFO - epoch 2, step 13850, training loss = 1.894159, validation loss = 2.426255
2018-12-05 09:49:16,788 - INFO - epoch 2, step 13860, training loss = 1.351562, validation loss = 2.667633
2018-12-05 09:49:20,613 - INFO - epoch 2, step 13870, training loss = 1.440519, validation loss = 2.282132
2018-12-05 09:49:24,084 - INFO - epoch 2, step 13880, training loss = 2.333903, validation loss = 2.066851
2018-12-05 09:49:28,288 - INFO - epoch 2, step 13890, training loss = 2.229567, validation loss = 2.049476
2018-12-05 09:49:32,602 - INFO - epoch 2, step 13900, training loss = 1.684044, validation loss = 2.859180
2018-12-05 09:49:36,952 - INFO - epoch 2, step 13910, training loss = 2.010938, validation loss = 2.568788
2018-12-05 09:49:41,062 - INFO - epoch 2, step 13920, training loss = 1.662020, validation loss = 2.263478
2018-12-05 09:49:45,293 - INFO - epoch 2, step 13930, training loss = 1.831113, validation loss = 2.553643
2018-12-05 09:49:49,531 - INFO - epoch 2, step 13940, training loss = 2.125761, validation loss = 2.585909
2018-12-05 09:49:53,742 - INFO - epoch 2, step 13950, training loss = 2.452490, validation loss = 2.850812
2018-12-05 09:49:58,128 - INFO - epoch 2, step 13960, training loss = 2.240065, validation loss = 2.517165
2018-12-05 09:50:02,520 - INFO - epoch 2, step 13970, training loss = 1.649557, validation loss = 3.001488
2018-12-05 09:50:07,040 - INFO - epoch 2, step 13980, training loss = 1.790124, validation loss = 2.766766
2018-12-05 09:50:11,206 - INFO - epoch 2, step 13990, training loss = 1.437474, validation loss = 2.112418
2018-12-05 09:50:15,398 - INFO - epoch 2, step 14000, training loss = 1.551350, validation loss = 2.303371
2018-12-05 09:50:19,662 - INFO - epoch 2, step 14010, training loss = 2.023111, validation loss = 1.868518
2018-12-05 09:50:23,493 - INFO - epoch 2, step 14020, training loss = 1.878583, validation loss = 2.748654
2018-12-05 09:50:27,046 - INFO - epoch 2, step 14030, training loss = 1.900498, validation loss = 2.954117
2018-12-05 09:50:31,397 - INFO - epoch 2, step 14040, training loss = 2.027647, validation loss = 2.705445
2018-12-05 09:50:35,585 - INFO - epoch 2, step 14050, training loss = 2.090412, validation loss = 2.632330
2018-12-05 09:50:39,274 - INFO - epoch 2, step 14060, training loss = 2.095952, validation loss = 2.628141
2018-12-05 09:50:42,854 - INFO - epoch 2, step 14070, training loss = 1.852946, validation loss = 2.470018
2018-12-05 09:50:46,429 - INFO - epoch 2, step 14080, training loss = 2.034903, validation loss = 2.149156
2018-12-05 09:50:50,127 - INFO - epoch 2, step 14090, training loss = 1.893459, validation loss = 2.461315
2018-12-05 09:50:53,923 - INFO - epoch 2, step 14100, training loss = 2.297369, validation loss = 2.468257
2018-12-05 09:50:57,626 - INFO - epoch 2, step 14110, training loss = 1.745260, validation loss = 2.787157
2018-12-05 09:51:01,674 - INFO - epoch 2, step 14120, training loss = 1.934528, validation loss = 2.872602
2018-12-05 09:51:05,439 - INFO - epoch 2, step 14130, training loss = 1.967989, validation loss = 2.331894
2018-12-05 09:51:09,337 - INFO - epoch 2, step 14140, training loss = 2.257198, validation loss = 2.604075
2018-12-05 09:51:13,298 - INFO - epoch 2, step 14150, training loss = 2.115180, validation loss = 2.648415
2018-12-05 09:51:17,039 - INFO - epoch 2, step 14160, training loss = 1.877926, validation loss = 2.152423
2018-12-05 09:51:20,850 - INFO - epoch 2, step 14170, training loss = 2.099265, validation loss = 2.721604
2018-12-05 09:51:24,737 - INFO - epoch 2, step 14180, training loss = 1.855163, validation loss = 2.717248
2018-12-05 09:51:28,643 - INFO - epoch 2, step 14190, training loss = 2.260271, validation loss = 2.214002
2018-12-05 09:51:32,353 - INFO - epoch 2, step 14200, training loss = 1.955869, validation loss = 2.621786
2018-12-05 09:51:36,215 - INFO - epoch 2, step 14210, training loss = 1.940839, validation loss = 2.703963
2018-12-05 09:51:40,293 - INFO - epoch 2, step 14220, training loss = 2.038124, validation loss = 2.205171
2018-12-05 09:51:44,354 - INFO - epoch 2, step 14230, training loss = 1.879414, validation loss = 2.508008
2018-12-05 09:51:48,584 - INFO - epoch 2, step 14240, training loss = 1.815567, validation loss = 2.246005
2018-12-05 09:51:52,951 - INFO - epoch 2, step 14250, training loss = 2.005122, validation loss = 2.104336
2018-12-05 09:51:57,252 - INFO - epoch 2, step 14260, training loss = 2.079445, validation loss = 2.740299
2018-12-05 09:52:01,390 - INFO - epoch 2, step 14270, training loss = 1.277438, validation loss = 2.760018
2018-12-05 09:52:05,617 - INFO - epoch 2, step 14280, training loss = 1.973660, validation loss = 2.014885
2018-12-05 09:52:09,965 - INFO - epoch 2, step 14290, training loss = 1.897249, validation loss = 2.514225
2018-12-05 09:52:14,292 - INFO - epoch 2, step 14300, training loss = 2.074957, validation loss = 2.504546
2018-12-05 09:52:18,426 - INFO - epoch 2, step 14310, training loss = 1.754456, validation loss = 2.517096
2018-12-05 09:52:22,660 - INFO - epoch 2, step 14320, training loss = 1.968033, validation loss = 2.872333
2018-12-05 09:52:26,991 - INFO - epoch 2, step 14330, training loss = 2.033165, validation loss = 2.244287
2018-12-05 09:52:31,380 - INFO - epoch 2, step 14340, training loss = 2.277378, validation loss = 2.145424
2018-12-05 09:52:35,564 - INFO - epoch 2, step 14350, training loss = 2.351923, validation loss = 1.910508
2018-12-05 09:52:38,730 - INFO - epoch 2, step 14360, training loss = 2.650502, validation loss = 2.355631
2018-12-05 09:52:41,886 - INFO - epoch 2, step 14370, training loss = 2.458565, validation loss = 2.386754
2018-12-05 09:52:45,245 - INFO - epoch 2, step 14380, training loss = 2.392207, validation loss = 1.903231
2018-12-05 09:52:48,529 - INFO - epoch 2, step 14390, training loss = 2.113310, validation loss = 2.570508
2018-12-05 09:52:51,717 - INFO - epoch 2, step 14400, training loss = 2.245657, validation loss = 2.258417
2018-12-05 09:52:55,124 - INFO - epoch 2, step 14410, training loss = 2.189643, validation loss = 2.308532
2018-12-05 09:52:58,425 - INFO - epoch 2, step 14420, training loss = 2.391431, validation loss = 2.352845
2018-12-05 09:53:01,474 - INFO - epoch 2, step 14430, training loss = 2.997676, validation loss = 2.754158
2018-12-05 09:53:04,587 - INFO - epoch 2, step 14440, training loss = 2.168318, validation loss = 2.437903
2018-12-05 09:53:07,953 - INFO - epoch 2, step 14450, training loss = 2.249208, validation loss = 2.071506
2018-12-05 09:53:11,180 - INFO - epoch 2, step 14460, training loss = 2.609377, validation loss = 2.526774
2018-12-05 09:53:14,461 - INFO - epoch 2, step 14470, training loss = 2.331469, validation loss = 2.371773
2018-12-05 09:53:17,817 - INFO - epoch 2, step 14480, training loss = 1.994917, validation loss = 2.471006
2018-12-05 09:53:21,097 - INFO - epoch 2, step 14490, training loss = 2.343436, validation loss = 3.124072
2018-12-05 09:53:24,461 - INFO - epoch 2, step 14500, training loss = 2.418576, validation loss = 2.445052
2018-12-05 09:53:27,750 - INFO - epoch 2, step 14510, training loss = 2.720487, validation loss = 2.623681
2018-12-05 09:53:31,106 - INFO - epoch 2, step 14520, training loss = 2.774072, validation loss = 2.345779
2018-12-05 09:53:34,768 - INFO - epoch 2, step 14530, training loss = 2.657224, validation loss = 2.575287
2018-12-05 09:53:38,323 - INFO - epoch 2, step 14540, training loss = 2.156263, validation loss = 2.588488
2018-12-05 09:53:41,987 - INFO - epoch 2, step 14550, training loss = 2.706662, validation loss = 3.054613
2018-12-05 09:53:45,768 - INFO - epoch 2, step 14560, training loss = 2.537701, validation loss = 2.405468
2018-12-05 09:53:49,425 - INFO - epoch 2, step 14570, training loss = 2.498377, validation loss = 2.580208
2018-12-05 09:53:52,959 - INFO - epoch 2, step 14580, training loss = 2.653901, validation loss = 2.001541
2018-12-05 09:53:56,656 - INFO - epoch 2, step 14590, training loss = 2.760539, validation loss = 2.489962
2018-12-05 09:54:00,331 - INFO - epoch 2, step 14600, training loss = 2.352093, validation loss = 2.567990
2018-12-05 09:54:03,885 - INFO - epoch 2, step 14610, training loss = 2.706934, validation loss = 2.736299
2018-12-05 09:54:07,431 - INFO - epoch 2, step 14620, training loss = 2.982734, validation loss = 2.333265
2018-12-05 09:54:12,553 - INFO - epoch 2, step 14630, training loss = 2.090624, validation loss = 2.593058
2018-12-05 09:54:18,371 - INFO - epoch 2, step 14640, training loss = 2.096019, validation loss = 2.325498
2018-12-05 09:54:23,883 - INFO - epoch 2, step 14650, training loss = 2.504473, validation loss = 1.621094
2018-12-05 09:54:29,093 - INFO - epoch 2, step 14660, training loss = 1.850657, validation loss = 2.218733
2018-12-05 09:54:35,074 - INFO - epoch 2, step 14670, training loss = 1.998453, validation loss = 2.657905
2018-12-05 09:54:40,886 - INFO - epoch 2, step 14680, training loss = 2.048315, validation loss = 2.416714
2018-12-05 09:54:44,847 - INFO - epoch 2, step 14690, training loss = 2.483009, validation loss = 2.343906
2018-12-05 09:54:48,150 - INFO - epoch 2, step 14700, training loss = 1.965599, validation loss = 2.657202
2018-12-05 09:54:51,684 - INFO - epoch 2, step 14710, training loss = 1.761671, validation loss = 2.312496
2018-12-05 09:54:55,026 - INFO - epoch 2, step 14720, training loss = 2.273159, validation loss = 2.096323
2018-12-05 09:54:58,252 - INFO - epoch 2, step 14730, training loss = 2.359061, validation loss = 2.270634
2018-12-05 09:55:01,587 - INFO - epoch 2, step 14740, training loss = 1.934164, validation loss = 2.729131
2018-12-05 09:55:04,843 - INFO - epoch 2, step 14750, training loss = 2.151649, validation loss = 2.650562
2018-12-05 09:55:08,118 - INFO - epoch 2, step 14760, training loss = 1.946019, validation loss = 2.193094
2018-12-05 09:55:11,324 - INFO - epoch 2, step 14770, training loss = 2.340296, validation loss = 2.851336
2018-12-05 09:55:14,441 - INFO - epoch 2, step 14780, training loss = 2.240874, validation loss = 2.091203
2018-12-05 09:55:17,665 - INFO - epoch 2, step 14790, training loss = 2.057747, validation loss = 1.827625
2018-12-05 09:55:20,896 - INFO - epoch 2, step 14800, training loss = 2.208848, validation loss = 1.899511
2018-12-05 09:55:24,125 - INFO - epoch 2, step 14810, training loss = 2.087754, validation loss = 2.273572
2018-12-05 09:55:27,253 - INFO - epoch 2, step 14820, training loss = 2.764256, validation loss = 2.738426
2018-12-05 09:55:30,578 - INFO - epoch 2, step 14830, training loss = 2.002299, validation loss = 2.942170
2018-12-05 09:55:33,789 - INFO - epoch 2, step 14840, training loss = 2.020064, validation loss = 2.950089
2018-12-05 09:55:37,328 - INFO - epoch 2, step 14850, training loss = 2.090267, validation loss = 2.609142
2018-12-05 09:55:40,902 - INFO - epoch 2, step 14860, training loss = 2.379376, validation loss = 2.159897
2018-12-05 09:55:47,154 - INFO - epoch 2, step 14870, training loss = 2.066913, validation loss = 2.289208
2018-12-05 09:55:53,329 - INFO - epoch 2, step 14880, training loss = 2.138886, validation loss = 2.443944
2018-12-05 09:55:59,505 - INFO - epoch 2, step 14890, training loss = 2.080855, validation loss = 2.295138
2018-12-05 09:56:05,104 - INFO - epoch 2, step 14900, training loss = 1.649050, validation loss = 2.054832
2018-12-05 09:56:10,653 - INFO - epoch 2, step 14910, training loss = 2.215132, validation loss = 2.293397
2018-12-05 09:56:16,372 - INFO - epoch 2, step 14920, training loss = 2.112958, validation loss = 2.003058
2018-12-05 09:56:21,792 - INFO - epoch 2, step 14930, training loss = 2.116420, validation loss = 2.187961
2018-12-05 09:56:27,222 - INFO - epoch 2, step 14940, training loss = 2.126306, validation loss = 1.965854
2018-12-05 09:56:33,186 - INFO - epoch 2, step 14950, training loss = 2.088418, validation loss = 2.209055
2018-12-05 09:56:38,918 - INFO - epoch 2, step 14960, training loss = 1.892958, validation loss = 2.561323
2018-12-05 09:56:44,569 - INFO - epoch 2, step 14970, training loss = 1.999671, validation loss = 2.447857
2018-12-05 09:56:50,696 - INFO - epoch 2, step 14980, training loss = 1.483009, validation loss = 2.418799
2018-12-05 09:56:56,895 - INFO - epoch 2, step 14990, training loss = 2.008608, validation loss = 2.027005
2018-12-05 09:57:02,689 - INFO - epoch 2, step 15000, training loss = 2.089230, validation loss = 2.293641
2018-12-05 09:57:07,939 - INFO - epoch 2, step 15010, training loss = 1.852113, validation loss = 2.308173
2018-12-05 09:57:13,503 - INFO - epoch 2, step 15020, training loss = 1.560625, validation loss = 2.096913
2018-12-05 09:57:19,558 - INFO - epoch 2, step 15030, training loss = 1.903931, validation loss = 2.364900
2018-12-05 09:57:25,127 - INFO - epoch 2, step 15040, training loss = 1.785974, validation loss = 2.578877
2018-12-05 09:57:30,816 - INFO - epoch 2, step 15050, training loss = 2.044758, validation loss = 2.163920
2018-12-05 09:57:36,599 - INFO - epoch 2, step 15060, training loss = 2.090352, validation loss = 2.087473
2018-12-05 09:57:42,743 - INFO - epoch 2, step 15070, training loss = 1.705063, validation loss = 2.285993
2018-12-05 09:57:49,570 - INFO - epoch 2, step 15080, training loss = 1.979746, validation loss = 2.457775
2018-12-05 09:57:55,401 - INFO - epoch 2, step 15090, training loss = 2.276883, validation loss = 1.649490
2018-12-05 09:58:00,662 - INFO - epoch 2, step 15100, training loss = 2.246733, validation loss = 2.434308
2018-12-05 09:58:07,615 - INFO - epoch 2, step 15110, training loss = 1.343436, validation loss = 2.236512
2018-12-05 09:58:13,759 - INFO - epoch 2, step 15120, training loss = 1.454471, validation loss = 2.262429
2018-12-05 09:58:20,081 - INFO - epoch 2, step 15130, training loss = 2.334440, validation loss = 2.280446
2018-12-05 09:58:26,694 - INFO - epoch 2, step 15140, training loss = 1.960491, validation loss = 2.517593
2018-12-05 09:58:32,649 - INFO - epoch 2, step 15150, training loss = 2.174655, validation loss = 2.696554
2018-12-05 09:58:39,095 - INFO - epoch 2, step 15160, training loss = 1.810556, validation loss = 2.109774
2018-12-05 09:58:45,920 - INFO - epoch 2, step 15170, training loss = 1.528164, validation loss = 2.102739
2018-12-05 09:58:51,759 - INFO - epoch 2, step 15180, training loss = 1.951553, validation loss = 2.576471
2018-12-05 09:58:58,325 - INFO - epoch 2, step 15190, training loss = 1.447471, validation loss = 2.248536
2018-12-05 09:59:03,822 - INFO - epoch 2, step 15200, training loss = 2.075024, validation loss = 2.432927
2018-12-05 09:59:09,839 - INFO - epoch 2, step 15210, training loss = 2.181836, validation loss = 2.238956
2018-12-05 09:59:15,723 - INFO - epoch 2, step 15220, training loss = 2.142659, validation loss = 2.222857
2018-12-05 09:59:21,327 - INFO - epoch 2, step 15230, training loss = 2.130661, validation loss = 2.698164
2018-12-05 09:59:27,129 - INFO - epoch 2, step 15240, training loss = 2.478998, validation loss = 2.688449
2018-12-05 09:59:33,520 - INFO - epoch 2, step 15250, training loss = 1.829244, validation loss = 2.490396
2018-12-05 09:59:40,325 - INFO - epoch 2, step 15260, training loss = 1.872402, validation loss = 2.471040
2018-12-05 09:59:45,818 - INFO - epoch 2, step 15270, training loss = 1.967812, validation loss = 2.368009
2018-12-05 09:59:51,833 - INFO - epoch 2, step 15280, training loss = 1.985410, validation loss = 2.479316
2018-12-05 09:59:57,607 - INFO - epoch 2, step 15290, training loss = 1.934939, validation loss = 2.128288
2018-12-05 10:00:03,629 - INFO - epoch 2, step 15300, training loss = 1.608350, validation loss = 2.024010
2018-12-05 10:00:09,140 - INFO - epoch 2, step 15310, training loss = 2.076272, validation loss = 2.079622
2018-12-05 10:00:14,539 - INFO - epoch 2, step 15320, training loss = 2.117097, validation loss = 2.302058
2018-12-05 10:00:19,948 - INFO - epoch 2, step 15330, training loss = 1.686628, validation loss = 2.649807
2018-12-05 10:00:26,001 - INFO - epoch 2, step 15340, training loss = 1.721850, validation loss = 2.581705
2018-12-05 10:00:31,193 - INFO - epoch 2, step 15350, training loss = 2.027030, validation loss = 1.977753
2018-12-05 10:00:36,890 - INFO - epoch 2, step 15360, training loss = 2.119101, validation loss = 2.334403
2018-12-05 10:00:42,242 - INFO - epoch 2, step 15370, training loss = 1.924390, validation loss = 2.377465
2018-12-05 10:00:48,084 - INFO - epoch 2, step 15380, training loss = 1.924658, validation loss = 3.128662
2018-12-05 10:00:53,367 - INFO - epoch 2, step 15390, training loss = 2.851622, validation loss = 2.129947
2018-12-05 10:00:56,563 - INFO - epoch 2, step 15400, training loss = 2.670737, validation loss = 2.213154
2018-12-05 10:00:59,909 - INFO - epoch 2, step 15410, training loss = 2.273756, validation loss = 2.359075
2018-12-05 10:01:03,142 - INFO - epoch 2, step 15420, training loss = 1.829051, validation loss = 2.613158
2018-12-05 10:01:06,283 - INFO - epoch 2, step 15430, training loss = 2.124877, validation loss = 2.453371
2018-12-05 10:01:09,612 - INFO - epoch 2, step 15440, training loss = 1.912781, validation loss = 2.754163
2018-12-05 10:01:12,835 - INFO - epoch 2, step 15450, training loss = 2.212504, validation loss = 2.329293
2018-12-05 10:01:16,035 - INFO - epoch 2, step 15460, training loss = 2.661008, validation loss = 2.336513
2018-12-05 10:01:19,464 - INFO - epoch 2, step 15470, training loss = 1.615688, validation loss = 2.674345
2018-12-05 10:01:22,732 - INFO - epoch 2, step 15480, training loss = 1.890278, validation loss = 2.447379
2018-12-05 10:01:25,915 - INFO - epoch 2, step 15490, training loss = 2.246024, validation loss = 2.965454
2018-12-05 10:01:29,153 - INFO - epoch 2, step 15500, training loss = 2.275869, validation loss = 2.550198
2018-12-05 10:01:32,516 - INFO - epoch 2, step 15510, training loss = 2.024045, validation loss = 2.344629
2018-12-05 10:01:35,634 - INFO - epoch 2, step 15520, training loss = 2.083790, validation loss = 2.174767
2018-12-05 10:01:38,771 - INFO - epoch 2, step 15530, training loss = 2.318857, validation loss = 2.550534
2018-12-05 10:01:41,938 - INFO - epoch 2, step 15540, training loss = 2.300869, validation loss = 2.969463
2018-12-05 10:01:45,254 - INFO - epoch 2, step 15550, training loss = 2.115050, validation loss = 2.554918
2018-12-05 10:01:48,486 - INFO - epoch 2, step 15560, training loss = 2.068642, validation loss = 2.819639
2018-12-05 10:01:51,898 - INFO - epoch 2, step 15570, training loss = 1.815709, validation loss = 2.897826
2018-12-05 10:01:55,140 - INFO - epoch 2, step 15580, training loss = 2.440923, validation loss = 2.173711
2018-12-05 10:01:58,416 - INFO - epoch 2, step 15590, training loss = 2.219647, validation loss = 2.526567
2018-12-05 10:02:03,529 - INFO - epoch 2, step 15600, training loss = 2.063617, validation loss = 2.582784
2018-12-05 10:02:08,494 - INFO - epoch 2, step 15610, training loss = 2.698707, validation loss = 2.761847
2018-12-05 10:02:13,373 - INFO - epoch 2, step 15620, training loss = 2.619613, validation loss = 2.155169
2018-12-05 10:02:18,219 - INFO - epoch 2, step 15630, training loss = 2.532550, validation loss = 2.468135
2018-12-05 10:02:23,213 - INFO - epoch 2, step 15640, training loss = 1.908575, validation loss = 2.610101
2018-12-05 10:02:27,997 - INFO - epoch 2, step 15650, training loss = 2.158897, validation loss = 2.177435
2018-12-05 10:02:32,507 - INFO - epoch 2, step 15660, training loss = 2.780413, validation loss = 2.032103
2018-12-05 10:02:37,394 - INFO - epoch 2, step 15670, training loss = 2.198387, validation loss = 1.993976
2018-12-05 10:02:42,057 - INFO - epoch 2, step 15680, training loss = 2.253144, validation loss = 2.979949
2018-12-05 10:02:46,787 - INFO - epoch 2, step 15690, training loss = 2.677386, validation loss = 2.252321
2018-12-05 10:02:51,513 - INFO - epoch 2, step 15700, training loss = 2.489361, validation loss = 1.829732
2018-12-05 10:02:56,199 - INFO - epoch 2, step 15710, training loss = 2.291766, validation loss = 2.558506
2018-12-05 10:03:01,962 - INFO - epoch 2, step 15720, training loss = 1.997158, validation loss = 2.492928
2018-12-05 10:03:07,823 - INFO - epoch 2, step 15730, training loss = 2.521953, validation loss = 2.489593
2018-12-05 10:03:13,903 - INFO - epoch 2, step 15740, training loss = 2.036314, validation loss = 2.665812
2018-12-05 10:03:19,447 - INFO - epoch 2, step 15750, training loss = 1.975578, validation loss = 2.356166
2018-12-05 10:03:25,255 - INFO - epoch 2, step 15760, training loss = 1.839090, validation loss = 2.337288
2018-12-05 10:03:30,886 - INFO - epoch 2, step 15770, training loss = 1.812133, validation loss = 2.577951
2018-12-05 10:03:36,847 - INFO - epoch 2, step 15780, training loss = 2.019231, validation loss = 2.201828
2018-12-05 10:03:42,161 - INFO - epoch 2, step 15790, training loss = 2.401562, validation loss = 2.175950
2018-12-05 10:03:47,379 - INFO - epoch 2, step 15800, training loss = 2.143970, validation loss = 2.122105
2018-12-05 10:03:52,666 - INFO - epoch 2, step 15810, training loss = 2.122604, validation loss = 2.218465
2018-12-05 10:03:58,131 - INFO - epoch 2, step 15820, training loss = 2.800852, validation loss = 2.234691
2018-12-05 10:04:03,862 - INFO - epoch 2, step 15830, training loss = 2.040490, validation loss = 2.409425
2018-12-05 10:04:09,552 - INFO - epoch 2, step 15840, training loss = 2.443980, validation loss = 2.228031
2018-12-05 10:04:15,101 - INFO - epoch 2, step 15850, training loss = 2.291130, validation loss = 2.212964
2018-12-05 10:04:20,764 - INFO - epoch 2, step 15860, training loss = 1.932594, validation loss = 1.830747
2018-12-05 10:04:26,593 - INFO - epoch 2, step 15870, training loss = 1.955461, validation loss = 2.403327
2018-12-05 10:04:32,099 - INFO - epoch 2, step 15880, training loss = 2.103602, validation loss = 2.488422
2018-12-05 10:04:37,764 - INFO - epoch 2, step 15890, training loss = 1.968866, validation loss = 2.547020
2018-12-05 10:04:43,725 - INFO - epoch 2, step 15900, training loss = 1.794106, validation loss = 2.737619
2018-12-05 10:04:49,101 - INFO - epoch 2, step 15910, training loss = 1.796074, validation loss = 2.062619
2018-12-05 10:04:54,272 - INFO - epoch 2, step 15920, training loss = 1.862742, validation loss = 2.736680
2018-12-05 10:04:58,676 - INFO - epoch 2, step 15930, training loss = 2.253550, validation loss = 2.566502
2018-12-05 10:05:03,079 - INFO - epoch 2, step 15940, training loss = 2.401617, validation loss = 2.511683
2018-12-05 10:05:07,233 - INFO - epoch 2, step 15950, training loss = 2.208431, validation loss = 2.142416
2018-12-05 10:05:11,636 - INFO - epoch 2, step 15960, training loss = 2.023801, validation loss = 2.466900
2018-12-05 10:05:15,876 - INFO - epoch 2, step 15970, training loss = 2.076055, validation loss = 2.312746
2018-12-05 10:05:20,108 - INFO - epoch 2, step 15980, training loss = 1.778749, validation loss = 2.375153
2018-12-05 10:05:24,799 - INFO - epoch 2, step 15990, training loss = 1.954147, validation loss = 2.695244
2018-12-05 10:05:29,288 - INFO - epoch 2, step 16000, training loss = 2.189038, validation loss = 2.779470
2018-12-05 10:05:33,614 - INFO - epoch 2, step 16010, training loss = 2.293425, validation loss = 1.906551
2018-12-05 10:05:37,525 - INFO - epoch 2, step 16020, training loss = 2.177971, validation loss = 2.473557
2018-12-05 10:05:40,878 - INFO - epoch 2, step 16030, training loss = 2.268708, validation loss = 2.697030
2018-12-05 10:05:43,261 - INFO - epoch 2, step 16040, training loss = 2.370282, validation loss = 3.272322
2018-12-05 10:05:45,742 - INFO - epoch 2, step 16050, training loss = 2.258990, validation loss = 2.703165
2018-12-05 10:05:48,312 - INFO - epoch 2, step 16060, training loss = 2.659519, validation loss = 2.694107
2018-12-05 10:05:50,781 - INFO - epoch 2, step 16070, training loss = 2.551234, validation loss = 2.878435
2018-12-05 10:05:53,319 - INFO - epoch 2, step 16080, training loss = 1.782971, validation loss = 3.186769
2018-12-05 10:05:55,994 - INFO - epoch 2, step 16090, training loss = 2.274983, validation loss = 2.568775
2018-12-05 10:05:58,558 - INFO - epoch 2, step 16100, training loss = 2.208494, validation loss = 3.002004
2018-12-05 10:06:00,987 - INFO - epoch 2, step 16110, training loss = 2.542982, validation loss = 2.954081
2018-12-05 10:06:03,376 - INFO - epoch 2, step 16120, training loss = 1.974611, validation loss = 3.251025
2018-12-05 10:06:05,892 - INFO - epoch 2, step 16130, training loss = 2.471050, validation loss = 3.058287
2018-12-05 10:06:08,463 - INFO - epoch 2, step 16140, training loss = 1.990423, validation loss = 2.787811
2018-12-05 10:06:11,088 - INFO - epoch 2, step 16150, training loss = 2.062088, validation loss = 2.870516
2018-12-05 10:06:13,603 - INFO - epoch 2, step 16160, training loss = 2.146941, validation loss = 2.377990
2018-12-05 10:06:16,057 - INFO - epoch 2, step 16170, training loss = 1.887222, validation loss = 2.987547
2018-12-05 10:06:18,689 - INFO - epoch 2, step 16180, training loss = 2.537958, validation loss = 2.868384
2018-12-05 10:06:21,806 - INFO - epoch 2, step 16190, training loss = 2.546130, validation loss = 3.589774
2018-12-05 10:06:25,591 - INFO - epoch 2, step 16200, training loss = 2.580448, validation loss = 2.464436
2018-12-05 10:06:29,268 - INFO - epoch 2, step 16210, training loss = 2.955944, validation loss = 2.156279
2018-12-05 10:06:33,015 - INFO - epoch 2, step 16220, training loss = 2.200564, validation loss = 2.628241
2018-12-05 10:06:36,528 - INFO - epoch 2, step 16230, training loss = 2.558805, validation loss = 2.529702
2018-12-05 10:06:40,053 - INFO - epoch 2, step 16240, training loss = 2.604541, validation loss = 2.582586
2018-12-05 10:06:43,674 - INFO - epoch 2, step 16250, training loss = 2.338764, validation loss = 2.558069
2018-12-05 10:06:47,429 - INFO - epoch 2, step 16260, training loss = 2.676344, validation loss = 2.570394
2018-12-05 10:06:51,298 - INFO - epoch 2, step 16270, training loss = 2.638149, validation loss = 2.849637
2018-12-05 10:06:55,047 - INFO - epoch 2, step 16280, training loss = 2.646271, validation loss = 2.548895
2018-12-05 10:06:58,702 - INFO - epoch 2, step 16290, training loss = 2.504277, validation loss = 3.053724
2018-12-05 10:07:02,377 - INFO - epoch 2, step 16300, training loss = 2.282521, validation loss = 2.120556
2018-12-05 10:07:06,138 - INFO - epoch 2, step 16310, training loss = 2.190667, validation loss = 2.395910
2018-12-05 10:07:08,670 - INFO - epoch 2, step 16320, training loss = 2.321444, validation loss = 2.706176
2018-12-05 10:07:11,071 - INFO - epoch 2, step 16330, training loss = 2.255005, validation loss = 3.219998
2018-12-05 10:07:13,598 - INFO - epoch 2, step 16340, training loss = 2.314301, validation loss = 3.238183
2018-12-05 10:07:16,147 - INFO - epoch 2, step 16350, training loss = 2.270669, validation loss = 3.543314
2018-12-05 10:07:18,639 - INFO - epoch 2, step 16360, training loss = 2.065801, validation loss = 3.052031
2018-12-05 10:07:21,105 - INFO - epoch 2, step 16370, training loss = 2.251702, validation loss = 2.765857
2018-12-05 10:07:23,676 - INFO - epoch 2, step 16380, training loss = 2.495750, validation loss = 2.560746
2018-12-05 10:07:26,105 - INFO - epoch 2, step 16390, training loss = 2.368160, validation loss = 3.033490
2018-12-05 10:07:28,622 - INFO - epoch 2, step 16400, training loss = 2.091661, validation loss = 3.371121
2018-12-05 10:07:31,104 - INFO - epoch 2, step 16410, training loss = 2.028933, validation loss = 3.019419
2018-12-05 10:07:33,534 - INFO - epoch 2, step 16420, training loss = 2.267878, validation loss = 3.109370
2018-12-05 10:07:38,607 - INFO - epoch 2, step 16430, training loss = 2.676471, validation loss = 2.489440
2018-12-05 10:07:44,000 - INFO - epoch 2, step 16440, training loss = 2.302062, validation loss = 2.592189
2018-12-05 10:07:49,071 - INFO - epoch 2, step 16450, training loss = 2.215674, validation loss = 2.512452
2018-12-05 10:07:54,235 - INFO - epoch 2, step 16460, training loss = 2.189991, validation loss = 2.385079
2018-12-05 10:07:59,302 - INFO - epoch 2, step 16470, training loss = 2.287593, validation loss = 2.195365
2018-12-05 10:08:04,629 - INFO - epoch 2, step 16480, training loss = 2.702912, validation loss = 2.661128
2018-12-05 10:08:09,741 - INFO - epoch 2, step 16490, training loss = 2.294072, validation loss = 2.434429
2018-12-05 10:08:14,961 - INFO - epoch 2, step 16500, training loss = 2.541591, validation loss = 2.327846
2018-12-05 10:08:20,099 - INFO - epoch 2, step 16510, training loss = 2.270516, validation loss = 2.639487
2018-12-05 10:08:25,144 - INFO - epoch 2, step 16520, training loss = 2.146482, validation loss = 3.135506
2018-12-05 10:08:30,406 - INFO - epoch 2, step 16530, training loss = 2.453447, validation loss = 3.322078
2018-12-05 10:08:35,557 - INFO - epoch 2, step 16540, training loss = 1.961080, validation loss = 3.005789
2018-12-05 10:08:40,645 - INFO - epoch 2, step 16550, training loss = 2.521517, validation loss = 3.033840
2018-12-05 10:08:45,656 - INFO - epoch 2, step 16560, training loss = 2.707130, validation loss = 3.104773
2018-12-05 10:08:51,015 - INFO - epoch 2, step 16570, training loss = 2.273431, validation loss = 3.071408
2018-12-05 10:08:56,038 - INFO - epoch 2, step 16580, training loss = 2.131103, validation loss = 3.266629
2018-12-05 10:09:01,374 - INFO - epoch 2, step 16590, training loss = 2.101164, validation loss = 2.901797
2018-12-05 10:09:06,757 - INFO - epoch 2, step 16600, training loss = 2.784134, validation loss = 2.848978
2018-12-05 10:09:11,943 - INFO - epoch 2, step 16610, training loss = 2.329183, validation loss = 2.496096
2018-12-05 10:09:17,133 - INFO - epoch 2, step 16620, training loss = 2.324782, validation loss = 3.381931
2018-12-05 10:09:22,302 - INFO - epoch 2, step 16630, training loss = 2.205996, validation loss = 3.334000
2018-12-05 10:09:27,015 - INFO - epoch 2, step 16640, training loss = 1.929871, validation loss = 2.941089
2018-12-05 10:09:30,899 - INFO - epoch 2, step 16650, training loss = 2.192460, validation loss = 2.521994
2018-12-05 10:09:34,707 - INFO - epoch 2, step 16660, training loss = 2.034290, validation loss = 2.784215
2018-12-05 10:09:38,349 - INFO - epoch 2, step 16670, training loss = 1.818444, validation loss = 3.456085
2018-12-05 10:09:41,940 - INFO - epoch 2, step 16680, training loss = 1.993340, validation loss = 3.794358
2018-12-05 10:09:45,588 - INFO - epoch 2, step 16690, training loss = 2.520270, validation loss = 3.101604
2018-12-05 10:09:49,994 - INFO - epoch 2, step 16700, training loss = 2.217085, validation loss = 3.383002
2018-12-05 10:09:54,334 - INFO - epoch 2, step 16710, training loss = 2.269601, validation loss = 2.899958
2018-12-05 10:09:58,942 - INFO - epoch 2, step 16720, training loss = 2.428064, validation loss = 3.153055
2018-12-05 10:10:03,451 - INFO - epoch 2, step 16730, training loss = 2.529432, validation loss = 2.507103
2018-12-05 10:10:07,700 - INFO - epoch 2, step 16740, training loss = 2.091879, validation loss = 2.977194
2018-12-05 10:10:11,860 - INFO - epoch 2, step 16750, training loss = 2.377751, validation loss = 2.634591
2018-12-05 10:10:15,962 - INFO - epoch 2, step 16760, training loss = 2.072060, validation loss = 3.187742
2018-12-05 10:10:19,027 - INFO - epoch 2, step 16770, training loss = 2.135940, validation loss = 2.938591
2018-12-05 10:10:22,169 - INFO - epoch 2, step 16780, training loss = 2.059524, validation loss = 3.103193
2018-12-05 10:10:25,282 - INFO - epoch 2, step 16790, training loss = 2.129122, validation loss = 3.411968
2018-12-05 10:10:28,527 - INFO - epoch 2, step 16800, training loss = 2.450763, validation loss = 2.877640
2018-12-05 10:10:31,831 - INFO - epoch 2, step 16810, training loss = 1.937117, validation loss = 3.035224
2018-12-05 10:10:35,112 - INFO - epoch 2, step 16820, training loss = 2.502770, validation loss = 2.603748
2018-12-05 10:10:38,257 - INFO - epoch 2, step 16830, training loss = 2.431101, validation loss = 3.169411
2018-12-05 10:10:41,422 - INFO - epoch 2, step 16840, training loss = 2.186200, validation loss = 3.074602
2018-12-05 10:10:44,678 - INFO - epoch 2, step 16850, training loss = 2.358370, validation loss = 2.860490
2018-12-05 10:10:48,065 - INFO - epoch 2, step 16860, training loss = 2.020840, validation loss = 2.809828
2018-12-05 10:10:51,195 - INFO - epoch 2, step 16870, training loss = 1.736477, validation loss = 2.812893
2018-12-05 10:10:54,602 - INFO - epoch 2, step 16880, training loss = 2.488516, validation loss = 2.933235
2018-12-05 10:10:57,949 - INFO - epoch 2, step 16890, training loss = 2.040820, validation loss = 3.195489
2018-12-05 10:11:01,207 - INFO - epoch 2, step 16900, training loss = 2.389660, validation loss = 3.012468
2018-12-05 10:11:04,494 - INFO - epoch 2, step 16910, training loss = 2.173068, validation loss = 2.940254
2018-12-05 10:11:07,641 - INFO - epoch 2, step 16920, training loss = 2.492482, validation loss = 2.706738
2018-12-05 10:11:11,042 - INFO - epoch 2, step 16930, training loss = 2.444477, validation loss = 2.785070
2018-12-05 10:11:14,188 - INFO - epoch 2, step 16940, training loss = 1.846763, validation loss = 3.389791
2018-12-05 10:11:17,805 - INFO - epoch 2, step 16950, training loss = 2.264937, validation loss = 2.917141
2018-12-05 10:11:22,910 - INFO - epoch 2, step 16960, training loss = 2.220474, validation loss = 3.034135
2018-12-05 10:11:27,557 - INFO - epoch 2, step 16970, training loss = 2.791162, validation loss = 3.407413
2018-12-05 10:11:32,568 - INFO - epoch 2, step 16980, training loss = 2.070089, validation loss = 2.929625
2018-12-05 10:11:37,258 - INFO - epoch 2, step 16990, training loss = 2.486994, validation loss = 3.079889
2018-12-05 10:11:42,057 - INFO - epoch 2, step 17000, training loss = 2.624984, validation loss = 3.270073
2018-12-05 10:11:46,923 - INFO - epoch 2, step 17010, training loss = 2.266791, validation loss = 3.152259
2018-12-05 10:11:51,612 - INFO - epoch 2, step 17020, training loss = 2.283107, validation loss = 3.072131
2018-12-05 10:11:56,407 - INFO - epoch 2, step 17030, training loss = 2.084180, validation loss = 2.878151
2018-12-05 10:12:01,306 - INFO - epoch 2, step 17040, training loss = 1.858653, validation loss = 2.444428
2018-12-05 10:12:05,957 - INFO - epoch 2, step 17050, training loss = 2.041639, validation loss = 3.139210
2018-12-05 10:12:10,602 - INFO - epoch 2, step 17060, training loss = 2.661052, validation loss = 2.951985
2018-12-05 10:12:15,643 - INFO - epoch 2, step 17070, training loss = 2.489008, validation loss = 2.905798
2018-12-05 10:12:21,007 - INFO - epoch 2, step 17080, training loss = 2.338662, validation loss = 3.060485
2018-12-05 10:12:26,009 - INFO - epoch 2, step 17090, training loss = 1.908305, validation loss = 2.904336
2018-12-05 10:12:31,143 - INFO - epoch 2, step 17100, training loss = 1.993428, validation loss = 3.496840
2018-12-05 10:12:36,376 - INFO - epoch 2, step 17110, training loss = 2.364574, validation loss = 3.250843
2018-12-05 10:12:41,631 - INFO - epoch 2, step 17120, training loss = 2.227236, validation loss = 2.701980
2018-12-05 10:12:46,644 - INFO - epoch 2, step 17130, training loss = 2.176976, validation loss = 3.410583
2018-12-05 10:12:51,794 - INFO - epoch 2, step 17140, training loss = 2.290390, validation loss = 3.353672
2018-12-05 10:12:57,105 - INFO - epoch 2, step 17150, training loss = 1.999391, validation loss = 2.840145
2018-12-05 10:13:02,150 - INFO - epoch 2, step 17160, training loss = 1.949757, validation loss = 3.640952
2018-12-05 10:13:07,126 - INFO - epoch 2, step 17170, training loss = 2.469682, validation loss = 3.676435
2018-12-05 10:13:11,959 - INFO - epoch 2, step 17180, training loss = 1.960438, validation loss = 3.388683
2018-12-05 10:13:17,132 - INFO - epoch 2, step 17190, training loss = 1.946536, validation loss = 3.358344
2018-12-05 10:13:22,411 - INFO - epoch 2, step 17200, training loss = 2.157129, validation loss = 2.985887
2018-12-05 10:13:27,618 - INFO - epoch 2, step 17210, training loss = 2.061978, validation loss = 3.461815
2018-12-05 10:13:32,699 - INFO - epoch 2, step 17220, training loss = 2.421609, validation loss = 3.928706
2018-12-05 10:13:37,931 - INFO - epoch 2, step 17230, training loss = 2.488804, validation loss = 3.475418
2018-12-05 10:13:42,900 - INFO - epoch 2, step 17240, training loss = 2.375103, validation loss = 3.792597
2018-12-05 10:13:48,130 - INFO - epoch 2, step 17250, training loss = 2.234528, validation loss = 3.905124
2018-12-05 10:13:53,096 - INFO - epoch 2, step 17260, training loss = 1.936677, validation loss = 4.242191
2018-12-05 10:13:58,247 - INFO - epoch 2, step 17270, training loss = 2.149163, validation loss = 3.597431
2018-12-05 10:14:03,275 - INFO - epoch 2, step 17280, training loss = 2.302613, validation loss = 3.633683
2018-12-05 10:14:08,193 - INFO - epoch 2, step 17290, training loss = 2.153855, validation loss = 3.947299
2018-12-05 10:14:13,517 - INFO - epoch 2, step 17300, training loss = 1.768502, validation loss = 3.498351
2018-12-05 10:14:18,564 - INFO - epoch 2, step 17310, training loss = 1.901106, validation loss = 3.561946
2018-12-05 10:14:23,588 - INFO - epoch 2, step 17320, training loss = 1.817426, validation loss = 3.464089
2018-12-05 10:14:28,652 - INFO - epoch 2, step 17330, training loss = 2.575616, validation loss = 3.171475
2018-12-05 10:14:33,696 - INFO - epoch 2, step 17340, training loss = 1.974038, validation loss = 3.513340
2018-12-05 10:14:39,145 - INFO - epoch 2, step 17350, training loss = 2.347355, validation loss = 3.233593
2018-12-05 10:14:44,427 - INFO - epoch 2, step 17360, training loss = 2.254256, validation loss = 3.278934
2018-12-05 10:14:49,461 - INFO - epoch 2, step 17370, training loss = 2.169651, validation loss = 2.877455
2018-12-05 10:14:53,706 - INFO - epoch 2, step 17380, training loss = 2.164356, validation loss = 3.824723
2018-12-05 10:14:57,831 - INFO - epoch 2, step 17390, training loss = 1.996731, validation loss = 3.456757
2018-12-05 10:15:02,228 - INFO - epoch 2, step 17400, training loss = 1.638611, validation loss = 3.008051
2018-12-05 10:15:06,789 - INFO - epoch 2, step 17410, training loss = 2.315019, validation loss = 3.032106
2018-12-05 10:15:10,352 - INFO - epoch 2, step 17420, training loss = 2.829741, validation loss = 3.484884
2018-12-05 10:15:12,894 - INFO - epoch 2, step 17430, training loss = 2.510549, validation loss = 3.531270
2018-12-05 10:15:15,476 - INFO - epoch 2, step 17440, training loss = 2.586502, validation loss = 3.399854
2018-12-05 10:15:18,047 - INFO - epoch 2, step 17450, training loss = 2.372243, validation loss = 3.186578
2018-12-05 10:15:20,886 - INFO - epoch 2, step 17460, training loss = 2.355834, validation loss = 3.577327
2018-12-05 10:15:23,721 - INFO - epoch 2, step 17470, training loss = 2.110147, validation loss = 3.313850
2018-12-05 10:15:26,408 - INFO - epoch 2, step 17480, training loss = 2.024768, validation loss = 3.186629
2018-12-05 10:15:29,257 - INFO - epoch 2, step 17490, training loss = 2.232183, validation loss = 3.325397
2018-12-05 10:15:33,155 - INFO - epoch 2, step 17500, training loss = 2.845716, validation loss = 3.661968
2018-12-05 10:15:37,205 - INFO - epoch 2, step 17510, training loss = 2.170399, validation loss = 3.264263
2018-12-05 10:15:41,345 - INFO - epoch 2, step 17520, training loss = 2.582602, validation loss = 3.336600
2018-12-05 10:15:45,560 - INFO - epoch 2, step 17530, training loss = 1.985839, validation loss = 2.843268
2018-12-05 10:15:49,545 - INFO - epoch 2, step 17540, training loss = 2.194730, validation loss = 3.860434
2018-12-05 10:15:54,430 - INFO - epoch 2, step 17550, training loss = 2.523994, validation loss = 3.229400
2018-12-05 10:15:59,691 - INFO - epoch 2, step 17560, training loss = 2.597414, validation loss = 3.494330
2018-12-05 10:16:04,837 - INFO - epoch 2, step 17570, training loss = 2.467406, validation loss = 3.484196
2018-12-05 10:16:10,289 - INFO - epoch 2, step 17580, training loss = 2.627438, validation loss = 3.967731
2018-12-05 10:16:15,595 - INFO - epoch 2, step 17590, training loss = 1.884244, validation loss = 3.353372
2018-12-05 10:16:21,030 - INFO - epoch 2, step 17600, training loss = 2.350431, validation loss = 3.293358
2018-12-05 10:16:26,338 - INFO - epoch 2, step 17610, training loss = 2.149048, validation loss = 3.288547
2018-12-05 10:16:31,543 - INFO - epoch 2, step 17620, training loss = 2.834746, validation loss = 3.174467
2018-12-05 10:16:36,951 - INFO - epoch 2, step 17630, training loss = 2.180397, validation loss = 3.267904
2018-12-05 10:16:42,271 - INFO - epoch 2, step 17640, training loss = 2.091229, validation loss = 3.251897
2018-12-05 10:16:47,434 - INFO - epoch 2, step 17650, training loss = 2.610449, validation loss = 3.786095
2018-12-05 10:16:52,501 - INFO - epoch 2, step 17660, training loss = 2.349934, validation loss = 3.210507
2018-12-05 10:16:57,675 - INFO - epoch 2, step 17670, training loss = 2.464543, validation loss = 3.559991
2018-12-05 10:17:03,020 - INFO - epoch 2, step 17680, training loss = 2.086050, validation loss = 3.929686
2018-12-05 10:17:08,534 - INFO - epoch 2, step 17690, training loss = 2.255216, validation loss = 3.421039
2018-12-05 10:17:13,870 - INFO - epoch 2, step 17700, training loss = 2.221186, validation loss = 3.093256
2018-12-05 10:17:19,246 - INFO - epoch 2, step 17710, training loss = 2.408752, validation loss = 3.270162
2018-12-05 10:17:24,765 - INFO - epoch 2, step 17720, training loss = 2.172982, validation loss = 3.364394
2018-12-05 10:17:30,039 - INFO - epoch 2, step 17730, training loss = 2.314049, validation loss = 3.874315
2018-12-05 10:17:35,404 - INFO - epoch 2, step 17740, training loss = 2.279008, validation loss = 3.574969
2018-12-05 10:17:40,760 - INFO - epoch 2, step 17750, training loss = 2.457988, validation loss = 3.607567
2018-12-05 10:17:45,533 - INFO - epoch 2, step 17760, training loss = 1.862820, validation loss = 4.011001
2018-12-05 10:17:49,742 - INFO - epoch 2, step 17770, training loss = 2.007140, validation loss = 3.580403
2018-12-05 10:17:54,046 - INFO - epoch 2, step 17780, training loss = 1.888914, validation loss = 3.863543
2018-12-05 10:17:58,218 - INFO - epoch 2, step 17790, training loss = 2.155762, validation loss = 3.188902
2018-12-05 10:18:02,545 - INFO - epoch 2, step 17800, training loss = 2.388908, validation loss = 3.286958
2018-12-05 10:18:07,077 - INFO - epoch 2, step 17810, training loss = 2.026857, validation loss = 3.319107
2018-12-05 10:18:11,065 - INFO - epoch 2, step 17820, training loss = 2.077542, validation loss = 3.109627
2018-12-05 10:18:14,383 - INFO - epoch 2, step 17830, training loss = 2.288174, validation loss = 3.806053
2018-12-05 10:18:17,754 - INFO - epoch 2, step 17840, training loss = 2.016751, validation loss = 3.913680
2018-12-05 10:18:21,108 - INFO - epoch 2, step 17850, training loss = 2.009100, validation loss = 3.361461
2018-12-05 10:18:24,329 - INFO - epoch 2, step 17860, training loss = 2.112530, validation loss = 3.747806
2018-12-05 10:18:27,409 - INFO - epoch 2, step 17870, training loss = 2.055519, validation loss = 3.278816
2018-12-05 10:18:30,638 - INFO - epoch 2, step 17880, training loss = 2.382805, validation loss = 3.136724
2018-12-05 10:18:33,908 - INFO - epoch 2, step 17890, training loss = 2.156297, validation loss = 3.285146
2018-12-05 10:18:37,063 - INFO - epoch 2, step 17900, training loss = 2.421613, validation loss = 3.907392
2018-12-05 10:18:40,076 - INFO - epoch 2, step 17910, training loss = 2.480943, validation loss = 3.929672
2018-12-05 10:18:43,288 - INFO - epoch 2, step 17920, training loss = 2.622970, validation loss = 3.591498
2018-12-05 10:18:46,329 - INFO - epoch 2, step 17930, training loss = 2.774525, validation loss = 3.425507
2018-12-05 10:18:49,545 - INFO - epoch 2, step 17940, training loss = 2.580030, validation loss = 3.366182
2018-12-05 10:18:52,711 - INFO - epoch 2, step 17950, training loss = 2.307444, validation loss = 3.708373
2018-12-05 10:18:55,831 - INFO - epoch 2, step 17960, training loss = 2.189869, validation loss = 3.632670
2018-12-05 10:18:59,115 - INFO - epoch 2, step 17970, training loss = 1.951052, validation loss = 3.041887
2018-12-05 10:19:02,413 - INFO - epoch 2, step 17980, training loss = 2.234808, validation loss = 3.336443
2018-12-05 10:19:05,520 - INFO - epoch 2, step 17990, training loss = 2.247438, validation loss = 3.779733
2018-12-05 10:19:08,662 - INFO - epoch 2, step 18000, training loss = 2.198921, validation loss = 3.327686
2018-12-05 10:19:11,932 - INFO - epoch 2, step 18010, training loss = 2.466621, validation loss = 3.504190
2018-12-05 10:19:15,066 - INFO - epoch 2, step 18020, training loss = 2.052282, validation loss = 3.483953
2018-12-05 10:19:17,476 - INFO - epoch 2, step 18030, training loss = 2.355652, validation loss = 3.725173
2018-12-05 10:19:19,954 - INFO - epoch 2, step 18040, training loss = 2.009052, validation loss = 3.720646
2018-12-05 10:19:22,438 - INFO - epoch 2, step 18050, training loss = 2.106881, validation loss = 3.467043
2018-12-05 10:19:24,899 - INFO - epoch 2, step 18060, training loss = 2.335355, validation loss = 3.803189
2018-12-05 10:19:27,282 - INFO - epoch 2, step 18070, training loss = 2.504963, validation loss = 3.567928
2018-12-05 10:19:29,850 - INFO - epoch 2, step 18080, training loss = 1.959137, validation loss = 3.690548
2018-12-05 10:19:32,359 - INFO - epoch 2, step 18090, training loss = 1.867812, validation loss = 3.722775
2018-12-05 10:19:34,893 - INFO - epoch 2, step 18100, training loss = 2.177299, validation loss = 4.011889
2018-12-05 10:19:38,804 - INFO - epoch 2, step 18110, training loss = 2.520654, validation loss = 3.636672
2018-12-05 10:19:44,169 - INFO - epoch 2, step 18120, training loss = 2.136643, validation loss = 3.562816
2018-12-05 10:19:49,413 - INFO - epoch 2, step 18130, training loss = 1.948149, validation loss = 3.677015
2018-12-05 10:19:54,667 - INFO - epoch 2, step 18140, training loss = 2.060993, validation loss = 3.438003
2018-12-05 10:20:00,801 - INFO - epoch 2, step 18150, training loss = 2.196671, validation loss = 3.327370
2018-12-05 10:20:06,077 - INFO - epoch 2, step 18160, training loss = 1.817538, validation loss = 3.387029
2018-12-05 10:20:11,397 - INFO - epoch 2, step 18170, training loss = 1.893818, validation loss = 3.245245
2018-12-05 10:20:16,474 - INFO - epoch 2, step 18180, training loss = 2.142724, validation loss = 3.883673
2018-12-05 10:20:21,487 - INFO - epoch 2, step 18190, training loss = 2.232103, validation loss = 4.064161
2018-12-05 10:20:26,874 - INFO - epoch 2, step 18200, training loss = 1.986556, validation loss = 3.408036
2018-12-05 10:20:32,071 - INFO - epoch 2, step 18210, training loss = 2.118235, validation loss = 3.912228
2018-12-05 10:20:37,054 - INFO - epoch 2, step 18220, training loss = 2.178040, validation loss = 3.958090
2018-12-05 10:20:42,103 - INFO - epoch 2, step 18230, training loss = 1.904218, validation loss = 3.466001
2018-12-05 10:20:47,186 - INFO - epoch 2, step 18240, training loss = 2.121757, validation loss = 3.304560
2018-12-05 10:20:52,317 - INFO - epoch 2, step 18250, training loss = 2.428369, validation loss = 3.114119
2018-12-05 10:20:57,460 - INFO - epoch 2, step 18260, training loss = 2.221147, validation loss = 2.698510
2018-12-05 10:21:02,643 - INFO - epoch 2, step 18270, training loss = 2.029881, validation loss = 3.868669
2018-12-05 10:21:07,926 - INFO - epoch 2, step 18280, training loss = 1.986197, validation loss = 3.433209
2018-12-05 10:21:12,950 - INFO - epoch 2, step 18290, training loss = 2.528252, validation loss = 3.212532
2018-12-05 10:21:18,081 - INFO - epoch 2, step 18300, training loss = 2.556802, validation loss = 2.992055
2018-12-05 10:21:23,060 - INFO - epoch 2, step 18310, training loss = 1.803989, validation loss = 3.767465
2018-12-05 10:21:28,458 - INFO - epoch 2, step 18320, training loss = 2.174239, validation loss = 3.874379
2018-12-05 10:21:33,734 - INFO - epoch 2, step 18330, training loss = 2.145975, validation loss = 3.373238
2018-12-05 10:21:39,042 - INFO - epoch 2, step 18340, training loss = 1.786298, validation loss = 3.487882
2018-12-05 10:21:44,218 - INFO - epoch 2, step 18350, training loss = 2.171458, validation loss = 3.437234
2018-12-05 10:21:49,155 - INFO - epoch 2, step 18360, training loss = 2.468624, validation loss = 3.442328
2018-12-05 10:21:52,529 - INFO - epoch 2, step 18370, training loss = 2.358561, validation loss = 3.495566
2018-12-05 10:21:55,646 - INFO - epoch 2, step 18380, training loss = 2.204178, validation loss = 3.036877
2018-12-05 10:21:58,870 - INFO - epoch 2, step 18390, training loss = 1.897621, validation loss = 3.542104
2018-12-05 10:22:02,084 - INFO - epoch 2, step 18400, training loss = 2.384907, validation loss = 3.347152
2018-12-05 10:22:05,121 - INFO - epoch 2, step 18410, training loss = 2.221050, validation loss = 3.918124
2018-12-05 10:22:08,216 - INFO - epoch 2, step 18420, training loss = 1.832297, validation loss = 3.391335
2018-12-05 10:22:11,226 - INFO - epoch 2, step 18430, training loss = 2.335869, validation loss = 3.342356
2018-12-05 10:22:14,261 - INFO - epoch 2, step 18440, training loss = 2.135960, validation loss = 3.744235
2018-12-05 10:22:17,294 - INFO - epoch 2, step 18450, training loss = 2.561137, validation loss = 3.654167
2018-12-05 10:22:20,538 - INFO - epoch 2, step 18460, training loss = 1.503581, validation loss = 3.821912
2018-12-05 10:22:23,743 - INFO - epoch 2, step 18470, training loss = 2.149745, validation loss = 3.357665
2018-12-05 10:22:26,917 - INFO - epoch 2, step 18480, training loss = 2.125868, validation loss = 3.303065
2018-12-05 10:22:30,268 - INFO - epoch 2, step 18490, training loss = 1.862644, validation loss = 3.370893
2018-12-05 10:22:33,539 - INFO - epoch 2, step 18500, training loss = 2.038968, validation loss = 3.421328
2018-12-05 10:22:36,797 - INFO - epoch 2, step 18510, training loss = 2.055778, validation loss = 3.161552
2018-12-05 10:22:39,854 - INFO - epoch 2, step 18520, training loss = 2.817682, validation loss = 3.115526
2018-12-05 10:22:43,208 - INFO - epoch 2, step 18530, training loss = 2.024563, validation loss = 3.619370
2018-12-05 10:22:46,534 - INFO - epoch 2, step 18540, training loss = 1.916626, validation loss = 3.066555
2018-12-05 10:22:49,660 - INFO - epoch 2, step 18550, training loss = 1.658263, validation loss = 4.067775
2018-12-05 10:22:52,845 - INFO - epoch 2, step 18560, training loss = 1.815309, validation loss = 3.711159
2018-12-05 10:22:56,443 - INFO - epoch 2, step 18570, training loss = 1.624716, validation loss = 3.137356
2018-12-05 10:22:59,735 - INFO - epoch 2, step 18580, training loss = 1.815495, validation loss = 3.490665
2018-12-05 10:23:03,248 - INFO - epoch 2, step 18590, training loss = 2.511249, validation loss = 3.372761
2018-12-05 10:23:06,947 - INFO - epoch 2, step 18600, training loss = 2.189064, validation loss = 3.545210
2018-12-05 10:23:10,446 - INFO - epoch 2, step 18610, training loss = 2.280053, validation loss = 3.746867
2018-12-05 10:23:14,840 - INFO - epoch 2, step 18620, training loss = 2.143313, validation loss = 3.379780
2018-12-05 10:23:19,846 - INFO - epoch 2, step 18630, training loss = 2.385462, validation loss = 3.438101
2018-12-05 10:23:25,068 - INFO - epoch 2, step 18640, training loss = 2.126931, validation loss = 3.546655
2018-12-05 10:23:30,307 - INFO - epoch 2, step 18650, training loss = 2.470669, validation loss = 3.217928
2018-12-05 10:23:35,354 - INFO - epoch 2, step 18660, training loss = 2.092313, validation loss = 3.417778
2018-12-05 10:23:40,799 - INFO - epoch 2, step 18670, training loss = 2.241568, validation loss = 3.182338
2018-12-05 10:23:45,984 - INFO - epoch 2, step 18680, training loss = 2.306371, validation loss = 3.344888
2018-12-05 10:23:50,953 - INFO - epoch 2, step 18690, training loss = 2.201949, validation loss = 3.227922
2018-12-05 10:23:55,940 - INFO - epoch 2, step 18700, training loss = 2.173586, validation loss = 3.384144
2018-12-05 10:24:00,879 - INFO - epoch 2, step 18710, training loss = 2.417305, validation loss = 3.296531
2018-12-05 10:24:06,157 - INFO - epoch 2, step 18720, training loss = 2.104981, validation loss = 3.697491
2018-12-05 10:24:11,493 - INFO - epoch 2, step 18730, training loss = 2.106771, validation loss = 3.351744
2018-12-05 10:24:16,674 - INFO - epoch 2, step 18740, training loss = 1.474529, validation loss = 3.403948
2018-12-05 10:24:20,994 - INFO - epoch 2, step 18750, training loss = 2.807126, validation loss = 3.332940
2018-12-05 10:24:24,071 - INFO - epoch 2, step 18760, training loss = 2.644151, validation loss = 3.657271
2018-12-05 10:24:27,240 - INFO - epoch 2, step 18770, training loss = 2.214611, validation loss = 3.380912
2018-12-05 10:24:30,472 - INFO - epoch 2, step 18780, training loss = 1.652195, validation loss = 3.363209
2018-12-05 10:24:34,063 - INFO - epoch 2, step 18790, training loss = 1.957178, validation loss = 3.457148
2018-12-05 10:24:37,204 - INFO - epoch 2, step 18800, training loss = 2.540426, validation loss = 3.269425
2018-12-05 10:24:40,242 - INFO - epoch 2, step 18810, training loss = 2.399900, validation loss = 3.341012
2018-12-05 10:24:43,277 - INFO - epoch 2, step 18820, training loss = 1.983118, validation loss = 3.100390
2018-12-05 10:24:46,298 - INFO - epoch 2, step 18830, training loss = 2.148271, validation loss = 3.511913
2018-12-05 10:24:49,530 - INFO - epoch 2, step 18840, training loss = 2.348429, validation loss = 3.094316
2018-12-05 10:24:52,695 - INFO - epoch 2, step 18850, training loss = 1.791614, validation loss = 3.705732
2018-12-05 10:24:55,872 - INFO - epoch 2, step 18860, training loss = 2.301430, validation loss = 3.538731
2018-12-05 10:24:58,954 - INFO - epoch 2, step 18870, training loss = 1.730216, validation loss = 3.119311
2018-12-05 10:25:01,957 - INFO - epoch 2, step 18880, training loss = 2.179672, validation loss = 3.682033
2018-12-05 10:25:05,138 - INFO - epoch 2, step 18890, training loss = 2.343331, validation loss = 3.205965
2018-12-05 10:25:08,399 - INFO - epoch 2, step 18900, training loss = 2.044954, validation loss = 2.985667
2018-12-05 10:25:11,836 - INFO - epoch 2, step 18910, training loss = 1.694823, validation loss = 3.543694
2018-12-05 10:25:14,851 - INFO - epoch 2, step 18920, training loss = 2.051670, validation loss = 3.725450
2018-12-05 10:25:18,002 - INFO - epoch 2, step 18930, training loss = 2.255506, validation loss = 3.324755
2018-12-05 10:25:21,058 - INFO - epoch 2, step 18940, training loss = 1.890753, validation loss = 3.085113
2018-12-05 10:25:24,159 - INFO - epoch 2, step 18950, training loss = 1.496753, validation loss = 3.134120
2018-12-05 10:25:27,383 - INFO - epoch 2, step 18960, training loss = 1.948832, validation loss = 3.345039
2018-12-05 10:25:31,877 - INFO - epoch 2, step 18970, training loss = 1.997036, validation loss = 3.081380
2018-12-05 10:25:36,117 - INFO - epoch 2, step 18980, training loss = 2.315683, validation loss = 3.706690
2018-12-05 10:25:40,181 - INFO - epoch 2, step 18990, training loss = 2.160156, validation loss = 3.114786
2018-12-05 10:25:44,671 - INFO - epoch 2, step 19000, training loss = 2.023269, validation loss = 3.215352
2018-12-05 10:25:49,124 - INFO - epoch 2, step 19010, training loss = 2.298936, validation loss = 3.426201
2018-12-05 10:25:53,226 - INFO - epoch 2, step 19020, training loss = 2.559705, validation loss = 3.458162
2018-12-05 10:25:56,826 - INFO - epoch 2, step 19030, training loss = 2.515672, validation loss = 2.790245
2018-12-05 10:26:00,042 - INFO - epoch 2, step 19040, training loss = 1.978981, validation loss = 3.395823
2018-12-05 10:26:03,267 - INFO - epoch 2, step 19050, training loss = 2.016018, validation loss = 3.706923
2018-12-05 10:26:06,350 - INFO - epoch 2, step 19060, training loss = 2.229644, validation loss = 3.388664
2018-12-05 10:26:09,485 - INFO - epoch 2, step 19070, training loss = 1.899569, validation loss = 3.561705
2018-12-05 10:26:12,645 - INFO - epoch 2, step 19080, training loss = 2.699505, validation loss = 3.497212
2018-12-05 10:26:15,690 - INFO - epoch 2, step 19090, training loss = 2.263782, validation loss = 3.609833
2018-12-05 10:26:18,869 - INFO - epoch 2, step 19100, training loss = 1.923244, validation loss = 3.749469
2018-12-05 10:26:21,850 - INFO - epoch 2, step 19110, training loss = 2.161065, validation loss = 3.720179
2018-12-05 10:26:24,922 - INFO - epoch 2, step 19120, training loss = 2.409692, validation loss = 3.439729
2018-12-05 10:26:28,072 - INFO - epoch 2, step 19130, training loss = 1.992676, validation loss = 3.686381
2018-12-05 10:26:31,232 - INFO - epoch 2, step 19140, training loss = 1.898561, validation loss = 3.710319
2018-12-05 10:26:34,401 - INFO - epoch 2, step 19150, training loss = 1.905847, validation loss = 2.935320
2018-12-05 10:26:37,567 - INFO - epoch 2, step 19160, training loss = 2.130420, validation loss = 3.018422
2018-12-05 10:26:40,724 - INFO - epoch 2, step 19170, training loss = 2.013451, validation loss = 3.484873
2018-12-05 10:26:43,765 - INFO - epoch 2, step 19180, training loss = 2.074813, validation loss = 3.324928
2018-12-05 10:26:47,000 - INFO - epoch 2, step 19190, training loss = 1.780138, validation loss = 3.185769
2018-12-05 10:26:50,339 - INFO - epoch 2, step 19200, training loss = 2.436537, validation loss = 3.286636
2018-12-05 10:26:53,453 - INFO - epoch 2, step 19210, training loss = 2.684714, validation loss = 3.225833
2018-12-05 10:26:56,417 - INFO - epoch 2, step 19220, training loss = 2.539354, validation loss = 3.637435
2018-12-05 10:27:00,860 - INFO - epoch 2, step 19230, training loss = 2.987983, validation loss = 3.369511
2018-12-05 10:27:05,910 - INFO - epoch 2, step 19240, training loss = 2.404558, validation loss = 3.370389
2018-12-05 10:27:11,458 - INFO - epoch 2, step 19250, training loss = 2.266716, validation loss = 3.424013
2018-12-05 10:27:16,486 - INFO - epoch 2, step 19260, training loss = 2.134142, validation loss = 3.810356
2018-12-05 10:27:21,649 - INFO - epoch 2, step 19270, training loss = 2.209305, validation loss = 3.110277
2018-12-05 10:27:26,607 - INFO - epoch 2, step 19280, training loss = 1.929313, validation loss = 3.656858
2018-12-05 10:27:31,495 - INFO - epoch 2, step 19290, training loss = 2.536355, validation loss = 3.788390
2018-12-05 10:27:36,701 - INFO - epoch 2, step 19300, training loss = 2.593103, validation loss = 3.785151
2018-12-05 10:27:41,848 - INFO - epoch 2, step 19310, training loss = 2.055689, validation loss = 3.371600
2018-12-05 10:27:46,975 - INFO - epoch 2, step 19320, training loss = 1.897604, validation loss = 3.368444
2018-12-05 10:27:52,095 - INFO - epoch 2, step 19330, training loss = 1.896893, validation loss = 3.387046
2018-12-05 10:27:57,104 - INFO - epoch 2, step 19340, training loss = 2.416404, validation loss = 3.771250
2018-12-05 10:28:02,229 - INFO - epoch 2, step 19350, training loss = 1.726247, validation loss = 3.180853
2018-12-05 10:28:07,920 - INFO - epoch 2, step 19360, training loss = 1.906089, validation loss = 3.396295
2018-12-05 10:28:13,938 - INFO - epoch 2, step 19370, training loss = 1.665413, validation loss = 3.180373
2018-12-05 10:28:20,002 - INFO - epoch 2, step 19380, training loss = 1.667623, validation loss = 2.809304
2018-12-05 10:28:26,042 - INFO - epoch 2, step 19390, training loss = 1.874758, validation loss = 3.425720
2018-12-05 10:28:31,591 - INFO - epoch 2, step 19400, training loss = 1.740066, validation loss = 3.507564
2018-12-05 10:28:37,370 - INFO - epoch 2, step 19410, training loss = 1.849256, validation loss = 3.137538
2018-12-05 10:28:43,676 - INFO - epoch 2, step 19420, training loss = 2.025713, validation loss = 3.249004
2018-12-05 10:28:49,139 - INFO - epoch 2, step 19430, training loss = 1.889241, validation loss = 3.465882
2018-12-05 10:28:54,611 - INFO - epoch 2, step 19440, training loss = 2.204100, validation loss = 3.163256
2018-12-05 10:28:59,887 - INFO - epoch 2, step 19450, training loss = 1.872269, validation loss = 3.643427
2018-12-05 10:29:05,324 - INFO - epoch 2, step 19460, training loss = 2.180876, validation loss = 3.346555
2018-12-05 10:29:11,541 - INFO - epoch 2, step 19470, training loss = 2.008335, validation loss = 3.473568
2018-12-05 10:29:17,179 - INFO - epoch 2, step 19480, training loss = 2.126692, validation loss = 3.617836
2018-12-05 10:29:23,081 - INFO - epoch 2, step 19490, training loss = 1.920863, validation loss = 3.323032
2018-12-05 10:29:29,231 - INFO - epoch 2, step 19500, training loss = 2.000430, validation loss = 3.309576
2018-12-05 10:29:35,178 - INFO - epoch 2, step 19510, training loss = 1.496462, validation loss = 3.779275
2018-12-05 10:29:41,240 - INFO - epoch 2, step 19520, training loss = 1.432764, validation loss = 3.137887
2018-12-05 10:29:47,484 - INFO - epoch 2, step 19530, training loss = 2.048602, validation loss = 3.234389
2018-12-05 10:29:51,564 - INFO - epoch 2, step 19540, training loss = 2.215550, validation loss = 3.554164
2018-12-05 10:29:56,093 - INFO - epoch 2, step 19550, training loss = 1.963157, validation loss = 3.452232
2018-12-05 10:30:00,337 - INFO - epoch 2, step 19560, training loss = 2.392049, validation loss = 3.210461
2018-12-05 10:30:04,477 - INFO - epoch 2, step 19570, training loss = 1.959777, validation loss = 2.991168
2018-12-05 10:30:08,911 - INFO - epoch 2, step 19580, training loss = 2.368717, validation loss = 2.843061
2018-12-05 10:30:13,216 - INFO - epoch 2, step 19590, training loss = 2.085063, validation loss = 2.631853
2018-12-05 10:30:17,455 - INFO - epoch 2, step 19600, training loss = 2.508778, validation loss = 3.247134
2018-12-05 10:30:21,561 - INFO - epoch 2, step 19610, training loss = 2.206966, validation loss = 3.377865
2018-12-05 10:30:25,791 - INFO - epoch 2, step 19620, training loss = 2.436094, validation loss = 3.249360
2018-12-05 10:30:30,200 - INFO - epoch 2, step 19630, training loss = 1.938226, validation loss = 2.877758
2018-12-05 10:30:34,465 - INFO - epoch 2, step 19640, training loss = 2.114090, validation loss = 3.073538
2018-12-05 10:30:38,877 - INFO - epoch 2, step 19650, training loss = 2.293932, validation loss = 3.459857
2018-12-05 10:30:44,324 - INFO - epoch 2, step 19660, training loss = 1.931202, validation loss = 3.039594
2018-12-05 10:30:49,898 - INFO - epoch 2, step 19670, training loss = 1.916967, validation loss = 3.784629
2018-12-05 10:30:55,162 - INFO - epoch 2, step 19680, training loss = 1.862466, validation loss = 3.576550
2018-12-05 10:31:00,285 - INFO - epoch 2, step 19690, training loss = 1.851473, validation loss = 3.349968
2018-12-05 10:31:06,078 - INFO - epoch 2, step 19700, training loss = 1.606836, validation loss = 4.026513
2018-12-05 10:31:11,842 - INFO - epoch 2, step 19710, training loss = 1.743620, validation loss = 3.126943
2018-12-05 10:31:17,211 - INFO - epoch 2, step 19720, training loss = 2.079409, validation loss = 3.375858
2018-12-05 10:31:23,382 - INFO - epoch 2, step 19730, training loss = 1.900040, validation loss = 3.257375
2018-12-05 10:31:29,042 - INFO - epoch 2, step 19740, training loss = 1.943695, validation loss = 3.471077
2018-12-05 10:31:34,386 - INFO - epoch 2, step 19750, training loss = 2.428150, validation loss = 3.140398
2018-12-05 10:31:39,583 - INFO - epoch 2, step 19760, training loss = 1.769235, validation loss = 3.468066
2018-12-05 10:31:45,147 - INFO - epoch 2, step 19770, training loss = 1.996565, validation loss = 3.512954
2018-12-05 10:31:50,859 - INFO - epoch 2, step 19780, training loss = 1.881752, validation loss = 3.339226
2018-12-05 10:31:56,700 - INFO - epoch 2, step 19790, training loss = 2.126821, validation loss = 3.138794
2018-12-05 10:32:01,951 - INFO - epoch 2, step 19800, training loss = 2.172049, validation loss = 3.304263
2018-12-05 10:32:07,656 - INFO - epoch 2, step 19810, training loss = 2.288978, validation loss = 4.256012
2018-12-05 10:32:13,333 - INFO - epoch 2, step 19820, training loss = 2.203305, validation loss = 2.777148
2018-12-05 10:32:18,991 - INFO - epoch 2, step 19830, training loss = 1.994019, validation loss = 3.429266
2018-12-05 10:32:24,425 - INFO - epoch 2, step 19840, training loss = 1.837184, validation loss = 3.176032
2018-12-05 10:32:30,010 - INFO - epoch 2, step 19850, training loss = 1.887766, validation loss = 2.864942
2018-12-05 10:32:35,600 - INFO - epoch 2, step 19860, training loss = 2.070700, validation loss = 3.198091
2018-12-05 10:32:41,354 - INFO - epoch 2, step 19870, training loss = 1.804150, validation loss = 3.565907
2018-12-05 10:32:46,329 - INFO - epoch 2, step 19880, training loss = 2.513177, validation loss = 3.356965
2018-12-05 10:32:49,580 - INFO - epoch 2, step 19890, training loss = 2.334529, validation loss = 3.186164
2018-12-05 10:32:53,792 - INFO - epoch 2, step 19900, training loss = 1.947413, validation loss = 2.855330
2018-12-05 10:32:57,146 - INFO - epoch 2, step 19910, training loss = 2.106326, validation loss = 3.787838
2018-12-05 10:33:00,597 - INFO - epoch 2, step 19920, training loss = 2.382378, validation loss = 3.054742
2018-12-05 10:33:04,073 - INFO - epoch 2, step 19930, training loss = 2.523581, validation loss = 3.417015
2018-12-05 10:33:07,239 - INFO - epoch 2, step 19940, training loss = 2.085998, validation loss = 4.043678
2018-12-05 10:33:10,546 - INFO - epoch 2, step 19950, training loss = 1.978050, validation loss = 3.027426
2018-12-05 10:33:13,970 - INFO - epoch 2, step 19960, training loss = 2.026646, validation loss = 3.308011
2018-12-05 10:33:17,458 - INFO - epoch 2, step 19970, training loss = 2.243836, validation loss = 3.022198
2018-12-05 10:33:20,712 - INFO - epoch 2, step 19980, training loss = 2.554151, validation loss = 3.292825
2018-12-05 10:33:23,994 - INFO - epoch 2, step 19990, training loss = 2.412721, validation loss = 3.336810
2018-12-05 10:33:27,438 - INFO - epoch 2, step 20000, training loss = 2.202347, validation loss = 3.097968
2018-12-05 10:33:30,749 - INFO - epoch 2, step 20010, training loss = 1.832992, validation loss = 3.521932
2018-12-05 10:33:34,036 - INFO - epoch 2, step 20020, training loss = 2.141261, validation loss = 3.654933
2018-12-05 10:33:37,271 - INFO - epoch 2, step 20030, training loss = 2.260270, validation loss = 3.458371
2018-12-05 10:33:40,561 - INFO - epoch 2, step 20040, training loss = 2.149384, validation loss = 3.191180
2018-12-05 10:33:43,853 - INFO - epoch 2, step 20050, training loss = 2.538620, validation loss = 3.410653
2018-12-05 10:33:47,083 - INFO - epoch 2, step 20060, training loss = 2.491850, validation loss = 3.408488
2018-12-05 10:33:50,452 - INFO - epoch 2, step 20070, training loss = 2.034747, validation loss = 3.644331
2018-12-05 10:33:53,781 - INFO - epoch 2, step 20080, training loss = 2.221448, validation loss = 3.064786
2018-12-05 10:33:57,171 - INFO - epoch 2, step 20090, training loss = 2.546674, validation loss = 3.621022
2018-12-05 10:34:00,488 - INFO - epoch 2, step 20100, training loss = 2.240090, validation loss = 3.625442
2018-12-05 10:34:03,790 - INFO - epoch 2, step 20110, training loss = 2.019212, validation loss = 3.885684
2018-12-05 10:34:07,111 - INFO - epoch 2, step 20120, training loss = 2.297129, validation loss = 4.238552
2018-12-05 10:34:10,490 - INFO - epoch 2, step 20130, training loss = 2.061168, validation loss = 3.217747
2018-12-05 10:34:13,686 - INFO - epoch 2, step 20140, training loss = 1.960277, validation loss = 3.385791
2018-12-05 10:34:17,182 - INFO - epoch 2, step 20150, training loss = 1.726896, validation loss = 3.061294
2018-12-05 10:34:20,573 - INFO - epoch 2, step 20160, training loss = 2.297031, validation loss = 3.470452
2018-12-05 10:34:23,888 - INFO - epoch 2, step 20170, training loss = 2.700280, validation loss = 3.372854
2018-12-05 10:34:27,109 - INFO - epoch 2, step 20180, training loss = 2.067812, validation loss = 2.816587
2018-12-05 10:34:30,322 - INFO - epoch 2, step 20190, training loss = 2.233158, validation loss = 3.388641
2018-12-05 10:34:33,623 - INFO - epoch 2, step 20200, training loss = 1.719965, validation loss = 3.810295
2018-12-05 10:34:36,840 - INFO - epoch 2, step 20210, training loss = 2.399773, validation loss = 3.586085
2018-12-05 10:34:40,327 - INFO - epoch 2, step 20220, training loss = 1.985908, validation loss = 3.406636
2018-12-05 10:34:44,618 - INFO - epoch 2, step 20230, training loss = 2.317476, validation loss = 2.997185
2018-12-05 10:34:49,233 - INFO - epoch 2, step 20240, training loss = 2.510697, validation loss = 3.277555
2018-12-05 10:34:53,789 - INFO - epoch 2, step 20250, training loss = 1.967029, validation loss = 3.423728
2018-12-05 10:34:58,133 - INFO - epoch 2, step 20260, training loss = 2.201838, validation loss = 2.742058
2018-12-05 10:35:02,758 - INFO - epoch 2, step 20270, training loss = 2.171423, validation loss = 3.083411
2018-12-05 10:35:07,311 - INFO - epoch 2, step 20280, training loss = 2.099858, validation loss = 3.093823
2018-12-05 10:35:11,784 - INFO - epoch 2, step 20290, training loss = 2.103941, validation loss = 3.183818
2018-12-05 10:35:16,490 - INFO - epoch 2, step 20300, training loss = 2.386341, validation loss = 2.981996
2018-12-05 10:35:20,847 - INFO - epoch 2, step 20310, training loss = 2.440275, validation loss = 3.375949
2018-12-05 10:35:25,245 - INFO - epoch 2, step 20320, training loss = 1.813493, validation loss = 3.062165
2018-12-05 10:35:29,571 - INFO - epoch 2, step 20330, training loss = 1.991174, validation loss = 3.342442
2018-12-05 10:35:33,852 - INFO - epoch 2, step 20340, training loss = 2.139295, validation loss = 3.310407
2018-12-05 10:35:38,291 - INFO - epoch 2, step 20350, training loss = 2.202898, validation loss = 3.507793
2018-12-05 10:35:42,453 - INFO - epoch 2, step 20360, training loss = 2.276046, validation loss = 3.085708
2018-12-05 10:35:46,762 - INFO - epoch 2, step 20370, training loss = 1.848160, validation loss = 3.673732
2018-12-05 10:35:51,124 - INFO - epoch 2, step 20380, training loss = 2.100075, validation loss = 3.317585
2018-12-05 10:35:55,397 - INFO - epoch 2, step 20390, training loss = 1.846257, validation loss = 3.061704
2018-12-05 10:36:00,102 - INFO - epoch 2, step 20400, training loss = 1.982549, validation loss = 3.427041
2018-12-05 10:36:04,785 - INFO - epoch 2, step 20410, training loss = 1.513049, validation loss = 3.589058
2018-12-05 10:36:09,665 - INFO - epoch 2, step 20420, training loss = 2.027942, validation loss = 3.008498
2018-12-05 10:36:14,237 - INFO - epoch 2, step 20430, training loss = 2.175489, validation loss = 3.304133
2018-12-05 10:36:18,499 - INFO - epoch 2, step 20440, training loss = 2.318909, validation loss = 3.499457
2018-12-05 10:36:22,912 - INFO - epoch 2, step 20450, training loss = 2.276417, validation loss = 3.327543
2018-12-05 10:36:27,226 - INFO - epoch 2, step 20460, training loss = 1.933764, validation loss = 3.173821
2018-12-05 10:36:31,386 - INFO - epoch 2, step 20470, training loss = 2.518121, validation loss = 2.963528
2018-12-05 10:36:36,776 - INFO - epoch 2, step 20480, training loss = 2.256446, validation loss = 3.032000
2018-12-05 10:36:41,877 - INFO - epoch 2, step 20490, training loss = 2.523785, validation loss = 3.427932
2018-12-05 10:36:47,232 - INFO - epoch 2, step 20500, training loss = 1.923350, validation loss = 3.390735
2018-12-05 10:36:52,374 - INFO - epoch 2, step 20510, training loss = 2.128313, validation loss = 3.010285
2018-12-05 10:36:57,511 - INFO - epoch 2, step 20520, training loss = 2.253935, validation loss = 3.342851
2018-12-05 10:37:02,633 - INFO - epoch 2, step 20530, training loss = 2.341438, validation loss = 2.926152
2018-12-05 10:37:07,769 - INFO - epoch 2, step 20540, training loss = 2.754945, validation loss = 2.986912
2018-12-05 10:37:12,898 - INFO - epoch 2, step 20550, training loss = 2.078966, validation loss = 3.468588
2018-12-05 10:37:18,126 - INFO - epoch 2, step 20560, training loss = 2.036804, validation loss = 2.823820
2018-12-05 10:37:23,285 - INFO - epoch 2, step 20570, training loss = 2.130300, validation loss = 3.232352
2018-12-05 10:37:28,304 - INFO - epoch 2, step 20580, training loss = 2.505247, validation loss = 3.755466
2018-12-05 10:37:33,537 - INFO - epoch 2, step 20590, training loss = 2.314609, validation loss = 3.104568
2018-12-05 10:37:38,481 - INFO - epoch 2, step 20600, training loss = 2.105109, validation loss = 3.315250
2018-12-05 10:37:43,790 - INFO - epoch 2, step 20610, training loss = 1.931649, validation loss = 3.060303
2018-12-05 10:37:48,561 - INFO - epoch 2, step 20620, training loss = 2.591248, validation loss = 3.260739
2018-12-05 10:37:52,239 - INFO - epoch 2, step 20630, training loss = 2.360017, validation loss = 3.493127
2018-12-05 10:37:55,964 - INFO - epoch 2, step 20640, training loss = 2.573450, validation loss = 3.161961
2018-12-05 10:37:59,702 - INFO - epoch 2, step 20650, training loss = 2.155452, validation loss = 2.725683
2018-12-05 10:38:03,517 - INFO - epoch 2, step 20660, training loss = 2.073559, validation loss = 3.743193
2018-12-05 10:38:07,158 - INFO - epoch 2, step 20670, training loss = 2.352214, validation loss = 3.282436
2018-12-05 10:38:10,793 - INFO - epoch 2, step 20680, training loss = 2.652801, validation loss = 3.643773
2018-12-05 10:38:14,646 - INFO - epoch 2, step 20690, training loss = 2.450058, validation loss = 3.515554
2018-12-05 10:38:18,331 - INFO - epoch 2, step 20700, training loss = 2.067432, validation loss = 3.296095
2018-12-05 10:38:21,972 - INFO - epoch 2, step 20710, training loss = 2.102673, validation loss = 3.150956
2018-12-05 10:38:25,828 - INFO - epoch 2, step 20720, training loss = 1.853597, validation loss = 3.287631
2018-12-05 10:38:30,362 - INFO - epoch 2, step 20730, training loss = 2.084918, validation loss = 3.507481
2018-12-05 10:38:35,039 - INFO - epoch 2, step 20740, training loss = 2.028197, validation loss = 3.501366
2018-12-05 10:38:39,549 - INFO - epoch 2, step 20750, training loss = 1.545291, validation loss = 3.690137
2018-12-05 10:38:43,743 - INFO - epoch 2, step 20760, training loss = 2.035379, validation loss = 3.264338
2018-12-05 10:38:48,151 - INFO - epoch 2, step 20770, training loss = 2.131415, validation loss = 3.489318
2018-12-05 10:38:52,915 - INFO - epoch 2, step 20780, training loss = 2.282591, validation loss = 2.776309
2018-12-05 10:38:57,813 - INFO - epoch 2, step 20790, training loss = 2.288020, validation loss = 3.467034
2018-12-05 10:39:01,008 - INFO - epoch 2, step 20800, training loss = 2.386700, validation loss = 3.747818
2018-12-05 10:39:04,125 - INFO - epoch 2, step 20810, training loss = 1.601438, validation loss = 3.286460
2018-12-05 10:39:07,566 - INFO - epoch 2, step 20820, training loss = 2.344311, validation loss = 3.497940
2018-12-05 10:39:10,874 - INFO - epoch 2, step 20830, training loss = 1.976057, validation loss = 3.174110
2018-12-05 10:39:14,124 - INFO - epoch 2, step 20840, training loss = 2.088928, validation loss = 3.080096
2018-12-05 10:39:17,357 - INFO - epoch 2, step 20850, training loss = 1.696576, validation loss = 3.582336
2018-12-05 10:39:20,714 - INFO - epoch 2, step 20860, training loss = 2.046093, validation loss = 2.881016
2018-12-05 10:39:24,048 - INFO - epoch 2, step 20870, training loss = 2.439153, validation loss = 3.448372
2018-12-05 10:39:27,171 - INFO - epoch 2, step 20880, training loss = 2.421125, validation loss = 3.500798
2018-12-05 10:39:30,435 - INFO - epoch 2, step 20890, training loss = 2.288288, validation loss = 3.450432
2018-12-05 10:39:33,712 - INFO - epoch 2, step 20900, training loss = 2.394040, validation loss = 3.333548
2018-12-05 10:39:37,030 - INFO - epoch 2, step 20910, training loss = 1.680503, validation loss = 3.154216
2018-12-05 10:39:40,297 - INFO - epoch 2, step 20920, training loss = 2.385161, validation loss = 3.729694
2018-12-05 10:39:43,503 - INFO - epoch 2, step 20930, training loss = 2.487912, validation loss = 2.946855
2018-12-05 10:39:46,693 - INFO - epoch 2, step 20940, training loss = 1.863143, validation loss = 3.724242
2018-12-05 10:39:49,979 - INFO - epoch 2, step 20950, training loss = 2.119073, validation loss = 3.388351
2018-12-05 10:39:55,716 - INFO - epoch 2, step 20960, training loss = 2.047780, validation loss = 3.083524
2018-12-05 10:40:02,145 - INFO - epoch 2, step 20970, training loss = 1.804776, validation loss = 3.445163
2018-12-05 10:40:07,952 - INFO - epoch 2, step 20980, training loss = 2.147153, validation loss = 3.376653
2018-12-05 10:40:13,680 - INFO - epoch 2, step 20990, training loss = 2.158450, validation loss = 3.148819
2018-12-05 10:40:19,309 - INFO - epoch 2, step 21000, training loss = 1.981058, validation loss = 3.429113
2018-12-05 10:40:25,450 - INFO - epoch 2, step 21010, training loss = 2.193548, validation loss = 3.143142
2018-12-05 10:40:31,698 - INFO - epoch 2, step 21020, training loss = 2.294364, validation loss = 3.412512
2018-12-05 10:40:37,229 - INFO - epoch 2, step 21030, training loss = 1.954401, validation loss = 3.803351
2018-12-05 10:40:43,703 - INFO - epoch 2, step 21040, training loss = 1.658734, validation loss = 3.772656
2018-12-05 10:40:49,008 - INFO - epoch 2, step 21050, training loss = 1.716326, validation loss = 3.810204
2018-12-05 10:40:54,246 - INFO - epoch 2, step 21060, training loss = 2.100469, validation loss = 2.963838
2018-12-05 10:40:59,693 - INFO - epoch 2, step 21070, training loss = 2.163056, validation loss = 3.509575
2018-12-05 10:41:04,931 - INFO - epoch 2, step 21080, training loss = 1.920146, validation loss = 3.569715
2018-12-05 10:41:09,869 - INFO - epoch 2, step 21090, training loss = 2.012411, validation loss = 3.234420
2018-12-05 10:41:14,739 - INFO - epoch 2, step 21100, training loss = 2.348519, validation loss = 3.467917
2018-12-05 10:41:20,017 - INFO - epoch 2, step 21110, training loss = 1.836460, validation loss = 2.892449
2018-12-05 10:41:25,017 - INFO - epoch 2, step 21120, training loss = 2.188281, validation loss = 2.996557
2018-12-05 10:41:30,212 - INFO - epoch 2, step 21130, training loss = 2.195027, validation loss = 3.206195
2018-12-05 10:41:35,139 - INFO - epoch 2, step 21140, training loss = 2.380792, validation loss = 3.563341
2018-12-05 10:41:40,053 - INFO - epoch 2, step 21150, training loss = 2.381995, validation loss = 3.049617
2018-12-05 10:41:45,016 - INFO - epoch 2, step 21160, training loss = 2.109967, validation loss = 3.857718
2018-12-05 10:41:50,141 - INFO - epoch 2, step 21170, training loss = 2.256701, validation loss = 2.864677
2018-12-05 10:41:55,124 - INFO - epoch 2, step 21180, training loss = 1.976359, validation loss = 3.482509
2018-12-05 10:42:00,340 - INFO - epoch 2, step 21190, training loss = 2.212207, validation loss = 3.670857
2018-12-05 10:42:05,483 - INFO - epoch 2, step 21200, training loss = 2.434958, validation loss = 3.281250
2018-12-05 10:42:10,578 - INFO - epoch 2, step 21210, training loss = 2.158014, validation loss = 3.041160
2018-12-05 10:42:15,633 - INFO - epoch 2, step 21220, training loss = 2.233415, validation loss = 3.504646
2018-12-05 10:42:20,909 - INFO - epoch 2, step 21230, training loss = 2.332942, validation loss = 3.041082
2018-12-05 10:42:25,997 - INFO - epoch 2, step 21240, training loss = 2.215640, validation loss = 3.662483
2018-12-05 10:42:30,984 - INFO - epoch 2, step 21250, training loss = 1.732746, validation loss = 3.968134
2018-12-05 10:42:35,969 - INFO - epoch 2, step 21260, training loss = 2.403349, validation loss = 3.062698
2018-12-05 10:42:41,110 - INFO - epoch 2, step 21270, training loss = 2.070395, validation loss = 3.533688
2018-12-05 10:42:46,772 - INFO - epoch 2, step 21280, training loss = 2.501132, validation loss = 3.316373
2018-12-05 10:42:52,076 - INFO - epoch 2, step 21290, training loss = 2.008433, validation loss = 3.490827
2018-12-05 10:42:57,321 - INFO - epoch 2, step 21300, training loss = 2.463607, validation loss = 3.474135
2018-12-05 10:43:02,502 - INFO - epoch 2, step 21310, training loss = 2.415730, validation loss = 3.064857
2018-12-05 10:43:07,558 - INFO - epoch 2, step 21320, training loss = 2.255234, validation loss = 3.184437
2018-12-05 10:43:12,966 - INFO - epoch 2, step 21330, training loss = 2.109159, validation loss = 2.949058
2018-12-05 10:43:18,292 - INFO - epoch 2, step 21340, training loss = 2.020998, validation loss = 3.979820
2018-12-05 10:43:23,453 - INFO - epoch 2, step 21350, training loss = 2.129048, validation loss = 3.294952
2018-12-05 10:43:28,851 - INFO - epoch 2, step 21360, training loss = 2.146442, validation loss = 3.354562
2018-12-05 10:43:33,916 - INFO - epoch 2, step 21370, training loss = 2.302650, validation loss = 3.465503
2018-12-05 10:43:39,504 - INFO - epoch 2, step 21380, training loss = 1.915962, validation loss = 3.568194
2018-12-05 10:43:44,883 - INFO - epoch 2, step 21390, training loss = 1.983594, validation loss = 3.416571
2018-12-05 10:43:49,964 - INFO - epoch 2, step 21400, training loss = 2.093738, validation loss = 3.277444
2018-12-05 10:43:55,042 - INFO - epoch 2, step 21410, training loss = 2.681891, validation loss = 3.315529
2018-12-05 10:44:00,420 - INFO - epoch 2, step 21420, training loss = 2.190544, validation loss = 3.232330
2018-12-05 10:44:05,877 - INFO - epoch 2, step 21430, training loss = 1.888315, validation loss = 3.998187
2018-12-05 10:44:11,662 - INFO - epoch 2, step 21440, training loss = 2.343199, validation loss = 3.481292
2018-12-05 10:44:17,010 - INFO - epoch 2, step 21450, training loss = 2.348562, validation loss = 3.107894
2018-12-05 10:44:22,002 - INFO - epoch 2, step 21460, training loss = 1.914814, validation loss = 3.644666
2018-12-05 10:44:27,331 - INFO - epoch 2, step 21470, training loss = 2.607389, validation loss = 3.431897
2018-12-05 10:44:33,340 - INFO - epoch 2, step 21480, training loss = 1.780896, validation loss = 3.369155
2018-12-05 10:44:38,843 - INFO - epoch 2, step 21490, training loss = 2.017358, validation loss = 3.625879
2018-12-05 10:44:43,895 - INFO - epoch 2, step 21500, training loss = 2.282167, validation loss = 3.420936
2018-12-05 10:44:48,037 - INFO - epoch 2, step 21510, training loss = 2.602892, validation loss = 3.042707
2018-12-05 10:44:51,329 - INFO - epoch 2, step 21520, training loss = 2.330597, validation loss = 3.400314
2018-12-05 10:44:54,679 - INFO - epoch 2, step 21530, training loss = 1.993701, validation loss = 3.334981
2018-12-05 10:44:57,954 - INFO - epoch 2, step 21540, training loss = 2.527023, validation loss = 3.604616
2018-12-05 10:45:01,462 - INFO - epoch 2, step 21550, training loss = 2.382532, validation loss = 2.984738
2018-12-05 10:45:04,780 - INFO - epoch 2, step 21560, training loss = 2.597085, validation loss = 3.771778
2018-12-05 10:45:08,162 - INFO - epoch 2, step 21570, training loss = 2.391841, validation loss = 2.974430
2018-12-05 10:45:11,574 - INFO - epoch 2, step 21580, training loss = 2.375622, validation loss = 3.472529
2018-12-05 10:45:14,827 - INFO - epoch 2, step 21590, training loss = 2.279998, validation loss = 3.520657
2018-12-05 10:45:18,141 - INFO - epoch 2, step 21600, training loss = 2.686194, validation loss = 3.111911
2018-12-05 10:45:21,396 - INFO - epoch 2, step 21610, training loss = 2.114509, validation loss = 3.504605
2018-12-05 10:45:24,771 - INFO - epoch 2, step 21620, training loss = 2.370751, validation loss = 3.055238
2018-12-05 10:45:27,906 - INFO - epoch 2, step 21630, training loss = 2.372844, validation loss = 3.447109
2018-12-05 10:45:31,590 - INFO - epoch 2, step 21640, training loss = 2.552184, validation loss = 3.535296
2018-12-05 10:45:36,300 - INFO - epoch 2, step 21650, training loss = 2.166607, validation loss = 3.599504
2018-12-05 10:45:41,485 - INFO - epoch 2, step 21660, training loss = 2.203902, validation loss = 3.383090
2018-12-05 10:45:46,234 - INFO - epoch 2, step 21670, training loss = 2.367080, validation loss = 3.490235
2018-12-05 10:45:50,893 - INFO - epoch 2, step 21680, training loss = 2.062495, validation loss = 3.352118
2018-12-05 10:45:55,513 - INFO - epoch 2, step 21690, training loss = 2.414688, validation loss = 3.717217
2018-12-05 10:46:00,439 - INFO - epoch 2, step 21700, training loss = 2.106816, validation loss = 3.223612
2018-12-05 10:46:05,314 - INFO - epoch 2, step 21710, training loss = 2.357417, validation loss = 3.289272
2018-12-05 10:46:09,938 - INFO - epoch 2, step 21720, training loss = 2.418841, validation loss = 2.744859
2018-12-05 10:46:14,521 - INFO - epoch 2, step 21730, training loss = 2.579812, validation loss = 3.672939
2018-12-05 10:46:19,402 - INFO - epoch 2, step 21740, training loss = 2.455259, validation loss = 3.256938
2018-12-05 10:46:24,049 - INFO - epoch 2, step 21750, training loss = 2.323245, validation loss = 3.108327
2018-12-05 10:46:28,761 - INFO - epoch 2, step 21760, training loss = 2.637854, validation loss = 3.193664
2018-12-05 10:46:33,882 - INFO - epoch 2, step 21770, training loss = 1.838194, validation loss = 3.383698
2018-12-05 10:46:38,906 - INFO - epoch 2, step 21780, training loss = 1.977224, validation loss = 2.813901
2018-12-05 10:46:44,164 - INFO - epoch 2, step 21790, training loss = 2.329635, validation loss = 2.631159
2018-12-05 10:46:49,224 - INFO - epoch 2, step 21800, training loss = 2.535696, validation loss = 3.071399
2018-12-05 10:46:54,056 - INFO - epoch 2, step 21810, training loss = 2.244433, validation loss = 3.350736
2018-12-05 10:46:58,991 - INFO - epoch 2, step 21820, training loss = 2.379217, validation loss = 3.362254
2018-12-05 10:47:04,062 - INFO - epoch 2, step 21830, training loss = 2.193144, validation loss = 2.877378
2018-12-05 10:47:09,466 - INFO - epoch 2, step 21840, training loss = 2.618374, validation loss = 2.675654
2018-12-05 10:47:13,826 - INFO - epoch 2, step 21850, training loss = 2.515289, validation loss = 3.127434
2018-12-05 10:47:18,980 - INFO - epoch 2, step 21860, training loss = 2.407480, validation loss = 3.221052
2018-12-05 10:47:23,992 - INFO - epoch 2, step 21870, training loss = 2.502682, validation loss = 2.443582
2018-12-05 10:47:29,078 - INFO - epoch 2, step 21880, training loss = 1.890431, validation loss = 3.500159
2018-12-05 10:47:32,378 - INFO - epoch 2, step 21890, training loss = 2.472123, validation loss = 2.878097
2018-12-05 10:47:35,059 - INFO - epoch 2, step 21900, training loss = 1.493007, validation loss = 2.992454
2018-12-05 10:47:37,759 - INFO - epoch 2, step 21910, training loss = 2.616544, validation loss = 3.633710
2018-12-05 10:47:40,486 - INFO - epoch 2, step 21920, training loss = 1.749392, validation loss = 2.209915
2018-12-05 10:47:43,181 - INFO - epoch 2, step 21930, training loss = 2.190333, validation loss = 3.067458
2018-12-05 10:47:45,737 - INFO - epoch 2, step 21940, training loss = 1.908718, validation loss = 2.955786
2018-12-05 10:47:48,350 - INFO - epoch 2, step 21950, training loss = 1.996617, validation loss = 3.172669
2018-12-05 10:47:50,832 - INFO - epoch 2, step 21960, training loss = 2.321933, validation loss = 3.129930
2018-12-05 10:47:53,447 - INFO - epoch 2, step 21970, training loss = 2.289440, validation loss = 3.266486
2018-12-05 10:47:56,072 - INFO - epoch 2, step 21980, training loss = 2.556605, validation loss = 3.038830
2018-12-05 10:47:58,659 - INFO - epoch 2, step 21990, training loss = 2.342560, validation loss = 2.861739
2018-12-05 10:48:01,323 - INFO - epoch 2, step 22000, training loss = 2.285344, validation loss = 2.454036
2018-12-05 10:48:03,957 - INFO - epoch 2, step 22010, training loss = 1.773836, validation loss = 2.449126
2018-12-05 10:48:06,594 - INFO - epoch 2, step 22020, training loss = 1.558861, validation loss = 3.148738
2018-12-05 10:48:09,578 - INFO - epoch 2, step 22030, training loss = 2.091128, validation loss = 3.023779
2018-12-05 10:48:12,197 - INFO - epoch 2, step 22040, training loss = 2.521760, validation loss = 2.367284
2018-12-05 10:48:15,592 - INFO - epoch 2, step 22050, training loss = 2.437584, validation loss = 3.335986
2018-12-05 10:48:19,976 - INFO - epoch 2, step 22060, training loss = 2.377420, validation loss = 3.024786
2018-12-05 10:48:24,674 - INFO - epoch 2, step 22070, training loss = 2.267145, validation loss = 2.472862
2018-12-05 10:48:29,288 - INFO - epoch 2, step 22080, training loss = 2.169260, validation loss = 3.267115
2018-12-05 10:48:33,742 - INFO - epoch 2, step 22090, training loss = 1.540057, validation loss = 3.319181
2018-12-05 10:48:38,251 - INFO - epoch 2, step 22100, training loss = 2.026045, validation loss = 3.234593
2018-12-05 10:48:42,893 - INFO - epoch 2, step 22110, training loss = 2.234004, validation loss = 2.741875
2018-12-05 10:48:47,133 - INFO - epoch 2, step 22120, training loss = 1.809799, validation loss = 2.721055
2018-12-05 10:48:51,560 - INFO - epoch 2, step 22130, training loss = 1.908686, validation loss = 3.239324
2018-12-05 10:48:56,229 - INFO - epoch 2, step 22140, training loss = 2.251302, validation loss = 2.516359
2018-12-05 10:49:00,652 - INFO - epoch 2, step 22150, training loss = 1.992707, validation loss = 3.072846
2018-12-05 10:49:05,459 - INFO - epoch 2, step 22160, training loss = 1.565632, validation loss = 2.465111
2018-12-05 10:49:09,875 - INFO - epoch 2, step 22170, training loss = 1.835216, validation loss = 2.883881
2018-12-05 10:49:14,367 - INFO - epoch 2, step 22180, training loss = 2.351019, validation loss = 2.652783
2018-12-05 10:49:18,811 - INFO - epoch 2, step 22190, training loss = 2.919258, validation loss = 2.361571
2018-12-05 10:49:23,010 - INFO - epoch 2, step 22200, training loss = 2.195673, validation loss = 2.548321
2018-12-05 10:49:27,247 - INFO - epoch 2, step 22210, training loss = 2.278295, validation loss = 2.887788
2018-12-05 10:49:31,913 - INFO - epoch 2, step 22220, training loss = 1.854025, validation loss = 3.285148
2018-12-05 10:49:37,646 - INFO - epoch 2, step 22230, training loss = 1.709750, validation loss = 3.164327
2018-12-05 10:49:43,460 - INFO - epoch 2, step 22240, training loss = 2.179986, validation loss = 3.102141
2018-12-05 10:49:49,274 - INFO - epoch 2, step 22250, training loss = 2.191061, validation loss = 3.553785
2018-12-05 10:49:54,758 - INFO - epoch 2, step 22260, training loss = 1.924588, validation loss = 3.405213
2018-12-05 10:50:00,312 - INFO - epoch 2, step 22270, training loss = 2.134006, validation loss = 3.496950
2018-12-05 10:50:06,272 - INFO - epoch 2, step 22280, training loss = 2.308373, validation loss = 3.724111
2018-12-05 10:50:13,122 - INFO - epoch 2, step 22290, training loss = 1.526772, validation loss = 3.237446
2018-12-05 10:50:19,048 - INFO - epoch 2, step 22300, training loss = 1.730107, validation loss = 3.835142
2018-12-05 10:50:25,210 - INFO - epoch 2, step 22310, training loss = 1.572971, validation loss = 3.713509
2018-12-05 10:50:30,944 - INFO - epoch 2, step 22320, training loss = 2.070109, validation loss = 3.266089
2018-12-05 10:50:36,756 - INFO - epoch 2, step 22330, training loss = 1.700887, validation loss = 3.326844
2018-12-05 10:50:42,951 - INFO - epoch 2, step 22340, training loss = 2.163376, validation loss = 3.177440
2018-12-05 10:50:48,945 - INFO - epoch 2, step 22350, training loss = 1.839292, validation loss = 3.927581
2018-12-05 10:50:54,898 - INFO - epoch 2, step 22360, training loss = 2.126345, validation loss = 3.206438
2018-12-05 10:51:00,815 - INFO - epoch 2, step 22370, training loss = 1.781424, validation loss = 3.890459
2018-12-05 10:51:06,298 - INFO - epoch 2, step 22380, training loss = 2.007701, validation loss = 3.304613
2018-12-05 10:51:11,489 - INFO - epoch 2, step 22390, training loss = 1.817224, validation loss = 3.447971
2018-12-05 10:51:17,135 - INFO - epoch 2, step 22400, training loss = 2.315358, validation loss = 4.246194
2018-12-05 10:51:23,325 - INFO - epoch 2, step 22410, training loss = 2.329572, validation loss = 3.206894
2018-12-05 10:51:28,854 - INFO - epoch 2, step 22420, training loss = 1.855569, validation loss = 3.427956
2018-12-05 10:51:34,708 - INFO - epoch 2, step 22430, training loss = 2.222060, validation loss = 3.867308
2018-12-05 10:51:40,531 - INFO - epoch 2, step 22440, training loss = 1.621888, validation loss = 3.089631
2018-12-05 10:51:46,071 - INFO - epoch 2, step 22450, training loss = 2.073202, validation loss = 2.998173
2018-12-05 10:51:51,370 - INFO - epoch 2, step 22460, training loss = 2.509001, validation loss = 3.170145
2018-12-05 10:51:56,898 - INFO - epoch 2, step 22470, training loss = 2.138616, validation loss = 3.718420
2018-12-05 10:52:02,206 - INFO - epoch 2, step 22480, training loss = 2.154167, validation loss = 3.283841
2018-12-05 10:52:07,703 - INFO - epoch 2, step 22490, training loss = 2.073635, validation loss = 3.167317
2018-12-05 10:52:13,097 - INFO - epoch 2, step 22500, training loss = 2.396715, validation loss = 3.749247
2018-12-05 10:52:18,577 - INFO - epoch 2, step 22510, training loss = 2.274264, validation loss = 2.960967
2018-12-05 10:52:24,779 - INFO - epoch 2, step 22520, training loss = 2.171534, validation loss = 3.097482
2018-12-05 10:52:30,380 - INFO - epoch 2, step 22530, training loss = 2.035166, validation loss = 3.829344
2018-12-05 10:52:36,274 - INFO - epoch 2, step 22540, training loss = 2.183027, validation loss = 3.465167
2018-12-05 10:52:41,867 - INFO - epoch 2, step 22550, training loss = 2.032681, validation loss = 3.140765
2018-12-05 10:52:47,870 - INFO - epoch 2, step 22560, training loss = 1.694101, validation loss = 2.931542
2018-12-05 10:52:53,491 - INFO - epoch 2, step 22570, training loss = 1.866554, validation loss = 3.538507
2018-12-05 10:52:59,618 - INFO - epoch 2, step 22580, training loss = 1.871367, validation loss = 3.205252
2018-12-05 10:53:05,096 - INFO - epoch 2, step 22590, training loss = 2.317991, validation loss = 3.365588
2018-12-05 10:53:10,488 - INFO - epoch 2, step 22600, training loss = 1.784918, validation loss = 3.418148
2018-12-05 10:53:15,475 - INFO - epoch 2, step 22610, training loss = 2.376604, validation loss = 3.686016
2018-12-05 10:53:20,221 - INFO - epoch 2, step 22620, training loss = 2.294996, validation loss = 3.501729
2018-12-05 10:53:24,703 - INFO - epoch 2, step 22630, training loss = 2.350949, validation loss = 3.266255
2018-12-05 10:53:28,995 - INFO - epoch 2, step 22640, training loss = 2.165410, validation loss = 3.030338
2018-12-05 10:53:33,150 - INFO - epoch 2, step 22650, training loss = 2.082541, validation loss = 3.526953
2018-12-05 10:53:37,397 - INFO - epoch 2, step 22660, training loss = 2.311535, validation loss = 3.331735
2018-12-05 10:53:41,634 - INFO - epoch 2, step 22670, training loss = 2.295749, validation loss = 2.982034
2018-12-05 10:53:45,593 - INFO - epoch 2, step 22680, training loss = 2.689137, validation loss = 3.100312
2018-12-05 10:53:49,201 - INFO - epoch 2, step 22690, training loss = 2.247826, validation loss = 2.975583
2018-12-05 10:53:52,847 - INFO - epoch 2, step 22700, training loss = 2.161602, validation loss = 3.715616
2018-12-05 10:53:56,437 - INFO - epoch 2, step 22710, training loss = 2.330526, validation loss = 2.921219
2018-12-05 10:54:00,058 - INFO - epoch 2, step 22720, training loss = 2.545928, validation loss = 3.364971
2018-12-05 10:54:03,619 - INFO - epoch 2, step 22730, training loss = 2.276902, validation loss = 3.449099
2018-12-05 10:54:07,201 - INFO - epoch 2, step 22740, training loss = 2.022925, validation loss = 3.423359
2018-12-05 10:54:11,083 - INFO - epoch 2, step 22750, training loss = 2.271451, validation loss = 2.615425
2018-12-05 10:54:14,694 - INFO - epoch 2, step 22760, training loss = 2.331464, validation loss = 3.527733
2018-12-05 10:54:18,281 - INFO - epoch 2, step 22770, training loss = 2.255254, validation loss = 3.455253
2018-12-05 10:54:21,783 - INFO - epoch 2, step 22780, training loss = 1.928195, validation loss = 2.855771
2018-12-05 10:54:25,901 - INFO - epoch 2, step 22790, training loss = 2.003998, validation loss = 3.616511
2018-12-05 10:54:29,207 - INFO - epoch 2, step 22800, training loss = 1.803172, validation loss = 3.020728
2018-12-05 10:54:32,465 - INFO - epoch 2, step 22810, training loss = 2.078840, validation loss = 3.298578
2018-12-05 10:54:36,630 - INFO - epoch 2, step 22820, training loss = 1.673132, validation loss = 2.155084
2018-12-05 10:54:39,873 - INFO - epoch 2, step 22830, training loss = 2.060716, validation loss = 1.994796
2018-12-05 10:54:43,221 - INFO - epoch 2, step 22840, training loss = 2.157947, validation loss = 2.326693
2018-12-05 10:54:46,426 - INFO - epoch 2, step 22850, training loss = 1.710883, validation loss = 2.154490
2018-12-05 10:54:49,811 - INFO - epoch 2, step 22860, training loss = 2.119436, validation loss = 2.336445
2018-12-05 10:54:53,237 - INFO - epoch 2, step 22870, training loss = 1.769806, validation loss = 2.391476
2018-12-05 10:54:56,446 - INFO - epoch 2, step 22880, training loss = 2.430537, validation loss = 2.272364
2018-12-05 10:54:59,566 - INFO - epoch 2, step 22890, training loss = 2.056780, validation loss = 2.193311
2018-12-05 10:55:02,944 - INFO - epoch 2, step 22900, training loss = 2.116187, validation loss = 1.607450
2018-12-05 10:55:06,243 - INFO - epoch 2, step 22910, training loss = 2.051829, validation loss = 1.652083
2018-12-05 10:55:09,529 - INFO - epoch 2, step 22920, training loss = 2.194249, validation loss = 2.131333
2018-12-05 10:55:12,720 - INFO - epoch 2, step 22930, training loss = 1.618885, validation loss = 1.996787
2018-12-05 10:55:15,862 - INFO - epoch 2, step 22940, training loss = 1.888456, validation loss = 2.557744
2018-12-05 10:55:19,215 - INFO - epoch 2, step 22950, training loss = 2.098091, validation loss = 1.910143
2018-12-05 10:55:22,544 - INFO - epoch 2, step 22960, training loss = 2.521648, validation loss = 2.263656
2018-12-05 10:55:25,775 - INFO - epoch 2, step 22970, training loss = 2.675531, validation loss = 2.145355
2018-12-05 10:55:29,124 - INFO - epoch 2, step 22980, training loss = 2.240931, validation loss = 2.394490
2018-12-05 10:55:32,202 - INFO - epoch 2, step 22990, training loss = 2.068455, validation loss = 2.272735
2018-12-05 10:55:35,557 - INFO - epoch 2, step 23000, training loss = 2.312452, validation loss = 2.124922
2018-12-05 10:55:39,926 - INFO - epoch 2, step 23010, training loss = 2.218865, validation loss = 1.635320
2018-12-05 10:55:44,280 - INFO - epoch 2, step 23020, training loss = 2.377496, validation loss = 2.124999
2018-12-05 10:55:48,540 - INFO - epoch 2, step 23030, training loss = 2.274466, validation loss = 1.730695
2018-12-05 10:55:53,052 - INFO - epoch 2, step 23040, training loss = 2.633953, validation loss = 2.371457
2018-12-05 10:55:57,923 - INFO - epoch 2, step 23050, training loss = 2.002706, validation loss = 2.149247
2018-12-05 10:56:02,270 - INFO - epoch 2, step 23060, training loss = 2.019797, validation loss = 2.234549
2018-12-05 10:56:06,791 - INFO - epoch 2, step 23070, training loss = 1.505027, validation loss = 2.488382
2018-12-05 10:56:10,983 - INFO - epoch 2, step 23080, training loss = 2.078095, validation loss = 2.555466
2018-12-05 10:56:15,132 - INFO - epoch 2, step 23090, training loss = 2.378753, validation loss = 2.117788
2018-12-05 10:56:19,192 - INFO - epoch 2, step 23100, training loss = 2.334612, validation loss = 2.500518
2018-12-05 10:56:23,437 - INFO - epoch 2, step 23110, training loss = 2.577659, validation loss = 2.338215
2018-12-05 10:56:27,506 - INFO - epoch 2, step 23120, training loss = 2.009868, validation loss = 2.234112
2018-12-05 10:56:30,947 - INFO - epoch 2, step 23130, training loss = 2.379323, validation loss = 2.267739
2018-12-05 10:56:33,241 - INFO - epoch 2, step 23140, training loss = 2.631247, validation loss = 2.041485
2018-12-05 10:56:35,679 - INFO - epoch 2, step 23150, training loss = 1.762561, validation loss = 2.409825
2018-12-05 10:56:38,107 - INFO - epoch 2, step 23160, training loss = 1.916100, validation loss = 2.450227
2018-12-05 10:56:40,437 - INFO - epoch 2, step 23170, training loss = 1.980361, validation loss = 2.171162
2018-12-05 10:56:42,805 - INFO - epoch 2, step 23180, training loss = 1.677091, validation loss = 2.346794
2018-12-05 10:56:45,081 - INFO - epoch 2, step 23190, training loss = 2.480466, validation loss = 2.281304
2018-12-05 10:56:47,401 - INFO - epoch 2, step 23200, training loss = 1.993792, validation loss = 2.249594
2018-12-05 10:56:49,702 - INFO - epoch 2, step 23210, training loss = 1.996419, validation loss = 2.418660
2018-12-05 10:56:52,057 - INFO - epoch 2, step 23220, training loss = 1.743908, validation loss = 2.202831
2018-12-05 10:56:54,342 - INFO - epoch 2, step 23230, training loss = 2.132280, validation loss = 2.461317
2018-12-05 10:56:56,704 - INFO - epoch 2, step 23240, training loss = 2.130070, validation loss = 2.497766
2018-12-05 10:56:59,148 - INFO - epoch 2, step 23250, training loss = 2.114914, validation loss = 2.499382
2018-12-05 10:57:01,509 - INFO - epoch 2, step 23260, training loss = 1.870189, validation loss = 2.465278
2018-12-05 10:57:03,917 - INFO - epoch 2, step 23270, training loss = 2.312685, validation loss = 2.230426
2018-12-05 10:57:06,558 - INFO - epoch 2, step 23280, training loss = 2.351202, validation loss = 2.574877
2018-12-05 10:57:10,296 - INFO - epoch 2, step 23290, training loss = 2.376049, validation loss = 2.236866
2018-12-05 10:57:14,294 - INFO - epoch 2, step 23300, training loss = 2.201553, validation loss = 2.395136
2018-12-05 10:57:18,407 - INFO - epoch 2, step 23310, training loss = 2.183304, validation loss = 2.371030
2018-12-05 10:57:22,264 - INFO - epoch 2, step 23320, training loss = 2.182920, validation loss = 2.122376
2018-12-05 10:57:26,053 - INFO - epoch 2, step 23330, training loss = 2.453214, validation loss = 2.237501
2018-12-05 10:57:29,979 - INFO - epoch 2, step 23340, training loss = 2.161269, validation loss = 2.203561
2018-12-05 10:57:33,870 - INFO - epoch 2, step 23350, training loss = 1.881166, validation loss = 1.790768
2018-12-05 10:57:37,582 - INFO - epoch 2, step 23360, training loss = 2.811224, validation loss = 2.116232
2018-12-05 10:57:41,589 - INFO - epoch 2, step 23370, training loss = 2.044133, validation loss = 2.320985
2018-12-05 10:57:45,621 - INFO - epoch 2, step 23380, training loss = 2.141052, validation loss = 2.482794
2018-12-05 10:57:49,305 - INFO - epoch 2, step 23390, training loss = 2.168246, validation loss = 2.107062
2018-12-05 10:57:53,045 - INFO - epoch 2, step 23400, training loss = 1.984463, validation loss = 2.052211
2018-12-05 10:57:57,086 - INFO - epoch 2, step 23410, training loss = 2.205105, validation loss = 2.143565
2018-12-05 10:58:01,134 - INFO - epoch 2, step 23420, training loss = 2.324647, validation loss = 1.671214
2018-12-05 10:58:05,584 - INFO - epoch 2, step 23430, training loss = 1.938381, validation loss = 1.438504
2018-12-05 10:58:10,150 - INFO - epoch 2, step 23440, training loss = 2.031377, validation loss = 2.272687
2018-12-05 10:58:14,502 - INFO - epoch 2, step 23450, training loss = 1.887222, validation loss = 2.370723
2018-12-05 10:58:19,002 - INFO - epoch 2, step 23460, training loss = 1.872418, validation loss = 2.277166
2018-12-05 10:58:24,696 - INFO - epoch 2, step 23470, training loss = 2.284074, validation loss = 2.042879
2018-12-05 10:58:32,876 - INFO - epoch 2, step 23480, training loss = 2.097801, validation loss = 2.086049
2018-12-05 10:58:39,725 - INFO - epoch 2, step 23490, training loss = 2.292875, validation loss = 2.369594
2018-12-05 10:58:46,341 - INFO - epoch 2, step 23500, training loss = 1.816011, validation loss = 2.011622
2018-12-05 10:58:53,527 - INFO - epoch 2, step 23510, training loss = 2.653080, validation loss = 1.835479
2018-12-05 10:58:58,985 - INFO - epoch 2, step 23520, training loss = 2.083099, validation loss = 2.326378
2018-12-05 10:59:03,278 - INFO - epoch 2, step 23530, training loss = 2.086404, validation loss = 2.137385
2018-12-05 10:59:07,955 - INFO - epoch 2, step 23540, training loss = 2.096805, validation loss = 1.844147
2018-12-05 10:59:12,794 - INFO - epoch 2, step 23550, training loss = 2.345239, validation loss = 2.216963
2018-12-05 10:59:17,167 - INFO - epoch 2, step 23560, training loss = 2.318854, validation loss = 1.833769
2018-12-05 10:59:21,640 - INFO - epoch 2, step 23570, training loss = 2.142101, validation loss = 1.704442
2018-12-05 10:59:25,894 - INFO - epoch 2, step 23580, training loss = 2.087119, validation loss = 2.007075
2018-12-05 10:59:30,342 - INFO - epoch 2, step 23590, training loss = 1.895509, validation loss = 2.025241
2018-12-05 10:59:34,771 - INFO - epoch 2, step 23600, training loss = 2.187975, validation loss = 1.902939
2018-12-05 10:59:38,878 - INFO - epoch 2, step 23610, training loss = 2.090766, validation loss = 2.117878
2018-12-05 10:59:43,166 - INFO - epoch 2, step 23620, training loss = 1.962046, validation loss = 1.958396
2018-12-05 10:59:47,316 - INFO - epoch 2, step 23630, training loss = 2.385813, validation loss = 1.474222
2018-12-05 10:59:51,894 - INFO - epoch 2, step 23640, training loss = 2.096828, validation loss = 1.993384
2018-12-05 10:59:56,056 - INFO - epoch 2, step 23650, training loss = 1.877520, validation loss = 1.647974
2018-12-05 11:00:00,612 - INFO - epoch 2, step 23660, training loss = 2.224393, validation loss = 2.048193
2018-12-05 11:00:05,115 - INFO - epoch 2, step 23670, training loss = 2.057287, validation loss = 2.034098
2018-12-05 11:00:09,304 - INFO - epoch 2, step 23680, training loss = 2.064214, validation loss = 1.819982
2018-12-05 11:00:13,554 - INFO - epoch 2, step 23690, training loss = 2.323015, validation loss = 1.859674
2018-12-05 11:00:18,132 - INFO - epoch 2, step 23700, training loss = 1.881008, validation loss = 1.832134
2018-12-05 11:00:22,802 - INFO - epoch 2, step 23710, training loss = 2.286123, validation loss = 2.287547
2018-12-05 11:00:27,741 - INFO - epoch 2, step 23720, training loss = 1.975216, validation loss = 1.930763
2018-12-05 11:00:32,402 - INFO - epoch 2, step 23730, training loss = 2.434489, validation loss = 1.735505
2018-12-05 11:00:37,159 - INFO - epoch 2, step 23740, training loss = 2.334861, validation loss = 2.001286
2018-12-05 11:00:42,039 - INFO - epoch 2, step 23750, training loss = 2.381802, validation loss = 2.328840
2018-12-05 11:00:46,920 - INFO - epoch 2, step 23760, training loss = 2.187798, validation loss = 1.759862
2018-12-05 11:00:51,812 - INFO - epoch 2, step 23770, training loss = 2.171528, validation loss = 1.748405
2018-12-05 11:00:56,603 - INFO - epoch 2, step 23780, training loss = 2.292604, validation loss = 2.138975
2018-12-05 11:01:01,238 - INFO - epoch 2, step 23790, training loss = 1.773109, validation loss = 2.065440
2018-12-05 11:01:06,339 - INFO - epoch 2, step 23800, training loss = 2.628390, validation loss = 1.951855
2018-12-05 11:01:11,296 - INFO - epoch 2, step 23810, training loss = 2.517135, validation loss = 1.968671
2018-12-05 11:01:16,607 - INFO - epoch 2, step 23820, training loss = 2.311886, validation loss = 1.838708
2018-12-05 11:01:21,600 - INFO - epoch 2, step 23830, training loss = 2.250809, validation loss = 1.714458
2018-12-05 11:01:26,577 - INFO - epoch 2, step 23840, training loss = 2.658093, validation loss = 2.270527
2018-12-05 11:01:31,637 - INFO - epoch 2, step 23850, training loss = 2.490125, validation loss = 1.800041
2018-12-05 11:01:36,739 - INFO - epoch 2, step 23860, training loss = 1.918486, validation loss = 2.036823
2018-12-05 11:01:41,875 - INFO - epoch 2, step 23870, training loss = 2.210254, validation loss = 1.872436
2018-12-05 11:01:46,923 - INFO - epoch 2, step 23880, training loss = 2.094002, validation loss = 1.850900
2018-12-05 11:01:51,964 - INFO - epoch 2, step 23890, training loss = 2.216800, validation loss = 2.267618
2018-12-05 11:01:57,597 - INFO - epoch 2, step 23900, training loss = 2.445434, validation loss = 2.075209
2018-12-05 11:02:02,524 - INFO - epoch 2, step 23910, training loss = 2.473226, validation loss = 2.054333
2018-12-05 11:02:07,537 - INFO - epoch 2, step 23920, training loss = 2.049545, validation loss = 2.075717
2018-12-05 11:02:12,365 - INFO - epoch 2, step 23930, training loss = 2.212592, validation loss = 1.982811
2018-12-05 11:02:17,262 - INFO - epoch 2, step 23940, training loss = 2.535115, validation loss = 1.667744
2018-12-05 11:02:22,397 - INFO - epoch 2, step 23950, training loss = 2.174629, validation loss = 2.289841
2018-12-05 11:02:26,927 - INFO - epoch 2, step 23960, training loss = 2.063566, validation loss = 1.746882
2018-12-05 11:02:31,604 - INFO - epoch 2, step 23970, training loss = 1.861654, validation loss = 2.153954
2018-12-05 11:02:36,282 - INFO - epoch 2, step 23980, training loss = 1.862022, validation loss = 2.181834
2018-12-05 11:02:41,086 - INFO - epoch 2, step 23990, training loss = 2.597347, validation loss = 1.873838
2018-12-05 11:02:45,717 - INFO - epoch 2, step 24000, training loss = 2.022498, validation loss = 1.683472
2018-12-05 11:02:50,458 - INFO - epoch 2, step 24010, training loss = 1.995624, validation loss = 1.724434
2018-12-05 11:02:55,481 - INFO - epoch 2, step 24020, training loss = 1.741500, validation loss = 2.233013
2018-12-05 11:03:01,502 - INFO - epoch 2, step 24030, training loss = 1.648606, validation loss = 1.572115
2018-12-05 11:03:07,204 - INFO - epoch 2, step 24040, training loss = 1.847949, validation loss = 2.003018
2018-12-05 11:03:13,005 - INFO - epoch 2, step 24050, training loss = 1.552236, validation loss = 2.233643
2018-12-05 11:03:19,047 - INFO - epoch 2, step 24060, training loss = 1.652468, validation loss = 1.734837
2018-12-05 11:03:25,445 - INFO - epoch 2, step 24070, training loss = 1.669517, validation loss = 1.907525
2018-12-05 11:03:31,715 - INFO - epoch 2, step 24080, training loss = 1.858528, validation loss = 1.990199
2018-12-05 11:03:37,431 - INFO - epoch 2, step 24090, training loss = 2.103756, validation loss = 1.811462
2018-12-05 11:03:44,079 - INFO - epoch 2, step 24100, training loss = 2.074876, validation loss = 1.909105
2018-12-05 11:03:50,091 - INFO - epoch 2, step 24110, training loss = 1.990313, validation loss = 1.767529
2018-12-05 11:03:55,739 - INFO - epoch 2, step 24120, training loss = 1.688632, validation loss = 1.966968
2018-12-05 11:04:01,560 - INFO - epoch 2, step 24130, training loss = 1.935241, validation loss = 1.907992
2018-12-05 11:04:07,984 - INFO - epoch 2, step 24140, training loss = 1.601548, validation loss = 2.154159
2018-12-05 11:04:13,780 - INFO - epoch 2, step 24150, training loss = 1.803773, validation loss = 1.980329
2018-12-05 11:04:19,328 - INFO - epoch 2, step 24160, training loss = 2.303110, validation loss = 2.157671
2018-12-05 11:04:25,292 - INFO - epoch 2, step 24170, training loss = 1.742427, validation loss = 1.808686
2018-12-05 11:04:30,783 - INFO - epoch 2, step 24180, training loss = 1.752058, validation loss = 2.207904
2018-12-05 11:04:36,613 - INFO - epoch 2, step 24190, training loss = 1.967045, validation loss = 1.782477
2018-12-05 11:04:42,304 - INFO - epoch 2, step 24200, training loss = 1.739375, validation loss = 1.563963
2018-12-05 11:04:47,840 - INFO - epoch 2, step 24210, training loss = 1.977851, validation loss = 2.053764
2018-12-05 11:04:54,496 - INFO - epoch 2, step 24220, training loss = 1.435709, validation loss = 1.872979
2018-12-05 11:05:00,542 - INFO - epoch 2, step 24230, training loss = 2.013469, validation loss = 2.479401
2018-12-05 11:05:05,421 - INFO - epoch 2, step 24240, training loss = 2.853684, validation loss = 2.111619
2018-12-05 11:05:08,587 - INFO - epoch 2, step 24250, training loss = 2.112876, validation loss = 1.824547
2018-12-05 11:05:11,740 - INFO - epoch 2, step 24260, training loss = 2.208281, validation loss = 1.880504
2018-12-05 11:05:14,858 - INFO - epoch 2, step 24270, training loss = 2.402035, validation loss = 1.969669
2018-12-05 11:05:18,383 - INFO - epoch 2, step 24280, training loss = 1.726896, validation loss = 1.942358
2018-12-05 11:05:21,597 - INFO - epoch 2, step 24290, training loss = 1.564327, validation loss = 1.927049
2018-12-05 11:05:24,873 - INFO - epoch 2, step 24300, training loss = 2.112559, validation loss = 1.664917
2018-12-05 11:05:28,037 - INFO - epoch 2, step 24310, training loss = 1.843590, validation loss = 1.857976
2018-12-05 11:05:31,137 - INFO - epoch 2, step 24320, training loss = 2.302348, validation loss = 2.175155
2018-12-05 11:05:34,531 - INFO - epoch 2, step 24330, training loss = 2.770661, validation loss = 1.887372
2018-12-05 11:05:37,671 - INFO - epoch 2, step 24340, training loss = 2.254837, validation loss = 2.248421
2018-12-05 11:05:40,848 - INFO - epoch 2, step 24350, training loss = 1.921182, validation loss = 1.774150
2018-12-05 11:05:44,081 - INFO - epoch 2, step 24360, training loss = 1.867366, validation loss = 2.289962
2018-12-05 11:05:47,465 - INFO - epoch 2, step 24370, training loss = 2.077744, validation loss = 1.881012
2018-12-05 11:05:50,619 - INFO - epoch 2, step 24380, training loss = 2.175392, validation loss = 2.413882
2018-12-05 11:05:53,757 - INFO - epoch 2, step 24390, training loss = 2.396249, validation loss = 2.120114
2018-12-05 11:05:57,132 - INFO - epoch 2, step 24400, training loss = 1.932874, validation loss = 2.282930
2018-12-05 11:06:00,385 - INFO - epoch 2, step 24410, training loss = 2.304016, validation loss = 2.189814
2018-12-05 11:06:03,782 - INFO - epoch 2, step 24420, training loss = 2.076864, validation loss = 2.012137
2018-12-05 11:06:06,775 - INFO - epoch 2, step 24430, training loss = 2.062415, validation loss = 2.565665
2018-12-05 11:06:09,969 - INFO - epoch 2, step 24440, training loss = 2.232946, validation loss = 2.214288
2018-12-05 11:06:13,110 - INFO - epoch 2, step 24450, training loss = 2.525915, validation loss = 2.195860
2018-12-05 11:06:16,149 - INFO - epoch 2, step 24460, training loss = 2.835000, validation loss = 2.029476
2018-12-05 11:06:19,268 - INFO - epoch 2, step 24470, training loss = 2.282714, validation loss = 1.809618
2018-12-05 11:06:22,204 - INFO - epoch 2, step 24480, training loss = 2.028813, validation loss = 2.142383
2018-12-05 11:06:25,637 - INFO - epoch 2, step 24490, training loss = 2.499417, validation loss = 2.145106
2018-12-05 11:06:28,976 - INFO - epoch 2, step 24500, training loss = 2.139493, validation loss = 2.026946
2018-12-05 11:06:32,105 - INFO - epoch 2, step 24510, training loss = 2.325787, validation loss = 2.452267
2018-12-05 11:06:35,286 - INFO - epoch 2, step 24520, training loss = 2.434539, validation loss = 2.091506
2018-12-05 11:06:38,456 - INFO - epoch 2, step 24530, training loss = 2.576139, validation loss = 2.331716
2018-12-05 11:06:41,638 - INFO - epoch 2, step 24540, training loss = 1.922020, validation loss = 2.134790
2018-12-05 11:06:44,842 - INFO - epoch 2, step 24550, training loss = 2.128666, validation loss = 2.192881
2018-12-05 11:06:48,213 - INFO - epoch 2, step 24560, training loss = 2.006000, validation loss = 2.068425
2018-12-05 11:06:51,395 - INFO - epoch 2, step 24570, training loss = 2.181110, validation loss = 2.043042
2018-12-05 11:06:54,840 - INFO - epoch 2, step 24580, training loss = 1.824449, validation loss = 1.768067
2018-12-05 11:06:58,037 - INFO - epoch 2, step 24590, training loss = 2.198522, validation loss = 1.631691
2018-12-05 11:07:01,243 - INFO - epoch 2, step 24600, training loss = 3.090548, validation loss = 2.157342
2018-12-05 11:07:04,543 - INFO - epoch 2, step 24610, training loss = 2.634768, validation loss = 2.246104
2018-12-05 11:07:07,780 - INFO - epoch 2, step 24620, training loss = 2.853755, validation loss = 1.898527
2018-12-05 11:07:11,217 - INFO - epoch 2, step 24630, training loss = 1.961825, validation loss = 2.296584
2018-12-05 11:07:14,356 - INFO - epoch 2, step 24640, training loss = 2.142895, validation loss = 2.317024
2018-12-05 11:07:18,138 - INFO - epoch 2, step 24650, training loss = 0.933060, validation loss = 1.977668
2018-12-05 11:07:21,318 - INFO - epoch 2, step 24660, training loss = 1.984034, validation loss = 2.338443
2018-12-05 11:07:24,502 - INFO - epoch 2, step 24670, training loss = 1.828442, validation loss = 2.384809
2018-12-05 11:07:27,602 - INFO - epoch 2, step 24680, training loss = 2.486879, validation loss = 2.292986
2018-12-05 11:07:30,739 - INFO - epoch 2, step 24690, training loss = 2.049995, validation loss = 2.348109
2018-12-05 11:07:33,823 - INFO - epoch 2, step 24700, training loss = 2.296394, validation loss = 2.115078
2018-12-05 11:07:36,851 - INFO - epoch 2, step 24710, training loss = 2.193635, validation loss = 2.054380
2018-12-05 11:07:40,062 - INFO - epoch 2, step 24720, training loss = 1.965863, validation loss = 1.968687
2018-12-05 11:07:43,332 - INFO - epoch 2, step 24730, training loss = 1.716799, validation loss = 1.905934
2018-12-05 11:07:46,483 - INFO - epoch 2, step 24740, training loss = 1.993290, validation loss = 1.521260
2018-12-05 11:07:49,654 - INFO - epoch 2, step 24750, training loss = 2.412712, validation loss = 1.973900
2018-12-05 11:07:52,775 - INFO - epoch 2, step 24760, training loss = 2.667427, validation loss = 1.912388
2018-12-05 11:07:56,009 - INFO - epoch 2, step 24770, training loss = 2.017313, validation loss = 2.119310
2018-12-05 11:07:59,224 - INFO - epoch 2, step 24780, training loss = 2.472361, validation loss = 1.885562
2018-12-05 11:08:02,520 - INFO - epoch 2, step 24790, training loss = 1.998086, validation loss = 2.052191
2018-12-05 11:08:05,687 - INFO - epoch 2, step 24800, training loss = 1.701036, validation loss = 2.206651
2018-12-05 11:08:09,498 - INFO - epoch 2, step 24810, training loss = 2.085704, validation loss = 2.252383
2018-12-05 11:08:12,637 - INFO - epoch 2, step 24820, training loss = 2.196731, validation loss = 2.558093
2018-12-05 11:08:15,737 - INFO - epoch 2, step 24830, training loss = 2.051453, validation loss = 2.103236
2018-12-05 11:08:18,704 - INFO - epoch 2, step 24840, training loss = 2.788898, validation loss = 1.995398
2018-12-05 11:08:22,152 - INFO - epoch 2, step 24850, training loss = 1.615921, validation loss = 2.114680
2018-12-05 11:08:25,542 - INFO - epoch 2, step 24860, training loss = 1.767288, validation loss = 2.530518
2018-12-05 11:08:28,717 - INFO - epoch 2, step 24870, training loss = 1.996404, validation loss = 1.826379
2018-12-05 11:08:31,983 - INFO - epoch 2, step 24880, training loss = 2.112434, validation loss = 2.085952
2018-12-05 11:08:36,089 - INFO - epoch 2, step 24890, training loss = 2.482703, validation loss = 2.110893
2018-12-05 11:08:40,364 - INFO - epoch 2, step 24900, training loss = 2.061316, validation loss = 2.127558
2018-12-05 11:08:44,518 - INFO - epoch 2, step 24910, training loss = 2.738397, validation loss = 2.165658
2018-12-05 11:08:48,920 - INFO - epoch 2, step 24920, training loss = 2.140751, validation loss = 1.813311
2018-12-05 11:08:53,284 - INFO - epoch 2, step 24930, training loss = 2.008860, validation loss = 2.006408
2018-12-05 11:08:57,472 - INFO - epoch 2, step 24940, training loss = 2.054953, validation loss = 1.927745
2018-12-05 11:09:01,972 - INFO - epoch 2, step 24950, training loss = 2.443326, validation loss = 2.023297
2018-12-05 11:09:07,204 - INFO - epoch 2, step 24960, training loss = 2.713588, validation loss = 1.928883
2018-12-05 11:09:12,575 - INFO - epoch 2, step 24970, training loss = 2.431849, validation loss = 2.047661
2018-12-05 11:09:18,002 - INFO - epoch 2, step 24980, training loss = 2.006637, validation loss = 2.129234
2018-12-05 11:09:23,233 - INFO - epoch 2, step 24990, training loss = 2.279660, validation loss = 1.831517
2018-12-05 11:09:28,805 - INFO - epoch 2, step 25000, training loss = 2.352829, validation loss = 1.995173
2018-12-05 11:09:34,344 - INFO - epoch 2, step 25010, training loss = 2.528046, validation loss = 2.496736
2018-12-05 11:09:39,719 - INFO - epoch 2, step 25020, training loss = 2.794193, validation loss = 2.692751
2018-12-05 11:09:45,212 - INFO - epoch 2, step 25030, training loss = 2.467227, validation loss = 2.458206
2018-12-05 11:09:50,902 - INFO - epoch 2, step 25040, training loss = 2.451407, validation loss = 2.104845
2018-12-05 11:09:56,042 - INFO - epoch 2, step 25050, training loss = 2.368092, validation loss = 2.501419
2018-12-05 11:10:01,379 - INFO - epoch 2, step 25060, training loss = 2.033034, validation loss = 2.293193
2018-12-05 11:10:06,918 - INFO - epoch 2, step 25070, training loss = 2.137970, validation loss = 1.965004
2018-12-05 11:10:12,458 - INFO - epoch 2, step 25080, training loss = 2.402113, validation loss = 2.422545
2018-12-05 11:10:18,100 - INFO - epoch 2, step 25090, training loss = 2.553657, validation loss = 2.425317
2018-12-05 11:10:23,302 - INFO - epoch 2, step 25100, training loss = 2.553831, validation loss = 2.253881
2018-12-05 11:10:28,761 - INFO - epoch 2, step 25110, training loss = 2.682065, validation loss = 2.007946
2018-12-05 11:10:33,971 - INFO - epoch 2, step 25120, training loss = 2.445815, validation loss = 2.254538
2018-12-05 11:10:39,155 - INFO - epoch 2, step 25130, training loss = 2.287974, validation loss = 2.603942
2018-12-05 11:10:44,648 - INFO - epoch 2, step 25140, training loss = 2.417777, validation loss = 2.469487
2018-12-05 11:10:50,108 - INFO - epoch 2, step 25150, training loss = 2.357636, validation loss = 2.296779
2018-12-05 11:10:54,659 - INFO - epoch 2, step 25160, training loss = 2.385536, validation loss = 2.202037
2018-12-05 11:10:58,485 - INFO - epoch 2, step 25170, training loss = 2.570377, validation loss = 2.175452
2018-12-05 11:11:02,038 - INFO - epoch 2, step 25180, training loss = 2.618296, validation loss = 2.023041
2018-12-05 11:11:05,520 - INFO - epoch 2, step 25190, training loss = 2.579523, validation loss = 2.264033
2018-12-05 11:11:09,088 - INFO - epoch 2, step 25200, training loss = 2.143235, validation loss = 2.120744
2018-12-05 11:11:12,568 - INFO - epoch 2, step 25210, training loss = 2.153757, validation loss = 2.435331
2018-12-05 11:11:16,009 - INFO - epoch 2, step 25220, training loss = 2.230827, validation loss = 2.213711
2018-12-05 11:11:19,765 - INFO - epoch 2, step 25230, training loss = 2.030890, validation loss = 2.028809
2018-12-05 11:11:23,555 - INFO - epoch 2, step 25240, training loss = 1.951764, validation loss = 2.246823
2018-12-05 11:11:27,024 - INFO - epoch 2, step 25250, training loss = 2.278645, validation loss = 1.893230
2018-12-05 11:11:30,352 - INFO - epoch 2, step 25260, training loss = 2.405254, validation loss = 1.985143
2018-12-05 11:11:34,267 - INFO - epoch 2, step 25270, training loss = 1.873228, validation loss = 2.153716
2018-12-05 11:11:39,950 - INFO - epoch 2, step 25280, training loss = 2.129566, validation loss = 1.949565
2018-12-05 11:11:45,292 - INFO - epoch 2, step 25290, training loss = 1.868587, validation loss = 2.083825
2018-12-05 11:11:50,530 - INFO - epoch 2, step 25300, training loss = 2.257667, validation loss = 1.954269
2018-12-05 11:11:55,966 - INFO - epoch 2, step 25310, training loss = 1.749051, validation loss = 2.397454
2018-12-05 11:12:01,845 - INFO - epoch 2, step 25320, training loss = 1.969216, validation loss = 2.117659
2018-12-05 11:12:07,104 - INFO - epoch 2, step 25330, training loss = 2.232667, validation loss = 2.389781
2018-12-05 11:12:12,096 - INFO - epoch 2, step 25340, training loss = 1.970959, validation loss = 2.364058
2018-12-05 11:12:17,702 - INFO - epoch 2, step 25350, training loss = 2.640598, validation loss = 2.421418
2018-12-05 11:12:24,170 - INFO - epoch 2, step 25360, training loss = 1.861296, validation loss = 1.908213
2018-12-05 11:12:29,487 - INFO - epoch 2, step 25370, training loss = 1.902588, validation loss = 2.217674
2018-12-05 11:12:34,688 - INFO - epoch 2, step 25380, training loss = 2.357901, validation loss = 2.151730
2018-12-05 11:12:39,906 - INFO - epoch 2, step 25390, training loss = 2.445168, validation loss = 2.206389
2018-12-05 11:12:45,175 - INFO - epoch 2, step 25400, training loss = 2.004194, validation loss = 2.179791
2018-12-05 11:12:50,570 - INFO - epoch 2, step 25410, training loss = 1.954669, validation loss = 2.149699
2018-12-05 11:12:56,002 - INFO - epoch 2, step 25420, training loss = 2.142842, validation loss = 2.581181
2018-12-05 11:13:01,118 - INFO - epoch 2, step 25430, training loss = 1.821706, validation loss = 2.501160
2018-12-05 11:13:06,262 - INFO - epoch 2, step 25440, training loss = 2.051356, validation loss = 2.298537
2018-12-05 11:13:11,738 - INFO - epoch 2, step 25450, training loss = 1.494910, validation loss = 2.338270
2018-12-05 11:13:17,148 - INFO - epoch 2, step 25460, training loss = 2.590764, validation loss = 1.995920
2018-12-05 11:13:20,351 - INFO - epoch 2, step 25470, training loss = 2.559558, validation loss = 2.041254
2018-12-05 11:13:23,612 - INFO - epoch 2, step 25480, training loss = 1.514383, validation loss = 1.976600
2018-12-05 11:13:26,740 - INFO - epoch 2, step 25490, training loss = 2.025287, validation loss = 2.234387
2018-12-05 11:13:30,050 - INFO - epoch 2, step 25500, training loss = 2.415374, validation loss = 2.172155
2018-12-05 11:13:33,253 - INFO - epoch 2, step 25510, training loss = 2.204335, validation loss = 2.222057
2018-12-05 11:13:36,364 - INFO - epoch 2, step 25520, training loss = 2.070284, validation loss = 2.144025
2018-12-05 11:13:39,602 - INFO - epoch 2, step 25530, training loss = 2.374516, validation loss = 1.514371
2018-12-05 11:13:42,663 - INFO - epoch 2, step 25540, training loss = 2.130121, validation loss = 2.149198
2018-12-05 11:13:45,843 - INFO - epoch 2, step 25550, training loss = 2.263954, validation loss = 2.581495
2018-12-05 11:13:49,052 - INFO - epoch 2, step 25560, training loss = 2.251674, validation loss = 2.168888
2018-12-05 11:13:52,242 - INFO - epoch 2, step 25570, training loss = 1.972941, validation loss = 2.542450
2018-12-05 11:13:55,440 - INFO - epoch 2, step 25580, training loss = 2.275075, validation loss = 2.163101
2018-12-05 11:14:00,612 - INFO - epoch 2, step 25590, training loss = 2.467197, validation loss = 2.534022
2018-12-05 11:14:06,203 - INFO - epoch 2, step 25600, training loss = 1.868484, validation loss = 2.337839
2018-12-05 11:14:11,866 - INFO - epoch 2, step 25610, training loss = 2.164353, validation loss = 2.207776
2018-12-05 11:14:17,051 - INFO - epoch 2, step 25620, training loss = 2.044735, validation loss = 2.316303
2018-12-05 11:14:22,446 - INFO - epoch 2, step 25630, training loss = 2.206461, validation loss = 2.407885
2018-12-05 11:14:27,800 - INFO - epoch 2, step 25640, training loss = 2.179565, validation loss = 2.353030
2018-12-05 11:14:33,055 - INFO - epoch 2, step 25650, training loss = 2.147270, validation loss = 1.934488
2018-12-05 11:14:38,364 - INFO - epoch 2, step 25660, training loss = 1.755022, validation loss = 2.099860
2018-12-05 11:14:43,872 - INFO - epoch 2, step 25670, training loss = 2.251595, validation loss = 2.015216
2018-12-05 11:14:49,615 - INFO - epoch 2, step 25680, training loss = 1.685900, validation loss = 2.374833
2018-12-05 11:14:55,015 - INFO - epoch 2, step 25690, training loss = 2.297550, validation loss = 2.524418
2018-12-05 11:15:01,536 - INFO - epoch 2, step 25700, training loss = 1.733868, validation loss = 2.413441
2018-12-05 11:15:06,984 - INFO - epoch 2, step 25710, training loss = 2.365688, validation loss = 2.102129
2018-12-05 11:15:12,364 - INFO - epoch 2, step 25720, training loss = 1.947075, validation loss = 2.487949
2018-12-05 11:15:18,110 - INFO - epoch 2, step 25730, training loss = 2.105037, validation loss = 2.057128
2018-12-05 11:15:24,200 - INFO - epoch 2, step 25740, training loss = 1.508360, validation loss = 2.555562
2018-12-05 11:15:29,189 - INFO - epoch 2, step 25750, training loss = 2.209197, validation loss = 1.743973
2018-12-05 11:15:33,572 - INFO - epoch 2, step 25760, training loss = 2.545577, validation loss = 2.513580
2018-12-05 11:15:37,625 - INFO - epoch 2, step 25770, training loss = 2.106865, validation loss = 1.976252
2018-12-05 11:15:41,789 - INFO - epoch 2, step 25780, training loss = 2.151429, validation loss = 2.542676
2018-12-05 11:15:46,192 - INFO - epoch 2, step 25790, training loss = 2.361232, validation loss = 1.887772
2018-12-05 11:15:50,505 - INFO - epoch 2, step 25800, training loss = 2.003830, validation loss = 1.557083
2018-12-05 11:15:54,660 - INFO - epoch 2, step 25810, training loss = 2.276544, validation loss = 2.138481
2018-12-05 11:15:57,952 - INFO - epoch 2, step 25820, training loss = 1.885159, validation loss = 1.776633
2018-12-05 11:16:01,283 - INFO - epoch 2, step 25830, training loss = 1.835618, validation loss = 2.053126
2018-12-05 11:16:04,330 - INFO - epoch 2, step 25840, training loss = 2.421890, validation loss = 2.359728
2018-12-05 11:16:07,543 - INFO - epoch 2, step 25850, training loss = 2.080985, validation loss = 2.047575
2018-12-05 11:16:10,643 - INFO - epoch 2, step 25860, training loss = 2.084625, validation loss = 1.948325
2018-12-05 11:16:13,834 - INFO - epoch 2, step 25870, training loss = 2.236908, validation loss = 2.144534
2018-12-05 11:16:17,029 - INFO - epoch 2, step 25880, training loss = 1.738772, validation loss = 2.100993
2018-12-05 11:16:20,073 - INFO - epoch 2, step 25890, training loss = 2.078912, validation loss = 2.554212
2018-12-05 11:16:23,401 - INFO - epoch 2, step 25900, training loss = 2.019980, validation loss = 2.444203
2018-12-05 11:16:26,583 - INFO - epoch 2, step 25910, training loss = 2.478017, validation loss = 2.193770
2018-12-05 11:16:29,597 - INFO - epoch 2, step 25920, training loss = 2.145403, validation loss = 2.327303
2018-12-05 11:16:32,949 - INFO - epoch 2, step 25930, training loss = 1.931741, validation loss = 2.315371
2018-12-05 11:16:36,160 - INFO - epoch 2, step 25940, training loss = 2.381738, validation loss = 1.937242
2018-12-05 11:16:39,536 - INFO - epoch 2, step 25950, training loss = 2.266713, validation loss = 2.089620
2018-12-05 11:16:44,550 - INFO - epoch 2, step 25960, training loss = 2.232939, validation loss = 2.139985
2018-12-05 11:16:49,804 - INFO - epoch 2, step 25970, training loss = 2.307724, validation loss = 2.108346
2018-12-05 11:16:54,991 - INFO - epoch 2, step 25980, training loss = 2.063079, validation loss = 2.266975
2018-12-05 11:17:00,585 - INFO - epoch 2, step 25990, training loss = 2.312108, validation loss = 2.139868
2018-12-05 11:17:05,713 - INFO - epoch 2, step 26000, training loss = 2.011288, validation loss = 1.674178
2018-12-05 11:17:10,722 - INFO - epoch 2, step 26010, training loss = 2.394589, validation loss = 2.168017
2018-12-05 11:17:16,225 - INFO - epoch 2, step 26020, training loss = 2.481516, validation loss = 2.190966
2018-12-05 11:17:21,414 - INFO - epoch 2, step 26030, training loss = 2.415519, validation loss = 1.996497
2018-12-05 11:17:26,974 - INFO - epoch 2, step 26040, training loss = 2.250379, validation loss = 1.968226
2018-12-05 11:17:31,962 - INFO - epoch 2, step 26050, training loss = 1.913916, validation loss = 2.091002
2018-12-05 11:17:37,233 - INFO - epoch 2, step 26060, training loss = 2.389069, validation loss = 1.927346
2018-12-05 11:17:42,316 - INFO - epoch 2, step 26070, training loss = 2.080223, validation loss = 2.100511
2018-12-05 11:17:47,332 - INFO - epoch 2, step 26080, training loss = 2.545289, validation loss = 2.601537
2018-12-05 11:17:52,612 - INFO - epoch 2, step 26090, training loss = 2.394004, validation loss = 2.274743
2018-12-05 11:17:57,506 - INFO - epoch 2, step 26100, training loss = 1.833915, validation loss = 2.449196
2018-12-05 11:18:02,442 - INFO - epoch 2, step 26110, training loss = 1.916912, validation loss = 2.325376
2018-12-05 11:18:07,324 - INFO - epoch 2, step 26120, training loss = 2.211134, validation loss = 2.044198
2018-12-05 11:18:12,395 - INFO - epoch 2, step 26130, training loss = 2.374364, validation loss = 2.004104
2018-12-05 11:18:17,857 - INFO - epoch 2, step 26140, training loss = 2.355474, validation loss = 1.741132
2018-12-05 11:18:22,863 - INFO - epoch 2, step 26150, training loss = 2.287121, validation loss = 1.752616
2018-12-05 11:18:28,513 - INFO - epoch 2, step 26160, training loss = 1.863241, validation loss = 2.176162
2018-12-05 11:18:34,032 - INFO - epoch 2, step 26170, training loss = 2.311680, validation loss = 2.290873
2018-12-05 11:18:39,874 - INFO - epoch 2, step 26180, training loss = 1.932434, validation loss = 2.181109
2018-12-05 11:18:45,314 - INFO - epoch 2, step 26190, training loss = 1.869214, validation loss = 1.741735
2018-12-05 11:18:51,611 - INFO - epoch 2, step 26200, training loss = 2.469788, validation loss = 1.871992
2018-12-05 11:18:57,407 - INFO - epoch 2, step 26210, training loss = 2.338788, validation loss = 2.019094
2018-12-05 11:19:02,546 - INFO - epoch 2, step 26220, training loss = 2.179835, validation loss = 2.162781
2018-12-05 11:19:07,907 - INFO - epoch 2, step 26230, training loss = 1.791825, validation loss = 2.218589
2018-12-05 11:19:13,133 - INFO - epoch 2, step 26240, training loss = 1.877562, validation loss = 1.891258
2018-12-05 11:19:18,737 - INFO - epoch 2, step 26250, training loss = 2.304260, validation loss = 1.984204
2018-12-05 11:19:24,246 - INFO - epoch 2, step 26260, training loss = 1.928240, validation loss = 1.960414
2018-12-05 11:19:29,902 - INFO - epoch 2, step 26270, training loss = 2.162680, validation loss = 1.975790
2018-12-05 11:19:35,370 - INFO - epoch 2, step 26280, training loss = 2.007990, validation loss = 2.079903
2018-12-05 11:19:41,497 - INFO - epoch 2, step 26290, training loss = 1.982072, validation loss = 1.815000
2018-12-05 11:19:46,942 - INFO - epoch 2, step 26300, training loss = 1.716934, validation loss = 1.721346
2018-12-05 11:19:51,969 - INFO - epoch 2, step 26310, training loss = 2.264977, validation loss = 2.082013
2018-12-05 11:19:57,237 - INFO - epoch 2, step 26320, training loss = 2.117270, validation loss = 2.027972
2018-12-05 11:20:02,551 - INFO - epoch 2, step 26330, training loss = 2.387621, validation loss = 2.168910
2018-12-05 11:20:07,795 - INFO - epoch 2, step 26340, training loss = 2.684205, validation loss = 2.306739
2018-12-05 11:20:12,903 - INFO - epoch 2, step 26350, training loss = 2.839998, validation loss = 1.857762
2018-12-05 11:20:17,958 - INFO - epoch 2, step 26360, training loss = 2.220742, validation loss = 1.792694
2018-12-05 11:20:23,234 - INFO - epoch 2, step 26370, training loss = 1.848069, validation loss = 2.224045
2018-12-05 11:20:28,582 - INFO - epoch 2, step 26380, training loss = 2.476448, validation loss = 2.011408
2018-12-05 11:20:33,877 - INFO - epoch 2, step 26390, training loss = 2.178708, validation loss = 2.299921
2018-12-05 11:20:39,195 - INFO - epoch 2, step 26400, training loss = 2.173779, validation loss = 1.759678
2018-12-05 11:20:44,359 - INFO - epoch 2, step 26410, training loss = 2.219111, validation loss = 2.337772
2018-12-05 11:20:49,852 - INFO - epoch 2, step 26420, training loss = 1.877395, validation loss = 2.112886
2018-12-05 11:20:55,264 - INFO - epoch 2, step 26430, training loss = 2.301197, validation loss = 2.238879
2018-12-05 11:21:00,265 - INFO - epoch 2, step 26440, training loss = 2.041027, validation loss = 2.027941
2018-12-05 11:21:05,233 - INFO - epoch 2, step 26450, training loss = 2.227271, validation loss = 2.187394
2018-12-05 11:21:10,540 - INFO - epoch 2, step 26460, training loss = 2.529779, validation loss = 2.676740
2018-12-05 11:21:15,005 - INFO - epoch 2, step 26470, training loss = 2.504351, validation loss = 2.472694
2018-12-05 11:21:18,501 - INFO - epoch 2, step 26480, training loss = 2.728484, validation loss = 2.129797
2018-12-05 11:21:21,796 - INFO - epoch 2, step 26490, training loss = 2.070546, validation loss = 1.645847
2018-12-05 11:21:25,144 - INFO - epoch 2, step 26500, training loss = 1.859434, validation loss = 2.195364
2018-12-05 11:21:28,557 - INFO - epoch 2, step 26510, training loss = 2.051602, validation loss = 2.460324
2018-12-05 11:21:32,109 - INFO - epoch 2, step 26520, training loss = 2.026488, validation loss = 2.259342
2018-12-05 11:21:35,569 - INFO - epoch 2, step 26530, training loss = 2.174869, validation loss = 2.104933
2018-12-05 11:21:38,890 - INFO - epoch 2, step 26540, training loss = 2.077747, validation loss = 2.315434
2018-12-05 11:21:42,187 - INFO - epoch 2, step 26550, training loss = 2.555179, validation loss = 2.071064
2018-12-05 11:21:45,425 - INFO - epoch 2, step 26560, training loss = 2.317188, validation loss = 2.312914
2018-12-05 11:21:48,578 - INFO - epoch 2, step 26570, training loss = 2.411265, validation loss = 2.162546
2018-12-05 11:21:51,695 - INFO - epoch 2, step 26580, training loss = 2.538843, validation loss = 2.613597
2018-12-05 11:21:54,833 - INFO - epoch 2, step 26590, training loss = 2.588399, validation loss = 2.101948
2018-12-05 11:21:57,889 - INFO - epoch 2, step 26600, training loss = 2.336961, validation loss = 2.112298
2018-12-05 11:22:01,046 - INFO - epoch 2, step 26610, training loss = 2.198249, validation loss = 1.871954
2018-12-05 11:22:04,077 - INFO - epoch 2, step 26620, training loss = 2.411398, validation loss = 1.953932
2018-12-05 11:22:07,208 - INFO - epoch 2, step 26630, training loss = 2.165065, validation loss = 2.136086
2018-12-05 11:22:10,359 - INFO - epoch 2, step 26640, training loss = 2.492039, validation loss = 2.536594
2018-12-05 11:22:13,615 - INFO - epoch 2, step 26650, training loss = 2.160605, validation loss = 2.518827
2018-12-05 11:22:16,822 - INFO - epoch 2, step 26660, training loss = 1.979824, validation loss = 1.637886
2018-12-05 11:22:20,065 - INFO - epoch 2, step 26670, training loss = 2.081438, validation loss = 2.137952
2018-12-05 11:22:23,296 - INFO - epoch 2, step 26680, training loss = 2.254562, validation loss = 2.169523
2018-12-05 11:22:26,405 - INFO - epoch 2, step 26690, training loss = 1.955915, validation loss = 2.362858
2018-12-05 11:22:29,615 - INFO - epoch 2, step 26700, training loss = 2.136537, validation loss = 1.969293
2018-12-05 11:22:32,765 - INFO - epoch 2, step 26710, training loss = 2.289763, validation loss = 1.801456
2018-12-05 11:22:37,548 - INFO - epoch 2, step 26720, training loss = 2.087477, validation loss = 2.262090
2018-12-05 11:22:43,234 - INFO - epoch 2, step 26730, training loss = 2.535277, validation loss = 1.902349
2018-12-05 11:22:49,097 - INFO - epoch 2, step 26740, training loss = 1.977870, validation loss = 2.364631
2018-12-05 11:22:55,109 - INFO - epoch 2, step 26750, training loss = 2.163072, validation loss = 2.475471
2018-12-05 11:23:01,263 - INFO - epoch 2, step 26760, training loss = 1.953866, validation loss = 2.208035
2018-12-05 11:23:07,179 - INFO - epoch 2, step 26770, training loss = 1.790354, validation loss = 1.764309
2018-12-05 11:23:12,539 - INFO - epoch 2, step 26780, training loss = 2.050250, validation loss = 2.370650
2018-12-05 11:23:17,950 - INFO - epoch 2, step 26790, training loss = 2.297303, validation loss = 2.092065
2018-12-05 11:23:23,421 - INFO - epoch 2, step 26800, training loss = 2.171413, validation loss = 2.042662
2018-12-05 11:23:28,697 - INFO - epoch 2, step 26810, training loss = 1.558986, validation loss = 1.953957
2018-12-05 11:23:34,530 - INFO - epoch 2, step 26820, training loss = 1.768070, validation loss = 1.838848
2018-12-05 11:23:40,034 - INFO - epoch 2, step 26830, training loss = 1.997696, validation loss = 2.276503
2018-12-05 11:23:45,959 - INFO - epoch 2, step 26840, training loss = 1.693632, validation loss = 1.941010
2018-12-05 11:23:51,332 - INFO - epoch 2, step 26850, training loss = 2.088114, validation loss = 1.984883
2018-12-05 11:23:56,523 - INFO - epoch 2, step 26860, training loss = 2.376827, validation loss = 2.153579
2018-12-05 11:24:01,741 - INFO - epoch 2, step 26870, training loss = 2.515944, validation loss = 2.228730
2018-12-05 11:24:07,006 - INFO - epoch 2, step 26880, training loss = 2.425657, validation loss = 2.177677
2018-12-05 11:24:12,110 - INFO - epoch 2, step 26890, training loss = 2.440878, validation loss = 2.065761
2018-12-05 11:24:17,792 - INFO - epoch 2, step 26900, training loss = 2.114609, validation loss = 2.275462
2018-12-05 11:24:22,973 - INFO - epoch 2, step 26910, training loss = 2.288477, validation loss = 2.226729
2018-12-05 11:24:28,221 - INFO - epoch 2, step 26920, training loss = 2.389749, validation loss = 2.033224
2018-12-05 11:24:33,707 - INFO - epoch 2, step 26930, training loss = 2.386447, validation loss = 1.858413
2018-12-05 11:24:38,796 - INFO - epoch 2, step 26940, training loss = 2.380638, validation loss = 2.110950
2018-12-05 11:24:44,063 - INFO - epoch 2, step 26950, training loss = 2.628154, validation loss = 1.921032
2018-12-05 11:24:49,359 - INFO - epoch 2, step 26960, training loss = 2.198006, validation loss = 2.450393
2018-12-05 11:24:54,788 - INFO - epoch 2, step 26970, training loss = 2.474302, validation loss = 2.125457
2018-12-05 11:25:00,508 - INFO - epoch 2, step 26980, training loss = 2.396466, validation loss = 2.073873
2018-12-05 11:25:05,912 - INFO - epoch 2, step 26990, training loss = 2.466303, validation loss = 2.318237
2018-12-05 11:25:11,297 - INFO - epoch 2, step 27000, training loss = 2.619610, validation loss = 1.763082
2018-12-05 11:25:16,517 - INFO - epoch 2, step 27010, training loss = 2.693942, validation loss = 2.058324
2018-12-05 11:25:21,800 - INFO - epoch 2, step 27020, training loss = 1.952626, validation loss = 2.435452
2018-12-05 11:25:26,910 - INFO - epoch 2, step 27030, training loss = 2.239684, validation loss = 2.076676
2018-12-05 11:25:31,966 - INFO - epoch 2, step 27040, training loss = 2.576357, validation loss = 2.431891
2018-12-05 11:25:37,117 - INFO - epoch 2, step 27050, training loss = 2.378136, validation loss = 2.176240
2018-12-05 11:25:41,832 - INFO - epoch 2, step 27060, training loss = 2.383437, validation loss = 1.667584
2018-12-05 11:25:46,061 - INFO - epoch 2, step 27070, training loss = 2.298559, validation loss = 2.129122
2018-12-05 11:25:50,406 - INFO - epoch 2, step 27080, training loss = 2.252495, validation loss = 2.086768
2018-12-05 11:25:54,569 - INFO - epoch 2, step 27090, training loss = 2.103987, validation loss = 1.728137
2018-12-05 11:25:58,868 - INFO - epoch 2, step 27100, training loss = 1.842038, validation loss = 2.016596
2018-12-05 11:26:03,000 - INFO - epoch 2, step 27110, training loss = 1.799136, validation loss = 2.077091
2018-12-05 11:26:06,689 - INFO - epoch 2, step 27120, training loss = 2.111519, validation loss = 1.814401
2018-12-05 11:26:10,665 - INFO - epoch 2, step 27130, training loss = 1.779228, validation loss = 1.918232
2018-12-05 11:26:14,508 - INFO - epoch 2, step 27140, training loss = 1.956612, validation loss = 2.129205
2018-12-05 11:26:18,083 - INFO - epoch 2, step 27150, training loss = 2.216913, validation loss = 2.318825
2018-12-05 11:26:21,805 - INFO - epoch 2, step 27160, training loss = 2.009720, validation loss = 1.623536
2018-12-05 11:26:26,848 - INFO - epoch 2, step 27170, training loss = 1.954977, validation loss = 2.063085
2018-12-05 11:26:31,688 - INFO - epoch 2, step 27180, training loss = 2.164295, validation loss = 2.146655
2018-12-05 11:26:36,664 - INFO - epoch 2, step 27190, training loss = 2.112152, validation loss = 2.105407
2018-12-05 11:26:41,820 - INFO - epoch 2, step 27200, training loss = 2.247413, validation loss = 1.780369
2018-12-05 11:26:46,955 - INFO - epoch 2, step 27210, training loss = 2.166712, validation loss = 2.199063
2018-12-05 11:26:52,052 - INFO - epoch 2, step 27220, training loss = 2.177202, validation loss = 2.066234
2018-12-05 11:26:57,238 - INFO - epoch 2, step 27230, training loss = 1.994696, validation loss = 2.298034
2018-12-05 11:27:02,514 - INFO - epoch 2, step 27240, training loss = 2.184862, validation loss = 2.058351
2018-12-05 11:27:07,746 - INFO - epoch 2, step 27250, training loss = 2.097453, validation loss = 2.214201
2018-12-05 11:27:13,265 - INFO - epoch 2, step 27260, training loss = 1.580190, validation loss = 1.971815
2018-12-05 11:27:18,278 - INFO - epoch 2, step 27270, training loss = 2.433444, validation loss = 1.940995
2018-12-05 11:27:23,293 - INFO - epoch 2, step 27280, training loss = 2.263206, validation loss = 2.014760
2018-12-05 11:27:28,375 - INFO - epoch 2, step 27290, training loss = 2.311265, validation loss = 1.538596
2018-12-05 11:27:32,815 - INFO - epoch 2, step 27300, training loss = 2.213160, validation loss = 2.171373
2018-12-05 11:27:36,940 - INFO - epoch 2, step 27310, training loss = 2.138001, validation loss = 2.148072
2018-12-05 11:27:41,677 - INFO - epoch 2, step 27320, training loss = 1.940288, validation loss = 2.572099
2018-12-05 11:27:46,439 - INFO - epoch 2, step 27330, training loss = 2.349916, validation loss = 2.073928
2018-12-05 11:27:50,924 - INFO - epoch 2, step 27340, training loss = 1.998608, validation loss = 2.358439
2018-12-05 11:27:54,969 - INFO - epoch 2, step 27350, training loss = 1.799625, validation loss = 2.372820
2018-12-05 11:27:59,192 - INFO - epoch 2, step 27360, training loss = 2.129143, validation loss = 2.157971
2018-12-05 11:28:03,289 - INFO - epoch 2, step 27370, training loss = 2.366926, validation loss = 2.294286
2018-12-05 11:28:08,005 - INFO - epoch 2, step 27380, training loss = 2.115163, validation loss = 1.536336
2018-12-05 11:28:12,495 - INFO - epoch 2, step 27390, training loss = 1.985337, validation loss = 1.944496
2018-12-05 11:28:16,066 - INFO - epoch 2, step 27400, training loss = 2.232599, validation loss = 2.265799
2018-12-05 11:28:19,182 - INFO - epoch 2, step 27410, training loss = 2.311683, validation loss = 1.786448
2018-12-05 11:28:22,243 - INFO - epoch 2, step 27420, training loss = 2.112128, validation loss = 2.041340
2018-12-05 11:28:25,322 - INFO - epoch 2, step 27430, training loss = 2.116623, validation loss = 2.256170
2018-12-05 11:28:28,761 - INFO - epoch 2, step 27440, training loss = 2.360337, validation loss = 2.138802
2018-12-05 11:28:31,982 - INFO - epoch 2, step 27450, training loss = 2.211755, validation loss = 2.164358
2018-12-05 11:28:35,234 - INFO - epoch 2, step 27460, training loss = 2.353101, validation loss = 2.158813
2018-12-05 11:28:38,456 - INFO - epoch 2, step 27470, training loss = 2.513909, validation loss = 2.139531
2018-12-05 11:28:41,654 - INFO - epoch 2, step 27480, training loss = 2.313513, validation loss = 2.189182
2018-12-05 11:28:44,953 - INFO - epoch 2, step 27490, training loss = 2.146945, validation loss = 2.777239
2018-12-05 11:28:48,145 - INFO - epoch 2, step 27500, training loss = 2.197230, validation loss = 2.106154
2018-12-05 11:28:51,502 - INFO - epoch 2, step 27510, training loss = 1.927603, validation loss = 2.872719
2018-12-05 11:28:54,823 - INFO - epoch 2, step 27520, training loss = 1.954545, validation loss = 1.617773
2018-12-05 11:28:58,138 - INFO - epoch 2, step 27530, training loss = 2.193006, validation loss = 2.490127
2018-12-05 11:29:01,571 - INFO - epoch 2, step 27540, training loss = 1.783135, validation loss = 2.405983
2018-12-05 11:29:05,021 - INFO - epoch 2, step 27550, training loss = 1.586911, validation loss = 2.178671
2018-12-05 11:29:08,437 - INFO - epoch 2, step 27560, training loss = 2.241645, validation loss = 1.969936
2018-12-05 11:29:12,196 - INFO - epoch 2, step 27570, training loss = 2.286195, validation loss = 2.222100
2018-12-05 11:29:16,440 - INFO - epoch 2, step 27580, training loss = 2.046492, validation loss = 2.304753
2018-12-05 11:29:20,622 - INFO - epoch 2, step 27590, training loss = 2.425639, validation loss = 2.621092
2018-12-05 11:29:24,889 - INFO - epoch 2, step 27600, training loss = 2.258708, validation loss = 2.191720
2018-12-05 11:29:29,466 - INFO - epoch 2, step 27610, training loss = 1.720575, validation loss = 2.385899
2018-12-05 11:29:33,835 - INFO - epoch 2, step 27620, training loss = 2.332465, validation loss = 2.323990
2018-12-05 11:29:38,812 - INFO - epoch 2, step 27630, training loss = 1.923193, validation loss = 2.221670
2018-12-05 11:29:44,930 - INFO - epoch 2, step 27640, training loss = 1.912420, validation loss = 2.062382
2018-12-05 11:29:50,525 - INFO - epoch 2, step 27650, training loss = 1.579072, validation loss = 2.216109
2018-12-05 11:29:56,192 - INFO - epoch 2, step 27660, training loss = 2.252524, validation loss = 2.363220
2018-12-05 11:30:02,270 - INFO - epoch 2, step 27670, training loss = 1.724628, validation loss = 2.296634
2018-12-05 11:30:08,200 - INFO - epoch 2, step 27680, training loss = 1.949101, validation loss = 2.529106
2018-12-05 11:30:13,965 - INFO - epoch 2, step 27690, training loss = 1.955796, validation loss = 2.453359
2018-12-05 11:30:19,562 - INFO - epoch 2, step 27700, training loss = 1.779032, validation loss = 2.155284
2018-12-05 11:30:26,159 - INFO - epoch 2, step 27710, training loss = 1.946604, validation loss = 2.281074
2018-12-05 11:30:31,805 - INFO - epoch 2, step 27720, training loss = 2.052249, validation loss = 2.463890
2018-12-05 11:30:37,719 - INFO - epoch 2, step 27730, training loss = 1.794166, validation loss = 2.461581
2018-12-05 11:30:43,464 - INFO - epoch 2, step 27740, training loss = 2.251760, validation loss = 3.087302
2018-12-05 11:30:49,039 - INFO - epoch 2, step 27750, training loss = 2.026889, validation loss = 2.699625
2018-12-05 11:30:54,315 - INFO - epoch 2, step 27760, training loss = 2.029290, validation loss = 2.341358
2018-12-05 11:30:59,886 - INFO - epoch 2, step 27770, training loss = 1.928863, validation loss = 2.347875
2018-12-05 11:31:05,286 - INFO - epoch 2, step 27780, training loss = 1.841329, validation loss = 1.997284
2018-12-05 11:31:10,748 - INFO - epoch 2, step 27790, training loss = 2.214321, validation loss = 2.379969
2018-12-05 11:31:15,707 - INFO - epoch 2, step 27800, training loss = 2.105464, validation loss = 2.232970
2018-12-05 11:31:20,691 - INFO - epoch 2, step 27810, training loss = 2.390084, validation loss = 2.257011
2018-12-05 11:31:25,732 - INFO - epoch 2, step 27820, training loss = 2.150831, validation loss = 2.203397
2018-12-05 11:31:30,907 - INFO - epoch 2, step 27830, training loss = 2.181770, validation loss = 1.953811
2018-12-05 11:31:36,556 - INFO - epoch 2, step 27840, training loss = 1.695881, validation loss = 2.196509
2018-12-05 11:31:41,641 - INFO - epoch 2, step 27850, training loss = 1.848876, validation loss = 2.539843
2018-12-05 11:31:46,659 - INFO - epoch 2, step 27860, training loss = 2.081445, validation loss = 2.789101
2018-12-05 11:31:52,116 - INFO - epoch 2, step 27870, training loss = 1.528605, validation loss = 2.149395
2018-12-05 11:31:57,548 - INFO - epoch 2, step 27880, training loss = 1.717973, validation loss = 2.512696
2018-12-05 11:32:02,660 - INFO - epoch 2, step 27890, training loss = 2.197275, validation loss = 2.301209
2018-12-05 11:32:07,975 - INFO - epoch 2, step 27900, training loss = 2.229010, validation loss = 2.371238
2018-12-05 11:32:12,939 - INFO - epoch 2, step 27910, training loss = 2.029297, validation loss = 2.253316
2018-12-05 11:32:18,090 - INFO - epoch 2, step 27920, training loss = 2.225198, validation loss = 2.595307
2018-12-05 11:32:23,240 - INFO - epoch 2, step 27930, training loss = 2.408080, validation loss = 2.323081
2018-12-05 11:32:28,805 - INFO - epoch 2, step 27940, training loss = 1.694432, validation loss = 2.354208
2018-12-05 11:32:34,081 - INFO - epoch 2, step 27950, training loss = 1.928147, validation loss = 2.416986
2018-12-05 11:32:39,608 - INFO - epoch 2, step 27960, training loss = 1.403311, validation loss = 2.242329
2018-12-05 11:32:44,942 - INFO - epoch 2, step 27970, training loss = 1.979673, validation loss = 2.667588
2018-12-05 11:32:50,203 - INFO - epoch 2, step 27980, training loss = 1.774977, validation loss = 2.013518
2018-12-05 11:32:55,422 - INFO - epoch 2, step 27990, training loss = 2.055689, validation loss = 1.968358
2018-12-05 11:33:00,535 - INFO - epoch 2, step 28000, training loss = 2.064416, validation loss = 2.254799
2018-12-05 11:33:05,947 - INFO - epoch 2, step 28010, training loss = 2.076964, validation loss = 2.477382
2018-12-05 11:33:11,421 - INFO - epoch 2, step 28020, training loss = 2.035644, validation loss = 2.284507
2018-12-05 11:33:16,721 - INFO - epoch 2, step 28030, training loss = 2.283400, validation loss = 2.690774
2018-12-05 11:33:21,957 - INFO - epoch 2, step 28040, training loss = 1.992400, validation loss = 2.210765
2018-12-05 11:33:27,314 - INFO - epoch 2, step 28050, training loss = 1.857742, validation loss = 2.067972
2018-12-05 11:33:32,621 - INFO - epoch 2, step 28060, training loss = 1.657637, validation loss = 2.139405
2018-12-05 11:33:39,097 - INFO - epoch 2, step 28070, training loss = 1.641470, validation loss = 2.363561
2018-12-05 11:33:44,442 - INFO - epoch 2, step 28080, training loss = 2.079669, validation loss = 2.105253
2018-12-05 11:33:49,749 - INFO - epoch 2, step 28090, training loss = 1.704618, validation loss = 2.177854
2018-12-05 11:33:54,974 - INFO - epoch 2, step 28100, training loss = 1.995147, validation loss = 2.312436
2018-12-05 11:34:00,407 - INFO - epoch 2, step 28110, training loss = 1.960718, validation loss = 2.126362
2018-12-05 11:34:05,734 - INFO - epoch 2, step 28120, training loss = 2.138628, validation loss = 2.275405
2018-12-05 11:34:10,814 - INFO - epoch 2, step 28130, training loss = 1.960258, validation loss = 2.281192
2018-12-05 11:34:15,935 - INFO - epoch 2, step 28140, training loss = 1.899639, validation loss = 2.099984
2018-12-05 11:34:21,261 - INFO - epoch 2, step 28150, training loss = 2.508805, validation loss = 2.105414
2018-12-05 11:34:26,573 - INFO - epoch 2, step 28160, training loss = 2.009283, validation loss = 2.577463
2018-12-05 11:34:31,895 - INFO - epoch 2, step 28170, training loss = 2.096273, validation loss = 2.229965
2018-12-05 11:34:37,054 - INFO - epoch 2, step 28180, training loss = 1.905013, validation loss = 2.325567
2018-12-05 11:34:42,241 - INFO - epoch 2, step 28190, training loss = 2.098276, validation loss = 2.388656
2018-12-05 11:34:47,453 - INFO - epoch 2, step 28200, training loss = 1.995676, validation loss = 2.526017
2018-12-05 11:34:52,602 - INFO - epoch 2, step 28210, training loss = 2.159765, validation loss = 2.082116
2018-12-05 11:34:57,951 - INFO - epoch 2, step 28220, training loss = 2.437249, validation loss = 2.080590
2018-12-05 11:35:03,170 - INFO - epoch 2, step 28230, training loss = 2.197215, validation loss = 2.060628
2018-12-05 11:35:08,306 - INFO - epoch 2, step 28240, training loss = 2.183615, validation loss = 2.428306
2018-12-05 11:35:13,363 - INFO - epoch 2, step 28250, training loss = 1.888689, validation loss = 2.140983
2018-12-05 11:35:18,565 - INFO - epoch 2, step 28260, training loss = 1.809252, validation loss = 2.621475
2018-12-05 11:35:23,944 - INFO - epoch 2, step 28270, training loss = 2.000468, validation loss = 2.585143
2018-12-05 11:35:29,095 - INFO - epoch 2, step 28280, training loss = 2.038988, validation loss = 2.195368
2018-12-05 11:35:34,270 - INFO - epoch 2, step 28290, training loss = 2.250163, validation loss = 2.174714
2018-12-05 11:35:39,312 - INFO - epoch 2, step 28300, training loss = 2.352077, validation loss = 2.213009
2018-12-05 11:35:44,539 - INFO - epoch 2, step 28310, training loss = 2.008373, validation loss = 2.636623
2018-12-05 11:35:49,771 - INFO - epoch 2, step 28320, training loss = 2.397445, validation loss = 2.367454
2018-12-05 11:35:55,196 - INFO - epoch 2, step 28330, training loss = 2.327412, validation loss = 2.443192
2018-12-05 11:36:00,296 - INFO - epoch 2, step 28340, training loss = 2.356555, validation loss = 2.114824
2018-12-05 11:36:05,448 - INFO - epoch 2, step 28350, training loss = 2.201923, validation loss = 2.504447
2018-12-05 11:36:10,549 - INFO - epoch 2, step 28360, training loss = 2.569319, validation loss = 2.569670
2018-12-05 11:36:14,868 - INFO - epoch 2, step 28370, training loss = 2.263426, validation loss = 2.591224
2018-12-05 11:36:19,180 - INFO - epoch 2, step 28380, training loss = 2.501397, validation loss = 1.989475
2018-12-05 11:36:23,498 - INFO - epoch 2, step 28390, training loss = 2.264905, validation loss = 2.032686
2018-12-05 11:36:28,072 - INFO - epoch 2, step 28400, training loss = 1.569612, validation loss = 2.316055
2018-12-05 11:36:32,747 - INFO - epoch 2, step 28410, training loss = 1.747651, validation loss = 1.937733
2018-12-05 11:36:38,161 - INFO - epoch 2, step 28420, training loss = 2.029611, validation loss = 1.988440
2018-12-05 11:36:43,946 - INFO - epoch 2, step 28430, training loss = 1.919093, validation loss = 2.185400
2018-12-05 11:36:49,441 - INFO - epoch 2, step 28440, training loss = 1.570228, validation loss = 1.974031
2018-12-05 11:36:55,107 - INFO - epoch 2, step 28450, training loss = 1.901956, validation loss = 1.891752
2018-12-05 11:37:01,159 - INFO - epoch 2, step 28460, training loss = 1.973316, validation loss = 2.257824
2018-12-05 11:37:07,082 - INFO - epoch 2, step 28470, training loss = 1.673394, validation loss = 2.117543
2018-12-05 11:37:13,167 - INFO - epoch 2, step 28480, training loss = 2.247401, validation loss = 1.733128
2018-12-05 11:37:18,641 - INFO - epoch 2, step 28490, training loss = 2.341799, validation loss = 2.232783
2018-12-05 11:37:24,935 - INFO - epoch 2, step 28500, training loss = 1.824742, validation loss = 2.282176
2018-12-05 11:37:31,012 - INFO - epoch 2, step 28510, training loss = 1.567212, validation loss = 2.157040
2018-12-05 11:37:34,311 - INFO - epoch 2, step 28520, training loss = 2.055740, validation loss = 2.280544
2018-12-05 11:37:37,409 - INFO - epoch 2, step 28530, training loss = 1.849310, validation loss = 2.178061
2018-12-05 11:37:40,725 - INFO - epoch 2, step 28540, training loss = 3.109330, validation loss = 2.169642
2018-12-05 11:37:43,992 - INFO - epoch 2, step 28550, training loss = 2.581538, validation loss = 2.188457
2018-12-05 11:37:47,303 - INFO - epoch 2, step 28560, training loss = 1.974352, validation loss = 1.809052
2018-12-05 11:37:50,630 - INFO - epoch 2, step 28570, training loss = 2.026538, validation loss = 2.268345
2018-12-05 11:37:53,981 - INFO - epoch 2, step 28580, training loss = 2.442280, validation loss = 2.234217
2018-12-05 11:37:57,360 - INFO - epoch 2, step 28590, training loss = 1.888458, validation loss = 2.267962
2018-12-05 11:38:00,476 - INFO - epoch 2, step 28600, training loss = 2.501616, validation loss = 2.074893
2018-12-05 11:38:03,633 - INFO - epoch 2, step 28610, training loss = 2.146564, validation loss = 1.866294
2018-12-05 11:38:06,823 - INFO - epoch 2, step 28620, training loss = 1.796831, validation loss = 2.138884
2018-12-05 11:38:10,051 - INFO - epoch 2, step 28630, training loss = 1.825236, validation loss = 2.448504
2018-12-05 11:38:13,193 - INFO - epoch 2, step 28640, training loss = 1.954514, validation loss = 2.070446
2018-12-05 11:38:16,596 - INFO - epoch 2, step 28650, training loss = 2.232661, validation loss = 2.245668
2018-12-05 11:38:20,884 - INFO - epoch 2, step 28660, training loss = 1.743083, validation loss = 2.076287
2018-12-05 11:38:25,424 - INFO - epoch 2, step 28670, training loss = 2.128350, validation loss = 2.148867
2018-12-05 11:38:29,544 - INFO - epoch 2, step 28680, training loss = 2.241799, validation loss = 2.251117
2018-12-05 11:38:33,831 - INFO - epoch 2, step 28690, training loss = 2.232953, validation loss = 2.133077
2018-12-05 11:38:38,089 - INFO - epoch 2, step 28700, training loss = 2.415024, validation loss = 2.496633
2018-12-05 11:38:42,977 - INFO - epoch 2, step 28710, training loss = 2.759098, validation loss = 2.459341
2018-12-05 11:38:48,335 - INFO - epoch 2, step 28720, training loss = 2.300459, validation loss = 2.206514
2018-12-05 11:38:53,802 - INFO - epoch 2, step 28730, training loss = 2.084984, validation loss = 2.319095
2018-12-05 11:38:58,793 - INFO - epoch 2, step 28740, training loss = 2.166174, validation loss = 2.321072
2018-12-05 11:39:03,853 - INFO - epoch 2, step 28750, training loss = 2.275729, validation loss = 1.846252
2018-12-05 11:39:09,029 - INFO - epoch 2, step 28760, training loss = 2.224108, validation loss = 2.074091
2018-12-05 11:39:14,025 - INFO - epoch 2, step 28770, training loss = 2.354584, validation loss = 2.098915
2018-12-05 11:39:19,280 - INFO - epoch 2, step 28780, training loss = 2.506172, validation loss = 1.976608
2018-12-05 11:39:24,328 - INFO - epoch 2, step 28790, training loss = 2.171002, validation loss = 1.956006
2018-12-05 11:39:29,587 - INFO - epoch 2, step 28800, training loss = 2.190165, validation loss = 1.853747
2018-12-05 11:39:34,912 - INFO - epoch 2, step 28810, training loss = 2.085294, validation loss = 2.088497
2018-12-05 11:39:40,173 - INFO - epoch 2, step 28820, training loss = 2.238906, validation loss = 2.164907
2018-12-05 11:39:45,384 - INFO - epoch 2, step 28830, training loss = 1.649347, validation loss = 2.013586
2018-12-05 11:39:50,605 - INFO - epoch 2, step 28840, training loss = 2.346551, validation loss = 1.916246
2018-12-05 11:39:55,972 - INFO - epoch 2, step 28850, training loss = 1.805096, validation loss = 2.319909
2018-12-05 11:40:01,376 - INFO - epoch 2, step 28860, training loss = 2.441119, validation loss = 2.226329
2018-12-05 11:40:06,568 - INFO - epoch 2, step 28870, training loss = 2.633786, validation loss = 2.149264
2018-12-05 11:40:11,726 - INFO - epoch 2, step 28880, training loss = 2.118289, validation loss = 2.438624
2018-12-05 11:40:16,913 - INFO - epoch 2, step 28890, training loss = 1.915591, validation loss = 2.134798
2018-12-05 11:40:22,070 - INFO - epoch 2, step 28900, training loss = 1.995562, validation loss = 2.090267
2018-12-05 11:40:27,531 - INFO - epoch 2, step 28910, training loss = 2.408361, validation loss = 2.284450
2018-12-05 11:40:32,757 - INFO - epoch 2, step 28920, training loss = 2.413099, validation loss = 2.322341
2018-12-05 11:40:37,921 - INFO - epoch 2, step 28930, training loss = 2.109282, validation loss = 2.222937
2018-12-05 11:40:43,162 - INFO - epoch 2, step 28940, training loss = 2.327425, validation loss = 1.972194
2018-12-05 11:40:48,581 - INFO - epoch 2, step 28950, training loss = 2.225929, validation loss = 2.035222
2018-12-05 11:40:54,017 - INFO - epoch 2, step 28960, training loss = 2.376218, validation loss = 2.405041
2018-12-05 11:40:59,354 - INFO - epoch 2, step 28970, training loss = 2.417802, validation loss = 2.147065
2018-12-05 11:41:04,886 - INFO - epoch 2, step 28980, training loss = 2.483473, validation loss = 2.266022
2018-12-05 11:41:10,201 - INFO - epoch 2, step 28990, training loss = 2.114159, validation loss = 1.838638
2018-12-05 11:41:15,737 - INFO - epoch 2, step 29000, training loss = 2.201879, validation loss = 2.371741
2018-12-05 11:41:20,842 - INFO - epoch 2, step 29010, training loss = 2.286513, validation loss = 2.431599
2018-12-05 11:41:26,324 - INFO - epoch 2, step 29020, training loss = 2.113741, validation loss = 2.228963
2018-12-05 11:41:31,738 - INFO - epoch 2, step 29030, training loss = 2.477170, validation loss = 2.136605
2018-12-05 11:41:36,908 - INFO - epoch 2, step 29040, training loss = 2.575193, validation loss = 2.288588
2018-12-05 11:41:42,167 - INFO - epoch 2, step 29050, training loss = 2.202937, validation loss = 2.173333
2018-12-05 11:41:46,716 - INFO - epoch 2, step 29060, training loss = 1.805359, validation loss = 2.105662
2018-12-05 11:41:51,212 - INFO - epoch 2, step 29070, training loss = 2.194055, validation loss = 2.156005
2018-12-05 11:41:55,773 - INFO - epoch 2, step 29080, training loss = 2.014920, validation loss = 1.907085
2018-12-05 11:42:00,347 - INFO - epoch 2, step 29090, training loss = 2.232874, validation loss = 2.008396
2018-12-05 11:42:04,838 - INFO - epoch 2, step 29100, training loss = 1.917905, validation loss = 1.869006
2018-12-05 11:42:09,190 - INFO - epoch 2, step 29110, training loss = 2.211629, validation loss = 2.004755
2018-12-05 11:42:14,933 - INFO - epoch 2, step 29120, training loss = 1.915724, validation loss = 1.931713
2018-12-05 11:42:20,958 - INFO - epoch 2, step 29130, training loss = 2.333578, validation loss = 1.817968
2018-12-05 11:42:26,553 - INFO - epoch 2, step 29140, training loss = 2.188994, validation loss = 2.265387
2018-12-05 11:42:32,094 - INFO - epoch 2, step 29150, training loss = 2.152492, validation loss = 2.006060
2018-12-05 11:42:37,719 - INFO - epoch 2, step 29160, training loss = 1.740981, validation loss = 2.023504
2018-12-05 11:42:43,565 - INFO - epoch 2, step 29170, training loss = 2.197350, validation loss = 2.195497
2018-12-05 11:42:49,514 - INFO - epoch 2, step 29180, training loss = 1.701492, validation loss = 1.874904
2018-12-05 11:42:55,829 - INFO - epoch 2, step 29190, training loss = 1.659856, validation loss = 1.874841
2018-12-05 11:43:01,569 - INFO - epoch 2, step 29200, training loss = 1.816581, validation loss = 1.849297
2018-12-05 11:43:07,919 - INFO - epoch 2, step 29210, training loss = 2.060047, validation loss = 2.072853
2018-12-05 11:43:13,456 - INFO - epoch 2, step 29220, training loss = 2.377068, validation loss = 1.842852
2018-12-05 11:43:18,915 - INFO - epoch 2, step 29230, training loss = 2.118394, validation loss = 2.084926
2018-12-05 11:43:24,651 - INFO - epoch 2, step 29240, training loss = 1.870010, validation loss = 2.313416
2018-12-05 11:43:29,888 - INFO - epoch 2, step 29250, training loss = 2.105175, validation loss = 2.138078
2018-12-05 11:43:35,388 - INFO - epoch 2, step 29260, training loss = 2.195532, validation loss = 2.173596
2018-12-05 11:43:40,947 - INFO - epoch 2, step 29270, training loss = 2.294706, validation loss = 2.169010
2018-12-05 11:43:46,669 - INFO - epoch 2, step 29280, training loss = 2.208900, validation loss = 2.000223
2018-12-05 11:43:51,972 - INFO - epoch 2, step 29290, training loss = 2.297872, validation loss = 2.078470
2018-12-05 11:43:57,249 - INFO - epoch 2, step 29300, training loss = 2.338136, validation loss = 2.312154
2018-12-05 11:44:02,419 - INFO - epoch 2, step 29310, training loss = 2.462301, validation loss = 1.999955
2018-12-05 11:44:07,647 - INFO - epoch 2, step 29320, training loss = 2.310297, validation loss = 2.235277
2018-12-05 11:44:12,890 - INFO - epoch 2, step 29330, training loss = 2.542244, validation loss = 2.553481
2018-12-05 11:44:18,086 - INFO - epoch 2, step 29340, training loss = 2.264333, validation loss = 2.440095
2018-12-05 11:44:23,650 - INFO - epoch 2, step 29350, training loss = 1.731286, validation loss = 2.127374
2018-12-05 11:44:29,068 - INFO - epoch 2, step 29360, training loss = 1.914610, validation loss = 2.306532
2018-12-05 11:44:34,142 - INFO - epoch 2, step 29370, training loss = 1.768116, validation loss = 2.428037
2018-12-05 11:44:39,865 - INFO - epoch 2, step 29380, training loss = 1.924392, validation loss = 2.277066
2018-12-05 11:44:45,358 - INFO - epoch 2, step 29390, training loss = 1.931807, validation loss = 2.126892
2018-12-05 11:44:50,925 - INFO - epoch 2, step 29400, training loss = 2.045104, validation loss = 2.182463
2018-12-05 11:44:56,386 - INFO - epoch 2, step 29410, training loss = 2.424781, validation loss = 1.971722
2018-12-05 11:45:01,583 - INFO - epoch 2, step 29420, training loss = 2.170544, validation loss = 2.213936
2018-12-05 11:45:07,198 - INFO - epoch 2, step 29430, training loss = 2.085273, validation loss = 2.218441
2018-12-05 11:45:12,463 - INFO - epoch 2, step 29440, training loss = 2.149398, validation loss = 2.364235
2018-12-05 11:45:17,908 - INFO - epoch 2, step 29450, training loss = 2.241998, validation loss = 2.114982
2018-12-05 11:45:23,265 - INFO - epoch 2, step 29460, training loss = 2.103584, validation loss = 2.202877
2018-12-05 11:45:28,493 - INFO - epoch 2, step 29470, training loss = 2.380147, validation loss = 2.436330
2018-12-05 11:45:33,738 - INFO - epoch 2, step 29480, training loss = 2.196565, validation loss = 2.507973
2018-12-05 11:45:39,115 - INFO - epoch 2, step 29490, training loss = 2.194265, validation loss = 2.576039
2018-12-05 11:45:44,139 - INFO - epoch 2, step 29500, training loss = 2.419223, validation loss = 2.656015
2018-12-05 11:45:49,925 - INFO - epoch 2, step 29510, training loss = 1.913509, validation loss = 2.592131
2018-12-05 11:45:55,082 - INFO - epoch 2, step 29520, training loss = 1.918995, validation loss = 2.658839
2018-12-05 11:46:00,243 - INFO - epoch 2, step 29530, training loss = 2.222552, validation loss = 2.627897
2018-12-05 11:46:06,037 - INFO - epoch 2, step 29540, training loss = 2.335566, validation loss = 2.267654
2018-12-05 11:46:11,185 - INFO - epoch 2, step 29550, training loss = 2.366501, validation loss = 2.352774
2018-12-05 11:46:16,790 - INFO - epoch 2, step 29560, training loss = 1.924389, validation loss = 2.283731
2018-12-05 11:46:22,351 - INFO - epoch 2, step 29570, training loss = 2.007994, validation loss = 2.716387
2018-12-05 11:46:27,529 - INFO - epoch 2, step 29580, training loss = 2.259220, validation loss = 2.073685
2018-12-05 11:46:32,915 - INFO - epoch 2, step 29590, training loss = 2.429636, validation loss = 2.508631
2018-12-05 11:46:38,106 - INFO - epoch 2, step 29600, training loss = 1.988784, validation loss = 2.493844
2018-12-05 11:46:43,360 - INFO - epoch 2, step 29610, training loss = 2.042207, validation loss = 2.343868
2018-12-05 11:46:48,743 - INFO - epoch 2, step 29620, training loss = 1.937876, validation loss = 2.320721
2018-12-05 11:46:54,065 - INFO - epoch 2, step 29630, training loss = 1.884548, validation loss = 2.599336
2018-12-05 11:46:59,601 - INFO - epoch 2, step 29640, training loss = 2.309799, validation loss = 2.404815
2018-12-05 11:47:04,994 - INFO - epoch 2, step 29650, training loss = 2.222964, validation loss = 2.247855
2018-12-05 11:47:10,354 - INFO - epoch 2, step 29660, training loss = 1.788179, validation loss = 2.228699
2018-12-05 11:47:15,427 - INFO - epoch 2, step 29670, training loss = 2.412586, validation loss = 2.171166
2018-12-05 11:47:20,679 - INFO - epoch 2, step 29680, training loss = 2.152051, validation loss = 2.309235
2018-12-05 11:47:25,865 - INFO - epoch 2, step 29690, training loss = 2.345239, validation loss = 2.284299
2018-12-05 11:47:30,567 - INFO - epoch 2, step 29700, training loss = 2.268128, validation loss = 2.627033
2018-12-05 11:47:34,678 - INFO - epoch 2, step 29710, training loss = 1.983097, validation loss = 2.698101
2018-12-05 11:47:39,036 - INFO - epoch 2, step 29720, training loss = 2.261361, validation loss = 2.295949
2018-12-05 11:47:43,797 - INFO - epoch 2, step 29730, training loss = 2.050399, validation loss = 1.911741
2018-12-05 11:47:48,175 - INFO - epoch 2, step 29740, training loss = 2.081797, validation loss = 2.427268
2018-12-05 11:47:52,384 - INFO - epoch 2, step 29750, training loss = 2.036856, validation loss = 2.375940
2018-12-05 11:47:57,127 - INFO - epoch 2, step 29760, training loss = 1.951676, validation loss = 2.223992
2018-12-05 11:48:02,323 - INFO - epoch 2, step 29770, training loss = 2.177229, validation loss = 2.293570
2018-12-05 11:48:07,429 - INFO - epoch 2, step 29780, training loss = 2.197809, validation loss = 2.003062
2018-12-05 11:48:12,448 - INFO - epoch 2, step 29790, training loss = 2.154389, validation loss = 1.983736
2018-12-05 11:48:17,570 - INFO - epoch 2, step 29800, training loss = 1.997820, validation loss = 2.117465
2018-12-05 11:48:22,913 - INFO - epoch 2, step 29810, training loss = 1.962020, validation loss = 2.318723
2018-12-05 11:48:28,023 - INFO - epoch 2, step 29820, training loss = 2.102304, validation loss = 2.079406
2018-12-05 11:48:33,106 - INFO - epoch 2, step 29830, training loss = 2.280377, validation loss = 2.335403
2018-12-05 11:48:38,895 - INFO - epoch 2, step 29840, training loss = 2.182040, validation loss = 1.882488
2018-12-05 11:48:44,232 - INFO - epoch 2, step 29850, training loss = 1.897625, validation loss = 2.318388
2018-12-05 11:48:49,654 - INFO - epoch 2, step 29860, training loss = 2.468206, validation loss = 2.385990
2018-12-05 11:48:54,793 - INFO - epoch 2, step 29870, training loss = 2.213811, validation loss = 2.076780
2018-12-05 11:49:00,506 - INFO - epoch 2, step 29880, training loss = 2.345531, validation loss = 2.256072
2018-12-05 11:49:05,866 - INFO - epoch 2, step 29890, training loss = 2.216540, validation loss = 2.418019
2018-12-05 11:49:11,270 - INFO - epoch 2, step 29900, training loss = 2.305285, validation loss = 2.636059
2018-12-05 11:49:16,588 - INFO - epoch 2, step 29910, training loss = 2.209614, validation loss = 2.301561
2018-12-05 11:49:21,799 - INFO - epoch 2, step 29920, training loss = 2.237825, validation loss = 2.100748
2018-12-05 11:49:27,040 - INFO - epoch 2, step 29930, training loss = 2.009571, validation loss = 2.250214
2018-12-05 11:49:32,459 - INFO - epoch 2, step 29940, training loss = 2.005013, validation loss = 2.125850
2018-12-05 11:49:37,805 - INFO - epoch 2, step 29950, training loss = 2.323369, validation loss = 2.225149
2018-12-05 11:49:43,108 - INFO - epoch 2, step 29960, training loss = 2.609713, validation loss = 2.635510
2018-12-05 11:49:48,327 - INFO - epoch 2, step 29970, training loss = 2.105840, validation loss = 2.598883
2018-12-05 11:49:53,754 - INFO - epoch 2, step 29980, training loss = 2.035763, validation loss = 2.512893
2018-12-05 11:49:58,975 - INFO - epoch 2, step 29990, training loss = 2.125907, validation loss = 2.189325
2018-12-05 11:50:04,497 - INFO - epoch 2, step 30000, training loss = 1.996569, validation loss = 2.541562
2018-12-05 11:50:09,777 - INFO - epoch 2, step 30010, training loss = 2.340806, validation loss = 2.429325
2018-12-05 11:50:14,975 - INFO - epoch 2, step 30020, training loss = 2.252666, validation loss = 2.360914
2018-12-05 11:50:20,267 - INFO - epoch 2, step 30030, training loss = 2.180152, validation loss = 2.649270
2018-12-05 11:50:25,411 - INFO - epoch 2, step 30040, training loss = 2.210387, validation loss = 2.515782
2018-12-05 11:50:30,651 - INFO - epoch 2, step 30050, training loss = 1.943185, validation loss = 2.142776
2018-12-05 11:50:35,568 - INFO - epoch 2, step 30060, training loss = 2.153666, validation loss = 2.202304
2018-12-05 11:50:40,140 - INFO - epoch 2, step 30070, training loss = 1.901110, validation loss = 2.260274
2018-12-05 11:50:44,559 - INFO - epoch 2, step 30080, training loss = 2.142567, validation loss = 2.097109
2018-12-05 11:50:48,752 - INFO - epoch 2, step 30090, training loss = 2.152787, validation loss = 2.911183
2018-12-05 11:50:52,953 - INFO - epoch 2, step 30100, training loss = 2.571028, validation loss = 2.289956
2018-12-05 11:50:56,591 - INFO - epoch 2, step 30110, training loss = 2.181949, validation loss = 2.291004
2018-12-05 11:50:59,901 - INFO - epoch 2, step 30120, training loss = 2.131994, validation loss = 2.255702
2018-12-05 11:51:03,092 - INFO - epoch 2, step 30130, training loss = 2.207145, validation loss = 2.627482
2018-12-05 11:51:06,296 - INFO - epoch 2, step 30140, training loss = 2.023572, validation loss = 2.582763
2018-12-05 11:51:09,568 - INFO - epoch 2, step 30150, training loss = 1.892390, validation loss = 2.535194
2018-12-05 11:51:12,862 - INFO - epoch 2, step 30160, training loss = 2.083651, validation loss = 2.319474
2018-12-05 11:51:16,157 - INFO - epoch 2, step 30170, training loss = 2.115482, validation loss = 1.846079
2018-12-05 11:51:19,489 - INFO - epoch 2, step 30180, training loss = 1.786464, validation loss = 2.190058
2018-12-05 11:51:22,833 - INFO - epoch 2, step 30190, training loss = 1.907657, validation loss = 2.313327
2018-12-05 11:51:26,217 - INFO - epoch 2, step 30200, training loss = 2.354416, validation loss = 2.085494
2018-12-05 11:51:29,453 - INFO - epoch 2, step 30210, training loss = 2.473186, validation loss = 2.752028
2018-12-05 11:51:34,236 - INFO - epoch 2, step 30220, training loss = 2.179110, validation loss = 2.240214
2018-12-05 11:51:39,426 - INFO - epoch 2, step 30230, training loss = 2.509588, validation loss = 2.098216
2018-12-05 11:51:45,168 - INFO - epoch 2, step 30240, training loss = 2.502706, validation loss = 2.539417
2018-12-05 11:51:50,195 - INFO - epoch 2, step 30250, training loss = 2.269988, validation loss = 2.023857
2018-12-05 11:51:55,193 - INFO - epoch 2, step 30260, training loss = 1.838289, validation loss = 2.241232
2018-12-05 11:52:00,299 - INFO - epoch 2, step 30270, training loss = 2.092346, validation loss = 2.396296
2018-12-05 11:52:05,597 - INFO - epoch 2, step 30280, training loss = 2.452117, validation loss = 2.208030
2018-12-05 11:52:10,721 - INFO - epoch 2, step 30290, training loss = 1.905100, validation loss = 2.314934
2018-12-05 11:52:15,881 - INFO - epoch 2, step 30300, training loss = 2.017472, validation loss = 2.710875
2018-12-05 11:52:21,025 - INFO - epoch 2, step 30310, training loss = 2.133640, validation loss = 2.695669
2018-12-05 11:52:26,090 - INFO - epoch 2, step 30320, training loss = 2.378171, validation loss = 2.409291
2018-12-05 11:52:31,136 - INFO - epoch 2, step 30330, training loss = 1.896435, validation loss = 2.403727
2018-12-05 11:52:36,490 - INFO - epoch 2, step 30340, training loss = 2.078162, validation loss = 1.927062
2018-12-05 11:52:41,578 - INFO - epoch 2, step 30350, training loss = 2.221079, validation loss = 2.661153
2018-12-05 11:52:47,253 - INFO - epoch 2, step 30360, training loss = 2.207452, validation loss = 2.276746
2018-12-05 11:52:52,919 - INFO - epoch 2, step 30370, training loss = 2.193116, validation loss = 2.652707
2018-12-05 11:52:58,228 - INFO - epoch 2, step 30380, training loss = 2.098399, validation loss = 2.149533
2018-12-05 11:53:03,960 - INFO - epoch 2, step 30390, training loss = 2.086014, validation loss = 2.229404
2018-12-05 11:53:10,191 - INFO - epoch 2, step 30400, training loss = 1.438480, validation loss = 2.427140
2018-12-05 11:53:16,315 - INFO - epoch 2, step 30410, training loss = 1.292801, validation loss = 2.144076
2018-12-05 11:53:21,717 - INFO - epoch 2, step 30420, training loss = 1.791111, validation loss = 2.411665
2018-12-05 11:53:27,668 - INFO - epoch 2, step 30430, training loss = 1.711352, validation loss = 2.751880
2018-12-05 11:53:33,138 - INFO - epoch 2, step 30440, training loss = 1.982617, validation loss = 2.342934
2018-12-05 11:53:38,263 - INFO - epoch 2, step 30450, training loss = 1.955972, validation loss = 2.726757
2018-12-05 11:53:43,858 - INFO - epoch 2, step 30460, training loss = 1.547190, validation loss = 2.494298
2018-12-05 11:53:49,386 - INFO - epoch 2, step 30470, training loss = 2.028013, validation loss = 2.266068
2018-12-05 11:53:54,917 - INFO - epoch 2, step 30480, training loss = 1.724368, validation loss = 2.173561
2018-12-05 11:54:00,325 - INFO - epoch 2, step 30490, training loss = 2.293179, validation loss = 2.122633
2018-12-05 11:54:05,625 - INFO - epoch 2, step 30500, training loss = 2.090114, validation loss = 2.708089
2018-12-05 11:54:11,325 - INFO - epoch 2, step 30510, training loss = 1.637457, validation loss = 2.389741
2018-12-05 11:54:16,768 - INFO - epoch 2, step 30520, training loss = 2.339549, validation loss = 2.626550
2018-12-05 11:54:21,788 - INFO - epoch 2, step 30530, training loss = 2.168096, validation loss = 2.012398
2018-12-05 11:54:27,328 - INFO - epoch 2, step 30540, training loss = 1.856042, validation loss = 2.182269
2018-12-05 11:54:32,693 - INFO - epoch 2, step 30550, training loss = 2.120538, validation loss = 2.298650
2018-12-05 11:54:38,406 - INFO - epoch 2, step 30560, training loss = 2.045645, validation loss = 2.293807
2018-12-05 11:54:44,129 - INFO - epoch 2, step 30570, training loss = 2.340337, validation loss = 2.030507
2018-12-05 11:54:49,790 - INFO - epoch 2, step 30580, training loss = 1.858916, validation loss = 2.122130
2018-12-05 11:54:55,316 - INFO - epoch 2, step 30590, training loss = 1.745356, validation loss = 2.079763
2018-12-05 11:55:00,559 - INFO - epoch 2, step 30600, training loss = 2.086478, validation loss = 2.021203
2018-12-05 11:55:06,501 - INFO - epoch 2, step 30610, training loss = 1.933875, validation loss = 2.219189
2018-12-05 11:55:11,823 - INFO - epoch 2, step 30620, training loss = 1.848632, validation loss = 2.544118
2018-12-05 11:55:18,143 - INFO - epoch 2, step 30630, training loss = 1.923035, validation loss = 2.530216
2018-12-05 11:55:24,013 - INFO - epoch 2, step 30640, training loss = 1.845779, validation loss = 2.465664
2018-12-05 11:55:29,348 - INFO - epoch 2, step 30650, training loss = 1.916413, validation loss = 2.335178
2018-12-05 11:55:35,167 - INFO - epoch 2, step 30660, training loss = 1.842079, validation loss = 2.133348
2018-12-05 11:55:40,725 - INFO - epoch 2, step 30670, training loss = 2.023330, validation loss = 2.349768
2018-12-05 11:55:46,231 - INFO - epoch 2, step 30680, training loss = 2.096026, validation loss = 2.156885
2018-12-05 11:55:51,833 - INFO - epoch 2, step 30690, training loss = 1.914327, validation loss = 2.222363
2018-12-05 11:55:57,687 - INFO - epoch 2, step 30700, training loss = 1.615553, validation loss = 2.601085
2018-12-05 11:56:03,427 - INFO - epoch 2, step 30710, training loss = 1.883430, validation loss = 2.039403
2018-12-05 11:56:08,994 - INFO - epoch 2, step 30720, training loss = 2.326227, validation loss = 1.667959
2018-12-05 11:56:14,246 - INFO - epoch 2, step 30730, training loss = 1.870056, validation loss = 2.318678
2018-12-05 11:56:20,027 - INFO - epoch 2, step 30740, training loss = 1.961820, validation loss = 2.231418
2018-12-05 11:56:24,602 - INFO - epoch 2, step 30750, training loss = 3.504020, validation loss = 2.601430
2018-12-05 11:56:27,324 - INFO - epoch 2, step 30760, training loss = 1.996609, validation loss = 2.597238
2018-12-05 11:56:30,092 - INFO - epoch 2, step 30770, training loss = 2.937571, validation loss = 2.578026
2018-12-05 11:56:33,080 - INFO - epoch 2, step 30780, training loss = 2.068626, validation loss = 2.363550
2018-12-05 11:56:35,880 - INFO - epoch 2, step 30790, training loss = 2.763330, validation loss = 2.318006
2018-12-05 11:56:38,782 - INFO - epoch 2, step 30800, training loss = 1.933847, validation loss = 2.855480
2018-12-05 11:56:41,686 - INFO - epoch 2, step 30810, training loss = 2.520896, validation loss = 2.201630
2018-12-05 11:56:44,602 - INFO - epoch 2, step 30820, training loss = 2.189886, validation loss = 2.141726
2018-12-05 11:56:47,486 - INFO - epoch 2, step 30830, training loss = 2.265218, validation loss = 2.513778
2018-12-05 11:56:50,564 - INFO - epoch 2, step 30840, training loss = 2.030548, validation loss = 3.010405
2018-12-05 11:56:54,150 - INFO - epoch 2, step 30850, training loss = 1.678903, validation loss = 2.183929
2018-12-05 11:56:57,627 - INFO - epoch 2, step 30860, training loss = 2.420012, validation loss = 2.659909
2018-12-05 11:57:00,963 - INFO - epoch 2, step 30870, training loss = 2.569196, validation loss = 2.170135
2018-12-05 11:57:04,224 - INFO - epoch 2, step 30880, training loss = 1.924762, validation loss = 2.169783
2018-12-05 11:57:09,661 - INFO - epoch 2, step 30890, training loss = 2.019176, validation loss = 2.472625
2018-12-05 11:57:15,324 - INFO - epoch 2, step 30900, training loss = 1.996403, validation loss = 2.419053
2018-12-05 11:57:20,575 - INFO - epoch 2, step 30910, training loss = 2.226722, validation loss = 2.457744
2018-12-05 11:57:26,049 - INFO - epoch 2, step 30920, training loss = 2.349711, validation loss = 2.423556
2018-12-05 11:57:31,261 - INFO - epoch 2, step 30930, training loss = 2.110622, validation loss = 2.295128
2018-12-05 11:57:36,395 - INFO - epoch 2, step 30940, training loss = 1.916496, validation loss = 1.917171
2018-12-05 11:57:41,905 - INFO - epoch 2, step 30950, training loss = 2.134308, validation loss = 2.198600
2018-12-05 11:57:48,118 - INFO - epoch 2, step 30960, training loss = 1.994993, validation loss = 2.480472
2018-12-05 11:57:54,051 - INFO - epoch 2, step 30970, training loss = 2.361186, validation loss = 2.111100
2018-12-05 11:57:59,656 - INFO - epoch 2, step 30980, training loss = 1.812578, validation loss = 2.186285
2018-12-05 11:58:05,526 - INFO - epoch 2, step 30990, training loss = 2.004502, validation loss = 2.439865
2018-12-05 11:58:11,462 - INFO - epoch 2, step 31000, training loss = 1.787231, validation loss = 2.192077
2018-12-05 11:58:17,440 - INFO - epoch 2, step 31010, training loss = 2.132075, validation loss = 2.007435
2018-12-05 11:58:22,921 - INFO - epoch 2, step 31020, training loss = 1.904958, validation loss = 2.013580
2018-12-05 11:58:28,816 - INFO - epoch 2, step 31030, training loss = 2.184155, validation loss = 2.230044
2018-12-05 11:58:34,309 - INFO - epoch 2, step 31040, training loss = 2.516522, validation loss = 2.099439
2018-12-05 11:58:40,409 - INFO - epoch 2, step 31050, training loss = 1.671858, validation loss = 2.564232
2018-12-05 11:58:45,813 - INFO - epoch 2, step 31060, training loss = 2.621083, validation loss = 2.395068
2018-12-05 11:58:48,969 - INFO - epoch 2, step 31070, training loss = 2.128083, validation loss = 2.052435
2018-12-05 11:58:52,286 - INFO - epoch 2, step 31080, training loss = 2.096539, validation loss = 2.142984
2018-12-05 11:58:55,665 - INFO - epoch 2, step 31090, training loss = 2.452736, validation loss = 2.631644
2018-12-05 11:58:58,976 - INFO - epoch 2, step 31100, training loss = 2.152188, validation loss = 2.321521
2018-12-05 11:59:02,224 - INFO - epoch 2, step 31110, training loss = 2.219727, validation loss = 2.554751
2018-12-05 11:59:05,489 - INFO - epoch 2, step 31120, training loss = 2.842685, validation loss = 2.443949
2018-12-05 11:59:08,715 - INFO - epoch 2, step 31130, training loss = 2.094840, validation loss = 2.357993
2018-12-05 11:59:11,874 - INFO - epoch 2, step 31140, training loss = 2.066469, validation loss = 2.582533
2018-12-05 11:59:15,240 - INFO - epoch 2, step 31150, training loss = 2.152652, validation loss = 2.414921
2018-12-05 11:59:18,306 - INFO - epoch 2, step 31160, training loss = 2.052714, validation loss = 2.350502
2018-12-05 11:59:21,610 - INFO - epoch 2, step 31170, training loss = 2.430257, validation loss = 2.172851
2018-12-05 11:59:25,039 - INFO - epoch 2, step 31180, training loss = 2.316253, validation loss = 2.296045
2018-12-05 11:59:28,386 - INFO - epoch 2, step 31190, training loss = 2.265942, validation loss = 2.200468
2018-12-05 11:59:32,495 - INFO - epoch 2, step 31200, training loss = 2.334722, validation loss = 2.004488
2018-12-05 11:59:36,589 - INFO - epoch 2, step 31210, training loss = 1.998137, validation loss = 2.029839
2018-12-05 11:59:40,675 - INFO - epoch 2, step 31220, training loss = 2.156605, validation loss = 2.170623
2018-12-05 11:59:44,900 - INFO - epoch 2, step 31230, training loss = 2.396650, validation loss = 2.331095
2018-12-05 11:59:49,109 - INFO - epoch 2, step 31240, training loss = 2.231838, validation loss = 2.402366
2018-12-05 11:59:53,459 - INFO - epoch 2, step 31250, training loss = 2.279265, validation loss = 1.888330
2018-12-05 11:59:57,091 - INFO - epoch 2, step 31260, training loss = 1.832615, validation loss = 2.118711
2018-12-05 12:00:00,721 - INFO - epoch 2, step 31270, training loss = 1.834784, validation loss = 2.314204
2018-12-05 12:00:04,412 - INFO - epoch 2, step 31280, training loss = 1.938495, validation loss = 2.257880
2018-12-05 12:00:08,462 - INFO - epoch 2, step 31290, training loss = 1.888089, validation loss = 2.278820
2018-12-05 12:00:12,057 - INFO - epoch 2, step 31300, training loss = 2.359960, validation loss = 2.233066
2018-12-05 12:00:14,556 - INFO - epoch 2, step 31310, training loss = 1.709877, validation loss = 2.081153
2018-12-05 12:00:17,054 - INFO - epoch 2, step 31320, training loss = 1.979566, validation loss = 2.438600
2018-12-05 12:00:19,543 - INFO - epoch 2, step 31330, training loss = 2.686719, validation loss = 2.502293
2018-12-05 12:00:22,024 - INFO - epoch 2, step 31340, training loss = 1.713649, validation loss = 2.363765
2018-12-05 12:00:24,647 - INFO - epoch 2, step 31350, training loss = 1.606579, validation loss = 2.644825
2018-12-05 12:00:27,179 - INFO - epoch 2, step 31360, training loss = 2.222556, validation loss = 2.234642
2018-12-05 12:00:29,709 - INFO - epoch 2, step 31370, training loss = 2.265955, validation loss = 2.101808
2018-12-05 12:00:32,165 - INFO - epoch 2, step 31380, training loss = 2.353319, validation loss = 2.367622
2018-12-05 12:00:34,763 - INFO - epoch 2, step 31390, training loss = 2.521402, validation loss = 2.320957
2018-12-05 12:00:37,346 - INFO - epoch 2, step 31400, training loss = 1.984012, validation loss = 2.810586
2018-12-05 12:00:39,922 - INFO - epoch 2, step 31410, training loss = 2.737918, validation loss = 2.223498
2018-12-05 12:00:42,505 - INFO - epoch 2, step 31420, training loss = 1.834014, validation loss = 2.791718
2018-12-05 12:00:44,962 - INFO - epoch 2, step 31430, training loss = 2.198263, validation loss = 2.117412
2018-12-05 12:00:47,436 - INFO - epoch 2, step 31440, training loss = 2.537022, validation loss = 2.383351
2018-12-05 12:00:50,483 - INFO - epoch 2, step 31450, training loss = 2.372881, validation loss = 2.202655
2018-12-05 12:00:53,883 - INFO - epoch 2, step 31460, training loss = 2.252066, validation loss = 2.528591
2018-12-05 12:00:57,227 - INFO - epoch 2, step 31470, training loss = 2.296146, validation loss = 2.610369
2018-12-05 12:01:00,374 - INFO - epoch 2, step 31480, training loss = 2.583045, validation loss = 2.142540
2018-12-05 12:01:03,528 - INFO - epoch 2, step 31490, training loss = 1.949791, validation loss = 2.399620
2018-12-05 12:01:06,889 - INFO - epoch 2, step 31500, training loss = 2.121523, validation loss = 2.341421
2018-12-05 12:01:10,124 - INFO - epoch 2, step 31510, training loss = 2.261507, validation loss = 2.843670
2018-12-05 12:01:13,342 - INFO - epoch 2, step 31520, training loss = 2.258747, validation loss = 2.785591
2018-12-05 12:01:16,656 - INFO - epoch 2, step 31530, training loss = 1.858915, validation loss = 1.983163
2018-12-05 12:01:20,066 - INFO - epoch 2, step 31540, training loss = 2.424171, validation loss = 2.097435
2018-12-05 12:01:23,422 - INFO - epoch 2, step 31550, training loss = 2.365003, validation loss = 2.305206
2018-12-05 12:01:26,842 - INFO - epoch 2, step 31560, training loss = 2.318603, validation loss = 2.724891
2018-12-05 12:01:30,700 - INFO - epoch 2, step 31570, training loss = 2.552804, validation loss = 2.251734
2018-12-05 12:01:36,056 - INFO - epoch 2, step 31580, training loss = 2.543639, validation loss = 2.099513
2018-12-05 12:01:41,206 - INFO - epoch 2, step 31590, training loss = 2.353294, validation loss = 2.235473
2018-12-05 12:01:46,276 - INFO - epoch 2, step 31600, training loss = 2.449386, validation loss = 2.446455
2018-12-05 12:01:51,335 - INFO - epoch 2, step 31610, training loss = 2.324838, validation loss = 2.416413
2018-12-05 12:01:56,496 - INFO - epoch 2, step 31620, training loss = 1.983823, validation loss = 2.539637
2018-12-05 12:02:01,678 - INFO - epoch 2, step 31630, training loss = 2.486034, validation loss = 2.469498
2018-12-05 12:02:06,797 - INFO - epoch 2, step 31640, training loss = 2.137277, validation loss = 2.662693
2018-12-05 12:02:12,024 - INFO - epoch 2, step 31650, training loss = 1.827412, validation loss = 1.873978
2018-12-05 12:02:17,097 - INFO - epoch 2, step 31660, training loss = 2.086940, validation loss = 2.240618
2018-12-05 12:02:22,615 - INFO - epoch 2, step 31670, training loss = 2.363545, validation loss = 2.201312
2018-12-05 12:02:27,911 - INFO - epoch 2, step 31680, training loss = 2.204830, validation loss = 2.361763
2018-12-05 12:02:33,123 - INFO - epoch 2, step 31690, training loss = 1.981356, validation loss = 2.385449
2018-12-05 12:02:38,342 - INFO - epoch 2, step 31700, training loss = 2.427609, validation loss = 2.223790
2018-12-05 12:02:43,559 - INFO - epoch 2, step 31710, training loss = 2.281786, validation loss = 2.148396
2018-12-05 12:02:48,873 - INFO - epoch 2, step 31720, training loss = 2.282916, validation loss = 2.432382
2018-12-05 12:02:53,999 - INFO - epoch 2, step 31730, training loss = 2.021542, validation loss = 2.256796
2018-12-05 12:02:59,122 - INFO - epoch 2, step 31740, training loss = 2.218789, validation loss = 2.131780
2018-12-05 12:03:04,486 - INFO - epoch 2, step 31750, training loss = 2.772270, validation loss = 2.210684
2018-12-05 12:03:09,890 - INFO - epoch 2, step 31760, training loss = 2.204428, validation loss = 2.074115
2018-12-05 12:03:14,992 - INFO - epoch 2, step 31770, training loss = 2.067602, validation loss = 2.411279
2018-12-05 12:03:20,550 - INFO - epoch 2, step 31780, training loss = 2.413308, validation loss = 2.629895
2018-12-05 12:03:24,486 - INFO - epoch 2, step 31790, training loss = 2.789436, validation loss = 1.738469
2018-12-05 12:03:26,920 - INFO - epoch 2, step 31800, training loss = 2.232976, validation loss = 2.166241
2018-12-05 12:03:29,550 - INFO - epoch 2, step 31810, training loss = 2.248196, validation loss = 2.732628
2018-12-05 12:03:32,079 - INFO - epoch 2, step 31820, training loss = 2.067553, validation loss = 2.636906
2018-12-05 12:03:34,531 - INFO - epoch 2, step 31830, training loss = 1.802824, validation loss = 2.936827
2018-12-05 12:03:36,989 - INFO - epoch 2, step 31840, training loss = 2.224492, validation loss = 2.309523
2018-12-05 12:03:39,489 - INFO - epoch 2, step 31850, training loss = 1.957920, validation loss = 2.123080
2018-12-05 12:03:41,882 - INFO - epoch 2, step 31860, training loss = 2.298774, validation loss = 2.446338
2018-12-05 12:03:44,530 - INFO - epoch 2, step 31870, training loss = 1.823482, validation loss = 2.259977
2018-12-05 12:03:47,037 - INFO - epoch 2, step 31880, training loss = 2.212904, validation loss = 2.739286
2018-12-05 12:03:49,443 - INFO - epoch 2, step 31890, training loss = 2.024806, validation loss = 2.866546
2018-12-05 12:03:51,968 - INFO - epoch 2, step 31900, training loss = 2.399474, validation loss = 2.437253
2018-12-05 12:03:54,546 - INFO - epoch 2, step 31910, training loss = 2.165720, validation loss = 2.366612
2018-12-05 12:03:56,969 - INFO - epoch 2, step 31920, training loss = 2.090605, validation loss = 2.475889
2018-12-05 12:03:59,453 - INFO - epoch 2, step 31930, training loss = 2.229253, validation loss = 2.357045
2018-12-05 12:04:04,967 - INFO - epoch 2, step 31940, training loss = 2.269960, validation loss = 2.518067
2018-12-05 12:04:10,647 - INFO - epoch 2, step 31950, training loss = 2.089579, validation loss = 2.050589
2018-12-05 12:04:16,727 - INFO - epoch 2, step 31960, training loss = 1.681954, validation loss = 2.471529
2018-12-05 12:04:22,469 - INFO - epoch 2, step 31970, training loss = 2.113223, validation loss = 2.009241
2018-12-05 12:04:28,001 - INFO - epoch 2, step 31980, training loss = 1.832534, validation loss = 2.065298
2018-12-05 12:04:34,188 - INFO - epoch 2, step 31990, training loss = 2.088675, validation loss = 2.045854
2018-12-05 12:04:40,734 - INFO - epoch 2, step 32000, training loss = 2.045646, validation loss = 2.503521
2018-12-05 12:04:46,838 - INFO - epoch 2, step 32010, training loss = 1.421605, validation loss = 2.235526
2018-12-05 12:04:52,704 - INFO - epoch 2, step 32020, training loss = 1.704845, validation loss = 2.010632
2018-12-05 12:04:58,223 - INFO - epoch 2, step 32030, training loss = 1.985374, validation loss = 1.934743
2018-12-05 12:05:03,361 - INFO - epoch 2, step 32040, training loss = 1.984907, validation loss = 2.188539
2018-12-05 12:05:09,068 - INFO - epoch 2, step 32050, training loss = 2.472112, validation loss = 2.639599
2018-12-05 12:05:14,852 - INFO - epoch 2, step 32060, training loss = 1.949403, validation loss = 2.324614
2018-12-05 12:05:21,278 - INFO - epoch 2, step 32070, training loss = 1.752436, validation loss = 2.118817
2018-12-05 12:05:27,186 - INFO - epoch 2, step 32080, training loss = 1.803007, validation loss = 2.332193
2018-12-05 12:05:32,642 - INFO - epoch 2, step 32090, training loss = 1.851296, validation loss = 2.207637
2018-12-05 12:05:38,466 - INFO - epoch 2, step 32100, training loss = 1.476287, validation loss = 2.772661
2018-12-05 12:05:44,245 - INFO - epoch 2, step 32110, training loss = 2.162867, validation loss = 2.001001
2018-12-05 12:05:49,477 - INFO - epoch 2, step 32120, training loss = 2.986636, validation loss = 2.064317
2018-12-05 12:05:52,079 - INFO - epoch 2, step 32130, training loss = 2.246079, validation loss = 2.088392
2018-12-05 12:05:54,620 - INFO - epoch 2, step 32140, training loss = 2.056723, validation loss = 2.419201
2018-12-05 12:05:57,035 - INFO - epoch 2, step 32150, training loss = 1.819034, validation loss = 2.586556
2018-12-05 12:05:59,457 - INFO - epoch 2, step 32160, training loss = 2.061707, validation loss = 2.461731
2018-12-05 12:06:01,998 - INFO - epoch 2, step 32170, training loss = 1.758665, validation loss = 2.315683
2018-12-05 12:06:04,452 - INFO - epoch 2, step 32180, training loss = 1.867265, validation loss = 1.873594
2018-12-05 12:06:06,940 - INFO - epoch 2, step 32190, training loss = 1.691262, validation loss = 2.097720
2018-12-05 12:06:09,462 - INFO - epoch 2, step 32200, training loss = 2.123504, validation loss = 2.173456
2018-12-05 12:06:12,022 - INFO - epoch 2, step 32210, training loss = 1.582326, validation loss = 2.352838
2018-12-05 12:06:14,482 - INFO - epoch 2, step 32220, training loss = 1.724890, validation loss = 2.369880
2018-12-05 12:06:16,957 - INFO - epoch 2, step 32230, training loss = 2.511581, validation loss = 2.226217
2018-12-05 12:06:19,459 - INFO - epoch 2, step 32240, training loss = 1.260008, validation loss = 2.122548
2018-12-05 12:06:21,977 - INFO - epoch 2, step 32250, training loss = 2.238468, validation loss = 2.420271
2018-12-05 12:06:24,460 - INFO - epoch 2, step 32260, training loss = 1.901208, validation loss = 2.607818
2018-12-05 12:06:26,926 - INFO - epoch 2, step 32270, training loss = 2.404860, validation loss = 2.462322
2018-12-05 12:06:31,902 - INFO - epoch 2, step 32280, training loss = 2.000057, validation loss = 2.329034
2018-12-05 12:06:37,454 - INFO - epoch 2, step 32290, training loss = 2.133373, validation loss = 2.175748
2018-12-05 12:06:43,324 - INFO - epoch 2, step 32300, training loss = 2.575093, validation loss = 2.417301
2018-12-05 12:06:48,596 - INFO - epoch 2, step 32310, training loss = 2.155022, validation loss = 2.437866
2018-12-05 12:06:53,767 - INFO - epoch 2, step 32320, training loss = 2.199770, validation loss = 2.461853
2018-12-05 12:06:58,897 - INFO - epoch 2, step 32330, training loss = 2.211175, validation loss = 1.973724
2018-12-05 12:07:04,052 - INFO - epoch 2, step 32340, training loss = 2.104571, validation loss = 2.255528
2018-12-05 12:07:09,281 - INFO - epoch 2, step 32350, training loss = 2.303835, validation loss = 2.358675
2018-12-05 12:07:14,493 - INFO - epoch 2, step 32360, training loss = 2.319685, validation loss = 2.259335
2018-12-05 12:07:20,137 - INFO - epoch 2, step 32370, training loss = 2.471205, validation loss = 1.939290
2018-12-05 12:07:25,232 - INFO - epoch 2, step 32380, training loss = 2.444733, validation loss = 1.931715
2018-12-05 12:07:30,180 - INFO - epoch 2, step 32390, training loss = 2.273295, validation loss = 2.495312
2018-12-05 12:07:35,355 - INFO - epoch 2, step 32400, training loss = 2.421103, validation loss = 2.763299
2018-12-05 12:07:40,358 - INFO - epoch 2, step 32410, training loss = 2.030785, validation loss = 2.467661
2018-12-05 12:07:45,301 - INFO - epoch 2, step 32420, training loss = 2.378412, validation loss = 2.159936
2018-12-05 12:07:50,600 - INFO - epoch 2, step 32430, training loss = 2.289700, validation loss = 2.579433
2018-12-05 12:07:55,972 - INFO - epoch 2, step 32440, training loss = 2.000538, validation loss = 2.394894
2018-12-05 12:08:01,060 - INFO - epoch 2, step 32450, training loss = 1.956849, validation loss = 2.189116
2018-12-05 12:08:06,452 - INFO - epoch 2, step 32460, training loss = 2.415566, validation loss = 2.063719
2018-12-05 12:08:11,583 - INFO - epoch 2, step 32470, training loss = 2.266132, validation loss = 2.272273
2018-12-05 12:08:16,994 - INFO - epoch 2, step 32480, training loss = 1.608888, validation loss = 2.378114
2018-12-05 12:08:22,130 - INFO - epoch 2, step 32490, training loss = 2.148515, validation loss = 1.992075
2018-12-05 12:08:27,359 - INFO - epoch 2, step 32500, training loss = 2.503659, validation loss = 1.737605
2018-12-05 12:08:32,332 - INFO - epoch 2, step 32510, training loss = 2.156383, validation loss = 2.059366
2018-12-05 12:08:37,170 - INFO - epoch 2, step 32520, training loss = 2.323487, validation loss = 2.284678
2018-12-05 12:08:41,344 - INFO - epoch 2, step 32530, training loss = 2.138794, validation loss = 2.701124
2018-12-05 12:08:45,681 - INFO - epoch 2, step 32540, training loss = 2.521317, validation loss = 2.060446
2018-12-05 12:08:49,977 - INFO - epoch 2, step 32550, training loss = 2.117353, validation loss = 2.018355
2018-12-05 12:08:54,208 - INFO - epoch 2, step 32560, training loss = 2.074197, validation loss = 2.419089
2018-12-05 12:08:58,351 - INFO - epoch 2, step 32570, training loss = 1.962368, validation loss = 2.538292
2018-12-05 12:09:02,810 - INFO - epoch 2, step 32580, training loss = 2.009054, validation loss = 2.497416
2018-12-05 12:09:07,260 - INFO - epoch 2, step 32590, training loss = 1.825386, validation loss = 2.282189
2018-12-05 12:09:10,567 - INFO - epoch 2, step 32600, training loss = 1.915542, validation loss = 1.849540
2018-12-05 12:09:14,001 - INFO - epoch 2, step 32610, training loss = 2.439050, validation loss = 2.321371
2018-12-05 12:09:17,543 - INFO - epoch 2, step 32620, training loss = 1.815280, validation loss = 2.739243
2018-12-05 12:09:20,827 - INFO - epoch 2, step 32630, training loss = 2.012912, validation loss = 2.444858
2018-12-05 12:09:24,080 - INFO - epoch 2, step 32640, training loss = 2.218639, validation loss = 2.067056
2018-12-05 12:09:27,418 - INFO - epoch 2, step 32650, training loss = 1.848222, validation loss = 1.967491
2018-12-05 12:09:30,764 - INFO - epoch 2, step 32660, training loss = 1.988638, validation loss = 2.750483
2018-12-05 12:09:35,752 - INFO - epoch 2, step 32670, training loss = 2.242997, validation loss = 2.464540
2018-12-05 12:09:41,426 - INFO - epoch 2, step 32680, training loss = 1.890863, validation loss = 2.541083
2018-12-05 12:09:46,896 - INFO - epoch 2, step 32690, training loss = 1.948156, validation loss = 2.435978
2018-12-05 12:09:53,104 - INFO - epoch 2, step 32700, training loss = 2.065841, validation loss = 2.466772
2018-12-05 12:09:58,558 - INFO - epoch 2, step 32710, training loss = 1.943916, validation loss = 2.093254
2018-12-05 12:10:03,846 - INFO - epoch 2, step 32720, training loss = 2.008290, validation loss = 2.335856
2018-12-05 12:10:09,124 - INFO - epoch 2, step 32730, training loss = 2.124686, validation loss = 2.427889
2018-12-05 12:10:14,107 - INFO - epoch 2, step 32740, training loss = 2.219142, validation loss = 2.333625
2018-12-05 12:10:19,349 - INFO - epoch 2, step 32750, training loss = 1.940389, validation loss = 2.084926
2018-12-05 12:10:24,284 - INFO - epoch 2, step 32760, training loss = 1.983193, validation loss = 2.157712
2018-12-05 12:10:29,386 - INFO - epoch 2, step 32770, training loss = 2.013397, validation loss = 2.308879
2018-12-05 12:10:34,414 - INFO - epoch 2, step 32780, training loss = 2.474708, validation loss = 2.432706
2018-12-05 12:10:39,574 - INFO - epoch 2, step 32790, training loss = 1.980852, validation loss = 2.399684
2018-12-05 12:10:44,683 - INFO - epoch 2, step 32800, training loss = 2.162274, validation loss = 2.044200
2018-12-05 12:10:49,967 - INFO - epoch 2, step 32810, training loss = 2.071721, validation loss = 2.083977
2018-12-05 12:10:55,150 - INFO - epoch 2, step 32820, training loss = 2.642856, validation loss = 2.232451
2018-12-05 12:11:00,346 - INFO - epoch 2, step 32830, training loss = 2.115995, validation loss = 1.854505
2018-12-05 12:11:05,798 - INFO - epoch 2, step 32840, training loss = 2.519884, validation loss = 2.367870
2018-12-05 12:11:11,233 - INFO - epoch 2, step 32850, training loss = 1.887636, validation loss = 2.112744
2018-12-05 12:11:16,137 - INFO - epoch 2, step 32860, training loss = 2.387159, validation loss = 2.097280
2018-12-05 12:11:21,412 - INFO - epoch 2, step 32870, training loss = 2.311835, validation loss = 2.511917
2018-12-05 12:11:26,718 - INFO - epoch 2, step 32880, training loss = 2.044854, validation loss = 2.207948
2018-12-05 12:11:32,435 - INFO - epoch 2, step 32890, training loss = 1.926627, validation loss = 2.148090
2018-12-05 12:11:37,886 - INFO - epoch 2, step 32900, training loss = 2.058566, validation loss = 2.196760
2018-12-05 12:11:43,506 - INFO - epoch 2, step 32910, training loss = 1.697825, validation loss = 1.660092
2018-12-05 12:11:49,188 - INFO - epoch 2, step 32920, training loss = 2.055962, validation loss = 1.988970
2018-12-05 12:11:54,846 - INFO - epoch 2, step 32930, training loss = 1.885454, validation loss = 2.721823
2018-12-05 12:12:00,225 - INFO - epoch 2, step 32940, training loss = 2.112966, validation loss = 1.960236
2018-12-05 12:12:06,378 - INFO - epoch 2, step 32950, training loss = 1.557333, validation loss = 1.810163
2018-12-05 12:12:12,175 - INFO - epoch 2, step 32960, training loss = 1.582760, validation loss = 1.983292
2018-12-05 12:12:17,975 - INFO - epoch 2, step 32970, training loss = 1.616808, validation loss = 2.222857
2018-12-05 12:12:24,203 - INFO - epoch 2, step 32980, training loss = 2.330114, validation loss = 2.182533
2018-12-05 12:12:29,673 - INFO - epoch 2, step 32990, training loss = 2.089130, validation loss = 2.120309
2018-12-05 12:12:34,551 - INFO - epoch 2, step 33000, training loss = 1.939040, validation loss = 1.862427
2018-12-05 12:12:38,728 - INFO - epoch 2, step 33010, training loss = 2.246864, validation loss = 2.556664
2018-12-05 12:12:43,482 - INFO - epoch 2, step 33020, training loss = 1.959170, validation loss = 2.225374
2018-12-05 12:12:47,696 - INFO - epoch 2, step 33030, training loss = 2.145506, validation loss = 2.434721
2018-12-05 12:12:51,958 - INFO - epoch 2, step 33040, training loss = 1.694617, validation loss = 1.983885
2018-12-05 12:12:56,377 - INFO - epoch 2, step 33050, training loss = 1.817371, validation loss = 2.009415
2018-12-05 12:13:01,170 - INFO - epoch 2, step 33060, training loss = 1.958200, validation loss = 1.777935
2018-12-05 12:13:04,908 - INFO - epoch 2, step 33070, training loss = 2.072479, validation loss = 1.879915
2018-12-05 12:13:08,541 - INFO - epoch 2, step 33080, training loss = 2.971878, validation loss = 2.160396
2018-12-05 12:13:12,094 - INFO - epoch 2, step 33090, training loss = 1.981530, validation loss = 1.901200
2018-12-05 12:13:15,938 - INFO - epoch 2, step 33100, training loss = 2.299489, validation loss = 1.972843
2018-12-05 12:13:19,637 - INFO - epoch 2, step 33110, training loss = 2.380258, validation loss = 1.883106
2018-12-05 12:13:23,503 - INFO - epoch 2, step 33120, training loss = 2.277594, validation loss = 1.847082
2018-12-05 12:13:27,073 - INFO - epoch 2, step 33130, training loss = 2.439868, validation loss = 2.203471
2018-12-05 12:13:30,990 - INFO - epoch 2, step 33140, training loss = 2.117548, validation loss = 2.168521
2018-12-05 12:13:34,790 - INFO - epoch 2, step 33150, training loss = 2.709856, validation loss = 1.972410
2018-12-05 12:13:38,248 - INFO - epoch 2, step 33160, training loss = 2.254102, validation loss = 2.145742
2018-12-05 12:13:41,956 - INFO - epoch 2, step 33170, training loss = 2.592511, validation loss = 2.207930
2018-12-05 12:13:47,672 - INFO - epoch 2, step 33180, training loss = 1.733406, validation loss = 2.050202
2018-12-05 12:13:53,351 - INFO - epoch 2, step 33190, training loss = 1.992708, validation loss = 1.760892
2018-12-05 12:13:59,216 - INFO - epoch 2, step 33200, training loss = 1.752517, validation loss = 1.975511
2018-12-05 12:14:05,521 - INFO - epoch 2, step 33210, training loss = 2.019973, validation loss = 2.267784
2018-12-05 12:14:10,904 - INFO - epoch 2, step 33220, training loss = 2.196251, validation loss = 2.087126
2018-12-05 12:14:16,103 - INFO - epoch 2, step 33230, training loss = 2.276024, validation loss = 1.765240
2018-12-05 12:14:21,695 - INFO - epoch 2, step 33240, training loss = 1.592673, validation loss = 2.320266
2018-12-05 12:14:27,215 - INFO - epoch 2, step 33250, training loss = 1.709401, validation loss = 2.494970
2018-12-05 12:14:32,818 - INFO - epoch 2, step 33260, training loss = 2.066166, validation loss = 2.214863
2018-12-05 12:14:37,962 - INFO - epoch 2, step 33270, training loss = 1.892657, validation loss = 1.789865
2018-12-05 12:14:43,961 - INFO - epoch 2, step 33280, training loss = 1.923602, validation loss = 2.163193
2018-12-05 12:14:49,510 - INFO - epoch 2, step 33290, training loss = 1.971190, validation loss = 2.262677
2018-12-05 12:14:54,708 - INFO - epoch 2, step 33300, training loss = 2.059953, validation loss = 2.254444
2018-12-05 12:15:01,067 - INFO - epoch 2, step 33310, training loss = 2.287524, validation loss = 2.116730
2018-12-05 12:15:06,482 - INFO - epoch 2, step 33320, training loss = 1.970286, validation loss = 2.160642
2018-12-05 12:15:12,204 - INFO - epoch 2, step 33330, training loss = 1.796167, validation loss = 2.021726
2018-12-05 12:15:17,933 - INFO - epoch 2, step 33340, training loss = 1.886514, validation loss = 2.577310
2018-12-05 12:15:23,608 - INFO - epoch 2, step 33350, training loss = 1.576233, validation loss = 2.310679
2018-12-05 12:15:29,034 - INFO - epoch 2, step 33360, training loss = 2.663135, validation loss = 1.955002
2018-12-05 12:15:33,976 - INFO - epoch 2, step 33370, training loss = 2.653866, validation loss = 2.366089
2018-12-05 12:15:38,876 - INFO - epoch 2, step 33380, training loss = 2.620766, validation loss = 2.563438
2018-12-05 12:15:43,757 - INFO - epoch 2, step 33390, training loss = 2.167112, validation loss = 2.572137
2018-12-05 12:15:48,781 - INFO - epoch 2, step 33400, training loss = 1.706037, validation loss = 2.042781
2018-12-05 12:15:53,788 - INFO - epoch 2, step 33410, training loss = 2.017164, validation loss = 2.407940
2018-12-05 12:15:58,631 - INFO - epoch 2, step 33420, training loss = 2.326632, validation loss = 2.150000
2018-12-05 12:16:03,340 - INFO - epoch 2, step 33430, training loss = 2.299917, validation loss = 2.092837
2018-12-05 12:16:07,961 - INFO - epoch 2, step 33440, training loss = 2.074332, validation loss = 2.158742
2018-12-05 12:16:12,784 - INFO - epoch 2, step 33450, training loss = 2.394787, validation loss = 2.511577
2018-12-05 12:16:17,487 - INFO - epoch 2, step 33460, training loss = 1.990792, validation loss = 2.119199
2018-12-05 12:16:22,376 - INFO - epoch 2, step 33470, training loss = 2.260865, validation loss = 2.103807
2018-12-05 12:16:27,257 - INFO - epoch 2, step 33480, training loss = 1.955583, validation loss = 2.178885
2018-12-05 12:16:32,741 - INFO - epoch 2, step 33490, training loss = 2.133206, validation loss = 2.336875
2018-12-05 12:16:37,950 - INFO - epoch 2, step 33500, training loss = 2.201014, validation loss = 2.070038
2018-12-05 12:16:43,025 - INFO - epoch 2, step 33510, training loss = 1.812765, validation loss = 2.108947
2018-12-05 12:16:48,039 - INFO - epoch 2, step 33520, training loss = 2.121130, validation loss = 2.145178
2018-12-05 12:16:53,437 - INFO - epoch 2, step 33530, training loss = 1.856011, validation loss = 2.544089
2018-12-05 12:16:58,827 - INFO - epoch 2, step 33540, training loss = 2.007343, validation loss = 2.456549
2018-12-05 12:17:03,896 - INFO - epoch 2, step 33550, training loss = 2.371541, validation loss = 2.151324
2018-12-05 12:17:09,139 - INFO - epoch 2, step 33560, training loss = 2.112945, validation loss = 1.902537
2018-12-05 12:17:14,276 - INFO - epoch 2, step 33570, training loss = 2.009778, validation loss = 2.355052
2018-12-05 12:17:19,275 - INFO - epoch 2, step 33580, training loss = 2.192075, validation loss = 2.440491
2018-12-05 12:17:25,073 - INFO - epoch 2, step 33590, training loss = 1.497934, validation loss = 2.206515
2018-12-05 12:17:30,335 - INFO - epoch 2, step 33600, training loss = 1.763585, validation loss = 2.074189
2018-12-05 12:17:36,657 - INFO - epoch 2, step 33610, training loss = 2.199787, validation loss = 2.137114
2018-12-05 12:17:42,053 - INFO - epoch 2, step 33620, training loss = 1.551654, validation loss = 2.722195
2018-12-05 12:17:47,020 - INFO - epoch 2, step 33630, training loss = 2.314706, validation loss = 2.024425
2018-12-05 12:17:52,416 - INFO - epoch 2, step 33640, training loss = 2.074927, validation loss = 2.141779
2018-12-05 12:17:57,518 - INFO - epoch 2, step 33650, training loss = 2.288018, validation loss = 2.487327
2018-12-05 12:18:02,805 - INFO - epoch 2, step 33660, training loss = 1.990467, validation loss = 2.296254
2018-12-05 12:18:08,415 - INFO - epoch 2, step 33670, training loss = 2.112622, validation loss = 1.876714
2018-12-05 12:18:13,695 - INFO - epoch 2, step 33680, training loss = 2.143168, validation loss = 2.512243
2018-12-05 12:18:18,742 - INFO - epoch 2, step 33690, training loss = 1.863349, validation loss = 2.474865
2018-12-05 12:18:23,927 - INFO - epoch 2, step 33700, training loss = 1.940381, validation loss = 2.316784
2018-12-05 12:18:28,934 - INFO - epoch 2, step 33710, training loss = 1.869370, validation loss = 2.552898
2018-12-05 12:18:34,213 - INFO - epoch 2, step 33720, training loss = 1.816989, validation loss = 2.331755
2018-12-05 12:18:39,297 - INFO - epoch 2, step 33730, training loss = 2.053195, validation loss = 2.289752
2018-12-05 12:18:44,349 - INFO - epoch 2, step 33740, training loss = 2.245173, validation loss = 2.661126
2018-12-05 12:18:49,603 - INFO - epoch 2, step 33750, training loss = 2.500116, validation loss = 1.981942
2018-12-05 12:18:54,677 - INFO - epoch 2, step 33760, training loss = 1.701377, validation loss = 2.790356
2018-12-05 12:19:00,007 - INFO - epoch 2, step 33770, training loss = 2.229190, validation loss = 2.574022
2018-12-05 12:19:05,516 - INFO - epoch 2, step 33780, training loss = 2.603410, validation loss = 2.565858
2018-12-05 12:19:10,720 - INFO - epoch 2, step 33790, training loss = 1.986354, validation loss = 2.396832
2018-12-05 12:19:15,886 - INFO - epoch 2, step 33800, training loss = 2.020862, validation loss = 2.162092
2018-12-05 12:19:21,085 - INFO - epoch 2, step 33810, training loss = 1.895756, validation loss = 2.257247
2018-12-05 12:19:26,360 - INFO - epoch 2, step 33820, training loss = 2.189599, validation loss = 2.568181
2018-12-05 12:19:31,740 - INFO - epoch 2, step 33830, training loss = 2.202964, validation loss = 2.389054
2018-12-05 12:19:36,701 - INFO - epoch 2, step 33840, training loss = 2.008340, validation loss = 2.392956
2018-12-05 12:19:41,976 - INFO - epoch 2, step 33850, training loss = 2.248277, validation loss = 2.784415
2018-12-05 12:19:47,291 - INFO - epoch 2, step 33860, training loss = 2.240018, validation loss = 1.971065
2018-12-05 12:19:52,564 - INFO - epoch 2, step 33870, training loss = 1.925720, validation loss = 2.293775
2018-12-05 12:19:57,836 - INFO - epoch 2, step 33880, training loss = 2.197228, validation loss = 2.783361
2018-12-05 12:20:02,878 - INFO - epoch 2, step 33890, training loss = 2.449972, validation loss = 2.483456
2018-12-05 12:20:08,068 - INFO - epoch 2, step 33900, training loss = 2.404752, validation loss = 2.597020
2018-12-05 12:20:13,365 - INFO - epoch 2, step 33910, training loss = 2.354037, validation loss = 2.341079
2018-12-05 12:20:18,479 - INFO - epoch 2, step 33920, training loss = 2.028823, validation loss = 2.112696
2018-12-05 12:20:24,149 - INFO - epoch 2, step 33930, training loss = 2.270100, validation loss = 2.388874
2018-12-05 12:20:29,588 - INFO - epoch 2, step 33940, training loss = 1.940454, validation loss = 2.290574
2018-12-05 12:20:34,932 - INFO - epoch 2, step 33950, training loss = 2.218191, validation loss = 2.445205
2018-12-05 12:20:39,916 - INFO - epoch 2, step 33960, training loss = 2.294526, validation loss = 2.527645
2018-12-05 12:20:45,064 - INFO - epoch 2, step 33970, training loss = 2.158051, validation loss = 2.248245
2018-12-05 12:20:51,063 - INFO - epoch 2, step 33980, training loss = 2.161161, validation loss = 2.465599
2018-12-05 12:20:56,014 - INFO - epoch 2, step 33990, training loss = 2.370569, validation loss = 2.535544
2018-12-05 12:21:01,227 - INFO - epoch 2, step 34000, training loss = 2.298252, validation loss = 2.252671
2018-12-05 12:21:06,433 - INFO - epoch 2, step 34010, training loss = 2.121745, validation loss = 2.494729
2018-12-05 12:21:11,445 - INFO - epoch 2, step 34020, training loss = 2.177765, validation loss = 2.828429
2018-12-05 12:21:16,453 - INFO - epoch 2, step 34030, training loss = 2.309173, validation loss = 2.545889
2018-12-05 12:21:21,621 - INFO - epoch 2, step 34040, training loss = 2.277122, validation loss = 2.135640
2018-12-05 12:21:26,904 - INFO - epoch 2, step 34050, training loss = 1.724240, validation loss = 2.684549
2018-12-05 12:21:32,197 - INFO - epoch 2, step 34060, training loss = 2.149923, validation loss = 2.334842
2018-12-05 12:21:37,235 - INFO - epoch 2, step 34070, training loss = 2.138419, validation loss = 2.337028
2018-12-05 12:21:42,256 - INFO - epoch 2, step 34080, training loss = 2.349848, validation loss = 2.454320
2018-12-05 12:21:46,306 - INFO - epoch 2, step 34090, training loss = 2.337213, validation loss = 2.674046
2018-12-05 12:21:49,054 - INFO - epoch 2, step 34100, training loss = 1.729184, validation loss = 1.695025
2018-12-05 12:21:51,561 - INFO - epoch 2, step 34110, training loss = 2.659668, validation loss = 2.693094
2018-12-05 12:21:54,180 - INFO - epoch 2, step 34120, training loss = 1.877458, validation loss = 2.251861
2018-12-05 12:21:56,750 - INFO - epoch 2, step 34130, training loss = 1.952781, validation loss = 2.496773
2018-12-05 12:21:59,355 - INFO - epoch 2, step 34140, training loss = 1.927310, validation loss = 2.306327
2018-12-05 12:22:01,767 - INFO - epoch 2, step 34150, training loss = 2.419996, validation loss = 2.381624
2018-12-05 12:22:04,331 - INFO - epoch 2, step 34160, training loss = 1.577737, validation loss = 2.761307
2018-12-05 12:22:07,036 - INFO - epoch 2, step 34170, training loss = 1.781851, validation loss = 2.219558
2018-12-05 12:22:09,686 - INFO - epoch 2, step 34180, training loss = 2.197654, validation loss = 2.250063
2018-12-05 12:22:12,222 - INFO - epoch 2, step 34190, training loss = 2.230709, validation loss = 2.473575
2018-12-05 12:22:14,814 - INFO - epoch 2, step 34200, training loss = 1.503955, validation loss = 2.530342
2018-12-05 12:22:17,475 - INFO - epoch 2, step 34210, training loss = 1.641138, validation loss = 2.912576
2018-12-05 12:22:20,055 - INFO - epoch 2, step 34220, training loss = 2.251255, validation loss = 2.557946
2018-12-05 12:22:24,952 - INFO - epoch 2, step 34230, training loss = 2.310867, validation loss = 2.206204
2018-12-05 12:22:30,105 - INFO - epoch 2, step 34240, training loss = 1.874830, validation loss = 2.562422
2018-12-05 12:22:35,506 - INFO - epoch 2, step 34250, training loss = 2.109412, validation loss = 2.122344
2018-12-05 12:22:40,534 - INFO - epoch 2, step 34260, training loss = 2.048136, validation loss = 2.679127
2018-12-05 12:22:45,648 - INFO - epoch 2, step 34270, training loss = 2.088779, validation loss = 2.122553
2018-12-05 12:22:51,188 - INFO - epoch 2, step 34280, training loss = 2.453977, validation loss = 2.017660
2018-12-05 12:22:56,305 - INFO - epoch 2, step 34290, training loss = 2.177085, validation loss = 2.518582
2018-12-05 12:23:01,458 - INFO - epoch 2, step 34300, training loss = 2.640201, validation loss = 2.545611
2018-12-05 12:23:06,584 - INFO - epoch 2, step 34310, training loss = 2.200745, validation loss = 2.365523
2018-12-05 12:23:11,744 - INFO - epoch 2, step 34320, training loss = 1.911570, validation loss = 2.618252
2018-12-05 12:23:17,126 - INFO - epoch 2, step 34330, training loss = 1.920465, validation loss = 2.531564
2018-12-05 12:23:22,313 - INFO - epoch 2, step 34340, training loss = 2.083682, validation loss = 2.387041
2018-12-05 12:23:27,889 - INFO - epoch 2, step 34350, training loss = 2.074221, validation loss = 2.647084
2018-12-05 12:23:33,218 - INFO - epoch 2, step 34360, training loss = 1.873635, validation loss = 2.414170
2018-12-05 12:23:38,375 - INFO - epoch 2, step 34370, training loss = 2.012102, validation loss = 2.608853
2018-12-05 12:23:43,612 - INFO - epoch 2, step 34380, training loss = 2.156301, validation loss = 2.579099
2018-12-05 12:23:48,998 - INFO - epoch 2, step 34390, training loss = 2.389132, validation loss = 2.154505
2018-12-05 12:23:54,189 - INFO - epoch 2, step 34400, training loss = 2.111078, validation loss = 2.760535
2018-12-05 12:23:59,247 - INFO - epoch 2, step 34410, training loss = 2.250549, validation loss = 2.626671
2018-12-05 12:24:04,440 - INFO - epoch 2, step 34420, training loss = 2.346655, validation loss = 2.609304
2018-12-05 12:24:09,761 - INFO - epoch 2, step 34430, training loss = 2.130562, validation loss = 2.570184
2018-12-05 12:24:14,840 - INFO - epoch 2, step 34440, training loss = 2.036759, validation loss = 2.518414
2018-12-05 12:24:19,971 - INFO - epoch 2, step 34450, training loss = 2.227479, validation loss = 2.299910
2018-12-05 12:24:25,243 - INFO - epoch 2, step 34460, training loss = 2.077538, validation loss = 2.443918
2018-12-05 12:24:29,349 - INFO - epoch 2, step 34470, training loss = 1.909649, validation loss = 2.733575
2018-12-05 12:24:32,581 - INFO - epoch 2, step 34480, training loss = 2.823279, validation loss = 2.529736
2018-12-05 12:24:36,065 - INFO - epoch 2, step 34490, training loss = 1.705877, validation loss = 2.317586
2018-12-05 12:24:39,525 - INFO - epoch 2, step 34500, training loss = 2.317947, validation loss = 2.351506
2018-12-05 12:24:42,614 - INFO - epoch 2, step 34510, training loss = 2.224612, validation loss = 2.268950
2018-12-05 12:24:45,877 - INFO - epoch 2, step 34520, training loss = 2.179215, validation loss = 2.415024
2018-12-05 12:24:49,222 - INFO - epoch 2, step 34530, training loss = 2.119087, validation loss = 2.224311
2018-12-05 12:24:52,579 - INFO - epoch 2, step 34540, training loss = 2.266740, validation loss = 2.343246
2018-12-05 12:24:55,994 - INFO - epoch 2, step 34550, training loss = 2.199659, validation loss = 2.578819
2018-12-05 12:24:59,589 - INFO - epoch 2, step 34560, training loss = 2.252562, validation loss = 2.548443
2018-12-05 12:25:02,927 - INFO - epoch 2, step 34570, training loss = 2.140573, validation loss = 2.554935
2018-12-05 12:25:06,092 - INFO - epoch 2, step 34580, training loss = 2.323774, validation loss = 2.275445
2018-12-05 12:25:09,368 - INFO - epoch 2, step 34590, training loss = 2.079476, validation loss = 2.452375
2018-12-05 12:25:12,818 - INFO - epoch 2, step 34600, training loss = 1.783099, validation loss = 2.407032
2018-12-05 12:25:16,168 - INFO - epoch 2, step 34610, training loss = 2.347571, validation loss = 2.308753
2018-12-05 12:25:19,481 - INFO - epoch 2, step 34620, training loss = 2.239617, validation loss = 2.148567
2018-12-05 12:25:22,750 - INFO - epoch 2, step 34630, training loss = 1.936356, validation loss = 2.617789
2018-12-05 12:25:26,119 - INFO - epoch 2, step 34640, training loss = 2.154681, validation loss = 2.304125
2018-12-05 12:25:31,658 - INFO - epoch 2, step 34650, training loss = 2.491476, validation loss = 2.342412
2018-12-05 12:25:36,955 - INFO - epoch 2, step 34660, training loss = 2.036069, validation loss = 2.432646
2018-12-05 12:25:42,305 - INFO - epoch 2, step 34670, training loss = 2.566679, validation loss = 2.405135
2018-12-05 12:25:47,555 - INFO - epoch 2, step 34680, training loss = 2.433726, validation loss = 2.576401
2018-12-05 12:25:53,184 - INFO - epoch 2, step 34690, training loss = 2.498318, validation loss = 2.525350
2018-12-05 12:25:58,610 - INFO - epoch 2, step 34700, training loss = 1.850545, validation loss = 2.511213
2018-12-05 12:26:04,184 - INFO - epoch 2, step 34710, training loss = 2.143766, validation loss = 2.287735
2018-12-05 12:26:09,587 - INFO - epoch 2, step 34720, training loss = 2.158093, validation loss = 2.685626
2018-12-05 12:26:15,158 - INFO - epoch 2, step 34730, training loss = 2.199675, validation loss = 2.591305
2018-12-05 12:26:20,462 - INFO - epoch 2, step 34740, training loss = 2.562934, validation loss = 2.551931
2018-12-05 12:26:26,015 - INFO - epoch 2, step 34750, training loss = 2.040051, validation loss = 2.721797
2018-12-05 12:26:31,931 - INFO - epoch 2, step 34760, training loss = 2.303088, validation loss = 2.396976
2018-12-05 12:26:37,522 - INFO - epoch 2, step 34770, training loss = 2.609532, validation loss = 2.601209
2018-12-05 12:26:43,244 - INFO - epoch 2, step 34780, training loss = 2.302765, validation loss = 2.666921
2018-12-05 12:26:48,856 - INFO - epoch 2, step 34790, training loss = 2.185305, validation loss = 2.526850
2018-12-05 12:26:54,331 - INFO - epoch 2, step 34800, training loss = 2.551363, validation loss = 2.375515
2018-12-05 12:26:59,529 - INFO - epoch 2, step 34810, training loss = 2.265554, validation loss = 2.636775
2018-12-05 12:27:04,579 - INFO - epoch 2, step 34820, training loss = 2.037113, validation loss = 2.432529
2018-12-05 12:27:08,260 - INFO - epoch 2, step 34830, training loss = 2.401778, validation loss = 2.486557
2018-12-05 12:27:12,371 - INFO - epoch 2, step 34840, training loss = 2.037437, validation loss = 2.087924
2018-12-05 12:27:18,504 - INFO - epoch 2, step 34850, training loss = 2.011018, validation loss = 2.495405
2018-12-05 12:27:23,907 - INFO - epoch 2, step 34860, training loss = 2.030281, validation loss = 2.314843
2018-12-05 12:27:30,230 - INFO - epoch 2, step 34870, training loss = 2.034104, validation loss = 2.583163
2018-12-05 12:27:36,652 - INFO - epoch 2, step 34880, training loss = 2.192225, validation loss = 2.468921
2018-12-05 12:27:43,055 - INFO - epoch 2, step 34890, training loss = 2.230707, validation loss = 2.053800
2018-12-05 12:27:49,492 - INFO - epoch 2, step 34900, training loss = 1.687461, validation loss = 2.416530
2018-12-05 12:27:54,689 - INFO - epoch 2, step 34910, training loss = 2.212868, validation loss = 2.479050
2018-12-05 12:28:00,297 - INFO - epoch 2, step 34920, training loss = 1.629420, validation loss = 2.285913
2018-12-05 12:28:05,992 - INFO - epoch 2, step 34930, training loss = 2.003389, validation loss = 2.254405
2018-12-05 12:28:10,879 - INFO - epoch 2, step 34940, training loss = 2.423483, validation loss = 2.371120
2018-12-05 12:28:15,793 - INFO - epoch 2, step 34950, training loss = 2.319994, validation loss = 2.607214
2018-12-05 12:28:20,558 - INFO - epoch 2, step 34960, training loss = 2.112677, validation loss = 2.504359
2018-12-05 12:28:25,657 - INFO - epoch 2, step 34970, training loss = 2.086159, validation loss = 2.338929
2018-12-05 12:28:31,087 - INFO - epoch 2, step 34980, training loss = 2.425806, validation loss = 2.725776
2018-12-05 12:28:35,886 - INFO - epoch 2, step 34990, training loss = 1.936061, validation loss = 2.819473
2018-12-05 12:28:40,619 - INFO - epoch 2, step 35000, training loss = 1.998094, validation loss = 2.478163
2018-12-05 12:28:45,809 - INFO - epoch 2, step 35010, training loss = 2.123924, validation loss = 2.656361
2018-12-05 12:28:50,520 - INFO - epoch 2, step 35020, training loss = 2.257835, validation loss = 2.623857
2018-12-05 12:28:55,502 - INFO - epoch 2, step 35030, training loss = 2.339196, validation loss = 2.190847
2018-12-05 12:29:00,424 - INFO - epoch 2, step 35040, training loss = 1.838901, validation loss = 2.160490
2018-12-05 12:29:05,181 - INFO - epoch 2, step 35050, training loss = 2.266095, validation loss = 2.208395
2018-12-05 12:29:10,114 - INFO - epoch 2, step 35060, training loss = 1.637647, validation loss = 2.217288
2018-12-05 12:29:12,637 - INFO - epoch 2, step 35070, training loss = 2.481903, validation loss = 2.172984
2018-12-05 12:29:15,159 - INFO - epoch 2, step 35080, training loss = 2.392779, validation loss = 2.585784
2018-12-05 12:29:17,513 - INFO - epoch 2, step 35090, training loss = 2.417234, validation loss = 2.020901
2018-12-05 12:29:20,109 - INFO - epoch 2, step 35100, training loss = 2.150838, validation loss = 2.636329
2018-12-05 12:29:22,799 - INFO - epoch 2, step 35110, training loss = 2.564941, validation loss = 2.386220
2018-12-05 12:29:25,423 - INFO - epoch 2, step 35120, training loss = 2.324424, validation loss = 2.779425
2018-12-05 12:29:27,856 - INFO - epoch 2, step 35130, training loss = 1.930845, validation loss = 2.570447
2018-12-05 12:29:30,329 - INFO - epoch 2, step 35140, training loss = 2.203519, validation loss = 2.406666
2018-12-05 12:29:32,890 - INFO - epoch 2, step 35150, training loss = 1.716484, validation loss = 2.060164
2018-12-05 12:29:35,394 - INFO - epoch 2, step 35160, training loss = 2.459429, validation loss = 1.950063
2018-12-05 12:29:37,821 - INFO - epoch 2, step 35170, training loss = 2.029563, validation loss = 3.091968
2018-12-05 12:29:40,270 - INFO - epoch 2, step 35180, training loss = 2.154200, validation loss = 2.656600
2018-12-05 12:29:42,725 - INFO - epoch 2, step 35190, training loss = 2.181963, validation loss = 1.961304
2018-12-05 12:29:45,231 - INFO - epoch 2, step 35200, training loss = 2.149915, validation loss = 2.516225
2018-12-05 12:29:47,687 - INFO - epoch 2, step 35210, training loss = 1.450734, validation loss = 2.076052
2018-12-05 12:29:50,168 - INFO - epoch 2, step 35220, training loss = 2.075302, validation loss = 2.719193
2018-12-05 12:29:53,962 - INFO - epoch 2, step 35230, training loss = 2.040830, validation loss = 2.797887
2018-12-05 12:29:58,435 - INFO - epoch 2, step 35240, training loss = 2.000818, validation loss = 1.925838
2018-12-05 12:30:02,862 - INFO - epoch 2, step 35250, training loss = 1.605361, validation loss = 2.407836
2018-12-05 12:30:07,348 - INFO - epoch 2, step 35260, training loss = 2.543310, validation loss = 2.464267
2018-12-05 12:30:11,810 - INFO - epoch 2, step 35270, training loss = 2.349757, validation loss = 2.500908
2018-12-05 12:30:16,328 - INFO - epoch 2, step 35280, training loss = 1.756864, validation loss = 2.036072
2018-12-05 12:30:20,717 - INFO - epoch 2, step 35290, training loss = 1.986225, validation loss = 2.561574
2018-12-05 12:30:24,991 - INFO - epoch 2, step 35300, training loss = 1.924133, validation loss = 1.963890
2018-12-05 12:30:29,394 - INFO - epoch 2, step 35310, training loss = 2.209407, validation loss = 2.290436
2018-12-05 12:30:33,873 - INFO - epoch 2, step 35320, training loss = 2.217555, validation loss = 2.021816
2018-12-05 12:30:38,455 - INFO - epoch 2, step 35330, training loss = 2.445374, validation loss = 2.671995
2018-12-05 12:30:43,296 - INFO - epoch 2, step 35340, training loss = 2.397546, validation loss = 2.351283
2018-12-05 12:30:48,047 - INFO - epoch 2, step 35350, training loss = 2.027480, validation loss = 2.534317
2018-12-05 12:30:52,682 - INFO - epoch 2, step 35360, training loss = 2.260650, validation loss = 2.507395
2018-12-05 12:30:57,419 - INFO - epoch 2, step 35370, training loss = 2.553278, validation loss = 2.452425
2018-12-05 12:31:02,037 - INFO - epoch 2, step 35380, training loss = 2.359095, validation loss = 2.202757
2018-12-05 12:31:06,687 - INFO - epoch 2, step 35390, training loss = 2.673210, validation loss = 1.957307
2018-12-05 12:31:11,879 - INFO - epoch 2, step 35400, training loss = 2.428404, validation loss = 2.596574
2018-12-05 12:31:16,415 - INFO - epoch 2, step 35410, training loss = 2.355389, validation loss = 2.364019
2018-12-05 12:31:21,016 - INFO - epoch 2, step 35420, training loss = 2.274358, validation loss = 2.468171
2018-12-05 12:31:25,637 - INFO - epoch 2, step 35430, training loss = 2.223875, validation loss = 2.182555
2018-12-05 12:31:30,263 - INFO - epoch 2, step 35440, training loss = 2.491997, validation loss = 2.344984
2018-12-05 12:31:34,840 - INFO - epoch 2, step 35450, training loss = 2.090737, validation loss = 2.449774
2018-12-05 12:31:39,543 - INFO - epoch 2, step 35460, training loss = 2.083956, validation loss = 1.928643
2018-12-05 12:31:43,991 - INFO - epoch 2, step 35470, training loss = 2.326574, validation loss = 1.912245
2018-12-05 12:31:48,664 - INFO - epoch 2, step 35480, training loss = 1.422436, validation loss = 2.372463
2018-12-05 12:31:53,197 - INFO - epoch 2, step 35490, training loss = 1.822482, validation loss = 1.916219
2018-12-05 12:31:57,767 - INFO - epoch 2, step 35500, training loss = 2.095163, validation loss = 2.457364
2018-12-05 12:32:02,020 - INFO - epoch 2, step 35510, training loss = 2.173059, validation loss = 2.379768
2018-12-05 12:32:06,312 - INFO - epoch 2, step 35520, training loss = 2.381784, validation loss = 2.123863
2018-12-05 12:32:10,995 - INFO - epoch 2, step 35530, training loss = 2.062795, validation loss = 2.342681
2018-12-05 12:32:15,634 - INFO - epoch 2, step 35540, training loss = 2.572055, validation loss = 2.288143
2018-12-05 12:32:20,953 - INFO - epoch 2, step 35550, training loss = 2.026740, validation loss = 1.819326
2018-12-05 12:32:25,702 - INFO - epoch 2, step 35560, training loss = 2.294487, validation loss = 2.576852
2018-12-05 12:32:30,439 - INFO - epoch 2, step 35570, training loss = 1.769098, validation loss = 2.139229
2018-12-05 12:32:35,012 - INFO - epoch 2, step 35580, training loss = 2.476559, validation loss = 2.496025
2018-12-05 12:32:41,345 - INFO - epoch 2, step 35590, training loss = 2.243797, validation loss = 1.939619
2018-12-05 12:32:47,023 - INFO - epoch 2, step 35600, training loss = 1.960007, validation loss = 1.787148
2018-12-05 12:32:53,095 - INFO - epoch 2, step 35610, training loss = 2.024663, validation loss = 1.937649
2018-12-05 12:32:58,596 - INFO - epoch 2, step 35620, training loss = 2.005229, validation loss = 2.066242
2018-12-05 12:33:04,352 - INFO - epoch 2, step 35630, training loss = 2.279007, validation loss = 2.118357
2018-12-05 12:33:10,150 - INFO - epoch 2, step 35640, training loss = 1.694275, validation loss = 2.665408
2018-12-05 12:33:16,041 - INFO - epoch 2, step 35650, training loss = 1.970034, validation loss = 2.184669
2018-12-05 12:33:21,708 - INFO - epoch 2, step 35660, training loss = 1.902413, validation loss = 1.871296
2018-12-05 12:33:27,699 - INFO - epoch 2, step 35670, training loss = 1.805746, validation loss = 1.730491
2018-12-05 12:33:33,581 - INFO - epoch 2, step 35680, training loss = 2.289722, validation loss = 2.112807
2018-12-05 12:33:37,906 - INFO - epoch 2, step 35690, training loss = 1.678285, validation loss = 1.691790
2018-12-05 12:33:42,612 - INFO - epoch 2, step 35700, training loss = 2.185404, validation loss = 2.222356
2018-12-05 12:33:46,837 - INFO - epoch 2, step 35710, training loss = 2.095743, validation loss = 2.481829
2018-12-05 12:33:51,265 - INFO - epoch 2, step 35720, training loss = 2.121557, validation loss = 1.879363
2018-12-05 12:33:55,573 - INFO - epoch 2, step 35730, training loss = 2.384775, validation loss = 2.314460
2018-12-05 12:34:00,037 - INFO - epoch 2, step 35740, training loss = 2.186411, validation loss = 2.343598
2018-12-05 12:34:04,226 - INFO - epoch 2, step 35750, training loss = 2.664163, validation loss = 2.244084
2018-12-05 12:34:08,426 - INFO - epoch 2, step 35760, training loss = 2.554943, validation loss = 1.767497
2018-12-05 12:34:12,411 - INFO - epoch 2, step 35770, training loss = 2.415736, validation loss = 2.335556
2018-12-05 12:34:16,273 - INFO - epoch 2, step 35780, training loss = 2.237940, validation loss = 2.472273
2018-12-05 12:34:20,461 - INFO - epoch 2, step 35790, training loss = 2.144320, validation loss = 2.246935
2018-12-05 12:34:24,564 - INFO - epoch 2, step 35800, training loss = 2.182734, validation loss = 1.946289
2018-12-05 12:34:28,704 - INFO - epoch 2, step 35810, training loss = 2.527116, validation loss = 2.103790
2018-12-05 12:34:32,655 - INFO - epoch 2, step 35820, training loss = 2.193159, validation loss = 2.472946
2018-12-05 12:34:36,719 - INFO - epoch 2, step 35830, training loss = 2.378670, validation loss = 2.394091
2018-12-05 12:34:40,698 - INFO - epoch 2, step 35840, training loss = 2.425304, validation loss = 2.215327
2018-12-05 12:34:44,669 - INFO - epoch 2, step 35850, training loss = 2.344951, validation loss = 1.930143
2018-12-05 12:34:48,692 - INFO - epoch 2, step 35860, training loss = 2.440677, validation loss = 2.610519
2018-12-05 12:34:52,535 - INFO - epoch 2, step 35870, training loss = 2.092683, validation loss = 2.577510
2018-12-05 12:34:56,609 - INFO - epoch 2, step 35880, training loss = 2.354802, validation loss = 1.890425
2018-12-05 12:35:00,472 - INFO - epoch 2, step 35890, training loss = 2.133166, validation loss = 2.119492
2018-12-05 12:35:04,563 - INFO - epoch 2, step 35900, training loss = 2.170388, validation loss = 2.702520
2018-12-05 12:35:08,582 - INFO - epoch 2, step 35910, training loss = 1.964026, validation loss = 2.460358
2018-12-05 12:35:12,926 - INFO - epoch 2, step 35920, training loss = 2.034890, validation loss = 2.382911
2018-12-05 12:35:17,024 - INFO - epoch 2, step 35930, training loss = 2.018333, validation loss = 2.549660
2018-12-05 12:35:20,828 - INFO - epoch 2, step 35940, training loss = 2.079936, validation loss = 2.488793
2018-12-05 12:35:24,581 - INFO - epoch 2, step 35950, training loss = 2.058205, validation loss = 2.935289
2018-12-05 12:35:28,643 - INFO - epoch 2, step 35960, training loss = 2.313902, validation loss = 2.294992
2018-12-05 12:35:32,605 - INFO - epoch 2, step 35970, training loss = 2.442501, validation loss = 2.133109
2018-12-05 12:35:36,550 - INFO - epoch 2, step 35980, training loss = 2.043925, validation loss = 2.064376
2018-12-05 12:35:40,632 - INFO - epoch 2, step 35990, training loss = 1.831801, validation loss = 2.301846
2018-12-05 12:35:44,653 - INFO - epoch 2, step 36000, training loss = 2.203720, validation loss = 2.625412
2018-12-05 12:35:48,602 - INFO - epoch 2, step 36010, training loss = 2.091663, validation loss = 2.519665
2018-12-05 12:35:52,672 - INFO - epoch 2, step 36020, training loss = 1.731148, validation loss = 2.276426
2018-12-05 12:35:56,678 - INFO - epoch 2, step 36030, training loss = 2.111266, validation loss = 1.669269
2018-12-05 12:36:00,454 - INFO - epoch 2, step 36040, training loss = 1.947450, validation loss = 2.980869
2018-12-05 12:36:04,236 - INFO - epoch 2, step 36050, training loss = 2.166022, validation loss = 2.224573
2018-12-05 12:36:08,258 - INFO - epoch 2, step 36060, training loss = 2.372191, validation loss = 2.684032
2018-12-05 12:36:12,654 - INFO - epoch 2, step 36070, training loss = 1.937772, validation loss = 2.306633
2018-12-05 12:36:16,557 - INFO - epoch 2, step 36080, training loss = 2.042642, validation loss = 2.628842
2018-12-05 12:36:20,353 - INFO - epoch 2, step 36090, training loss = 1.905200, validation loss = 2.406177
2018-12-05 12:36:24,231 - INFO - epoch 2, step 36100, training loss = 2.083812, validation loss = 2.579480
2018-12-05 12:36:28,246 - INFO - epoch 2, step 36110, training loss = 2.232188, validation loss = 2.610899
2018-12-05 12:36:32,283 - INFO - epoch 2, step 36120, training loss = 2.288744, validation loss = 2.165163
2018-12-05 12:36:36,295 - INFO - epoch 2, step 36130, training loss = 2.203371, validation loss = 2.282962
2018-12-05 12:36:40,321 - INFO - epoch 2, step 36140, training loss = 2.150724, validation loss = 2.203735
2018-12-05 12:36:44,263 - INFO - epoch 2, step 36150, training loss = 1.881974, validation loss = 2.282483
2018-12-05 12:36:48,189 - INFO - epoch 2, step 36160, training loss = 2.209767, validation loss = 2.702230
2018-12-05 12:36:51,930 - INFO - epoch 2, step 36170, training loss = 1.857073, validation loss = 2.180921
2018-12-05 12:36:55,985 - INFO - epoch 2, step 36180, training loss = 2.104505, validation loss = 2.157336
2018-12-05 12:36:59,831 - INFO - epoch 2, step 36190, training loss = 2.286841, validation loss = 2.716422
2018-12-05 12:37:03,815 - INFO - epoch 2, step 36200, training loss = 1.802653, validation loss = 2.718158
2018-12-05 12:37:07,712 - INFO - epoch 2, step 36210, training loss = 2.308056, validation loss = 2.820877
2018-12-05 12:37:11,622 - INFO - epoch 2, step 36220, training loss = 2.083320, validation loss = 2.188681
2018-12-05 12:37:15,362 - INFO - epoch 2, step 36230, training loss = 1.920384, validation loss = 2.163785
2018-12-05 12:37:19,402 - INFO - epoch 2, step 36240, training loss = 2.038669, validation loss = 2.553978
2018-12-05 12:37:23,192 - INFO - epoch 2, step 36250, training loss = 2.303419, validation loss = 2.250243
2018-12-05 12:37:27,015 - INFO - epoch 2, step 36260, training loss = 2.089018, validation loss = 2.374562
2018-12-05 12:37:30,953 - INFO - epoch 2, step 36270, training loss = 2.390013, validation loss = 2.085853
2018-12-05 12:37:34,741 - INFO - epoch 2, step 36280, training loss = 2.020282, validation loss = 2.390724
2018-12-05 12:37:38,545 - INFO - epoch 2, step 36290, training loss = 2.009696, validation loss = 2.605007
2018-12-05 12:37:42,566 - INFO - epoch 2, step 36300, training loss = 2.095281, validation loss = 2.412372
2018-12-05 12:37:46,447 - INFO - epoch 2, step 36310, training loss = 2.065653, validation loss = 2.331487
2018-12-05 12:37:50,225 - INFO - epoch 2, step 36320, training loss = 2.007478, validation loss = 2.770217
2018-12-05 12:37:54,110 - INFO - epoch 2, step 36330, training loss = 2.038463, validation loss = 2.274330
2018-12-05 12:37:58,024 - INFO - epoch 2, step 36340, training loss = 1.979821, validation loss = 2.319939
2018-12-05 12:38:02,054 - INFO - epoch 2, step 36350, training loss = 1.895648, validation loss = 2.417559
2018-12-05 12:38:05,706 - INFO - epoch 2, step 36360, training loss = 1.860826, validation loss = 2.460508
2018-12-05 12:38:09,588 - INFO - epoch 2, step 36370, training loss = 2.112262, validation loss = 2.591602
2018-12-05 12:38:13,558 - INFO - epoch 2, step 36380, training loss = 1.911777, validation loss = 2.271262
2018-12-05 12:38:17,512 - INFO - epoch 2, step 36390, training loss = 2.246915, validation loss = 2.338669
2018-12-05 12:38:21,485 - INFO - epoch 2, step 36400, training loss = 2.240919, validation loss = 2.666201
2018-12-05 12:38:25,269 - INFO - epoch 2, step 36410, training loss = 2.108523, validation loss = 2.192245
2018-12-05 12:38:28,872 - INFO - epoch 2, step 36420, training loss = 2.123477, validation loss = 2.595873
2018-12-05 12:38:32,698 - INFO - epoch 2, step 36430, training loss = 2.196029, validation loss = 2.182916
2018-12-05 12:38:36,601 - INFO - epoch 2, step 36440, training loss = 2.306893, validation loss = 2.427788
2018-12-05 12:38:40,431 - INFO - epoch 2, step 36450, training loss = 2.144315, validation loss = 2.485711
2018-12-05 12:38:44,150 - INFO - epoch 2, step 36460, training loss = 1.793317, validation loss = 2.244082
2018-12-05 12:38:47,980 - INFO - epoch 2, step 36470, training loss = 2.257074, validation loss = 2.590450
2018-12-05 12:38:51,935 - INFO - epoch 2, step 36480, training loss = 2.206302, validation loss = 2.395649
2018-12-05 12:38:55,687 - INFO - epoch 2, step 36490, training loss = 2.167898, validation loss = 2.734551
2018-12-05 12:38:59,603 - INFO - epoch 2, step 36500, training loss = 2.133931, validation loss = 2.669912
2018-12-05 12:39:03,601 - INFO - epoch 2, step 36510, training loss = 1.938872, validation loss = 2.700200
2018-12-05 12:39:07,684 - INFO - epoch 2, step 36520, training loss = 2.134258, validation loss = 2.318352
2018-12-05 12:39:11,436 - INFO - epoch 2, step 36530, training loss = 2.063090, validation loss = 2.533126
2018-12-05 12:39:15,520 - INFO - epoch 2, step 36540, training loss = 1.987391, validation loss = 1.929247
2018-12-05 12:39:19,365 - INFO - epoch 2, step 36550, training loss = 2.044433, validation loss = 2.156309
2018-12-05 12:39:23,252 - INFO - epoch 2, step 36560, training loss = 1.844187, validation loss = 2.402736
2018-12-05 12:39:27,338 - INFO - epoch 2, step 36570, training loss = 2.181304, validation loss = 2.465363
2018-12-05 12:39:31,236 - INFO - epoch 2, step 36580, training loss = 2.200792, validation loss = 2.235380
2018-12-05 12:39:35,090 - INFO - epoch 2, step 36590, training loss = 2.143268, validation loss = 2.384107
2018-12-05 12:39:38,689 - INFO - epoch 2, step 36600, training loss = 1.849533, validation loss = 2.588415
2018-12-05 12:39:42,744 - INFO - epoch 2, step 36610, training loss = 2.391120, validation loss = 2.159823
2018-12-05 12:39:46,814 - INFO - epoch 2, step 36620, training loss = 2.234570, validation loss = 2.333441
2018-12-05 12:39:50,720 - INFO - epoch 2, step 36630, training loss = 1.946770, validation loss = 2.222608
2018-12-05 12:39:54,387 - INFO - epoch 2, step 36640, training loss = 2.252033, validation loss = 2.653121
2018-12-05 12:39:58,389 - INFO - epoch 2, step 36650, training loss = 2.353077, validation loss = 2.807318
2018-12-05 12:40:02,328 - INFO - epoch 2, step 36660, training loss = 1.809872, validation loss = 2.838901
2018-12-05 12:40:06,251 - INFO - epoch 2, step 36670, training loss = 1.890722, validation loss = 2.636180
2018-12-05 12:40:10,139 - INFO - epoch 2, step 36680, training loss = 1.942030, validation loss = 3.067622
2018-12-05 12:40:13,872 - INFO - epoch 2, step 36690, training loss = 1.856609, validation loss = 2.514937
2018-12-05 12:40:17,627 - INFO - epoch 2, step 36700, training loss = 1.843836, validation loss = 2.390078
2018-12-05 12:40:21,274 - INFO - epoch 2, step 36710, training loss = 2.238061, validation loss = 2.806672
2018-12-05 12:40:25,138 - INFO - epoch 2, step 36720, training loss = 1.763259, validation loss = 2.744556
2018-12-05 12:40:29,163 - INFO - epoch 2, step 36730, training loss = 2.110354, validation loss = 2.112972
2018-12-05 12:40:33,191 - INFO - epoch 2, step 36740, training loss = 2.295251, validation loss = 2.634604
2018-12-05 12:40:37,226 - INFO - epoch 2, step 36750, training loss = 1.899912, validation loss = 2.325316
2018-12-05 12:40:41,008 - INFO - epoch 2, step 36760, training loss = 2.404645, validation loss = 2.538042
2018-12-05 12:40:44,719 - INFO - epoch 2, step 36770, training loss = 2.299675, validation loss = 2.386565
2018-12-05 12:40:48,352 - INFO - epoch 2, step 36780, training loss = 2.794580, validation loss = 2.478080
2018-12-05 12:40:51,906 - INFO - epoch 2, step 36790, training loss = 3.165740, validation loss = 2.681934
2018-12-05 12:40:55,576 - INFO - epoch 2, step 36800, training loss = 3.357158, validation loss = 2.061302
2018-12-05 12:40:59,241 - INFO - epoch 2, step 36810, training loss = 3.009699, validation loss = 2.520382
2018-12-05 12:41:02,710 - INFO - epoch 2, step 36820, training loss = 2.901583, validation loss = 3.099916
2018-12-05 12:41:06,493 - INFO - epoch 2, step 36830, training loss = 2.754296, validation loss = 2.188316
2018-12-05 12:41:10,489 - INFO - epoch 2, step 36840, training loss = 2.628598, validation loss = 2.350328
2018-12-05 12:41:14,139 - INFO - epoch 2, step 36850, training loss = 2.972811, validation loss = 2.974232
2018-12-05 12:41:17,994 - INFO - epoch 2, step 36860, training loss = 2.596080, validation loss = 2.282876
2018-12-05 12:41:21,353 - INFO - epoch 2, step 36870, training loss = 2.801080, validation loss = 2.724296
2018-12-05 12:41:25,122 - INFO - epoch 2, step 36880, training loss = 2.372845, validation loss = 2.476871
2018-12-05 12:41:28,995 - INFO - epoch 2, step 36890, training loss = 3.177979, validation loss = 2.623698
2018-12-05 12:41:32,640 - INFO - epoch 2, step 36900, training loss = 3.241537, validation loss = 2.636415
2018-12-05 12:41:36,180 - INFO - epoch 2, step 36910, training loss = 2.875166, validation loss = 2.888336
2018-12-05 12:41:39,699 - INFO - epoch 2, step 36920, training loss = 2.587344, validation loss = 2.897191
2018-12-05 12:41:43,373 - INFO - epoch 2, step 36930, training loss = 2.913813, validation loss = 2.964306
2018-12-05 12:41:47,065 - INFO - epoch 2, step 36940, training loss = 2.638566, validation loss = 2.737192
2018-12-05 12:41:51,035 - INFO - epoch 2, step 36950, training loss = 2.971391, validation loss = 2.263294
2018-12-05 12:41:55,049 - INFO - epoch 2, step 36960, training loss = 2.899170, validation loss = 2.516824
2018-12-05 12:41:59,131 - INFO - epoch 2, step 36970, training loss = 3.331283, validation loss = 3.301670
2018-12-05 12:42:02,867 - INFO - epoch 2, step 36980, training loss = 2.605352, validation loss = 2.434759
2018-12-05 12:42:06,507 - INFO - epoch 2, step 36990, training loss = 3.042867, validation loss = 2.786864
2018-12-05 12:42:10,067 - INFO - epoch 2, step 37000, training loss = 2.803050, validation loss = 1.944040
2018-12-05 12:42:13,667 - INFO - epoch 2, step 37010, training loss = 2.470429, validation loss = 2.715145
2018-12-05 12:42:17,562 - INFO - epoch 2, step 37020, training loss = 2.678983, validation loss = 2.594404
2018-12-05 12:42:21,290 - INFO - epoch 2, step 37030, training loss = 2.774771, validation loss = 2.872389
2018-12-05 12:42:25,319 - INFO - epoch 2, step 37040, training loss = 3.028019, validation loss = 2.276888
2018-12-05 12:42:28,768 - INFO - epoch 2, step 37050, training loss = 2.728342, validation loss = 2.651932
2018-12-05 12:42:32,235 - INFO - epoch 2, step 37060, training loss = 2.613200, validation loss = 2.873472
2018-12-05 12:42:36,119 - INFO - epoch 2, step 37070, training loss = 2.856028, validation loss = 2.727961
2018-12-05 12:42:39,701 - INFO - epoch 2, step 37080, training loss = 2.804691, validation loss = 3.092494
2018-12-05 12:42:43,544 - INFO - epoch 2, step 37090, training loss = 3.205806, validation loss = 2.984988
2018-12-05 12:42:47,442 - INFO - epoch 2, step 37100, training loss = 2.918717, validation loss = 2.317644
2018-12-05 12:42:50,933 - INFO - epoch 2, step 37110, training loss = 2.596102, validation loss = 2.685477
2018-12-05 12:42:54,802 - INFO - epoch 2, step 37120, training loss = 2.602618, validation loss = 2.764436
2018-12-05 12:42:58,214 - INFO - epoch 2, step 37130, training loss = 2.720054, validation loss = 2.728926
2018-12-05 12:43:01,830 - INFO - epoch 2, step 37140, training loss = 2.457476, validation loss = 3.028037
2018-12-05 12:43:05,340 - INFO - epoch 2, step 37150, training loss = 2.643462, validation loss = 3.053392
2018-12-05 12:43:08,913 - INFO - epoch 2, step 37160, training loss = 3.119480, validation loss = 2.910805
2018-12-05 12:43:12,342 - INFO - epoch 2, step 37170, training loss = 2.689647, validation loss = 2.406343
2018-12-05 12:43:16,197 - INFO - epoch 2, step 37180, training loss = 2.971776, validation loss = 2.711295
2018-12-05 12:43:19,797 - INFO - epoch 2, step 37190, training loss = 3.381682, validation loss = 2.811748
2018-12-05 12:43:23,267 - INFO - epoch 2, step 37200, training loss = 2.817643, validation loss = 2.854347
2018-12-05 12:43:27,019 - INFO - epoch 2, step 37210, training loss = 2.953064, validation loss = 2.724617
2018-12-05 12:43:30,483 - INFO - epoch 2, step 37220, training loss = 3.016109, validation loss = 2.653135
2018-12-05 12:43:34,319 - INFO - epoch 2, step 37230, training loss = 2.880673, validation loss = 3.043820
2018-12-05 12:43:38,243 - INFO - epoch 2, step 37240, training loss = 2.482372, validation loss = 2.789885
2018-12-05 12:43:42,038 - INFO - epoch 2, step 37250, training loss = 2.170118, validation loss = 2.479095
2018-12-05 12:43:45,591 - INFO - epoch 2, step 37260, training loss = 3.090840, validation loss = 2.937384
2018-12-05 12:43:49,476 - INFO - epoch 2, step 37270, training loss = 2.569121, validation loss = 2.721792
2018-12-05 12:43:52,956 - INFO - epoch 2, step 37280, training loss = 2.601079, validation loss = 3.008400
2018-12-05 12:43:56,522 - INFO - epoch 2, step 37290, training loss = 3.090923, validation loss = 2.394301
2018-12-05 12:44:00,263 - INFO - epoch 2, step 37300, training loss = 2.862202, validation loss = 2.778794
2018-12-05 12:44:03,679 - INFO - epoch 2, step 37310, training loss = 2.738423, validation loss = 2.918971
2018-12-05 12:44:07,349 - INFO - epoch 2, step 37320, training loss = 3.295218, validation loss = 3.140296
2018-12-05 12:44:10,819 - INFO - epoch 2, step 37330, training loss = 2.630619, validation loss = 2.419498
2018-12-05 12:44:14,212 - INFO - epoch 2, step 37340, training loss = 2.924015, validation loss = 2.534699
2018-12-05 12:44:17,828 - INFO - epoch 2, step 37350, training loss = 2.915602, validation loss = 2.259362
2018-12-05 12:44:21,465 - INFO - epoch 2, step 37360, training loss = 2.832869, validation loss = 2.177123
2018-12-05 12:44:25,000 - INFO - epoch 2, step 37370, training loss = 3.156385, validation loss = 2.985785
2018-12-05 12:44:28,579 - INFO - epoch 2, step 37380, training loss = 3.030905, validation loss = 2.496056
2018-12-05 12:44:32,194 - INFO - epoch 2, step 37390, training loss = 2.683864, validation loss = 2.497990
2018-12-05 12:44:35,898 - INFO - epoch 2, step 37400, training loss = 2.912471, validation loss = 2.479334
2018-12-05 12:44:39,623 - INFO - epoch 2, step 37410, training loss = 2.750824, validation loss = 3.072858
2018-12-05 12:44:43,184 - INFO - epoch 2, step 37420, training loss = 3.292203, validation loss = 3.179579
2018-12-05 12:44:46,947 - INFO - epoch 2, step 37430, training loss = 3.305037, validation loss = 3.030814
2018-12-05 12:44:50,500 - INFO - epoch 2, step 37440, training loss = 2.592079, validation loss = 2.649102
2018-12-05 12:44:53,986 - INFO - epoch 2, step 37450, training loss = 2.765888, validation loss = 2.783316
2018-12-05 12:44:57,654 - INFO - epoch 2, step 37460, training loss = 2.983531, validation loss = 2.830986
2018-12-05 12:45:01,563 - INFO - epoch 2, step 37470, training loss = 3.129665, validation loss = 2.446152
2018-12-05 12:45:05,400 - INFO - epoch 2, step 37480, training loss = 2.528261, validation loss = 2.873204
2018-12-05 12:45:08,976 - INFO - epoch 2, step 37490, training loss = 2.738108, validation loss = 2.970545
2018-12-05 12:45:12,379 - INFO - epoch 2, step 37500, training loss = 3.101664, validation loss = 2.449802
2018-12-05 12:45:15,778 - INFO - epoch 2, step 37510, training loss = 2.569612, validation loss = 2.778214
2018-12-05 12:45:19,260 - INFO - epoch 2, step 37520, training loss = 2.655135, validation loss = 2.515751
2018-12-05 12:45:23,309 - INFO - epoch 2, step 37530, training loss = 3.059817, validation loss = 2.530931
2018-12-05 12:45:27,037 - INFO - epoch 2, step 37540, training loss = 2.830817, validation loss = 2.809406
2018-12-05 12:45:30,712 - INFO - epoch 2, step 37550, training loss = 2.574189, validation loss = 3.055258
2018-12-05 12:45:34,281 - INFO - epoch 2, step 37560, training loss = 2.343666, validation loss = 2.891770
2018-12-05 12:45:37,898 - INFO - epoch 2, step 37570, training loss = 3.296658, validation loss = 2.797125
2018-12-05 12:45:41,655 - INFO - epoch 2, step 37580, training loss = 2.921392, validation loss = 2.533886
2018-12-05 12:45:45,459 - INFO - epoch 2, step 37590, training loss = 2.587413, validation loss = 2.811742
2018-12-05 12:45:49,041 - INFO - epoch 2, step 37600, training loss = 2.639226, validation loss = 2.785347
2018-12-05 12:45:52,563 - INFO - epoch 2, step 37610, training loss = 2.789692, validation loss = 2.406568
2018-12-05 12:45:56,396 - INFO - epoch 2, step 37620, training loss = 2.697183, validation loss = 2.859103
2018-12-05 12:46:00,214 - INFO - epoch 2, step 37630, training loss = 3.005502, validation loss = 3.236254
2018-12-05 12:46:04,361 - INFO - epoch 2, step 37640, training loss = 3.223418, validation loss = 2.946035
2018-12-05 12:46:08,020 - INFO - epoch 2, step 37650, training loss = 2.683792, validation loss = 3.147917
2018-12-05 12:46:11,784 - INFO - epoch 2, step 37660, training loss = 3.206302, validation loss = 2.427194
2018-12-05 12:46:15,636 - INFO - epoch 2, step 37670, training loss = 2.395747, validation loss = 2.997067
2018-12-05 12:46:19,242 - INFO - epoch 2, step 37680, training loss = 3.164583, validation loss = 2.923732
2018-12-05 12:46:23,201 - INFO - epoch 2, step 37690, training loss = 2.292794, validation loss = 2.275059
2018-12-05 12:46:27,084 - INFO - epoch 2, step 37700, training loss = 3.064360, validation loss = 2.852774
2018-12-05 12:46:30,746 - INFO - epoch 2, step 37710, training loss = 2.514934, validation loss = 2.626431
2018-12-05 12:46:34,537 - INFO - epoch 2, step 37720, training loss = 3.225718, validation loss = 2.631974
2018-12-05 12:46:38,452 - INFO - epoch 2, step 37730, training loss = 2.553490, validation loss = 3.039941
2018-12-05 12:46:42,153 - INFO - epoch 2, step 37740, training loss = 3.293948, validation loss = 2.534899
2018-12-05 12:46:46,024 - INFO - epoch 2, step 37750, training loss = 3.142521, validation loss = 3.259579
2018-12-05 12:46:49,838 - INFO - epoch 2, step 37760, training loss = 2.924637, validation loss = 2.839898
2018-12-05 12:46:53,480 - INFO - epoch 2, step 37770, training loss = 2.477811, validation loss = 2.255932
2018-12-05 12:46:57,318 - INFO - epoch 2, step 37780, training loss = 2.944971, validation loss = 2.937030
2018-12-05 12:47:00,886 - INFO - epoch 2, step 37790, training loss = 2.979116, validation loss = 2.880683
2018-12-05 12:47:04,337 - INFO - epoch 2, step 37800, training loss = 2.989221, validation loss = 2.463491
2018-12-05 12:47:08,314 - INFO - epoch 2, step 37810, training loss = 2.906568, validation loss = 2.646368
2018-12-05 12:47:12,350 - INFO - epoch 2, step 37820, training loss = 2.719040, validation loss = 2.496820
2018-12-05 12:47:16,375 - INFO - epoch 2, step 37830, training loss = 3.182288, validation loss = 2.849715
2018-12-05 12:47:20,153 - INFO - epoch 2, step 37840, training loss = 2.933993, validation loss = 2.856020
2018-12-05 12:47:23,819 - INFO - epoch 2, step 37850, training loss = 2.670150, validation loss = 2.949312
2018-12-05 12:47:27,835 - INFO - epoch 2, step 37860, training loss = 2.478422, validation loss = 2.522935
2018-12-05 12:47:31,801 - INFO - epoch 2, step 37870, training loss = 3.487900, validation loss = 3.105609
2018-12-05 12:47:35,770 - INFO - epoch 2, step 37880, training loss = 2.628457, validation loss = 2.397297
2018-12-05 12:47:39,578 - INFO - epoch 2, step 37890, training loss = 2.935362, validation loss = 3.086756
2018-12-05 12:47:43,359 - INFO - epoch 2, step 37900, training loss = 2.862841, validation loss = 2.146211
2018-12-05 12:47:46,764 - INFO - epoch 2, step 37910, training loss = 2.650412, validation loss = 2.780237
2018-12-05 12:47:50,358 - INFO - epoch 2, step 37920, training loss = 2.595549, validation loss = 2.525207
2018-12-05 12:47:54,001 - INFO - epoch 2, step 37930, training loss = 2.663821, validation loss = 2.323631
2018-12-05 12:47:57,515 - INFO - epoch 2, step 37940, training loss = 2.710802, validation loss = 2.582994
2018-12-05 12:48:01,527 - INFO - epoch 2, step 37950, training loss = 2.938386, validation loss = 2.548091
2018-12-05 12:48:05,356 - INFO - epoch 2, step 37960, training loss = 2.753756, validation loss = 2.772068
2018-12-05 12:48:08,904 - INFO - epoch 2, step 37970, training loss = 2.554267, validation loss = 2.646882
2018-12-05 12:48:12,430 - INFO - epoch 2, step 37980, training loss = 3.127547, validation loss = 2.586643
2018-12-05 12:48:16,095 - INFO - epoch 2, step 37990, training loss = 2.629037, validation loss = 2.262427
2018-12-05 12:48:19,502 - INFO - epoch 2, step 38000, training loss = 2.718628, validation loss = 2.668110
2018-12-05 12:48:23,045 - INFO - epoch 2, step 38010, training loss = 2.737108, validation loss = 2.852424
2018-12-05 12:48:26,640 - INFO - epoch 2, step 38020, training loss = 2.562019, validation loss = 2.426242
2018-12-05 12:48:30,480 - INFO - epoch 2, step 38030, training loss = 2.751916, validation loss = 2.099125
2018-12-05 12:48:34,359 - INFO - epoch 2, step 38040, training loss = 2.846890, validation loss = 2.618183
2018-12-05 12:48:38,079 - INFO - epoch 2, step 38050, training loss = 3.131004, validation loss = 2.820348
2018-12-05 12:48:41,688 - INFO - epoch 2, step 38060, training loss = 2.183287, validation loss = 2.595263
2018-12-05 12:48:45,341 - INFO - epoch 2, step 38070, training loss = 2.636276, validation loss = 1.828982
2018-12-05 12:48:49,020 - INFO - epoch 2, step 38080, training loss = 2.612336, validation loss = 2.175831
2018-12-05 12:48:52,636 - INFO - epoch 2, step 38090, training loss = 3.036088, validation loss = 2.261156
2018-12-05 12:48:56,020 - INFO - epoch 2, step 38100, training loss = 3.213362, validation loss = 2.613208
2018-12-05 12:48:59,489 - INFO - epoch 2, step 38110, training loss = 2.940871, validation loss = 1.988301
2018-12-05 12:49:02,945 - INFO - epoch 2, step 38120, training loss = 2.994487, validation loss = 2.570395
2018-12-05 12:49:06,442 - INFO - epoch 2, step 38130, training loss = 2.968096, validation loss = 2.413340
2018-12-05 12:49:10,110 - INFO - epoch 2, step 38140, training loss = 2.876580, validation loss = 2.123714
2018-12-05 12:49:13,588 - INFO - epoch 2, step 38150, training loss = 2.571559, validation loss = 2.480470
2018-12-05 12:49:17,125 - INFO - epoch 2, step 38160, training loss = 2.835269, validation loss = 3.238679
2018-12-05 12:49:20,810 - INFO - epoch 2, step 38170, training loss = 3.111731, validation loss = 2.352642
2018-12-05 12:49:24,436 - INFO - epoch 2, step 38180, training loss = 2.814748, validation loss = 2.584693
2018-12-05 12:49:28,248 - INFO - epoch 2, step 38190, training loss = 2.686722, validation loss = 2.384205
2018-12-05 12:49:31,816 - INFO - epoch 2, step 38200, training loss = 2.539379, validation loss = 2.290258
2018-12-05 12:49:35,331 - INFO - epoch 2, step 38210, training loss = 2.871287, validation loss = 2.184942
2018-12-05 12:49:39,386 - INFO - epoch 2, step 38220, training loss = 2.350933, validation loss = 1.752827
2018-12-05 12:49:43,382 - INFO - epoch 2, step 38230, training loss = 3.300496, validation loss = 2.006637
2018-12-05 12:49:47,367 - INFO - epoch 2, step 38240, training loss = 2.920021, validation loss = 2.513563
2018-12-05 12:49:51,305 - INFO - epoch 2, step 38250, training loss = 2.801844, validation loss = 2.377659
2018-12-05 12:49:55,258 - INFO - epoch 2, step 38260, training loss = 2.844184, validation loss = 2.434537
2018-12-05 12:49:59,083 - INFO - epoch 2, step 38270, training loss = 2.995223, validation loss = 2.431803
2018-12-05 12:50:03,324 - INFO - epoch 2, step 38280, training loss = 2.810018, validation loss = 2.709370
2018-12-05 12:50:08,205 - INFO - epoch 2, step 38290, training loss = 2.119033, validation loss = 2.617622
2018-12-05 12:50:13,196 - INFO - epoch 2, step 38300, training loss = 2.746105, validation loss = 2.577140
2018-12-05 12:50:18,102 - INFO - epoch 2, step 38310, training loss = 2.145593, validation loss = 2.719252
2018-12-05 12:50:23,606 - INFO - epoch 2, step 38320, training loss = 2.315052, validation loss = 2.741460
2018-12-05 12:50:28,963 - INFO - epoch 2, step 38330, training loss = 2.199573, validation loss = 2.520974
2018-12-05 12:50:34,111 - INFO - epoch 2, step 38340, training loss = 3.376277, validation loss = 2.508889
2018-12-05 12:50:39,367 - INFO - epoch 2, step 38350, training loss = 3.314226, validation loss = 1.972468
2018-12-05 12:50:45,130 - INFO - epoch 2, step 38360, training loss = 2.674678, validation loss = 2.706585
2018-12-05 12:50:50,625 - INFO - epoch 2, step 38370, training loss = 2.624749, validation loss = 2.251818
2018-12-05 12:50:56,602 - INFO - epoch 2, step 38380, training loss = 2.923977, validation loss = 2.134470
2018-12-05 12:51:03,083 - INFO - epoch 2, step 38390, training loss = 1.553265, validation loss = 2.480746
2018-12-05 12:51:07,222 - INFO - epoch 2, step 38400, training loss = 3.030844, validation loss = 2.410051
2018-12-05 12:51:10,931 - INFO - epoch 2, step 38410, training loss = 3.040344, validation loss = 2.779366
2018-12-05 12:51:14,923 - INFO - epoch 2, step 38420, training loss = 3.006998, validation loss = 2.015963
2018-12-05 12:51:18,879 - INFO - epoch 2, step 38430, training loss = 3.153470, validation loss = 2.388784
2018-12-05 12:51:22,869 - INFO - epoch 2, step 38440, training loss = 2.461051, validation loss = 2.348306
2018-12-05 12:51:26,813 - INFO - epoch 2, step 38450, training loss = 3.240829, validation loss = 2.577215
2018-12-05 12:51:31,429 - INFO - epoch 2, step 38460, training loss = 2.286356, validation loss = 2.466047
2018-12-05 12:51:36,661 - INFO - epoch 2, step 38470, training loss = 2.119092, validation loss = 1.973063
2018-12-05 12:51:41,715 - INFO - epoch 2, step 38480, training loss = 2.696534, validation loss = 2.454120
2018-12-05 12:51:46,588 - INFO - epoch 2, step 38490, training loss = 2.823370, validation loss = 2.472581
2018-12-05 12:51:51,669 - INFO - epoch 2, step 38500, training loss = 2.799914, validation loss = 2.410454
2018-12-05 12:51:57,239 - INFO - epoch 2, step 38510, training loss = 2.225417, validation loss = 1.961767
2018-12-05 12:52:02,166 - INFO - epoch 2, step 38520, training loss = 2.145414, validation loss = 2.041760
2018-12-05 12:52:07,655 - INFO - epoch 2, step 38530, training loss = 2.321939, validation loss = 2.098099
2018-12-05 12:52:12,795 - INFO - epoch 2, step 38540, training loss = 2.444898, validation loss = 2.594892
2018-12-05 12:52:16,930 - INFO - epoch 2, step 38550, training loss = 2.699901, validation loss = 2.783310
2018-12-05 12:52:20,608 - INFO - epoch 2, step 38560, training loss = 2.329268, validation loss = 2.427246
2018-12-05 12:52:24,498 - INFO - epoch 2, step 38570, training loss = 2.757931, validation loss = 2.603612
2018-12-05 12:52:28,372 - INFO - epoch 2, step 38580, training loss = 2.973362, validation loss = 3.147404
2018-12-05 12:52:32,392 - INFO - epoch 2, step 38590, training loss = 2.996402, validation loss = 1.559151
2018-12-05 12:52:36,385 - INFO - epoch 2, step 38600, training loss = 2.636934, validation loss = 2.686180
2018-12-05 12:52:40,720 - INFO - epoch 2, step 38610, training loss = 2.038952, validation loss = 2.398710
2018-12-05 12:52:44,880 - INFO - epoch 2, step 38620, training loss = 2.516333, validation loss = 2.521338
2018-12-05 12:52:48,904 - INFO - epoch 2, step 38630, training loss = 2.368141, validation loss = 2.779670
2018-12-05 12:52:52,850 - INFO - epoch 2, step 38640, training loss = 2.278363, validation loss = 2.357512
2018-12-05 12:52:56,782 - INFO - epoch 2, step 38650, training loss = 2.299261, validation loss = 2.871832
2018-12-05 12:53:00,751 - INFO - epoch 2, step 38660, training loss = 2.898414, validation loss = 2.664893
2018-12-05 12:53:05,041 - INFO - epoch 2, step 38670, training loss = 2.471954, validation loss = 3.300631
2018-12-05 12:53:09,168 - INFO - epoch 2, step 38680, training loss = 3.022201, validation loss = 3.019642
2018-12-05 12:53:13,077 - INFO - epoch 2, step 38690, training loss = 2.920761, validation loss = 2.738181
2018-12-05 12:53:17,138 - INFO - epoch 2, step 38700, training loss = 2.938839, validation loss = 2.522022
2018-12-05 12:53:21,265 - INFO - epoch 2, step 38710, training loss = 2.607913, validation loss = 2.535278
2018-12-05 12:53:25,725 - INFO - epoch 2, step 38720, training loss = 2.583613, validation loss = 3.496857
2018-12-05 12:53:30,020 - INFO - epoch 2, step 38730, training loss = 1.935809, validation loss = 2.658370
2018-12-05 12:53:35,819 - INFO - epoch 2, step 38740, training loss = 2.701745, validation loss = 2.180901
2018-12-05 12:53:42,129 - INFO - epoch 2, step 38750, training loss = 1.677934, validation loss = 2.450365
2018-12-05 12:53:47,329 - INFO - epoch 2, step 38760, training loss = 1.892137, validation loss = 2.667365
2018-12-05 12:53:53,148 - INFO - epoch 2, step 38770, training loss = 2.093169, validation loss = 2.830632
2018-12-05 12:53:58,554 - INFO - epoch 2, step 38780, training loss = 2.419215, validation loss = 3.174114
2018-12-05 12:54:03,996 - INFO - epoch 2, step 38790, training loss = 2.240180, validation loss = 3.021133
2018-12-05 12:54:09,212 - INFO - epoch 2, step 38800, training loss = 2.176887, validation loss = 3.255983
2018-12-05 12:54:14,268 - INFO - epoch 2, step 38810, training loss = 2.446597, validation loss = 2.790917
2018-12-05 12:54:19,426 - INFO - epoch 2, step 38820, training loss = 3.341942, validation loss = 2.777006
2018-12-05 12:54:24,800 - INFO - epoch 2, step 38830, training loss = 2.138891, validation loss = 2.477846
2018-12-05 12:54:30,850 - INFO - epoch 2, step 38840, training loss = 1.939953, validation loss = 2.866838
2018-12-05 12:54:36,263 - INFO - epoch 2, step 38850, training loss = 2.431986, validation loss = 2.985728
2018-12-05 12:54:41,756 - INFO - epoch 2, step 38860, training loss = 1.945487, validation loss = 2.880810
2018-12-05 12:54:47,023 - INFO - epoch 2, step 38870, training loss = 2.108963, validation loss = 3.484007
2018-12-05 12:54:52,240 - INFO - epoch 2, step 38880, training loss = 2.500383, validation loss = 2.820755
2018-12-05 12:54:57,419 - INFO - epoch 2, step 38890, training loss = 3.311981, validation loss = 2.553912
2018-12-05 12:55:03,050 - INFO - epoch 2, step 38900, training loss = 2.122542, validation loss = 2.642014
2018-12-05 12:55:08,531 - INFO - epoch 2, step 38910, training loss = 1.878478, validation loss = 2.658961
2018-12-05 12:55:13,846 - INFO - epoch 2, step 38920, training loss = 2.271111, validation loss = 2.555542
2018-12-05 12:55:18,763 - INFO - epoch 2, step 38930, training loss = 2.760366, validation loss = 2.271069
2018-12-05 12:55:24,570 - INFO - epoch 2, step 38940, training loss = 2.478635, validation loss = 2.582338
2018-12-05 12:55:29,964 - INFO - epoch 2, step 38950, training loss = 2.409501, validation loss = 2.999146
2018-12-05 12:55:35,331 - INFO - epoch 2, step 38960, training loss = 1.733764, validation loss = 2.725599
2018-12-05 12:55:40,554 - INFO - epoch 2, step 38970, training loss = 2.762140, validation loss = 3.417325
2018-12-05 12:55:44,648 - INFO - epoch 2, step 38980, training loss = 3.313517, validation loss = 2.244278
2018-12-05 12:55:48,631 - INFO - epoch 2, step 38990, training loss = 3.144548, validation loss = 2.468704
2018-12-05 12:55:52,858 - INFO - epoch 2, step 39000, training loss = 2.508222, validation loss = 2.454069
2018-12-05 12:55:56,919 - INFO - epoch 2, step 39010, training loss = 2.583420, validation loss = 2.848009
2018-12-05 12:56:01,651 - INFO - epoch 2, step 39020, training loss = 2.670088, validation loss = 2.605973
2018-12-05 12:56:08,000 - INFO - epoch 2, step 39030, training loss = 2.386689, validation loss = 3.413630
2018-12-05 12:56:13,585 - INFO - epoch 2, step 39040, training loss = 2.227578, validation loss = 3.256685
2018-12-05 12:56:19,011 - INFO - epoch 2, step 39050, training loss = 2.150464, validation loss = 2.914038
2018-12-05 12:56:24,539 - INFO - epoch 2, step 39060, training loss = 2.089004, validation loss = 2.650947
2018-12-05 12:56:29,916 - INFO - epoch 2, step 39070, training loss = 2.089656, validation loss = 2.554979
2018-12-05 12:56:35,246 - INFO - epoch 2, step 39080, training loss = 2.305560, validation loss = 2.856714
2018-12-05 12:56:40,142 - INFO - epoch 2, step 39090, training loss = 2.020099, validation loss = 2.830129
2018-12-05 12:56:45,166 - INFO - epoch 2, step 39100, training loss = 2.535110, validation loss = 2.408381
2018-12-05 12:56:49,411 - INFO - epoch 2, step 39110, training loss = 2.921272, validation loss = 2.645133
2018-12-05 12:56:53,450 - INFO - epoch 2, step 39120, training loss = 2.870553, validation loss = 2.870580
2018-12-05 12:56:57,705 - INFO - epoch 2, step 39130, training loss = 2.988639, validation loss = 2.490848
2018-12-05 12:57:02,098 - INFO - epoch 2, step 39140, training loss = 2.688894, validation loss = 2.542711
2018-12-05 12:57:06,579 - INFO - epoch 2, step 39150, training loss = 2.941718, validation loss = 2.691438
2018-12-05 12:57:10,770 - INFO - epoch 2, step 39160, training loss = 2.645157, validation loss = 2.715683
2018-12-05 12:57:14,862 - INFO - epoch 2, step 39170, training loss = 2.986031, validation loss = 2.819605
2018-12-05 12:57:19,124 - INFO - epoch 2, step 39180, training loss = 2.264027, validation loss = 2.757211
2018-12-05 12:57:23,290 - INFO - epoch 2, step 39190, training loss = 2.822837, validation loss = 3.150010
2018-12-05 12:57:27,737 - INFO - epoch 2, step 39200, training loss = 2.576848, validation loss = 2.743442
2018-12-05 12:57:33,087 - INFO - epoch 2, step 39210, training loss = 2.258843, validation loss = 2.300038
2018-12-05 12:57:37,837 - INFO - epoch 2, step 39220, training loss = 2.583597, validation loss = 2.279553
2018-12-05 12:57:43,279 - INFO - epoch 2, step 39230, training loss = 2.572748, validation loss = 2.535765
2018-12-05 12:57:48,738 - INFO - epoch 2, step 39240, training loss = 2.112523, validation loss = 2.867852
2018-12-05 12:57:54,104 - INFO - epoch 2, step 39250, training loss = 2.087961, validation loss = 2.752437
2018-12-05 12:57:59,328 - INFO - epoch 2, step 39260, training loss = 2.147733, validation loss = 2.788951
2018-12-05 12:58:04,717 - INFO - epoch 2, step 39270, training loss = 2.137913, validation loss = 2.629526
2018-12-05 12:58:09,736 - INFO - epoch 2, step 39280, training loss = 2.767578, validation loss = 2.479195
2018-12-05 12:58:15,234 - INFO - epoch 2, step 39290, training loss = 2.365028, validation loss = 2.432455
2018-12-05 12:58:20,374 - INFO - epoch 2, step 39300, training loss = 1.878903, validation loss = 2.686442
2018-12-05 12:58:25,191 - INFO - epoch 2, step 39310, training loss = 2.753497, validation loss = 2.875661
2018-12-05 12:58:29,651 - INFO - epoch 2, step 39320, training loss = 2.108517, validation loss = 2.659863
2018-12-05 12:58:34,901 - INFO - epoch 2, step 39330, training loss = 2.188518, validation loss = 3.003485
2018-12-05 12:58:38,889 - INFO - epoch 2, step 39340, training loss = 2.753732, validation loss = 2.506641
2018-12-05 12:58:42,625 - INFO - epoch 2, step 39350, training loss = 2.801745, validation loss = 2.340194
2018-12-05 12:58:46,351 - INFO - epoch 2, step 39360, training loss = 2.696051, validation loss = 2.929300
2018-12-05 12:58:50,232 - INFO - epoch 2, step 39370, training loss = 2.472066, validation loss = 2.773248
2018-12-05 12:58:53,811 - INFO - epoch 2, step 39380, training loss = 3.170947, validation loss = 2.952921
2018-12-05 12:58:57,485 - INFO - epoch 2, step 39390, training loss = 2.515299, validation loss = 3.128066
2018-12-05 12:59:02,151 - INFO - epoch 2, step 39400, training loss = 2.481984, validation loss = 2.905109
2018-12-05 12:59:07,803 - INFO - epoch 2, step 39410, training loss = 2.413021, validation loss = 2.824056
2018-12-05 12:59:13,308 - INFO - epoch 2, step 39420, training loss = 2.039236, validation loss = 2.843990
2018-12-05 12:59:18,586 - INFO - epoch 2, step 39430, training loss = 2.907774, validation loss = 3.115646
2018-12-05 12:59:24,218 - INFO - epoch 2, step 39440, training loss = 2.232950, validation loss = 3.233461
2018-12-05 12:59:29,610 - INFO - epoch 2, step 39450, training loss = 2.093990, validation loss = 2.849684
2018-12-05 12:59:35,222 - INFO - epoch 2, step 39460, training loss = 1.715342, validation loss = 2.334718
2018-12-05 12:59:40,639 - INFO - epoch 2, step 39470, training loss = 2.435818, validation loss = 2.629733
2018-12-05 12:59:44,831 - INFO - epoch 2, step 39480, training loss = 2.394166, validation loss = 2.858824
2018-12-05 12:59:48,577 - INFO - epoch 2, step 39490, training loss = 2.670523, validation loss = 2.719947
2018-12-05 12:59:52,357 - INFO - epoch 2, step 39500, training loss = 2.959857, validation loss = 3.325367
2018-12-05 12:59:56,456 - INFO - epoch 2, step 39510, training loss = 2.879557, validation loss = 3.303995
2018-12-05 13:00:00,515 - INFO - epoch 2, step 39520, training loss = 2.804357, validation loss = 2.833909
2018-12-05 13:00:04,621 - INFO - epoch 2, step 39530, training loss = 2.850228, validation loss = 2.501124
2018-12-05 13:00:09,696 - INFO - epoch 2, step 39540, training loss = 2.183615, validation loss = 2.805610
2018-12-05 13:00:14,894 - INFO - epoch 2, step 39550, training loss = 1.971511, validation loss = 2.543190
2018-12-05 13:00:19,875 - INFO - epoch 2, step 39560, training loss = 2.301815, validation loss = 2.987085
2018-12-05 13:00:24,847 - INFO - epoch 2, step 39570, training loss = 2.547843, validation loss = 2.940593
2018-12-05 13:00:30,061 - INFO - epoch 2, step 39580, training loss = 1.984022, validation loss = 2.712537
2018-12-05 13:00:35,739 - INFO - epoch 2, step 39590, training loss = 2.159410, validation loss = 2.923979
2018-12-05 13:00:41,102 - INFO - epoch 2, step 39600, training loss = 2.346983, validation loss = 2.827114
2018-12-05 13:00:46,604 - INFO - epoch 2, step 39610, training loss = 2.000839, validation loss = 2.179975
2018-12-05 13:00:51,435 - INFO - epoch 2, step 39620, training loss = 2.524513, validation loss = 2.349405
2018-12-05 13:00:56,933 - INFO - epoch 2, step 39630, training loss = 1.642624, validation loss = 2.591184
2018-12-05 13:01:01,790 - INFO - epoch 2, step 39640, training loss = 2.355340, validation loss = 2.805372
2018-12-05 13:01:07,412 - INFO - epoch 2, step 39650, training loss = 2.259603, validation loss = 3.129893
2018-12-05 13:01:13,129 - INFO - epoch 2, step 39660, training loss = 1.708974, validation loss = 3.031480
2018-12-05 13:01:18,582 - INFO - epoch 2, step 39670, training loss = 2.365238, validation loss = 3.095932
2018-12-05 13:01:24,020 - INFO - epoch 2, step 39680, training loss = 2.644744, validation loss = 2.713180
2018-12-05 13:01:29,946 - INFO - epoch 2, step 39690, training loss = 1.719174, validation loss = 2.823161
2018-12-05 13:01:34,809 - INFO - epoch 2, step 39700, training loss = 2.669555, validation loss = 2.989179
2018-12-05 13:01:40,399 - INFO - epoch 2, step 39710, training loss = 2.581657, validation loss = 2.923842
2018-12-05 13:01:45,715 - INFO - epoch 2, step 39720, training loss = 2.137183, validation loss = 3.002206
2018-12-05 13:01:51,226 - INFO - epoch 2, step 39730, training loss = 2.707635, validation loss = 3.032578
2018-12-05 13:01:54,996 - INFO - epoch 2, step 39740, training loss = 2.930757, validation loss = 3.048544
2018-12-05 13:01:58,981 - INFO - epoch 2, step 39750, training loss = 2.827055, validation loss = 2.276233
2018-12-05 13:02:02,792 - INFO - epoch 2, step 39760, training loss = 2.715226, validation loss = 2.524658
2018-12-05 13:02:06,894 - INFO - epoch 2, step 39770, training loss = 2.793011, validation loss = 2.199040
2018-12-05 13:02:10,631 - INFO - epoch 2, step 39780, training loss = 2.838659, validation loss = 2.686481
2018-12-05 13:02:14,661 - INFO - epoch 2, step 39790, training loss = 3.004679, validation loss = 2.844007
2018-12-05 13:02:18,704 - INFO - epoch 2, step 39800, training loss = 2.654835, validation loss = 2.713978
2018-12-05 13:02:22,988 - INFO - epoch 2, step 39810, training loss = 2.889349, validation loss = 2.736870
2018-12-05 13:02:27,012 - INFO - epoch 2, step 39820, training loss = 2.787829, validation loss = 2.931289
2018-12-05 13:02:31,255 - INFO - epoch 2, step 39830, training loss = 3.036606, validation loss = 2.088547
2018-12-05 13:02:35,437 - INFO - epoch 2, step 39840, training loss = 2.689359, validation loss = 2.113985
2018-12-05 13:02:39,398 - INFO - epoch 2, step 39850, training loss = 2.902367, validation loss = 2.526587
2018-12-05 13:02:43,561 - INFO - epoch 2, step 39860, training loss = 2.974363, validation loss = 2.411901
2018-12-05 13:02:47,633 - INFO - epoch 2, step 39870, training loss = 2.621426, validation loss = 2.234580
2018-12-05 13:02:52,724 - INFO - epoch 2, step 39880, training loss = 2.953536, validation loss = 2.920946
2018-12-05 13:02:57,686 - INFO - epoch 2, step 39890, training loss = 2.602600, validation loss = 2.808283
2018-12-05 13:03:03,025 - INFO - epoch 2, step 39900, training loss = 2.208537, validation loss = 2.131238
2018-12-05 13:03:08,062 - INFO - epoch 2, step 39910, training loss = 2.310297, validation loss = 2.092585
2018-12-05 13:03:13,787 - INFO - epoch 2, step 39920, training loss = 1.957971, validation loss = 1.862522
2018-12-05 13:03:19,462 - INFO - epoch 2, step 39930, training loss = 1.834514, validation loss = 1.669666
2018-12-05 13:03:24,832 - INFO - epoch 2, step 39940, training loss = 1.886026, validation loss = 2.383984
2018-12-05 13:03:30,473 - INFO - epoch 2, step 39950, training loss = 2.358436, validation loss = 2.111942
2018-12-05 13:03:36,127 - INFO - epoch 2, step 39960, training loss = 1.978385, validation loss = 1.942917
2018-12-05 13:03:41,714 - INFO - epoch 2, step 39970, training loss = 2.670269, validation loss = 2.366630
2018-12-05 13:03:46,402 - INFO - epoch 2, step 39980, training loss = 2.708608, validation loss = 2.213544
2018-12-05 13:03:50,534 - INFO - epoch 2, step 39990, training loss = 3.152699, validation loss = 2.397087
2018-12-05 13:03:54,473 - INFO - epoch 2, step 40000, training loss = 2.703346, validation loss = 2.414536
2018-12-05 13:03:58,279 - INFO - epoch 2, step 40010, training loss = 3.044052, validation loss = 1.886636
2018-12-05 13:04:02,397 - INFO - epoch 2, step 40020, training loss = 2.918287, validation loss = 2.070291
2018-12-05 13:04:06,739 - INFO - epoch 2, step 40030, training loss = 3.118454, validation loss = 1.958712
2018-12-05 13:04:10,961 - INFO - epoch 2, step 40040, training loss = 2.560814, validation loss = 2.115005
2018-12-05 13:04:15,193 - INFO - epoch 2, step 40050, training loss = 3.150535, validation loss = 2.849577
2018-12-05 13:04:19,414 - INFO - epoch 2, step 40060, training loss = 2.961363, validation loss = 2.339782
2018-12-05 13:04:23,435 - INFO - epoch 2, step 40070, training loss = 2.415376, validation loss = 2.463968
2018-12-05 13:04:27,642 - INFO - epoch 2, step 40080, training loss = 2.685759, validation loss = 2.523161
2018-12-05 13:04:31,949 - INFO - epoch 2, step 40090, training loss = 3.027926, validation loss = 1.888461
2018-12-05 13:04:36,244 - INFO - epoch 2, step 40100, training loss = 2.987414, validation loss = 1.861400
2018-12-05 13:04:39,971 - INFO - epoch 2, step 40110, training loss = 2.641152, validation loss = 2.240118
2018-12-05 13:04:43,792 - INFO - epoch 2, step 40120, training loss = 2.878234, validation loss = 2.223175
2018-12-05 13:04:47,779 - INFO - epoch 2, step 40130, training loss = 2.631253, validation loss = 1.986650
2018-12-05 13:04:51,846 - INFO - epoch 2, step 40140, training loss = 2.755216, validation loss = 2.143888
2018-12-05 13:04:55,721 - INFO - epoch 2, step 40150, training loss = 3.063010, validation loss = 2.465078
2018-12-05 13:04:59,748 - INFO - epoch 2, step 40160, training loss = 2.506302, validation loss = 2.089748
2018-12-05 13:05:03,612 - INFO - epoch 2, step 40170, training loss = 2.917969, validation loss = 2.106164
2018-12-05 13:05:07,928 - INFO - epoch 2, step 40180, training loss = 2.635190, validation loss = 1.855093
2018-12-05 13:05:11,978 - INFO - epoch 2, step 40190, training loss = 2.953795, validation loss = 2.606843
2018-12-05 13:05:15,697 - INFO - epoch 2, step 40200, training loss = 2.697975, validation loss = 2.078623
2018-12-05 13:05:19,622 - INFO - epoch 2, step 40210, training loss = 2.606908, validation loss = 2.428915
2018-12-05 13:05:23,446 - INFO - epoch 2, step 40220, training loss = 2.859776, validation loss = 2.231558
2018-12-05 13:05:27,516 - INFO - epoch 2, step 40230, training loss = 2.883241, validation loss = 1.844124
2018-12-05 13:05:31,716 - INFO - epoch 2, step 40240, training loss = 2.767535, validation loss = 2.112437
2018-12-05 13:05:35,927 - INFO - epoch 2, step 40250, training loss = 2.294872, validation loss = 2.466420
2018-12-05 13:05:40,163 - INFO - epoch 2, step 40260, training loss = 2.273627, validation loss = 2.429990
2018-12-05 13:05:44,397 - INFO - epoch 2, step 40270, training loss = 2.050985, validation loss = 2.404087
2018-12-05 13:05:48,601 - INFO - epoch 2, step 40280, training loss = 2.572019, validation loss = 1.913981
2018-12-05 13:05:53,188 - INFO - epoch 2, step 40290, training loss = 2.454795, validation loss = 2.195891
2018-12-05 13:05:57,411 - INFO - epoch 2, step 40300, training loss = 2.721079, validation loss = 2.287678
2018-12-05 13:06:01,776 - INFO - epoch 2, step 40310, training loss = 2.627704, validation loss = 2.413844
2018-12-05 13:06:05,609 - INFO - epoch 2, step 40320, training loss = 2.892075, validation loss = 2.372096
2018-12-05 13:06:09,438 - INFO - epoch 2, step 40330, training loss = 2.700518, validation loss = 2.444993
2018-12-05 13:06:13,781 - INFO - epoch 2, step 40340, training loss = 2.596284, validation loss = 2.493532
2018-12-05 13:06:17,707 - INFO - epoch 2, step 40350, training loss = 2.849946, validation loss = 2.068991
2018-12-05 13:06:21,827 - INFO - epoch 2, step 40360, training loss = 3.319668, validation loss = 2.526751
2018-12-05 13:06:25,866 - INFO - epoch 2, step 40370, training loss = 2.854605, validation loss = 2.716293
2018-12-05 13:06:30,118 - INFO - epoch 2, step 40380, training loss = 2.223077, validation loss = 2.560423
2018-12-05 13:06:33,966 - INFO - epoch 2, step 40390, training loss = 2.839800, validation loss = 2.613651
2018-12-05 13:06:37,711 - INFO - epoch 2, step 40400, training loss = 2.699283, validation loss = 2.257303
2018-12-05 13:06:41,744 - INFO - epoch 2, step 40410, training loss = 3.287687, validation loss = 2.423955
2018-12-05 13:06:45,957 - INFO - epoch 2, step 40420, training loss = 2.431818, validation loss = 1.902417
2018-12-05 13:06:51,384 - INFO - epoch 2, step 40430, training loss = 2.352004, validation loss = 2.111113
2018-12-05 13:06:56,791 - INFO - epoch 2, step 40440, training loss = 2.532897, validation loss = 2.194997
2018-12-05 13:07:02,310 - INFO - epoch 2, step 40450, training loss = 2.346989, validation loss = 2.366253
2018-12-05 13:07:06,564 - INFO - epoch 2, step 40460, training loss = 2.739974, validation loss = 2.351187
2018-12-05 13:07:10,462 - INFO - epoch 2, step 40470, training loss = 2.705646, validation loss = 2.458600
2018-12-05 13:07:14,346 - INFO - epoch 2, step 40480, training loss = 3.443320, validation loss = 2.283756
2018-12-05 13:07:18,246 - INFO - epoch 2, step 40490, training loss = 2.470190, validation loss = 2.164000
2018-12-05 13:07:22,067 - INFO - epoch 2, step 40500, training loss = 2.426957, validation loss = 2.445660
2018-12-05 13:07:26,219 - INFO - epoch 2, step 40510, training loss = 2.328195, validation loss = 1.743095
2018-12-05 13:07:30,189 - INFO - epoch 2, step 40520, training loss = 2.623065, validation loss = 2.464020
2018-12-05 13:07:34,070 - INFO - epoch 2, step 40530, training loss = 2.264161, validation loss = 2.481762
2018-12-05 13:07:37,779 - INFO - epoch 2, step 40540, training loss = 2.680250, validation loss = 2.625010
2018-12-05 13:07:41,858 - INFO - epoch 2, step 40550, training loss = 2.978898, validation loss = 2.138921
2018-12-05 13:07:45,870 - INFO - epoch 2, step 40560, training loss = 2.547322, validation loss = 2.437114
2018-12-05 13:07:50,261 - INFO - epoch 2, step 40570, training loss = 2.284555, validation loss = 2.437129
2018-12-05 13:07:55,592 - INFO - epoch 2, step 40580, training loss = 1.869882, validation loss = 2.959332
2018-12-05 13:08:00,932 - INFO - epoch 2, step 40590, training loss = 2.937958, validation loss = 1.633391
2018-12-05 13:08:06,127 - INFO - epoch 2, step 40600, training loss = 2.331022, validation loss = 2.390223
2018-12-05 13:08:11,160 - INFO - epoch 2, step 40610, training loss = 1.836134, validation loss = 2.143284
2018-12-05 13:08:16,626 - INFO - epoch 2, step 40620, training loss = 2.247665, validation loss = 1.929984
2018-12-05 13:08:21,712 - INFO - epoch 2, step 40630, training loss = 1.939596, validation loss = 2.550203
2018-12-05 13:08:26,856 - INFO - epoch 2, step 40640, training loss = 2.520035, validation loss = 2.332320
2018-12-05 13:08:32,319 - INFO - epoch 2, step 40650, training loss = 2.601042, validation loss = 2.542691
2018-12-05 13:08:37,801 - INFO - epoch 2, step 40660, training loss = 2.393404, validation loss = 2.801358
2018-12-05 13:08:43,377 - INFO - epoch 2, step 40670, training loss = 2.379710, validation loss = 2.187030
2018-12-05 13:08:48,619 - INFO - epoch 2, step 40680, training loss = 2.473606, validation loss = 2.150660
2018-12-05 13:08:54,340 - INFO - epoch 2, step 40690, training loss = 2.422084, validation loss = 2.443241
2018-12-05 13:08:58,715 - INFO - epoch 2, step 40700, training loss = 2.368293, validation loss = 2.272025
2018-12-05 13:09:03,105 - INFO - epoch 2, step 40710, training loss = 2.195055, validation loss = 2.406273
2018-12-05 13:09:07,405 - INFO - epoch 2, step 40720, training loss = 2.956152, validation loss = 2.210694
2018-12-05 13:09:11,684 - INFO - epoch 2, step 40730, training loss = 2.607479, validation loss = 2.654381
2018-12-05 13:09:16,083 - INFO - epoch 2, step 40740, training loss = 2.455108, validation loss = 2.767640
2018-12-05 13:09:20,369 - INFO - epoch 2, step 40750, training loss = 2.941847, validation loss = 2.025613
2018-12-05 13:09:24,775 - INFO - epoch 2, step 40760, training loss = 1.970802, validation loss = 2.218274
2018-12-05 13:09:29,048 - INFO - epoch 2, step 40770, training loss = 2.727431, validation loss = 2.205103
2018-12-05 13:09:33,106 - INFO - epoch 2, step 40780, training loss = 2.716058, validation loss = 2.165846
2018-12-05 13:09:37,292 - INFO - epoch 2, step 40790, training loss = 2.607771, validation loss = 2.461805
2018-12-05 13:09:41,095 - INFO - epoch 2, step 40800, training loss = 2.660923, validation loss = 2.605850
2018-12-05 13:09:45,449 - INFO - epoch 2, step 40810, training loss = 2.814903, validation loss = 2.274759
2018-12-05 13:09:49,700 - INFO - epoch 2, step 40820, training loss = 2.911859, validation loss = 2.203456
2018-12-05 13:09:54,153 - INFO - epoch 2, step 40830, training loss = 2.459737, validation loss = 2.551740
2018-12-05 13:09:58,280 - INFO - epoch 2, step 40840, training loss = 2.751895, validation loss = 2.448967
2018-12-05 13:10:02,576 - INFO - epoch 2, step 40850, training loss = 2.248658, validation loss = 2.088660
2018-12-05 13:10:06,464 - INFO - epoch 2, step 40860, training loss = 2.457196, validation loss = 2.756349
2018-12-05 13:10:10,550 - INFO - epoch 2, step 40870, training loss = 3.170295, validation loss = 2.676250
2018-12-05 13:10:14,504 - INFO - epoch 2, step 40880, training loss = 2.690066, validation loss = 2.483161
2018-12-05 13:10:18,658 - INFO - epoch 2, step 40890, training loss = 2.654922, validation loss = 2.079179
2018-12-05 13:10:22,760 - INFO - epoch 2, step 40900, training loss = 2.727431, validation loss = 2.364589
2018-12-05 13:10:26,774 - INFO - epoch 2, step 40910, training loss = 2.879579, validation loss = 2.022441
2018-12-05 13:10:30,726 - INFO - epoch 2, step 40920, training loss = 2.126476, validation loss = 2.730189
2018-12-05 13:10:34,657 - INFO - epoch 2, step 40930, training loss = 2.988467, validation loss = 2.597552
2018-12-05 13:10:38,595 - INFO - epoch 2, step 40940, training loss = 3.062067, validation loss = 2.465057
2018-12-05 13:10:42,636 - INFO - epoch 2, step 40950, training loss = 2.995880, validation loss = 2.641510
2018-12-05 13:10:46,890 - INFO - epoch 2, step 40960, training loss = 1.924200, validation loss = 2.408063
2018-12-05 13:10:50,688 - INFO - epoch 2, step 40970, training loss = 2.564949, validation loss = 2.384652
2018-12-05 13:10:54,699 - INFO - epoch 2, step 40980, training loss = 2.828343, validation loss = 2.959960
2018-12-05 13:10:58,983 - INFO - epoch 2, step 40990, training loss = 2.495349, validation loss = 2.967045
2018-12-05 13:11:03,302 - INFO - epoch 2, step 41000, training loss = 2.519722, validation loss = 2.542414
2018-12-05 13:11:07,723 - INFO - epoch 2, step 41010, training loss = 2.441929, validation loss = 2.593781
2018-12-05 13:11:12,177 - INFO - epoch 2, step 41020, training loss = 2.443602, validation loss = 2.199162
2018-12-05 13:11:16,327 - INFO - epoch 2, step 41030, training loss = 2.605768, validation loss = 2.515478
2018-12-05 13:11:20,450 - INFO - epoch 2, step 41040, training loss = 2.723349, validation loss = 2.352793
2018-12-05 13:11:24,889 - INFO - epoch 2, step 41050, training loss = 2.353575, validation loss = 2.109786
2018-12-05 13:11:28,925 - INFO - epoch 2, step 41060, training loss = 2.426569, validation loss = 2.323050
2018-12-05 13:11:33,165 - INFO - epoch 2, step 41070, training loss = 2.481410, validation loss = 2.662105
2018-12-05 13:11:37,244 - INFO - epoch 2, step 41080, training loss = 2.439045, validation loss = 2.114106
2018-12-05 13:11:41,569 - INFO - epoch 2, step 41090, training loss = 2.682420, validation loss = 2.664458
2018-12-05 13:11:45,460 - INFO - epoch 2, step 41100, training loss = 3.215174, validation loss = 1.876372
2018-12-05 13:11:49,637 - INFO - epoch 2, step 41110, training loss = 2.433491, validation loss = 2.304960
2018-12-05 13:11:53,547 - INFO - epoch 2, step 41120, training loss = 2.549445, validation loss = 2.399756
2018-12-05 13:11:57,690 - INFO - epoch 2, step 41130, training loss = 3.159546, validation loss = 2.510231
2018-12-05 13:12:01,758 - INFO - epoch 2, step 41140, training loss = 2.840192, validation loss = 2.202722
2018-12-05 13:12:05,697 - INFO - epoch 2, step 41150, training loss = 2.635427, validation loss = 2.141542
2018-12-05 13:12:09,852 - INFO - epoch 2, step 41160, training loss = 2.771515, validation loss = 2.434002
2018-12-05 13:12:14,072 - INFO - epoch 2, step 41170, training loss = 2.511928, validation loss = 2.371838
2018-12-05 13:12:17,950 - INFO - epoch 2, step 41180, training loss = 2.165102, validation loss = 2.416713
2018-12-05 13:12:22,034 - INFO - epoch 2, step 41190, training loss = 2.514210, validation loss = 2.101896
2018-12-05 13:12:25,956 - INFO - epoch 2, step 41200, training loss = 2.722039, validation loss = 2.271013
2018-12-05 13:12:30,455 - INFO - epoch 2, step 41210, training loss = 2.723204, validation loss = 2.442859
2018-12-05 13:12:34,524 - INFO - epoch 2, step 41220, training loss = 2.852815, validation loss = 2.609526
2018-12-05 13:12:38,619 - INFO - epoch 2, step 41230, training loss = 2.538393, validation loss = 2.028035
2018-12-05 13:12:42,593 - INFO - epoch 2, step 41240, training loss = 2.364770, validation loss = 2.435481
2018-12-05 13:12:46,795 - INFO - epoch 2, step 41250, training loss = 2.780696, validation loss = 2.026744
2018-12-05 13:12:50,824 - INFO - epoch 2, step 41260, training loss = 2.450315, validation loss = 2.669398
2018-12-05 13:12:54,966 - INFO - epoch 2, step 41270, training loss = 2.604320, validation loss = 2.291144
2018-12-05 13:12:58,612 - INFO - epoch 2, step 41280, training loss = 3.165623, validation loss = 2.723550
2018-12-05 13:13:02,529 - INFO - epoch 2, step 41290, training loss = 3.286288, validation loss = 2.382292
2018-12-05 13:13:06,690 - INFO - epoch 2, step 41300, training loss = 2.591445, validation loss = 2.618494
2018-12-05 13:13:10,713 - INFO - epoch 2, step 41310, training loss = 2.879170, validation loss = 2.349859
2018-12-05 13:13:14,730 - INFO - epoch 2, step 41320, training loss = 2.529028, validation loss = 2.068980
2018-12-05 13:13:18,703 - INFO - epoch 2, step 41330, training loss = 2.642688, validation loss = 2.287899
2018-12-05 13:13:22,773 - INFO - epoch 2, step 41340, training loss = 3.099509, validation loss = 1.968690
2018-12-05 13:13:26,800 - INFO - epoch 2, step 41350, training loss = 2.461673, validation loss = 2.348092
2018-12-05 13:13:30,738 - INFO - epoch 2, step 41360, training loss = 2.708697, validation loss = 2.458211
2018-12-05 13:13:34,729 - INFO - epoch 2, step 41370, training loss = 2.523148, validation loss = 2.213636
2018-12-05 13:13:40,343 - INFO - epoch 2, step 41380, training loss = 2.251454, validation loss = 1.987724
2018-12-05 13:13:45,686 - INFO - epoch 2, step 41390, training loss = 2.718636, validation loss = 2.382031
2018-12-05 13:13:50,944 - INFO - epoch 2, step 41400, training loss = 2.474960, validation loss = 2.283905
2018-12-05 13:13:56,310 - INFO - epoch 2, step 41410, training loss = 2.658842, validation loss = 2.249740
2018-12-05 13:14:02,110 - INFO - epoch 2, step 41420, training loss = 1.954748, validation loss = 2.577863
2018-12-05 13:14:08,182 - INFO - epoch 2, step 41430, training loss = 1.971133, validation loss = 2.194420
2018-12-05 13:14:13,308 - INFO - epoch 2, step 41440, training loss = 2.184864, validation loss = 2.286168
2018-12-05 13:14:18,906 - INFO - epoch 2, step 41450, training loss = 2.580723, validation loss = 2.918415
2018-12-05 13:14:24,545 - INFO - epoch 2, step 41460, training loss = 2.151514, validation loss = 2.574488
2018-12-05 13:14:30,122 - INFO - epoch 2, step 41470, training loss = 2.527070, validation loss = 2.144249
2018-12-05 13:14:35,708 - INFO - epoch 2, step 41480, training loss = 2.311922, validation loss = 2.019195
2018-12-05 13:14:40,445 - INFO - epoch 2, step 41490, training loss = 2.805126, validation loss = 2.638746
2018-12-05 13:14:44,671 - INFO - epoch 2, step 41500, training loss = 2.646196, validation loss = 2.752457
2018-12-05 13:14:49,058 - INFO - epoch 2, step 41510, training loss = 2.544533, validation loss = 2.062047
2018-12-05 13:14:53,157 - INFO - epoch 2, step 41520, training loss = 2.802756, validation loss = 1.898563
2018-12-05 13:14:57,462 - INFO - epoch 2, step 41530, training loss = 2.758466, validation loss = 2.295596
2018-12-05 13:15:01,777 - INFO - epoch 2, step 41540, training loss = 2.937037, validation loss = 2.416188
2018-12-05 13:15:05,780 - INFO - epoch 2, step 41550, training loss = 3.031916, validation loss = 2.383156
2018-12-05 13:15:10,329 - INFO - epoch 2, step 41560, training loss = 2.638661, validation loss = 2.124398
2018-12-05 13:15:16,385 - INFO - epoch 2, step 41570, training loss = 2.383275, validation loss = 1.736014
2018-12-05 13:15:21,794 - INFO - epoch 2, step 41580, training loss = 2.273467, validation loss = 1.923005
2018-12-05 13:15:27,213 - INFO - epoch 2, step 41590, training loss = 1.561960, validation loss = 2.375636
2018-12-05 13:15:32,501 - INFO - epoch 2, step 41600, training loss = 2.277095, validation loss = 1.889165
2018-12-05 13:15:37,719 - INFO - epoch 2, step 41610, training loss = 1.604560, validation loss = 2.698057
2018-12-05 13:15:43,020 - INFO - epoch 2, step 41620, training loss = 2.341603, validation loss = 2.421415
2018-12-05 13:15:48,955 - INFO - epoch 2, step 41630, training loss = 1.754232, validation loss = 2.366797
2018-12-05 13:15:54,066 - INFO - epoch 2, step 41640, training loss = 2.485382, validation loss = 2.332647
2018-12-05 13:15:58,382 - INFO - epoch 2, step 41650, training loss = 2.463250, validation loss = 2.619035
2018-12-05 13:16:02,511 - INFO - epoch 2, step 41660, training loss = 2.678817, validation loss = 2.557194
2018-12-05 13:16:06,688 - INFO - epoch 2, step 41670, training loss = 2.799741, validation loss = 2.245721
2018-12-05 13:16:10,969 - INFO - epoch 2, step 41680, training loss = 2.382278, validation loss = 2.236072
2018-12-05 13:16:15,224 - INFO - epoch 2, step 41690, training loss = 2.833474, validation loss = 2.467930
2018-12-05 13:16:19,525 - INFO - epoch 2, step 41700, training loss = 2.167403, validation loss = 2.533738
2018-12-05 13:16:23,844 - INFO - epoch 2, step 41710, training loss = 2.762169, validation loss = 2.277772
2018-12-05 13:16:28,031 - INFO - epoch 2, step 41720, training loss = 2.520448, validation loss = 2.020289
2018-12-05 13:16:32,688 - INFO - epoch 2, step 41730, training loss = 2.284129, validation loss = 2.191687
2018-12-05 13:16:38,238 - INFO - epoch 2, step 41740, training loss = 1.853862, validation loss = 2.344502
2018-12-05 13:16:43,306 - INFO - epoch 2, step 41750, training loss = 2.117573, validation loss = 2.940917
2018-12-05 13:16:48,590 - INFO - epoch 2, step 41760, training loss = 2.392984, validation loss = 2.721836
2018-12-05 13:16:52,605 - INFO - epoch 2, step 41770, training loss = 2.693374, validation loss = 2.994998
2018-12-05 13:16:56,721 - INFO - epoch 2, step 41780, training loss = 2.958064, validation loss = 2.429414
2018-12-05 13:17:00,790 - INFO - epoch 2, step 41790, training loss = 2.826210, validation loss = 2.802969
2018-12-05 13:17:04,764 - INFO - epoch 2, step 41800, training loss = 2.995429, validation loss = 2.495151
2018-12-05 13:17:08,771 - INFO - epoch 2, step 41810, training loss = 2.760618, validation loss = 3.047190
2018-12-05 13:17:12,674 - INFO - epoch 2, step 41820, training loss = 2.491328, validation loss = 2.605206
2018-12-05 13:17:16,825 - INFO - epoch 2, step 41830, training loss = 2.794678, validation loss = 2.380774
2018-12-05 13:17:20,852 - INFO - epoch 2, step 41840, training loss = 2.572370, validation loss = 2.646609
2018-12-05 13:17:25,129 - INFO - epoch 2, step 41850, training loss = 2.724768, validation loss = 2.942461
2018-12-05 13:17:29,102 - INFO - epoch 2, step 41860, training loss = 2.888769, validation loss = 2.358412
2018-12-05 13:17:33,154 - INFO - epoch 2, step 41870, training loss = 2.862385, validation loss = 2.276517
2018-12-05 13:17:37,162 - INFO - epoch 2, step 41880, training loss = 2.639689, validation loss = 2.701912
2018-12-05 13:17:41,082 - INFO - epoch 2, step 41890, training loss = 2.935406, validation loss = 2.338861
2018-12-05 13:17:45,836 - INFO - epoch 2, step 41900, training loss = 2.130219, validation loss = 2.562795
2018-12-05 13:17:51,512 - INFO - epoch 2, step 41910, training loss = 2.066868, validation loss = 2.775451
2018-12-05 13:17:56,669 - INFO - epoch 2, step 41920, training loss = 2.482947, validation loss = 2.985184
2018-12-05 13:18:01,799 - INFO - epoch 2, step 41930, training loss = 2.356848, validation loss = 2.785722
2018-12-05 13:18:06,918 - INFO - epoch 2, step 41940, training loss = 2.531705, validation loss = 2.655064
2018-12-05 13:18:12,233 - INFO - epoch 2, step 41950, training loss = 2.097155, validation loss = 2.493539
2018-12-05 13:18:17,598 - INFO - epoch 2, step 41960, training loss = 1.990532, validation loss = 2.273973
2018-12-05 13:18:23,118 - INFO - epoch 2, step 41970, training loss = 2.672222, validation loss = 3.068502
2018-12-05 13:18:28,626 - INFO - epoch 2, step 41980, training loss = 2.190656, validation loss = 2.530463
2018-12-05 13:18:34,344 - INFO - epoch 2, step 41990, training loss = 1.767582, validation loss = 2.633455
2018-12-05 13:18:38,230 - INFO - epoch 2, step 42000, training loss = 2.417894, validation loss = 2.972304
2018-12-05 13:18:42,209 - INFO - epoch 2, step 42010, training loss = 2.764972, validation loss = 2.455994
2018-12-05 13:18:46,189 - INFO - epoch 2, step 42020, training loss = 2.772628, validation loss = 2.288970
2018-12-05 13:18:50,441 - INFO - epoch 2, step 42030, training loss = 2.523198, validation loss = 2.088861
2018-12-05 13:18:54,349 - INFO - epoch 2, step 42040, training loss = 2.846455, validation loss = 2.790098
2018-12-05 13:18:58,385 - INFO - epoch 2, step 42050, training loss = 2.993748, validation loss = 2.684803
2018-12-05 13:19:02,584 - INFO - epoch 2, step 42060, training loss = 2.890529, validation loss = 3.049202
2018-12-05 13:19:06,832 - INFO - epoch 2, step 42070, training loss = 2.575652, validation loss = 3.176942
2018-12-05 13:19:10,929 - INFO - epoch 2, step 42080, training loss = 3.064368, validation loss = 2.696536
2018-12-05 13:19:14,935 - INFO - epoch 2, step 42090, training loss = 2.594640, validation loss = 2.821773
2018-12-05 13:19:19,036 - INFO - epoch 2, step 42100, training loss = 2.664062, validation loss = 2.358684
2018-12-05 13:19:23,153 - INFO - epoch 2, step 42110, training loss = 2.895638, validation loss = 2.663897
2018-12-05 13:19:27,513 - INFO - epoch 2, step 42120, training loss = 2.958256, validation loss = 2.189059
2018-12-05 13:19:31,887 - INFO - epoch 2, step 42130, training loss = 2.435750, validation loss = 2.398684
2018-12-05 13:19:37,182 - INFO - epoch 2, step 42140, training loss = 2.261907, validation loss = 2.595285
2018-12-05 13:19:42,928 - INFO - epoch 2, step 42150, training loss = 2.101192, validation loss = 2.852668
2018-12-05 13:19:48,366 - INFO - epoch 2, step 42160, training loss = 2.929053, validation loss = 2.868129
2018-12-05 13:19:54,207 - INFO - epoch 2, step 42170, training loss = 2.132283, validation loss = 2.636768
2018-12-05 13:19:59,971 - INFO - epoch 2, step 42180, training loss = 1.898573, validation loss = 2.380548
2018-12-05 13:20:04,752 - INFO - epoch 2, step 42190, training loss = 2.871289, validation loss = 3.240169
2018-12-05 13:20:09,047 - INFO - epoch 2, step 42200, training loss = 3.055363, validation loss = 2.728253
2018-12-05 13:20:13,206 - INFO - epoch 2, step 42210, training loss = 2.918481, validation loss = 2.729074
2018-12-05 13:20:17,133 - INFO - epoch 2, step 42220, training loss = 2.826209, validation loss = 2.654756
2018-12-05 13:20:21,196 - INFO - epoch 2, step 42230, training loss = 2.773843, validation loss = 2.507205
2018-12-05 13:20:25,337 - INFO - epoch 2, step 42240, training loss = 2.760617, validation loss = 2.491320
2018-12-05 13:20:29,517 - INFO - epoch 2, step 42250, training loss = 3.173584, validation loss = 2.429882
2018-12-05 13:20:33,779 - INFO - epoch 2, step 42260, training loss = 2.109277, validation loss = 2.542488
2018-12-05 13:20:37,608 - INFO - epoch 2, step 42270, training loss = 2.713323, validation loss = 2.869840
2018-12-05 13:20:41,699 - INFO - epoch 2, step 42280, training loss = 2.994395, validation loss = 2.251163
2018-12-05 13:20:45,579 - INFO - epoch 2, step 42290, training loss = 3.095580, validation loss = 2.160424
2018-12-05 13:20:49,373 - INFO - epoch 2, step 42300, training loss = 2.357385, validation loss = 2.263231
2018-12-05 13:20:53,391 - INFO - epoch 2, step 42310, training loss = 2.585591, validation loss = 3.069700
2018-12-05 13:20:57,164 - INFO - epoch 2, step 42320, training loss = 2.570781, validation loss = 3.400324
2018-12-05 13:21:01,381 - INFO - epoch 2, step 42330, training loss = 2.438385, validation loss = 2.828909
2018-12-05 13:21:05,450 - INFO - epoch 2, step 42340, training loss = 3.232384, validation loss = 2.626058
2018-12-05 13:21:09,610 - INFO - epoch 2, step 42350, training loss = 2.469214, validation loss = 2.984617
2018-12-05 13:21:14,148 - INFO - epoch 2, step 42360, training loss = 1.860097, validation loss = 2.560435
2018-12-05 13:21:18,295 - INFO - epoch 2, step 42370, training loss = 2.488837, validation loss = 2.624378
2018-12-05 13:21:22,589 - INFO - epoch 2, step 42380, training loss = 2.784283, validation loss = 2.650389
2018-12-05 13:21:26,515 - INFO - epoch 2, step 42390, training loss = 2.340874, validation loss = 2.833454
2018-12-05 13:21:30,771 - INFO - epoch 2, step 42400, training loss = 2.330443, validation loss = 2.670859
2018-12-05 13:21:35,124 - INFO - epoch 2, step 42410, training loss = 2.225432, validation loss = 2.681554
2018-12-05 13:21:39,977 - INFO - epoch 2, step 42420, training loss = 2.641545, validation loss = 2.489301
2018-12-05 13:21:45,336 - INFO - epoch 2, step 42430, training loss = 1.945454, validation loss = 2.637915
2018-12-05 13:21:50,516 - INFO - epoch 2, step 42440, training loss = 2.215092, validation loss = 3.124871
2018-12-05 13:21:56,451 - INFO - epoch 2, step 42450, training loss = 2.054757, validation loss = 2.742654
2018-12-05 13:22:02,111 - INFO - epoch 2, step 42460, training loss = 1.755441, validation loss = 2.641319
2018-12-05 13:22:07,799 - INFO - epoch 2, step 42470, training loss = 2.162770, validation loss = 2.720819
2018-12-05 13:22:13,034 - INFO - epoch 2, step 42480, training loss = 2.658006, validation loss = 2.937406
2018-12-05 13:22:18,104 - INFO - epoch 2, step 42490, training loss = 2.350292, validation loss = 2.891236
2018-12-05 13:22:23,301 - INFO - epoch 2, step 42500, training loss = 2.523827, validation loss = 2.739981
2018-12-05 13:22:28,423 - INFO - epoch 2, step 42510, training loss = 2.278449, validation loss = 2.864145
2018-12-05 13:22:33,613 - INFO - epoch 2, step 42520, training loss = 2.100900, validation loss = 2.889382
2018-12-05 13:22:38,889 - INFO - epoch 2, step 42530, training loss = 2.010016, validation loss = 2.527271
2018-12-05 13:22:44,901 - INFO - epoch 2, step 42540, training loss = 1.578733, validation loss = 2.710327
2018-12-05 13:22:48,784 - INFO - epoch 2, step 42550, training loss = 3.158431, validation loss = 2.756661
2018-12-05 13:22:52,887 - INFO - epoch 2, step 42560, training loss = 2.734469, validation loss = 2.951796
2018-12-05 13:22:56,774 - INFO - epoch 2, step 42570, training loss = 2.715854, validation loss = 2.820081
2018-12-05 13:23:00,810 - INFO - epoch 2, step 42580, training loss = 2.979215, validation loss = 2.076189
2018-12-05 13:23:04,712 - INFO - epoch 2, step 42590, training loss = 2.449135, validation loss = 2.513449
2018-12-05 13:23:08,930 - INFO - epoch 2, step 42600, training loss = 2.637983, validation loss = 2.836712
2018-12-05 13:23:12,991 - INFO - epoch 2, step 42610, training loss = 2.653610, validation loss = 2.120512
2018-12-05 13:23:17,102 - INFO - epoch 2, step 42620, training loss = 2.579870, validation loss = 2.770926
2018-12-05 13:23:21,019 - INFO - epoch 2, step 42630, training loss = 2.428941, validation loss = 2.347684
2018-12-05 13:23:25,168 - INFO - epoch 2, step 42640, training loss = 3.385116, validation loss = 3.001541
2018-12-05 13:23:29,290 - INFO - epoch 2, step 42650, training loss = 2.960906, validation loss = 2.520524
2018-12-05 13:23:33,550 - INFO - epoch 2, step 42660, training loss = 2.339867, validation loss = 2.745688
2018-12-05 13:23:37,635 - INFO - epoch 2, step 42670, training loss = 2.992581, validation loss = 2.572451
2018-12-05 13:23:41,781 - INFO - epoch 2, step 42680, training loss = 2.615531, validation loss = 2.785792
2018-12-05 13:23:46,174 - INFO - epoch 2, step 42690, training loss = 2.461212, validation loss = 2.749717
2018-12-05 13:23:50,414 - INFO - epoch 2, step 42700, training loss = 2.332189, validation loss = 3.416271
2018-12-05 13:23:54,496 - INFO - epoch 2, step 42710, training loss = 2.499060, validation loss = 3.087532
2018-12-05 13:23:58,878 - INFO - epoch 2, step 42720, training loss = 2.407664, validation loss = 2.761426
2018-12-05 13:24:03,125 - INFO - epoch 2, step 42730, training loss = 2.890483, validation loss = 2.540181
2018-12-05 13:24:07,559 - INFO - epoch 2, step 42740, training loss = 2.332945, validation loss = 2.753808
2018-12-05 13:24:11,999 - INFO - epoch 2, step 42750, training loss = 2.070077, validation loss = 2.719788
2018-12-05 13:24:18,283 - INFO - epoch 2, step 42760, training loss = 1.986241, validation loss = 2.881238
2018-12-05 13:24:24,549 - INFO - epoch 2, step 42770, training loss = 2.956819, validation loss = 2.862261
2018-12-05 13:24:30,148 - INFO - epoch 2, step 42780, training loss = 2.670044, validation loss = 2.224595
2018-12-05 13:24:35,481 - INFO - epoch 2, step 42790, training loss = 2.401324, validation loss = 2.163946
2018-12-05 13:24:41,329 - INFO - epoch 2, step 42800, training loss = 2.499531, validation loss = 2.588906
2018-12-05 13:24:47,217 - INFO - epoch 2, step 42810, training loss = 2.214725, validation loss = 2.613420
2018-12-05 13:24:52,834 - INFO - epoch 2, step 42820, training loss = 2.179284, validation loss = 2.689022
2018-12-05 13:24:58,363 - INFO - epoch 2, step 42830, training loss = 2.474509, validation loss = 2.356302
2018-12-05 13:25:02,572 - INFO - epoch 2, step 42840, training loss = 3.037515, validation loss = 2.704849
2018-12-05 13:25:06,199 - INFO - epoch 2, step 42850, training loss = 2.963483, validation loss = 2.810967
2018-12-05 13:25:10,087 - INFO - epoch 2, step 42860, training loss = 2.887311, validation loss = 1.993520
2018-12-05 13:25:13,837 - INFO - epoch 2, step 42870, training loss = 2.397093, validation loss = 2.773745
2018-12-05 13:25:17,635 - INFO - epoch 2, step 42880, training loss = 2.417041, validation loss = 3.081378
2018-12-05 13:25:21,368 - INFO - epoch 2, step 42890, training loss = 3.436566, validation loss = 2.832675
2018-12-05 13:25:25,298 - INFO - epoch 2, step 42900, training loss = 2.969759, validation loss = 2.166118
2018-12-05 13:25:29,367 - INFO - epoch 2, step 42910, training loss = 3.251068, validation loss = 2.430233
2018-12-05 13:25:33,326 - INFO - epoch 2, step 42920, training loss = 2.790716, validation loss = 2.725804
2018-12-05 13:25:37,178 - INFO - epoch 2, step 42930, training loss = 2.583596, validation loss = 3.248583
2018-12-05 13:25:41,060 - INFO - epoch 2, step 42940, training loss = 2.765044, validation loss = 2.632809
2018-12-05 13:25:44,857 - INFO - epoch 2, step 42950, training loss = 2.990982, validation loss = 2.825521
2018-12-05 13:25:48,859 - INFO - epoch 2, step 42960, training loss = 2.551707, validation loss = 2.394629
2018-12-05 13:25:52,747 - INFO - epoch 2, step 42970, training loss = 2.817213, validation loss = 2.273933
2018-12-05 13:25:56,755 - INFO - epoch 2, step 42980, training loss = 2.454897, validation loss = 2.702255
2018-12-05 13:26:00,606 - INFO - epoch 2, step 42990, training loss = 2.676923, validation loss = 2.689917
2018-12-05 13:26:05,758 - INFO - epoch 2, step 43000, training loss = 2.531431, validation loss = 3.122281
2018-12-05 13:26:11,042 - INFO - epoch 2, step 43010, training loss = 2.269982, validation loss = 1.963982
2018-12-05 13:26:16,358 - INFO - epoch 2, step 43020, training loss = 2.355206, validation loss = 3.062754
2018-12-05 13:26:21,268 - INFO - epoch 2, step 43030, training loss = 2.562151, validation loss = 2.720294
2018-12-05 13:26:25,910 - INFO - epoch 2, step 43040, training loss = 2.112356, validation loss = 2.841412
2018-12-05 13:26:30,823 - INFO - epoch 2, step 43050, training loss = 2.524521, validation loss = 2.442560
2018-12-05 13:26:36,552 - INFO - epoch 2, step 43060, training loss = 1.799649, validation loss = 2.084641
2018-12-05 13:26:42,089 - INFO - epoch 2, step 43070, training loss = 2.846790, validation loss = 2.489227
2018-12-05 13:26:47,738 - INFO - epoch 2, step 43080, training loss = 1.523320, validation loss = 2.429282
2018-12-05 13:26:51,916 - INFO - epoch 2, step 43090, training loss = 2.475898, validation loss = 2.391944
2018-12-05 13:26:56,160 - INFO - epoch 2, step 43100, training loss = 2.740809, validation loss = 2.068089
2018-12-05 13:27:00,052 - INFO - epoch 2, step 43110, training loss = 2.702969, validation loss = 2.704726
2018-12-05 13:27:04,530 - INFO - epoch 2, step 43120, training loss = 2.843834, validation loss = 2.224756
2018-12-05 13:27:09,032 - INFO - epoch 2, step 43130, training loss = 2.293016, validation loss = 1.692589
2018-12-05 13:27:12,983 - INFO - epoch 2, step 43140, training loss = 2.933186, validation loss = 2.088218
2018-12-05 13:27:17,020 - INFO - epoch 2, step 43150, training loss = 2.837017, validation loss = 1.771255
2018-12-05 13:27:21,041 - INFO - epoch 2, step 43160, training loss = 2.632349, validation loss = 2.328781
2018-12-05 13:27:25,483 - INFO - epoch 2, step 43170, training loss = 2.435277, validation loss = 2.504799
2018-12-05 13:27:29,716 - INFO - epoch 2, step 43180, training loss = 2.608748, validation loss = 2.479527
2018-12-05 13:27:33,960 - INFO - epoch 2, step 43190, training loss = 2.611471, validation loss = 2.102027
2018-12-05 13:27:38,260 - INFO - epoch 2, step 43200, training loss = 2.506064, validation loss = 1.904015
2018-12-05 13:27:42,408 - INFO - epoch 2, step 43210, training loss = 2.937645, validation loss = 2.152723
2018-12-05 13:27:46,547 - INFO - epoch 2, step 43220, training loss = 2.469254, validation loss = 2.126244
2018-12-05 13:27:50,382 - INFO - epoch 2, step 43230, training loss = 2.336164, validation loss = 2.301473
2018-12-05 13:27:54,228 - INFO - epoch 2, step 43240, training loss = 2.521534, validation loss = 2.795015
2018-12-05 13:27:58,587 - INFO - epoch 2, step 43250, training loss = 2.890873, validation loss = 2.985402
2018-12-05 13:28:03,622 - INFO - epoch 2, step 43260, training loss = 2.439369, validation loss = 2.981972
2018-12-05 13:28:09,374 - INFO - epoch 2, step 43270, training loss = 2.454212, validation loss = 2.260630
2018-12-05 13:28:15,055 - INFO - epoch 2, step 43280, training loss = 2.841487, validation loss = 2.789205
2018-12-05 13:28:20,665 - INFO - epoch 2, step 43290, training loss = 2.323382, validation loss = 2.477073
2018-12-05 13:28:26,485 - INFO - epoch 2, step 43300, training loss = 2.718277, validation loss = 2.099546
2018-12-05 13:28:31,836 - INFO - epoch 2, step 43310, training loss = 2.948271, validation loss = 2.471489
2018-12-05 13:28:35,793 - INFO - epoch 2, step 43320, training loss = 3.138047, validation loss = 2.221887
2018-12-05 13:28:40,113 - INFO - epoch 2, step 43330, training loss = 2.731899, validation loss = 2.661300
2018-12-05 13:28:44,378 - INFO - epoch 2, step 43340, training loss = 3.035616, validation loss = 2.569079
2018-12-05 13:28:48,653 - INFO - epoch 2, step 43350, training loss = 2.931679, validation loss = 2.704502
2018-12-05 13:28:52,863 - INFO - epoch 2, step 43360, training loss = 2.578434, validation loss = 2.600920
2018-12-05 13:28:56,938 - INFO - epoch 2, step 43370, training loss = 2.612829, validation loss = 2.094719
2018-12-05 13:29:01,455 - INFO - epoch 2, step 43380, training loss = 2.698508, validation loss = 2.289217
2018-12-05 13:29:06,129 - INFO - epoch 2, step 43390, training loss = 1.598628, validation loss = 2.189711
2018-12-05 13:29:10,025 - INFO - epoch 2, step 43400, training loss = 2.488100, validation loss = 2.267582
2018-12-05 13:29:14,243 - INFO - epoch 2, step 43410, training loss = 2.831215, validation loss = 2.280182
2018-12-05 13:29:18,687 - INFO - epoch 2, step 43420, training loss = 2.765080, validation loss = 2.316895
2018-12-05 13:29:22,912 - INFO - epoch 2, step 43430, training loss = 3.117844, validation loss = 2.291780
2018-12-05 13:29:27,411 - INFO - epoch 2, step 43440, training loss = 2.170407, validation loss = 2.190562
2018-12-05 13:29:31,659 - INFO - epoch 2, step 43450, training loss = 2.891612, validation loss = 2.246677
2018-12-05 13:29:35,827 - INFO - epoch 2, step 43460, training loss = 2.538862, validation loss = 2.033878
2018-12-05 13:29:40,039 - INFO - epoch 2, step 43470, training loss = 2.747058, validation loss = 2.569837
2018-12-05 13:29:44,106 - INFO - epoch 2, step 43480, training loss = 2.574388, validation loss = 2.391534
2018-12-05 13:29:48,447 - INFO - epoch 2, step 43490, training loss = 2.591961, validation loss = 2.681309
2018-12-05 13:29:52,746 - INFO - epoch 2, step 43500, training loss = 2.590757, validation loss = 2.183270
2018-12-05 13:29:57,144 - INFO - epoch 2, step 43510, training loss = 2.548326, validation loss = 2.030813
2018-12-05 13:30:01,334 - INFO - epoch 2, step 43520, training loss = 2.321301, validation loss = 1.990123
2018-12-05 13:30:06,289 - INFO - epoch 2, step 43530, training loss = 1.956354, validation loss = 2.667494
2018-12-05 13:30:11,818 - INFO - epoch 2, step 43540, training loss = 2.153366, validation loss = 2.565525
2018-12-05 13:30:16,856 - INFO - epoch 2, step 43550, training loss = 2.036356, validation loss = 2.230817
2018-12-05 13:30:22,101 - INFO - epoch 2, step 43560, training loss = 2.095462, validation loss = 2.554551
2018-12-05 13:30:26,251 - INFO - epoch 2, step 43570, training loss = 2.705297, validation loss = 2.621820
2018-12-05 13:30:30,420 - INFO - epoch 2, step 43580, training loss = 2.745474, validation loss = 2.798077
2018-12-05 13:30:34,515 - INFO - epoch 2, step 43590, training loss = 2.751234, validation loss = 2.461773
2018-12-05 13:30:38,650 - INFO - epoch 2, step 43600, training loss = 2.706834, validation loss = 2.841028
2018-12-05 13:30:42,693 - INFO - epoch 2, step 43610, training loss = 2.505552, validation loss = 2.520702
2018-12-05 13:30:46,814 - INFO - epoch 2, step 43620, training loss = 2.912393, validation loss = 2.264490
2018-12-05 13:30:50,918 - INFO - epoch 2, step 43630, training loss = 2.669751, validation loss = 2.316547
2018-12-05 13:30:55,611 - INFO - epoch 2, step 43640, training loss = 2.037346, validation loss = 1.917978
2018-12-05 13:31:00,905 - INFO - epoch 2, step 43650, training loss = 2.097275, validation loss = 2.775257
2018-12-05 13:31:06,438 - INFO - epoch 2, step 43660, training loss = 2.412425, validation loss = 2.921532
2018-12-05 13:31:11,855 - INFO - epoch 2, step 43670, training loss = 2.016267, validation loss = 2.594045
2018-12-05 13:31:16,243 - INFO - epoch 2, step 43680, training loss = 2.874932, validation loss = 2.528533
2018-12-05 13:31:20,320 - INFO - epoch 2, step 43690, training loss = 2.655613, validation loss = 2.479679
2018-12-05 13:31:24,416 - INFO - epoch 2, step 43700, training loss = 2.292616, validation loss = 2.493524
2018-12-05 13:31:28,502 - INFO - epoch 2, step 43710, training loss = 2.453174, validation loss = 2.108085
2018-12-05 13:31:32,481 - INFO - epoch 2, step 43720, training loss = 2.739138, validation loss = 2.446538
2018-12-05 13:31:36,562 - INFO - epoch 2, step 43730, training loss = 2.356273, validation loss = 2.475299
2018-12-05 13:31:40,341 - INFO - epoch 2, step 43740, training loss = 2.794497, validation loss = 2.719793
2018-12-05 13:31:44,555 - INFO - epoch 2, step 43750, training loss = 2.810391, validation loss = 2.708385
2018-12-05 13:31:48,907 - INFO - epoch 2, step 43760, training loss = 2.802362, validation loss = 2.228680
2018-12-05 13:31:52,924 - INFO - epoch 2, step 43770, training loss = 2.451385, validation loss = 2.514216
2018-12-05 13:31:56,918 - INFO - epoch 2, step 43780, training loss = 3.222893, validation loss = 2.634788
2018-12-05 13:32:03,007 - INFO - epoch 2, step 43790, training loss = 1.925985, validation loss = 2.106604
2018-12-05 13:32:08,688 - INFO - epoch 2, step 43800, training loss = 1.883251, validation loss = 2.412290
2018-12-05 13:32:14,241 - INFO - epoch 2, step 43810, training loss = 1.912515, validation loss = 2.693461
2018-12-05 13:32:18,902 - INFO - epoch 2, step 43820, training loss = 3.203781, validation loss = 2.224266
2018-12-05 13:32:22,814 - INFO - epoch 2, step 43830, training loss = 2.833601, validation loss = 2.541774
2018-12-05 13:32:26,706 - INFO - epoch 2, step 43840, training loss = 2.531781, validation loss = 2.590023
2018-12-05 13:32:30,864 - INFO - epoch 2, step 43850, training loss = 2.695688, validation loss = 2.285149
2018-12-05 13:32:34,605 - INFO - epoch 2, step 43860, training loss = 2.832971, validation loss = 2.571757
2018-12-05 13:32:38,843 - INFO - epoch 2, step 43870, training loss = 2.702404, validation loss = 2.339082
2018-12-05 13:32:43,144 - INFO - epoch 2, step 43880, training loss = 3.107544, validation loss = 2.103566
2018-12-05 13:32:47,536 - INFO - epoch 2, step 43890, training loss = 2.664844, validation loss = 2.722664
2018-12-05 13:32:51,712 - INFO - epoch 2, step 43900, training loss = 2.933221, validation loss = 2.701607
2018-12-05 13:32:55,788 - INFO - epoch 2, step 43910, training loss = 2.968723, validation loss = 2.027045
2018-12-05 13:32:59,955 - INFO - epoch 2, step 43920, training loss = 2.820747, validation loss = 2.531401
2018-12-05 13:33:04,020 - INFO - epoch 2, step 43930, training loss = 3.076328, validation loss = 2.515727
2018-12-05 13:33:08,340 - INFO - epoch 2, step 43940, training loss = 2.810600, validation loss = 2.547767
2018-12-05 13:33:12,520 - INFO - epoch 2, step 43950, training loss = 2.588657, validation loss = 2.866123
2018-12-05 13:33:16,737 - INFO - epoch 2, step 43960, training loss = 2.616011, validation loss = 2.199558
2018-12-05 13:33:21,360 - INFO - epoch 2, step 43970, training loss = 2.913083, validation loss = 2.046883
2018-12-05 13:33:25,757 - INFO - epoch 2, step 43980, training loss = 2.961765, validation loss = 1.831377
2018-12-05 13:33:30,060 - INFO - epoch 2, step 43990, training loss = 2.721248, validation loss = 2.271683
2018-12-05 13:33:34,567 - INFO - epoch 2, step 44000, training loss = 2.864716, validation loss = 2.240709
2018-12-05 13:33:38,824 - INFO - epoch 2, step 44010, training loss = 2.714142, validation loss = 1.783308
2018-12-05 13:33:42,903 - INFO - epoch 2, step 44020, training loss = 2.391590, validation loss = 2.401399
2018-12-05 13:33:47,120 - INFO - epoch 2, step 44030, training loss = 2.528394, validation loss = 2.130033
2018-12-05 13:33:51,354 - INFO - epoch 2, step 44040, training loss = 3.016824, validation loss = 2.229557
2018-12-05 13:33:55,472 - INFO - epoch 2, step 44050, training loss = 2.286778, validation loss = 2.100415
2018-12-05 13:33:59,400 - INFO - epoch 2, step 44060, training loss = 2.470793, validation loss = 2.495458
2018-12-05 13:34:03,659 - INFO - epoch 2, step 44070, training loss = 2.651841, validation loss = 2.263575
2018-12-05 13:34:08,035 - INFO - epoch 2, step 44080, training loss = 2.447861, validation loss = 1.856172
2018-12-05 13:34:12,270 - INFO - epoch 2, step 44090, training loss = 2.733304, validation loss = 2.370261
2018-12-05 13:34:16,468 - INFO - epoch 2, step 44100, training loss = 2.461610, validation loss = 2.084859
2018-12-05 13:34:20,703 - INFO - epoch 2, step 44110, training loss = 2.454133, validation loss = 2.271342
2018-12-05 13:34:24,702 - INFO - epoch 2, step 44120, training loss = 2.740740, validation loss = 2.822475
2018-12-05 13:34:29,056 - INFO - epoch 2, step 44130, training loss = 2.553951, validation loss = 2.221256
2018-12-05 13:34:33,399 - INFO - epoch 2, step 44140, training loss = 2.311725, validation loss = 2.376887
2018-12-05 13:34:37,790 - INFO - epoch 2, step 44150, training loss = 2.456586, validation loss = 2.171407
2018-12-05 13:34:42,123 - INFO - epoch 2, step 44160, training loss = 2.592385, validation loss = 2.546156
2018-12-05 13:34:46,371 - INFO - epoch 2, step 44170, training loss = 2.672647, validation loss = 2.489178
2018-12-05 13:34:50,429 - INFO - epoch 2, step 44180, training loss = 2.775311, validation loss = 2.944151
2018-12-05 13:34:54,523 - INFO - epoch 2, step 44190, training loss = 2.646732, validation loss = 2.330803
2018-12-05 13:34:58,512 - INFO - epoch 2, step 44200, training loss = 2.989411, validation loss = 2.589293
2018-12-05 13:35:02,802 - INFO - epoch 2, step 44210, training loss = 2.588918, validation loss = 2.025711
2018-12-05 13:35:06,938 - INFO - epoch 2, step 44220, training loss = 2.855106, validation loss = 2.463964
2018-12-05 13:35:10,798 - INFO - epoch 2, step 44230, training loss = 2.804312, validation loss = 2.518870
2018-12-05 13:35:14,907 - INFO - epoch 2, step 44240, training loss = 2.334405, validation loss = 2.770370
2018-12-05 13:35:19,097 - INFO - epoch 2, step 44250, training loss = 2.563093, validation loss = 2.360174
2018-12-05 13:35:23,342 - INFO - epoch 2, step 44260, training loss = 2.709620, validation loss = 2.540315
2018-12-05 13:35:27,517 - INFO - epoch 2, step 44270, training loss = 2.441547, validation loss = 2.346189
2018-12-05 13:35:31,841 - INFO - epoch 2, step 44280, training loss = 2.545081, validation loss = 1.629389
2018-12-05 13:35:35,926 - INFO - epoch 2, step 44290, training loss = 2.648398, validation loss = 2.343313
2018-12-05 13:35:40,509 - INFO - epoch 2, step 44300, training loss = 2.789648, validation loss = 2.770816
2018-12-05 13:35:44,782 - INFO - epoch 2, step 44310, training loss = 2.553009, validation loss = 2.555535
2018-12-05 13:35:49,122 - INFO - epoch 2, step 44320, training loss = 3.026252, validation loss = 2.449095
2018-12-05 13:35:53,348 - INFO - epoch 2, step 44330, training loss = 2.279027, validation loss = 2.648521
2018-12-05 13:35:57,480 - INFO - epoch 2, step 44340, training loss = 2.746758, validation loss = 2.197594
2018-12-05 13:36:01,842 - INFO - epoch 2, step 44350, training loss = 3.050235, validation loss = 2.070673
2018-12-05 13:36:05,979 - INFO - epoch 2, step 44360, training loss = 3.054081, validation loss = 2.231844
2018-12-05 13:36:10,259 - INFO - epoch 2, step 44370, training loss = 2.505320, validation loss = 2.668818
2018-12-05 13:36:14,112 - INFO - epoch 2, step 44380, training loss = 2.773488, validation loss = 2.532082
2018-12-05 13:36:18,160 - INFO - epoch 2, step 44390, training loss = 2.873253, validation loss = 1.990884
2018-12-05 13:36:22,253 - INFO - epoch 2, step 44400, training loss = 2.590470, validation loss = 2.635296
2018-12-05 13:36:26,176 - INFO - epoch 2, step 44410, training loss = 2.408053, validation loss = 2.022771
2018-12-05 13:36:30,174 - INFO - epoch 2, step 44420, training loss = 2.645264, validation loss = 1.760612
2018-12-05 13:36:34,159 - INFO - epoch 2, step 44430, training loss = 3.010141, validation loss = 1.805223
2018-12-05 13:36:37,975 - INFO - epoch 2, step 44440, training loss = 2.873013, validation loss = 2.157460
2018-12-05 13:36:41,808 - INFO - epoch 2, step 44450, training loss = 2.503943, validation loss = 2.603805
2018-12-05 13:36:46,029 - INFO - epoch 2, step 44460, training loss = 2.633842, validation loss = 2.771330
2018-12-05 13:36:49,958 - INFO - epoch 2, step 44470, training loss = 3.211238, validation loss = 2.705582
2018-12-05 13:36:53,918 - INFO - epoch 2, step 44480, training loss = 3.289372, validation loss = 2.380842
2018-12-05 13:36:57,981 - INFO - epoch 2, step 44490, training loss = 2.500016, validation loss = 2.080446
2018-12-05 13:37:03,613 - INFO - epoch 2, step 44500, training loss = 1.577401, validation loss = 2.371523
2018-12-05 13:37:08,969 - INFO - epoch 2, step 44510, training loss = 1.898362, validation loss = 2.500469
2018-12-05 13:37:13,981 - INFO - epoch 2, step 44520, training loss = 2.445798, validation loss = 2.386787
2018-12-05 13:37:18,706 - INFO - epoch 2, step 44530, training loss = 2.472913, validation loss = 2.103807
2018-12-05 13:37:23,117 - INFO - epoch 2, step 44540, training loss = 2.391356, validation loss = 2.271313
2018-12-05 13:37:27,324 - INFO - epoch 2, step 44550, training loss = 2.864897, validation loss = 2.006932
2018-12-05 13:37:31,397 - INFO - epoch 2, step 44560, training loss = 2.947028, validation loss = 2.276126
2018-12-05 13:37:35,614 - INFO - epoch 2, step 44570, training loss = 2.960942, validation loss = 2.080909
2018-12-05 13:37:39,866 - INFO - epoch 2, step 44580, training loss = 2.719865, validation loss = 2.304255
2018-12-05 13:37:44,259 - INFO - epoch 2, step 44590, training loss = 2.511797, validation loss = 2.624535
2018-12-05 13:37:48,595 - INFO - epoch 2, step 44600, training loss = 2.625681, validation loss = 2.424848
2018-12-05 13:37:53,015 - INFO - epoch 2, step 44610, training loss = 2.291038, validation loss = 2.333778
2018-12-05 13:37:57,443 - INFO - epoch 2, step 44620, training loss = 2.629250, validation loss = 2.115049
2018-12-05 13:38:02,012 - INFO - epoch 2, step 44630, training loss = 2.083042, validation loss = 2.424635
2018-12-05 13:38:07,603 - INFO - epoch 2, step 44640, training loss = 1.858730, validation loss = 2.455472
2018-12-05 13:38:13,071 - INFO - epoch 2, step 44650, training loss = 2.150258, validation loss = 2.093780
2018-12-05 13:38:18,099 - INFO - epoch 2, step 44660, training loss = 2.046511, validation loss = 2.522207
2018-12-05 13:38:23,858 - INFO - epoch 2, step 44670, training loss = 2.058666, validation loss = 2.759369
2018-12-05 13:38:29,364 - INFO - epoch 2, step 44680, training loss = 1.704720, validation loss = 2.202453
2018-12-05 13:38:35,038 - INFO - epoch 2, step 44690, training loss = 2.590595, validation loss = 2.122973
2018-12-05 13:38:40,324 - INFO - epoch 2, step 44700, training loss = 2.477436, validation loss = 2.391720
2018-12-05 13:38:45,396 - INFO - epoch 2, step 44710, training loss = 2.294327, validation loss = 2.637312
2018-12-05 13:38:50,431 - INFO - epoch 2, step 44720, training loss = 2.487825, validation loss = 1.727628
2018-12-05 13:38:55,286 - INFO - epoch 2, step 44730, training loss = 2.800564, validation loss = 2.490248
2018-12-05 13:38:59,118 - INFO - epoch 2, step 44740, training loss = 2.716249, validation loss = 2.290593
2018-12-05 13:39:03,513 - INFO - epoch 2, step 44750, training loss = 2.738979, validation loss = 2.371420
2018-12-05 13:39:07,800 - INFO - epoch 2, step 44760, training loss = 2.847965, validation loss = 2.421894
2018-12-05 13:39:11,963 - INFO - epoch 2, step 44770, training loss = 2.681503, validation loss = 2.617670
2018-12-05 13:39:15,950 - INFO - epoch 2, step 44780, training loss = 2.285478, validation loss = 2.778352
2018-12-05 13:39:20,745 - INFO - epoch 2, step 44790, training loss = 1.959500, validation loss = 2.190978
2018-12-05 13:39:26,361 - INFO - epoch 2, step 44800, training loss = 2.125770, validation loss = 2.162185
2018-12-05 13:39:31,184 - INFO - epoch 2, step 44810, training loss = 3.041269, validation loss = 2.626098
2018-12-05 13:39:35,856 - INFO - epoch 2, step 44820, training loss = 3.167927, validation loss = 2.388596
2018-12-05 13:39:40,469 - INFO - epoch 2, step 44830, training loss = 2.755799, validation loss = 2.679882
2018-12-05 13:39:44,560 - INFO - epoch 2, step 44840, training loss = 2.532563, validation loss = 2.403689
2018-12-05 13:39:48,547 - INFO - epoch 2, step 44850, training loss = 3.061825, validation loss = 2.371504
2018-12-05 13:39:52,527 - INFO - epoch 2, step 44860, training loss = 3.029994, validation loss = 2.907433
2018-12-05 13:39:56,311 - INFO - epoch 2, step 44870, training loss = 2.606308, validation loss = 2.789322
2018-12-05 13:40:00,286 - INFO - epoch 2, step 44880, training loss = 2.656045, validation loss = 2.489980
2018-12-05 13:40:03,992 - INFO - epoch 2, step 44890, training loss = 2.631038, validation loss = 2.613723
2018-12-05 13:40:07,826 - INFO - epoch 2, step 44900, training loss = 3.104847, validation loss = 2.584818
2018-12-05 13:40:11,725 - INFO - epoch 2, step 44910, training loss = 2.593796, validation loss = 2.624293
2018-12-05 13:40:15,411 - INFO - epoch 2, step 44920, training loss = 2.622820, validation loss = 2.286874
2018-12-05 13:40:19,216 - INFO - epoch 2, step 44930, training loss = 2.788406, validation loss = 2.183068
2018-12-05 13:40:23,291 - INFO - epoch 2, step 44940, training loss = 2.257443, validation loss = 2.179089
2018-12-05 13:40:28,274 - INFO - epoch 2, step 44950, training loss = 2.398531, validation loss = 2.404238
2018-12-05 13:40:33,608 - INFO - epoch 2, step 44960, training loss = 2.018736, validation loss = 2.768157
2018-12-05 13:40:38,831 - INFO - epoch 2, step 44970, training loss = 2.345891, validation loss = 2.722058
2018-12-05 13:40:43,418 - INFO - epoch 2, step 44980, training loss = 2.451249, validation loss = 2.164601
2018-12-05 13:40:47,679 - INFO - epoch 2, step 44990, training loss = 2.641855, validation loss = 2.554622
2018-12-05 13:40:51,971 - INFO - epoch 2, step 45000, training loss = 2.765486, validation loss = 2.472613
2018-12-05 13:40:56,129 - INFO - epoch 2, step 45010, training loss = 2.682423, validation loss = 3.284962
2018-12-05 13:41:00,978 - INFO - epoch 2, step 45020, training loss = 2.090330, validation loss = 2.225413
2018-12-05 13:41:05,873 - INFO - epoch 2, step 45030, training loss = 2.890721, validation loss = 2.373846
2018-12-05 13:41:11,263 - INFO - epoch 2, step 45040, training loss = 1.810426, validation loss = 2.354898
2018-12-05 13:41:16,445 - INFO - epoch 2, step 45050, training loss = 2.852327, validation loss = 2.575880
2018-12-05 13:41:21,699 - INFO - epoch 2, step 45060, training loss = 2.157372, validation loss = 2.388218
2018-12-05 13:41:26,938 - INFO - epoch 2, step 45070, training loss = 3.175354, validation loss = 2.724910
2018-12-05 13:41:31,813 - INFO - epoch 2, step 45080, training loss = 2.950172, validation loss = 2.361084
2018-12-05 13:41:36,070 - INFO - epoch 2, step 45090, training loss = 2.703373, validation loss = 2.266620
2018-12-05 13:41:40,378 - INFO - epoch 2, step 45100, training loss = 2.519193, validation loss = 2.559879
2018-12-05 13:41:44,457 - INFO - epoch 2, step 45110, training loss = 2.678909, validation loss = 2.298678
2018-12-05 13:41:48,791 - INFO - epoch 2, step 45120, training loss = 2.937054, validation loss = 2.773676
2018-12-05 13:41:53,235 - INFO - epoch 2, step 45130, training loss = 2.345404, validation loss = 2.456840
2018-12-05 13:41:57,144 - INFO - epoch 2, step 45140, training loss = 3.063760, validation loss = 2.319890
2018-12-05 13:42:01,161 - INFO - epoch 2, step 45150, training loss = 2.748992, validation loss = 2.106425
2018-12-05 13:42:05,092 - INFO - epoch 2, step 45160, training loss = 2.093076, validation loss = 2.437099
2018-12-05 13:42:09,195 - INFO - epoch 2, step 45170, training loss = 2.829392, validation loss = 2.803619
2018-12-05 13:42:14,228 - INFO - epoch 2, step 45180, training loss = 2.938895, validation loss = 2.477027
2018-12-05 13:42:20,147 - INFO - epoch 2, step 45190, training loss = 2.075637, validation loss = 2.725591
2018-12-05 13:42:25,870 - INFO - epoch 2, step 45200, training loss = 2.877533, validation loss = 2.732899
2018-12-05 13:42:31,236 - INFO - epoch 2, step 45210, training loss = 2.181596, validation loss = 2.148680
2018-12-05 13:42:36,311 - INFO - epoch 2, step 45220, training loss = 2.585560, validation loss = 2.460109
2018-12-05 13:42:39,944 - INFO - epoch 2, step 45230, training loss = 3.132039, validation loss = 2.629050
2018-12-05 13:42:43,915 - INFO - epoch 2, step 45240, training loss = 2.722423, validation loss = 2.928905
2018-12-05 13:42:47,705 - INFO - epoch 2, step 45250, training loss = 3.059489, validation loss = 2.278964
2018-12-05 13:42:51,680 - INFO - epoch 2, step 45260, training loss = 2.655278, validation loss = 2.507187
2018-12-05 13:42:55,574 - INFO - epoch 2, step 45270, training loss = 2.393183, validation loss = 2.611697
2018-12-05 13:43:00,202 - INFO - epoch 2, step 45280, training loss = 2.497277, validation loss = 2.298053
2018-12-05 13:43:05,687 - INFO - epoch 2, step 45290, training loss = 2.313413, validation loss = 2.171756
2018-12-05 13:43:10,813 - INFO - epoch 2, step 45300, training loss = 2.113584, validation loss = 2.012549
2018-12-05 13:43:16,148 - INFO - epoch 2, step 45310, training loss = 2.256850, validation loss = 2.989887
2018-12-05 13:43:21,082 - INFO - epoch 2, step 45320, training loss = 2.462481, validation loss = 2.325169
2018-12-05 13:43:26,593 - INFO - epoch 2, step 45330, training loss = 2.167643, validation loss = 1.992826
2018-12-05 13:43:31,953 - INFO - epoch 2, step 45340, training loss = 2.357950, validation loss = 2.660000
2018-12-05 13:43:37,730 - INFO - epoch 2, step 45350, training loss = 2.337117, validation loss = 2.582218
2018-12-05 13:43:42,738 - INFO - epoch 2, step 45360, training loss = 2.495748, validation loss = 2.534216
2018-12-05 13:43:48,041 - INFO - epoch 2, step 45370, training loss = 2.361049, validation loss = 2.693847
2018-12-05 13:43:53,078 - INFO - epoch 2, step 45380, training loss = 2.418431, validation loss = 2.541141
2018-12-05 13:43:58,141 - INFO - epoch 2, step 45390, training loss = 2.405765, validation loss = 2.508392
2018-12-05 13:44:03,982 - INFO - epoch 2, step 45400, training loss = 2.131906, validation loss = 2.758683
2018-12-05 13:44:08,975 - INFO - epoch 2, step 45410, training loss = 2.589866, validation loss = 2.298407
2018-12-05 13:44:14,300 - INFO - epoch 2, step 45420, training loss = 2.131428, validation loss = 2.185981
2018-12-05 13:44:19,700 - INFO - epoch 2, step 45430, training loss = 2.304163, validation loss = 2.161210
2018-12-05 13:44:25,510 - INFO - epoch 2, step 45440, training loss = 2.184304, validation loss = 2.363692
2018-12-05 13:44:30,204 - INFO - epoch 2, step 45450, training loss = 2.617782, validation loss = 2.406659
2018-12-05 13:44:34,485 - INFO - epoch 2, step 45460, training loss = 2.789217, validation loss = 2.498255
2018-12-05 13:44:38,970 - INFO - epoch 2, step 45470, training loss = 2.931339, validation loss = 2.278143
2018-12-05 13:44:42,745 - INFO - epoch 2, step 45480, training loss = 2.978098, validation loss = 2.387013
2018-12-05 13:44:46,738 - INFO - epoch 2, step 45490, training loss = 2.902765, validation loss = 1.900169
2018-12-05 13:44:51,177 - INFO - epoch 2, step 45500, training loss = 1.874135, validation loss = 2.480557
2018-12-05 13:44:56,958 - INFO - epoch 2, step 45510, training loss = 1.615404, validation loss = 2.679804
2018-12-05 13:45:02,272 - INFO - epoch 2, step 45520, training loss = 2.063120, validation loss = 2.720580
2018-12-05 13:45:07,273 - INFO - epoch 2, step 45530, training loss = 2.811540, validation loss = 2.955570
2018-12-05 13:45:11,281 - INFO - epoch 2, step 45540, training loss = 2.638827, validation loss = 2.143237
2018-12-05 13:45:15,080 - INFO - epoch 2, step 45550, training loss = 3.078351, validation loss = 2.828560
2018-12-05 13:45:19,076 - INFO - epoch 2, step 45560, training loss = 2.949983, validation loss = 2.601233
2018-12-05 13:45:23,031 - INFO - epoch 2, step 45570, training loss = 2.943012, validation loss = 2.518867
2018-12-05 13:45:27,021 - INFO - epoch 2, step 45580, training loss = 2.645804, validation loss = 2.316645
2018-12-05 13:45:31,032 - INFO - epoch 2, step 45590, training loss = 2.627533, validation loss = 2.618216
2018-12-05 13:45:34,834 - INFO - epoch 2, step 45600, training loss = 2.937987, validation loss = 2.379890
2018-12-05 13:45:38,776 - INFO - epoch 2, step 45610, training loss = 3.099350, validation loss = 2.422207
2018-12-05 13:45:42,722 - INFO - epoch 2, step 45620, training loss = 3.025769, validation loss = 2.711152
2018-12-05 13:45:46,662 - INFO - epoch 2, step 45630, training loss = 2.781156, validation loss = 2.879311
2018-12-05 13:45:50,629 - INFO - epoch 2, step 45640, training loss = 2.907962, validation loss = 2.014702
2018-12-05 13:45:54,542 - INFO - epoch 2, step 45650, training loss = 2.819536, validation loss = 2.522634
2018-12-05 13:45:58,503 - INFO - epoch 2, step 45660, training loss = 2.748031, validation loss = 2.629726
2018-12-05 13:46:02,547 - INFO - epoch 2, step 45670, training loss = 2.169130, validation loss = 2.910166
2018-12-05 13:46:06,260 - INFO - epoch 2, step 45680, training loss = 2.782049, validation loss = 2.386713
2018-12-05 13:46:10,354 - INFO - epoch 2, step 45690, training loss = 2.628849, validation loss = 2.333897
2018-12-05 13:46:14,353 - INFO - epoch 2, step 45700, training loss = 2.997801, validation loss = 2.551335
2018-12-05 13:46:18,485 - INFO - epoch 2, step 45710, training loss = 2.686557, validation loss = 2.823992
2018-12-05 13:46:22,703 - INFO - epoch 2, step 45720, training loss = 2.433099, validation loss = 2.203159
2018-12-05 13:46:26,658 - INFO - epoch 2, step 45730, training loss = 2.808342, validation loss = 2.589757
2018-12-05 13:46:30,483 - INFO - epoch 2, step 45740, training loss = 3.110325, validation loss = 2.662408
2018-12-05 13:46:34,313 - INFO - epoch 2, step 45750, training loss = 2.784771, validation loss = 2.824006
2018-12-05 13:46:38,257 - INFO - epoch 2, step 45760, training loss = 2.563207, validation loss = 2.547400
2018-12-05 13:46:42,288 - INFO - epoch 2, step 45770, training loss = 2.621506, validation loss = 2.347274
2018-12-05 13:46:46,033 - INFO - epoch 2, step 45780, training loss = 2.967604, validation loss = 2.494785
2018-12-05 13:46:50,004 - INFO - epoch 2, step 45790, training loss = 2.757010, validation loss = 2.061533
2018-12-05 13:46:54,046 - INFO - epoch 2, step 45800, training loss = 2.800893, validation loss = 2.559944
2018-12-05 13:46:58,878 - INFO - epoch 2, step 45810, training loss = 2.513503, validation loss = 2.432297
2018-12-05 13:47:04,217 - INFO - epoch 2, step 45820, training loss = 2.516965, validation loss = 3.097512
2018-12-05 13:47:09,355 - INFO - epoch 2, step 45830, training loss = 2.690457, validation loss = 2.450495
2018-12-05 13:47:14,597 - INFO - epoch 2, step 45840, training loss = 2.310465, validation loss = 2.307587
2018-12-05 13:47:19,976 - INFO - epoch 2, step 45850, training loss = 2.360063, validation loss = 2.712735
2018-12-05 13:47:25,172 - INFO - epoch 2, step 45860, training loss = 2.273746, validation loss = 2.517256
2018-12-05 13:47:30,242 - INFO - epoch 2, step 45870, training loss = 2.439923, validation loss = 2.556825
2018-12-05 13:47:35,598 - INFO - epoch 2, step 45880, training loss = 1.993460, validation loss = 2.579596
2018-12-05 13:47:41,511 - INFO - epoch 2, step 45890, training loss = 2.158723, validation loss = 2.631903
2018-12-05 13:47:47,096 - INFO - epoch 2, step 45900, training loss = 1.812431, validation loss = 2.849167
2018-12-05 13:47:52,854 - INFO - epoch 2, step 45910, training loss = 1.643852, validation loss = 2.573881
2018-12-05 13:47:58,324 - INFO - epoch 2, step 45920, training loss = 2.958459, validation loss = 3.036923
2018-12-05 13:48:04,563 - INFO - epoch 2, step 45930, training loss = 1.788666, validation loss = 2.122934
2018-12-05 13:48:09,774 - INFO - epoch 2, step 45940, training loss = 2.259287, validation loss = 2.465696
2018-12-05 13:48:15,112 - INFO - epoch 2, step 45950, training loss = 2.233726, validation loss = 2.590896
2018-12-05 13:48:20,551 - INFO - epoch 2, step 45960, training loss = 2.489803, validation loss = 2.705068
2018-12-05 13:48:26,125 - INFO - epoch 2, step 45970, training loss = 2.145413, validation loss = 2.734893
2018-12-05 13:48:32,442 - INFO - epoch 2, step 45980, training loss = 1.800802, validation loss = 3.065782
2018-12-05 13:48:37,480 - INFO - epoch 2, step 45990, training loss = 2.458671, validation loss = 2.722027
2018-12-05 13:48:42,819 - INFO - epoch 2, step 46000, training loss = 1.972545, validation loss = 2.378812
2018-12-05 13:48:48,625 - INFO - epoch 2, step 46010, training loss = 2.427075, validation loss = 2.227471
2018-12-05 13:48:53,127 - INFO - epoch 2, step 46020, training loss = 2.765430, validation loss = 2.513392
2018-12-05 13:48:57,129 - INFO - epoch 2, step 46030, training loss = 2.969234, validation loss = 2.761704
2018-12-05 13:49:01,100 - INFO - epoch 2, step 46040, training loss = 2.875069, validation loss = 2.549998
2018-12-05 13:49:05,231 - INFO - epoch 2, step 46050, training loss = 3.048599, validation loss = 2.626687
2018-12-05 13:49:09,234 - INFO - epoch 2, step 46060, training loss = 2.999176, validation loss = 2.373976
2018-12-05 13:49:13,220 - INFO - epoch 2, step 46070, training loss = 3.088377, validation loss = 2.592157
2018-12-05 13:49:17,337 - INFO - epoch 2, step 46080, training loss = 2.809212, validation loss = 2.495011
2018-12-05 13:49:21,726 - INFO - epoch 2, step 46090, training loss = 2.409280, validation loss = 2.477486
2018-12-05 13:49:25,971 - INFO - epoch 2, step 46100, training loss = 2.566841, validation loss = 2.187882
2018-12-05 13:49:30,272 - INFO - epoch 2, step 46110, training loss = 2.307364, validation loss = 2.675572
2018-12-05 13:49:34,444 - INFO - epoch 2, step 46120, training loss = 2.686404, validation loss = 2.547344
2018-12-05 13:49:38,654 - INFO - epoch 2, step 46130, training loss = 2.985139, validation loss = 2.334403
2018-12-05 13:49:43,059 - INFO - epoch 2, step 46140, training loss = 2.591008, validation loss = 2.544273
2018-12-05 13:49:47,142 - INFO - epoch 2, step 46150, training loss = 2.321064, validation loss = 2.887001
2018-12-05 13:49:51,155 - INFO - epoch 2, step 46160, training loss = 2.763145, validation loss = 2.962168
2018-12-05 13:49:55,200 - INFO - epoch 2, step 46170, training loss = 2.813278, validation loss = 2.675086
2018-12-05 13:49:59,151 - INFO - epoch 2, step 46180, training loss = 2.916601, validation loss = 2.735539
2018-12-05 13:50:02,964 - INFO - epoch 2, step 46190, training loss = 2.641004, validation loss = 2.756726
2018-12-05 13:50:06,940 - INFO - epoch 2, step 46200, training loss = 2.604543, validation loss = 2.831022
2018-12-05 13:50:11,216 - INFO - epoch 2, step 46210, training loss = 2.029742, validation loss = 2.975198
2018-12-05 13:50:15,097 - INFO - epoch 2, step 46220, training loss = 2.984219, validation loss = 2.569258
2018-12-05 13:50:18,937 - INFO - epoch 2, step 46230, training loss = 2.467880, validation loss = 2.650721
2018-12-05 13:50:22,904 - INFO - epoch 2, step 46240, training loss = 2.462917, validation loss = 2.340101
2018-12-05 13:50:27,216 - INFO - epoch 2, step 46250, training loss = 2.698996, validation loss = 3.025958
2018-12-05 13:50:31,538 - INFO - epoch 2, step 46260, training loss = 2.739470, validation loss = 3.002482
2018-12-05 13:50:35,776 - INFO - epoch 2, step 46270, training loss = 2.119988, validation loss = 2.679520
2018-12-05 13:50:39,740 - INFO - epoch 2, step 46280, training loss = 2.649330, validation loss = 2.375144
2018-12-05 13:50:43,995 - INFO - epoch 2, step 46290, training loss = 2.287051, validation loss = 2.555367
2018-12-05 13:50:48,470 - INFO - epoch 2, step 46300, training loss = 2.464870, validation loss = 3.142787
2018-12-05 13:50:52,669 - INFO - epoch 2, step 46310, training loss = 2.639725, validation loss = 3.353632
2018-12-05 13:50:56,681 - INFO - epoch 2, step 46320, training loss = 2.729203, validation loss = 2.771925
2018-12-05 13:51:00,487 - INFO - epoch 2, step 46330, training loss = 2.899926, validation loss = 3.130469
2018-12-05 13:51:04,530 - INFO - epoch 2, step 46340, training loss = 2.725746, validation loss = 2.642803
2018-12-05 13:51:08,622 - INFO - epoch 2, step 46350, training loss = 2.803139, validation loss = 2.875728
2018-12-05 13:51:12,634 - INFO - epoch 2, step 46360, training loss = 2.368061, validation loss = 2.362097
2018-12-05 13:51:16,426 - INFO - epoch 2, step 46370, training loss = 2.930135, validation loss = 2.739812
2018-12-05 13:51:20,181 - INFO - epoch 2, step 46380, training loss = 2.749157, validation loss = 2.432952
2018-12-05 13:51:24,164 - INFO - epoch 2, step 46390, training loss = 2.897386, validation loss = 2.816325
2018-12-05 13:51:28,239 - INFO - epoch 2, step 46400, training loss = 2.733047, validation loss = 2.560113
2018-12-05 13:51:32,212 - INFO - epoch 2, step 46410, training loss = 2.733993, validation loss = 2.766775
2018-12-05 13:51:36,042 - INFO - epoch 2, step 46420, training loss = 2.930065, validation loss = 3.154819
2018-12-05 13:51:39,887 - INFO - epoch 2, step 46430, training loss = 2.385102, validation loss = 2.611071
2018-12-05 13:51:43,549 - INFO - epoch 2, step 46440, training loss = 2.828007, validation loss = 2.741734
2018-12-05 13:51:47,236 - INFO - epoch 2, step 46450, training loss = 2.525638, validation loss = 2.315768
2018-12-05 13:51:50,877 - INFO - epoch 2, step 46460, training loss = 2.748669, validation loss = 2.863639
2018-12-05 13:51:54,860 - INFO - epoch 2, step 46470, training loss = 2.306135, validation loss = 2.641926
2018-12-05 13:52:00,535 - INFO - epoch 2, step 46480, training loss = 1.670177, validation loss = 2.628663
2018-12-05 13:52:05,532 - INFO - epoch 2, step 46490, training loss = 2.477317, validation loss = 2.551119
2018-12-05 13:52:10,995 - INFO - epoch 2, step 46500, training loss = 1.866364, validation loss = 2.536779
2018-12-05 13:52:16,252 - INFO - epoch 2, step 46510, training loss = 2.575515, validation loss = 2.618453
2018-12-05 13:52:21,796 - INFO - epoch 2, step 46520, training loss = 2.302076, validation loss = 2.858922
2018-12-05 13:52:26,096 - INFO - epoch 2, step 46530, training loss = 2.740008, validation loss = 2.651479
2018-12-05 13:52:29,991 - INFO - epoch 2, step 46540, training loss = 2.461644, validation loss = 2.628396
2018-12-05 13:52:34,209 - INFO - epoch 2, step 46550, training loss = 2.622744, validation loss = 2.438158
2018-12-05 13:52:38,144 - INFO - epoch 2, step 46560, training loss = 2.581585, validation loss = 2.461426
2018-12-05 13:52:42,225 - INFO - epoch 2, step 46570, training loss = 2.719703, validation loss = 2.937246
2018-12-05 13:52:46,299 - INFO - epoch 2, step 46580, training loss = 2.347194, validation loss = 2.539522
2018-12-05 13:52:50,536 - INFO - epoch 2, step 46590, training loss = 1.925201, validation loss = 2.816483
2018-12-05 13:52:55,729 - INFO - epoch 2, step 46600, training loss = 2.367200, validation loss = 3.077538
2018-12-05 13:53:01,303 - INFO - epoch 2, step 46610, training loss = 2.051302, validation loss = 2.667417
2018-12-05 13:53:07,254 - INFO - epoch 2, step 46620, training loss = 3.446551, validation loss = 2.889573
2018-12-05 13:53:11,951 - INFO - epoch 2, step 46630, training loss = 2.533387, validation loss = 2.932561
2018-12-05 13:53:17,624 - INFO - epoch 2, step 46640, training loss = 1.885831, validation loss = 3.003945
2018-12-05 13:53:23,070 - INFO - epoch 2, step 46650, training loss = 2.606834, validation loss = 2.836249
2018-12-05 13:53:26,955 - INFO - epoch 2, step 46660, training loss = 2.998649, validation loss = 2.623384
2018-12-05 13:53:31,052 - INFO - epoch 2, step 46670, training loss = 2.545243, validation loss = 2.295453
2018-12-05 13:53:34,868 - INFO - epoch 2, step 46680, training loss = 2.764015, validation loss = 3.026959
2018-12-05 13:53:38,628 - INFO - epoch 2, step 46690, training loss = 2.798375, validation loss = 2.763096
2018-12-05 13:53:42,402 - INFO - epoch 2, step 46700, training loss = 2.764742, validation loss = 2.654018
2018-12-05 13:53:46,643 - INFO - epoch 2, step 46710, training loss = 2.247674, validation loss = 2.959936
2018-12-05 13:53:50,603 - INFO - epoch 2, step 46720, training loss = 2.637969, validation loss = 2.664454
2018-12-05 13:53:54,748 - INFO - epoch 2, step 46730, training loss = 3.035059, validation loss = 3.122662
2018-12-05 13:53:58,868 - INFO - epoch 2, step 46740, training loss = 2.665910, validation loss = 3.058212
2018-12-05 13:54:03,300 - INFO - epoch 2, step 46750, training loss = 2.258327, validation loss = 2.508778
2018-12-05 13:54:07,472 - INFO - epoch 2, step 46760, training loss = 2.217384, validation loss = 3.126288
2018-12-05 13:54:11,664 - INFO - epoch 2, step 46770, training loss = 2.714216, validation loss = 3.142172
2018-12-05 13:54:15,700 - INFO - epoch 2, step 46780, training loss = 2.171111, validation loss = 2.692544
2018-12-05 13:54:19,854 - INFO - epoch 2, step 46790, training loss = 2.648785, validation loss = 3.423199
2018-12-05 13:54:24,070 - INFO - epoch 2, step 46800, training loss = 2.908219, validation loss = 3.153034
2018-12-05 13:54:27,985 - INFO - epoch 2, step 46810, training loss = 2.780123, validation loss = 2.992634
2018-12-05 13:54:31,857 - INFO - epoch 2, step 46820, training loss = 2.745031, validation loss = 2.921577
2018-12-05 13:54:35,832 - INFO - epoch 2, step 46830, training loss = 3.090543, validation loss = 2.602549
2018-12-05 13:54:39,779 - INFO - epoch 2, step 46840, training loss = 2.775913, validation loss = 3.019418
2018-12-05 13:54:43,664 - INFO - epoch 2, step 46850, training loss = 2.999781, validation loss = 3.524930
2018-12-05 13:54:47,676 - INFO - epoch 2, step 46860, training loss = 2.476064, validation loss = 2.968718
2018-12-05 13:54:51,655 - INFO - epoch 2, step 46870, training loss = 2.425933, validation loss = 3.292326
2018-12-05 13:54:55,520 - INFO - epoch 2, step 46880, training loss = 2.356118, validation loss = 3.333838
2018-12-05 13:54:59,422 - INFO - epoch 2, step 46890, training loss = 2.892268, validation loss = 3.782589
2018-12-05 13:55:03,087 - INFO - epoch 2, step 46900, training loss = 2.476178, validation loss = 3.139209
2018-12-05 13:55:07,334 - INFO - epoch 2, step 46910, training loss = 2.487873, validation loss = 3.198289
2018-12-05 13:55:12,362 - INFO - epoch 2, step 46920, training loss = 2.197401, validation loss = 3.443802
2018-12-05 13:55:17,839 - INFO - epoch 2, step 46930, training loss = 2.503821, validation loss = 3.005768
2018-12-05 13:55:23,356 - INFO - epoch 2, step 46940, training loss = 1.898618, validation loss = 3.037173
2018-12-05 13:55:28,898 - INFO - epoch 2, step 46950, training loss = 2.550547, validation loss = 3.079612
2018-12-05 13:55:34,480 - INFO - epoch 2, step 46960, training loss = 2.171329, validation loss = 2.850520
2018-12-05 13:55:40,141 - INFO - epoch 2, step 46970, training loss = 2.363187, validation loss = 2.940109
2018-12-05 13:55:46,027 - INFO - epoch 2, step 46980, training loss = 2.222215, validation loss = 2.844549
2018-12-05 13:55:51,529 - INFO - epoch 2, step 46990, training loss = 2.418548, validation loss = 2.774477
2018-12-05 13:55:56,852 - INFO - epoch 2, step 47000, training loss = 3.001801, validation loss = 2.437849
2018-12-05 13:56:02,214 - INFO - epoch 2, step 47010, training loss = 2.374114, validation loss = 3.318129
2018-12-05 13:56:07,223 - INFO - epoch 2, step 47020, training loss = 1.896659, validation loss = 3.115942
2018-12-05 13:56:12,489 - INFO - epoch 2, step 47030, training loss = 1.900166, validation loss = 2.723221
2018-12-05 13:56:17,255 - INFO - epoch 2, step 47040, training loss = 3.038742, validation loss = 2.702923
2018-12-05 13:56:21,999 - INFO - epoch 2, step 47050, training loss = 2.321220, validation loss = 3.165608
2018-12-05 13:56:26,293 - INFO - epoch 2, step 47060, training loss = 2.714330, validation loss = 3.175517
2018-12-05 13:56:30,739 - INFO - epoch 2, step 47070, training loss = 2.436035, validation loss = 2.996054
2018-12-05 13:56:35,386 - INFO - epoch 2, step 47080, training loss = 2.118514, validation loss = 2.782964
2018-12-05 13:56:39,794 - INFO - epoch 2, step 47090, training loss = 2.367743, validation loss = 3.188661
2018-12-05 13:56:44,405 - INFO - epoch 2, step 47100, training loss = 2.320106, validation loss = 2.939211
2018-12-05 13:56:48,698 - INFO - epoch 2, step 47110, training loss = 2.793091, validation loss = 2.818779
2018-12-05 13:56:52,946 - INFO - epoch 2, step 47120, training loss = 2.549410, validation loss = 2.933989
2018-12-05 13:56:57,673 - INFO - epoch 2, step 47130, training loss = 2.614479, validation loss = 3.244872
2018-12-05 13:57:01,949 - INFO - epoch 2, step 47140, training loss = 2.866350, validation loss = 2.921977
2018-12-05 13:57:06,342 - INFO - epoch 2, step 47150, training loss = 2.489985, validation loss = 2.974163
2018-12-05 13:57:10,657 - INFO - epoch 2, step 47160, training loss = 2.559839, validation loss = 2.581266
2018-12-05 13:57:14,934 - INFO - epoch 2, step 47170, training loss = 2.399860, validation loss = 3.455664
2018-12-05 13:57:19,178 - INFO - epoch 2, step 47180, training loss = 2.707733, validation loss = 2.940691
2018-12-05 13:57:23,460 - INFO - epoch 2, step 47190, training loss = 2.643130, validation loss = 3.126808
2018-12-05 13:57:27,106 - INFO - epoch 2, step 47200, training loss = 2.015070, validation loss = 2.903160
2018-12-05 13:57:30,282 - INFO - epoch 2, step 47210, training loss = 2.154991, validation loss = 3.278325
2018-12-05 13:57:33,354 - INFO - epoch 2, step 47220, training loss = 1.957356, validation loss = 2.962393
2018-12-05 13:57:36,647 - INFO - epoch 2, step 47230, training loss = 1.744850, validation loss = 2.945612
2018-12-05 13:57:39,714 - INFO - epoch 2, step 47240, training loss = 1.994765, validation loss = 2.966705
2018-12-05 13:57:43,319 - INFO - epoch 2, step 47250, training loss = 1.762500, validation loss = 2.827533
2018-12-05 13:57:46,564 - INFO - epoch 2, step 47260, training loss = 1.676973, validation loss = 2.870618
2018-12-05 13:57:50,468 - INFO - epoch 2, step 47270, training loss = 1.671784, validation loss = 2.915275
2018-12-05 13:57:54,353 - INFO - epoch 2, step 47280, training loss = 1.659569, validation loss = 3.354137
2018-12-05 13:57:58,366 - INFO - epoch 2, step 47290, training loss = 1.794876, validation loss = 2.766598
2018-12-05 13:58:02,195 - INFO - epoch 2, step 47300, training loss = 1.996814, validation loss = 3.191438
2018-12-05 13:58:05,839 - INFO - epoch 2, step 47310, training loss = 2.202759, validation loss = 3.590244
2018-12-05 13:58:09,769 - INFO - epoch 2, step 47320, training loss = 1.602138, validation loss = 3.088784
2018-12-05 13:58:13,655 - INFO - epoch 2, step 47330, training loss = 1.888268, validation loss = 2.736707
2018-12-05 13:58:17,896 - INFO - epoch 2, step 47340, training loss = 1.668149, validation loss = 2.895989
2018-12-05 13:58:21,932 - INFO - epoch 2, step 47350, training loss = 1.823165, validation loss = 3.045224
2018-12-05 13:58:25,417 - INFO - epoch 2, step 47360, training loss = 1.592791, validation loss = 3.596507
2018-12-05 13:58:28,570 - INFO - epoch 2, step 47370, training loss = 1.612482, validation loss = 3.244063
2018-12-05 13:58:31,956 - INFO - epoch 2, step 47380, training loss = 1.903366, validation loss = 3.245322
2018-12-05 13:58:35,360 - INFO - epoch 2, step 47390, training loss = 2.001308, validation loss = 3.697332
2018-12-05 13:58:38,507 - INFO - epoch 2, step 47400, training loss = 2.067643, validation loss = 3.286854
2018-12-05 13:58:41,698 - INFO - epoch 2, step 47410, training loss = 1.745044, validation loss = 3.689582
2018-12-05 13:58:44,836 - INFO - epoch 2, step 47420, training loss = 1.777995, validation loss = 3.057935
2018-12-05 13:58:48,414 - INFO - epoch 2, step 47430, training loss = 1.619045, validation loss = 3.122180
2018-12-05 13:58:52,361 - INFO - epoch 2, step 47440, training loss = 1.846010, validation loss = 3.075670
2018-12-05 13:58:56,245 - INFO - epoch 2, step 47450, training loss = 1.778935, validation loss = 2.998534
2018-12-05 13:58:59,937 - INFO - epoch 2, step 47460, training loss = 1.901162, validation loss = 3.693699
2018-12-05 13:59:03,736 - INFO - epoch 2, step 47470, training loss = 1.481381, validation loss = 3.756166
2018-12-05 13:59:07,441 - INFO - epoch 2, step 47480, training loss = 2.010466, validation loss = 3.084669
2018-12-05 13:59:11,516 - INFO - epoch 2, step 47490, training loss = 1.436908, validation loss = 3.598959
2018-12-05 13:59:15,226 - INFO - epoch 2, step 47500, training loss = 1.594078, validation loss = 3.048486
2018-12-05 13:59:19,068 - INFO - epoch 2, step 47510, training loss = 1.674715, validation loss = 2.946046
2018-12-05 13:59:22,809 - INFO - epoch 2, step 47520, training loss = 1.720486, validation loss = 2.946987
2018-12-05 13:59:26,471 - INFO - epoch 2, step 47530, training loss = 1.832261, validation loss = 3.668024
2018-12-05 13:59:30,223 - INFO - epoch 2, step 47540, training loss = 1.849715, validation loss = 3.684424
2018-12-05 13:59:33,965 - INFO - epoch 2, step 47550, training loss = 1.815306, validation loss = 3.348100
2018-12-05 13:59:37,748 - INFO - epoch 2, step 47560, training loss = 1.762458, validation loss = 3.186265
2018-12-05 13:59:41,350 - INFO - epoch 2, step 47570, training loss = 1.644931, validation loss = 3.169747
2018-12-05 13:59:45,080 - INFO - epoch 2, step 47580, training loss = 1.959449, validation loss = 3.476209
2018-12-05 13:59:48,666 - INFO - epoch 2, step 47590, training loss = 1.702019, validation loss = 3.362076
2018-12-05 13:59:52,122 - INFO - epoch 2, step 47600, training loss = 1.730996, validation loss = 2.898243
2018-12-05 13:59:55,644 - INFO - epoch 2, step 47610, training loss = 2.095038, validation loss = 2.992773
2018-12-05 13:59:59,310 - INFO - epoch 2, step 47620, training loss = 1.976486, validation loss = 3.541489
2018-12-05 14:00:03,126 - INFO - epoch 2, step 47630, training loss = 2.107912, validation loss = 3.034124
2018-12-05 14:00:06,638 - INFO - epoch 2, step 47640, training loss = 1.920925, validation loss = 3.232163
2018-12-05 14:00:09,747 - INFO - epoch 2, step 47650, training loss = 1.956474, validation loss = 3.183372
2018-12-05 14:00:12,968 - INFO - epoch 2, step 47660, training loss = 1.607061, validation loss = 3.437267
2018-12-05 14:00:16,172 - INFO - epoch 2, step 47670, training loss = 1.686492, validation loss = 3.317734
2018-12-05 14:00:19,318 - INFO - epoch 2, step 47680, training loss = 1.836248, validation loss = 3.122355
2018-12-05 14:00:22,583 - INFO - epoch 2, step 47690, training loss = 1.594288, validation loss = 3.527501
2018-12-05 14:00:25,822 - INFO - epoch 2, step 47700, training loss = 1.934042, validation loss = 3.236014
2018-12-05 14:00:28,969 - INFO - epoch 2, step 47710, training loss = 1.687053, validation loss = 3.291238
2018-12-05 14:00:32,536 - INFO - epoch 2, step 47720, training loss = 1.389479, validation loss = 3.365737
2018-12-05 14:00:36,010 - INFO - epoch 2, step 47730, training loss = 1.766650, validation loss = 3.654392
2018-12-05 14:00:39,372 - INFO - epoch 2, step 47740, training loss = 1.758081, validation loss = 3.281610
2018-12-05 14:00:43,034 - INFO - epoch 2, step 47750, training loss = 1.507374, validation loss = 3.325835
2018-12-05 14:00:46,557 - INFO - epoch 2, step 47760, training loss = 1.575134, validation loss = 3.261981
2018-12-05 14:00:50,058 - INFO - epoch 2, step 47770, training loss = 1.547146, validation loss = 3.169331
2018-12-05 14:00:53,689 - INFO - epoch 2, step 47780, training loss = 2.078071, validation loss = 3.192830
2018-12-05 14:00:57,454 - INFO - epoch 2, step 47790, training loss = 1.830416, validation loss = 3.167120
2018-12-05 14:01:01,268 - INFO - epoch 2, step 47800, training loss = 1.481069, validation loss = 3.026716
2018-12-05 14:01:05,276 - INFO - epoch 2, step 47810, training loss = 1.563274, validation loss = 3.641494
2018-12-05 14:01:09,064 - INFO - epoch 2, step 47820, training loss = 1.664841, validation loss = 3.723113
2018-12-05 14:01:12,807 - INFO - epoch 2, step 47830, training loss = 1.429304, validation loss = 3.245805
2018-12-05 14:01:17,120 - INFO - epoch 2, step 47840, training loss = 1.721935, validation loss = 3.563381
2018-12-05 14:01:21,102 - INFO - epoch 2, step 47850, training loss = 1.778423, validation loss = 3.625884
2018-12-05 14:01:25,512 - INFO - epoch 2, step 47860, training loss = 1.870557, validation loss = 3.237484
2018-12-05 14:01:29,734 - INFO - epoch 2, step 47870, training loss = 1.891151, validation loss = 3.110141
2018-12-05 14:01:34,430 - INFO - epoch 2, step 47880, training loss = 1.734522, validation loss = 2.939350
2018-12-05 14:01:38,869 - INFO - epoch 2, step 47890, training loss = 2.030777, validation loss = 2.491089
2018-12-05 14:01:43,146 - INFO - epoch 2, step 47900, training loss = 1.901452, validation loss = 3.698784
2018-12-05 14:01:47,574 - INFO - epoch 2, step 47910, training loss = 2.094707, validation loss = 3.205910
2018-12-05 14:01:52,211 - INFO - epoch 2, step 47920, training loss = 1.554249, validation loss = 3.094303
2018-12-05 14:01:56,923 - INFO - epoch 2, step 47930, training loss = 1.715180, validation loss = 2.813915
2018-12-05 14:02:01,418 - INFO - epoch 2, step 47940, training loss = 1.529138, validation loss = 3.556370
2018-12-05 14:02:05,594 - INFO - epoch 2, step 47950, training loss = 1.948801, validation loss = 3.650812
2018-12-05 14:02:09,929 - INFO - epoch 2, step 47960, training loss = 1.675464, validation loss = 3.249510
2018-12-05 14:02:14,111 - INFO - epoch 2, step 47970, training loss = 1.463930, validation loss = 3.283138
2018-12-05 14:02:18,137 - INFO - epoch 2, step 47980, training loss = 1.957696, validation loss = 3.269702
2018-12-05 14:02:22,059 - INFO - epoch 2, step 47990, training loss = 1.824821, validation loss = 3.198963
2018-12-05 14:02:26,302 - INFO - epoch 2, step 48000, training loss = 1.751885, validation loss = 3.409554
2018-12-05 14:02:30,449 - INFO - epoch 2, step 48010, training loss = 1.851019, validation loss = 2.831195
2018-12-05 14:02:34,446 - INFO - epoch 2, step 48020, training loss = 2.002560, validation loss = 3.399185
2018-12-05 14:02:37,633 - INFO - epoch 2, step 48030, training loss = 2.106430, validation loss = 3.146403
2018-12-05 14:02:40,999 - INFO - epoch 2, step 48040, training loss = 1.861320, validation loss = 3.794793
2018-12-05 14:02:44,345 - INFO - epoch 2, step 48050, training loss = 1.737257, validation loss = 3.285766
2018-12-05 14:02:47,398 - INFO - epoch 2, step 48060, training loss = 1.960128, validation loss = 3.270516
2018-12-05 14:02:50,707 - INFO - epoch 2, step 48070, training loss = 1.773460, validation loss = 3.538409
2018-12-05 14:02:54,147 - INFO - epoch 2, step 48080, training loss = 2.014248, validation loss = 3.457574
2018-12-05 14:02:57,646 - INFO - epoch 2, step 48090, training loss = 1.643413, validation loss = 3.622999
2018-12-05 14:03:01,232 - INFO - epoch 2, step 48100, training loss = 1.733889, validation loss = 3.239591
2018-12-05 14:03:04,535 - INFO - epoch 2, step 48110, training loss = 1.585045, validation loss = 3.090475
2018-12-05 14:03:08,071 - INFO - epoch 2, step 48120, training loss = 1.734531, validation loss = 3.173101
2018-12-05 14:03:12,080 - INFO - epoch 2, step 48130, training loss = 1.594306, validation loss = 3.226373
2018-12-05 14:03:15,761 - INFO - epoch 2, step 48140, training loss = 1.706534, validation loss = 2.993406
2018-12-05 14:03:19,437 - INFO - epoch 2, step 48150, training loss = 1.623156, validation loss = 2.943041
2018-12-05 14:03:23,070 - INFO - epoch 2, step 48160, training loss = 1.669998, validation loss = 3.406532
2018-12-05 14:03:27,585 - INFO - epoch 2, step 48170, training loss = 1.798216, validation loss = 2.887685
2018-12-05 14:03:31,920 - INFO - epoch 2, step 48180, training loss = 1.668415, validation loss = 3.837562
2018-12-05 14:03:36,339 - INFO - epoch 2, step 48190, training loss = 1.733750, validation loss = 3.580399
2018-12-05 14:03:40,553 - INFO - epoch 2, step 48200, training loss = 1.251179, validation loss = 2.869947
2018-12-05 14:03:45,087 - INFO - epoch 2, step 48210, training loss = 1.388048, validation loss = 3.380739
2018-12-05 14:03:49,537 - INFO - epoch 2, step 48220, training loss = 1.633219, validation loss = 3.096701
2018-12-05 14:03:53,618 - INFO - epoch 2, step 48230, training loss = 1.680044, validation loss = 3.263513
2018-12-05 14:03:57,896 - INFO - epoch 2, step 48240, training loss = 1.251907, validation loss = 3.477000
2018-12-05 14:04:01,956 - INFO - epoch 2, step 48250, training loss = 1.688010, validation loss = 3.244857
2018-12-05 14:04:06,192 - INFO - epoch 2, step 48260, training loss = 1.728201, validation loss = 3.283510
2018-12-05 14:04:10,081 - INFO - epoch 2, step 48270, training loss = 1.749574, validation loss = 3.237988
2018-12-05 14:04:14,082 - INFO - epoch 2, step 48280, training loss = 1.475941, validation loss = 3.099457
2018-12-05 14:04:18,082 - INFO - epoch 2, step 48290, training loss = 1.824612, validation loss = 3.258807
2018-12-05 14:04:22,168 - INFO - epoch 2, step 48300, training loss = 1.571360, validation loss = 3.025418
2018-12-05 14:04:26,353 - INFO - epoch 2, step 48310, training loss = 2.044804, validation loss = 3.278289
2018-12-05 14:04:30,848 - INFO - epoch 2, step 48320, training loss = 1.497532, validation loss = 3.096573
2018-12-05 14:04:35,505 - INFO - epoch 2, step 48330, training loss = 1.521125, validation loss = 3.206928
2018-12-05 14:04:39,765 - INFO - epoch 2, step 48340, training loss = 1.516477, validation loss = 3.165892
2018-12-05 14:04:44,177 - INFO - epoch 2, step 48350, training loss = 1.770733, validation loss = 3.506434
2018-12-05 14:04:48,743 - INFO - epoch 2, step 48360, training loss = 1.547937, validation loss = 3.263347
2018-12-05 14:04:53,246 - INFO - epoch 2, step 48370, training loss = 1.430457, validation loss = 3.202839
2018-12-05 14:04:57,891 - INFO - epoch 2, step 48380, training loss = 1.377365, validation loss = 3.180479
2018-12-05 14:05:02,186 - INFO - epoch 2, step 48390, training loss = 1.513786, validation loss = 3.515724
2018-12-05 14:05:06,802 - INFO - epoch 2, step 48400, training loss = 1.719154, validation loss = 3.269067
2018-12-05 14:05:11,003 - INFO - epoch 2, step 48410, training loss = 1.691309, validation loss = 3.410456
2018-12-05 14:05:15,092 - INFO - epoch 2, step 48420, training loss = 1.443210, validation loss = 3.207467
2018-12-05 14:05:19,342 - INFO - epoch 2, step 48430, training loss = 1.569353, validation loss = 3.141451
2018-12-05 14:05:23,563 - INFO - epoch 2, step 48440, training loss = 1.418464, validation loss = 3.251591
2018-12-05 14:05:27,744 - INFO - epoch 2, step 48450, training loss = 1.642543, validation loss = 2.917232
2018-12-05 14:05:31,832 - INFO - epoch 2, step 48460, training loss = 1.802421, validation loss = 3.357188
2018-12-05 14:05:36,046 - INFO - epoch 2, step 48470, training loss = 2.076676, validation loss = 2.853991
2018-12-05 14:05:39,316 - INFO - epoch 2, step 48480, training loss = 1.969821, validation loss = 3.507069
2018-12-05 14:05:42,647 - INFO - epoch 2, step 48490, training loss = 1.517959, validation loss = 3.451640
2018-12-05 14:05:45,933 - INFO - epoch 2, step 48500, training loss = 1.873294, validation loss = 2.907888
2018-12-05 14:05:49,175 - INFO - epoch 2, step 48510, training loss = 1.762238, validation loss = 3.529365
2018-12-05 14:05:52,505 - INFO - epoch 2, step 48520, training loss = 1.805765, validation loss = 3.117136
2018-12-05 14:05:55,738 - INFO - epoch 2, step 48530, training loss = 1.964534, validation loss = 2.733751
2018-12-05 14:05:59,020 - INFO - epoch 2, step 48540, training loss = 1.714545, validation loss = 3.436242
2018-12-05 14:06:02,467 - INFO - epoch 2, step 48550, training loss = 1.777226, validation loss = 3.518774
2018-12-05 14:06:05,722 - INFO - epoch 2, step 48560, training loss = 1.372233, validation loss = 3.163427
2018-12-05 14:06:09,097 - INFO - epoch 2, step 48570, training loss = 1.725678, validation loss = 2.884249
2018-12-05 14:06:12,765 - INFO - epoch 2, step 48580, training loss = 1.643418, validation loss = 2.945805
2018-12-05 14:06:16,307 - INFO - epoch 2, step 48590, training loss = 1.562346, validation loss = 3.138059
2018-12-05 14:06:19,794 - INFO - epoch 2, step 48600, training loss = 1.485250, validation loss = 3.025084
2018-12-05 14:06:23,227 - INFO - epoch 2, step 48610, training loss = 1.270190, validation loss = 3.630517
2018-12-05 14:06:26,484 - INFO - epoch 2, step 48620, training loss = 2.025196, validation loss = 2.914728
2018-12-05 14:06:30,541 - INFO - epoch 2, step 48630, training loss = 1.741954, validation loss = 3.145158
2018-12-05 14:06:34,656 - INFO - epoch 2, step 48640, training loss = 1.617311, validation loss = 3.279519
2018-12-05 14:06:38,599 - INFO - epoch 2, step 48650, training loss = 1.446072, validation loss = 3.458400
2018-12-05 14:06:42,749 - INFO - epoch 2, step 48660, training loss = 1.628545, validation loss = 2.775108
2018-12-05 14:06:46,883 - INFO - epoch 2, step 48670, training loss = 1.574138, validation loss = 3.312943
2018-12-05 14:06:50,998 - INFO - epoch 2, step 48680, training loss = 1.486685, validation loss = 3.650817
2018-12-05 14:06:55,327 - INFO - epoch 2, step 48690, training loss = 1.607427, validation loss = 3.303819
2018-12-05 14:06:59,370 - INFO - epoch 2, step 48700, training loss = 1.789799, validation loss = 3.451639
2018-12-05 14:07:03,625 - INFO - epoch 2, step 48710, training loss = 1.687867, validation loss = 3.202784
2018-12-05 14:07:07,729 - INFO - epoch 2, step 48720, training loss = 1.648825, validation loss = 3.345919
2018-12-05 14:07:11,951 - INFO - epoch 2, step 48730, training loss = 1.851045, validation loss = 3.579167
2018-12-05 14:07:16,153 - INFO - epoch 2, step 48740, training loss = 1.632445, validation loss = 3.476920
2018-12-05 14:07:20,262 - INFO - epoch 2, step 48750, training loss = 1.597390, validation loss = 3.257212
2018-12-05 14:07:24,527 - INFO - epoch 2, step 48760, training loss = 1.220405, validation loss = 3.445508
2018-12-05 14:07:28,490 - INFO - epoch 2, step 48770, training loss = 1.622365, validation loss = 3.416109
2018-12-05 14:07:32,651 - INFO - epoch 2, step 48780, training loss = 1.859135, validation loss = 2.690503
2018-12-05 14:07:37,199 - INFO - epoch 2, step 48790, training loss = 1.971377, validation loss = 2.815092
2018-12-05 14:07:41,783 - INFO - epoch 2, step 48800, training loss = 1.362009, validation loss = 3.212450
2018-12-05 14:07:46,053 - INFO - epoch 2, step 48810, training loss = 1.755836, validation loss = 3.122854
2018-12-05 14:07:50,350 - INFO - epoch 2, step 48820, training loss = 1.562399, validation loss = 3.006351
2018-12-05 14:07:54,775 - INFO - epoch 2, step 48830, training loss = 1.737386, validation loss = 3.071553
2018-12-05 14:07:59,129 - INFO - epoch 2, step 48840, training loss = 1.816847, validation loss = 2.829937
2018-12-05 14:08:03,478 - INFO - epoch 2, step 48850, training loss = 1.941252, validation loss = 3.412262
2018-12-05 14:08:07,539 - INFO - epoch 2, step 48860, training loss = 1.648367, validation loss = 3.227162
2018-12-05 14:08:11,430 - INFO - epoch 2, step 48870, training loss = 1.761763, validation loss = 3.060383
2018-12-05 14:08:15,127 - INFO - epoch 2, step 48880, training loss = 1.796326, validation loss = 3.206488
2018-12-05 14:08:19,219 - INFO - epoch 2, step 48890, training loss = 1.273057, validation loss = 3.555549
2018-12-05 14:08:23,368 - INFO - epoch 2, step 48900, training loss = 1.833921, validation loss = 2.888522
2018-12-05 14:08:27,211 - INFO - epoch 2, step 48910, training loss = 1.533516, validation loss = 3.456821
2018-12-05 14:08:31,003 - INFO - epoch 2, step 48920, training loss = 1.797749, validation loss = 3.611260
2018-12-05 14:08:34,678 - INFO - epoch 2, step 48930, training loss = 1.950905, validation loss = 3.593922
2018-12-05 14:08:38,426 - INFO - epoch 2, step 48940, training loss = 1.805029, validation loss = 3.298654
2018-12-05 14:08:42,507 - INFO - epoch 2, step 48950, training loss = 1.726354, validation loss = 3.286093
2018-12-05 14:08:46,208 - INFO - epoch 2, step 48960, training loss = 1.460937, validation loss = 3.189073
2018-12-05 14:08:49,839 - INFO - epoch 2, step 48970, training loss = 1.478489, validation loss = 3.484089
2018-12-05 14:08:53,687 - INFO - epoch 2, step 48980, training loss = 1.330086, validation loss = 3.054319
2018-12-05 14:08:57,225 - INFO - epoch 2, step 48990, training loss = 2.097185, validation loss = 3.187923
2018-12-05 14:09:00,549 - INFO - epoch 2, step 49000, training loss = 1.937550, validation loss = 3.022549
2018-12-05 14:09:03,927 - INFO - epoch 2, step 49010, training loss = 1.597857, validation loss = 2.686797
2018-12-05 14:09:07,287 - INFO - epoch 2, step 49020, training loss = 1.813419, validation loss = 3.313617
2018-12-05 14:09:10,500 - INFO - epoch 2, step 49030, training loss = 2.089602, validation loss = 3.354195
2018-12-05 14:09:13,696 - INFO - epoch 2, step 49040, training loss = 1.762316, validation loss = 3.011777
2018-12-05 14:09:17,379 - INFO - epoch 2, step 49050, training loss = 1.508776, validation loss = 3.120492
2018-12-05 14:09:21,433 - INFO - epoch 2, step 49060, training loss = 1.636346, validation loss = 3.423790
2018-12-05 14:09:25,294 - INFO - epoch 2, step 49070, training loss = 1.860980, validation loss = 3.031638
2018-12-05 14:09:29,353 - INFO - epoch 2, step 49080, training loss = 1.428462, validation loss = 3.458165
2018-12-05 14:09:33,182 - INFO - epoch 2, step 49090, training loss = 1.652931, validation loss = 3.249045
2018-12-05 14:09:36,984 - INFO - epoch 2, step 49100, training loss = 1.816680, validation loss = 3.357327
2018-12-05 14:09:40,815 - INFO - epoch 2, step 49110, training loss = 1.848913, validation loss = 3.367735
2018-12-05 14:09:44,721 - INFO - epoch 2, step 49120, training loss = 1.678549, validation loss = 3.200547
2018-12-05 14:09:48,457 - INFO - epoch 2, step 49130, training loss = 1.467396, validation loss = 3.111251
2018-12-05 14:09:52,081 - INFO - epoch 2, step 49140, training loss = 1.590977, validation loss = 3.610271
2018-12-05 14:09:55,672 - INFO - epoch 2, step 49150, training loss = 1.562564, validation loss = 3.090059
2018-12-05 14:09:59,124 - INFO - epoch 2, step 49160, training loss = 1.906508, validation loss = 3.088819
2018-12-05 14:10:02,624 - INFO - epoch 2, step 49170, training loss = 1.466180, validation loss = 3.442237
2018-12-05 14:10:06,231 - INFO - epoch 2, step 49180, training loss = 1.754753, validation loss = 3.389443
2018-12-05 14:10:09,882 - INFO - epoch 2, step 49190, training loss = 1.482202, validation loss = 3.103517
2018-12-05 14:10:14,151 - INFO - epoch 2, step 49200, training loss = 1.858128, validation loss = 2.922952
2018-12-05 14:10:18,352 - INFO - epoch 2, step 49210, training loss = 1.527070, validation loss = 2.723424
2018-12-05 14:10:22,680 - INFO - epoch 2, step 49220, training loss = 1.659317, validation loss = 2.491108
2018-12-05 14:10:27,014 - INFO - epoch 2, step 49230, training loss = 1.598888, validation loss = 3.126565
2018-12-05 14:10:31,147 - INFO - epoch 2, step 49240, training loss = 1.526439, validation loss = 3.281225
2018-12-05 14:10:35,252 - INFO - epoch 2, step 49250, training loss = 1.627723, validation loss = 3.138569
2018-12-05 14:10:39,497 - INFO - epoch 2, step 49260, training loss = 1.538763, validation loss = 2.664585
2018-12-05 14:10:43,813 - INFO - epoch 2, step 49270, training loss = 1.587916, validation loss = 2.920954
2018-12-05 14:10:47,277 - INFO - epoch 2, step 49280, training loss = 1.802155, validation loss = 3.367536
2018-12-05 14:10:50,914 - INFO - epoch 2, step 49290, training loss = 1.769198, validation loss = 2.747736
2018-12-05 14:10:54,404 - INFO - epoch 2, step 49300, training loss = 1.622295, validation loss = 3.558902
2018-12-05 14:10:57,768 - INFO - epoch 2, step 49310, training loss = 1.577153, validation loss = 3.467281
2018-12-05 14:11:01,425 - INFO - epoch 2, step 49320, training loss = 1.799870, validation loss = 3.248699
2018-12-05 14:11:04,826 - INFO - epoch 2, step 49330, training loss = 1.725793, validation loss = 3.934332
2018-12-05 14:11:08,515 - INFO - epoch 2, step 49340, training loss = 1.848092, validation loss = 3.080476
2018-12-05 14:11:11,902 - INFO - epoch 2, step 49350, training loss = 1.788140, validation loss = 3.137750
2018-12-05 14:11:15,248 - INFO - epoch 2, step 49360, training loss = 1.682734, validation loss = 3.187605
2018-12-05 14:11:18,653 - INFO - epoch 2, step 49370, training loss = 1.783529, validation loss = 3.337377
2018-12-05 14:11:21,993 - INFO - epoch 2, step 49380, training loss = 1.551725, validation loss = 3.068931
2018-12-05 14:11:25,521 - INFO - epoch 2, step 49390, training loss = 1.477417, validation loss = 3.353067
2018-12-05 14:11:29,245 - INFO - epoch 2, step 49400, training loss = 1.762542, validation loss = 3.191543
2018-12-05 14:11:32,467 - INFO - epoch 2, step 49410, training loss = 2.140807, validation loss = 3.133569
2018-12-05 14:11:35,489 - INFO - epoch 2, step 49420, training loss = 1.714059, validation loss = 3.130101
2018-12-05 14:11:38,632 - INFO - epoch 2, step 49430, training loss = 1.682661, validation loss = 3.368699
2018-12-05 14:11:41,798 - INFO - epoch 2, step 49440, training loss = 1.878955, validation loss = 4.031519
2018-12-05 14:11:45,157 - INFO - epoch 2, step 49450, training loss = 1.986229, validation loss = 2.631952
2018-12-05 14:11:48,514 - INFO - epoch 2, step 49460, training loss = 1.752184, validation loss = 3.302893
2018-12-05 14:11:51,725 - INFO - epoch 2, step 49470, training loss = 1.937561, validation loss = 3.048316
2018-12-05 14:11:55,031 - INFO - epoch 2, step 49480, training loss = 1.658604, validation loss = 2.735352
2018-12-05 14:11:59,058 - INFO - epoch 2, step 49490, training loss = 1.804691, validation loss = 3.117792
2018-12-05 14:12:02,580 - INFO - epoch 2, step 49500, training loss = 1.902750, validation loss = 3.501077
2018-12-05 14:12:05,917 - INFO - epoch 2, step 49510, training loss = 1.525029, validation loss = 3.186561
2018-12-05 14:12:09,212 - INFO - epoch 2, step 49520, training loss = 1.619549, validation loss = 3.102533
2018-12-05 14:12:12,321 - INFO - epoch 2, step 49530, training loss = 1.986019, validation loss = 2.722760
2018-12-05 14:12:15,506 - INFO - epoch 2, step 49540, training loss = 1.909379, validation loss = 3.605541
2018-12-05 14:12:18,748 - INFO - epoch 2, step 49550, training loss = 1.924668, validation loss = 2.932148
2018-12-05 14:12:21,831 - INFO - epoch 2, step 49560, training loss = 1.650409, validation loss = 3.332216
2018-12-05 14:12:25,409 - INFO - epoch 2, step 49570, training loss = 1.435332, validation loss = 3.873702
2018-12-05 14:12:29,057 - INFO - epoch 2, step 49580, training loss = 1.925655, validation loss = 2.759618
2018-12-05 14:12:32,464 - INFO - epoch 2, step 49590, training loss = 1.645378, validation loss = 3.058807
2018-12-05 14:12:36,078 - INFO - epoch 2, step 49600, training loss = 1.460234, validation loss = 2.882985
2018-12-05 14:12:39,681 - INFO - epoch 2, step 49610, training loss = 1.519004, validation loss = 3.096260
2018-12-05 14:12:43,148 - INFO - epoch 2, step 49620, training loss = 1.481103, validation loss = 2.997429
2018-12-05 14:12:47,013 - INFO - epoch 2, step 49630, training loss = 1.623666, validation loss = 2.884881
2018-12-05 14:12:51,328 - INFO - epoch 2, step 49640, training loss = 1.487978, validation loss = 3.135870
2018-12-05 14:12:55,861 - INFO - epoch 2, step 49650, training loss = 1.669518, validation loss = 3.459112
2018-12-05 14:13:00,331 - INFO - epoch 2, step 49660, training loss = 1.990839, validation loss = 3.266507
2018-12-05 14:13:04,866 - INFO - epoch 2, step 49670, training loss = 1.720703, validation loss = 2.887625
2018-12-05 14:13:09,404 - INFO - epoch 2, step 49680, training loss = 1.329840, validation loss = 3.119388
2018-12-05 14:13:13,864 - INFO - epoch 2, step 49690, training loss = 1.467747, validation loss = 3.260551
2018-12-05 14:13:18,413 - INFO - epoch 2, step 49700, training loss = 1.791612, validation loss = 3.446301
2018-12-05 14:13:22,868 - INFO - epoch 2, step 49710, training loss = 1.745758, validation loss = 2.742064
2018-12-05 14:13:27,225 - INFO - epoch 2, step 49720, training loss = 1.604225, validation loss = 3.260307
2018-12-05 14:13:31,351 - INFO - epoch 2, step 49730, training loss = 1.664413, validation loss = 3.364425
2018-12-05 14:13:35,885 - INFO - epoch 2, step 49740, training loss = 1.521723, validation loss = 3.728354
2018-12-05 14:13:40,327 - INFO - epoch 2, step 49750, training loss = 1.681927, validation loss = 4.077619
2018-12-05 14:13:44,606 - INFO - epoch 2, step 49760, training loss = 1.536439, validation loss = 3.029644
2018-12-05 14:13:48,968 - INFO - epoch 2, step 49770, training loss = 1.674262, validation loss = 3.189843
2018-12-05 14:13:53,499 - INFO - epoch 2, step 49780, training loss = 1.500124, validation loss = 2.775365
2018-12-05 14:13:57,696 - INFO - epoch 2, step 49790, training loss = 1.728331, validation loss = 3.176543
2018-12-05 14:14:01,027 - INFO - epoch 2, step 49800, training loss = 1.902625, validation loss = 3.166781
2018-12-05 14:14:04,393 - INFO - epoch 2, step 49810, training loss = 1.697895, validation loss = 2.659465
2018-12-05 14:14:07,667 - INFO - epoch 2, step 49820, training loss = 1.894491, validation loss = 3.131722
2018-12-05 14:14:11,186 - INFO - epoch 2, step 49830, training loss = 1.598876, validation loss = 3.551441
2018-12-05 14:14:14,478 - INFO - epoch 2, step 49840, training loss = 1.700232, validation loss = 3.374949
2018-12-05 14:14:17,884 - INFO - epoch 2, step 49850, training loss = 1.586723, validation loss = 3.243565
2018-12-05 14:14:21,484 - INFO - epoch 2, step 49860, training loss = 1.498147, validation loss = 2.887619
2018-12-05 14:14:25,083 - INFO - epoch 2, step 49870, training loss = 1.561073, validation loss = 3.164930
2018-12-05 14:14:28,870 - INFO - epoch 2, step 49880, training loss = 1.676348, validation loss = 3.276258
2018-12-05 14:14:32,510 - INFO - epoch 2, step 49890, training loss = 1.464312, validation loss = 2.649467
2018-12-05 14:14:36,181 - INFO - epoch 2, step 49900, training loss = 1.736124, validation loss = 3.005320
2018-12-05 14:14:39,992 - INFO - epoch 2, step 49910, training loss = 1.784485, validation loss = 2.931799
2018-12-05 14:14:43,584 - INFO - epoch 2, step 49920, training loss = 1.599376, validation loss = 3.023504
2018-12-05 14:14:47,829 - INFO - epoch 2, step 49930, training loss = 1.714823, validation loss = 2.947351
2018-12-05 14:14:52,041 - INFO - epoch 2, step 49940, training loss = 1.398081, validation loss = 3.264288
2018-12-05 14:14:56,247 - INFO - epoch 2, step 49950, training loss = 1.321872, validation loss = 2.886027
2018-12-05 14:15:00,548 - INFO - epoch 2, step 49960, training loss = 1.673624, validation loss = 3.186865
2018-12-05 14:15:04,433 - INFO - epoch 2, step 49970, training loss = 2.010919, validation loss = 3.173033
2018-12-05 14:15:08,664 - INFO - epoch 2, step 49980, training loss = 1.572776, validation loss = 3.414378
2018-12-05 14:15:12,888 - INFO - epoch 2, step 49990, training loss = 1.755445, validation loss = 3.031389
2018-12-05 14:15:17,169 - INFO - epoch 2, step 50000, training loss = 1.585593, validation loss = 3.634843
2018-12-05 14:15:21,381 - INFO - epoch 2, step 50010, training loss = 1.694844, validation loss = 3.260157
2018-12-05 14:15:25,746 - INFO - epoch 2, step 50020, training loss = 1.613070, validation loss = 2.988877
2018-12-05 14:15:30,118 - INFO - epoch 2, step 50030, training loss = 1.344905, validation loss = 3.265326
2018-12-05 14:15:34,070 - INFO - epoch 2, step 50040, training loss = 1.771463, validation loss = 3.467543
2018-12-05 14:15:38,366 - INFO - epoch 2, step 50050, training loss = 1.497021, validation loss = 2.855747
2018-12-05 14:15:42,764 - INFO - epoch 2, step 50060, training loss = 1.661467, validation loss = 3.135049
2018-12-05 14:15:47,074 - INFO - epoch 2, step 50070, training loss = 1.621282, validation loss = 3.335903
2018-12-05 14:15:51,686 - INFO - epoch 2, step 50080, training loss = 1.706642, validation loss = 3.216313
2018-12-05 14:15:54,854 - INFO - epoch 2, step 50090, training loss = 1.906316, validation loss = 3.102739
2018-12-05 14:15:58,265 - INFO - epoch 2, step 50100, training loss = 1.589105, validation loss = 2.930531
2018-12-05 14:16:01,589 - INFO - epoch 2, step 50110, training loss = 1.447677, validation loss = 2.930681
2018-12-05 14:16:04,869 - INFO - epoch 2, step 50120, training loss = 1.673252, validation loss = 3.328157
2018-12-05 14:16:08,392 - INFO - epoch 2, step 50130, training loss = 1.266284, validation loss = 3.212473
2018-12-05 14:16:11,797 - INFO - epoch 2, step 50140, training loss = 1.738579, validation loss = 2.973629
2018-12-05 14:16:15,892 - INFO - epoch 2, step 50150, training loss = 1.120563, validation loss = 3.324090
2018-12-05 14:16:20,224 - INFO - epoch 2, step 50160, training loss = 1.438413, validation loss = 2.801630
2018-12-05 14:16:24,530 - INFO - epoch 2, step 50170, training loss = 1.553306, validation loss = 2.837961
2018-12-05 14:16:28,903 - INFO - epoch 2, step 50180, training loss = 1.448271, validation loss = 3.388550
2018-12-05 14:16:33,140 - INFO - epoch 2, step 50190, training loss = 1.715172, validation loss = 2.693825
2018-12-05 14:16:37,442 - INFO - epoch 2, step 50200, training loss = 1.634504, validation loss = 3.129553
2018-12-05 14:16:41,706 - INFO - epoch 2, step 50210, training loss = 1.277330, validation loss = 3.701380
2018-12-05 14:16:45,939 - INFO - epoch 2, step 50220, training loss = 1.268005, validation loss = 3.074638
2018-12-05 14:16:50,050 - INFO - epoch 2, step 50230, training loss = 1.323262, validation loss = 3.221592
2018-12-05 14:16:54,652 - INFO - epoch 2, step 50240, training loss = 1.562446, validation loss = 3.001358
2018-12-05 14:16:58,941 - INFO - epoch 2, step 50250, training loss = 1.868844, validation loss = 3.232152
2018-12-05 14:17:03,279 - INFO - epoch 2, step 50260, training loss = 1.555818, validation loss = 3.339063
2018-12-05 14:17:07,490 - INFO - epoch 2, step 50270, training loss = 1.774704, validation loss = 3.070798
2018-12-05 14:17:11,900 - INFO - epoch 2, step 50280, training loss = 1.708154, validation loss = 2.549972
2018-12-05 14:17:16,393 - INFO - epoch 2, step 50290, training loss = 1.483849, validation loss = 3.694401
2018-12-05 14:17:20,741 - INFO - epoch 2, step 50300, training loss = 1.491515, validation loss = 3.181095
2018-12-05 14:17:25,211 - INFO - epoch 2, step 50310, training loss = 1.559919, validation loss = 3.498841
2018-12-05 14:17:29,457 - INFO - epoch 2, step 50320, training loss = 1.692728, validation loss = 3.295693
2018-12-05 14:17:33,839 - INFO - epoch 2, step 50330, training loss = 1.637766, validation loss = 3.260455
2018-12-05 14:17:38,071 - INFO - epoch 2, step 50340, training loss = 1.461119, validation loss = 3.066301
2018-12-05 14:17:42,741 - INFO - epoch 2, step 50350, training loss = 1.531317, validation loss = 3.148960
2018-12-05 14:17:47,416 - INFO - epoch 2, step 50360, training loss = 1.569842, validation loss = 3.372626
2018-12-05 14:17:51,587 - INFO - epoch 2, step 50370, training loss = 1.633834, validation loss = 3.489594
2018-12-05 14:17:55,689 - INFO - epoch 2, step 50380, training loss = 1.690723, validation loss = 3.579000
2018-12-05 14:17:59,968 - INFO - epoch 2, step 50390, training loss = 1.633943, validation loss = 3.121090
2018-12-05 14:18:04,377 - INFO - epoch 2, step 50400, training loss = 1.575240, validation loss = 3.359039
2018-12-05 14:18:08,306 - INFO - epoch 2, step 50410, training loss = 1.740858, validation loss = 2.722636
2018-12-05 14:18:12,297 - INFO - epoch 2, step 50420, training loss = 1.636026, validation loss = 3.475142
2018-12-05 14:18:16,036 - INFO - epoch 2, step 50430, training loss = 1.738595, validation loss = 3.745301
2018-12-05 14:18:19,820 - INFO - epoch 2, step 50440, training loss = 1.906717, validation loss = 3.163215
2018-12-05 14:18:23,531 - INFO - epoch 2, step 50450, training loss = 1.549271, validation loss = 3.193459
2018-12-05 14:18:27,417 - INFO - epoch 2, step 50460, training loss = 1.347686, validation loss = 2.977303
2018-12-05 14:18:31,372 - INFO - epoch 2, step 50470, training loss = 1.447235, validation loss = 2.836926
2018-12-05 14:18:34,668 - INFO - epoch 2, step 50480, training loss = 1.845288, validation loss = 3.489275
2018-12-05 14:18:37,908 - INFO - epoch 2, step 50490, training loss = 2.157054, validation loss = 2.728726
2018-12-05 14:18:40,957 - INFO - epoch 2, step 50500, training loss = 1.953033, validation loss = 3.341142
2018-12-05 14:18:44,269 - INFO - epoch 2, step 50510, training loss = 1.476250, validation loss = 3.418345
2018-12-05 14:18:47,431 - INFO - epoch 2, step 50520, training loss = 1.509036, validation loss = 3.382117
2018-12-05 14:18:50,837 - INFO - epoch 2, step 50530, training loss = 1.701267, validation loss = 3.100946
2018-12-05 14:18:54,130 - INFO - epoch 2, step 50540, training loss = 1.417160, validation loss = 2.985778
2018-12-05 14:18:57,371 - INFO - epoch 2, step 50550, training loss = 1.978926, validation loss = 3.580657
2018-12-05 14:19:01,486 - INFO - epoch 2, step 50560, training loss = 1.225506, validation loss = 2.705525
2018-12-05 14:19:05,858 - INFO - epoch 2, step 50570, training loss = 1.541275, validation loss = 3.582133
2018-12-05 14:19:09,927 - INFO - epoch 2, step 50580, training loss = 1.875252, validation loss = 3.239407
2018-12-05 14:19:14,130 - INFO - epoch 2, step 50590, training loss = 1.638862, validation loss = 3.009194
2018-12-05 14:19:18,467 - INFO - epoch 2, step 50600, training loss = 1.575214, validation loss = 3.356867
2018-12-05 14:19:22,608 - INFO - epoch 2, step 50610, training loss = 1.137526, validation loss = 3.221506
2018-12-05 14:19:26,611 - INFO - epoch 2, step 50620, training loss = 1.657346, validation loss = 3.033280
2018-12-05 14:19:30,781 - INFO - epoch 2, step 50630, training loss = 1.750523, validation loss = 3.353838
2018-12-05 14:19:35,230 - INFO - epoch 2, step 50640, training loss = 1.549765, validation loss = 2.990580
2018-12-05 14:19:39,772 - INFO - epoch 2, step 50650, training loss = 1.739649, validation loss = 3.236535
2018-12-05 14:19:44,304 - INFO - epoch 2, step 50660, training loss = 1.492537, validation loss = 3.706412
2018-12-05 14:19:48,558 - INFO - epoch 2, step 50670, training loss = 1.350193, validation loss = 3.780456
2018-12-05 14:19:52,868 - INFO - epoch 2, step 50680, training loss = 1.424117, validation loss = 3.729309
2018-12-05 14:19:57,149 - INFO - epoch 2, step 50690, training loss = 1.478267, validation loss = 2.882508
2018-12-05 14:20:00,816 - INFO - epoch 2, step 50700, training loss = 1.645138, validation loss = 3.436510
2018-12-05 14:20:04,693 - INFO - epoch 2, step 50710, training loss = 1.917212, validation loss = 3.406138
2018-12-05 14:20:08,333 - INFO - epoch 2, step 50720, training loss = 1.483351, validation loss = 3.054906
2018-12-05 14:20:11,800 - INFO - epoch 2, step 50730, training loss = 1.640371, validation loss = 3.348369
2018-12-05 14:20:15,430 - INFO - epoch 2, step 50740, training loss = 1.680141, validation loss = 2.834939
2018-12-05 14:20:18,998 - INFO - epoch 2, step 50750, training loss = 1.418248, validation loss = 2.914229
2018-12-05 14:20:22,688 - INFO - epoch 2, step 50760, training loss = 1.446390, validation loss = 3.079299
2018-12-05 14:20:26,231 - INFO - epoch 2, step 50770, training loss = 1.747936, validation loss = 3.541537
2018-12-05 14:20:29,573 - INFO - epoch 2, step 50780, training loss = 1.454353, validation loss = 2.973493
2018-12-05 14:20:33,032 - INFO - epoch 2, step 50790, training loss = 1.991195, validation loss = 3.759497
2018-12-05 14:20:36,644 - INFO - epoch 2, step 50800, training loss = 1.766898, validation loss = 2.823635
2018-12-05 14:20:40,216 - INFO - epoch 2, step 50810, training loss = 1.788629, validation loss = 3.402259
2018-12-05 14:20:43,768 - INFO - epoch 2, step 50820, training loss = 1.430817, validation loss = 3.620617
2018-12-05 14:20:47,331 - INFO - epoch 2, step 50830, training loss = 1.922953, validation loss = 3.172005
2018-12-05 14:20:50,833 - INFO - epoch 2, step 50840, training loss = 1.349311, validation loss = 2.908892
2018-12-05 14:20:54,321 - INFO - epoch 2, step 50850, training loss = 1.311778, validation loss = 3.430980
2018-12-05 14:20:57,926 - INFO - epoch 2, step 50860, training loss = 1.560299, validation loss = 3.017103
2018-12-05 14:21:01,735 - INFO - epoch 2, step 50870, training loss = 1.478778, validation loss = 3.570195
2018-12-05 14:21:05,406 - INFO - epoch 2, step 50880, training loss = 1.425367, validation loss = 3.842927
2018-12-05 14:21:08,959 - INFO - epoch 2, step 50890, training loss = 1.685171, validation loss = 3.126251
2018-12-05 14:21:13,034 - INFO - epoch 2, step 50900, training loss = 1.648280, validation loss = 3.432550
2018-12-05 14:21:16,635 - INFO - epoch 2, step 50910, training loss = 1.617711, validation loss = 3.269742
2018-12-05 14:21:20,161 - INFO - epoch 2, step 50920, training loss = 1.391912, validation loss = 3.434358
2018-12-05 14:21:23,715 - INFO - epoch 2, step 50930, training loss = 1.650495, validation loss = 3.391751
2018-12-05 14:21:27,357 - INFO - epoch 2, step 50940, training loss = 1.418310, validation loss = 2.873267
2018-12-05 14:21:30,847 - INFO - epoch 2, step 50950, training loss = 1.491604, validation loss = 3.045057
2018-12-05 14:21:34,596 - INFO - epoch 2, step 50960, training loss = 1.690421, validation loss = 2.809215
2018-12-05 14:21:38,108 - INFO - epoch 2, step 50970, training loss = 1.574749, validation loss = 3.735976
2018-12-05 14:21:41,631 - INFO - epoch 2, step 50980, training loss = 1.921121, validation loss = 3.106953
2018-12-05 14:21:45,167 - INFO - epoch 2, step 50990, training loss = 1.736485, validation loss = 3.161755
2018-12-05 14:21:48,501 - INFO - epoch 2, step 51000, training loss = 2.150286, validation loss = 3.348420
2018-12-05 14:21:52,077 - INFO - epoch 2, step 51010, training loss = 1.548407, validation loss = 3.370363
2018-12-05 14:21:55,714 - INFO - epoch 2, step 51020, training loss = 1.420502, validation loss = 3.219948
2018-12-05 14:21:59,032 - INFO - epoch 2, step 51030, training loss = 1.798281, validation loss = 3.028319
2018-12-05 14:22:02,541 - INFO - epoch 2, step 51040, training loss = 1.537769, validation loss = 3.181814
2018-12-05 14:22:06,362 - INFO - epoch 2, step 51050, training loss = 1.822536, validation loss = 3.067317
2018-12-05 14:22:10,300 - INFO - epoch 2, step 51060, training loss = 1.790739, validation loss = 3.703395
2018-12-05 14:22:14,267 - INFO - epoch 2, step 51070, training loss = 1.777488, validation loss = 3.309142
2018-12-05 14:22:18,290 - INFO - epoch 2, step 51080, training loss = 1.339338, validation loss = 2.902425
2018-12-05 14:22:22,482 - INFO - epoch 2, step 51090, training loss = 1.816845, validation loss = 3.451472
2018-12-05 14:22:26,672 - INFO - epoch 2, step 51100, training loss = 1.546838, validation loss = 3.287179
2018-12-05 14:22:30,721 - INFO - epoch 2, step 51110, training loss = 1.735785, validation loss = 3.203014
2018-12-05 14:22:34,837 - INFO - epoch 2, step 51120, training loss = 1.446036, validation loss = 3.463679
2018-12-05 14:22:38,775 - INFO - epoch 2, step 51130, training loss = 1.311679, validation loss = 3.214031
2018-12-05 14:22:42,542 - INFO - epoch 2, step 51140, training loss = 1.431582, validation loss = 2.967548
2018-12-05 14:22:46,418 - INFO - epoch 2, step 51150, training loss = 1.259724, validation loss = 3.290935
2018-12-05 14:22:50,379 - INFO - epoch 2, step 51160, training loss = 1.236842, validation loss = 3.084735
2018-12-05 14:22:54,263 - INFO - epoch 2, step 51170, training loss = 1.678801, validation loss = 3.375744
2018-12-05 14:22:58,069 - INFO - epoch 2, step 51180, training loss = 1.833765, validation loss = 2.814827
2018-12-05 14:23:01,674 - INFO - epoch 2, step 51190, training loss = 1.572414, validation loss = 3.610945
2018-12-05 14:23:05,412 - INFO - epoch 2, step 51200, training loss = 1.582479, validation loss = 2.757770
2018-12-05 14:23:09,038 - INFO - epoch 2, step 51210, training loss = 1.720665, validation loss = 3.265069
2018-12-05 14:23:12,499 - INFO - epoch 2, step 51220, training loss = 1.459740, validation loss = 3.329944
2018-12-05 14:23:16,272 - INFO - epoch 2, step 51230, training loss = 1.641191, validation loss = 2.987041
2018-12-05 14:23:19,861 - INFO - epoch 2, step 51240, training loss = 1.591177, validation loss = 3.265160
2018-12-05 14:23:23,574 - INFO - epoch 2, step 51250, training loss = 1.504133, validation loss = 2.789312
2018-12-05 14:23:27,065 - INFO - epoch 2, step 51260, training loss = 1.394701, validation loss = 3.201623
2018-12-05 14:23:30,359 - INFO - epoch 2, step 51270, training loss = 1.844985, validation loss = 3.302398
2018-12-05 14:23:33,831 - INFO - epoch 2, step 51280, training loss = 1.922572, validation loss = 3.506233
2018-12-05 14:23:37,270 - INFO - epoch 2, step 51290, training loss = 1.614488, validation loss = 3.312555
2018-12-05 14:23:40,728 - INFO - epoch 2, step 51300, training loss = 1.828791, validation loss = 3.485772
2018-12-05 14:23:43,893 - INFO - epoch 2, step 51310, training loss = 1.748706, validation loss = 3.393954
2018-12-05 14:23:47,049 - INFO - epoch 2, step 51320, training loss = 1.733317, validation loss = 3.635247
2018-12-05 14:23:50,272 - INFO - epoch 2, step 51330, training loss = 1.738002, validation loss = 3.216388
2018-12-05 14:23:53,477 - INFO - epoch 2, step 51340, training loss = 1.874203, validation loss = 3.283771
2018-12-05 14:23:56,594 - INFO - epoch 2, step 51350, training loss = 1.986549, validation loss = 2.860736
2018-12-05 14:23:59,712 - INFO - epoch 2, step 51360, training loss = 1.545266, validation loss = 3.728771
2018-12-05 14:24:03,056 - INFO - epoch 2, step 51370, training loss = 1.902913, validation loss = 3.175825
2018-12-05 14:24:06,304 - INFO - epoch 2, step 51380, training loss = 1.770584, validation loss = 3.119351
2018-12-05 14:24:09,526 - INFO - epoch 2, step 51390, training loss = 1.689181, validation loss = 3.217013
2018-12-05 14:24:12,644 - INFO - epoch 2, step 51400, training loss = 1.851959, validation loss = 3.240920
2018-12-05 14:24:15,923 - INFO - epoch 2, step 51410, training loss = 2.016894, validation loss = 2.759001
2018-12-05 14:24:19,347 - INFO - epoch 2, step 51420, training loss = 1.779858, validation loss = 2.584069
2018-12-05 14:24:23,550 - INFO - epoch 2, step 51430, training loss = 1.283177, validation loss = 2.988855
2018-12-05 14:24:27,390 - INFO - epoch 2, step 51440, training loss = 1.445811, validation loss = 3.252825
2018-12-05 14:24:31,477 - INFO - epoch 2, step 51450, training loss = 1.462217, validation loss = 3.334048
2018-12-05 14:24:35,810 - INFO - epoch 2, step 51460, training loss = 1.604291, validation loss = 2.903450
2018-12-05 14:24:39,777 - INFO - epoch 2, step 51470, training loss = 1.629678, validation loss = 2.614067
2018-12-05 14:24:44,070 - INFO - epoch 2, step 51480, training loss = 1.522894, validation loss = 3.112445
2018-12-05 14:24:48,150 - INFO - epoch 2, step 51490, training loss = 1.499964, validation loss = 3.204544
2018-12-05 14:24:52,331 - INFO - epoch 2, step 51500, training loss = 1.491690, validation loss = 2.411606
2018-12-05 14:24:56,399 - INFO - epoch 2, step 51510, training loss = 1.657084, validation loss = 3.408918
2018-12-05 14:25:00,525 - INFO - epoch 2, step 51520, training loss = 1.721237, validation loss = 2.802115
2018-12-05 14:25:04,607 - INFO - epoch 2, step 51530, training loss = 1.176338, validation loss = 2.729259
2018-12-05 14:25:08,867 - INFO - epoch 2, step 51540, training loss = 1.526911, validation loss = 3.434403
2018-12-05 14:25:13,144 - INFO - epoch 2, step 51550, training loss = 1.611176, validation loss = 2.086891
2018-12-05 14:25:16,980 - INFO - epoch 2, step 51560, training loss = 1.707860, validation loss = 2.876864
2018-12-05 14:25:20,705 - INFO - epoch 2, step 51570, training loss = 1.821111, validation loss = 2.802297
2018-12-05 14:25:24,813 - INFO - epoch 2, step 51580, training loss = 1.749971, validation loss = 2.969695
2018-12-05 14:25:28,862 - INFO - epoch 2, step 51590, training loss = 1.709814, validation loss = 2.873511
2018-12-05 14:25:33,074 - INFO - epoch 2, step 51600, training loss = 1.632237, validation loss = 3.075395
2018-12-05 14:25:37,227 - INFO - epoch 2, step 51610, training loss = 1.560191, validation loss = 2.636402
2018-12-05 14:25:41,393 - INFO - epoch 2, step 51620, training loss = 1.855903, validation loss = 2.688505
2018-12-05 14:25:45,534 - INFO - epoch 2, step 51630, training loss = 1.927302, validation loss = 2.339906
2018-12-05 14:25:49,463 - INFO - epoch 2, step 51640, training loss = 1.442339, validation loss = 2.283946
2018-12-05 14:25:53,466 - INFO - epoch 2, step 51650, training loss = 1.567104, validation loss = 2.837835
2018-12-05 14:25:57,398 - INFO - epoch 2, step 51660, training loss = 1.693687, validation loss = 2.863827
2018-12-05 14:26:01,462 - INFO - epoch 2, step 51670, training loss = 1.388372, validation loss = 2.232626
2018-12-05 14:26:05,384 - INFO - epoch 2, step 51680, training loss = 1.592314, validation loss = 3.094850
2018-12-05 14:26:09,203 - INFO - epoch 2, step 51690, training loss = 1.225167, validation loss = 3.005875
2018-12-05 14:26:13,010 - INFO - epoch 2, step 51700, training loss = 1.639597, validation loss = 2.484271
2018-12-05 14:26:17,056 - INFO - epoch 2, step 51710, training loss = 1.441624, validation loss = 3.251296
2018-12-05 14:26:21,322 - INFO - epoch 2, step 51720, training loss = 1.341789, validation loss = 3.329032
2018-12-05 14:26:25,682 - INFO - epoch 2, step 51730, training loss = 1.271112, validation loss = 3.163743
2018-12-05 14:26:29,978 - INFO - epoch 2, step 51740, training loss = 1.776635, validation loss = 2.686118
2018-12-05 14:26:34,229 - INFO - epoch 2, step 51750, training loss = 1.544329, validation loss = 2.695214
2018-12-05 14:26:38,498 - INFO - epoch 2, step 51760, training loss = 1.282339, validation loss = 3.315410
2018-12-05 14:26:42,835 - INFO - epoch 2, step 51770, training loss = 1.696850, validation loss = 2.468857
2018-12-05 14:26:47,320 - INFO - epoch 2, step 51780, training loss = 1.502891, validation loss = 3.098712
2018-12-05 14:26:51,980 - INFO - epoch 2, step 51790, training loss = 1.916616, validation loss = 2.421839
2018-12-05 14:26:56,501 - INFO - epoch 2, step 51800, training loss = 1.675495, validation loss = 2.904466
2018-12-05 14:27:00,822 - INFO - epoch 2, step 51810, training loss = 1.778908, validation loss = 2.544253
2018-12-05 14:27:05,361 - INFO - epoch 2, step 51820, training loss = 1.481958, validation loss = 2.318454
2018-12-05 14:27:09,683 - INFO - epoch 2, step 51830, training loss = 1.715640, validation loss = 2.555030
2018-12-05 14:27:14,089 - INFO - epoch 2, step 51840, training loss = 1.415834, validation loss = 2.765170
2018-12-05 14:27:18,136 - INFO - epoch 2, step 51850, training loss = 1.885866, validation loss = 3.252464
2018-12-05 14:27:21,249 - INFO - epoch 2, step 51860, training loss = 1.590525, validation loss = 3.056585
2018-12-05 14:27:24,562 - INFO - epoch 2, step 51870, training loss = 1.877292, validation loss = 2.993170
2018-12-05 14:27:27,749 - INFO - epoch 2, step 51880, training loss = 2.043046, validation loss = 3.474376
2018-12-05 14:27:30,925 - INFO - epoch 2, step 51890, training loss = 1.472105, validation loss = 3.323117
2018-12-05 14:27:34,068 - INFO - epoch 2, step 51900, training loss = 1.660917, validation loss = 3.426808
2018-12-05 14:27:37,288 - INFO - epoch 2, step 51910, training loss = 1.570889, validation loss = 3.732811
2018-12-05 14:27:40,475 - INFO - epoch 2, step 51920, training loss = 1.638157, validation loss = 3.174282
2018-12-05 14:27:43,601 - INFO - epoch 2, step 51930, training loss = 2.044021, validation loss = 3.722517
2018-12-05 14:27:47,124 - INFO - epoch 2, step 51940, training loss = 1.744188, validation loss = 3.596374
2018-12-05 14:27:50,528 - INFO - epoch 2, step 51950, training loss = 1.655683, validation loss = 3.173012
2018-12-05 14:27:53,996 - INFO - epoch 2, step 51960, training loss = 1.907539, validation loss = 3.219729
2018-12-05 14:27:57,215 - INFO - epoch 2, step 51970, training loss = 1.701174, validation loss = 3.098104
2018-12-05 14:28:00,735 - INFO - epoch 2, step 51980, training loss = 1.630644, validation loss = 3.876038
2018-12-05 14:28:03,968 - INFO - epoch 2, step 51990, training loss = 1.741511, validation loss = 3.122118
2018-12-05 14:28:08,225 - INFO - epoch 2, step 52000, training loss = 1.820307, validation loss = 3.957632
2018-12-05 14:28:12,247 - INFO - epoch 2, step 52010, training loss = 1.515662, validation loss = 3.167650
2018-12-05 14:28:16,223 - INFO - epoch 2, step 52020, training loss = 1.475067, validation loss = 3.485954
2018-12-05 14:28:20,467 - INFO - epoch 2, step 52030, training loss = 1.505331, validation loss = 4.230803
2018-12-05 14:28:24,475 - INFO - epoch 2, step 52040, training loss = 1.869720, validation loss = 3.206384
2018-12-05 14:28:28,742 - INFO - epoch 2, step 52050, training loss = 1.731538, validation loss = 3.404957
2018-12-05 14:28:33,042 - INFO - epoch 2, step 52060, training loss = 1.386930, validation loss = 3.634252
2018-12-05 14:28:37,358 - INFO - epoch 2, step 52070, training loss = 1.781959, validation loss = 2.980539
2018-12-05 14:28:41,682 - INFO - epoch 2, step 52080, training loss = 1.364952, validation loss = 2.924363
2018-12-05 14:28:45,998 - INFO - epoch 2, step 52090, training loss = 1.499204, validation loss = 3.154741
2018-12-05 14:28:50,208 - INFO - epoch 2, step 52100, training loss = 1.467893, validation loss = 3.620141
2018-12-05 14:28:54,636 - INFO - epoch 2, step 52110, training loss = 1.424744, validation loss = 3.247629
2018-12-05 14:28:58,862 - INFO - epoch 2, step 52120, training loss = 1.457309, validation loss = 3.090734
2018-12-05 14:29:03,074 - INFO - epoch 2, step 52130, training loss = 1.482066, validation loss = 3.659407
2018-12-05 14:29:07,479 - INFO - epoch 2, step 52140, training loss = 1.441917, validation loss = 2.884164
2018-12-05 14:29:10,987 - INFO - epoch 2, step 52150, training loss = 1.466338, validation loss = 3.131852
2018-12-05 14:29:14,271 - INFO - epoch 2, step 52160, training loss = 1.894953, validation loss = 3.835619
2018-12-05 14:29:17,620 - INFO - epoch 2, step 52170, training loss = 1.676471, validation loss = 3.485000
2018-12-05 14:29:20,916 - INFO - epoch 2, step 52180, training loss = 1.848173, validation loss = 3.079712
2018-12-05 14:29:24,284 - INFO - epoch 2, step 52190, training loss = 1.417314, validation loss = 2.933897
2018-12-05 14:29:28,075 - INFO - epoch 2, step 52200, training loss = 1.688248, validation loss = 3.452287
2018-12-05 14:29:31,536 - INFO - epoch 2, step 52210, training loss = 1.782081, validation loss = 3.211223
2018-12-05 14:29:34,914 - INFO - epoch 2, step 52220, training loss = 1.592457, validation loss = 3.281881
2018-12-05 14:29:38,291 - INFO - epoch 2, step 52230, training loss = 1.649047, validation loss = 3.309071
2018-12-05 14:29:41,608 - INFO - epoch 2, step 52240, training loss = 1.810808, validation loss = 3.724680
2018-12-05 14:29:44,885 - INFO - epoch 2, step 52250, training loss = 1.943215, validation loss = 3.587759
2018-12-05 14:29:48,241 - INFO - epoch 2, step 52260, training loss = 1.547209, validation loss = 3.291136
2018-12-05 14:29:51,749 - INFO - epoch 2, step 52270, training loss = 1.579104, validation loss = 3.070482
2018-12-05 14:29:55,219 - INFO - epoch 2, step 52280, training loss = 1.186053, validation loss = 3.521910
2018-12-05 14:29:58,802 - INFO - epoch 2, step 52290, training loss = 1.684617, validation loss = 3.363280
2018-12-05 14:30:02,213 - INFO - epoch 2, step 52300, training loss = 1.634735, validation loss = 2.945926
2018-12-05 14:30:06,860 - INFO - epoch 2, step 52310, training loss = 1.720873, validation loss = 3.114190
2018-12-05 14:30:11,100 - INFO - epoch 2, step 52320, training loss = 1.852949, validation loss = 2.892687
2018-12-05 14:30:15,653 - INFO - epoch 2, step 52330, training loss = 1.761685, validation loss = 3.709458
2018-12-05 14:30:20,226 - INFO - epoch 2, step 52340, training loss = 1.351720, validation loss = 2.899161
2018-12-05 14:30:24,694 - INFO - epoch 2, step 52350, training loss = 1.385146, validation loss = 3.485081
2018-12-05 14:30:29,421 - INFO - epoch 2, step 52360, training loss = 1.527100, validation loss = 3.496695
2018-12-05 14:30:33,928 - INFO - epoch 2, step 52370, training loss = 1.411631, validation loss = 3.487167
2018-12-05 14:30:37,845 - INFO - epoch 2, step 52380, training loss = 1.675972, validation loss = 2.630152
2018-12-05 14:30:41,053 - INFO - epoch 2, step 52390, training loss = 1.702708, validation loss = 3.578941
2018-12-05 14:30:44,297 - INFO - epoch 2, step 52400, training loss = 1.774568, validation loss = 3.420471
2018-12-05 14:30:47,898 - INFO - epoch 2, step 52410, training loss = 1.637777, validation loss = 2.818036
2018-12-05 14:30:51,210 - INFO - epoch 2, step 52420, training loss = 1.886924, validation loss = 3.504066
2018-12-05 14:30:54,462 - INFO - epoch 2, step 52430, training loss = 1.703996, validation loss = 3.048345
2018-12-05 14:30:57,767 - INFO - epoch 2, step 52440, training loss = 1.468884, validation loss = 3.116652
2018-12-05 14:31:01,086 - INFO - epoch 2, step 52450, training loss = 1.801632, validation loss = 1.771590
2018-12-05 14:31:04,429 - INFO - epoch 2, step 52460, training loss = 1.557458, validation loss = 1.761297
2018-12-05 14:31:08,011 - INFO - epoch 2, step 52470, training loss = 1.694235, validation loss = 1.905585
2018-12-05 14:31:11,300 - INFO - epoch 2, step 52480, training loss = 1.555556, validation loss = 1.757398
2018-12-05 14:31:14,794 - INFO - epoch 2, step 52490, training loss = 1.658483, validation loss = 1.939195
2018-12-05 14:31:18,052 - INFO - epoch 2, step 52500, training loss = 1.383381, validation loss = 2.089112
2018-12-05 14:31:21,503 - INFO - epoch 2, step 52510, training loss = 1.575192, validation loss = 1.713922
2018-12-05 14:31:25,176 - INFO - epoch 2, step 52520, training loss = 1.748869, validation loss = 1.884124
2018-12-05 14:31:29,253 - INFO - epoch 2, step 52530, training loss = 1.395106, validation loss = 1.330017
2018-12-05 14:31:33,421 - INFO - epoch 2, step 52540, training loss = 1.810498, validation loss = 1.410413
2018-12-05 14:31:37,714 - INFO - epoch 2, step 52550, training loss = 1.679052, validation loss = 1.847771
2018-12-05 14:31:41,982 - INFO - epoch 2, step 52560, training loss = 1.752498, validation loss = 1.681037
2018-12-05 14:31:46,085 - INFO - epoch 2, step 52570, training loss = 1.731738, validation loss = 2.241103
2018-12-05 14:31:50,276 - INFO - epoch 2, step 52580, training loss = 1.690266, validation loss = 1.541849
2018-12-05 14:31:54,203 - INFO - epoch 2, step 52590, training loss = 1.547537, validation loss = 1.892730
2018-12-05 14:31:58,087 - INFO - epoch 2, step 52600, training loss = 1.810310, validation loss = 1.937538
2018-12-05 14:32:01,578 - INFO - epoch 2, step 52610, training loss = 1.780601, validation loss = 1.702965
2018-12-05 14:32:05,038 - INFO - epoch 2, step 52620, training loss = 1.442003, validation loss = 1.914960
2018-12-05 14:32:08,800 - INFO - epoch 2, step 52630, training loss = 1.300320, validation loss = 1.747090
2018-12-05 14:32:12,489 - INFO - epoch 2, step 52640, training loss = 1.510360, validation loss = 1.360780
2018-12-05 14:32:15,902 - INFO - epoch 2, step 52650, training loss = 1.626474, validation loss = 1.866012
2018-12-05 14:32:19,272 - INFO - epoch 2, step 52660, training loss = 1.773474, validation loss = 1.483723
2018-12-05 14:32:23,407 - INFO - epoch 2, step 52670, training loss = 1.706159, validation loss = 2.034657
2018-12-05 14:32:27,840 - INFO - epoch 2, step 52680, training loss = 1.649647, validation loss = 1.893129
2018-12-05 14:32:32,182 - INFO - epoch 2, step 52690, training loss = 1.606576, validation loss = 1.986205
2018-12-05 14:32:36,487 - INFO - epoch 2, step 52700, training loss = 1.578837, validation loss = 2.090349
2018-12-05 14:32:40,612 - INFO - epoch 2, step 52710, training loss = 1.640848, validation loss = 2.196847
2018-12-05 14:32:45,106 - INFO - epoch 2, step 52720, training loss = 1.055289, validation loss = 1.817392
2018-12-05 14:32:49,355 - INFO - epoch 2, step 52730, training loss = 1.680112, validation loss = 2.244105
2018-12-05 14:32:53,809 - INFO - epoch 2, step 52740, training loss = 1.675689, validation loss = 1.960632
2018-12-05 14:32:58,074 - INFO - epoch 2, step 52750, training loss = 1.588305, validation loss = 1.945785
2018-12-05 14:33:02,535 - INFO - epoch 2, step 52760, training loss = 1.349033, validation loss = 1.924636
2018-12-05 14:33:06,706 - INFO - epoch 2, step 52770, training loss = 1.630849, validation loss = 1.745214
2018-12-05 14:33:11,139 - INFO - epoch 2, step 52780, training loss = 1.694516, validation loss = 2.117657
2018-12-05 14:33:15,410 - INFO - epoch 2, step 52790, training loss = 1.489081, validation loss = 2.120462
2018-12-05 14:33:19,706 - INFO - epoch 2, step 52800, training loss = 1.614206, validation loss = 1.861960
2018-12-05 14:33:24,139 - INFO - epoch 2, step 52810, training loss = 1.547564, validation loss = 2.065040
2018-12-05 14:33:28,699 - INFO - epoch 2, step 52820, training loss = 1.719636, validation loss = 1.877609
2018-12-05 14:33:33,448 - INFO - epoch 2, step 52830, training loss = 1.413378, validation loss = 1.802900
2018-12-05 14:33:37,768 - INFO - epoch 2, step 52840, training loss = 1.893779, validation loss = 2.044663
2018-12-05 14:33:42,188 - INFO - epoch 2, step 52850, training loss = 1.623254, validation loss = 1.859140
2018-12-05 14:33:46,593 - INFO - epoch 2, step 52860, training loss = 1.667256, validation loss = 2.126267
2018-12-05 14:33:50,764 - INFO - epoch 2, step 52870, training loss = 1.679325, validation loss = 2.154633
2018-12-05 14:33:54,375 - INFO - epoch 2, step 52880, training loss = 1.525060, validation loss = 2.016621
2018-12-05 14:33:57,702 - INFO - epoch 2, step 52890, training loss = 1.638110, validation loss = 1.965881
2018-12-05 14:34:00,998 - INFO - epoch 2, step 52900, training loss = 1.598429, validation loss = 1.770608
2018-12-05 14:34:04,176 - INFO - epoch 2, step 52910, training loss = 1.809598, validation loss = 1.940952
2018-12-05 14:34:07,420 - INFO - epoch 2, step 52920, training loss = 1.727735, validation loss = 1.916777
2018-12-05 14:34:10,790 - INFO - epoch 2, step 52930, training loss = 1.373576, validation loss = 2.092307
2018-12-05 14:34:13,987 - INFO - epoch 2, step 52940, training loss = 1.598351, validation loss = 1.931314
2018-12-05 14:34:17,417 - INFO - epoch 2, step 52950, training loss = 1.522671, validation loss = 1.749176
2018-12-05 14:34:20,743 - INFO - epoch 2, step 52960, training loss = 1.742392, validation loss = 1.919716
2018-12-05 14:34:23,966 - INFO - epoch 2, step 52970, training loss = 1.590423, validation loss = 1.859589
2018-12-05 14:34:27,352 - INFO - epoch 2, step 52980, training loss = 1.710476, validation loss = 1.588764
2018-12-05 14:34:30,717 - INFO - epoch 2, step 52990, training loss = 1.205522, validation loss = 1.763532
2018-12-05 14:34:34,172 - INFO - epoch 2, step 53000, training loss = 1.511185, validation loss = 1.799503
2018-12-05 14:34:37,426 - INFO - epoch 2, step 53010, training loss = 2.045426, validation loss = 1.940296
2018-12-05 14:34:41,085 - INFO - epoch 2, step 53020, training loss = 1.708482, validation loss = 1.762454
2018-12-05 14:34:44,718 - INFO - epoch 2, step 53030, training loss = 1.737363, validation loss = 1.665552
2018-12-05 14:34:48,286 - INFO - epoch 2, step 53040, training loss = 1.424700, validation loss = 1.691108
2018-12-05 14:34:52,088 - INFO - epoch 2, step 53050, training loss = 1.469036, validation loss = 1.422757
2018-12-05 14:34:55,823 - INFO - epoch 2, step 53060, training loss = 1.479726, validation loss = 1.198364
2018-12-05 14:34:59,528 - INFO - epoch 2, step 53070, training loss = 1.934055, validation loss = 1.816054
2018-12-05 14:35:03,301 - INFO - epoch 2, step 53080, training loss = 1.600955, validation loss = 1.937329
2018-12-05 14:35:07,062 - INFO - epoch 2, step 53090, training loss = 1.429135, validation loss = 1.916265
2018-12-05 14:35:10,942 - INFO - epoch 2, step 53100, training loss = 1.314447, validation loss = 1.655461
2018-12-05 14:35:14,834 - INFO - epoch 2, step 53110, training loss = 1.526905, validation loss = 1.740403
2018-12-05 14:35:18,658 - INFO - epoch 2, step 53120, training loss = 1.647070, validation loss = 1.876884
2018-12-05 14:35:22,600 - INFO - epoch 2, step 53130, training loss = 1.581337, validation loss = 1.624541
2018-12-05 14:35:26,521 - INFO - epoch 2, step 53140, training loss = 1.574792, validation loss = 1.533537
2018-12-05 14:35:30,368 - INFO - epoch 2, step 53150, training loss = 1.677200, validation loss = 2.044894
2018-12-05 14:35:34,057 - INFO - epoch 2, step 53160, training loss = 1.868937, validation loss = 1.727854
2018-12-05 14:35:37,210 - INFO - epoch 2, step 53170, training loss = 1.617345, validation loss = 1.548504
2018-12-05 14:35:40,542 - INFO - epoch 2, step 53180, training loss = 1.486996, validation loss = 1.956098
2018-12-05 14:35:43,802 - INFO - epoch 2, step 53190, training loss = 1.580020, validation loss = 1.623068
2018-12-05 14:35:47,117 - INFO - epoch 2, step 53200, training loss = 1.595333, validation loss = 1.475287
2018-12-05 14:35:50,476 - INFO - epoch 2, step 53210, training loss = 1.566615, validation loss = 1.700996
2018-12-05 14:35:53,661 - INFO - epoch 2, step 53220, training loss = 1.850468, validation loss = 1.750345
2018-12-05 14:35:56,917 - INFO - epoch 2, step 53230, training loss = 1.785332, validation loss = 1.708449
2018-12-05 14:36:00,663 - INFO - epoch 2, step 53240, training loss = 1.479597, validation loss = 1.820283
2018-12-05 14:36:04,497 - INFO - epoch 2, step 53250, training loss = 1.832663, validation loss = 1.730141
2018-12-05 14:36:08,594 - INFO - epoch 2, step 53260, training loss = 1.585655, validation loss = 1.223941
2018-12-05 14:36:12,541 - INFO - epoch 2, step 53270, training loss = 1.573036, validation loss = 1.705860
2018-12-05 14:36:16,197 - INFO - epoch 2, step 53280, training loss = 1.406321, validation loss = 1.383299
2018-12-05 14:36:19,939 - INFO - epoch 2, step 53290, training loss = 1.534440, validation loss = 1.706962
2018-12-05 14:36:24,182 - INFO - epoch 2, step 53300, training loss = 1.299083, validation loss = 1.722416
2018-12-05 14:36:28,023 - INFO - epoch 2, step 53310, training loss = 1.913626, validation loss = 1.533624
2018-12-05 14:36:32,039 - INFO - epoch 2, step 53320, training loss = 1.534560, validation loss = 1.657455
2018-12-05 14:36:36,474 - INFO - epoch 2, step 53330, training loss = 1.813868, validation loss = 1.574816
2018-12-05 14:36:40,788 - INFO - epoch 2, step 53340, training loss = 1.626477, validation loss = 1.963766
2018-12-05 14:36:45,288 - INFO - epoch 2, step 53350, training loss = 1.441755, validation loss = 1.728490
2018-12-05 14:36:49,565 - INFO - epoch 2, step 53360, training loss = 1.892248, validation loss = 1.506633
2018-12-05 14:36:53,983 - INFO - epoch 2, step 53370, training loss = 1.501508, validation loss = 1.679766
2018-12-05 14:36:58,244 - INFO - epoch 2, step 53380, training loss = 1.476530, validation loss = 1.978678
2018-12-05 14:37:02,609 - INFO - epoch 2, step 53390, training loss = 1.773377, validation loss = 1.486943
2018-12-05 14:37:07,156 - INFO - epoch 2, step 53400, training loss = 1.452013, validation loss = 1.472732
2018-12-05 14:37:11,666 - INFO - epoch 2, step 53410, training loss = 1.455650, validation loss = 1.830191
2018-12-05 14:37:16,225 - INFO - epoch 2, step 53420, training loss = 1.171975, validation loss = 1.791297
2018-12-05 14:37:20,720 - INFO - epoch 2, step 53430, training loss = 1.791162, validation loss = 1.699664
2018-12-05 14:37:25,302 - INFO - epoch 2, step 53440, training loss = 1.116261, validation loss = 1.700953
2018-12-05 14:37:29,838 - INFO - epoch 2, step 53450, training loss = 1.868304, validation loss = 1.616752
2018-12-05 14:37:34,448 - INFO - epoch 2, step 53460, training loss = 1.414545, validation loss = 1.388515
2018-12-05 14:37:38,972 - INFO - epoch 2, step 53470, training loss = 1.344723, validation loss = 1.875219
2018-12-05 14:37:42,915 - INFO - epoch 2, step 53480, training loss = 1.527419, validation loss = 1.558826
2018-12-05 14:37:46,760 - INFO - epoch 2, step 53490, training loss = 1.440573, validation loss = 1.732520
2018-12-05 14:37:50,489 - INFO - epoch 2, step 53500, training loss = 1.579109, validation loss = 1.568490
2018-12-05 14:37:54,034 - INFO - epoch 2, step 53510, training loss = 1.477467, validation loss = 1.564965
2018-12-05 14:37:57,555 - INFO - epoch 2, step 53520, training loss = 1.491540, validation loss = 1.933363
2018-12-05 14:38:01,277 - INFO - epoch 2, step 53530, training loss = 1.515639, validation loss = 1.666923
2018-12-05 14:38:04,857 - INFO - epoch 2, step 53540, training loss = 1.646705, validation loss = 1.715744
2018-12-05 14:38:08,430 - INFO - epoch 2, step 53550, training loss = 1.800817, validation loss = 1.768726
2018-12-05 14:38:11,736 - INFO - epoch 2, step 53560, training loss = 1.472312, validation loss = 1.632920
2018-12-05 14:38:14,977 - INFO - epoch 2, step 53570, training loss = 1.703120, validation loss = 1.528821
2018-12-05 14:38:18,308 - INFO - epoch 2, step 53580, training loss = 1.523321, validation loss = 1.979408
2018-12-05 14:38:21,786 - INFO - epoch 2, step 53590, training loss = 1.880132, validation loss = 1.479433
2018-12-05 14:38:25,023 - INFO - epoch 2, step 53600, training loss = 1.662722, validation loss = 1.926195
2018-12-05 14:38:28,344 - INFO - epoch 2, step 53610, training loss = 1.378729, validation loss = 1.877351
2018-12-05 14:38:31,784 - INFO - epoch 2, step 53620, training loss = 1.603773, validation loss = 1.691791
2018-12-05 14:38:36,194 - INFO - epoch 2, step 53630, training loss = 1.509529, validation loss = 1.493659
2018-12-05 14:38:40,310 - INFO - epoch 2, step 53640, training loss = 1.348331, validation loss = 1.452944
2018-12-05 14:38:44,248 - INFO - epoch 2, step 53650, training loss = 1.771265, validation loss = 1.994794
2018-12-05 14:38:48,084 - INFO - epoch 2, step 53660, training loss = 1.498734, validation loss = 1.344927
2018-12-05 14:38:51,949 - INFO - epoch 2, step 53670, training loss = 1.437627, validation loss = 1.633879
2018-12-05 14:38:55,622 - INFO - epoch 2, step 53680, training loss = 1.816921, validation loss = 1.908132
2018-12-05 14:38:59,470 - INFO - epoch 2, step 53690, training loss = 1.299298, validation loss = 1.442703
2018-12-05 14:39:03,740 - INFO - epoch 2, step 53700, training loss = 1.498223, validation loss = 1.614941
2018-12-05 14:39:07,975 - INFO - epoch 2, step 53710, training loss = 1.156892, validation loss = 1.673112
2018-12-05 14:39:12,109 - INFO - epoch 2, step 53720, training loss = 1.396762, validation loss = 1.475651
2018-12-05 14:39:16,449 - INFO - epoch 2, step 53730, training loss = 1.344993, validation loss = 1.642832
2018-12-05 14:39:20,492 - INFO - epoch 2, step 53740, training loss = 1.678605, validation loss = 1.464500
2018-12-05 14:39:24,704 - INFO - epoch 2, step 53750, training loss = 1.384095, validation loss = 1.611741
2018-12-05 14:39:29,003 - INFO - epoch 2, step 53760, training loss = 1.614966, validation loss = 1.667818
2018-12-05 14:39:33,465 - INFO - epoch 2, step 53770, training loss = 1.761610, validation loss = 1.811758
2018-12-05 14:39:37,661 - INFO - epoch 2, step 53780, training loss = 1.671293, validation loss = 1.663422
2018-12-05 14:39:40,983 - INFO - epoch 2, step 53790, training loss = 1.718762, validation loss = 1.889205
2018-12-05 14:39:44,274 - INFO - epoch 2, step 53800, training loss = 1.742120, validation loss = 1.470324
2018-12-05 14:39:47,780 - INFO - epoch 2, step 53810, training loss = 1.531027, validation loss = 1.874211
2018-12-05 14:39:51,453 - INFO - epoch 2, step 53820, training loss = 1.516248, validation loss = 1.571798
2018-12-05 14:39:54,831 - INFO - epoch 2, step 53830, training loss = 1.642278, validation loss = 1.297941
2018-12-05 14:39:58,243 - INFO - epoch 2, step 53840, training loss = 1.684965, validation loss = 1.807344
2018-12-05 14:40:01,761 - INFO - epoch 2, step 53850, training loss = 1.989576, validation loss = 1.668453
2018-12-05 14:40:04,946 - INFO - epoch 2, step 53860, training loss = 1.567294, validation loss = 2.201539
2018-12-05 14:40:08,170 - INFO - epoch 2, step 53870, training loss = 1.601351, validation loss = 1.850801
2018-12-05 14:40:11,384 - INFO - epoch 2, step 53880, training loss = 1.646710, validation loss = 1.634048
2018-12-05 14:40:14,535 - INFO - epoch 2, step 53890, training loss = 1.461908, validation loss = 1.545368
2018-12-05 14:40:17,728 - INFO - epoch 2, step 53900, training loss = 1.829250, validation loss = 1.654152
2018-12-05 14:40:21,032 - INFO - epoch 2, step 53910, training loss = 1.597137, validation loss = 1.584943
2018-12-05 14:40:24,328 - INFO - epoch 2, step 53920, training loss = 1.533566, validation loss = 1.695728
2018-12-05 14:40:27,605 - INFO - epoch 2, step 53930, training loss = 1.628609, validation loss = 1.413566
2018-12-05 14:40:30,781 - INFO - epoch 2, step 53940, training loss = 2.039346, validation loss = 1.471584
2018-12-05 14:40:34,367 - INFO - epoch 2, step 53950, training loss = 1.213532, validation loss = 1.797796
2018-12-05 14:40:37,966 - INFO - epoch 2, step 53960, training loss = 1.614763, validation loss = 1.568494
2018-12-05 14:40:41,301 - INFO - epoch 2, step 53970, training loss = 1.499238, validation loss = 1.894481
2018-12-05 14:40:44,835 - INFO - epoch 2, step 53980, training loss = 1.567338, validation loss = 1.532241
2018-12-05 14:40:48,201 - INFO - epoch 2, step 53990, training loss = 1.507498, validation loss = 1.834895
2018-12-05 14:40:52,888 - INFO - epoch 2, step 54000, training loss = 1.520255, validation loss = 1.574537
2018-12-05 14:40:57,410 - INFO - epoch 2, step 54010, training loss = 1.699348, validation loss = 2.084201
2018-12-05 14:41:02,056 - INFO - epoch 2, step 54020, training loss = 1.653598, validation loss = 1.704988
2018-12-05 14:41:06,670 - INFO - epoch 2, step 54030, training loss = 1.022709, validation loss = 1.921343
2018-12-05 14:41:11,140 - INFO - epoch 2, step 54040, training loss = 1.630616, validation loss = 1.930674
2018-12-05 14:41:15,628 - INFO - epoch 2, step 54050, training loss = 1.663113, validation loss = 1.553428
2018-12-05 14:41:20,234 - INFO - epoch 2, step 54060, training loss = 1.668466, validation loss = 2.092799
2018-12-05 14:41:24,459 - INFO - epoch 2, step 54070, training loss = 1.666533, validation loss = 1.881844
2018-12-05 14:41:28,049 - INFO - epoch 2, step 54080, training loss = 1.914926, validation loss = 1.774628
2018-12-05 14:41:31,356 - INFO - epoch 2, step 54090, training loss = 1.533167, validation loss = 1.696521
2018-12-05 14:41:34,454 - INFO - epoch 2, step 54100, training loss = 1.567363, validation loss = 1.549270
2018-12-05 14:41:37,623 - INFO - epoch 2, step 54110, training loss = 1.508258, validation loss = 1.782028
2018-12-05 14:41:40,803 - INFO - epoch 2, step 54120, training loss = 1.647402, validation loss = 1.803687
2018-12-05 14:41:44,062 - INFO - epoch 2, step 54130, training loss = 1.660699, validation loss = 1.799229
2018-12-05 14:41:47,234 - INFO - epoch 2, step 54140, training loss = 1.592601, validation loss = 2.093354
2018-12-05 14:41:50,507 - INFO - epoch 2, step 54150, training loss = 1.697779, validation loss = 1.689806
2018-12-05 14:41:53,840 - INFO - epoch 2, step 54160, training loss = 1.589906, validation loss = 1.984276
2018-12-05 14:41:57,194 - INFO - epoch 2, step 54170, training loss = 1.617857, validation loss = 1.739770
2018-12-05 14:42:00,558 - INFO - epoch 2, step 54180, training loss = 1.606707, validation loss = 1.908269
2018-12-05 14:42:04,007 - INFO - epoch 2, step 54190, training loss = 1.868167, validation loss = 1.764342
2018-12-05 14:42:07,206 - INFO - epoch 2, step 54200, training loss = 1.535276, validation loss = 1.557895
2018-12-05 14:42:10,864 - INFO - epoch 2, step 54210, training loss = 1.838030, validation loss = 1.527336
2018-12-05 14:42:14,468 - INFO - epoch 2, step 54220, training loss = 1.699412, validation loss = 1.380604
2018-12-05 14:42:17,875 - INFO - epoch 2, step 54230, training loss = 1.404571, validation loss = 1.824974
2018-12-05 14:42:21,839 - INFO - epoch 2, step 54240, training loss = 1.846756, validation loss = 1.881193
2018-12-05 14:42:25,985 - INFO - epoch 2, step 54250, training loss = 1.858041, validation loss = 1.506944
2018-12-05 14:42:30,165 - INFO - epoch 2, step 54260, training loss = 1.653939, validation loss = 1.872376
2018-12-05 14:42:34,257 - INFO - epoch 2, step 54270, training loss = 1.713017, validation loss = 1.938707
2018-12-05 14:42:38,370 - INFO - epoch 2, step 54280, training loss = 1.347203, validation loss = 1.562448
2018-12-05 14:42:42,731 - INFO - epoch 2, step 54290, training loss = 1.776359, validation loss = 2.028103
2018-12-05 14:42:46,897 - INFO - epoch 2, step 54300, training loss = 1.250356, validation loss = 1.915940
2018-12-05 14:42:50,358 - INFO - epoch 2, step 54310, training loss = 1.840352, validation loss = 1.871181
2018-12-05 14:42:53,738 - INFO - epoch 2, step 54320, training loss = 1.619666, validation loss = 1.899368
2018-12-05 14:42:57,335 - INFO - epoch 2, step 54330, training loss = 1.542767, validation loss = 1.813774
2018-12-05 14:43:00,890 - INFO - epoch 2, step 54340, training loss = 1.880921, validation loss = 1.672324
2018-12-05 14:43:04,295 - INFO - epoch 2, step 54350, training loss = 1.722213, validation loss = 1.642932
2018-12-05 14:43:07,923 - INFO - epoch 2, step 54360, training loss = 1.615437, validation loss = 1.578987
2018-12-05 14:43:11,568 - INFO - epoch 2, step 54370, training loss = 1.515656, validation loss = 1.256565
2018-12-05 14:43:14,733 - INFO - epoch 2, step 54380, training loss = 1.835170, validation loss = 1.627865
2018-12-05 14:43:18,017 - INFO - epoch 2, step 54390, training loss = 1.716960, validation loss = 1.636288
2018-12-05 14:43:21,426 - INFO - epoch 2, step 54400, training loss = 1.936803, validation loss = 1.726222
2018-12-05 14:43:24,581 - INFO - epoch 2, step 54410, training loss = 1.913949, validation loss = 1.616856
2018-12-05 14:43:28,017 - INFO - epoch 2, step 54420, training loss = 1.565798, validation loss = 1.862587
2018-12-05 14:43:31,662 - INFO - epoch 2, step 54430, training loss = 1.524533, validation loss = 1.729440
2018-12-05 14:43:34,809 - INFO - epoch 2, step 54440, training loss = 1.838853, validation loss = 1.869660
2018-12-05 14:43:38,811 - INFO - epoch 2, step 54450, training loss = 1.571557, validation loss = 2.144958
2018-12-05 14:43:43,329 - INFO - epoch 2, step 54460, training loss = 1.607384, validation loss = 1.712226
2018-12-05 14:43:47,599 - INFO - epoch 2, step 54470, training loss = 1.750789, validation loss = 1.635256
2018-12-05 14:43:52,201 - INFO - epoch 2, step 54480, training loss = 1.225825, validation loss = 1.669480
2018-12-05 14:43:56,643 - INFO - epoch 2, step 54490, training loss = 1.703619, validation loss = 2.072163
2018-12-05 14:44:00,976 - INFO - epoch 2, step 54500, training loss = 1.368287, validation loss = 1.456220
2018-12-05 14:44:05,105 - INFO - epoch 2, step 54510, training loss = 1.815076, validation loss = 1.634176
2018-12-05 14:44:09,082 - INFO - epoch 2, step 54520, training loss = 2.069217, validation loss = 1.836477
2018-12-05 14:44:13,039 - INFO - epoch 2, step 54530, training loss = 1.633538, validation loss = 1.771773
2018-12-05 14:44:16,609 - INFO - epoch 2, step 54540, training loss = 1.643271, validation loss = 1.861693
2018-12-05 14:44:20,349 - INFO - epoch 2, step 54550, training loss = 1.684319, validation loss = 1.518992
2018-12-05 14:44:23,946 - INFO - epoch 2, step 54560, training loss = 1.824030, validation loss = 1.605966
2018-12-05 14:44:27,609 - INFO - epoch 2, step 54570, training loss = 1.531294, validation loss = 1.594312
2018-12-05 14:44:31,355 - INFO - epoch 2, step 54580, training loss = 1.613054, validation loss = 1.777371
2018-12-05 14:44:34,946 - INFO - epoch 2, step 54590, training loss = 1.491366, validation loss = 1.550566
2018-12-05 14:44:38,872 - INFO - epoch 2, step 54600, training loss = 1.119597, validation loss = 1.703746
2018-12-05 14:44:42,677 - INFO - epoch 2, step 54610, training loss = 1.470277, validation loss = 1.758543
2018-12-05 14:44:46,609 - INFO - epoch 2, step 54620, training loss = 1.735886, validation loss = 1.470082
2018-12-05 14:44:50,523 - INFO - epoch 2, step 54630, training loss = 1.683324, validation loss = 1.666675
2018-12-05 14:44:54,335 - INFO - epoch 2, step 54640, training loss = 1.564540, validation loss = 2.049111
2018-12-05 14:44:58,675 - INFO - epoch 2, step 54650, training loss = 1.687722, validation loss = 2.093536
2018-12-05 14:45:02,659 - INFO - epoch 2, step 54660, training loss = 1.417110, validation loss = 1.865645
2018-12-05 14:45:06,644 - INFO - epoch 2, step 54670, training loss = 1.593246, validation loss = 1.679571
2018-12-05 14:45:10,599 - INFO - epoch 2, step 54680, training loss = 1.511045, validation loss = 1.810996
2018-12-05 14:45:14,776 - INFO - epoch 2, step 54690, training loss = 1.418370, validation loss = 1.710426
2018-12-05 14:45:19,322 - INFO - epoch 2, step 54700, training loss = 1.633768, validation loss = 1.545196
2018-12-05 14:45:23,499 - INFO - epoch 2, step 54710, training loss = 1.701839, validation loss = 1.827901
2018-12-05 14:45:27,780 - INFO - epoch 2, step 54720, training loss = 1.564696, validation loss = 1.941754
2018-12-05 14:45:32,225 - INFO - epoch 2, step 54730, training loss = 1.305737, validation loss = 1.822080
2018-12-05 14:45:36,443 - INFO - epoch 2, step 54740, training loss = 1.239256, validation loss = 1.565468
2018-12-05 14:45:39,870 - INFO - epoch 2, step 54750, training loss = 1.539230, validation loss = 1.630346
2018-12-05 14:45:43,208 - INFO - epoch 2, step 54760, training loss = 1.966257, validation loss = 1.929288
2018-12-05 14:45:46,675 - INFO - epoch 2, step 54770, training loss = 1.766573, validation loss = 1.785732
2018-12-05 14:45:50,052 - INFO - epoch 2, step 54780, training loss = 1.679438, validation loss = 1.851988
2018-12-05 14:45:53,351 - INFO - epoch 2, step 54790, training loss = 1.711692, validation loss = 1.663945
2018-12-05 14:45:56,766 - INFO - epoch 2, step 54800, training loss = 1.553184, validation loss = 1.694906
2018-12-05 14:46:00,286 - INFO - epoch 2, step 54810, training loss = 1.476179, validation loss = 1.706693
2018-12-05 14:46:03,404 - INFO - epoch 2, step 54820, training loss = 1.721498, validation loss = 1.860174
2018-12-05 14:46:07,793 - INFO - epoch 2, step 54830, training loss = 1.659930, validation loss = 1.666123
2018-12-05 14:46:12,327 - INFO - epoch 2, step 54840, training loss = 1.777264, validation loss = 2.139435
2018-12-05 14:46:17,157 - INFO - epoch 2, step 54850, training loss = 1.576975, validation loss = 1.848418
2018-12-05 14:46:21,917 - INFO - epoch 2, step 54860, training loss = 1.572628, validation loss = 1.701370
2018-12-05 14:46:26,615 - INFO - epoch 2, step 54870, training loss = 1.498365, validation loss = 1.997745
2018-12-05 14:46:31,362 - INFO - epoch 2, step 54880, training loss = 1.580191, validation loss = 1.594720
2018-12-05 14:46:35,924 - INFO - epoch 2, step 54890, training loss = 1.572495, validation loss = 1.668057
2018-12-05 14:46:40,268 - INFO - epoch 2, step 54900, training loss = 1.425632, validation loss = 1.729641
2018-12-05 14:46:45,014 - INFO - epoch 2, step 54910, training loss = 1.535868, validation loss = 1.648576
2018-12-05 14:46:49,350 - INFO - epoch 2, step 54920, training loss = 1.303475, validation loss = 1.643311
2018-12-05 14:46:53,591 - INFO - epoch 2, step 54930, training loss = 1.756382, validation loss = 1.568252
2018-12-05 14:46:58,000 - INFO - epoch 2, step 54940, training loss = 1.391862, validation loss = 1.917936
2018-12-05 14:47:02,238 - INFO - epoch 2, step 54950, training loss = 1.534689, validation loss = 1.642219
2018-12-05 14:47:06,583 - INFO - epoch 2, step 54960, training loss = 1.561193, validation loss = 1.924765
2018-12-05 14:47:10,743 - INFO - epoch 2, step 54970, training loss = 1.401646, validation loss = 1.898621
2018-12-05 14:47:14,880 - INFO - epoch 2, step 54980, training loss = 1.542903, validation loss = 1.922046
2018-12-05 14:47:19,168 - INFO - epoch 2, step 54990, training loss = 1.682557, validation loss = 1.569774
2018-12-05 14:47:23,517 - INFO - epoch 2, step 55000, training loss = 1.387401, validation loss = 1.749618
2018-12-05 14:47:28,035 - INFO - epoch 2, step 55010, training loss = 1.463883, validation loss = 1.725673
2018-12-05 14:47:32,429 - INFO - epoch 2, step 55020, training loss = 1.379975, validation loss = 1.916982
2018-12-05 14:47:36,645 - INFO - epoch 2, step 55030, training loss = 1.658731, validation loss = 1.814645
2018-12-05 14:47:41,035 - INFO - epoch 2, step 55040, training loss = 1.181608, validation loss = 1.684095
2018-12-05 14:47:45,328 - INFO - epoch 2, step 55050, training loss = 1.677645, validation loss = 2.148677
2018-12-05 14:47:49,631 - INFO - epoch 2, step 55060, training loss = 1.451596, validation loss = 2.081416
2018-12-05 14:47:53,770 - INFO - epoch 2, step 55070, training loss = 1.497645, validation loss = 1.957707
2018-12-05 14:47:57,874 - INFO - epoch 2, step 55080, training loss = 1.496755, validation loss = 1.949257
2018-12-05 14:48:02,005 - INFO - epoch 2, step 55090, training loss = 1.679079, validation loss = 1.633022
2018-12-05 14:48:06,393 - INFO - epoch 2, step 55100, training loss = 1.406092, validation loss = 1.717991
2018-12-05 14:48:10,521 - INFO - epoch 2, step 55110, training loss = 1.430270, validation loss = 1.734701
2018-12-05 14:48:14,359 - INFO - epoch 2, step 55120, training loss = 1.579566, validation loss = 1.786711
2018-12-05 14:48:18,530 - INFO - epoch 2, step 55130, training loss = 1.215392, validation loss = 1.753516
2018-12-05 14:48:22,624 - INFO - epoch 2, step 55140, training loss = 1.444229, validation loss = 1.855470
2018-12-05 14:48:26,544 - INFO - epoch 2, step 55150, training loss = 1.371161, validation loss = 1.744729
2018-12-05 14:48:30,279 - INFO - epoch 2, step 55160, training loss = 1.586610, validation loss = 1.223953
2018-12-05 14:48:33,849 - INFO - epoch 2, step 55170, training loss = 1.606481, validation loss = 1.682221
2018-12-05 14:48:37,674 - INFO - epoch 2, step 55180, training loss = 1.432186, validation loss = 2.092792
2018-12-05 14:48:41,305 - INFO - epoch 2, step 55190, training loss = 1.651991, validation loss = 1.668505
2018-12-05 14:48:45,058 - INFO - epoch 2, step 55200, training loss = 1.820302, validation loss = 2.129338
2018-12-05 14:48:48,643 - INFO - epoch 2, step 55210, training loss = 1.580253, validation loss = 1.810057
2018-12-05 14:48:53,014 - INFO - epoch 2, step 55220, training loss = 1.638043, validation loss = 2.016601
2018-12-05 14:48:57,230 - INFO - epoch 2, step 55230, training loss = 1.673875, validation loss = 1.778345
2018-12-05 14:49:01,739 - INFO - epoch 2, step 55240, training loss = 1.605234, validation loss = 1.800195
2018-12-05 14:49:06,187 - INFO - epoch 2, step 55250, training loss = 1.613333, validation loss = 1.895890
2018-12-05 14:49:10,559 - INFO - epoch 2, step 55260, training loss = 1.539119, validation loss = 2.037683
2018-12-05 14:49:15,150 - INFO - epoch 2, step 55270, training loss = 1.700122, validation loss = 1.976555
2018-12-05 14:49:19,493 - INFO - epoch 2, step 55280, training loss = 1.609661, validation loss = 1.584161
2018-12-05 14:49:24,144 - INFO - epoch 2, step 55290, training loss = 1.676490, validation loss = 1.641145
2018-12-05 14:49:28,737 - INFO - epoch 2, step 55300, training loss = 1.227606, validation loss = 1.651409
2018-12-05 14:49:33,323 - INFO - epoch 2, step 55310, training loss = 1.830570, validation loss = 1.931908
2018-12-05 14:49:38,046 - INFO - epoch 2, step 55320, training loss = 1.504138, validation loss = 2.092359
2018-12-05 14:49:42,686 - INFO - epoch 2, step 55330, training loss = 1.425382, validation loss = 1.992750
2018-12-05 14:49:47,015 - INFO - epoch 2, step 55340, training loss = 1.818180, validation loss = 1.681778
2018-12-05 14:49:51,807 - INFO - epoch 2, step 55350, training loss = 1.511475, validation loss = 2.021309
2018-12-05 14:49:56,521 - INFO - epoch 2, step 55360, training loss = 1.878780, validation loss = 1.750673
2018-12-05 14:50:01,077 - INFO - epoch 2, step 55370, training loss = 1.506709, validation loss = 2.154996
2018-12-05 14:50:05,261 - INFO - epoch 2, step 55380, training loss = 2.075653, validation loss = 1.375829
2018-12-05 14:50:08,434 - INFO - epoch 2, step 55390, training loss = 1.458592, validation loss = 2.126923
2018-12-05 14:50:11,915 - INFO - epoch 2, step 55400, training loss = 1.716049, validation loss = 1.629439
2018-12-05 14:50:15,240 - INFO - epoch 2, step 55410, training loss = 1.790891, validation loss = 2.086436
2018-12-05 14:50:18,471 - INFO - epoch 2, step 55420, training loss = 1.756389, validation loss = 1.563777
2018-12-05 14:50:21,743 - INFO - epoch 2, step 55430, training loss = 1.681322, validation loss = 1.282441
2018-12-05 14:50:25,065 - INFO - epoch 2, step 55440, training loss = 1.677445, validation loss = 1.923323
2018-12-05 14:50:28,505 - INFO - epoch 2, step 55450, training loss = 1.727735, validation loss = 1.502489
2018-12-05 14:50:32,561 - INFO - epoch 2, step 55460, training loss = 1.534371, validation loss = 1.714956
2018-12-05 14:50:36,640 - INFO - epoch 2, step 55470, training loss = 1.626932, validation loss = 2.011074
2018-12-05 14:50:40,498 - INFO - epoch 2, step 55480, training loss = 1.321250, validation loss = 1.764649
2018-12-05 14:50:44,448 - INFO - epoch 2, step 55490, training loss = 1.596016, validation loss = 1.466470
2018-12-05 14:50:48,551 - INFO - epoch 2, step 55500, training loss = 1.515153, validation loss = 1.779187
2018-12-05 14:50:52,712 - INFO - epoch 2, step 55510, training loss = 1.602640, validation loss = 1.822360
2018-12-05 14:50:57,265 - INFO - epoch 2, step 55520, training loss = 1.547300, validation loss = 2.061940
2018-12-05 14:51:01,183 - INFO - epoch 2, step 55530, training loss = 1.318082, validation loss = 2.047188
2018-12-05 14:51:04,647 - INFO - epoch 2, step 55540, training loss = 1.294289, validation loss = 1.869094
2018-12-05 14:51:08,272 - INFO - epoch 2, step 55550, training loss = 1.817846, validation loss = 1.898266
2018-12-05 14:51:11,716 - INFO - epoch 2, step 55560, training loss = 1.787949, validation loss = 1.791640
2018-12-05 14:51:15,139 - INFO - epoch 2, step 55570, training loss = 1.742952, validation loss = 1.540041
2018-12-05 14:51:18,766 - INFO - epoch 2, step 55580, training loss = 1.395723, validation loss = 1.762072
2018-12-05 14:51:22,143 - INFO - epoch 2, step 55590, training loss = 1.764254, validation loss = 1.690316
2018-12-05 14:51:26,513 - INFO - epoch 2, step 55600, training loss = 1.563625, validation loss = 1.584151
2018-12-05 14:51:30,932 - INFO - epoch 2, step 55610, training loss = 1.353858, validation loss = 1.902020
2018-12-05 14:51:35,441 - INFO - epoch 2, step 55620, training loss = 1.416623, validation loss = 1.700291
2018-12-05 14:51:39,813 - INFO - epoch 2, step 55630, training loss = 1.785294, validation loss = 1.337615
2018-12-05 14:51:44,338 - INFO - epoch 2, step 55640, training loss = 1.467772, validation loss = 1.798984
2018-12-05 14:51:49,022 - INFO - epoch 2, step 55650, training loss = 1.429189, validation loss = 1.853376
2018-12-05 14:51:53,635 - INFO - epoch 2, step 55660, training loss = 1.620840, validation loss = 1.625092
2018-12-05 14:51:58,088 - INFO - epoch 2, step 55670, training loss = 1.582135, validation loss = 1.577629
2018-12-05 14:52:02,383 - INFO - epoch 2, step 55680, training loss = 1.564047, validation loss = 1.685278
2018-12-05 14:52:06,682 - INFO - epoch 2, step 55690, training loss = 1.389380, validation loss = 1.540266
2018-12-05 14:52:10,951 - INFO - epoch 2, step 55700, training loss = 1.597659, validation loss = 1.766142
2018-12-05 14:52:15,258 - INFO - epoch 2, step 55710, training loss = 1.630693, validation loss = 2.057646
2018-12-05 14:52:19,628 - INFO - epoch 2, step 55720, training loss = 1.827037, validation loss = 1.857569
2018-12-05 14:52:23,627 - INFO - epoch 2, step 55730, training loss = 1.396631, validation loss = 2.008343
2018-12-05 14:52:27,943 - INFO - epoch 2, step 55740, training loss = 1.373426, validation loss = 1.977641
2018-12-05 14:52:32,234 - INFO - epoch 2, step 55750, training loss = 1.504087, validation loss = 1.577368
2018-12-05 14:52:35,985 - INFO - epoch 2, step 55760, training loss = 1.558873, validation loss = 1.626753
2018-12-05 14:52:39,792 - INFO - epoch 2, step 55770, training loss = 1.688247, validation loss = 1.501543
2018-12-05 14:52:43,728 - INFO - epoch 2, step 55780, training loss = 1.803111, validation loss = 1.405651
2018-12-05 14:52:47,612 - INFO - epoch 2, step 55790, training loss = 1.346541, validation loss = 1.733916
2018-12-05 14:52:51,321 - INFO - epoch 2, step 55800, training loss = 1.600632, validation loss = 1.925193
2018-12-05 14:52:54,963 - INFO - epoch 2, step 55810, training loss = 1.746771, validation loss = 1.927183
2018-12-05 14:52:58,659 - INFO - epoch 2, step 55820, training loss = 1.846043, validation loss = 1.494462
2018-12-05 14:53:02,555 - INFO - epoch 2, step 55830, training loss = 1.663781, validation loss = 1.513629
2018-12-05 14:53:07,003 - INFO - epoch 2, step 55840, training loss = 1.676449, validation loss = 1.692458
2018-12-05 14:53:11,554 - INFO - epoch 2, step 55850, training loss = 1.592293, validation loss = 1.825188
2018-12-05 14:53:16,068 - INFO - epoch 2, step 55860, training loss = 1.273767, validation loss = 1.649211
2018-12-05 14:53:20,644 - INFO - epoch 2, step 55870, training loss = 1.315264, validation loss = 1.549634
2018-12-05 14:53:25,196 - INFO - epoch 2, step 55880, training loss = 1.465482, validation loss = 1.700744
2018-12-05 14:53:29,857 - INFO - epoch 2, step 55890, training loss = 1.633611, validation loss = 1.721348
2018-12-05 14:53:34,352 - INFO - epoch 2, step 55900, training loss = 1.386145, validation loss = 1.698324
2018-12-05 14:53:38,561 - INFO - epoch 2, step 55910, training loss = 1.454233, validation loss = 1.742204
2018-12-05 14:53:43,001 - INFO - epoch 2, step 55920, training loss = 1.575278, validation loss = 1.433795
2018-12-05 14:53:47,591 - INFO - epoch 2, step 55930, training loss = 1.429292, validation loss = 1.399759
2018-12-05 14:53:51,723 - INFO - epoch 2, step 55940, training loss = 1.689292, validation loss = 1.667434
2018-12-05 14:53:55,749 - INFO - epoch 2, step 55950, training loss = 1.685773, validation loss = 1.680321
2018-12-05 14:54:00,387 - INFO - epoch 2, step 55960, training loss = 1.150264, validation loss = 1.823314
2018-12-05 14:54:04,547 - INFO - epoch 2, step 55970, training loss = 1.638753, validation loss = 1.807857
2018-12-05 14:54:08,921 - INFO - epoch 2, step 55980, training loss = 1.481648, validation loss = 1.533392
2018-12-05 14:54:13,133 - INFO - epoch 2, step 55990, training loss = 1.623690, validation loss = 1.451293
2018-12-05 14:54:17,183 - INFO - epoch 2, step 56000, training loss = 1.676204, validation loss = 1.801624
2018-12-05 14:54:21,662 - INFO - epoch 2, step 56010, training loss = 1.145736, validation loss = 1.705659
2018-12-05 14:54:25,814 - INFO - epoch 2, step 56020, training loss = 1.594528, validation loss = 1.828646
2018-12-05 14:54:29,827 - INFO - epoch 2, step 56030, training loss = 1.904568, validation loss = 1.375283
2018-12-05 14:54:33,978 - INFO - epoch 2, step 56040, training loss = 1.712391, validation loss = 1.966801
2018-12-05 14:54:37,986 - INFO - epoch 2, step 56050, training loss = 1.624815, validation loss = 1.615569
2018-12-05 14:54:41,829 - INFO - epoch 2, step 56060, training loss = 1.211312, validation loss = 2.022651
2018-12-05 14:54:45,868 - INFO - epoch 2, step 56070, training loss = 1.395395, validation loss = 1.599684
2018-12-05 14:54:49,546 - INFO - epoch 2, step 56080, training loss = 1.228849, validation loss = 1.844493
2018-12-05 14:54:53,427 - INFO - epoch 2, step 56090, training loss = 1.546206, validation loss = 2.187824
2018-12-05 14:54:57,280 - INFO - epoch 2, step 56100, training loss = 1.612476, validation loss = 1.991652
2018-12-05 14:55:01,727 - INFO - epoch 2, step 56110, training loss = 1.603617, validation loss = 1.669445
2018-12-05 14:55:06,178 - INFO - epoch 2, step 56120, training loss = 1.499954, validation loss = 1.284742
2018-12-05 14:55:10,863 - INFO - epoch 2, step 56130, training loss = 1.807149, validation loss = 1.724748
2018-12-05 14:55:15,347 - INFO - epoch 2, step 56140, training loss = 1.885188, validation loss = 2.003957
2018-12-05 14:55:19,947 - INFO - epoch 2, step 56150, training loss = 2.131989, validation loss = 1.741376
2018-12-05 14:55:24,719 - INFO - epoch 2, step 56160, training loss = 1.374207, validation loss = 1.637765
2018-12-05 14:55:29,225 - INFO - epoch 2, step 56170, training loss = 1.574121, validation loss = 1.781438
2018-12-05 14:55:33,579 - INFO - epoch 2, step 56180, training loss = 1.627933, validation loss = 1.610330
2018-12-05 14:55:37,825 - INFO - epoch 2, step 56190, training loss = 1.596426, validation loss = 1.843763
2018-12-05 14:55:41,435 - INFO - epoch 2, step 56200, training loss = 1.696048, validation loss = 1.827533
2018-12-05 14:55:44,841 - INFO - epoch 2, step 56210, training loss = 1.788579, validation loss = 2.189124
2018-12-05 14:55:48,070 - INFO - epoch 2, step 56220, training loss = 1.791220, validation loss = 1.743691
2018-12-05 14:55:51,539 - INFO - epoch 2, step 56230, training loss = 1.786307, validation loss = 1.728977
2018-12-05 14:55:55,080 - INFO - epoch 2, step 56240, training loss = 1.746408, validation loss = 1.590464
2018-12-05 14:55:58,272 - INFO - epoch 2, step 56250, training loss = 1.824460, validation loss = 1.652755
2018-12-05 14:56:01,521 - INFO - epoch 2, step 56260, training loss = 1.374264, validation loss = 1.723787
2018-12-05 14:56:04,979 - INFO - epoch 2, step 56270, training loss = 1.218743, validation loss = 2.020284
2018-12-05 14:56:08,253 - INFO - epoch 2, step 56280, training loss = 1.844419, validation loss = 2.221826
2018-12-05 14:56:11,616 - INFO - epoch 2, step 56290, training loss = 1.674645, validation loss = 1.394606
2018-12-05 14:56:14,946 - INFO - epoch 2, step 56300, training loss = 1.543316, validation loss = 1.825038
2018-12-05 14:56:18,234 - INFO - epoch 2, step 56310, training loss = 1.503847, validation loss = 1.844279
2018-12-05 14:56:21,976 - INFO - epoch 2, step 56320, training loss = 1.460701, validation loss = 1.863778
2018-12-05 14:56:25,554 - INFO - epoch 2, step 56330, training loss = 1.575916, validation loss = 1.590239
2018-12-05 14:56:29,059 - INFO - epoch 2, step 56340, training loss = 1.607276, validation loss = 1.512421
2018-12-05 14:56:33,021 - INFO - epoch 2, step 56350, training loss = 1.519254, validation loss = 1.768109
2018-12-05 14:56:37,519 - INFO - epoch 2, step 56360, training loss = 1.537625, validation loss = 1.550700
2018-12-05 14:56:41,805 - INFO - epoch 2, step 56370, training loss = 1.612081, validation loss = 1.929854
2018-12-05 14:56:46,094 - INFO - epoch 2, step 56380, training loss = 1.889896, validation loss = 1.987320
2018-12-05 14:56:50,462 - INFO - epoch 2, step 56390, training loss = 1.481292, validation loss = 1.897817
2018-12-05 14:56:55,012 - INFO - epoch 2, step 56400, training loss = 1.927104, validation loss = 1.511410
2018-12-05 14:56:59,605 - INFO - epoch 2, step 56410, training loss = 1.639477, validation loss = 1.948687
2018-12-05 14:57:03,979 - INFO - epoch 2, step 56420, training loss = 1.550288, validation loss = 1.773436
2018-12-05 14:57:08,336 - INFO - epoch 2, step 56430, training loss = 1.685511, validation loss = 1.735148
2018-12-05 14:57:12,649 - INFO - epoch 2, step 56440, training loss = 1.624624, validation loss = 1.548566
2018-12-05 14:57:17,134 - INFO - epoch 2, step 56450, training loss = 1.668975, validation loss = 1.499430
2018-12-05 14:57:21,868 - INFO - epoch 2, step 56460, training loss = 1.513393, validation loss = 1.890626
2018-12-05 14:57:26,315 - INFO - epoch 2, step 56470, training loss = 1.481925, validation loss = 1.521241
2018-12-05 14:57:31,047 - INFO - epoch 2, step 56480, training loss = 1.536417, validation loss = 1.676047
2018-12-05 14:57:35,778 - INFO - epoch 2, step 56490, training loss = 1.520436, validation loss = 1.797826
2018-12-05 14:57:40,299 - INFO - epoch 2, step 56500, training loss = 1.519083, validation loss = 1.730240
2018-12-05 14:57:44,748 - INFO - epoch 2, step 56510, training loss = 1.502295, validation loss = 1.788641
2018-12-05 14:57:49,404 - INFO - epoch 2, step 56520, training loss = 1.708444, validation loss = 1.691798
2018-12-05 14:57:54,024 - INFO - epoch 2, step 56530, training loss = 1.580173, validation loss = 1.705822
2018-12-05 14:57:58,682 - INFO - epoch 2, step 56540, training loss = 1.412891, validation loss = 1.777267
2018-12-05 14:58:02,910 - INFO - epoch 2, step 56550, training loss = 1.768324, validation loss = 1.661337
2018-12-05 14:58:06,631 - INFO - epoch 2, step 56560, training loss = 1.652513, validation loss = 1.440198
2018-12-05 14:58:10,308 - INFO - epoch 2, step 56570, training loss = 1.429270, validation loss = 1.687439
2018-12-05 14:58:14,296 - INFO - epoch 2, step 56580, training loss = 1.529938, validation loss = 1.486100
2018-12-05 14:58:17,905 - INFO - epoch 2, step 56590, training loss = 1.787759, validation loss = 1.932084
2018-12-05 14:58:21,560 - INFO - epoch 2, step 56600, training loss = 1.556885, validation loss = 1.754949
2018-12-05 14:58:25,346 - INFO - epoch 2, step 56610, training loss = 1.461417, validation loss = 1.644175
2018-12-05 14:58:28,998 - INFO - epoch 2, step 56620, training loss = 1.544859, validation loss = 1.807774
2018-12-05 14:58:32,879 - INFO - epoch 2, step 56630, training loss = 1.608412, validation loss = 1.413529
2018-12-05 14:58:36,406 - INFO - epoch 2, step 56640, training loss = 1.479746, validation loss = 1.617049
2018-12-05 14:58:40,142 - INFO - epoch 2, step 56650, training loss = 1.556909, validation loss = 1.911295
2018-12-05 14:58:43,937 - INFO - epoch 2, step 56660, training loss = 1.442242, validation loss = 1.733794
2018-12-05 14:58:47,541 - INFO - epoch 2, step 56670, training loss = 1.519466, validation loss = 1.955805
2018-12-05 14:58:50,986 - INFO - epoch 2, step 56680, training loss = 1.561683, validation loss = 1.648552
2018-12-05 14:58:54,570 - INFO - epoch 2, step 56690, training loss = 1.487259, validation loss = 1.445390
2018-12-05 14:58:58,504 - INFO - epoch 2, step 56700, training loss = 1.762859, validation loss = 1.679945
2018-12-05 14:59:02,978 - INFO - epoch 2, step 56710, training loss = 1.528778, validation loss = 1.636605
2018-12-05 14:59:07,217 - INFO - epoch 2, step 56720, training loss = 1.366926, validation loss = 1.377502
2018-12-05 14:59:11,628 - INFO - epoch 2, step 56730, training loss = 1.654325, validation loss = 1.638355
2018-12-05 14:59:15,963 - INFO - epoch 2, step 56740, training loss = 1.722458, validation loss = 1.764999
2018-12-05 14:59:20,460 - INFO - epoch 2, step 56750, training loss = 1.736264, validation loss = 1.533932
2018-12-05 14:59:24,763 - INFO - epoch 2, step 56760, training loss = 1.422538, validation loss = 1.454576
2018-12-05 14:59:28,838 - INFO - epoch 2, step 56770, training loss = 1.537674, validation loss = 1.708947
2018-12-05 14:59:32,946 - INFO - epoch 2, step 56780, training loss = 1.543060, validation loss = 1.817716
2018-12-05 14:59:36,824 - INFO - epoch 2, step 56790, training loss = 1.776347, validation loss = 1.177390
2018-12-05 14:59:40,646 - INFO - epoch 2, step 56800, training loss = 1.489500, validation loss = 1.755418
2018-12-05 14:59:44,525 - INFO - epoch 2, step 56810, training loss = 1.361656, validation loss = 1.677432
2018-12-05 14:59:48,632 - INFO - epoch 2, step 56820, training loss = 1.313262, validation loss = 1.674962
2018-12-05 14:59:52,589 - INFO - epoch 2, step 56830, training loss = 1.540501, validation loss = 1.455143
2018-12-05 14:59:56,546 - INFO - epoch 2, step 56840, training loss = 1.624129, validation loss = 1.757185
2018-12-05 15:00:00,024 - INFO - epoch 2, step 56850, training loss = 1.672946, validation loss = 1.587671
2018-12-05 15:00:03,483 - INFO - epoch 2, step 56860, training loss = 1.718569, validation loss = 1.909107
2018-12-05 15:00:07,083 - INFO - epoch 2, step 56870, training loss = 1.948525, validation loss = 1.632188
2018-12-05 15:00:10,353 - INFO - epoch 2, step 56880, training loss = 2.109141, validation loss = 1.684878
2018-12-05 15:00:13,827 - INFO - epoch 2, step 56890, training loss = 1.863163, validation loss = 1.662526
2018-12-05 15:00:17,483 - INFO - epoch 2, step 56900, training loss = 1.661498, validation loss = 1.628466
2018-12-05 15:00:20,869 - INFO - epoch 2, step 56910, training loss = 1.724235, validation loss = 1.626613
2018-12-05 15:00:24,240 - INFO - epoch 2, step 56920, training loss = 1.651373, validation loss = 1.200326
2018-12-05 15:00:27,921 - INFO - epoch 2, step 56930, training loss = 1.504652, validation loss = 1.757002
2018-12-05 15:00:31,589 - INFO - epoch 2, step 56940, training loss = 1.901366, validation loss = 1.844288
2018-12-05 15:00:35,439 - INFO - epoch 2, step 56950, training loss = 1.723969, validation loss = 2.091594
2018-12-05 15:00:38,960 - INFO - epoch 2, step 56960, training loss = 1.641734, validation loss = 1.690887
2018-12-05 15:00:42,606 - INFO - epoch 2, step 56970, training loss = 1.609178, validation loss = 1.966045
2018-12-05 15:00:46,369 - INFO - epoch 2, step 56980, training loss = 1.932378, validation loss = 1.969730
2018-12-05 15:00:50,205 - INFO - epoch 2, step 56990, training loss = 1.625383, validation loss = 1.795166
2018-12-05 15:00:54,993 - INFO - epoch 2, step 57000, training loss = 1.472731, validation loss = 1.879467
2018-12-05 15:00:59,627 - INFO - epoch 2, step 57010, training loss = 1.399088, validation loss = 1.272430
2018-12-05 15:01:04,031 - INFO - epoch 2, step 57020, training loss = 1.259085, validation loss = 1.725662
2018-12-05 15:01:08,542 - INFO - epoch 2, step 57030, training loss = 1.466387, validation loss = 1.704184
2018-12-05 15:01:13,188 - INFO - epoch 2, step 57040, training loss = 1.396615, validation loss = 1.516968
2018-12-05 15:01:17,470 - INFO - epoch 2, step 57050, training loss = 1.404522, validation loss = 1.640606
2018-12-05 15:01:21,645 - INFO - epoch 2, step 57060, training loss = 1.407090, validation loss = 1.893103
2018-12-05 15:01:26,167 - INFO - epoch 2, step 57070, training loss = 1.428437, validation loss = 1.769602
2018-12-05 15:01:30,333 - INFO - epoch 2, step 57080, training loss = 1.411714, validation loss = 1.773362
2018-12-05 15:01:34,625 - INFO - epoch 2, step 57090, training loss = 1.675883, validation loss = 1.801373
2018-12-05 15:01:38,510 - INFO - epoch 2, step 57100, training loss = 1.639392, validation loss = 1.622501
2018-12-05 15:01:42,596 - INFO - epoch 2, step 57110, training loss = 1.753885, validation loss = 1.825962
2018-12-05 15:01:46,561 - INFO - epoch 2, step 57120, training loss = 1.304513, validation loss = 2.180359
2018-12-05 15:01:50,428 - INFO - epoch 2, step 57130, training loss = 1.503606, validation loss = 1.530265
2018-12-05 15:01:54,524 - INFO - epoch 2, step 57140, training loss = 1.641254, validation loss = 2.266249
2018-12-05 15:01:58,853 - INFO - epoch 2, step 57150, training loss = 1.561351, validation loss = 1.340951
2018-12-05 15:02:03,182 - INFO - epoch 2, step 57160, training loss = 1.226521, validation loss = 1.962637
2018-12-05 15:02:07,600 - INFO - epoch 2, step 57170, training loss = 1.687903, validation loss = 1.960326
2018-12-05 15:02:12,080 - INFO - epoch 2, step 57180, training loss = 1.537537, validation loss = 1.781742
2018-12-05 15:02:16,559 - INFO - epoch 2, step 57190, training loss = 1.208527, validation loss = 1.553861
2018-12-05 15:02:20,777 - INFO - epoch 2, step 57200, training loss = 1.512202, validation loss = 1.732122
2018-12-05 15:02:25,312 - INFO - epoch 2, step 57210, training loss = 1.335636, validation loss = 1.783870
2018-12-05 15:02:29,631 - INFO - epoch 2, step 57220, training loss = 1.662929, validation loss = 2.049697
2018-12-05 15:02:34,099 - INFO - epoch 2, step 57230, training loss = 1.239345, validation loss = 1.829841
2018-12-05 15:02:38,574 - INFO - epoch 2, step 57240, training loss = 1.513014, validation loss = 1.951333
2018-12-05 15:02:43,144 - INFO - epoch 2, step 57250, training loss = 1.457817, validation loss = 1.940151
2018-12-05 15:02:47,521 - INFO - epoch 2, step 57260, training loss = 1.302349, validation loss = 1.785050
2018-12-05 15:02:51,961 - INFO - epoch 2, step 57270, training loss = 1.569894, validation loss = 1.770887
2018-12-05 15:02:56,613 - INFO - epoch 2, step 57280, training loss = 1.433194, validation loss = 1.766288
2018-12-05 15:03:00,450 - INFO - epoch 2, step 57290, training loss = 1.650521, validation loss = 1.739949
2018-12-05 15:03:04,202 - INFO - epoch 2, step 57300, training loss = 1.404143, validation loss = 1.810554
2018-12-05 15:03:07,848 - INFO - epoch 2, step 57310, training loss = 1.416046, validation loss = 1.954310
2018-12-05 15:03:11,383 - INFO - epoch 2, step 57320, training loss = 1.621941, validation loss = 1.904234
2018-12-05 15:03:15,471 - INFO - epoch 2, step 57330, training loss = 1.611509, validation loss = 1.615439
2018-12-05 15:03:19,219 - INFO - epoch 2, step 57340, training loss = 1.579972, validation loss = 1.744361
2018-12-05 15:03:23,233 - INFO - epoch 2, step 57350, training loss = 1.165258, validation loss = 1.829750
2018-12-05 15:03:27,002 - INFO - epoch 2, step 57360, training loss = 1.624399, validation loss = 1.977466
2018-12-05 15:03:30,406 - INFO - epoch 2, step 57370, training loss = 1.520025, validation loss = 2.360353
2018-12-05 15:03:33,746 - INFO - epoch 2, step 57380, training loss = 1.682595, validation loss = 1.956230
2018-12-05 15:03:37,265 - INFO - epoch 2, step 57390, training loss = 1.607185, validation loss = 1.989424
2018-12-05 15:03:40,599 - INFO - epoch 2, step 57400, training loss = 1.812111, validation loss = 1.764205
2018-12-05 15:03:44,077 - INFO - epoch 2, step 57410, training loss = 1.585451, validation loss = 1.621686
2018-12-05 15:03:47,384 - INFO - epoch 2, step 57420, training loss = 1.829539, validation loss = 1.791476
2018-12-05 15:03:50,839 - INFO - epoch 2, step 57430, training loss = 1.576387, validation loss = 1.775361
2018-12-05 15:03:54,400 - INFO - epoch 2, step 57440, training loss = 1.506163, validation loss = 1.732939
2018-12-05 15:03:57,772 - INFO - epoch 2, step 57450, training loss = 1.582786, validation loss = 1.741899
2018-12-05 15:04:01,043 - INFO - epoch 2, step 57460, training loss = 1.998473, validation loss = 1.424159
2018-12-05 15:04:04,328 - INFO - epoch 2, step 57470, training loss = 1.791305, validation loss = 1.755476
2018-12-05 15:04:07,553 - INFO - epoch 2, step 57480, training loss = 1.775078, validation loss = 1.880901
2018-12-05 15:04:11,192 - INFO - epoch 2, step 57490, training loss = 1.430485, validation loss = 2.242327
2018-12-05 15:04:14,459 - INFO - epoch 2, step 57500, training loss = 1.520602, validation loss = 1.611635
2018-12-05 15:04:17,684 - INFO - epoch 2, step 57510, training loss = 1.566017, validation loss = 1.879426
2018-12-05 15:04:21,049 - INFO - epoch 2, step 57520, training loss = 1.722124, validation loss = 1.763029
2018-12-05 15:04:24,496 - INFO - epoch 2, step 57530, training loss = 1.431592, validation loss = 1.794061
2018-12-05 15:04:27,983 - INFO - epoch 2, step 57540, training loss = 1.697000, validation loss = 1.751031
2018-12-05 15:04:31,470 - INFO - epoch 2, step 57550, training loss = 1.655814, validation loss = 2.033411
2018-12-05 15:04:35,115 - INFO - epoch 2, step 57560, training loss = 1.374039, validation loss = 1.725818
2018-12-05 15:04:38,592 - INFO - epoch 2, step 57570, training loss = 1.738771, validation loss = 1.791252
2018-12-05 15:04:41,871 - INFO - epoch 2, step 57580, training loss = 1.966652, validation loss = 1.858535
2018-12-05 15:04:45,086 - INFO - epoch 2, step 57590, training loss = 1.808134, validation loss = 1.772564
2018-12-05 15:04:48,298 - INFO - epoch 2, step 57600, training loss = 1.595977, validation loss = 2.071341
2018-12-05 15:04:51,601 - INFO - epoch 2, step 57610, training loss = 1.811612, validation loss = 1.525545
2018-12-05 15:04:54,982 - INFO - epoch 2, step 57620, training loss = 1.423645, validation loss = 1.296165
2018-12-05 15:04:58,238 - INFO - epoch 2, step 57630, training loss = 1.644755, validation loss = 1.724434
2018-12-05 15:05:01,558 - INFO - epoch 2, step 57640, training loss = 1.311649, validation loss = 1.946595
2018-12-05 15:05:04,993 - INFO - epoch 2, step 57650, training loss = 1.360797, validation loss = 1.577785
2018-12-05 15:05:09,213 - INFO - epoch 2, step 57660, training loss = 1.464227, validation loss = 2.094373
2018-12-05 15:05:13,596 - INFO - epoch 2, step 57670, training loss = 1.769330, validation loss = 1.739709
2018-12-05 15:05:17,981 - INFO - epoch 2, step 57680, training loss = 1.546938, validation loss = 1.654955
2018-12-05 15:05:22,287 - INFO - epoch 2, step 57690, training loss = 1.688548, validation loss = 1.678240
2018-12-05 15:05:26,365 - INFO - epoch 2, step 57700, training loss = 1.971629, validation loss = 1.938514
2018-12-05 15:05:30,779 - INFO - epoch 2, step 57710, training loss = 1.164985, validation loss = 1.593463
2018-12-05 15:05:34,541 - INFO - epoch 2, step 57720, training loss = 1.664948, validation loss = 1.740402
2018-12-05 15:05:38,443 - INFO - epoch 2, step 57730, training loss = 1.636173, validation loss = 1.725767
2018-12-05 15:05:42,376 - INFO - epoch 2, step 57740, training loss = 1.409521, validation loss = 1.661306
2018-12-05 15:05:46,582 - INFO - epoch 2, step 57750, training loss = 1.989102, validation loss = 1.863319
2018-12-05 15:05:50,547 - INFO - epoch 2, step 57760, training loss = 1.617246, validation loss = 1.749129
2018-12-05 15:05:54,745 - INFO - epoch 2, step 57770, training loss = 1.538661, validation loss = 1.569227
2018-12-05 15:05:58,541 - INFO - epoch 2, step 57780, training loss = 1.562283, validation loss = 1.686257
2018-12-05 15:06:02,450 - INFO - epoch 2, step 57790, training loss = 1.451989, validation loss = 2.014769
2018-12-05 15:06:06,229 - INFO - epoch 2, step 57800, training loss = 1.448257, validation loss = 1.679268
2018-12-05 15:06:10,457 - INFO - epoch 2, step 57810, training loss = 1.577102, validation loss = 1.784385
2018-12-05 15:06:14,555 - INFO - epoch 2, step 57820, training loss = 1.578686, validation loss = 1.884654
2018-12-05 15:06:18,380 - INFO - epoch 2, step 57830, training loss = 1.783678, validation loss = 2.120467
2018-12-05 15:06:22,157 - INFO - epoch 2, step 57840, training loss = 1.894556, validation loss = 1.590274
2018-12-05 15:06:26,456 - INFO - epoch 2, step 57850, training loss = 1.753265, validation loss = 1.629432
2018-12-05 15:06:30,940 - INFO - epoch 2, step 57860, training loss = 1.671369, validation loss = 1.636110
2018-12-05 15:06:35,447 - INFO - epoch 2, step 57870, training loss = 1.628141, validation loss = 1.885204
2018-12-05 15:06:39,789 - INFO - epoch 2, step 57880, training loss = 1.466219, validation loss = 1.579627
2018-12-05 15:06:43,744 - INFO - epoch 2, step 57890, training loss = 1.615639, validation loss = 2.188252
2018-12-05 15:06:47,729 - INFO - epoch 2, step 57900, training loss = 1.712188, validation loss = 1.951630
2018-12-05 15:06:51,802 - INFO - epoch 2, step 57910, training loss = 1.674027, validation loss = 1.695339
2018-12-05 15:06:56,014 - INFO - epoch 2, step 57920, training loss = 1.607073, validation loss = 1.682493
2018-12-05 15:07:00,325 - INFO - epoch 2, step 57930, training loss = 1.585126, validation loss = 1.749679
2018-12-05 15:07:04,646 - INFO - epoch 2, step 57940, training loss = 1.805266, validation loss = 2.006154
2018-12-05 15:07:09,046 - INFO - epoch 2, step 57950, training loss = 1.201196, validation loss = 1.961354
2018-12-05 15:07:13,132 - INFO - epoch 2, step 57960, training loss = 1.587184, validation loss = 1.910149
2018-12-05 15:07:17,375 - INFO - epoch 2, step 57970, training loss = 1.442454, validation loss = 1.614141
2018-12-05 15:07:21,512 - INFO - epoch 2, step 57980, training loss = 1.311787, validation loss = 1.946826
2018-12-05 15:07:26,035 - INFO - epoch 2, step 57990, training loss = 1.865743, validation loss = 2.006061
2018-12-05 15:07:30,545 - INFO - epoch 2, step 58000, training loss = 1.415990, validation loss = 2.070805
2018-12-05 15:07:34,839 - INFO - epoch 2, step 58010, training loss = 1.579761, validation loss = 1.561457
2018-12-05 15:07:39,151 - INFO - epoch 2, step 58020, training loss = 1.440789, validation loss = 1.628350
2018-12-05 15:07:43,430 - INFO - epoch 2, step 58030, training loss = 1.641287, validation loss = 1.938444
2018-12-05 15:07:47,458 - INFO - epoch 2, step 58040, training loss = 1.603695, validation loss = 1.578347
2018-12-05 15:07:51,571 - INFO - epoch 2, step 58050, training loss = 1.344468, validation loss = 1.659566
2018-12-05 15:07:55,649 - INFO - epoch 2, step 58060, training loss = 1.698176, validation loss = 1.783222
2018-12-05 15:07:59,966 - INFO - epoch 2, step 58070, training loss = 1.635178, validation loss = 1.487778
2018-12-05 15:08:04,301 - INFO - epoch 2, step 58080, training loss = 1.612615, validation loss = 1.569016
2018-12-05 15:08:07,975 - INFO - epoch 2, step 58090, training loss = 1.453487, validation loss = 1.747583
2018-12-05 15:08:11,605 - INFO - epoch 2, step 58100, training loss = 1.518485, validation loss = 1.663874
2018-12-05 15:08:15,427 - INFO - epoch 2, step 58110, training loss = 1.553373, validation loss = 1.440099
2018-12-05 15:08:19,091 - INFO - epoch 2, step 58120, training loss = 1.389657, validation loss = 1.871019
2018-12-05 15:08:22,790 - INFO - epoch 2, step 58130, training loss = 1.557427, validation loss = 1.832801
2018-12-05 15:08:25,972 - INFO - epoch 2, step 58140, training loss = 1.648388, validation loss = 1.721090
2018-12-05 15:08:29,255 - INFO - epoch 2, step 58150, training loss = 1.687169, validation loss = 1.890919
2018-12-05 15:08:32,530 - INFO - epoch 2, step 58160, training loss = 1.524944, validation loss = 1.806464
2018-12-05 15:08:35,622 - INFO - epoch 2, step 58170, training loss = 1.765909, validation loss = 1.877925
2018-12-05 15:08:38,873 - INFO - epoch 2, step 58180, training loss = 1.989385, validation loss = 1.749166
2018-12-05 15:08:41,996 - INFO - epoch 2, step 58190, training loss = 1.825414, validation loss = 1.351713
2018-12-05 15:08:45,180 - INFO - epoch 2, step 58200, training loss = 1.861314, validation loss = 1.809268
2018-12-05 15:08:48,371 - INFO - epoch 2, step 58210, training loss = 1.875624, validation loss = 1.706430
2018-12-05 15:08:52,311 - INFO - epoch 2, step 58220, training loss = 1.409742, validation loss = 1.710094
2018-12-05 15:08:56,714 - INFO - epoch 2, step 58230, training loss = 1.508315, validation loss = 1.718123
2018-12-05 15:09:01,025 - INFO - epoch 2, step 58240, training loss = 1.403195, validation loss = 1.482250
2018-12-05 15:09:05,018 - INFO - epoch 2, step 58250, training loss = 1.520164, validation loss = 1.538345
2018-12-05 15:09:09,155 - INFO - epoch 2, step 58260, training loss = 1.302932, validation loss = 1.882398
2018-12-05 15:09:13,274 - INFO - epoch 2, step 58270, training loss = 1.295250, validation loss = 1.644145
2018-12-05 15:09:17,673 - INFO - epoch 2, step 58280, training loss = 1.491636, validation loss = 1.696327
2018-12-05 15:09:21,901 - INFO - epoch 2, step 58290, training loss = 1.483452, validation loss = 1.685935
2018-12-05 15:09:26,090 - INFO - epoch 2, step 58300, training loss = 1.314512, validation loss = 1.827495
2018-12-05 15:09:30,100 - INFO - epoch 2, step 58310, training loss = 1.626485, validation loss = 1.714137
2018-12-05 15:09:34,345 - INFO - epoch 2, step 58320, training loss = 1.405656, validation loss = 1.773594
2018-12-05 15:09:38,566 - INFO - epoch 2, step 58330, training loss = 1.412318, validation loss = 2.015913
2018-12-05 15:09:42,827 - INFO - epoch 2, step 58340, training loss = 1.422380, validation loss = 2.018723
2018-12-05 15:09:46,984 - INFO - epoch 2, step 58350, training loss = 1.668111, validation loss = 1.745855
2018-12-05 15:09:51,158 - INFO - epoch 2, step 58360, training loss = 1.491287, validation loss = 1.816810
2018-12-05 15:09:55,515 - INFO - epoch 2, step 58370, training loss = 1.304567, validation loss = 1.846350
2018-12-05 15:09:59,834 - INFO - epoch 2, step 58380, training loss = 1.485686, validation loss = 1.345478
2018-12-05 15:10:04,183 - INFO - epoch 2, step 58390, training loss = 1.449690, validation loss = 1.693460
2018-12-05 15:10:08,201 - INFO - epoch 2, step 58400, training loss = 1.866742, validation loss = 1.672051
2018-12-05 15:10:11,924 - INFO - epoch 2, step 58410, training loss = 1.712529, validation loss = 1.439947
2018-12-05 15:10:15,942 - INFO - epoch 2, step 58420, training loss = 1.582353, validation loss = 1.647723
2018-12-05 15:10:19,877 - INFO - epoch 2, step 58430, training loss = 1.293921, validation loss = 1.324967
2018-12-05 15:10:23,523 - INFO - epoch 2, step 58440, training loss = 1.708247, validation loss = 1.650209
2018-12-05 15:10:27,222 - INFO - epoch 2, step 58450, training loss = 1.409071, validation loss = 1.862682
2018-12-05 15:10:31,335 - INFO - epoch 2, step 58460, training loss = 1.567472, validation loss = 1.677942
2018-12-05 15:10:35,437 - INFO - epoch 2, step 58470, training loss = 1.181146, validation loss = 1.565645
2018-12-05 15:10:39,190 - INFO - epoch 2, step 58480, training loss = 1.454292, validation loss = 1.872244
2018-12-05 15:10:43,058 - INFO - epoch 2, step 58490, training loss = 1.525773, validation loss = 1.716666
2018-12-05 15:10:46,818 - INFO - epoch 2, step 58500, training loss = 1.697301, validation loss = 1.786742
2018-12-05 15:10:50,470 - INFO - epoch 2, step 58510, training loss = 1.524979, validation loss = 1.791247
2018-12-05 15:10:54,447 - INFO - epoch 2, step 58520, training loss = 1.429146, validation loss = 1.744874
2018-12-05 15:10:58,183 - INFO - epoch 2, step 58530, training loss = 1.407616, validation loss = 1.616067
2018-12-05 15:11:02,102 - INFO - epoch 2, step 58540, training loss = 1.396427, validation loss = 1.823724
2018-12-05 15:11:06,115 - INFO - epoch 2, step 58550, training loss = 1.540132, validation loss = 1.828716
2018-12-05 15:11:10,085 - INFO - epoch 2, step 58560, training loss = 1.918836, validation loss = 1.752470
2018-12-05 15:11:14,422 - INFO - epoch 2, step 58570, training loss = 1.625275, validation loss = 1.519695
2018-12-05 15:11:18,611 - INFO - epoch 2, step 58580, training loss = 1.256799, validation loss = 1.698729
2018-12-05 15:11:22,740 - INFO - epoch 2, step 58590, training loss = 1.471071, validation loss = 1.777988
2018-12-05 15:11:27,087 - INFO - epoch 2, step 58600, training loss = 1.451024, validation loss = 1.686523
2018-12-05 15:11:31,294 - INFO - epoch 2, step 58610, training loss = 1.745333, validation loss = 1.884919
2018-12-05 15:11:35,545 - INFO - epoch 2, step 58620, training loss = 1.452303, validation loss = 1.358344
2018-12-05 15:11:39,165 - INFO - epoch 2, step 58630, training loss = 1.920088, validation loss = 1.964600
2018-12-05 15:11:42,448 - INFO - epoch 2, step 58640, training loss = 1.811372, validation loss = 2.038025
2018-12-05 15:11:45,779 - INFO - epoch 2, step 58650, training loss = 1.524310, validation loss = 1.776360
2018-12-05 15:11:49,308 - INFO - epoch 2, step 58660, training loss = 1.701286, validation loss = 1.690685
2018-12-05 15:11:52,435 - INFO - epoch 2, step 58670, training loss = 1.685511, validation loss = 1.781668
2018-12-05 15:11:55,860 - INFO - epoch 2, step 58680, training loss = 1.409592, validation loss = 1.729537
2018-12-05 15:11:59,457 - INFO - epoch 2, step 58690, training loss = 1.735367, validation loss = 1.745401
2018-12-05 15:12:02,728 - INFO - epoch 2, step 58700, training loss = 1.715424, validation loss = 1.773140
2018-12-05 15:12:06,575 - INFO - epoch 2, step 58710, training loss = 1.658644, validation loss = 1.557619
2018-12-05 15:12:10,813 - INFO - epoch 2, step 58720, training loss = 1.642093, validation loss = 1.638469
2018-12-05 15:12:15,134 - INFO - epoch 2, step 58730, training loss = 1.585226, validation loss = 1.536632
2018-12-05 15:12:19,269 - INFO - epoch 2, step 58740, training loss = 1.313048, validation loss = 1.649692
2018-12-05 15:12:23,741 - INFO - epoch 2, step 58750, training loss = 1.095542, validation loss = 1.534353
2018-12-05 15:12:28,308 - INFO - epoch 2, step 58760, training loss = 1.650713, validation loss = 1.484763
2018-12-05 15:12:32,699 - INFO - epoch 2, step 58770, training loss = 1.510192, validation loss = 1.810081
2018-12-05 15:12:37,182 - INFO - epoch 2, step 58780, training loss = 1.506580, validation loss = 1.620999
2018-12-05 15:12:41,509 - INFO - epoch 2, step 58790, training loss = 1.316478, validation loss = 1.624586
2018-12-05 15:12:45,704 - INFO - epoch 2, step 58800, training loss = 1.321454, validation loss = 1.847214
2018-12-05 15:12:49,836 - INFO - epoch 2, step 58810, training loss = 1.566599, validation loss = 1.454486
2018-12-05 15:12:54,181 - INFO - epoch 2, step 58820, training loss = 1.370769, validation loss = 1.533479
2018-12-05 15:12:58,495 - INFO - epoch 2, step 58830, training loss = 1.736530, validation loss = 1.437186
2018-12-05 15:13:02,523 - INFO - epoch 2, step 58840, training loss = 1.318891, validation loss = 1.707047
2018-12-05 15:13:06,491 - INFO - epoch 2, step 58850, training loss = 1.461255, validation loss = 1.468109
2018-12-05 15:13:10,833 - INFO - epoch 2, step 58860, training loss = 1.299794, validation loss = 1.701746
2018-12-05 15:13:15,050 - INFO - epoch 2, step 58870, training loss = 1.321826, validation loss = 1.834733
2018-12-05 15:13:19,455 - INFO - epoch 2, step 58880, training loss = 1.719082, validation loss = 1.798553
2018-12-05 15:13:23,711 - INFO - epoch 2, step 58890, training loss = 1.666394, validation loss = 1.751495
2018-12-05 15:13:28,185 - INFO - epoch 2, step 58900, training loss = 1.689323, validation loss = 1.671430
2018-12-05 15:13:32,449 - INFO - epoch 2, step 58910, training loss = 1.802900, validation loss = 1.607617
2018-12-05 15:13:37,165 - INFO - epoch 2, step 58920, training loss = 1.825677, validation loss = 1.679873
2018-12-05 15:13:41,561 - INFO - epoch 2, step 58930, training loss = 1.403273, validation loss = 2.230604
2018-12-05 15:13:45,043 - INFO - epoch 2, step 58940, training loss = 1.886098, validation loss = 1.929629
2018-12-05 15:13:48,334 - INFO - epoch 2, step 58950, training loss = 1.810198, validation loss = 2.227565
2018-12-05 15:13:51,978 - INFO - epoch 2, step 58960, training loss = 1.797614, validation loss = 2.431364
2018-12-05 15:13:55,370 - INFO - epoch 2, step 58970, training loss = 1.933997, validation loss = 2.481095
2018-12-05 15:13:58,855 - INFO - epoch 2, step 58980, training loss = 1.784752, validation loss = 2.118402
2018-12-05 15:14:02,309 - INFO - epoch 2, step 58990, training loss = 1.826894, validation loss = 2.275135
2018-12-05 15:14:06,005 - INFO - epoch 2, step 59000, training loss = 1.559824, validation loss = 2.467957
2018-12-05 15:14:09,466 - INFO - epoch 2, step 59010, training loss = 1.699661, validation loss = 2.279933
2018-12-05 15:14:13,885 - INFO - epoch 2, step 59020, training loss = 1.742174, validation loss = 2.132075
2018-12-05 15:14:18,166 - INFO - epoch 2, step 59030, training loss = 1.533950, validation loss = 2.078945
2018-12-05 15:14:22,413 - INFO - epoch 2, step 59040, training loss = 1.560087, validation loss = 1.989530
2018-12-05 15:14:26,735 - INFO - epoch 2, step 59050, training loss = 1.490630, validation loss = 2.144664
2018-12-05 15:14:31,317 - INFO - epoch 2, step 59060, training loss = 1.511963, validation loss = 2.164246
2018-12-05 15:14:35,248 - INFO - epoch 2, step 59070, training loss = 1.443514, validation loss = 2.318975
2018-12-05 15:14:39,151 - INFO - epoch 2, step 59080, training loss = 1.735184, validation loss = 2.145466
2018-12-05 15:14:43,090 - INFO - epoch 2, step 59090, training loss = 1.680810, validation loss = 2.141020
2018-12-05 15:14:47,036 - INFO - epoch 2, step 59100, training loss = 1.312689, validation loss = 2.437772
2018-12-05 15:14:50,691 - INFO - epoch 2, step 59110, training loss = 1.574590, validation loss = 2.466082
2018-12-05 15:14:54,374 - INFO - epoch 2, step 59120, training loss = 1.475532, validation loss = 2.563750
2018-12-05 15:14:58,290 - INFO - epoch 2, step 59130, training loss = 1.579207, validation loss = 2.660639
2018-12-05 15:15:01,970 - INFO - epoch 2, step 59140, training loss = 1.326396, validation loss = 2.468848
2018-12-05 15:15:05,730 - INFO - epoch 2, step 59150, training loss = 1.426744, validation loss = 2.593892
2018-12-05 15:15:09,703 - INFO - epoch 2, step 59160, training loss = 1.595208, validation loss = 2.614185
2018-12-05 15:15:13,722 - INFO - epoch 2, step 59170, training loss = 1.423710, validation loss = 2.254373
2018-12-05 15:15:17,576 - INFO - epoch 2, step 59180, training loss = 1.791265, validation loss = 2.274495
2018-12-05 15:15:21,586 - INFO - epoch 2, step 59190, training loss = 1.437911, validation loss = 2.329150
2018-12-05 15:15:25,761 - INFO - epoch 2, step 59200, training loss = 1.343723, validation loss = 2.685471
2018-12-05 15:15:30,360 - INFO - epoch 2, step 59210, training loss = 1.340845, validation loss = 2.034249
2018-12-05 15:15:34,801 - INFO - epoch 2, step 59220, training loss = 1.642448, validation loss = 2.493585
2018-12-05 15:15:38,995 - INFO - epoch 2, step 59230, training loss = 1.445760, validation loss = 2.514111
2018-12-05 15:15:43,724 - INFO - epoch 2, step 59240, training loss = 1.534991, validation loss = 2.249937
2018-12-05 15:15:48,161 - INFO - epoch 2, step 59250, training loss = 1.155819, validation loss = 2.254915
2018-12-05 15:15:52,598 - INFO - epoch 2, step 59260, training loss = 1.434959, validation loss = 2.584272
2018-12-05 15:15:57,443 - INFO - epoch 2, step 59270, training loss = 1.552498, validation loss = 2.390937
2018-12-05 15:16:02,095 - INFO - epoch 2, step 59280, training loss = 1.415820, validation loss = 2.328655
2018-12-05 15:16:06,764 - INFO - epoch 2, step 59290, training loss = 1.532985, validation loss = 2.182387
2018-12-05 15:16:11,375 - INFO - epoch 2, step 59300, training loss = 1.681441, validation loss = 2.126011
2018-12-05 15:16:16,277 - INFO - epoch 2, step 59310, training loss = 1.637417, validation loss = 2.303961
2018-12-05 15:16:20,979 - INFO - epoch 2, step 59320, training loss = 1.519000, validation loss = 2.265283
2018-12-05 15:16:25,694 - INFO - epoch 2, step 59330, training loss = 1.530489, validation loss = 2.517557
2018-12-05 15:16:30,474 - INFO - epoch 2, step 59340, training loss = 1.619665, validation loss = 2.690502
2018-12-05 15:16:35,074 - INFO - epoch 2, step 59350, training loss = 1.432611, validation loss = 2.408671
2018-12-05 15:16:39,920 - INFO - epoch 2, step 59360, training loss = 1.498008, validation loss = 1.929858
2018-12-05 15:16:43,484 - INFO - epoch 2, step 59370, training loss = 1.760870, validation loss = 2.408906
2018-12-05 15:16:47,047 - INFO - epoch 2, step 59380, training loss = 1.710073, validation loss = 2.406701
2018-12-05 15:16:50,563 - INFO - epoch 2, step 59390, training loss = 1.726533, validation loss = 2.248693
2018-12-05 15:16:53,996 - INFO - epoch 2, step 59400, training loss = 1.814484, validation loss = 2.268438
2018-12-05 15:16:57,481 - INFO - epoch 2, step 59410, training loss = 1.522890, validation loss = 2.042790
2018-12-05 15:17:01,069 - INFO - epoch 2, step 59420, training loss = 1.471301, validation loss = 1.960244
2018-12-05 15:17:04,578 - INFO - epoch 2, step 59430, training loss = 1.546992, validation loss = 2.127305
2018-12-05 15:17:06,823 - INFO - Model saved in dir ./models
2018-12-05 15:17:10,929 - INFO - epoch 3, step 10, training loss = 2.284357, validation loss = 2.255198
2018-12-05 15:17:14,926 - INFO - epoch 3, step 20, training loss = 1.505929, validation loss = 2.019564
2018-12-05 15:17:18,949 - INFO - epoch 3, step 30, training loss = 2.042455, validation loss = 2.292015
2018-12-05 15:17:22,974 - INFO - epoch 3, step 40, training loss = 2.303619, validation loss = 1.851039
2018-12-05 15:17:26,837 - INFO - epoch 3, step 50, training loss = 2.420456, validation loss = 2.326676
2018-12-05 15:17:30,906 - INFO - epoch 3, step 60, training loss = 1.926658, validation loss = 2.352413
2018-12-05 15:17:34,783 - INFO - epoch 3, step 70, training loss = 1.606831, validation loss = 1.991824
2018-12-05 15:17:38,684 - INFO - epoch 3, step 80, training loss = 1.995973, validation loss = 2.243868
2018-12-05 15:17:42,659 - INFO - epoch 3, step 90, training loss = 1.934625, validation loss = 2.347785
2018-12-05 15:17:46,575 - INFO - epoch 3, step 100, training loss = 1.604380, validation loss = 2.465361
2018-12-05 15:17:50,633 - INFO - epoch 3, step 110, training loss = 2.098647, validation loss = 2.266684
2018-12-05 15:17:54,612 - INFO - epoch 3, step 120, training loss = 1.825122, validation loss = 1.981372
2018-12-05 15:17:58,639 - INFO - epoch 3, step 130, training loss = 2.023672, validation loss = 2.112900
2018-12-05 15:18:02,703 - INFO - epoch 3, step 140, training loss = 2.191400, validation loss = 2.036785
2018-12-05 15:18:06,606 - INFO - epoch 3, step 150, training loss = 2.030030, validation loss = 2.132076
2018-12-05 15:18:10,763 - INFO - epoch 3, step 160, training loss = 1.719934, validation loss = 2.566305
2018-12-05 15:18:14,819 - INFO - epoch 3, step 170, training loss = 2.081520, validation loss = 2.578561
2018-12-05 15:18:19,209 - INFO - epoch 3, step 180, training loss = 1.876591, validation loss = 2.467942
2018-12-05 15:18:24,078 - INFO - epoch 3, step 190, training loss = 2.295704, validation loss = 2.035882
2018-12-05 15:18:28,099 - INFO - epoch 3, step 200, training loss = 1.803255, validation loss = 2.313536
2018-12-05 15:18:32,411 - INFO - epoch 3, step 210, training loss = 1.993141, validation loss = 2.264805
2018-12-05 15:18:36,743 - INFO - epoch 3, step 220, training loss = 2.131608, validation loss = 2.284757
2018-12-05 15:18:41,136 - INFO - epoch 3, step 230, training loss = 1.835583, validation loss = 2.494608
2018-12-05 15:18:45,479 - INFO - epoch 3, step 240, training loss = 1.994855, validation loss = 2.457022
2018-12-05 15:18:49,849 - INFO - epoch 3, step 250, training loss = 1.949611, validation loss = 1.971857
2018-12-05 15:18:54,247 - INFO - epoch 3, step 260, training loss = 1.966268, validation loss = 2.117062
2018-12-05 15:18:58,430 - INFO - epoch 3, step 270, training loss = 1.770705, validation loss = 2.230373
2018-12-05 15:19:02,531 - INFO - epoch 3, step 280, training loss = 2.279526, validation loss = 1.996071
2018-12-05 15:19:06,680 - INFO - epoch 3, step 290, training loss = 1.775375, validation loss = 2.916684
2018-12-05 15:19:11,067 - INFO - epoch 3, step 300, training loss = 1.546150, validation loss = 2.258059
2018-12-05 15:19:15,287 - INFO - epoch 3, step 310, training loss = 2.255723, validation loss = 2.311662
2018-12-05 15:19:19,542 - INFO - epoch 3, step 320, training loss = 1.993239, validation loss = 2.223210
2018-12-05 15:19:23,411 - INFO - epoch 3, step 330, training loss = 2.234354, validation loss = 2.528984
2018-12-05 15:19:27,449 - INFO - epoch 3, step 340, training loss = 1.936472, validation loss = 2.415621
2018-12-05 15:19:31,203 - INFO - epoch 3, step 350, training loss = 1.875208, validation loss = 2.405150
2018-12-05 15:19:35,062 - INFO - epoch 3, step 360, training loss = 1.897141, validation loss = 2.156352
2018-12-05 15:19:39,363 - INFO - epoch 3, step 370, training loss = 1.852309, validation loss = 1.714513
2018-12-05 15:19:43,201 - INFO - epoch 3, step 380, training loss = 1.821660, validation loss = 1.977299
2018-12-05 15:19:47,352 - INFO - epoch 3, step 390, training loss = 2.074006, validation loss = 2.145993
2018-12-05 15:19:51,388 - INFO - epoch 3, step 400, training loss = 1.844330, validation loss = 1.858538
2018-12-05 15:19:55,273 - INFO - epoch 3, step 410, training loss = 2.196486, validation loss = 2.596471
2018-12-05 15:19:59,206 - INFO - epoch 3, step 420, training loss = 1.782324, validation loss = 2.059412
2018-12-05 15:20:03,512 - INFO - epoch 3, step 430, training loss = 1.872913, validation loss = 1.886917
2018-12-05 15:20:07,871 - INFO - epoch 3, step 440, training loss = 1.639102, validation loss = 2.369309
2018-12-05 15:20:12,125 - INFO - epoch 3, step 450, training loss = 1.943639, validation loss = 1.855783
2018-12-05 15:20:16,334 - INFO - epoch 3, step 460, training loss = 1.732244, validation loss = 2.167036
2018-12-05 15:20:20,479 - INFO - epoch 3, step 470, training loss = 2.168017, validation loss = 2.258525
2018-12-05 15:20:24,848 - INFO - epoch 3, step 480, training loss = 1.515062, validation loss = 2.052948
2018-12-05 15:20:29,311 - INFO - epoch 3, step 490, training loss = 1.604063, validation loss = 2.149959
2018-12-05 15:20:33,524 - INFO - epoch 3, step 500, training loss = 2.337363, validation loss = 2.441333
2018-12-05 15:20:37,803 - INFO - epoch 3, step 510, training loss = 1.569670, validation loss = 2.569467
2018-12-05 15:20:42,023 - INFO - epoch 3, step 520, training loss = 1.760851, validation loss = 2.218588
2018-12-05 15:20:46,187 - INFO - epoch 3, step 530, training loss = 1.795539, validation loss = 2.234671
2018-12-05 15:20:50,305 - INFO - epoch 3, step 540, training loss = 1.948121, validation loss = 1.775215
2018-12-05 15:20:54,349 - INFO - epoch 3, step 550, training loss = 1.886414, validation loss = 2.327131
2018-12-05 15:20:58,400 - INFO - epoch 3, step 560, training loss = 1.929563, validation loss = 2.199904
2018-12-05 15:21:02,442 - INFO - epoch 3, step 570, training loss = 1.502591, validation loss = 2.493521
2018-12-05 15:21:06,516 - INFO - epoch 3, step 580, training loss = 2.138963, validation loss = 1.917267
2018-12-05 15:21:10,786 - INFO - epoch 3, step 590, training loss = 1.886460, validation loss = 2.062113
2018-12-05 15:21:14,988 - INFO - epoch 3, step 600, training loss = 1.846161, validation loss = 2.274983
2018-12-05 15:21:19,162 - INFO - epoch 3, step 610, training loss = 1.892947, validation loss = 2.016963
2018-12-05 15:21:23,352 - INFO - epoch 3, step 620, training loss = 2.353246, validation loss = 2.290184
2018-12-05 15:21:27,464 - INFO - epoch 3, step 630, training loss = 2.042560, validation loss = 2.637648
2018-12-05 15:21:31,811 - INFO - epoch 3, step 640, training loss = 1.789156, validation loss = 2.213307
2018-12-05 15:21:35,918 - INFO - epoch 3, step 650, training loss = 1.901751, validation loss = 2.591650
2018-12-05 15:21:39,779 - INFO - epoch 3, step 660, training loss = 1.835332, validation loss = 2.350069
2018-12-05 15:21:43,928 - INFO - epoch 3, step 670, training loss = 2.078223, validation loss = 2.147246
2018-12-05 15:21:47,987 - INFO - epoch 3, step 680, training loss = 1.988202, validation loss = 1.993106
2018-12-05 15:21:52,297 - INFO - epoch 3, step 690, training loss = 1.941139, validation loss = 1.960410
2018-12-05 15:21:56,466 - INFO - epoch 3, step 700, training loss = 1.910571, validation loss = 2.569665
2018-12-05 15:22:00,601 - INFO - epoch 3, step 710, training loss = 1.834336, validation loss = 2.187888
2018-12-05 15:22:04,712 - INFO - epoch 3, step 720, training loss = 1.926459, validation loss = 2.450627
2018-12-05 15:22:08,936 - INFO - epoch 3, step 730, training loss = 1.925385, validation loss = 1.869847
2018-12-05 15:22:13,046 - INFO - epoch 3, step 740, training loss = 1.501914, validation loss = 2.046184
2018-12-05 15:22:17,309 - INFO - epoch 3, step 750, training loss = 2.279944, validation loss = 2.152013
2018-12-05 15:22:21,515 - INFO - epoch 3, step 760, training loss = 1.237923, validation loss = 2.119489
2018-12-05 15:22:25,725 - INFO - epoch 3, step 770, training loss = 2.172042, validation loss = 1.851897
2018-12-05 15:22:30,224 - INFO - epoch 3, step 780, training loss = 1.943298, validation loss = 1.994025
2018-12-05 15:22:34,797 - INFO - epoch 3, step 790, training loss = 1.972412, validation loss = 1.941938
2018-12-05 15:22:39,263 - INFO - epoch 3, step 800, training loss = 2.294283, validation loss = 1.916497
2018-12-05 15:22:44,399 - INFO - epoch 3, step 810, training loss = 2.109988, validation loss = 2.055558
2018-12-05 15:22:48,669 - INFO - epoch 3, step 820, training loss = 1.919529, validation loss = 2.423228
2018-12-05 15:22:52,987 - INFO - epoch 3, step 830, training loss = 2.061224, validation loss = 2.388799
2018-12-05 15:22:57,395 - INFO - epoch 3, step 840, training loss = 1.900406, validation loss = 2.353714
2018-12-05 15:23:01,712 - INFO - epoch 3, step 850, training loss = 1.983226, validation loss = 2.248046
2018-12-05 15:23:06,152 - INFO - epoch 3, step 860, training loss = 1.765249, validation loss = 2.017344
2018-12-05 15:23:10,387 - INFO - epoch 3, step 870, training loss = 2.246305, validation loss = 2.255433
2018-12-05 15:23:14,651 - INFO - epoch 3, step 880, training loss = 2.360359, validation loss = 2.030245
2018-12-05 15:23:19,203 - INFO - epoch 3, step 890, training loss = 1.739102, validation loss = 2.168461
2018-12-05 15:23:23,466 - INFO - epoch 3, step 900, training loss = 2.285466, validation loss = 2.410778
2018-12-05 15:23:27,974 - INFO - epoch 3, step 910, training loss = 1.783376, validation loss = 1.935777
2018-12-05 15:23:32,486 - INFO - epoch 3, step 920, training loss = 1.981865, validation loss = 1.528862
2018-12-05 15:23:37,194 - INFO - epoch 3, step 930, training loss = 2.140273, validation loss = 2.230947
2018-12-05 15:23:41,748 - INFO - epoch 3, step 940, training loss = 1.917557, validation loss = 2.089146
2018-12-05 15:23:46,254 - INFO - epoch 3, step 950, training loss = 1.803094, validation loss = 2.450431
2018-12-05 15:23:50,770 - INFO - epoch 3, step 960, training loss = 2.249554, validation loss = 2.424830
2018-12-05 15:23:55,078 - INFO - epoch 3, step 970, training loss = 1.885423, validation loss = 2.362259
2018-12-05 15:23:59,670 - INFO - epoch 3, step 980, training loss = 1.894794, validation loss = 2.131761
2018-12-05 15:24:04,152 - INFO - epoch 3, step 990, training loss = 2.037036, validation loss = 2.081183
2018-12-05 15:24:08,487 - INFO - epoch 3, step 1000, training loss = 1.994704, validation loss = 2.530723
2018-12-05 15:24:12,939 - INFO - epoch 3, step 1010, training loss = 1.705242, validation loss = 1.972555
2018-12-05 15:24:17,099 - INFO - epoch 3, step 1020, training loss = 2.011198, validation loss = 1.907303
2018-12-05 15:24:21,400 - INFO - epoch 3, step 1030, training loss = 2.063685, validation loss = 2.364438
2018-12-05 15:24:25,681 - INFO - epoch 3, step 1040, training loss = 2.051487, validation loss = 2.734447
2018-12-05 15:24:30,034 - INFO - epoch 3, step 1050, training loss = 2.020478, validation loss = 2.020131
2018-12-05 15:24:34,318 - INFO - epoch 3, step 1060, training loss = 2.139177, validation loss = 2.456065
2018-12-05 15:24:38,347 - INFO - epoch 3, step 1070, training loss = 1.928267, validation loss = 1.940974
2018-12-05 15:24:42,662 - INFO - epoch 3, step 1080, training loss = 1.917118, validation loss = 1.945843
2018-12-05 15:24:47,194 - INFO - epoch 3, step 1090, training loss = 1.822036, validation loss = 2.305634
2018-12-05 15:24:51,323 - INFO - epoch 3, step 1100, training loss = 2.003201, validation loss = 2.210135
2018-12-05 15:24:55,818 - INFO - epoch 3, step 1110, training loss = 1.991944, validation loss = 2.342799
2018-12-05 15:24:59,848 - INFO - epoch 3, step 1120, training loss = 1.925704, validation loss = 2.306947
2018-12-05 15:25:03,999 - INFO - epoch 3, step 1130, training loss = 1.892393, validation loss = 2.069055
2018-12-05 15:25:08,374 - INFO - epoch 3, step 1140, training loss = 1.766208, validation loss = 1.710255
2018-12-05 15:25:12,752 - INFO - epoch 3, step 1150, training loss = 1.630057, validation loss = 1.970641
2018-12-05 15:25:17,202 - INFO - epoch 3, step 1160, training loss = 2.066071, validation loss = 2.230297
2018-12-05 15:25:21,525 - INFO - epoch 3, step 1170, training loss = 1.958647, validation loss = 1.941329
2018-12-05 15:25:25,726 - INFO - epoch 3, step 1180, training loss = 2.005809, validation loss = 2.005870
2018-12-05 15:25:30,047 - INFO - epoch 3, step 1190, training loss = 2.094976, validation loss = 2.287159
2018-12-05 15:25:34,222 - INFO - epoch 3, step 1200, training loss = 2.249975, validation loss = 2.050993
2018-12-05 15:25:38,533 - INFO - epoch 3, step 1210, training loss = 1.941378, validation loss = 1.768739
2018-12-05 15:25:42,951 - INFO - epoch 3, step 1220, training loss = 1.544938, validation loss = 1.867251
2018-12-05 15:25:47,134 - INFO - epoch 3, step 1230, training loss = 1.995364, validation loss = 2.056601
2018-12-05 15:25:51,588 - INFO - epoch 3, step 1240, training loss = 2.023817, validation loss = 1.928846
2018-12-05 15:25:55,849 - INFO - epoch 3, step 1250, training loss = 1.795620, validation loss = 2.448777
2018-12-05 15:26:00,087 - INFO - epoch 3, step 1260, training loss = 2.100622, validation loss = 2.261694
2018-12-05 15:26:04,280 - INFO - epoch 3, step 1270, training loss = 1.983916, validation loss = 1.941394
2018-12-05 15:26:08,472 - INFO - epoch 3, step 1280, training loss = 1.851084, validation loss = 2.017893
2018-12-05 15:26:12,779 - INFO - epoch 3, step 1290, training loss = 1.737185, validation loss = 2.391122
2018-12-05 15:26:16,971 - INFO - epoch 3, step 1300, training loss = 2.082881, validation loss = 2.165673
2018-12-05 15:26:20,794 - INFO - epoch 3, step 1310, training loss = 1.769599, validation loss = 2.376644
2018-12-05 15:26:24,731 - INFO - epoch 3, step 1320, training loss = 2.194529, validation loss = 2.240501
2018-12-05 15:26:28,500 - INFO - epoch 3, step 1330, training loss = 2.044576, validation loss = 2.179091
2018-12-05 15:26:32,175 - INFO - epoch 3, step 1340, training loss = 2.108562, validation loss = 2.386556
2018-12-05 15:26:36,111 - INFO - epoch 3, step 1350, training loss = 1.931526, validation loss = 2.173181
2018-12-05 15:26:40,150 - INFO - epoch 3, step 1360, training loss = 2.104882, validation loss = 2.049098
2018-12-05 15:26:44,028 - INFO - epoch 3, step 1370, training loss = 2.023285, validation loss = 1.931967
2018-12-05 15:26:47,925 - INFO - epoch 3, step 1380, training loss = 2.105232, validation loss = 2.071396
2018-12-05 15:26:51,601 - INFO - epoch 3, step 1390, training loss = 2.112738, validation loss = 1.928939
2018-12-05 15:26:55,333 - INFO - epoch 3, step 1400, training loss = 1.691446, validation loss = 1.858121
2018-12-05 15:26:59,316 - INFO - epoch 3, step 1410, training loss = 2.081102, validation loss = 1.828021
2018-12-05 15:27:02,933 - INFO - epoch 3, step 1420, training loss = 1.824301, validation loss = 2.061032
2018-12-05 15:27:06,976 - INFO - epoch 3, step 1430, training loss = 1.891982, validation loss = 2.231357
2018-12-05 15:27:11,257 - INFO - epoch 3, step 1440, training loss = 1.795263, validation loss = 2.245049
2018-12-05 15:27:15,161 - INFO - epoch 3, step 1450, training loss = 1.667894, validation loss = 1.757418
2018-12-05 15:27:19,228 - INFO - epoch 3, step 1460, training loss = 1.839246, validation loss = 1.956687
2018-12-05 15:27:23,137 - INFO - epoch 3, step 1470, training loss = 1.622170, validation loss = 2.128680
2018-12-05 15:27:26,793 - INFO - epoch 3, step 1480, training loss = 2.073903, validation loss = 2.025182
2018-12-05 15:27:30,779 - INFO - epoch 3, step 1490, training loss = 1.788180, validation loss = 2.031315
2018-12-05 15:27:37,202 - INFO - epoch 3, step 1500, training loss = 0.560571, validation loss = 1.952390
2018-12-05 15:27:41,216 - INFO - epoch 3, step 1510, training loss = 2.104217, validation loss = 1.634612
2018-12-05 15:27:45,304 - INFO - epoch 3, step 1520, training loss = 2.044785, validation loss = 1.999687
2018-12-05 15:27:49,238 - INFO - epoch 3, step 1530, training loss = 1.702079, validation loss = 2.113327
2018-12-05 15:27:53,256 - INFO - epoch 3, step 1540, training loss = 1.641672, validation loss = 2.141778
2018-12-05 15:27:57,225 - INFO - epoch 3, step 1550, training loss = 2.088226, validation loss = 2.305880
2018-12-05 15:28:01,255 - INFO - epoch 3, step 1560, training loss = 1.894634, validation loss = 1.733688
2018-12-05 15:28:05,595 - INFO - epoch 3, step 1570, training loss = 1.606808, validation loss = 1.683172
2018-12-05 15:28:09,422 - INFO - epoch 3, step 1580, training loss = 2.103990, validation loss = 1.963744
2018-12-05 15:28:13,272 - INFO - epoch 3, step 1590, training loss = 1.888435, validation loss = 1.942937
2018-12-05 15:28:16,946 - INFO - epoch 3, step 1600, training loss = 2.139388, validation loss = 2.348181
2018-12-05 15:28:20,786 - INFO - epoch 3, step 1610, training loss = 1.593170, validation loss = 1.880601
2018-12-05 15:28:24,736 - INFO - epoch 3, step 1620, training loss = 1.643309, validation loss = 2.233796
2018-12-05 15:28:28,441 - INFO - epoch 3, step 1630, training loss = 1.792405, validation loss = 1.661750
2018-12-05 15:28:32,220 - INFO - epoch 3, step 1640, training loss = 1.723554, validation loss = 1.862613
2018-12-05 15:28:36,224 - INFO - epoch 3, step 1650, training loss = 2.041516, validation loss = 1.829032
2018-12-05 15:28:41,284 - INFO - epoch 3, step 1660, training loss = 2.231065, validation loss = 2.312529
2018-12-05 15:28:46,552 - INFO - epoch 3, step 1670, training loss = 2.029089, validation loss = 2.403686
2018-12-05 15:28:50,419 - INFO - epoch 3, step 1680, training loss = 1.555743, validation loss = 1.866319
2018-12-05 15:28:54,282 - INFO - epoch 3, step 1690, training loss = 2.112042, validation loss = 2.186137
2018-12-05 15:28:58,039 - INFO - epoch 3, step 1700, training loss = 2.097728, validation loss = 2.191173
2018-12-05 15:29:01,707 - INFO - epoch 3, step 1710, training loss = 2.074925, validation loss = 2.602442
2018-12-05 15:29:05,691 - INFO - epoch 3, step 1720, training loss = 1.588560, validation loss = 2.621831
2018-12-05 15:29:09,469 - INFO - epoch 3, step 1730, training loss = 1.947121, validation loss = 1.779057
2018-12-05 15:29:12,904 - INFO - epoch 3, step 1740, training loss = 1.757189, validation loss = 1.933868
2018-12-05 15:29:16,372 - INFO - epoch 3, step 1750, training loss = 2.111145, validation loss = 2.138587
2018-12-05 15:29:19,907 - INFO - epoch 3, step 1760, training loss = 2.165517, validation loss = 2.464797
2018-12-05 15:29:23,598 - INFO - epoch 3, step 1770, training loss = 2.315410, validation loss = 2.102089
2018-12-05 15:29:27,199 - INFO - epoch 3, step 1780, training loss = 1.730905, validation loss = 1.988965
2018-12-05 15:29:30,728 - INFO - epoch 3, step 1790, training loss = 2.191329, validation loss = 2.052182
2018-12-05 15:29:34,246 - INFO - epoch 3, step 1800, training loss = 2.114943, validation loss = 2.241423
2018-12-05 15:29:37,834 - INFO - epoch 3, step 1810, training loss = 1.433644, validation loss = 2.287269
2018-12-05 15:29:41,552 - INFO - epoch 3, step 1820, training loss = 1.398697, validation loss = 2.455178
2018-12-05 15:29:45,134 - INFO - epoch 3, step 1830, training loss = 2.191581, validation loss = 2.411372
2018-12-05 15:29:48,866 - INFO - epoch 3, step 1840, training loss = 1.969847, validation loss = 2.499174
2018-12-05 15:29:52,631 - INFO - epoch 3, step 1850, training loss = 2.111855, validation loss = 1.755349
2018-12-05 15:29:57,064 - INFO - epoch 3, step 1860, training loss = 2.226897, validation loss = 2.095598
2018-12-05 15:30:01,329 - INFO - epoch 3, step 1870, training loss = 1.873200, validation loss = 1.999423
2018-12-05 15:30:05,777 - INFO - epoch 3, step 1880, training loss = 2.023987, validation loss = 2.214868
2018-12-05 15:30:10,241 - INFO - epoch 3, step 1890, training loss = 2.094224, validation loss = 2.213128
2018-12-05 15:30:14,810 - INFO - epoch 3, step 1900, training loss = 1.996784, validation loss = 1.975298
2018-12-05 15:30:19,212 - INFO - epoch 3, step 1910, training loss = 1.588414, validation loss = 1.951380
2018-12-05 15:30:23,479 - INFO - epoch 3, step 1920, training loss = 1.927639, validation loss = 2.180905
2018-12-05 15:30:27,915 - INFO - epoch 3, step 1930, training loss = 2.355331, validation loss = 2.070831
2018-12-05 15:30:32,645 - INFO - epoch 3, step 1940, training loss = 1.904460, validation loss = 1.979061
2018-12-05 15:30:37,082 - INFO - epoch 3, step 1950, training loss = 2.279927, validation loss = 2.011956
2018-12-05 15:30:40,582 - INFO - epoch 3, step 1960, training loss = 2.033404, validation loss = 1.900514
2018-12-05 15:30:44,136 - INFO - epoch 3, step 1970, training loss = 1.885130, validation loss = 2.207536
2018-12-05 15:30:47,463 - INFO - epoch 3, step 1980, training loss = 1.918129, validation loss = 2.435677
2018-12-05 15:30:51,201 - INFO - epoch 3, step 1990, training loss = 1.938107, validation loss = 1.611991
2018-12-05 15:30:54,681 - INFO - epoch 3, step 2000, training loss = 2.000474, validation loss = 1.925387
2018-12-05 15:30:58,098 - INFO - epoch 3, step 2010, training loss = 2.461316, validation loss = 2.326501
2018-12-05 15:31:01,577 - INFO - epoch 3, step 2020, training loss = 2.110533, validation loss = 2.335104
2018-12-05 15:31:04,907 - INFO - epoch 3, step 2030, training loss = 2.068858, validation loss = 2.526778
2018-12-05 15:31:08,290 - INFO - epoch 3, step 2040, training loss = 1.837237, validation loss = 1.931631
2018-12-05 15:31:11,879 - INFO - epoch 3, step 2050, training loss = 1.949149, validation loss = 1.744523
2018-12-05 15:31:15,489 - INFO - epoch 3, step 2060, training loss = 2.107902, validation loss = 2.014139
2018-12-05 15:31:19,053 - INFO - epoch 3, step 2070, training loss = 1.662158, validation loss = 1.868457
2018-12-05 15:31:22,633 - INFO - epoch 3, step 2080, training loss = 2.374387, validation loss = 2.367118
2018-12-05 15:31:25,981 - INFO - epoch 3, step 2090, training loss = 1.853786, validation loss = 2.579144
2018-12-05 15:31:29,584 - INFO - epoch 3, step 2100, training loss = 2.108362, validation loss = 2.075400
2018-12-05 15:31:33,172 - INFO - epoch 3, step 2110, training loss = 1.729836, validation loss = 2.063075
2018-12-05 15:31:36,691 - INFO - epoch 3, step 2120, training loss = 1.832911, validation loss = 2.124617
2018-12-05 15:31:40,339 - INFO - epoch 3, step 2130, training loss = 1.464007, validation loss = 1.938385
2018-12-05 15:31:43,777 - INFO - epoch 3, step 2140, training loss = 1.803739, validation loss = 2.295574
2018-12-05 15:31:47,372 - INFO - epoch 3, step 2150, training loss = 1.367111, validation loss = 1.852874
2018-12-05 15:31:50,962 - INFO - epoch 3, step 2160, training loss = 1.762056, validation loss = 2.288254
2018-12-05 15:31:54,508 - INFO - epoch 3, step 2170, training loss = 2.007401, validation loss = 1.844638
2018-12-05 15:31:58,073 - INFO - epoch 3, step 2180, training loss = 2.269116, validation loss = 1.905605
2018-12-05 15:32:01,814 - INFO - epoch 3, step 2190, training loss = 1.989600, validation loss = 1.947207
2018-12-05 15:32:05,520 - INFO - epoch 3, step 2200, training loss = 2.176606, validation loss = 2.417425
2018-12-05 15:32:09,440 - INFO - epoch 3, step 2210, training loss = 1.939934, validation loss = 2.101656
2018-12-05 15:32:13,169 - INFO - epoch 3, step 2220, training loss = 1.680701, validation loss = 1.836548
2018-12-05 15:32:16,952 - INFO - epoch 3, step 2230, training loss = 1.941945, validation loss = 1.815573
2018-12-05 15:32:20,664 - INFO - epoch 3, step 2240, training loss = 2.241463, validation loss = 2.083445
2018-12-05 15:32:24,618 - INFO - epoch 3, step 2250, training loss = 1.666946, validation loss = 2.582080
2018-12-05 15:32:28,209 - INFO - epoch 3, step 2260, training loss = 2.045828, validation loss = 2.230459
2018-12-05 15:32:32,132 - INFO - epoch 3, step 2270, training loss = 1.809908, validation loss = 1.985845
2018-12-05 15:32:36,010 - INFO - epoch 3, step 2280, training loss = 1.839809, validation loss = 2.245621
2018-12-05 15:32:40,261 - INFO - epoch 3, step 2290, training loss = 2.141625, validation loss = 2.048590
2018-12-05 15:32:44,522 - INFO - epoch 3, step 2300, training loss = 1.949341, validation loss = 2.650189
2018-12-05 15:32:48,857 - INFO - epoch 3, step 2310, training loss = 1.892712, validation loss = 1.840436
2018-12-05 15:32:52,969 - INFO - epoch 3, step 2320, training loss = 1.992689, validation loss = 1.937369
2018-12-05 15:32:57,452 - INFO - epoch 3, step 2330, training loss = 1.907201, validation loss = 1.929395
2018-12-05 15:33:01,534 - INFO - epoch 3, step 2340, training loss = 2.011067, validation loss = 2.203211
2018-12-05 15:33:05,707 - INFO - epoch 3, step 2350, training loss = 2.038793, validation loss = 2.235605
2018-12-05 15:33:09,914 - INFO - epoch 3, step 2360, training loss = 1.962175, validation loss = 2.127161
2018-12-05 15:33:13,922 - INFO - epoch 3, step 2370, training loss = 2.174370, validation loss = 2.006449
2018-12-05 15:33:18,310 - INFO - epoch 3, step 2380, training loss = 2.045171, validation loss = 1.635560
2018-12-05 15:33:22,652 - INFO - epoch 3, step 2390, training loss = 1.784419, validation loss = 1.679916
2018-12-05 15:33:26,836 - INFO - epoch 3, step 2400, training loss = 1.740879, validation loss = 1.844231
2018-12-05 15:33:30,920 - INFO - epoch 3, step 2410, training loss = 1.835924, validation loss = 2.001020
2018-12-05 15:33:35,551 - INFO - epoch 3, step 2420, training loss = 1.921143, validation loss = 1.959788
2018-12-05 15:33:39,542 - INFO - epoch 3, step 2430, training loss = 2.141532, validation loss = 1.861101
2018-12-05 15:33:43,357 - INFO - epoch 3, step 2440, training loss = 2.196717, validation loss = 1.728143
2018-12-05 15:33:47,180 - INFO - epoch 3, step 2450, training loss = 1.768850, validation loss = 2.098066
2018-12-05 15:33:50,999 - INFO - epoch 3, step 2460, training loss = 1.896119, validation loss = 2.305207
2018-12-05 15:33:54,810 - INFO - epoch 3, step 2470, training loss = 1.902072, validation loss = 2.103556
2018-12-05 15:33:58,691 - INFO - epoch 3, step 2480, training loss = 1.913349, validation loss = 2.072278
2018-12-05 15:34:02,821 - INFO - epoch 3, step 2490, training loss = 1.745550, validation loss = 2.032358
2018-12-05 15:34:06,523 - INFO - epoch 3, step 2500, training loss = 2.092001, validation loss = 2.218697
2018-12-05 15:34:10,177 - INFO - epoch 3, step 2510, training loss = 1.757759, validation loss = 2.286780
2018-12-05 15:34:13,859 - INFO - epoch 3, step 2520, training loss = 2.046335, validation loss = 2.201466
2018-12-05 15:34:17,618 - INFO - epoch 3, step 2530, training loss = 1.765052, validation loss = 1.819414
2018-12-05 15:34:21,250 - INFO - epoch 3, step 2540, training loss = 1.882422, validation loss = 2.115213
2018-12-05 15:34:25,016 - INFO - epoch 3, step 2550, training loss = 1.781472, validation loss = 2.154864
2018-12-05 15:34:28,705 - INFO - epoch 3, step 2560, training loss = 1.994461, validation loss = 2.156295
2018-12-05 15:34:32,456 - INFO - epoch 3, step 2570, training loss = 1.661766, validation loss = 1.742221
2018-12-05 15:34:36,190 - INFO - epoch 3, step 2580, training loss = 1.873735, validation loss = 1.847717
2018-12-05 15:34:39,990 - INFO - epoch 3, step 2590, training loss = 1.171055, validation loss = 2.247293
2018-12-05 15:34:43,886 - INFO - epoch 3, step 2600, training loss = 1.900204, validation loss = 2.596189
2018-12-05 15:34:47,805 - INFO - epoch 3, step 2610, training loss = 1.778280, validation loss = 2.281582
2018-12-05 15:34:51,628 - INFO - epoch 3, step 2620, training loss = 1.217795, validation loss = 2.033107
2018-12-05 15:34:55,199 - INFO - epoch 3, step 2630, training loss = 1.810987, validation loss = 2.445323
2018-12-05 15:34:58,782 - INFO - epoch 3, step 2640, training loss = 1.806902, validation loss = 2.210292
2018-12-05 15:35:02,865 - INFO - epoch 3, step 2650, training loss = 1.809016, validation loss = 2.070387
2018-12-05 15:35:07,230 - INFO - epoch 3, step 2660, training loss = 1.908070, validation loss = 1.941086
2018-12-05 15:35:11,470 - INFO - epoch 3, step 2670, training loss = 2.187611, validation loss = 2.098056
2018-12-05 15:35:15,673 - INFO - epoch 3, step 2680, training loss = 2.146099, validation loss = 2.151827
2018-12-05 15:35:20,317 - INFO - epoch 3, step 2690, training loss = 1.822883, validation loss = 1.845209
2018-12-05 15:35:24,698 - INFO - epoch 3, step 2700, training loss = 2.003747, validation loss = 1.577466
2018-12-05 15:35:28,918 - INFO - epoch 3, step 2710, training loss = 2.119395, validation loss = 1.874851
2018-12-05 15:35:33,276 - INFO - epoch 3, step 2720, training loss = 1.865196, validation loss = 2.080821
2018-12-05 15:35:37,617 - INFO - epoch 3, step 2730, training loss = 2.261858, validation loss = 2.610787
2018-12-05 15:35:42,103 - INFO - epoch 3, step 2740, training loss = 2.124254, validation loss = 1.870703
2018-12-05 15:35:46,419 - INFO - epoch 3, step 2750, training loss = 1.815307, validation loss = 1.912135
2018-12-05 15:35:50,710 - INFO - epoch 3, step 2760, training loss = 1.937577, validation loss = 2.163783
2018-12-05 15:35:55,248 - INFO - epoch 3, step 2770, training loss = 2.034179, validation loss = 2.336721
2018-12-05 15:35:59,582 - INFO - epoch 3, step 2780, training loss = 2.051971, validation loss = 2.401663
2018-12-05 15:36:03,668 - INFO - epoch 3, step 2790, training loss = 1.794826, validation loss = 2.131351
2018-12-05 15:36:08,004 - INFO - epoch 3, step 2800, training loss = 2.136236, validation loss = 1.684802
2018-12-05 15:36:12,259 - INFO - epoch 3, step 2810, training loss = 2.024196, validation loss = 2.111541
2018-12-05 15:36:16,351 - INFO - epoch 3, step 2820, training loss = 2.323056, validation loss = 2.446355
2018-12-05 15:36:20,225 - INFO - epoch 3, step 2830, training loss = 1.857407, validation loss = 2.246620
